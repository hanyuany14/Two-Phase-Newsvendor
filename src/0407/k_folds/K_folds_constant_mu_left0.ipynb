{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpAJ7uLZxpkB"
   },
   "source": [
    "# Week HW 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmCtfhVmxlqf"
   },
   "source": [
    "# Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9zBt0n0EZLVO",
    "outputId": "6e9e44a1-d4ec-4ca4-f089-7102126a2f8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter WLSAccessID\n",
      "Set parameter WLSSecret\n",
      "Set parameter LicenseID to value 2563044\n"
     ]
    },
    {
     "ename": "GurobiError",
     "evalue": "License 2563044 has expired",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGurobiError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 26\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m     20\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWLSACCESSID\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m73a6e3bf-2a9d-41e8-85eb-dd9b9eda802b\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWLSSECRET\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc394298a-96ea-4c8c-9d5e-ef2bd5032427\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLICENSEID\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2563044\u001b[39m,\n\u001b[1;32m     24\u001b[0m }\n\u001b[0;32m---> 26\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mgp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m model \u001b[38;5;241m=\u001b[39m gp\u001b[38;5;241m.\u001b[39mModel(env\u001b[38;5;241m=\u001b[39menv)\n",
      "File \u001b[0;32msrc/gurobipy/env.pxi:70\u001b[0m, in \u001b[0;36mgurobipy.Env.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mGurobiError\u001b[0m: License 2563044 has expired"
     ]
    }
   ],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import gurobipy_pandas as gppd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gurobipy import min_, max_\n",
    "from scipy.stats import multivariate_normal, norm\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "params = {\n",
    "    \"WLSACCESSID\": \"73a6e3bf-2a9d-41e8-85eb-dd9b9eda802b\",\n",
    "    \"WLSSECRET\": \"c394298a-96ea-4c8c-9d5e-ef2bd5032427\",\n",
    "    \"LICENSEID\": 2563044,\n",
    "}\n",
    "\n",
    "env = gp.Env(params=params)\n",
    "model = gp.Model(env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTASer1nQ6iQ"
   },
   "source": [
    "# Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2lZY1EXmRAie"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "#####################\n",
    "\n",
    "salvage_value = 0\n",
    "cost = 400\n",
    "price = 1000\n",
    "holding_cost = 0\n",
    "\n",
    "model_prefix = f\"med_with_holding_cost_{holding_cost}\"\n",
    "\n",
    "#####################\n",
    "\n",
    "CHUNK_SIZE = 30\n",
    "data_size = CHUNK_SIZE * 3\n",
    "train_size = 0.5\n",
    "testing_size = 0.5\n",
    "\n",
    "T = 10\n",
    "service_level = 0.95  # 服務水準\n",
    "M = 5000000\n",
    "LASSO_BETA = 100\n",
    "LASSO_ALPHA = 0.1\n",
    "LASSO_BETA_SECOND_TRAIN = 0.9\n",
    "\n",
    "\n",
    "ASSIGNED_FS = np.arange(0.1, 1.0, 0.1)\n",
    "ASSIGNED_TS = list(range(2, T))  # 2 到 T-1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Gurobi Model Constants\n",
    "THREADS = 12\n",
    "TIME_LIMIT = 20000\n",
    "MIPGAP = 0.01\n",
    "CURRENT_TIMESTAMP = int(datetime.now().strftime(\"%Y%m%d%H%M\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRmALsClGzQB"
   },
   "source": [
    "# Utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models' Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_parameters(\n",
    "    name: str,\n",
    "    alpha_values=None,\n",
    "    beta_values=None,\n",
    "    f_values=None,\n",
    "    tau_values=None,\n",
    "    data_size=data_size,\n",
    "    current_timestamp=CURRENT_TIMESTAMP,\n",
    "):\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "    params = {}\n",
    "    if alpha_values is not None:\n",
    "        params[\"alpha\"] = alpha_values\n",
    "    if beta_values is not None:\n",
    "        params[\"beta\"] = beta_values\n",
    "    if f_values is not None:\n",
    "        params[\"f_values\"] = f_values\n",
    "    if tau_values is not None:\n",
    "        params[\"tau_values\"] = tau_values\n",
    "\n",
    "    # 如果有參數才進行保存\n",
    "    if params:\n",
    "        with open(f\"models/{name}_{data_size}_{current_timestamp}.pkl\", \"wb\") as f:\n",
    "            pickle.dump(params, f)\n",
    "        print(\n",
    "            f\"Model parameters saved as models/{name}_{data_size}_{current_timestamp}.pkl\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"No parameters provided to save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_model_parameters(name: str, data_size: int):\n",
    "    # 構建檔案的路徑\n",
    "    file_path = f\"models/{name}_{data_size}_{CURRENT_TIMESTAMP}.pkl\"\n",
    "\n",
    "    # 檢查檔案是否存在\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "        print(f\"Model parameters file '{file_path}' has been deleted.\")\n",
    "    else:\n",
    "        print(f\"File '{file_path}' does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_models(model_prefix):\n",
    "    file_paths = sorted(glob.glob(f\"models/{model_prefix}_*.pkl\"))\n",
    "\n",
    "    # 逐一讀取並打印每個檔案的內容\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            params = pickle.load(f)\n",
    "            print(f\"Contents of {file_path}:\")\n",
    "            print(params)\n",
    "            print()  # 空行分隔每個檔案的內容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_models(\"linear_constraint_med_with_holding_cost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_models(\"med_with_holding_cost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_strategies_profits_scatter(save_type, dfs: dict):\n",
    "    names = list(dfs.keys())\n",
    "    df_list = [dfs[name] for name in names]\n",
    "\n",
    "    if len(df_list) <= 1:\n",
    "        print(\"No dataframes to plot.\")\n",
    "        return\n",
    "\n",
    "    pairs = list(itertools.combinations(range(len(df_list)), 2))\n",
    "    num_pairs = len(pairs)\n",
    "    grid_size = math.ceil(math.sqrt(num_pairs))\n",
    "    fig, axes = plt.subplots(grid_size, grid_size, figsize=(15, 15))\n",
    "    fig.suptitle(\"Scatter Plots of Profits (Matrix View)\")\n",
    "\n",
    "    for idx, (i, j) in enumerate(pairs):\n",
    "        row, col = divmod(idx, grid_size)\n",
    "        df_i, df_j = df_list[i], df_list[j]\n",
    "\n",
    "        if df_i is None or df_j is None or df_i.empty or df_j.empty:\n",
    "            continue\n",
    "        if len(df_i) != len(df_j):\n",
    "            continue\n",
    "\n",
    "        ax = axes[row, col]\n",
    "        ax.scatter(df_i[\"profits\"], df_j[\"profits\"], alpha=0.6)\n",
    "        ax.plot(\n",
    "            [\n",
    "                min(df_i[\"profits\"].min(), df_j[\"profits\"].min()),\n",
    "                max(df_i[\"profits\"].max(), df_j[\"profits\"].max()),\n",
    "            ],\n",
    "            [\n",
    "                min(df_i[\"profits\"].min(), df_j[\"profits\"].min()),\n",
    "                max(df_i[\"profits\"].max(), df_j[\"profits\"].max()),\n",
    "            ],\n",
    "            \"k--\",\n",
    "            linewidth=1,\n",
    "        )\n",
    "        ax.set_xlabel(names[i])\n",
    "        ax.set_ylabel(names[j])\n",
    "        ax.set_title(f\"{names[i]} vs {names[j]}\")\n",
    "\n",
    "    # Remove empty subplots\n",
    "    for idx in range(num_pairs, grid_size * grid_size):\n",
    "        row, col = divmod(idx, grid_size)\n",
    "        fig.delaxes(axes[row, col])\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "    os.makedirs(\"plots\", exist_ok=True)\n",
    "    save_path = f\"plots/plot_strategies_profits_scatter_{save_type}.png\"\n",
    "    plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "    print(f\"Plot saved as {save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_relative_profit_deviation(save_type, baseline_profit, max_profits):\n",
    "    \"\"\"\n",
    "    繪製多個策略相對於基準的平均利潤偏差。\n",
    "\n",
    "    :param baseline_profit: 基準利潤值\n",
    "    :param max_profits: 各策略的最大利潤列表，包含 None 值或 -1 表示無效數據\n",
    "    \"\"\"\n",
    "    print(f\"Baseline is: {baseline_profit}\")\n",
    "    for i, profit in enumerate(max_profits):\n",
    "        print(f\"S{i+1}'s profit: {profit}\")\n",
    "\n",
    "    # 計算相對值\n",
    "    ratios = {}\n",
    "    for idx, max_profit in enumerate(max_profits, start=1):\n",
    "        if max_profit is not None and max_profit != -1:\n",
    "            if baseline_profit != 0:\n",
    "                ratio = (max_profit - baseline_profit) / abs(baseline_profit)\n",
    "                ratios[f\"S{idx}\"] = ratio\n",
    "            else:\n",
    "                # 基準利潤為零時，直接記錄增量\n",
    "                ratio = max_profit\n",
    "                ratios[f\"S{idx}\"] = ratio\n",
    "\n",
    "    # 設置 y 軸範圍\n",
    "    if ratios:\n",
    "        y_min = min(ratios.values()) - 0.1\n",
    "        y_max = max(ratios.values()) + 0.1\n",
    "    else:\n",
    "        y_min, y_max = -0.1, 0.1\n",
    "\n",
    "    # 創建圖表顯示結果\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    if ratios:\n",
    "        bars = plt.bar(\n",
    "            ratios.keys(), ratios.values(), color=plt.cm.tab10(range(len(ratios)))\n",
    "        )\n",
    "\n",
    "        # 在每個柱狀圖上標出數值\n",
    "        for bar in bars:\n",
    "            yval = bar.get_height()\n",
    "            plt.text(\n",
    "                bar.get_x() + bar.get_width() / 2,\n",
    "                yval,\n",
    "                f\"{yval:.4f}\",\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "            )\n",
    "\n",
    "    # 添加基準線，表示基準值（No Opt）\n",
    "    plt.axhline(y=0, color=\"gray\", linestyle=\"--\", label=\"Baseline (No Opt)\")\n",
    "\n",
    "    # 設置圖表標題和軸標籤\n",
    "    plt.title(\"Relative Avg Profit Deviation from Baseline (1)\")\n",
    "    plt.xlabel(\"Strategies\")\n",
    "    plt.ylabel(\"Deviation from Baseline (1)\")\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.legend()\n",
    "\n",
    "    name = \"plot_relative_profit_deviation\"\n",
    "\n",
    "    os.makedirs(\"plots\", exist_ok=True)\n",
    "    save_path = f\"plots/{name}_{save_type}_{data_size}_{CURRENT_TIMESTAMP}.png\"\n",
    "\n",
    "    plt.savefig(save_path, format=\"png\", bbox_inches=\"tight\")\n",
    "    print(f\"Plot saved as {save_path}\")\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_relative_profit_comparison(\n",
    "    save_type,\n",
    "    train_baseline_profit,\n",
    "    test_baseline_profit,\n",
    "    test_max_profits,\n",
    "    train_max_profits,\n",
    "):\n",
    "\n",
    "    # Calculate relative deviations from baseline for test and train data\n",
    "    test_ratios, train_ratios = {}, {}\n",
    "    for idx, (test_profit, train_profit) in enumerate(\n",
    "        zip(test_max_profits, train_max_profits), start=1\n",
    "    ):\n",
    "        if test_profit is not None and test_profit != -1:\n",
    "            if test_baseline_profit != 0:\n",
    "                test_ratio = (test_profit - test_baseline_profit) / abs(\n",
    "                    test_baseline_profit\n",
    "                )  # Relative deviation\n",
    "            else:\n",
    "                test_ratio = test_profit  # Use profit directly if baseline is zero\n",
    "            test_ratios[f\"S{idx}\"] = test_ratio\n",
    "\n",
    "        if train_profit is not None and train_profit != -1:\n",
    "            if train_baseline_profit != 0:\n",
    "                train_ratio = (train_profit - train_baseline_profit) / abs(\n",
    "                    train_baseline_profit\n",
    "                )  # Relative deviation\n",
    "            else:\n",
    "                train_ratio = train_profit  # Use profit directly if baseline is zero\n",
    "            train_ratios[f\"S{idx}\"] = train_ratio\n",
    "\n",
    "    # Define the fixed range of the y-axis\n",
    "    max_value = max(\n",
    "        max(test_ratios.values(), default=0), max(train_ratios.values(), default=0)\n",
    "    )\n",
    "    y_max = min(max_value + 0.1, 1.0)  # Limit max y to 1.0\n",
    "    y_min = -y_max  # Keep symmetric scaling\n",
    "\n",
    "    # Ensure y-axis tick marks are at intervals of 0.05\n",
    "    y_ticks = np.arange(y_min, y_max + 0.05, 0.05)  # Generate ticks\n",
    "\n",
    "    # Create bar plot for relative profit deviation comparison\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    bar_width = 0.35\n",
    "    indices = np.arange(len(train_ratios))\n",
    "\n",
    "    # Plot bars for train and test ratios, with train on the left for each pair\n",
    "    train_bars = plt.bar(\n",
    "        indices - bar_width / 2,\n",
    "        train_ratios.values(),\n",
    "        bar_width,\n",
    "        label=\"Train Data\",\n",
    "        color=\"salmon\",\n",
    "    )\n",
    "    test_bars = plt.bar(\n",
    "        indices + bar_width / 2,\n",
    "        test_ratios.values(),\n",
    "        bar_width,\n",
    "        label=\"Test Data\",\n",
    "        color=\"skyblue\",\n",
    "    )\n",
    "\n",
    "    # Add baseline line\n",
    "    plt.axhline(y=0, color=\"gray\", linestyle=\"--\", label=\"Baseline (No Opt)\")\n",
    "\n",
    "    # Add labels for each bar\n",
    "    for bar in train_bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            yval,\n",
    "            f\"{yval:.2f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "        )\n",
    "    for bar in test_bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            yval,\n",
    "            f\"{yval:.2f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "        )\n",
    "\n",
    "    # Set plot labels and title\n",
    "    plt.xlabel(\"Strategies\")\n",
    "    plt.ylabel(\"Deviation from Baseline\")\n",
    "    plt.title(\"Relative Profit Deviation Comparison between Train and Test Data\")\n",
    "    plt.xticks(indices, train_ratios.keys())\n",
    "\n",
    "    # Set fixed y-axis range and ticks\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.yticks(y_ticks)  # Apply fixed 0.05 intervals\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    name = \"plot_relative_profit_comparison\"\n",
    "\n",
    "    os.makedirs(\"plots\", exist_ok=True)\n",
    "    save_path = f\"plots/{name}_{save_type}.png\"\n",
    "\n",
    "    plt.savefig(save_path, format=\"png\", bbox_inches=\"tight\")\n",
    "    print(f\"Plot saved as {save_path}\")\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_Q0_Q1_distribution(save_type, stimulation_results_dfs):\n",
    "\n",
    "    for idx, df in enumerate(stimulation_results_dfs, start=1):\n",
    "        if df is None or len(df) == 0:\n",
    "            continue\n",
    "\n",
    "        df[\"Q0\"] = pd.to_numeric(df[\"Q0\"], errors=\"coerce\")\n",
    "        df[\"Q1\"] = pd.to_numeric(df[\"Q1\"], errors=\"coerce\")\n",
    "        df.dropna(subset=[\"Q0\", \"Q1\"], inplace=True)\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(df[\"Q0\"], bins=20, alpha=0.6, label=\"Q0\", edgecolor=\"black\")\n",
    "        plt.hist(df[\"Q1\"], bins=20, alpha=0.6, label=\"Q1\", edgecolor=\"black\")\n",
    "        plt.title(f\"Histogram of Q0 and Q1 for stimulation_results_df_{idx}\")\n",
    "        plt.xlabel(\"Value\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        name = \"plot_Q0_Q1_distribution\"\n",
    "\n",
    "        os.makedirs(\"plots\", exist_ok=True)\n",
    "        save_path = (\n",
    "            f\"plots/{name}_{save_type}_{data_size}_S{idx}_{CURRENT_TIMESTAMP}.png\"\n",
    "        )\n",
    "\n",
    "        plt.savefig(save_path, format=\"png\", bbox_inches=\"tight\")\n",
    "        print(f\"Plot saved as {save_path}\")\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_profits_deviation_box_plot(\n",
    "    save_type, stimulation_results_dfs, baseline_avg_profits\n",
    "):\n",
    "\n",
    "    for idx, df in enumerate(stimulation_results_dfs, start=1):\n",
    "        if df is not None and \"profits\" in df.columns:\n",
    "            df[\"profits\"] = pd.to_numeric(df[\"profits\"], errors=\"coerce\")\n",
    "            df.dropna(subset=[\"profits\"], inplace=True)\n",
    "\n",
    "            # Calculate deviation\n",
    "            df[\"Deviation\"] = df[\"profits\"] - baseline_avg_profits\n",
    "\n",
    "            # Plot deviation as a boxplot\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.boxplot(y=df[\"Deviation\"])\n",
    "            plt.axhline(0, color=\"red\", linestyle=\"--\", label=\"Baseline\")\n",
    "            plt.title(\n",
    "                f\"Boxplot of Deviation of Profits from Baseline for stimulation_results_df_{idx}\"\n",
    "            )\n",
    "            plt.ylabel(\"Deviation\")\n",
    "            plt.legend()\n",
    "            plt.grid(True, axis=\"y\")\n",
    "\n",
    "            name = \"plot_profits_deviation_box_plot\"\n",
    "\n",
    "            os.makedirs(\"plots\", exist_ok=True)\n",
    "            save_path = (\n",
    "                f\"plots/{name}_{save_type}_{data_size}_S{idx}_{CURRENT_TIMESTAMP}.png\"\n",
    "            )\n",
    "\n",
    "            plt.savefig(save_path, format=\"png\", bbox_inches=\"tight\")\n",
    "            print(f\"Plot saved as {save_path}\")\n",
    "\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"Skipping stimulation_results_df_{idx}: Missing 'profits' column.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 線性模型預測公式\n",
    "def compute_f_F_Q(X_data, alphas, Q_star):\n",
    "    f = sum(X_data[j] * alphas[j] for j in range(len(alphas)))\n",
    "    big_f = 1 / (1 + np.exp(-f))\n",
    "    q0 = big_f * Q_star\n",
    "    print(f\"f_vars[i]: {f:.4f}, F_vars[i]: {big_f:.4f}, Q0_vars[i]: {q0:.4f}\")\n",
    "    return f, big_f, q0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def truncate_to_2(x):\n",
    "    return math.floor(x * 100) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "96OwNkWqLEx1"
   },
   "outputs": [],
   "source": [
    "# Function to replace negative values with 0\n",
    "def replace_negative_with_zero(df):\n",
    "    return df.applymap(lambda x: max(x, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ruyH6M8Jc5yW"
   },
   "outputs": [],
   "source": [
    "def check_values(\n",
    "    Q1_vars,\n",
    "    Q_hat_adjusteds,\n",
    "    Q0_vars,\n",
    "    Sold_0s,\n",
    "    total_demand_up_to_k_minus_1_vars,\n",
    "    Sold_1s,\n",
    "    total_demand_from_k_to_T_vars,\n",
    "    Q1_plus_lefts,\n",
    "    Left_0s,\n",
    "    Lost_0s,\n",
    "    Left_1s,\n",
    "    Lost_1s,\n",
    "):\n",
    "\n",
    "    # 用於存儲每個條件的統計結果\n",
    "    results = {\n",
    "        \"Condition\": [],\n",
    "        \"Average_Error_Percentage\": [],\n",
    "        \"Max_Error_Percentage\": [],\n",
    "        \"Min_Error_Percentage\": [],\n",
    "        \"Max_Error\": [],\n",
    "        \"Min_Error\": [],\n",
    "    }\n",
    "\n",
    "    # 定義存儲每個條件下的誤差和誤差百分比\n",
    "    conditions_errors = {\n",
    "        \"Q1_vars\": [],\n",
    "        \"Sold_0s\": [],\n",
    "        \"Sold_1s\": [],\n",
    "        \"Left_0s\": [],\n",
    "        \"Left_1s\": [],\n",
    "        \"Lost_0s\": [],\n",
    "        \"Lost_1s\": [],\n",
    "    }\n",
    "\n",
    "    # 存儲每個條件下的誤差百分比\n",
    "    conditions_error_percentage = {\n",
    "        \"Q1_vars\": [],\n",
    "        \"Sold_0s\": [],\n",
    "        \"Sold_1s\": [],\n",
    "        \"Left_0s\": [],\n",
    "        \"Left_1s\": [],\n",
    "        \"Lost_0s\": [],\n",
    "        \"Lost_1s\": [],\n",
    "    }\n",
    "\n",
    "    # 遍歷每一個變量集合\n",
    "    for i in range(len(Q1_vars)):\n",
    "        # 提取變量的值\n",
    "        Q1 = Q1_vars[i].X\n",
    "        Q_hat_adjusted = Q_hat_adjusteds[i].X\n",
    "        Q0 = Q0_vars[i].X\n",
    "        Sold_0 = Sold_0s[i].X\n",
    "        total_demand_up_to_k_minus_1 = total_demand_up_to_k_minus_1_vars[i].X\n",
    "        Sold_1 = Sold_1s[i].X\n",
    "        total_demand_from_k_to_T = total_demand_from_k_to_T_vars[i].X\n",
    "        Q1_plus_left = Q1_plus_lefts[i].X\n",
    "        Left_0 = Left_0s[i].X\n",
    "        Lost_0 = Lost_0s[i].X\n",
    "        Left_1 = Left_1s[i].X\n",
    "        Lost_1 = Lost_1s[i].X\n",
    "\n",
    "        # 計算理論值\n",
    "        theoretical_sold_0 = min(total_demand_up_to_k_minus_1, Q0)\n",
    "        theoretical_left_0 = max(Q0 - theoretical_sold_0, 0)\n",
    "        theoretical_Q1_plus_left = Q1 + theoretical_left_0  # Q1_plus_left 的理論值\n",
    "        theoretical_sold_1 = min(total_demand_from_k_to_T, theoretical_Q1_plus_left)\n",
    "        theoretical_left_1 = max(theoretical_Q1_plus_left - theoretical_sold_1, 0)\n",
    "        theoretical_lost_0 = max(total_demand_up_to_k_minus_1 - Q0, 0)\n",
    "        theoretical_lost_1 = max(total_demand_from_k_to_T - theoretical_Q1_plus_left, 0)\n",
    "\n",
    "        # 檢查條件 2：Sold_0 一定等於理論值\n",
    "        if not (Sold_0 == theoretical_sold_0):\n",
    "            error = abs(Sold_0 - theoretical_sold_0)\n",
    "            conditions_errors[\"Sold_0s\"].append(error)\n",
    "            # 計算誤差百分比\n",
    "            conditions_error_percentage[\"Sold_0s\"].append(\n",
    "                (error / theoretical_sold_0) * 100 if theoretical_sold_0 != 0 else 0\n",
    "            )\n",
    "\n",
    "        # 檢查條件 3：Sold_1 一定等於理論值\n",
    "        if not (Sold_1 == theoretical_sold_1):\n",
    "            error = abs(Sold_1 - theoretical_sold_1)\n",
    "            conditions_errors[\"Sold_1s\"].append(error)\n",
    "            # 計算誤差百分比\n",
    "            conditions_error_percentage[\"Sold_1s\"].append(\n",
    "                (error / theoretical_sold_1) * 100 if theoretical_sold_1 != 0 else 0\n",
    "            )\n",
    "\n",
    "        # 檢查條件 4：Left_0 一定等於理論值\n",
    "        if not (Left_0 == theoretical_left_0):\n",
    "            error = abs(Left_0 - theoretical_left_0)\n",
    "            conditions_errors[\"Left_0s\"].append(error)\n",
    "            # 計算誤差百分比\n",
    "            conditions_error_percentage[\"Left_0s\"].append(\n",
    "                (error / theoretical_left_0) * 100 if theoretical_left_0 != 0 else 0\n",
    "            )\n",
    "\n",
    "        # 檢查條件 5：Left_1 一定等於理論值\n",
    "        if not (Left_1 == theoretical_left_1):\n",
    "            error = abs(Left_1 - theoretical_left_1)\n",
    "            conditions_errors[\"Left_1s\"].append(error)\n",
    "            # 計算誤差百分比\n",
    "            conditions_error_percentage[\"Left_1s\"].append(\n",
    "                (error / theoretical_left_1) * 100 if theoretical_left_1 != 0 else 0\n",
    "            )\n",
    "\n",
    "        # 檢查條件 6：Lost_0 一定等於理論值\n",
    "        if not (Lost_0 == theoretical_lost_0):\n",
    "            error = abs(Lost_0 - theoretical_lost_0)\n",
    "            conditions_errors[\"Lost_0s\"].append(error)\n",
    "            # 計算誤差百分比\n",
    "            conditions_error_percentage[\"Lost_0s\"].append(\n",
    "                (error / theoretical_lost_0) * 100 if theoretical_lost_0 != 0 else 0\n",
    "            )\n",
    "\n",
    "        # 檢查條件 7：Lost_1 一定等於理論值\n",
    "        if not (Lost_1 == theoretical_lost_1):\n",
    "            error = abs(Lost_1 - theoretical_lost_1)\n",
    "            conditions_errors[\"Lost_1s\"].append(error)\n",
    "            # 計算誤差百分比\n",
    "            conditions_error_percentage[\"Lost_1s\"].append(\n",
    "                (error / theoretical_lost_1) * 100 if theoretical_lost_1 != 0 else 0\n",
    "            )\n",
    "\n",
    "    # 計算每個條件的統計結果\n",
    "    for condition, errors in conditions_errors.items():\n",
    "        error_percentages = conditions_error_percentage[condition]\n",
    "        if errors:\n",
    "            # 統計數據，並將所有數值四捨五入至小數點后三位\n",
    "            avg_error_percentage = (\n",
    "                round(sum(error_percentages) / len(error_percentages), 3)\n",
    "                if error_percentages\n",
    "                else 0.0\n",
    "            )\n",
    "            max_error_percentage = (\n",
    "                round(max(error_percentages), 3) if error_percentages else 0.0\n",
    "            )\n",
    "            min_error_percentage = (\n",
    "                round(min(error_percentages), 3) if error_percentages else 0.0\n",
    "            )\n",
    "            max_error = round(max(errors), 3) if errors else 0.0\n",
    "            min_error = round(min(errors), 3) if errors else 0.0\n",
    "\n",
    "            # 存儲結果\n",
    "            results[\"Condition\"].append(condition)\n",
    "            results[\"Average_Error_Percentage\"].append(avg_error_percentage)\n",
    "            results[\"Max_Error_Percentage\"].append(max_error_percentage)\n",
    "            results[\"Min_Error_Percentage\"].append(min_error_percentage)\n",
    "            results[\"Max_Error\"].append(max_error)\n",
    "            results[\"Min_Error\"].append(min_error)\n",
    "\n",
    "    # 轉換為 DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "eNMFp-eLU956"
   },
   "outputs": [],
   "source": [
    "# Calculate service level\n",
    "def calculate_service_level(*, salvage_value, cost, price):\n",
    "\n",
    "    cu = price - cost\n",
    "    co = cost - salvage_value\n",
    "    service_lv = cu / (co + cu)\n",
    "\n",
    "    return service_lv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_service_level(salvage_value=salvage_value, cost=cost, price=price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_s3_related_strtegies_result(\n",
    "    *,\n",
    "    all_Rs,\n",
    "    losses,\n",
    "    lefts,\n",
    "    profits,\n",
    "    operation_profits,\n",
    "    alpha_values,\n",
    "    beta_values,\n",
    "    F_vars,\n",
    "    Q0_vars,\n",
    "    Q1_vars,\n",
    "    f_values,\n",
    "    tau_values,\n",
    "    holding_costs_0s,\n",
    "    holding_costs_1s,\n",
    "    all_left0s,\n",
    "    all_left1s,\n",
    "    all_lost0s,\n",
    "    all_lost1s,\n",
    "    gamma_values=None\n",
    "):\n",
    "\n",
    "    results_dict = {\n",
    "        \"average_profits\": [sum(profits) / len(profits) if profits else 0],\n",
    "        \"average_losses\": [sum(losses) / len(losses) if losses else 0],\n",
    "        \"average_lefts\": [sum(lefts) / len(lefts) if lefts else 0],\n",
    "        \"average_operation_profits\": [\n",
    "            sum(operation_profits) / len(operation_profits) if operation_profits else 0\n",
    "        ],\n",
    "        \"alpha_values\": [alpha_values],\n",
    "        \"beta_values\": [beta_values],\n",
    "        \"tau_values\": [tau_values],\n",
    "        \"gamma_values\": [gamma_values],\n",
    "    }\n",
    "    stimulations_result = {\n",
    "        \"R(T)\": all_Rs,\n",
    "        # \"R\": [x - 2 for x in all_Rs],\n",
    "        \"F\": F_vars,\n",
    "        \"f_values\": f_values,\n",
    "        \"profits\": profits,\n",
    "        \"losses\": losses,\n",
    "        \"lefts\": lefts,\n",
    "        \"operation_profits\": operation_profits,\n",
    "        \"Q0\": Q0_vars,\n",
    "        \"Q1\": Q1_vars,\n",
    "        \"hc0\": holding_costs_0s,\n",
    "        \"hc1\": holding_costs_1s,\n",
    "        \"Left0s\": all_left0s,\n",
    "        \"Left1s\": all_left1s,\n",
    "        \"lost0s\": all_lost0s,\n",
    "        \"lost1s\": all_lost1s,\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(results_dict).sort_values(\n",
    "        by=\"average_profits\", ascending=False\n",
    "    ), pd.DataFrame(stimulations_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zg9HWiZOypqj"
   },
   "source": [
    "# Generate Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LS641siV6sA_"
   },
   "source": [
    "## Data1: Training data for LR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qIeKRFI5LRNJ"
   },
   "source": [
    "### Making full data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lf_ktM4A9qZV",
    "outputId": "2c0e47cb-7ee1-4e26-add4-5c6afe560c3e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.744068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>254.356465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.575947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>251.010920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.013817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>291.630992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.724416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>288.907838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.118274</td>\n",
       "      <td>0.0</td>\n",
       "      <td>293.500607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>18.487144</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.239247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>17.267713</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.453517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>18.610278</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69.280813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>19.331912</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.044144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>19.877608</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.318389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X1   X2          X3\n",
       "0   17.744068  0.0  254.356465\n",
       "1   18.575947  0.0  251.010920\n",
       "2   18.013817  0.0  291.630992\n",
       "3   17.724416  0.0  288.907838\n",
       "4   17.118274  0.0  293.500607\n",
       "..        ...  ...         ...\n",
       "85  18.487144  1.0   62.239247\n",
       "86  17.267713  1.0   63.453517\n",
       "87  18.610278  1.0   69.280813\n",
       "88  19.331912  1.0   67.044144\n",
       "89  19.877608  1.0   60.318389\n",
       "\n",
       "[90 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# full_df = pd.DataFrame(\n",
    "#     {\n",
    "#         \"X1\": np.zeros(data_size),\n",
    "#         \"X2\": np.zeros(data_size),\n",
    "#         \"X3\": np.zeros(data_size),\n",
    "#         \"X4\": np.random.uniform(5, 15, data_size),\n",
    "#     }\n",
    "# )\n",
    "\n",
    "full_df = pd.DataFrame(\n",
    "    {\n",
    "        \"X1\": np.zeros(data_size),\n",
    "        \"X2\": np.zeros(data_size),\n",
    "        \"X3\": np.zeros(data_size),  # 將作為轉折時間\n",
    "        # \"X4\": np.random.uniform(5, 15, data_size),\n",
    "    }\n",
    ")\n",
    "\n",
    "for i in range(0, data_size, CHUNK_SIZE):\n",
    "    half_chunk = CHUNK_SIZE // 2\n",
    "    # 訓練 (前 half_chunk)\n",
    "    full_df.loc[i : i + half_chunk - 1, \"X1\"] = np.random.uniform(\n",
    "        15, 20, size=half_chunk\n",
    "    )\n",
    "    full_df.loc[i : i + half_chunk - 1, \"X2\"] = 0\n",
    "    full_df.loc[i : i + half_chunk - 1, \"X3\"] = np.random.uniform(\n",
    "        250, 300, size=half_chunk\n",
    "    )\n",
    "\n",
    "    # 測試 (後 half_chunk)\n",
    "    full_df.loc[i + half_chunk : i + CHUNK_SIZE - 1, \"X1\"] = np.random.uniform(\n",
    "        15, 20, size=half_chunk\n",
    "    )\n",
    "    full_df.loc[i + half_chunk : i + CHUNK_SIZE - 1, \"X2\"] = 1\n",
    "    full_df.loc[i + half_chunk : i + CHUNK_SIZE - 1, \"X3\"] = np.random.uniform(\n",
    "        60, 70, size=half_chunk\n",
    "    )\n",
    "\n",
    "\n",
    "# # 初始化 X3\n",
    "# X3_values = np.zeros(data_size)\n",
    "\n",
    "# # 對每個 chunk 設定對應的 X3 範圍\n",
    "# for i in range(0, data_size, CHUNK_SIZE):\n",
    "#     half_chunk = CHUNK_SIZE // 2\n",
    "#     # 訓練資料 X3：200~250\n",
    "#     X3_values[i : i + half_chunk] = np.random.uniform(\n",
    "#         250, 300, size=min(half_chunk, data_size - i)\n",
    "#     )\n",
    "#     # 測試資料 X3：40~90\n",
    "#     X3_values[i + half_chunk : i + CHUNK_SIZE] = np.random.uniform(\n",
    "#         50, 100, size=min(half_chunk, data_size - i - half_chunk)\n",
    "#     )\n",
    "\n",
    "# # 填入 full_df\n",
    "# full_df[\"X3\"] = X3_values\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(0)\n",
    "\n",
    "# # 初始化 full_df，包含 X1, X2, X3, X4\n",
    "# # 其他變數 (例如 X4) 用 uniform 隨機數\n",
    "# full_df = pd.DataFrame(\n",
    "#     {\n",
    "#         \"X1\": np.zeros(data_size),\n",
    "#         \"X2\": np.zeros(data_size),\n",
    "#         \"X3\": np.zeros(data_size),  # 將作為轉折時間\n",
    "#         # \"X4\": np.random.uniform(5, 15, data_size),\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# # # 根據 chunk，對第一半 (訓練) 設定 X1=1，對第二半 (測試) 設定 X2=1，\n",
    "# # # 並設定 X3 為轉折時間:\n",
    "# # #  訓練：X3 ~ Uniform(7, 9)\n",
    "# # #  測試：X3 ~ Uniform(2, 4)\n",
    "# # for i in range(0, data_size, CHUNK_SIZE):\n",
    "# #     half_chunk = CHUNK_SIZE // 2\n",
    "# #     # 訓練 (前 half_chunk)\n",
    "# #     full_df.loc[i : i + half_chunk - 1, \"X1\"] = 1\n",
    "# #     full_df.loc[i : i + half_chunk - 1, \"X2\"] = 0\n",
    "# #     full_df.loc[i : i + half_chunk - 1, \"X3\"] = np.random.uniform(7, 9, size=half_chunk)\n",
    "\n",
    "# #     # 測試 (後 half_chunk)\n",
    "# #     full_df.loc[i + half_chunk : i + CHUNK_SIZE - 1, \"X1\"] = 0\n",
    "# #     full_df.loc[i + half_chunk : i + CHUNK_SIZE - 1, \"X2\"] = 1\n",
    "# #     full_df.loc[i + half_chunk : i + CHUNK_SIZE - 1, \"X3\"] = np.random.uniform(\n",
    "# #         2, 4, size=half_chunk\n",
    "# #     )\n",
    "\n",
    "# for i in range(0, data_size, CHUNK_SIZE):\n",
    "#     half_chunk = CHUNK_SIZE // 2\n",
    "#     # 訓練部分（前 half_chunk）\n",
    "#     full_df.loc[i : i + half_chunk - 1, \"X1\"] = 250\n",
    "#     full_df.loc[i : i + half_chunk - 1, \"X2\"] = 0\n",
    "#     full_df.loc[i : i + half_chunk - 1, \"X3\"] = np.random.uniform(6, 8, size=half_chunk)\n",
    "\n",
    "#     # 測試部分（後 half_chunk）\n",
    "#     full_df.loc[i + half_chunk : i + CHUNK_SIZE - 1, \"X1\"] = 100\n",
    "#     full_df.loc[i + half_chunk : i + CHUNK_SIZE - 1, \"X2\"] = 1\n",
    "#     full_df.loc[i + half_chunk : i + CHUNK_SIZE - 1, \"X3\"] = np.random.uniform(\n",
    "#         2, 4, size=half_chunk\n",
    "#     )\n",
    "\n",
    "# # 顯示 full_df（部分）\n",
    "# full_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QK33A94iyiRx",
    "outputId": "2ba8de7b-27cf-4945-f51d-2a536cafd7d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_num = full_df.shape[1]\n",
    "features_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBjAqX8vLWW1"
   },
   "source": [
    "### Split training and testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# def train_data_split_and_normalized(data, train_size=0.5):\n",
    "#     folds = []\n",
    "#     scalers = []\n",
    "\n",
    "#     # 計算訓練集的大小\n",
    "#     train_len = int(len(data) * train_size)\n",
    "\n",
    "#     # 將資料切分為前半部分為訓練集，後半部分為測試集\n",
    "#     train_data = data.iloc[:train_len].reset_index(drop=True)\n",
    "#     test_data = data.iloc[train_len:].reset_index(drop=True)\n",
    "\n",
    "#     # # 標準化處理\n",
    "#     # scaler = StandardScaler()\n",
    "#     # train_data_normalized = scaler.fit_transform(train_data)\n",
    "#     # test_data_normalized = scaler.transform(test_data)\n",
    "\n",
    "#     # # 將標準化資料轉回 DataFrame\n",
    "#     # train_data_normalized = pd.DataFrame(train_data_normalized, columns=data.columns)\n",
    "#     # test_data_normalized = pd.DataFrame(test_data_normalized, columns=data.columns)\n",
    "\n",
    "#     # # 將資料加入 folds 與 scaler\n",
    "#     # folds.append((train_data_normalized, test_data_normalized))\n",
    "#     # scalers.append(scaler)\n",
    "\n",
    "#     # 將資料加入 folds 與 scaler\n",
    "#     folds.append((train_data, test_data))\n",
    "#     scalers.append(None)\n",
    "\n",
    "#     return folds, scalers\n",
    "\n",
    "\n",
    "# training_data_folds, scalers = train_data_split_and_normalized(full_df, train_size)\n",
    "\n",
    "# for i, (train, test) in enumerate(training_data_folds):\n",
    "#     print(f\"Fold {i + 1}:\")\n",
    "#     print(f\"Train size: {train.shape}, Test size: {test.shape}\")\n",
    "#     print(\"Train (normalized):\")\n",
    "#     print(train.head())\n",
    "#     print(\"Test (normalized):\")\n",
    "#     print(test.head())\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Train size: (15, 3), Test size: (15, 3)\n",
      "Train (normalized):\n",
      "(15, 3)\n",
      "          X1   X2          X3\n",
      "0  17.744068  0.0  254.356465\n",
      "1  18.575947  0.0  251.010920\n",
      "2  18.013817  0.0  291.630992\n",
      "3  17.724416  0.0  288.907838\n",
      "4  17.118274  0.0  293.500607\n",
      "Test (normalized):\n",
      "(15, 3)\n",
      "          X1   X2         X3\n",
      "0  16.322778  1.0  66.706379\n",
      "1  18.871168  1.0  62.103826\n",
      "2  17.280752  1.0  61.289263\n",
      "3  17.842170  1.0  63.154284\n",
      "4  15.093949  1.0  63.637108\n",
      "\n",
      "Fold 2:\n",
      "Train size: (15, 3), Test size: (15, 3)\n",
      "Train (normalized):\n",
      "(15, 3)\n",
      "          X1   X2          X3\n",
      "0  15.794848  0.0  251.959390\n",
      "1  15.551876  0.0  264.140348\n",
      "2  18.281648  0.0  256.009828\n",
      "3  15.690915  0.0  264.807010\n",
      "4  15.982912  0.0  255.936386\n",
      "Test (normalized):\n",
      "(15, 3)\n",
      "          X1   X2         X3\n",
      "0  16.592845  1.0  65.761573\n",
      "1  18.337052  1.0  65.920419\n",
      "2  15.658989  1.0  65.722519\n",
      "3  18.581636  1.0  62.230816\n",
      "4  16.447030  1.0  69.527490\n",
      "\n",
      "Fold 3:\n",
      "Train size: (15, 3), Test size: (15, 3)\n",
      "Train (normalized):\n",
      "(15, 3)\n",
      "          X1   X2          X3\n",
      "0  18.626271  0.0  279.543638\n",
      "1  17.506622  0.0  278.716262\n",
      "2  19.780418  0.0  282.660041\n",
      "3  18.219951  0.0  282.605164\n",
      "4  17.119275  0.0  271.570922\n",
      "Test (normalized):\n",
      "(15, 3)\n",
      "          X1   X2         X3\n",
      "0  15.747242  1.0  68.558033\n",
      "1  19.340630  1.0  60.117141\n",
      "2  15.812465  1.0  63.599781\n",
      "3  18.077798  1.0  67.299906\n",
      "4  15.619100  1.0  61.716297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def train_data_split_and_normalized_k_fold(data, train_size=0.5, chunk_size=CHUNK_SIZE):\n",
    "\n",
    "    folds = []\n",
    "    scalers = []\n",
    "    train_chunk = int(train_size * chunk_size)\n",
    "    n = len(data)\n",
    "\n",
    "    # 依序將資料切分成 chunk_size 大小的子集\n",
    "    for start in range(0, n, chunk_size):\n",
    "        if start + chunk_size > n:\n",
    "            break  # 若剩餘資料不足一個完整的 chunk，則跳過\n",
    "        chunk = data.iloc[start : start + chunk_size].reset_index(drop=True)\n",
    "        train_data = chunk.iloc[:train_chunk].reset_index(drop=True)\n",
    "        test_data = chunk.iloc[train_chunk:].reset_index(drop=True)\n",
    "\n",
    "        # # 建立並使用 StandardScaler 分別標準化當前的訓練與測試資料\n",
    "        # scaler = StandardScaler()\n",
    "        # train_data_normalized = scaler.fit_transform(train_data)\n",
    "        # test_data_normalized = scaler.transform(test_data)\n",
    "\n",
    "        # # 轉回 DataFrame 格式\n",
    "        # train_data_normalized = pd.DataFrame(\n",
    "        #     train_data_normalized, columns=data.columns\n",
    "        # )\n",
    "        # test_data_normalized = pd.DataFrame(test_data_normalized, columns=data.columns)\n",
    "\n",
    "        # folds.append((train_data_normalized, test_data_normalized))\n",
    "        # scalers.append(scaler)\n",
    "\n",
    "        folds.append((train_data, test_data))\n",
    "        scalers.append(None)\n",
    "\n",
    "    return folds, scalers\n",
    "\n",
    "\n",
    "training_data_folds, scalers = train_data_split_and_normalized_k_fold(full_df)\n",
    "\n",
    "for i, (train, test) in enumerate(training_data_folds):\n",
    "    print(f\"Fold {i + 1}:\")\n",
    "    print(f\"Train size: {train.shape}, Test size: {test.shape}\")\n",
    "    print(\"Train (normalized):\")\n",
    "    print(train.shape)\n",
    "    print(train.head())\n",
    "    print(\"Test (normalized):\")\n",
    "    print(test.shape)\n",
    "    print(test.head())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8_ZeISZmXmZ"
   },
   "source": [
    "## Data2: demand_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8sxaCcInWRTC"
   },
   "source": [
    "### mu of each time(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "54SdjO8-NCOc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu_matrix shape: (90, 10)\n",
      "mu_matrix[:3]: \n",
      "[[254.35646499 254.35646499 254.35646499 254.35646499 254.35646499\n",
      "  254.35646499 254.35646499 254.35646499 254.35646499 254.35646499]\n",
      " [251.01091987 251.01091987 251.01091987 251.01091987 251.01091987\n",
      "  251.01091987 251.01091987 251.01091987 251.01091987 251.01091987]\n",
      " [291.63099228 291.63099228 291.63099228 291.63099228 291.63099228\n",
      "  291.63099228 291.63099228 291.63099228 291.63099228 291.63099228]]\n",
      "mu_matrix[CHUNK_SIZE : CHUNK_SIZE + 3]: \n",
      "[[251.95938961 251.95938961 251.95938961 251.95938961 251.95938961\n",
      "  251.95938961 251.95938961 251.95938961 251.95938961 251.95938961]\n",
      " [264.14034813 264.14034813 264.14034813 264.14034813 264.14034813\n",
      "  264.14034813 264.14034813 264.14034813 264.14034813 264.14034813]\n",
      " [256.00982806 256.00982806 256.00982806 256.00982806 256.00982806\n",
      "  256.00982806 256.00982806 256.00982806 256.00982806 256.00982806]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>t4</th>\n",
       "      <th>t5</th>\n",
       "      <th>t6</th>\n",
       "      <th>t7</th>\n",
       "      <th>t8</th>\n",
       "      <th>t9</th>\n",
       "      <th>t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.356465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251.010920</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>251.010920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>291.630992</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>291.630992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.907838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>293.500607</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>293.500607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>298.930917</td>\n",
       "      <td>298.930917</td>\n",
       "      <td>298.930917</td>\n",
       "      <td>298.930917</td>\n",
       "      <td>298.930917</td>\n",
       "      <td>298.930917</td>\n",
       "      <td>298.930917</td>\n",
       "      <td>298.930917</td>\n",
       "      <td>298.930917</td>\n",
       "      <td>298.930917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>289.957928</td>\n",
       "      <td>289.957928</td>\n",
       "      <td>289.957928</td>\n",
       "      <td>289.957928</td>\n",
       "      <td>289.957928</td>\n",
       "      <td>289.957928</td>\n",
       "      <td>289.957928</td>\n",
       "      <td>289.957928</td>\n",
       "      <td>289.957928</td>\n",
       "      <td>289.957928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>273.073968</td>\n",
       "      <td>273.073968</td>\n",
       "      <td>273.073968</td>\n",
       "      <td>273.073968</td>\n",
       "      <td>273.073968</td>\n",
       "      <td>273.073968</td>\n",
       "      <td>273.073968</td>\n",
       "      <td>273.073968</td>\n",
       "      <td>273.073968</td>\n",
       "      <td>273.073968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>289.026459</td>\n",
       "      <td>289.026459</td>\n",
       "      <td>289.026459</td>\n",
       "      <td>289.026459</td>\n",
       "      <td>289.026459</td>\n",
       "      <td>289.026459</td>\n",
       "      <td>289.026459</td>\n",
       "      <td>289.026459</td>\n",
       "      <td>289.026459</td>\n",
       "      <td>289.026459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>255.913721</td>\n",
       "      <td>255.913721</td>\n",
       "      <td>255.913721</td>\n",
       "      <td>255.913721</td>\n",
       "      <td>255.913721</td>\n",
       "      <td>255.913721</td>\n",
       "      <td>255.913721</td>\n",
       "      <td>255.913721</td>\n",
       "      <td>255.913721</td>\n",
       "      <td>255.913721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>281.996051</td>\n",
       "      <td>281.996051</td>\n",
       "      <td>281.996051</td>\n",
       "      <td>281.996051</td>\n",
       "      <td>281.996051</td>\n",
       "      <td>281.996051</td>\n",
       "      <td>281.996051</td>\n",
       "      <td>281.996051</td>\n",
       "      <td>281.996051</td>\n",
       "      <td>281.996051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>257.167664</td>\n",
       "      <td>257.167664</td>\n",
       "      <td>257.167664</td>\n",
       "      <td>257.167664</td>\n",
       "      <td>257.167664</td>\n",
       "      <td>257.167664</td>\n",
       "      <td>257.167664</td>\n",
       "      <td>257.167664</td>\n",
       "      <td>257.167664</td>\n",
       "      <td>257.167664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>297.233446</td>\n",
       "      <td>297.233446</td>\n",
       "      <td>297.233446</td>\n",
       "      <td>297.233446</td>\n",
       "      <td>297.233446</td>\n",
       "      <td>297.233446</td>\n",
       "      <td>297.233446</td>\n",
       "      <td>297.233446</td>\n",
       "      <td>297.233446</td>\n",
       "      <td>297.233446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>276.092416</td>\n",
       "      <td>276.092416</td>\n",
       "      <td>276.092416</td>\n",
       "      <td>276.092416</td>\n",
       "      <td>276.092416</td>\n",
       "      <td>276.092416</td>\n",
       "      <td>276.092416</td>\n",
       "      <td>276.092416</td>\n",
       "      <td>276.092416</td>\n",
       "      <td>276.092416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>270.733097</td>\n",
       "      <td>270.733097</td>\n",
       "      <td>270.733097</td>\n",
       "      <td>270.733097</td>\n",
       "      <td>270.733097</td>\n",
       "      <td>270.733097</td>\n",
       "      <td>270.733097</td>\n",
       "      <td>270.733097</td>\n",
       "      <td>270.733097</td>\n",
       "      <td>270.733097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>66.706379</td>\n",
       "      <td>66.706379</td>\n",
       "      <td>66.706379</td>\n",
       "      <td>66.706379</td>\n",
       "      <td>66.706379</td>\n",
       "      <td>66.706379</td>\n",
       "      <td>66.706379</td>\n",
       "      <td>66.706379</td>\n",
       "      <td>66.706379</td>\n",
       "      <td>66.706379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>62.103826</td>\n",
       "      <td>62.103826</td>\n",
       "      <td>62.103826</td>\n",
       "      <td>62.103826</td>\n",
       "      <td>62.103826</td>\n",
       "      <td>62.103826</td>\n",
       "      <td>62.103826</td>\n",
       "      <td>62.103826</td>\n",
       "      <td>62.103826</td>\n",
       "      <td>62.103826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>61.289263</td>\n",
       "      <td>61.289263</td>\n",
       "      <td>61.289263</td>\n",
       "      <td>61.289263</td>\n",
       "      <td>61.289263</td>\n",
       "      <td>61.289263</td>\n",
       "      <td>61.289263</td>\n",
       "      <td>61.289263</td>\n",
       "      <td>61.289263</td>\n",
       "      <td>61.289263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>63.154284</td>\n",
       "      <td>63.154284</td>\n",
       "      <td>63.154284</td>\n",
       "      <td>63.154284</td>\n",
       "      <td>63.154284</td>\n",
       "      <td>63.154284</td>\n",
       "      <td>63.154284</td>\n",
       "      <td>63.154284</td>\n",
       "      <td>63.154284</td>\n",
       "      <td>63.154284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>63.637108</td>\n",
       "      <td>63.637108</td>\n",
       "      <td>63.637108</td>\n",
       "      <td>63.637108</td>\n",
       "      <td>63.637108</td>\n",
       "      <td>63.637108</td>\n",
       "      <td>63.637108</td>\n",
       "      <td>63.637108</td>\n",
       "      <td>63.637108</td>\n",
       "      <td>63.637108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>65.701968</td>\n",
       "      <td>65.701968</td>\n",
       "      <td>65.701968</td>\n",
       "      <td>65.701968</td>\n",
       "      <td>65.701968</td>\n",
       "      <td>65.701968</td>\n",
       "      <td>65.701968</td>\n",
       "      <td>65.701968</td>\n",
       "      <td>65.701968</td>\n",
       "      <td>65.701968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>64.386015</td>\n",
       "      <td>64.386015</td>\n",
       "      <td>64.386015</td>\n",
       "      <td>64.386015</td>\n",
       "      <td>64.386015</td>\n",
       "      <td>64.386015</td>\n",
       "      <td>64.386015</td>\n",
       "      <td>64.386015</td>\n",
       "      <td>64.386015</td>\n",
       "      <td>64.386015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>69.883738</td>\n",
       "      <td>69.883738</td>\n",
       "      <td>69.883738</td>\n",
       "      <td>69.883738</td>\n",
       "      <td>69.883738</td>\n",
       "      <td>69.883738</td>\n",
       "      <td>69.883738</td>\n",
       "      <td>69.883738</td>\n",
       "      <td>69.883738</td>\n",
       "      <td>69.883738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>61.020448</td>\n",
       "      <td>61.020448</td>\n",
       "      <td>61.020448</td>\n",
       "      <td>61.020448</td>\n",
       "      <td>61.020448</td>\n",
       "      <td>61.020448</td>\n",
       "      <td>61.020448</td>\n",
       "      <td>61.020448</td>\n",
       "      <td>61.020448</td>\n",
       "      <td>61.020448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>62.088768</td>\n",
       "      <td>62.088768</td>\n",
       "      <td>62.088768</td>\n",
       "      <td>62.088768</td>\n",
       "      <td>62.088768</td>\n",
       "      <td>62.088768</td>\n",
       "      <td>62.088768</td>\n",
       "      <td>62.088768</td>\n",
       "      <td>62.088768</td>\n",
       "      <td>62.088768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>61.613095</td>\n",
       "      <td>61.613095</td>\n",
       "      <td>61.613095</td>\n",
       "      <td>61.613095</td>\n",
       "      <td>61.613095</td>\n",
       "      <td>61.613095</td>\n",
       "      <td>61.613095</td>\n",
       "      <td>61.613095</td>\n",
       "      <td>61.613095</td>\n",
       "      <td>61.613095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>66.531083</td>\n",
       "      <td>66.531083</td>\n",
       "      <td>66.531083</td>\n",
       "      <td>66.531083</td>\n",
       "      <td>66.531083</td>\n",
       "      <td>66.531083</td>\n",
       "      <td>66.531083</td>\n",
       "      <td>66.531083</td>\n",
       "      <td>66.531083</td>\n",
       "      <td>66.531083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>62.532916</td>\n",
       "      <td>62.532916</td>\n",
       "      <td>62.532916</td>\n",
       "      <td>62.532916</td>\n",
       "      <td>62.532916</td>\n",
       "      <td>62.532916</td>\n",
       "      <td>62.532916</td>\n",
       "      <td>62.532916</td>\n",
       "      <td>62.532916</td>\n",
       "      <td>62.532916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>64.663108</td>\n",
       "      <td>64.663108</td>\n",
       "      <td>64.663108</td>\n",
       "      <td>64.663108</td>\n",
       "      <td>64.663108</td>\n",
       "      <td>64.663108</td>\n",
       "      <td>64.663108</td>\n",
       "      <td>64.663108</td>\n",
       "      <td>64.663108</td>\n",
       "      <td>64.663108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>62.444256</td>\n",
       "      <td>62.444256</td>\n",
       "      <td>62.444256</td>\n",
       "      <td>62.444256</td>\n",
       "      <td>62.444256</td>\n",
       "      <td>62.444256</td>\n",
       "      <td>62.444256</td>\n",
       "      <td>62.444256</td>\n",
       "      <td>62.444256</td>\n",
       "      <td>62.444256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            t1          t2          t3          t4          t5          t6  \\\n",
       "0   254.356465  254.356465  254.356465  254.356465  254.356465  254.356465   \n",
       "1   251.010920  251.010920  251.010920  251.010920  251.010920  251.010920   \n",
       "2   291.630992  291.630992  291.630992  291.630992  291.630992  291.630992   \n",
       "3   288.907838  288.907838  288.907838  288.907838  288.907838  288.907838   \n",
       "4   293.500607  293.500607  293.500607  293.500607  293.500607  293.500607   \n",
       "5   298.930917  298.930917  298.930917  298.930917  298.930917  298.930917   \n",
       "6   289.957928  289.957928  289.957928  289.957928  289.957928  289.957928   \n",
       "7   273.073968  273.073968  273.073968  273.073968  273.073968  273.073968   \n",
       "8   289.026459  289.026459  289.026459  289.026459  289.026459  289.026459   \n",
       "9   255.913721  255.913721  255.913721  255.913721  255.913721  255.913721   \n",
       "10  281.996051  281.996051  281.996051  281.996051  281.996051  281.996051   \n",
       "11  257.167664  257.167664  257.167664  257.167664  257.167664  257.167664   \n",
       "12  297.233446  297.233446  297.233446  297.233446  297.233446  297.233446   \n",
       "13  276.092416  276.092416  276.092416  276.092416  276.092416  276.092416   \n",
       "14  270.733097  270.733097  270.733097  270.733097  270.733097  270.733097   \n",
       "15   66.706379   66.706379   66.706379   66.706379   66.706379   66.706379   \n",
       "16   62.103826   62.103826   62.103826   62.103826   62.103826   62.103826   \n",
       "17   61.289263   61.289263   61.289263   61.289263   61.289263   61.289263   \n",
       "18   63.154284   63.154284   63.154284   63.154284   63.154284   63.154284   \n",
       "19   63.637108   63.637108   63.637108   63.637108   63.637108   63.637108   \n",
       "20   65.701968   65.701968   65.701968   65.701968   65.701968   65.701968   \n",
       "21   64.386015   64.386015   64.386015   64.386015   64.386015   64.386015   \n",
       "22   69.883738   69.883738   69.883738   69.883738   69.883738   69.883738   \n",
       "23   61.020448   61.020448   61.020448   61.020448   61.020448   61.020448   \n",
       "24   62.088768   62.088768   62.088768   62.088768   62.088768   62.088768   \n",
       "25   61.613095   61.613095   61.613095   61.613095   61.613095   61.613095   \n",
       "26   66.531083   66.531083   66.531083   66.531083   66.531083   66.531083   \n",
       "27   62.532916   62.532916   62.532916   62.532916   62.532916   62.532916   \n",
       "28   64.663108   64.663108   64.663108   64.663108   64.663108   64.663108   \n",
       "29   62.444256   62.444256   62.444256   62.444256   62.444256   62.444256   \n",
       "\n",
       "            t7          t8          t9         t10  \n",
       "0   254.356465  254.356465  254.356465  254.356465  \n",
       "1   251.010920  251.010920  251.010920  251.010920  \n",
       "2   291.630992  291.630992  291.630992  291.630992  \n",
       "3   288.907838  288.907838  288.907838  288.907838  \n",
       "4   293.500607  293.500607  293.500607  293.500607  \n",
       "5   298.930917  298.930917  298.930917  298.930917  \n",
       "6   289.957928  289.957928  289.957928  289.957928  \n",
       "7   273.073968  273.073968  273.073968  273.073968  \n",
       "8   289.026459  289.026459  289.026459  289.026459  \n",
       "9   255.913721  255.913721  255.913721  255.913721  \n",
       "10  281.996051  281.996051  281.996051  281.996051  \n",
       "11  257.167664  257.167664  257.167664  257.167664  \n",
       "12  297.233446  297.233446  297.233446  297.233446  \n",
       "13  276.092416  276.092416  276.092416  276.092416  \n",
       "14  270.733097  270.733097  270.733097  270.733097  \n",
       "15   66.706379   66.706379   66.706379   66.706379  \n",
       "16   62.103826   62.103826   62.103826   62.103826  \n",
       "17   61.289263   61.289263   61.289263   61.289263  \n",
       "18   63.154284   63.154284   63.154284   63.154284  \n",
       "19   63.637108   63.637108   63.637108   63.637108  \n",
       "20   65.701968   65.701968   65.701968   65.701968  \n",
       "21   64.386015   64.386015   64.386015   64.386015  \n",
       "22   69.883738   69.883738   69.883738   69.883738  \n",
       "23   61.020448   61.020448   61.020448   61.020448  \n",
       "24   62.088768   62.088768   62.088768   62.088768  \n",
       "25   61.613095   61.613095   61.613095   61.613095  \n",
       "26   66.531083   66.531083   66.531083   66.531083  \n",
       "27   62.532916   62.532916   62.532916   62.532916  \n",
       "28   64.663108   64.663108   64.663108   64.663108  \n",
       "29   62.444256   62.444256   62.444256   62.444256  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 設定 b0, b1, b2\n",
    "b0 = 0\n",
    "b1 = 0\n",
    "b2 = 0\n",
    "b3 = 1\n",
    "# b4 = 0\n",
    "bt = 0\n",
    "\n",
    "\n",
    "def cal_mu_matrix_with_random_noise(data_size, T, training_df, sigma_t):\n",
    "    np.random.seed(0)\n",
    "\n",
    "    # 初始化 mu_matrix\n",
    "    mu_matrix = np.zeros((data_size, T))\n",
    "\n",
    "    # 生成每個 t 的隨機數\n",
    "    random_noises = np.random.normal(0, sigma_t, T)\n",
    "\n",
    "    # 計算 mu_matrix\n",
    "    for t in range(1, T + 1):\n",
    "        mu_matrix[:, t - 1] = (\n",
    "            b0 * random_noises[t - 1]\n",
    "            + b1 * training_df[\"X1\"]\n",
    "            + b2 * training_df[\"X2\"]\n",
    "            + b3 * training_df[\"X3\"]\n",
    "            # + b4 * training_df[\"X4\"]\n",
    "            + bt * t\n",
    "        )\n",
    "\n",
    "    return mu_matrix\n",
    "\n",
    "\n",
    "mu_matrix = cal_mu_matrix_with_random_noise(data_size, T, full_df, sigma_t=1)\n",
    "\n",
    "print(f\"mu_matrix shape: {mu_matrix.shape}\")\n",
    "print(f\"mu_matrix[:3]: \\n{mu_matrix[:3]}\")\n",
    "print(\n",
    "    f\"mu_matrix[CHUNK_SIZE : CHUNK_SIZE + 3]: \\n{mu_matrix[CHUNK_SIZE : CHUNK_SIZE + 3]}\"\n",
    ")\n",
    "\n",
    "\n",
    "mu_df = pd.DataFrame(mu_matrix, columns=[f\"t{t}\" for t in range(1, T + 1)])\n",
    "mu_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cal_mu_matrix_with_turning_point(\n",
    "#     data_size, T, training_df, sigma_t, delta=50, gamma=1.0\n",
    "# ):\n",
    "#     np.random.seed(0)\n",
    "#     mu_matrix = np.zeros((data_size, T))\n",
    "#     random_noises = np.random.normal(0, sigma_t, T)\n",
    "\n",
    "#     # 用 X1, X2 區分高低 baseline，X3 作為轉折點\n",
    "#     for i in range(data_size):\n",
    "#         # 根據 X1 / X2 決定 baseline range\n",
    "#         if training_df.loc[i, \"X2\"] == 1:\n",
    "\n",
    "#             # 低 baseline\n",
    "#             # baseline1 = np.random.uniform(50, 100)\n",
    "#             # baseline2 = np.random.uniform(100, 150)\n",
    "#             baseline1 = np.random.uniform(100, 120)\n",
    "#             baseline2 = np.random.uniform(160, 180)\n",
    "\n",
    "#         else:\n",
    "#             # 高 baseline\n",
    "#             baseline1 = np.random.uniform(120, 140)\n",
    "#             baseline2 = np.random.uniform(160, 180)\n",
    "\n",
    "#         # 將 X3 視為轉折點\n",
    "#         t_switch = training_df.loc[i, \"X3\"]\n",
    "\n",
    "#         # 對於每一個時間點，生成一個平滑轉折項\n",
    "#         for t in range(1, T + 1):\n",
    "#             # 基本線性部分：當 t < t_switch 則為 baseline1，之後用 baseline2\n",
    "#             if t < t_switch:\n",
    "#                 mu_base = baseline1\n",
    "#             else:\n",
    "#                 mu_base = baseline2\n",
    "#             # 加上轉折項（使轉折更平滑或更明顯）\n",
    "#             turning_term = delta / (1 + np.exp(-gamma * (t - t_switch)))\n",
    "#             mu_matrix[i, t - 1] = mu_base + turning_term\n",
    "#     return mu_matrix\n",
    "\n",
    "\n",
    "# mu_matrix = cal_mu_matrix_with_turning_point(\n",
    "#     data_size, T, full_df, 1, delta=50, gamma=1.0\n",
    "# )\n",
    "# mu_df = pd.DataFrame(mu_matrix, columns=[f\"t{t}\" for t in range(1, T + 1)])\n",
    "# mu_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前 25 筆資料的 row 總和平均： 1923.8017141614046\n",
      "後 25 筆資料的 row 總和平均： 1499.1527685666672\n"
     ]
    }
   ],
   "source": [
    "# 每一筆 row 的總和\n",
    "row_sums = mu_df.sum(axis=1)\n",
    "\n",
    "# 前 25 筆 row 的總和平均\n",
    "first_25_avg = row_sums.head(25).mean()\n",
    "\n",
    "# 後 25 筆（第 6 到第 30 筆）的 row 總和平均\n",
    "last_25_avg = row_sums.iloc[5:30].mean()\n",
    "\n",
    "print(\"前 25 筆資料的 row 總和平均：\", first_25_avg)\n",
    "print(\"後 25 筆資料的 row 總和平均：\", last_25_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices: [0, 1, 2]\n",
      "Test indices: [15, 16, 17]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 現在我們從 full_df 中取出第一個 chunk（共 CHUNK_SIZE 筆），並分別選出前 3 筆訓練與後 3 筆測試觀測\n",
    "chunk_indices = range(0, CHUNK_SIZE)\n",
    "train_indices = [i for i in chunk_indices if full_df.loc[i, \"X2\"] == 0][:3]\n",
    "test_indices = [i for i in chunk_indices if full_df.loc[i, \"X2\"] == 1][:3]\n",
    "\n",
    "print(\"Train indices:\", train_indices)\n",
    "print(\"Test indices:\", test_indices)\n",
    "\n",
    "# 繪圖：X軸為 t=1..T, Y軸為 mu\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 畫出訓練資料趨勢\n",
    "plt.subplot(1, 2, 1)\n",
    "for i in train_indices:\n",
    "    plt.plot(range(1, T + 1), mu_matrix[i, :], marker=\"o\", label=f\"Train {i}\")\n",
    "plt.title(\"Train Demand Trend\")\n",
    "plt.xlabel(\"Time Period\")\n",
    "plt.ylabel(\"Demand Mean (mu)\")\n",
    "plt.legend()\n",
    "\n",
    "# 畫出測試資料趨勢\n",
    "plt.subplot(1, 2, 2)\n",
    "for i in test_indices:\n",
    "    plt.plot(range(1, T + 1), mu_matrix[i, :], marker=\"o\", label=f\"Test {i}\")\n",
    "plt.title(\"Test Demand Trend\")\n",
    "plt.xlabel(\"Time Period\")\n",
    "plt.ylabel(\"Demand Mean (mu)\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLArWn7yNAR0"
   },
   "source": [
    "### sigma matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MV_pdKuXNCRO",
    "outputId": "f8f01814-2bfe-4428-d764-0ddcd4d5795d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (90, 3)\n",
      "coefficients.shape: (3, 10)\n",
      "coefficients: [[ 0.43037873  0.20552675  0.08976637 -0.1526904   0.29178823 -0.12482558\n",
      "   0.783546    0.92732552 -0.23311696  0.58345008]\n",
      " [ 0.05778984  0.13608912  0.85119328 -0.85792788 -0.8257414  -0.95956321\n",
      "   0.66523969  0.5563135   0.7400243   0.95723668]\n",
      " [ 0.59831713 -0.07704128  0.56105835 -0.76345115  0.27984204 -0.71329343\n",
      "   0.88933783  0.04369664 -0.17067612 -0.47088878]]\n"
     ]
    }
   ],
   "source": [
    "X = full_df.values\n",
    "feature_num = X.shape[1]\n",
    "print(f\"X.shape: {X.shape}\")\n",
    "\n",
    "# 生成輸入特徵矩陣 X (shape: feature_num * data_size)\n",
    "np.random.seed(0)\n",
    "\n",
    "# 隨機生成常數項 c 和係數向量 coefficients\n",
    "c = np.random.uniform(0, 1)\n",
    "coefficients = np.random.uniform(-1, 1, (feature_num, T))  # shape: (feature_num, T)\n",
    "\n",
    "print(f\"coefficients.shape: {coefficients.shape}\")\n",
    "print(f\"coefficients: {coefficients}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YirRAft9lcD4",
    "outputId": "d4233ae9-50b8-456b-c963-bd23826b8882"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value range: (np.float64(4.0272318378257487e-101), np.float64(1.0))\n",
      "New Value range: (np.float64(1.2081695513477245e-100), np.float64(3.0))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((90, 10),\n",
       " array([[3.00000000e+000, 6.15001987e-007, 3.00000000e+000,\n",
       "         1.59851432e-085, 3.00000000e+000, 9.10228636e-080,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.16196204e-020,\n",
       "         1.56533256e-047],\n",
       "        [3.00000000e+000, 9.44205568e-007, 3.00000000e+000,\n",
       "         1.81054848e-084, 3.00000000e+000, 8.92142828e-079,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.69416411e-020,\n",
       "         1.22906399e-046],\n",
       "        [3.00000000e+000, 3.67960049e-008, 3.00000000e+000,\n",
       "         6.71411518e-098, 3.00000000e+000, 2.49831072e-091,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.88345983e-023,\n",
       "         4.36670099e-055],\n",
       "        [3.00000000e+000, 4.27643558e-008, 3.00000000e+000,\n",
       "         5.61146214e-097, 3.00000000e+000, 1.80680972e-090,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.20705214e-023,\n",
       "         1.32959541e-054],\n",
       "        [3.00000000e+000, 2.65039486e-008, 3.00000000e+000,\n",
       "         1.84705603e-098, 3.00000000e+000, 7.36252067e-092,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.68670682e-023,\n",
       "         1.07371270e-055],\n",
       "        [3.00000000e+000, 2.19181785e-008, 3.00000000e+000,\n",
       "         2.46777762e-100, 3.00000000e+000, 1.33226099e-093,\n",
       "         3.00000000e+000, 3.00000000e+000, 5.15259327e-024,\n",
       "         1.59195590e-056],\n",
       "        [3.00000000e+000, 3.53233304e-008, 3.00000000e+000,\n",
       "         2.73199939e-097, 3.00000000e+000, 9.13480131e-091,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.03796940e-023,\n",
       "         5.92970617e-055],\n",
       "        [3.00000000e+000, 2.06859967e-007, 3.00000000e+000,\n",
       "         7.65560397e-092, 3.00000000e+000, 1.16921033e-085,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.19280864e-022,\n",
       "         6.32857605e-051],\n",
       "        [3.00000000e+000, 6.51647213e-008, 3.00000000e+000,\n",
       "         3.72300696e-097, 3.00000000e+000, 1.27836117e-090,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.92896434e-023,\n",
       "         4.26610891e-054],\n",
       "        [3.00000000e+000, 4.60222792e-007, 3.00000000e+000,\n",
       "         5.52356893e-086, 3.00000000e+000, 3.32329982e-080,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.08012697e-020,\n",
       "         4.64112776e-048],\n",
       "        [3.00000000e+000, 9.38653023e-008, 3.00000000e+000,\n",
       "         9.09750815e-095, 3.00000000e+000, 2.14355033e-088,\n",
       "         3.00000000e+000, 3.00000000e+000, 7.82492350e-023,\n",
       "         7.07856900e-053],\n",
       "        [3.00000000e+000, 4.85208234e-007, 3.00000000e+000,\n",
       "         1.89772011e-086, 3.00000000e+000, 1.24078884e-080,\n",
       "         3.00000000e+000, 3.00000000e+000, 7.36034845e-021,\n",
       "         3.93068479e-048],\n",
       "        [3.00000000e+000, 2.30598010e-008, 3.00000000e+000,\n",
       "         9.57053181e-100, 3.00000000e+000, 4.69388527e-093,\n",
       "         3.00000000e+000, 3.00000000e+000, 7.53800983e-024,\n",
       "         2.82124115e-056],\n",
       "        [3.00000000e+000, 1.69737872e-007, 3.00000000e+000,\n",
       "         7.44663850e-093, 3.00000000e+000, 1.32944866e-086,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.83363379e-022,\n",
       "         1.68605926e-051],\n",
       "        [3.00000000e+000, 1.06587774e-007, 3.00000000e+000,\n",
       "         8.55560683e-091, 3.00000000e+000, 1.03636178e-084,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.23922378e-021,\n",
       "         1.73858234e-051],\n",
       "        [3.00000000e+000, 7.49515217e-001, 3.00000000e+000,\n",
       "         1.39035916e-023, 3.00000000e+000, 5.61820992e-022,\n",
       "         3.00000000e+000, 2.99999999e+000, 2.75290686e-006,\n",
       "         4.22141092e-009],\n",
       "        [3.00000000e+000, 1.33482846e+000, 3.00000000e+000,\n",
       "         3.16352432e-022, 3.00000000e+000, 1.08948974e-020,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.33385762e-006,\n",
       "         1.63092661e-007],\n",
       "        [3.00000000e+000, 1.14304407e+000, 3.00000000e+000,\n",
       "         7.51128723e-022, 3.00000000e+000, 2.37561494e-020,\n",
       "         3.00000000e+000, 2.99999999e+000, 5.55061570e-006,\n",
       "         9.46284474e-008],\n",
       "        [3.00000000e+000, 1.12309159e+000, 3.00000000e+000,\n",
       "         1.66002329e-022, 3.00000000e+000, 5.85593220e-021,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.54209720e-006,\n",
       "         5.45599635e-008],\n",
       "        [3.00000000e+000, 7.40501221e-001, 3.00000000e+000,\n",
       "         1.74690539e-022, 3.00000000e+000, 5.84804907e-021,\n",
       "         3.00000000e+000, 2.99999995e+000, 6.19020627e-006,\n",
       "         8.74510628e-009],\n",
       "        [3.00000000e+000, 1.02272001e+000, 3.00000000e+000,\n",
       "         2.28604050e-023, 3.00000000e+000, 9.22655601e-022,\n",
       "         3.00000000e+000, 3.00000000e+000, 2.16526339e-006,\n",
       "         1.89756713e-008],\n",
       "        [3.00000000e+000, 1.08816786e+000, 3.00000000e+000,\n",
       "         6.26962243e-023, 3.00000000e+000, 2.36698880e-021,\n",
       "         3.00000000e+000, 3.00000000e+000, 2.72808686e-006,\n",
       "         3.46973766e-008],\n",
       "        [3.00000000e+000, 8.17398397e-001, 3.00000000e+000,\n",
       "         9.39285604e-025, 3.00000000e+000, 4.67523411e-023,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.06144548e-006,\n",
       "         2.64312619e-009],\n",
       "        [3.00000000e+000, 1.52740056e+000, 3.00000000e+000,\n",
       "         6.35585475e-022, 3.00000000e+000, 2.12267451e-020,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.29186200e-006,\n",
       "         4.45405295e-007],\n",
       "        [3.00000000e+000, 1.26573378e+000, 3.00000000e+000,\n",
       "         3.43403506e-022, 3.00000000e+000, 1.16664026e-020,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.72257503e-006,\n",
       "         1.25438575e-007],\n",
       "        [3.00000000e+000, 1.05651632e+000, 3.00000000e+000,\n",
       "         6.31519507e-022, 3.00000000e+000, 2.00288008e-020,\n",
       "         3.00000000e+000, 2.99999999e+000, 5.87839212e-006,\n",
       "         6.12852402e-008],\n",
       "        [3.00000000e+000, 8.61781322e-001, 3.00000000e+000,\n",
       "         1.39335457e-023, 3.00000000e+000, 5.71676385e-022,\n",
       "         3.00000000e+000, 2.99999999e+000, 2.31993804e-006,\n",
       "         7.58271065e-009],\n",
       "        [3.00000000e+000, 1.25260383e+000, 3.00000000e+000,\n",
       "         2.41712654e-022, 3.00000000e+000, 8.41517762e-021,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.38780180e-006,\n",
       "         1.06569358e-007],\n",
       "        [3.00000000e+000, 7.20352921e-001, 3.00000000e+000,\n",
       "         7.73299257e-023, 3.00000000e+000, 2.74123319e-021,\n",
       "         3.00000000e+000, 2.99999996e+000, 4.95084531e-006,\n",
       "         6.08751893e-009],\n",
       "        [3.00000000e+000, 1.23448451e+000, 3.00000000e+000,\n",
       "         2.64806892e-022, 3.00000000e+000, 9.13890878e-021,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.56544385e-006,\n",
       "         1.01545366e-007],\n",
       "        [3.00000000e+000, 4.95557063e-007, 3.00000000e+000,\n",
       "         1.34200749e-084, 3.00000000e+000, 6.41777255e-079,\n",
       "         3.00000000e+000, 3.00000000e+000, 2.75558473e-020,\n",
       "         1.55205811e-047],\n",
       "        [3.00000000e+000, 1.84437148e-007, 3.00000000e+000,\n",
       "         1.27384483e-088, 3.00000000e+000, 1.11466945e-082,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.64682513e-021,\n",
       "         4.34792335e-050],\n",
       "        [3.00000000e+000, 6.04701811e-007, 3.00000000e+000,\n",
       "         4.16749205e-086, 3.00000000e+000, 2.61715757e-080,\n",
       "         3.00000000e+000, 3.00000000e+000, 7.73059915e-021,\n",
       "         9.83339866e-048],\n",
       "        [3.00000000e+000, 1.80282401e-007, 3.00000000e+000,\n",
       "         7.49646248e-089, 3.00000000e+000, 6.80911345e-083,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.15081567e-021,\n",
       "         3.44490784e-050],\n",
       "        [3.00000000e+000, 3.79153766e-007, 3.00000000e+000,\n",
       "         6.26124369e-086, 3.00000000e+000, 3.67449488e-080,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.33777860e-020,\n",
       "         2.66224542e-048],\n",
       "        [3.00000000e+000, 2.10039775e-007, 3.00000000e+000,\n",
       "         2.73087164e-089, 3.00000000e+000, 2.70567477e-083,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.99878817e-021,\n",
       "         4.03564354e-050],\n",
       "        [3.00000000e+000, 2.30715845e-007, 3.00000000e+000,\n",
       "         4.90011806e-091, 3.00000000e+000, 6.58280177e-085,\n",
       "         3.00000000e+000, 3.00000000e+000, 5.18793704e-022,\n",
       "         1.56469471e-050],\n",
       "        [3.00000000e+000, 4.22402309e-007, 3.00000000e+000,\n",
       "         5.42603932e-085, 3.00000000e+000, 2.73875982e-079,\n",
       "         3.00000000e+000, 3.00000000e+000, 2.39346271e-020,\n",
       "         7.19955619e-048],\n",
       "        [3.00000000e+000, 8.03930494e-008, 3.00000000e+000,\n",
       "         1.18140462e-095, 3.00000000e+000, 3.19626785e-089,\n",
       "         3.00000000e+000, 3.00000000e+000, 4.73499138e-023,\n",
       "         2.35048241e-053],\n",
       "        [3.00000000e+000, 6.09127827e-008, 3.00000000e+000,\n",
       "         2.54136997e-093, 3.00000000e+000, 4.52201020e-087,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.29114545e-022,\n",
       "         5.22796853e-053],\n",
       "        [3.00000000e+000, 4.80304052e-007, 3.00000000e+000,\n",
       "         1.27851005e-088, 3.00000000e+000, 1.20828129e-082,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.54187553e-021,\n",
       "         8.19711830e-049],\n",
       "        [3.00000000e+000, 1.05561205e-007, 3.00000000e+000,\n",
       "         1.00060238e-092, 3.00000000e+000, 1.68208776e-086,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.08627017e-022,\n",
       "         4.30165122e-052],\n",
       "        [3.00000000e+000, 9.29978586e-007, 3.00000000e+000,\n",
       "         8.89012359e-086, 3.00000000e+000, 5.46580825e-080,\n",
       "         3.00000000e+000, 3.00000000e+000, 6.65760841e-021,\n",
       "         4.64672379e-047],\n",
       "        [3.00000000e+000, 9.91120521e-008, 3.00000000e+000,\n",
       "         1.20632091e-093, 3.00000000e+000, 2.35878237e-087,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.67950480e-022,\n",
       "         1.85068647e-052],\n",
       "        [3.00000000e+000, 2.91734200e-008, 3.00000000e+000,\n",
       "         1.51013975e-099, 3.00000000e+000, 7.29844330e-093,\n",
       "         3.00000000e+000, 3.00000000e+000, 7.03977153e-024,\n",
       "         6.67659223e-056],\n",
       "        [3.00000000e+000, 8.23936474e-001, 3.00000000e+000,\n",
       "         2.74460795e-023, 3.00000000e+000, 1.06570890e-021,\n",
       "         3.00000000e+000, 2.99999999e+000, 3.03726027e-006,\n",
       "         7.71092447e-009],\n",
       "        [3.00000000e+000, 1.04597912e+000, 3.00000000e+000,\n",
       "         1.86273049e-023, 3.00000000e+000, 7.65378166e-022,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.96843883e-006,\n",
       "         1.97963403e-008],\n",
       "        [3.00000000e+000, 7.15945789e-001, 3.00000000e+000,\n",
       "         3.26103635e-023, 3.00000000e+000, 1.23129496e-021,\n",
       "         3.00000000e+000, 2.99999997e+000, 3.80120761e-006,\n",
       "         4.55474833e-009],\n",
       "        [3.00000000e+000, 1.28370642e+000, 3.00000000e+000,\n",
       "         3.00099624e-022, 3.00000000e+000, 1.03176288e-020,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.49017076e-006,\n",
       "         1.29747766e-007],\n",
       "        [3.00000000e+000, 6.46909145e-001, 3.00000000e+000,\n",
       "         1.58311479e-024, 3.00000000e+000, 7.39502948e-023,\n",
       "         3.00000000e+000, 2.99999999e+000, 1.65234595e-006,\n",
       "         1.20229807e-009],\n",
       "        [3.00000000e+000, 8.00417086e-001, 3.00000000e+000,\n",
       "         8.15057504e-023, 3.00000000e+000, 2.91103766e-021,\n",
       "         3.00000000e+000, 2.99999998e+000, 4.43255522e-006,\n",
       "         9.53819968e-009],\n",
       "        [3.00000000e+000, 8.64665312e-001, 3.00000000e+000,\n",
       "         2.84176125e-024, 3.00000000e+000, 1.31168028e-022,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.40128615e-006,\n",
       "         4.71955518e-009],\n",
       "        [3.00000000e+000, 6.06456498e-001, 3.00000000e+000,\n",
       "         1.34446535e-023, 3.00000000e+000, 5.32736156e-022,\n",
       "         3.00000000e+000, 2.99999996e+000, 3.48461203e-006,\n",
       "         1.80623083e-009],\n",
       "        [3.00000000e+000, 1.32679471e+000, 3.00000000e+000,\n",
       "         1.56096355e-022, 3.00000000e+000, 5.65871913e-021,\n",
       "         3.00000000e+000, 3.00000000e+000, 2.69604088e-006,\n",
       "         1.26973863e-007],\n",
       "        [3.00000000e+000, 5.57730285e-001, 3.00000000e+000,\n",
       "         5.68358193e-024, 3.00000000e+000, 2.37987637e-022,\n",
       "         3.00000000e+000, 2.99999995e+000, 2.91889908e-006,\n",
       "         1.00800003e-009],\n",
       "        [3.00000000e+000, 1.15839749e+000, 3.00000000e+000,\n",
       "         8.22289310e-023, 3.00000000e+000, 3.06751192e-021,\n",
       "         3.00000000e+000, 3.00000000e+000, 2.71514357e-006,\n",
       "         5.12447110e-008],\n",
       "        [3.00000000e+000, 6.64981199e-001, 3.00000000e+000,\n",
       "         2.77648189e-024, 3.00000000e+000, 1.24779099e-022,\n",
       "         3.00000000e+000, 2.99999999e+000, 1.90997171e-006,\n",
       "         1.59204239e-009],\n",
       "        [3.00000000e+000, 1.09969435e+000, 3.00000000e+000,\n",
       "         1.92035557e-023, 3.00000000e+000, 7.92251880e-022,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.85264328e-006,\n",
       "         2.53796895e-008],\n",
       "        [3.00000000e+000, 1.10093952e+000, 3.00000000e+000,\n",
       "         1.62891102e-024, 3.00000000e+000, 8.06425623e-023,\n",
       "         3.00000000e+000, 3.00000000e+000, 8.51474836e-007,\n",
       "         1.19568574e-008],\n",
       "        [3.00000000e+000, 7.31055489e-001, 3.00000000e+000,\n",
       "         1.19062535e-023, 3.00000000e+000, 4.85354510e-022,\n",
       "         3.00000000e+000, 2.99999998e+000, 2.70123527e-006,\n",
       "         3.63632874e-009],\n",
       "        [3.00000000e+000, 1.05899468e-007, 3.00000000e+000,\n",
       "         6.22429517e-094, 3.00000000e+000, 1.28486637e-087,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.28502029e-022,\n",
       "         1.85037549e-052],\n",
       "        [3.00000000e+000, 8.96680378e-008, 3.00000000e+000,\n",
       "         1.38887729e-093, 3.00000000e+000, 2.66599462e-087,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.92129043e-022,\n",
       "         1.42152594e-052],\n",
       "        [3.00000000e+000, 1.05594534e-007, 3.00000000e+000,\n",
       "         4.83362534e-095, 3.00000000e+000, 1.20473913e-088,\n",
       "         3.00000000e+000, 3.00000000e+000, 5.76850444e-023,\n",
       "         8.36353800e-053],\n",
       "        [3.00000000e+000, 7.69469866e-008, 3.00000000e+000,\n",
       "         6.39656686e-095, 3.00000000e+000, 1.52225536e-088,\n",
       "         3.00000000e+000, 3.00000000e+000, 8.37750802e-023,\n",
       "         3.45308504e-053],\n",
       "        [3.00000000e+000, 1.43594079e-007, 3.00000000e+000,\n",
       "         3.44728921e-091, 3.00000000e+000, 4.57443095e-085,\n",
       "         3.00000000e+000, 3.00000000e+000, 7.11946910e-022,\n",
       "         3.27988738e-051],\n",
       "        [3.00000000e+000, 2.88719202e-008, 3.00000000e+000,\n",
       "         5.83444061e-099, 3.00000000e+000, 2.54978200e-092,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.08691244e-023,\n",
       "         9.79686642e-056],\n",
       "        [3.00000000e+000, 1.21161675e-007, 3.00000000e+000,\n",
       "         5.37367162e-090, 3.00000000e+000, 5.74242373e-084,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.96768025e-021,\n",
       "         4.53024556e-051],\n",
       "        [3.00000000e+000, 1.24487209e-007, 3.00000000e+000,\n",
       "         3.19379347e-091, 3.00000000e+000, 4.21318213e-085,\n",
       "         3.00000000e+000, 3.00000000e+000, 7.90436910e-022,\n",
       "         2.06761739e-051],\n",
       "        [3.00000000e+000, 3.10607510e-008, 3.00000000e+000,\n",
       "         6.68055204e-099, 3.00000000e+000, 2.90760125e-092,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.06195268e-023,\n",
       "         1.27790213e-055],\n",
       "        [3.00000000e+000, 2.95432978e-008, 3.00000000e+000,\n",
       "         2.33751889e-097, 3.00000000e+000, 7.79311135e-091,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.39765449e-023,\n",
       "         3.26744092e-055],\n",
       "        [3.00000000e+000, 6.13713935e-008, 3.00000000e+000,\n",
       "         9.03764966e-096, 3.00000000e+000, 2.44020856e-089,\n",
       "         3.00000000e+000, 3.00000000e+000, 5.55056917e-023,\n",
       "         9.45763248e-054],\n",
       "        [3.00000000e+000, 5.16879978e-007, 3.00000000e+000,\n",
       "         1.06263819e-085, 3.00000000e+000, 6.14923561e-080,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.19513615e-020,\n",
       "         8.10197042e-048],\n",
       "        [3.00000000e+000, 1.62905647e-008, 3.00000000e+000,\n",
       "         3.48258942e-099, 3.00000000e+000, 1.50970777e-092,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.54729111e-023,\n",
       "         1.44521463e-056],\n",
       "        [3.00000000e+000, 4.24571773e-008, 3.00000000e+000,\n",
       "         7.77031249e-096, 3.00000000e+000, 2.05939375e-089,\n",
       "         3.00000000e+000, 3.00000000e+000, 7.37597764e-023,\n",
       "         2.91634663e-054],\n",
       "        [3.00000000e+000, 1.87532458e-008, 3.00000000e+000,\n",
       "         1.20816955e-100, 3.00000000e+000, 6.78967756e-094,\n",
       "         3.00000000e+000, 3.00000000e+000, 4.73686044e-024,\n",
       "         7.92301198e-057],\n",
       "        [3.00000000e+000, 6.12517949e-001, 3.00000000e+000,\n",
       "         3.69277487e-024, 3.00000000e+000, 1.61136498e-022,\n",
       "         3.00000000e+000, 2.99999998e+000, 2.29513492e-006,\n",
       "         1.26168629e-009],\n",
       "        [3.00000000e+000, 1.52131232e+000, 3.00000000e+000,\n",
       "         1.34199331e-021, 3.00000000e+000, 4.23845069e-020,\n",
       "         3.00000000e+000, 3.00000000e+000, 4.19448229e-006,\n",
       "         5.46608864e-007],\n",
       "        [3.00000000e+000, 8.27622049e-001, 3.00000000e+000,\n",
       "         1.61064193e-022, 3.00000000e+000, 5.49063618e-021,\n",
       "         3.00000000e+000, 2.99999997e+000, 5.26900407e-006,\n",
       "         1.35351388e-008],\n",
       "        [3.00000000e+000, 9.40054552e-001, 3.00000000e+000,\n",
       "         6.76014074e-024, 3.00000000e+000, 2.95524892e-022,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.65240535e-006,\n",
       "         8.88754321e-009],\n",
       "        [3.00000000e+000, 8.92233215e-001, 3.00000000e+000,\n",
       "         6.98738013e-022, 3.00000000e+000, 2.15560746e-020,\n",
       "         3.00000000e+000, 2.99999997e+000, 7.60178366e-006,\n",
       "         2.93526228e-008],\n",
       "        [3.00000000e+000, 1.21502194e+000, 3.00000000e+000,\n",
       "         2.79059991e-023, 3.00000000e+000, 1.13470752e-021,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.80025412e-006,\n",
       "         4.68383507e-008],\n",
       "        [3.00000000e+000, 1.44983840e+000, 3.00000000e+000,\n",
       "         1.01528227e-021, 3.00000000e+000, 3.24824776e-020,\n",
       "         3.00000000e+000, 3.00000000e+000, 4.18663341e-006,\n",
       "         3.74515367e-007],\n",
       "        [3.00000000e+000, 1.18673348e+000, 3.00000000e+000,\n",
       "         4.00517860e-022, 3.00000000e+000, 1.33351934e-020,\n",
       "         3.00000000e+000, 3.00000000e+000, 4.31007837e-006,\n",
       "         9.41416946e-008],\n",
       "        [3.00000000e+000, 1.16772087e+000, 3.00000000e+000,\n",
       "         1.81138218e-021, 3.00000000e+000, 5.38343196e-020,\n",
       "         3.00000000e+000, 2.99999999e+000, 7.09519432e-006,\n",
       "         1.37963815e-007],\n",
       "        [3.00000000e+000, 5.95799203e-001, 3.00000000e+000,\n",
       "         6.30797883e-024, 3.00000000e+000, 2.63842692e-022,\n",
       "         3.00000000e+000, 2.99999997e+000, 2.80209018e-006,\n",
       "         1.33735924e-009],\n",
       "        [3.00000000e+000, 1.26898857e+000, 3.00000000e+000,\n",
       "         3.02507547e-022, 3.00000000e+000, 1.03774537e-020,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.56277405e-006,\n",
       "         1.22301707e-007],\n",
       "        [3.00000000e+000, 1.02582043e+000, 3.00000000e+000,\n",
       "         1.44209309e-022, 3.00000000e+000, 5.08208138e-021,\n",
       "         3.00000000e+000, 2.99999999e+000, 3.84803418e-006,\n",
       "         3.38936662e-008],\n",
       "        [3.00000000e+000, 9.12414154e-001, 3.00000000e+000,\n",
       "         1.37356993e-024, 3.00000000e+000, 6.73106024e-023,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.04081960e-006,\n",
       "         4.77092038e-009],\n",
       "        [3.00000000e+000, 1.12766391e+000, 3.00000000e+000,\n",
       "         6.78567695e-024, 3.00000000e+000, 3.03275205e-022,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.28856517e-006,\n",
       "         2.08384267e-008],\n",
       "        [3.00000000e+000, 1.59234091e+000, 3.00000000e+000,\n",
       "         1.06026770e-021, 3.00000000e+000, 3.43363720e-020,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.57599450e-006,\n",
       "         6.80118616e-007]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 進行矩陣運算\n",
    "# X.T 的形狀為 (data_size, feature_num)，X.T @ coefficients 的形狀為 (feature_num, T)\n",
    "linear_combination = c + X @ coefficients\n",
    "\n",
    "# 使用 sigmoid 函數將值映射到 [0, 1] 之間\n",
    "sigma_matrix = 1 / (1 + np.exp(-linear_combination))  # shape: (data_size, T)\n",
    "# print(f\"sigma_matrix.shape: {sigma_matrix.shape}\")\n",
    "# print(f\"sigma_matrix: {sigma_matrix}\")\n",
    "\n",
    "# 計算每個元素的最小值和最大值\n",
    "min_value = np.min(sigma_matrix)\n",
    "max_value = np.max(sigma_matrix)\n",
    "print(f\"Value range: {(min_value, max_value)}\")\n",
    "\n",
    "# 再將值縮放到 [2, 10] 的範圍\n",
    "# shape: (data_size, T)\n",
    "# sigma_matrix = 0 + sigma_matrix * 300\n",
    "\n",
    "# sigma_matrix = 0 + sigma_matrix * 200\n",
    "# sigma_matrix = 100 + sigma_matrix * 100\n",
    "# sigma_matrix = 0 + sigma_matrix * 10\n",
    "sigma_matrix = 0 + sigma_matrix * 3\n",
    "# sigma_matrix = 50 + sigma_matrix * 50\n",
    "# sigma_matrix = 0 + sigma_matrix * 2\n",
    "# sigma_matrix = 10 + sigma_matrix * 5\n",
    "# sigma_matrix = 0 + sigma_matrix * 1\n",
    "\n",
    "\n",
    "# sigma_matrix = 0 + sigma_matrix * 80\n",
    "# sigma_matrix = 40 + sigma_matrix * 40\n",
    "# sigma_matrix = 0 + sigma_matrix * 40\n",
    "# sigma_matrix = 20 + sigma_matrix * 20\n",
    "# sigma_matrix = 0 + sigma_matrix * 5\n",
    "\n",
    "# sigma_matrix = 0 + sigma_matrix * 8\n",
    "# sigma_matrix = 4 + sigma_matrix * 4\n",
    "# sigma_matrix = 0 + sigma_matrix * 4\n",
    "# sigma_matrix = 2 + sigma_matrix * 2\n",
    "# sigma_matrix = 0 + sigma_matrix * 0.3\n",
    "\n",
    "# 計算每個元素的最小值和最大值\n",
    "min_value = np.min(sigma_matrix)\n",
    "max_value = np.max(sigma_matrix)\n",
    "print(f\"New Value range: {(min_value, max_value)}\")\n",
    "\n",
    "# 輸出 sigma_matrix 的形狀和內容\n",
    "sigma_matrix_shape = sigma_matrix.shape\n",
    "sigma_matrix_content = sigma_matrix\n",
    "\n",
    "sigma_matrix_shape, sigma_matrix_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNQRS392qk1H"
   },
   "source": [
    "### corr matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6t2w0Y7EYxB0",
    "outputId": "72618685-7498-42d7-e92c-67457a485da5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr_matrix shape: (10, 10)\n",
      "corr_matrix: \n",
      "[[ 1.          0.35424279  0.5557836   0.58741064 -0.38777369 -0.16148427\n",
      "  -0.0990728  -0.27594366 -0.48889127 -0.02092469]\n",
      " [ 0.35424279  1.          0.64567134  0.34424882 -0.53396229 -0.11871438\n",
      "  -0.3666009   0.07223015  0.10995817 -0.04912633]\n",
      " [ 0.5557836   0.64567134  1.          0.259728   -0.42849166 -0.23652044\n",
      "  -0.55154321  0.01056255 -0.4142461  -0.12870872]\n",
      " [ 0.58741064  0.34424882  0.259728    1.         -0.43371556 -0.07896157\n",
      "   0.16623268 -0.63102156  0.08913915  0.24417687]\n",
      " [-0.38777369 -0.53396229 -0.42849166 -0.43371556  1.          0.37139904\n",
      "   0.30031034  0.29401969 -0.15371929 -0.10854857]\n",
      " [-0.16148427 -0.11871438 -0.23652044 -0.07896157  0.37139904  1.\n",
      "   0.65829169  0.52050763 -0.34173775  0.14741869]\n",
      " [-0.0990728  -0.3666009  -0.55154321  0.16623268  0.30031034  0.65829169\n",
      "   1.          0.03894138 -0.00977194  0.48587032]\n",
      " [-0.27594366  0.07223015  0.01056255 -0.63102156  0.29401969  0.52050763\n",
      "   0.03894138  1.         -0.20365855  0.13048727]\n",
      " [-0.48889127  0.10995817 -0.4142461   0.08913915 -0.15371929 -0.34173775\n",
      "  -0.00977194 -0.20365855  1.          0.35511152]\n",
      " [-0.02092469 -0.04912633 -0.12870872  0.24417687 -0.10854857  0.14741869\n",
      "   0.48587032  0.13048727  0.35511152  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Generate correlation matrix\n",
    "np.random.seed(0)\n",
    "\n",
    "A = np.random.uniform(-1, 1, (T, T))\n",
    "corr_matrix = np.dot(A, A.T)\n",
    "\n",
    "D = np.diag(1 / np.sqrt(np.diag(corr_matrix)))\n",
    "corr_matrix = D @ corr_matrix @ D\n",
    "\n",
    "print(f\"corr_matrix shape: {corr_matrix.shape}\")\n",
    "print(f\"corr_matrix: \\n{corr_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxpp4zz0qxAA"
   },
   "source": [
    "### cov matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ft_GZABHZ754",
    "outputId": "a7b0c34d-fecb-4cda-c58a-ded5cb35b8a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cov_matrices shape: (90, 10, 10)\n",
      "cov_matrices: \n",
      "[[ 9.00000000e+000  6.53580061e-007  5.00205241e+000  2.81695297e-085\n",
      "  -3.48996324e+000 -4.40962825e-080 -8.91655219e-001 -2.48349295e+000\n",
      "  -1.70421930e-020 -9.82623188e-049]\n",
      " [ 6.53580061e-007  3.78227444e-013  1.19126747e-006  3.38427395e-092\n",
      "  -9.85163603e-007 -6.64554083e-087 -6.76380850e-007  1.33265054e-007\n",
      "   7.85770906e-028 -4.72930647e-055]\n",
      " [ 5.00205241e+000  1.19126747e-006  9.00000000e+000  1.24553678e-085\n",
      "  -3.85642497e+000 -6.45863021e-080 -4.96388886e+000  9.50629143e-002\n",
      "  -1.44401472e-020 -6.04415847e-048]\n",
      " [ 2.81695297e-085  3.38427395e-092  1.24553678e-085  2.55524802e-170\n",
      "  -2.07990158e-085 -1.14890155e-165  7.97175933e-086 -3.02609098e-085\n",
      "   1.65568211e-106  6.10980952e-133]\n",
      " [-3.48996324e+000 -9.85163603e-007 -3.85642497e+000 -2.07990158e-085\n",
      "   9.00000000e+000  1.01417413e-079  2.70279307e+000  2.64617719e+000\n",
      "  -5.35847928e-021 -5.09743830e-048]\n",
      " [-4.40962825e-080 -6.64554083e-087 -6.45863021e-080 -1.14890155e-165\n",
      "   1.01417413e-079  8.28516171e-159  1.79758785e-079  1.42134284e-079\n",
      "  -3.61439311e-100  2.10043700e-127]\n",
      " [-8.91655219e-001 -6.76380850e-007 -4.96388886e+000  7.97175933e-086\n",
      "   2.70279307e+000  1.79758785e-079  9.00000000e+000  3.50472395e-001\n",
      "  -3.40638856e-022  2.28164587e-047]\n",
      " [-2.48349295e+000  1.33265054e-007  9.50629143e-002 -3.02609098e-085\n",
      "   2.64617719e+000  1.42134284e-079  3.50472395e-001  9.00000000e+000\n",
      "  -7.09930513e-021  6.12767894e-048]\n",
      " [-1.70421930e-020  7.85770906e-028 -1.44401472e-020  1.65568211e-106\n",
      "  -5.35847928e-021 -3.61439311e-100 -3.40638856e-022 -7.09930513e-021\n",
      "   1.35015577e-040  6.45897075e-068]\n",
      " [-9.82623188e-049 -4.72930647e-055 -6.04415847e-048  6.10980952e-133\n",
      "  -5.09743830e-048  2.10043700e-127  2.28164587e-047  6.12767894e-048\n",
      "   6.45897075e-068  2.45026601e-094]]\n"
     ]
    }
   ],
   "source": [
    "# Generate covariance matrices\n",
    "cov_matrices = []\n",
    "for i in range(data_size):\n",
    "    cov_matrix = np.zeros((T, T))  # 每一個模擬都會有 T*T 的共變異矩陣\n",
    "    for j in range(T):\n",
    "        for k in range(T):\n",
    "            cov_matrix[j, k] = (\n",
    "                corr_matrix[j, k] * sigma_matrix[i, j] * sigma_matrix[i, k]\n",
    "            )\n",
    "    cov_matrices.append(cov_matrix)\n",
    "\n",
    "print(f\"cov_matrices shape: {np.array(cov_matrices).shape}\")\n",
    "print(f\"cov_matrices: \\n{cov_matrices[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "36jbx5j7Tt0D",
    "outputId": "62658998-8158-425b-c756-8448e4c96db5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All covariance matrices are positive definite: False\n"
     ]
    }
   ],
   "source": [
    "def is_positive_definite(matrix):\n",
    "    return np.all(np.linalg.eigvals(matrix) > 0)\n",
    "\n",
    "\n",
    "positive_definite_check = all(is_positive_definite(cov) for cov in cov_matrices)\n",
    "print(\"All covariance matrices are positive definite:\", positive_definite_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDjqi0k25thw"
   },
   "source": [
    "### MVN stimulation for demand_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kz-UdBRYc2Hb",
    "outputId": "4e19fe37-abd4-4435-d5b9-9e964c44ceb0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>251.794016</td>\n",
       "      <td>254.356464</td>\n",
       "      <td>247.741536</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>261.523870</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.087872</td>\n",
       "      <td>252.716034</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.356465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251.056784</td>\n",
       "      <td>251.010919</td>\n",
       "      <td>248.192143</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>250.249903</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>252.054546</td>\n",
       "      <td>246.842220</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>251.010920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>297.528249</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>294.250464</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>283.569719</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>285.767294</td>\n",
       "      <td>287.835884</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>291.630992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>289.066894</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.355508</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>285.816090</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>292.681865</td>\n",
       "      <td>290.851589</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.907838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298.072424</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>299.903104</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>296.615372</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>290.943971</td>\n",
       "      <td>295.944768</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>293.500607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>65.746933</td>\n",
       "      <td>65.853934</td>\n",
       "      <td>70.574162</td>\n",
       "      <td>62.239247</td>\n",
       "      <td>55.130102</td>\n",
       "      <td>62.239247</td>\n",
       "      <td>57.888206</td>\n",
       "      <td>63.679955</td>\n",
       "      <td>62.239243</td>\n",
       "      <td>62.239247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>61.329502</td>\n",
       "      <td>63.260741</td>\n",
       "      <td>60.017189</td>\n",
       "      <td>63.453517</td>\n",
       "      <td>66.141381</td>\n",
       "      <td>63.453517</td>\n",
       "      <td>65.584679</td>\n",
       "      <td>64.101433</td>\n",
       "      <td>63.453519</td>\n",
       "      <td>63.453517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>66.822772</td>\n",
       "      <td>69.549069</td>\n",
       "      <td>66.237491</td>\n",
       "      <td>69.280813</td>\n",
       "      <td>70.547457</td>\n",
       "      <td>69.280813</td>\n",
       "      <td>70.842404</td>\n",
       "      <td>73.111604</td>\n",
       "      <td>69.280814</td>\n",
       "      <td>69.280813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>62.577572</td>\n",
       "      <td>67.210049</td>\n",
       "      <td>65.172995</td>\n",
       "      <td>67.044144</td>\n",
       "      <td>70.357863</td>\n",
       "      <td>67.044144</td>\n",
       "      <td>68.535449</td>\n",
       "      <td>70.440907</td>\n",
       "      <td>67.044145</td>\n",
       "      <td>67.044144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>59.277409</td>\n",
       "      <td>59.472203</td>\n",
       "      <td>62.933669</td>\n",
       "      <td>60.318389</td>\n",
       "      <td>57.697020</td>\n",
       "      <td>60.318389</td>\n",
       "      <td>59.467526</td>\n",
       "      <td>57.168997</td>\n",
       "      <td>60.318390</td>\n",
       "      <td>60.318390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "0   251.794016  254.356464  247.741536  254.356465  261.523870  254.356465   \n",
       "1   251.056784  251.010919  248.192143  251.010920  250.249903  251.010920   \n",
       "2   297.528249  291.630992  294.250464  291.630992  283.569719  291.630992   \n",
       "3   289.066894  288.907838  288.355508  288.907838  285.816090  288.907838   \n",
       "4   298.072424  293.500607  299.903104  293.500607  296.615372  293.500607   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "85   65.746933   65.853934   70.574162   62.239247   55.130102   62.239247   \n",
       "86   61.329502   63.260741   60.017189   63.453517   66.141381   63.453517   \n",
       "87   66.822772   69.549069   66.237491   69.280813   70.547457   69.280813   \n",
       "88   62.577572   67.210049   65.172995   67.044144   70.357863   67.044144   \n",
       "89   59.277409   59.472203   62.933669   60.318389   57.697020   60.318389   \n",
       "\n",
       "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "0   254.087872  252.716034  254.356465  254.356465  \n",
       "1   252.054546  246.842220  251.010920  251.010920  \n",
       "2   285.767294  287.835884  291.630992  291.630992  \n",
       "3   292.681865  290.851589  288.907838  288.907838  \n",
       "4   290.943971  295.944768  293.500607  293.500607  \n",
       "..         ...         ...         ...         ...  \n",
       "85   57.888206   63.679955   62.239243   62.239247  \n",
       "86   65.584679   64.101433   63.453519   63.453517  \n",
       "87   70.842404   73.111604   69.280814   69.280813  \n",
       "88   68.535449   70.440907   67.044145   67.044144  \n",
       "89   59.467526   57.168997   60.318390   60.318390  \n",
       "\n",
       "[90 rows x 10 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simulate_demand_data(data_size, T, cov_matrices, mu_matrix):\n",
    "    np.random.seed(0)\n",
    "\n",
    "    simulated_data = np.array(\n",
    "        [\n",
    "            np.random.multivariate_normal(mu_matrix[i], cov_matrices[i])\n",
    "            for i in range(data_size)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    demand_df = pd.DataFrame(\n",
    "        simulated_data, columns=[f\"demand_t{t}\" for t in range(1, T + 1)]\n",
    "    )\n",
    "    return demand_df\n",
    "\n",
    "\n",
    "demand_df = simulate_demand_data(data_size, T, cov_matrices, mu_matrix)\n",
    "demand_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9SB3AS8eLXlJ"
   },
   "source": [
    "### Replace negative values to 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jj5Gvln1Lb2X",
    "outputId": "09dc87db-1439-4d01-a41e-7bd0e7a0f1ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27318/2799096767.py:3: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df.applymap(lambda x: max(x, 0))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>251.794016</td>\n",
       "      <td>254.356464</td>\n",
       "      <td>247.741536</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>261.523870</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.087872</td>\n",
       "      <td>252.716034</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.356465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251.056784</td>\n",
       "      <td>251.010919</td>\n",
       "      <td>248.192143</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>250.249903</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>252.054546</td>\n",
       "      <td>246.842220</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>251.010920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>297.528249</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>294.250464</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>283.569719</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>285.767294</td>\n",
       "      <td>287.835884</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>291.630992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>289.066894</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.355508</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>285.816090</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>292.681865</td>\n",
       "      <td>290.851589</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.907838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298.072424</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>299.903104</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>296.615372</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>290.943971</td>\n",
       "      <td>295.944768</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>293.500607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>65.746933</td>\n",
       "      <td>65.853934</td>\n",
       "      <td>70.574162</td>\n",
       "      <td>62.239247</td>\n",
       "      <td>55.130102</td>\n",
       "      <td>62.239247</td>\n",
       "      <td>57.888206</td>\n",
       "      <td>63.679955</td>\n",
       "      <td>62.239243</td>\n",
       "      <td>62.239247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>61.329502</td>\n",
       "      <td>63.260741</td>\n",
       "      <td>60.017189</td>\n",
       "      <td>63.453517</td>\n",
       "      <td>66.141381</td>\n",
       "      <td>63.453517</td>\n",
       "      <td>65.584679</td>\n",
       "      <td>64.101433</td>\n",
       "      <td>63.453519</td>\n",
       "      <td>63.453517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>66.822772</td>\n",
       "      <td>69.549069</td>\n",
       "      <td>66.237491</td>\n",
       "      <td>69.280813</td>\n",
       "      <td>70.547457</td>\n",
       "      <td>69.280813</td>\n",
       "      <td>70.842404</td>\n",
       "      <td>73.111604</td>\n",
       "      <td>69.280814</td>\n",
       "      <td>69.280813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>62.577572</td>\n",
       "      <td>67.210049</td>\n",
       "      <td>65.172995</td>\n",
       "      <td>67.044144</td>\n",
       "      <td>70.357863</td>\n",
       "      <td>67.044144</td>\n",
       "      <td>68.535449</td>\n",
       "      <td>70.440907</td>\n",
       "      <td>67.044145</td>\n",
       "      <td>67.044144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>59.277409</td>\n",
       "      <td>59.472203</td>\n",
       "      <td>62.933669</td>\n",
       "      <td>60.318389</td>\n",
       "      <td>57.697020</td>\n",
       "      <td>60.318389</td>\n",
       "      <td>59.467526</td>\n",
       "      <td>57.168997</td>\n",
       "      <td>60.318390</td>\n",
       "      <td>60.318390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "0   251.794016  254.356464  247.741536  254.356465  261.523870  254.356465   \n",
       "1   251.056784  251.010919  248.192143  251.010920  250.249903  251.010920   \n",
       "2   297.528249  291.630992  294.250464  291.630992  283.569719  291.630992   \n",
       "3   289.066894  288.907838  288.355508  288.907838  285.816090  288.907838   \n",
       "4   298.072424  293.500607  299.903104  293.500607  296.615372  293.500607   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "85   65.746933   65.853934   70.574162   62.239247   55.130102   62.239247   \n",
       "86   61.329502   63.260741   60.017189   63.453517   66.141381   63.453517   \n",
       "87   66.822772   69.549069   66.237491   69.280813   70.547457   69.280813   \n",
       "88   62.577572   67.210049   65.172995   67.044144   70.357863   67.044144   \n",
       "89   59.277409   59.472203   62.933669   60.318389   57.697020   60.318389   \n",
       "\n",
       "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "0   254.087872  252.716034  254.356465  254.356465  \n",
       "1   252.054546  246.842220  251.010920  251.010920  \n",
       "2   285.767294  287.835884  291.630992  291.630992  \n",
       "3   292.681865  290.851589  288.907838  288.907838  \n",
       "4   290.943971  295.944768  293.500607  293.500607  \n",
       "..         ...         ...         ...         ...  \n",
       "85   57.888206   63.679955   62.239243   62.239247  \n",
       "86   65.584679   64.101433   63.453519   63.453517  \n",
       "87   70.842404   73.111604   69.280814   69.280813  \n",
       "88   68.535449   70.440907   67.044145   67.044144  \n",
       "89   59.467526   57.168997   60.318390   60.318390  \n",
       "\n",
       "[90 rows x 10 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df = replace_negative_with_zero(demand_df)\n",
    "demand_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJ_lOKc5Sx_y"
   },
   "source": [
    "### Validate the mean and std of total demand\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ypOKYMaS8cm"
   },
   "source": [
    "檢查生成的需求數據是否符合上述總需求的特性。例如，從生成的需求 demand_df 中計算總需求\n",
    "𝐷\n",
    "D，然後檢查其均值和標準差是否接近理論值（即均值為所有\n",
    "𝜇\n",
    "𝑡\n",
    "μ\n",
    "t\n",
    "​\n",
    "的和，標準差根據共變異數矩陣計算）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OYoBmwqpUMLF",
    "outputId": "5ed51381-2231-42d6-c082-01af32258d0a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>theoretical_mean</th>\n",
       "      <th>empirical_mean</th>\n",
       "      <th>theoretical_std</th>\n",
       "      <th>empirical_std</th>\n",
       "      <th>std_relative_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2543.564650</td>\n",
       "      <td>2539.645651</td>\n",
       "      <td>5.934835</td>\n",
       "      <td>3.208153</td>\n",
       "      <td>84.992292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2510.109199</td>\n",
       "      <td>2503.450193</td>\n",
       "      <td>5.934835</td>\n",
       "      <td>1.501990</td>\n",
       "      <td>295.131489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2916.309923</td>\n",
       "      <td>2907.106572</td>\n",
       "      <td>5.934835</td>\n",
       "      <td>3.833263</td>\n",
       "      <td>54.824635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2889.078375</td>\n",
       "      <td>2891.311133</td>\n",
       "      <td>5.934835</td>\n",
       "      <td>1.655663</td>\n",
       "      <td>258.456665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2935.006074</td>\n",
       "      <td>2948.982676</td>\n",
       "      <td>5.934835</td>\n",
       "      <td>2.541082</td>\n",
       "      <td>133.555385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>622.392469</td>\n",
       "      <td>627.830276</td>\n",
       "      <td>6.175676</td>\n",
       "      <td>4.042657</td>\n",
       "      <td>52.762794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>634.535168</td>\n",
       "      <td>634.248994</td>\n",
       "      <td>6.109878</td>\n",
       "      <td>1.689231</td>\n",
       "      <td>261.695820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>692.808129</td>\n",
       "      <td>694.234050</td>\n",
       "      <td>6.082276</td>\n",
       "      <td>1.840933</td>\n",
       "      <td>230.390993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>670.441440</td>\n",
       "      <td>672.471413</td>\n",
       "      <td>6.136350</td>\n",
       "      <td>2.186541</td>\n",
       "      <td>180.641854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>603.183893</td>\n",
       "      <td>597.290383</td>\n",
       "      <td>6.276710</td>\n",
       "      <td>1.505996</td>\n",
       "      <td>316.781412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    theoretical_mean  empirical_mean  theoretical_std  empirical_std  \\\n",
       "0        2543.564650     2539.645651         5.934835       3.208153   \n",
       "1        2510.109199     2503.450193         5.934835       1.501990   \n",
       "2        2916.309923     2907.106572         5.934835       3.833263   \n",
       "3        2889.078375     2891.311133         5.934835       1.655663   \n",
       "4        2935.006074     2948.982676         5.934835       2.541082   \n",
       "..               ...             ...              ...            ...   \n",
       "85        622.392469      627.830276         6.175676       4.042657   \n",
       "86        634.535168      634.248994         6.109878       1.689231   \n",
       "87        692.808129      694.234050         6.082276       1.840933   \n",
       "88        670.441440      672.471413         6.136350       2.186541   \n",
       "89        603.183893      597.290383         6.276710       1.505996   \n",
       "\n",
       "    std_relative_error  \n",
       "0            84.992292  \n",
       "1           295.131489  \n",
       "2            54.824635  \n",
       "3           258.456665  \n",
       "4           133.555385  \n",
       "..                 ...  \n",
       "85           52.762794  \n",
       "86          261.695820  \n",
       "87          230.390993  \n",
       "88          180.641854  \n",
       "89          316.781412  \n",
       "\n",
       "[90 rows x 5 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_theoretical_vs_empirical(demand_df, cov_matrices, mu_matrix):\n",
    "    results = []\n",
    "    for i in range(len(demand_df)):\n",
    "\n",
    "        demand_i = demand_df.iloc[i, :]\n",
    "\n",
    "        # theoretical mean\n",
    "        theoretical_mean = mu_matrix[i].sum()\n",
    "\n",
    "        # theoretical std\n",
    "        variance_sum = np.sum(np.diag(cov_matrices[i]))\n",
    "        covariance_sum = np.sum(cov_matrices[i]) - variance_sum\n",
    "        theoretical_variance = variance_sum + covariance_sum\n",
    "        theoretical_std = np.sqrt(theoretical_variance)\n",
    "\n",
    "        # empirical mean and std\n",
    "        empirical_mean = demand_i.sum()\n",
    "        empirical_std = demand_i.std(ddof=0)  # 指定除以 n 而非 n-1\n",
    "        std_relative_error = abs(theoretical_std - empirical_std) / empirical_std * 100\n",
    "\n",
    "        # save the results\n",
    "        results.append(\n",
    "            {\n",
    "                \"theoretical_mean\": theoretical_mean,\n",
    "                \"empirical_mean\": empirical_mean,\n",
    "                \"theoretical_std\": theoretical_std,\n",
    "                \"empirical_std\": empirical_std,\n",
    "                \"std_relative_error\": std_relative_error,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "results_df = check_theoretical_vs_empirical(demand_df, cov_matrices, mu_matrix)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-QM7SNl1okD"
   },
   "source": [
    "### Validate normal distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_pKfG7Hq1vHo",
    "outputId": "55ca004b-bca0-468b-f047-ec36a691b1f5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>251.794016</td>\n",
       "      <td>254.356464</td>\n",
       "      <td>247.741536</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>261.523870</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.087872</td>\n",
       "      <td>252.716034</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.356465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251.056784</td>\n",
       "      <td>251.010919</td>\n",
       "      <td>248.192143</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>250.249903</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>252.054546</td>\n",
       "      <td>246.842220</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>251.010920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>297.528249</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>294.250464</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>283.569719</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>285.767294</td>\n",
       "      <td>287.835884</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>291.630992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>289.066894</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.355508</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>285.816090</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>292.681865</td>\n",
       "      <td>290.851589</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.907838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298.072424</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>299.903104</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>296.615372</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>290.943971</td>\n",
       "      <td>295.944768</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>293.500607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>65.746933</td>\n",
       "      <td>65.853934</td>\n",
       "      <td>70.574162</td>\n",
       "      <td>62.239247</td>\n",
       "      <td>55.130102</td>\n",
       "      <td>62.239247</td>\n",
       "      <td>57.888206</td>\n",
       "      <td>63.679955</td>\n",
       "      <td>62.239243</td>\n",
       "      <td>62.239247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>61.329502</td>\n",
       "      <td>63.260741</td>\n",
       "      <td>60.017189</td>\n",
       "      <td>63.453517</td>\n",
       "      <td>66.141381</td>\n",
       "      <td>63.453517</td>\n",
       "      <td>65.584679</td>\n",
       "      <td>64.101433</td>\n",
       "      <td>63.453519</td>\n",
       "      <td>63.453517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>66.822772</td>\n",
       "      <td>69.549069</td>\n",
       "      <td>66.237491</td>\n",
       "      <td>69.280813</td>\n",
       "      <td>70.547457</td>\n",
       "      <td>69.280813</td>\n",
       "      <td>70.842404</td>\n",
       "      <td>73.111604</td>\n",
       "      <td>69.280814</td>\n",
       "      <td>69.280813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>62.577572</td>\n",
       "      <td>67.210049</td>\n",
       "      <td>65.172995</td>\n",
       "      <td>67.044144</td>\n",
       "      <td>70.357863</td>\n",
       "      <td>67.044144</td>\n",
       "      <td>68.535449</td>\n",
       "      <td>70.440907</td>\n",
       "      <td>67.044145</td>\n",
       "      <td>67.044144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>59.277409</td>\n",
       "      <td>59.472203</td>\n",
       "      <td>62.933669</td>\n",
       "      <td>60.318389</td>\n",
       "      <td>57.697020</td>\n",
       "      <td>60.318389</td>\n",
       "      <td>59.467526</td>\n",
       "      <td>57.168997</td>\n",
       "      <td>60.318390</td>\n",
       "      <td>60.318390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "0   251.794016  254.356464  247.741536  254.356465  261.523870  254.356465   \n",
       "1   251.056784  251.010919  248.192143  251.010920  250.249903  251.010920   \n",
       "2   297.528249  291.630992  294.250464  291.630992  283.569719  291.630992   \n",
       "3   289.066894  288.907838  288.355508  288.907838  285.816090  288.907838   \n",
       "4   298.072424  293.500607  299.903104  293.500607  296.615372  293.500607   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "85   65.746933   65.853934   70.574162   62.239247   55.130102   62.239247   \n",
       "86   61.329502   63.260741   60.017189   63.453517   66.141381   63.453517   \n",
       "87   66.822772   69.549069   66.237491   69.280813   70.547457   69.280813   \n",
       "88   62.577572   67.210049   65.172995   67.044144   70.357863   67.044144   \n",
       "89   59.277409   59.472203   62.933669   60.318389   57.697020   60.318389   \n",
       "\n",
       "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "0   254.087872  252.716034  254.356465  254.356465  \n",
       "1   252.054546  246.842220  251.010920  251.010920  \n",
       "2   285.767294  287.835884  291.630992  291.630992  \n",
       "3   292.681865  290.851589  288.907838  288.907838  \n",
       "4   290.943971  295.944768  293.500607  293.500607  \n",
       "..         ...         ...         ...         ...  \n",
       "85   57.888206   63.679955   62.239243   62.239247  \n",
       "86   65.584679   64.101433   63.453519   63.453517  \n",
       "87   70.842404   73.111604   69.280814   69.280813  \n",
       "88   68.535449   70.440907   67.044145   67.044144  \n",
       "89   59.467526   57.168997   60.318390   60.318390  \n",
       "\n",
       "[90 rows x 10 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bVUx-51j2NEz",
    "outputId": "977a455f-19f4-4bb0-9415-4ebf9a65f5b1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x800 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 創建 2x5 的子圖網格\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "fig.suptitle(\"Normal Distributions of Demand Columns\")\n",
    "\n",
    "for idx, column in enumerate(demand_df.columns):\n",
    "    data = demand_df[column].dropna()  # 移除缺失值\n",
    "    mean, std_dev = np.mean(data), np.std(data)\n",
    "\n",
    "    # 產生 x 值範圍\n",
    "    x = np.linspace(mean - 3 * std_dev, mean + 3 * std_dev, 100)\n",
    "    pdf = norm.pdf(x, mean, std_dev)\n",
    "\n",
    "    # 確定當前的軸位置\n",
    "    ax = axes[idx // 5, idx % 5]\n",
    "    ax.hist(data, bins=15, density=True, alpha=0.6, color=\"skyblue\")\n",
    "    ax.plot(\n",
    "        x,\n",
    "        pdf,\n",
    "        \"r-\",\n",
    "        label=f\"Normal Distribution\\nMean={mean:.2f}, StdDev={std_dev:.2f}\",\n",
    "    )\n",
    "    ax.set_xlabel(column)\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.legend()\n",
    "\n",
    "# 移除空白子圖（若有）\n",
    "for idx in range(len(demand_df.columns), 10):\n",
    "    fig.delaxes(axes[idx // 5, idx % 5])\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79eqz9n_cweM"
   },
   "source": [
    "### Validate the covariance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LRxNQvrdcnxf",
    "outputId": "787e0b16-4a37-4522-d09f-0ea4383dfb1e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>demand_t1</th>\n",
       "      <td>11500.121499</td>\n",
       "      <td>11437.913773</td>\n",
       "      <td>11491.817461</td>\n",
       "      <td>11449.279979</td>\n",
       "      <td>11421.185949</td>\n",
       "      <td>11449.279979</td>\n",
       "      <td>11433.606145</td>\n",
       "      <td>11464.092453</td>\n",
       "      <td>11449.279975</td>\n",
       "      <td>11449.279978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t2</th>\n",
       "      <td>11437.913773</td>\n",
       "      <td>11384.045435</td>\n",
       "      <td>11434.337551</td>\n",
       "      <td>11395.461660</td>\n",
       "      <td>11371.288335</td>\n",
       "      <td>11395.461660</td>\n",
       "      <td>11380.612522</td>\n",
       "      <td>11413.068444</td>\n",
       "      <td>11395.461657</td>\n",
       "      <td>11395.461660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t3</th>\n",
       "      <td>11491.817461</td>\n",
       "      <td>11434.337551</td>\n",
       "      <td>11492.345369</td>\n",
       "      <td>11445.297344</td>\n",
       "      <td>11417.879197</td>\n",
       "      <td>11445.297344</td>\n",
       "      <td>11425.363324</td>\n",
       "      <td>11462.865280</td>\n",
       "      <td>11445.297340</td>\n",
       "      <td>11445.297344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t4</th>\n",
       "      <td>11449.279979</td>\n",
       "      <td>11395.461660</td>\n",
       "      <td>11445.297344</td>\n",
       "      <td>11407.517926</td>\n",
       "      <td>11383.949213</td>\n",
       "      <td>11407.517926</td>\n",
       "      <td>11393.252462</td>\n",
       "      <td>11424.882556</td>\n",
       "      <td>11407.517923</td>\n",
       "      <td>11407.517925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t5</th>\n",
       "      <td>11421.185949</td>\n",
       "      <td>11371.288335</td>\n",
       "      <td>11417.879197</td>\n",
       "      <td>11383.949213</td>\n",
       "      <td>11369.605301</td>\n",
       "      <td>11383.949213</td>\n",
       "      <td>11371.762863</td>\n",
       "      <td>11404.029308</td>\n",
       "      <td>11383.949211</td>\n",
       "      <td>11383.949213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t6</th>\n",
       "      <td>11449.279979</td>\n",
       "      <td>11395.461660</td>\n",
       "      <td>11445.297344</td>\n",
       "      <td>11407.517926</td>\n",
       "      <td>11383.949213</td>\n",
       "      <td>11407.517925</td>\n",
       "      <td>11393.252462</td>\n",
       "      <td>11424.882556</td>\n",
       "      <td>11407.517923</td>\n",
       "      <td>11407.517925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t7</th>\n",
       "      <td>11433.606145</td>\n",
       "      <td>11380.612522</td>\n",
       "      <td>11425.363324</td>\n",
       "      <td>11393.252462</td>\n",
       "      <td>11371.762863</td>\n",
       "      <td>11393.252462</td>\n",
       "      <td>11388.486336</td>\n",
       "      <td>11411.147017</td>\n",
       "      <td>11393.252460</td>\n",
       "      <td>11393.252462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t8</th>\n",
       "      <td>11464.092453</td>\n",
       "      <td>11413.068444</td>\n",
       "      <td>11462.865280</td>\n",
       "      <td>11424.882556</td>\n",
       "      <td>11404.029308</td>\n",
       "      <td>11424.882556</td>\n",
       "      <td>11411.147017</td>\n",
       "      <td>11449.352112</td>\n",
       "      <td>11424.882554</td>\n",
       "      <td>11424.882556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t9</th>\n",
       "      <td>11449.279975</td>\n",
       "      <td>11395.461657</td>\n",
       "      <td>11445.297340</td>\n",
       "      <td>11407.517923</td>\n",
       "      <td>11383.949211</td>\n",
       "      <td>11407.517923</td>\n",
       "      <td>11393.252460</td>\n",
       "      <td>11424.882554</td>\n",
       "      <td>11407.517920</td>\n",
       "      <td>11407.517922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t10</th>\n",
       "      <td>11449.279978</td>\n",
       "      <td>11395.461660</td>\n",
       "      <td>11445.297344</td>\n",
       "      <td>11407.517925</td>\n",
       "      <td>11383.949213</td>\n",
       "      <td>11407.517925</td>\n",
       "      <td>11393.252462</td>\n",
       "      <td>11424.882556</td>\n",
       "      <td>11407.517922</td>\n",
       "      <td>11407.517925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               demand_t1     demand_t2     demand_t3     demand_t4  \\\n",
       "demand_t1   11500.121499  11437.913773  11491.817461  11449.279979   \n",
       "demand_t2   11437.913773  11384.045435  11434.337551  11395.461660   \n",
       "demand_t3   11491.817461  11434.337551  11492.345369  11445.297344   \n",
       "demand_t4   11449.279979  11395.461660  11445.297344  11407.517926   \n",
       "demand_t5   11421.185949  11371.288335  11417.879197  11383.949213   \n",
       "demand_t6   11449.279979  11395.461660  11445.297344  11407.517926   \n",
       "demand_t7   11433.606145  11380.612522  11425.363324  11393.252462   \n",
       "demand_t8   11464.092453  11413.068444  11462.865280  11424.882556   \n",
       "demand_t9   11449.279975  11395.461657  11445.297340  11407.517923   \n",
       "demand_t10  11449.279978  11395.461660  11445.297344  11407.517925   \n",
       "\n",
       "               demand_t5     demand_t6     demand_t7     demand_t8  \\\n",
       "demand_t1   11421.185949  11449.279979  11433.606145  11464.092453   \n",
       "demand_t2   11371.288335  11395.461660  11380.612522  11413.068444   \n",
       "demand_t3   11417.879197  11445.297344  11425.363324  11462.865280   \n",
       "demand_t4   11383.949213  11407.517926  11393.252462  11424.882556   \n",
       "demand_t5   11369.605301  11383.949213  11371.762863  11404.029308   \n",
       "demand_t6   11383.949213  11407.517925  11393.252462  11424.882556   \n",
       "demand_t7   11371.762863  11393.252462  11388.486336  11411.147017   \n",
       "demand_t8   11404.029308  11424.882556  11411.147017  11449.352112   \n",
       "demand_t9   11383.949211  11407.517923  11393.252460  11424.882554   \n",
       "demand_t10  11383.949213  11407.517925  11393.252462  11424.882556   \n",
       "\n",
       "               demand_t9    demand_t10  \n",
       "demand_t1   11449.279975  11449.279978  \n",
       "demand_t2   11395.461657  11395.461660  \n",
       "demand_t3   11445.297340  11445.297344  \n",
       "demand_t4   11407.517923  11407.517925  \n",
       "demand_t5   11383.949211  11383.949213  \n",
       "demand_t6   11407.517923  11407.517925  \n",
       "demand_t7   11393.252460  11393.252462  \n",
       "demand_t8   11424.882554  11424.882556  \n",
       "demand_t9   11407.517920  11407.517922  \n",
       "demand_t10  11407.517922  11407.517925  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sfelD3W3dxO8",
    "outputId": "8bbaf932-fa69-4d5d-9a3d-91f3dd739124"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>demand_t1</th>\n",
       "      <td>11491.121499</td>\n",
       "      <td>11437.374121</td>\n",
       "      <td>11486.815409</td>\n",
       "      <td>11449.279979</td>\n",
       "      <td>11424.675912</td>\n",
       "      <td>11449.279979</td>\n",
       "      <td>11434.497800</td>\n",
       "      <td>11466.575946</td>\n",
       "      <td>11449.279977</td>\n",
       "      <td>11449.279978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t2</th>\n",
       "      <td>11437.374121</td>\n",
       "      <td>11383.492713</td>\n",
       "      <td>11433.353939</td>\n",
       "      <td>11395.461660</td>\n",
       "      <td>11372.101770</td>\n",
       "      <td>11395.461660</td>\n",
       "      <td>11381.171000</td>\n",
       "      <td>11412.958409</td>\n",
       "      <td>11395.461657</td>\n",
       "      <td>11395.461660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t3</th>\n",
       "      <td>11486.815409</td>\n",
       "      <td>11433.353939</td>\n",
       "      <td>11483.345369</td>\n",
       "      <td>11445.297344</td>\n",
       "      <td>11421.735622</td>\n",
       "      <td>11445.297344</td>\n",
       "      <td>11430.327213</td>\n",
       "      <td>11462.770217</td>\n",
       "      <td>11445.297342</td>\n",
       "      <td>11445.297344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t4</th>\n",
       "      <td>11449.279979</td>\n",
       "      <td>11395.461660</td>\n",
       "      <td>11445.297344</td>\n",
       "      <td>11407.517926</td>\n",
       "      <td>11383.949213</td>\n",
       "      <td>11407.517926</td>\n",
       "      <td>11393.252462</td>\n",
       "      <td>11424.882556</td>\n",
       "      <td>11407.517923</td>\n",
       "      <td>11407.517925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t5</th>\n",
       "      <td>11424.675912</td>\n",
       "      <td>11372.101770</td>\n",
       "      <td>11421.735622</td>\n",
       "      <td>11383.949213</td>\n",
       "      <td>11360.605301</td>\n",
       "      <td>11383.949213</td>\n",
       "      <td>11369.060070</td>\n",
       "      <td>11401.383131</td>\n",
       "      <td>11383.949211</td>\n",
       "      <td>11383.949213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t6</th>\n",
       "      <td>11449.279979</td>\n",
       "      <td>11395.461660</td>\n",
       "      <td>11445.297344</td>\n",
       "      <td>11407.517926</td>\n",
       "      <td>11383.949213</td>\n",
       "      <td>11407.517925</td>\n",
       "      <td>11393.252462</td>\n",
       "      <td>11424.882556</td>\n",
       "      <td>11407.517923</td>\n",
       "      <td>11407.517925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t7</th>\n",
       "      <td>11434.497800</td>\n",
       "      <td>11381.171000</td>\n",
       "      <td>11430.327213</td>\n",
       "      <td>11393.252462</td>\n",
       "      <td>11369.060070</td>\n",
       "      <td>11393.252462</td>\n",
       "      <td>11379.486336</td>\n",
       "      <td>11410.796545</td>\n",
       "      <td>11393.252460</td>\n",
       "      <td>11393.252462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t8</th>\n",
       "      <td>11466.575946</td>\n",
       "      <td>11412.958409</td>\n",
       "      <td>11462.770217</td>\n",
       "      <td>11424.882556</td>\n",
       "      <td>11401.383131</td>\n",
       "      <td>11424.882556</td>\n",
       "      <td>11410.796545</td>\n",
       "      <td>11440.352112</td>\n",
       "      <td>11424.882555</td>\n",
       "      <td>11424.882556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t9</th>\n",
       "      <td>11449.279977</td>\n",
       "      <td>11395.461657</td>\n",
       "      <td>11445.297342</td>\n",
       "      <td>11407.517923</td>\n",
       "      <td>11383.949211</td>\n",
       "      <td>11407.517923</td>\n",
       "      <td>11393.252460</td>\n",
       "      <td>11424.882555</td>\n",
       "      <td>11407.517920</td>\n",
       "      <td>11407.517922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t10</th>\n",
       "      <td>11449.279978</td>\n",
       "      <td>11395.461660</td>\n",
       "      <td>11445.297344</td>\n",
       "      <td>11407.517925</td>\n",
       "      <td>11383.949213</td>\n",
       "      <td>11407.517925</td>\n",
       "      <td>11393.252462</td>\n",
       "      <td>11424.882556</td>\n",
       "      <td>11407.517922</td>\n",
       "      <td>11407.517925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               demand_t1     demand_t2     demand_t3     demand_t4  \\\n",
       "demand_t1   11491.121499  11437.374121  11486.815409  11449.279979   \n",
       "demand_t2   11437.374121  11383.492713  11433.353939  11395.461660   \n",
       "demand_t3   11486.815409  11433.353939  11483.345369  11445.297344   \n",
       "demand_t4   11449.279979  11395.461660  11445.297344  11407.517926   \n",
       "demand_t5   11424.675912  11372.101770  11421.735622  11383.949213   \n",
       "demand_t6   11449.279979  11395.461660  11445.297344  11407.517926   \n",
       "demand_t7   11434.497800  11381.171000  11430.327213  11393.252462   \n",
       "demand_t8   11466.575946  11412.958409  11462.770217  11424.882556   \n",
       "demand_t9   11449.279977  11395.461657  11445.297342  11407.517923   \n",
       "demand_t10  11449.279978  11395.461660  11445.297344  11407.517925   \n",
       "\n",
       "               demand_t5     demand_t6     demand_t7     demand_t8  \\\n",
       "demand_t1   11424.675912  11449.279979  11434.497800  11466.575946   \n",
       "demand_t2   11372.101770  11395.461660  11381.171000  11412.958409   \n",
       "demand_t3   11421.735622  11445.297344  11430.327213  11462.770217   \n",
       "demand_t4   11383.949213  11407.517926  11393.252462  11424.882556   \n",
       "demand_t5   11360.605301  11383.949213  11369.060070  11401.383131   \n",
       "demand_t6   11383.949213  11407.517925  11393.252462  11424.882556   \n",
       "demand_t7   11369.060070  11393.252462  11379.486336  11410.796545   \n",
       "demand_t8   11401.383131  11424.882556  11410.796545  11440.352112   \n",
       "demand_t9   11383.949211  11407.517923  11393.252460  11424.882555   \n",
       "demand_t10  11383.949213  11407.517925  11393.252462  11424.882556   \n",
       "\n",
       "               demand_t9    demand_t10  \n",
       "demand_t1   11449.279977  11449.279978  \n",
       "demand_t2   11395.461657  11395.461660  \n",
       "demand_t3   11445.297342  11445.297344  \n",
       "demand_t4   11407.517923  11407.517925  \n",
       "demand_t5   11383.949211  11383.949213  \n",
       "demand_t6   11407.517923  11407.517925  \n",
       "demand_t7   11393.252460  11393.252462  \n",
       "demand_t8   11424.882555  11424.882556  \n",
       "demand_t9   11407.517920  11407.517922  \n",
       "demand_t10  11407.517922  11407.517925  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empirical_covariance = demand_df.cov()\n",
    "covariance_diff = np.abs(empirical_covariance - np.array(cov_matrices).mean(axis=0))\n",
    "covariance_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zoLCr9riPt8d"
   },
   "source": [
    "### Validate the corr matrix of damand_df is close to original setting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>251.794016</td>\n",
       "      <td>254.356464</td>\n",
       "      <td>247.741536</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>261.523870</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.087872</td>\n",
       "      <td>252.716034</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.356465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251.056784</td>\n",
       "      <td>251.010919</td>\n",
       "      <td>248.192143</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>250.249903</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>252.054546</td>\n",
       "      <td>246.842220</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>251.010920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>297.528249</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>294.250464</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>283.569719</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>285.767294</td>\n",
       "      <td>287.835884</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>291.630992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>289.066894</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.355508</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>285.816090</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>292.681865</td>\n",
       "      <td>290.851589</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.907838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298.072424</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>299.903104</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>296.615372</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>290.943971</td>\n",
       "      <td>295.944768</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>293.500607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>65.746933</td>\n",
       "      <td>65.853934</td>\n",
       "      <td>70.574162</td>\n",
       "      <td>62.239247</td>\n",
       "      <td>55.130102</td>\n",
       "      <td>62.239247</td>\n",
       "      <td>57.888206</td>\n",
       "      <td>63.679955</td>\n",
       "      <td>62.239243</td>\n",
       "      <td>62.239247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>61.329502</td>\n",
       "      <td>63.260741</td>\n",
       "      <td>60.017189</td>\n",
       "      <td>63.453517</td>\n",
       "      <td>66.141381</td>\n",
       "      <td>63.453517</td>\n",
       "      <td>65.584679</td>\n",
       "      <td>64.101433</td>\n",
       "      <td>63.453519</td>\n",
       "      <td>63.453517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>66.822772</td>\n",
       "      <td>69.549069</td>\n",
       "      <td>66.237491</td>\n",
       "      <td>69.280813</td>\n",
       "      <td>70.547457</td>\n",
       "      <td>69.280813</td>\n",
       "      <td>70.842404</td>\n",
       "      <td>73.111604</td>\n",
       "      <td>69.280814</td>\n",
       "      <td>69.280813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>62.577572</td>\n",
       "      <td>67.210049</td>\n",
       "      <td>65.172995</td>\n",
       "      <td>67.044144</td>\n",
       "      <td>70.357863</td>\n",
       "      <td>67.044144</td>\n",
       "      <td>68.535449</td>\n",
       "      <td>70.440907</td>\n",
       "      <td>67.044145</td>\n",
       "      <td>67.044144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>59.277409</td>\n",
       "      <td>59.472203</td>\n",
       "      <td>62.933669</td>\n",
       "      <td>60.318389</td>\n",
       "      <td>57.697020</td>\n",
       "      <td>60.318389</td>\n",
       "      <td>59.467526</td>\n",
       "      <td>57.168997</td>\n",
       "      <td>60.318390</td>\n",
       "      <td>60.318390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "0   251.794016  254.356464  247.741536  254.356465  261.523870  254.356465   \n",
       "1   251.056784  251.010919  248.192143  251.010920  250.249903  251.010920   \n",
       "2   297.528249  291.630992  294.250464  291.630992  283.569719  291.630992   \n",
       "3   289.066894  288.907838  288.355508  288.907838  285.816090  288.907838   \n",
       "4   298.072424  293.500607  299.903104  293.500607  296.615372  293.500607   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "85   65.746933   65.853934   70.574162   62.239247   55.130102   62.239247   \n",
       "86   61.329502   63.260741   60.017189   63.453517   66.141381   63.453517   \n",
       "87   66.822772   69.549069   66.237491   69.280813   70.547457   69.280813   \n",
       "88   62.577572   67.210049   65.172995   67.044144   70.357863   67.044144   \n",
       "89   59.277409   59.472203   62.933669   60.318389   57.697020   60.318389   \n",
       "\n",
       "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "0   254.087872  252.716034  254.356465  254.356465  \n",
       "1   252.054546  246.842220  251.010920  251.010920  \n",
       "2   285.767294  287.835884  291.630992  291.630992  \n",
       "3   292.681865  290.851589  288.907838  288.907838  \n",
       "4   290.943971  295.944768  293.500607  293.500607  \n",
       "..         ...         ...         ...         ...  \n",
       "85   57.888206   63.679955   62.239243   62.239247  \n",
       "86   65.584679   64.101433   63.453519   63.453517  \n",
       "87   70.842404   73.111604   69.280814   69.280813  \n",
       "88   68.535449   70.440907   67.044145   67.044144  \n",
       "89   59.467526   57.168997   60.318390   60.318390  \n",
       "\n",
       "[90 rows x 10 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YLqFAdfQPz6O",
    "outputId": "aaa6eb63-394c-40f8-8d58-665e9fb63026"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Matrix from demand_df:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>demand_t1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999648</td>\n",
       "      <td>0.999616</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.998820</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.999077</td>\n",
       "      <td>0.999075</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.999612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t2</th>\n",
       "      <td>0.999648</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999674</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999514</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999504</td>\n",
       "      <td>0.999686</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t3</th>\n",
       "      <td>0.999616</td>\n",
       "      <td>0.999674</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999602</td>\n",
       "      <td>0.998869</td>\n",
       "      <td>0.999602</td>\n",
       "      <td>0.998695</td>\n",
       "      <td>0.999306</td>\n",
       "      <td>0.999602</td>\n",
       "      <td>0.999602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t4</th>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999602</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999584</td>\n",
       "      <td>0.999691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t5</th>\n",
       "      <td>0.998820</td>\n",
       "      <td>0.999514</td>\n",
       "      <td>0.998869</td>\n",
       "      <td>0.999596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999596</td>\n",
       "      <td>0.999360</td>\n",
       "      <td>0.999528</td>\n",
       "      <td>0.999596</td>\n",
       "      <td>0.999596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t6</th>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999602</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999584</td>\n",
       "      <td>0.999691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t7</th>\n",
       "      <td>0.999077</td>\n",
       "      <td>0.999504</td>\n",
       "      <td>0.998695</td>\n",
       "      <td>0.999584</td>\n",
       "      <td>0.999360</td>\n",
       "      <td>0.999584</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999323</td>\n",
       "      <td>0.999584</td>\n",
       "      <td>0.999584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t8</th>\n",
       "      <td>0.999075</td>\n",
       "      <td>0.999686</td>\n",
       "      <td>0.999306</td>\n",
       "      <td>0.999691</td>\n",
       "      <td>0.999528</td>\n",
       "      <td>0.999691</td>\n",
       "      <td>0.999323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999691</td>\n",
       "      <td>0.999691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t9</th>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999602</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999584</td>\n",
       "      <td>0.999691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t10</th>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999602</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999584</td>\n",
       "      <td>0.999691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            demand_t1  demand_t2  demand_t3  demand_t4  demand_t5  demand_t6  \\\n",
       "demand_t1    1.000000   0.999648   0.999616   0.999612   0.998820   0.999612   \n",
       "demand_t2    0.999648   1.000000   0.999674   0.999972   0.999514   0.999972   \n",
       "demand_t3    0.999616   0.999674   1.000000   0.999602   0.998869   0.999602   \n",
       "demand_t4    0.999612   0.999972   0.999602   1.000000   0.999596   1.000000   \n",
       "demand_t5    0.998820   0.999514   0.998869   0.999596   1.000000   0.999596   \n",
       "demand_t6    0.999612   0.999972   0.999602   1.000000   0.999596   1.000000   \n",
       "demand_t7    0.999077   0.999504   0.998695   0.999584   0.999360   0.999584   \n",
       "demand_t8    0.999075   0.999686   0.999306   0.999691   0.999528   0.999691   \n",
       "demand_t9    0.999612   0.999972   0.999602   1.000000   0.999596   1.000000   \n",
       "demand_t10   0.999612   0.999972   0.999602   1.000000   0.999596   1.000000   \n",
       "\n",
       "            demand_t7  demand_t8  demand_t9  demand_t10  \n",
       "demand_t1    0.999077   0.999075   0.999612    0.999612  \n",
       "demand_t2    0.999504   0.999686   0.999972    0.999972  \n",
       "demand_t3    0.998695   0.999306   0.999602    0.999602  \n",
       "demand_t4    0.999584   0.999691   1.000000    1.000000  \n",
       "demand_t5    0.999360   0.999528   0.999596    0.999596  \n",
       "demand_t6    0.999584   0.999691   1.000000    1.000000  \n",
       "demand_t7    1.000000   0.999323   0.999584    0.999584  \n",
       "demand_t8    0.999323   1.000000   0.999691    0.999691  \n",
       "demand_t9    0.999584   0.999691   1.000000    1.000000  \n",
       "demand_t10   0.999584   0.999691   1.000000    1.000000  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_matrix = demand_df.corr()\n",
    "print(\"Correlation Matrix from demand_df:\")\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bsBxErYBQDXT",
    "outputId": "0b94e967-9e3d-4114-f049-cada8da8e427"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original corr_matrix shape: (10, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.354243</td>\n",
       "      <td>0.555784</td>\n",
       "      <td>0.587411</td>\n",
       "      <td>-0.387774</td>\n",
       "      <td>-0.161484</td>\n",
       "      <td>-0.099073</td>\n",
       "      <td>-0.275944</td>\n",
       "      <td>-0.488891</td>\n",
       "      <td>-0.020925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.354243</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.645671</td>\n",
       "      <td>0.344249</td>\n",
       "      <td>-0.533962</td>\n",
       "      <td>-0.118714</td>\n",
       "      <td>-0.366601</td>\n",
       "      <td>0.072230</td>\n",
       "      <td>0.109958</td>\n",
       "      <td>-0.049126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.555784</td>\n",
       "      <td>0.645671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.259728</td>\n",
       "      <td>-0.428492</td>\n",
       "      <td>-0.236520</td>\n",
       "      <td>-0.551543</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>-0.414246</td>\n",
       "      <td>-0.128709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.587411</td>\n",
       "      <td>0.344249</td>\n",
       "      <td>0.259728</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.433716</td>\n",
       "      <td>-0.078962</td>\n",
       "      <td>0.166233</td>\n",
       "      <td>-0.631022</td>\n",
       "      <td>0.089139</td>\n",
       "      <td>0.244177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.387774</td>\n",
       "      <td>-0.533962</td>\n",
       "      <td>-0.428492</td>\n",
       "      <td>-0.433716</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.371399</td>\n",
       "      <td>0.300310</td>\n",
       "      <td>0.294020</td>\n",
       "      <td>-0.153719</td>\n",
       "      <td>-0.108549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.161484</td>\n",
       "      <td>-0.118714</td>\n",
       "      <td>-0.236520</td>\n",
       "      <td>-0.078962</td>\n",
       "      <td>0.371399</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.658292</td>\n",
       "      <td>0.520508</td>\n",
       "      <td>-0.341738</td>\n",
       "      <td>0.147419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.099073</td>\n",
       "      <td>-0.366601</td>\n",
       "      <td>-0.551543</td>\n",
       "      <td>0.166233</td>\n",
       "      <td>0.300310</td>\n",
       "      <td>0.658292</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.038941</td>\n",
       "      <td>-0.009772</td>\n",
       "      <td>0.485870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.275944</td>\n",
       "      <td>0.072230</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>-0.631022</td>\n",
       "      <td>0.294020</td>\n",
       "      <td>0.520508</td>\n",
       "      <td>0.038941</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.203659</td>\n",
       "      <td>0.130487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.488891</td>\n",
       "      <td>0.109958</td>\n",
       "      <td>-0.414246</td>\n",
       "      <td>0.089139</td>\n",
       "      <td>-0.153719</td>\n",
       "      <td>-0.341738</td>\n",
       "      <td>-0.009772</td>\n",
       "      <td>-0.203659</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.355112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.020925</td>\n",
       "      <td>-0.049126</td>\n",
       "      <td>-0.128709</td>\n",
       "      <td>0.244177</td>\n",
       "      <td>-0.108549</td>\n",
       "      <td>0.147419</td>\n",
       "      <td>0.485870</td>\n",
       "      <td>0.130487</td>\n",
       "      <td>0.355112</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.000000  0.354243  0.555784  0.587411 -0.387774 -0.161484 -0.099073   \n",
       "1  0.354243  1.000000  0.645671  0.344249 -0.533962 -0.118714 -0.366601   \n",
       "2  0.555784  0.645671  1.000000  0.259728 -0.428492 -0.236520 -0.551543   \n",
       "3  0.587411  0.344249  0.259728  1.000000 -0.433716 -0.078962  0.166233   \n",
       "4 -0.387774 -0.533962 -0.428492 -0.433716  1.000000  0.371399  0.300310   \n",
       "5 -0.161484 -0.118714 -0.236520 -0.078962  0.371399  1.000000  0.658292   \n",
       "6 -0.099073 -0.366601 -0.551543  0.166233  0.300310  0.658292  1.000000   \n",
       "7 -0.275944  0.072230  0.010563 -0.631022  0.294020  0.520508  0.038941   \n",
       "8 -0.488891  0.109958 -0.414246  0.089139 -0.153719 -0.341738 -0.009772   \n",
       "9 -0.020925 -0.049126 -0.128709  0.244177 -0.108549  0.147419  0.485870   \n",
       "\n",
       "          7         8         9  \n",
       "0 -0.275944 -0.488891 -0.020925  \n",
       "1  0.072230  0.109958 -0.049126  \n",
       "2  0.010563 -0.414246 -0.128709  \n",
       "3 -0.631022  0.089139  0.244177  \n",
       "4  0.294020 -0.153719 -0.108549  \n",
       "5  0.520508 -0.341738  0.147419  \n",
       "6  0.038941 -0.009772  0.485870  \n",
       "7  1.000000 -0.203659  0.130487  \n",
       "8 -0.203659  1.000000  0.355112  \n",
       "9  0.130487  0.355112  1.000000  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Original corr_matrix shape: {corr_matrix.shape}\")\n",
    "corr_matrix_df = pd.DataFrame(corr_matrix)\n",
    "corr_matrix_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hne073eTB2gq"
   },
   "source": [
    "### Split test and train demand_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Train Data:\n",
      "(15, 10)\n",
      "Test Data:\n",
      "(15, 10)\n",
      "========================================\n",
      "Fold 2:\n",
      "Train Data:\n",
      "(15, 10)\n",
      "Test Data:\n",
      "(15, 10)\n",
      "========================================\n",
      "Fold 3:\n",
      "Train Data:\n",
      "(15, 10)\n",
      "Test Data:\n",
      "(15, 10)\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "def demand_data_split_data_k_fold(data):\n",
    "    folds = []\n",
    "    chunk_size = CHUNK_SIZE  # 每組 60 筆資料\n",
    "    train_chunk = int(train_size * chunk_size)\n",
    "\n",
    "    n = len(data)\n",
    "    # 依序切分每一個 chunk\n",
    "    for start in range(0, n, chunk_size):\n",
    "        # 若剩餘資料不足 60 筆，這裡直接跳過\n",
    "        if start + chunk_size > n:\n",
    "            break\n",
    "        chunk = data.iloc[start : start + chunk_size].reset_index(drop=True)\n",
    "        train_data = chunk.iloc[:train_chunk].reset_index(drop=True)\n",
    "        test_data = chunk.iloc[train_chunk:].reset_index(drop=True)\n",
    "        folds.append((train_data, test_data))\n",
    "\n",
    "    return folds\n",
    "\n",
    "\n",
    "# 使用函數切分資料\n",
    "demand_folds = demand_data_split_data_k_fold(demand_df)\n",
    "\n",
    "# 印出結果，每個 fold 的訓練與測試資料\n",
    "for i, (train_data, test_data) in enumerate(demand_folds, 1):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(\"Train Data:\")\n",
    "    print(train_data.shape)\n",
    "    print(\"Test Data:\")\n",
    "    print(test_data.shape)\n",
    "    print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJ2ej5ZlAg1e"
   },
   "source": [
    "### Define the Q star(Q optimal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "JZM_eOn8ldpT"
   },
   "outputs": [],
   "source": [
    "def calculate_Q_star(demand_df, service_level=0.95):\n",
    "\n",
    "    # 計算每一行的總和\n",
    "    demand_sum = demand_df.sum(axis=1)\n",
    "\n",
    "    # 計算總和的均值和標準差\n",
    "    mean_sum = demand_sum.mean()\n",
    "    std_sum = demand_sum.std()\n",
    "\n",
    "    # 計算總和的95%百分位數值\n",
    "    Q_star = norm.ppf(service_level, loc=mean_sum, scale=std_sum)\n",
    "\n",
    "    # 打印結果\n",
    "    print(f\"mean of sum: {mean_sum}\")\n",
    "    print(f\"std of sum: {std_sum}\")\n",
    "    print(f\"{service_level*100} percentile of sum: {Q_star}\")\n",
    "\n",
    "    return Q_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "  0   251.794016  254.356464  247.741536  254.356465  261.523870  254.356465   \n",
       "  1   251.056784  251.010919  248.192143  251.010920  250.249903  251.010920   \n",
       "  2   297.528249  291.630992  294.250464  291.630992  283.569719  291.630992   \n",
       "  3   289.066894  288.907838  288.355508  288.907838  285.816090  288.907838   \n",
       "  4   298.072424  293.500607  299.903104  293.500607  296.615372  293.500607   \n",
       "  5   301.401948  298.930917  300.714683  298.930917  294.785980  298.930917   \n",
       "  6   291.672619  289.957928  291.788015  289.957928  285.872455  289.957928   \n",
       "  7   269.341662  273.073968  269.572013  273.073968  271.669642  273.073968   \n",
       "  8   291.803572  289.026459  288.668454  289.026459  282.672846  289.026459   \n",
       "  9   258.259455  255.913721  255.439341  255.913721  255.976937  255.913721   \n",
       "  10  278.551022  281.996051  281.029925  281.996051  289.535263  281.996051   \n",
       "  11  256.151738  257.167663  252.945792  257.167664  264.788247  257.167664   \n",
       "  12  295.186828  297.233446  298.436136  297.233446  301.105487  297.233446   \n",
       "  13  278.898077  276.092416  278.517826  276.092416  274.536813  276.092416   \n",
       "  14  276.126061  270.733097  271.699824  270.733097  268.070512  270.733097   \n",
       "  \n",
       "       demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "  0   254.087872  252.716034  254.356465  254.356465  \n",
       "  1   252.054546  246.842220  251.010920  251.010920  \n",
       "  2   285.767294  287.835884  291.630992  291.630992  \n",
       "  3   292.681865  290.851589  288.907838  288.907838  \n",
       "  4   290.943971  295.944768  293.500607  293.500607  \n",
       "  5   299.484772  298.727945  298.930917  298.930917  \n",
       "  6   290.444897  292.664979  289.957928  289.957928  \n",
       "  7   273.459253  273.376911  273.073968  273.073968  \n",
       "  8   287.717318  286.983188  289.026459  289.026459  \n",
       "  9   255.911150  251.612160  255.913721  255.913721  \n",
       "  10  285.332026  287.403702  281.996051  281.996051  \n",
       "  11  262.220107  256.201799  257.167664  257.167664  \n",
       "  12  295.272601  298.475322  297.233446  297.233446  \n",
       "  13  276.925605  274.583612  276.092416  276.092416  \n",
       "  14  266.551512  268.201901  270.733097  270.733097  ,\n",
       "      demand_t1  demand_t2  demand_t3  demand_t4  demand_t5  demand_t6  \\\n",
       "  0   69.049446  66.984864  65.276090  66.706379  64.399509  66.706379   \n",
       "  1   62.472855  61.379065  62.263812  62.103826  59.547465  62.103826   \n",
       "  2   57.026718  60.339037  58.994137  61.289263  61.559450  61.289263   \n",
       "  3   62.944633  65.536993  64.153686  63.154284  59.520451  63.154284   \n",
       "  4   66.458142  64.430325  65.691033  63.637108  58.415305  63.637108   \n",
       "  5   65.340264  66.665934  65.624076  65.701968  65.763430  65.701968   \n",
       "  6   60.459442  64.184997  61.973620  64.386015  65.111260  64.386015   \n",
       "  7   71.557122  70.563024  74.662817  69.883738  69.277905  69.883738   \n",
       "  8   63.840751  62.306341  66.968545  61.020448  59.275984  61.020448   \n",
       "  9   62.969099  64.263725  64.029270  62.088768  60.721711  62.088768   \n",
       "  10  60.057707  60.871552  60.104051  61.613095  62.302393  61.613095   \n",
       "  11  68.193840  67.527301  72.362407  66.531083  64.621767  66.531083   \n",
       "  12  55.740736  63.143807  63.924512  62.532916  65.056794  62.532916   \n",
       "  13  67.989985  63.983761  64.570792  64.663108  66.958315  64.663108   \n",
       "  14  58.797450  62.278203  63.120200  62.444256  58.121198  62.444256   \n",
       "  \n",
       "      demand_t7  demand_t8  demand_t9  demand_t10  \n",
       "  0   71.005184  64.088969  66.706381   66.706379  \n",
       "  1   63.271804  55.331312  62.103825   62.103826  \n",
       "  2   63.232738  60.581985  61.289264   61.289263  \n",
       "  3   62.573906  68.894022  63.154284   63.154283  \n",
       "  4   62.211406  62.929656  63.637111   63.637108  \n",
       "  5   62.072328  64.226544  65.701970   65.701968  \n",
       "  6   66.214844  63.597722  64.386018   64.386015  \n",
       "  7   68.924536  69.361419  69.883738   69.883738  \n",
       "  8   59.005480  60.829499  61.020442   61.020448  \n",
       "  9   60.879685  62.634618  62.088772   62.088768  \n",
       "  10  61.283812  63.885645  61.613092   61.613095  \n",
       "  11  65.714526  66.642278  66.531082   66.531083  \n",
       "  12  56.151613  66.725960  62.532920   62.532916  \n",
       "  13  65.885875  61.730881  64.663100   64.663108  \n",
       "  14  57.806186  61.151295  62.444260   62.444256  ),\n",
       " (     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "  0   256.519623  251.959390  252.619473  251.959390  246.815799  251.959390   \n",
       "  1   266.557046  264.140348  264.160430  264.140348  262.456134  264.140348   \n",
       "  2   255.104623  256.009829  259.397400  256.009828  253.201453  256.009828   \n",
       "  3   258.328805  264.807010  266.027383  264.807010  264.784493  264.807010   \n",
       "  4   253.416118  255.936386  254.214539  255.936386  256.695107  255.936386   \n",
       "  5   263.215996  265.899159  268.949097  265.899159  263.130433  265.899159   \n",
       "  6   267.820993  270.713150  268.501904  270.713150  272.402984  270.713150   \n",
       "  7   250.255196  253.207375  252.917631  253.207375  253.511599  253.207375   \n",
       "  8   291.872275  284.623606  289.498687  284.623606  279.906507  284.623606   \n",
       "  9   276.428735  278.330073  277.122965  278.330073  276.905217  278.330073   \n",
       "  10  261.244738  263.269475  267.407733  263.269475  263.036084  263.269475   \n",
       "  11  281.624515  276.162403  277.291903  276.162403  272.064668  276.162403   \n",
       "  12  256.640801  254.697025  253.216210  254.697026  257.734949  254.697026   \n",
       "  13  276.596581  278.797325  282.033169  278.797325  278.763871  278.797325   \n",
       "  14  297.215013  296.464810  297.943972  296.464810  296.618148  296.464810   \n",
       "  \n",
       "       demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "  0   252.404141  247.642667  251.959390  251.959390  \n",
       "  1   268.037060  263.302797  264.140348  264.140348  \n",
       "  2   254.294350  257.262525  256.009828  256.009828  \n",
       "  3   265.545294  267.617149  264.807010  264.807010  \n",
       "  4   259.314176  259.850532  255.936386  255.936386  \n",
       "  5   261.011138  267.280099  265.899159  265.899159  \n",
       "  6   270.361907  270.006558  270.713150  270.713150  \n",
       "  7   251.010061  255.083055  253.207375  253.207375  \n",
       "  8   286.218363  285.561041  284.623606  284.623606  \n",
       "  9   280.820443  281.184906  278.330073  278.330073  \n",
       "  10  260.086461  263.477115  263.269475  263.269475  \n",
       "  11  274.337136  273.932259  276.162403  276.162403  \n",
       "  12  260.510507  256.621323  254.697026  254.697026  \n",
       "  13  274.790903  280.071033  278.797325  278.797325  \n",
       "  14  293.376616  299.036274  296.464810  296.464810  ,\n",
       "      demand_t1  demand_t2  demand_t3  demand_t4  demand_t5  demand_t6  \\\n",
       "  0   68.370121  64.894454  67.199076  65.761573  63.053747  65.761573   \n",
       "  1   66.587610  64.979976  69.411094  65.920419  65.768066  65.920419   \n",
       "  2   70.933664  66.187890  69.618863  65.722519  60.188051  65.722519   \n",
       "  3   63.476652  63.427189  58.172863  62.230816  63.207280  62.230816   \n",
       "  4   72.298368  69.469709  69.557802  69.527490  69.049027  69.527490   \n",
       "  5   61.418697  64.596306  63.090749  64.471254  64.412447  64.471254   \n",
       "  6   68.349991  68.233833  65.527941  68.464087  66.683151  68.464087   \n",
       "  7   69.173899  67.791676  68.980601  66.994793  66.269833  66.994793   \n",
       "  8   65.242553  65.421038  68.671875  62.974370  57.570268  62.974370   \n",
       "  9   67.587048  68.232925  69.938504  68.137978  72.345359  68.137978   \n",
       "  10  61.458167  62.971443  63.673554  63.965057  63.243366  63.965057   \n",
       "  11  62.593521  68.252412  63.791590  68.811032  69.928345  68.811032   \n",
       "  12  64.041609  65.899146  66.197404  65.812729  69.316660  65.812729   \n",
       "  13  74.367057  70.734412  75.902168  68.817354  67.054075  68.817354   \n",
       "  14  66.151275  66.585163  64.513272  66.925316  65.898617  66.925316   \n",
       "  \n",
       "      demand_t7  demand_t8  demand_t9  demand_t10  \n",
       "  0   63.984974  62.127812  65.761570   65.761573  \n",
       "  1   64.382597  68.059276  65.920415   65.920419  \n",
       "  2   61.025759  66.547948  65.722519   65.722519  \n",
       "  3   66.306121  62.062609  62.230823   62.230816  \n",
       "  4   62.861684  67.820569  69.527490   69.527490  \n",
       "  5   63.799314  63.693119  64.471254   64.471254  \n",
       "  6   76.051808  69.090667  68.464087   68.464087  \n",
       "  7   68.198098  71.791799  66.994793   66.994793  \n",
       "  8   58.224097  57.855352  62.974371   62.974369  \n",
       "  9   66.220593  70.069887  68.137978   68.137978  \n",
       "  10  63.568947  62.804834  63.965054   63.965057  \n",
       "  11  73.798658  71.999444  68.811034   68.811032  \n",
       "  12  62.910571  70.182959  65.812727   65.812729  \n",
       "  13  65.788339  68.993258  68.817352   68.817354  \n",
       "  14  69.469320  67.743843  66.925316   66.925316  ),\n",
       " (     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "  0   283.936601  279.543638  285.077369  279.543638  276.931626  279.543638   \n",
       "  1   280.752154  278.716263  284.554707  278.716262  277.019908  278.716262   \n",
       "  2   280.810270  282.660041  281.793406  282.660041  283.966752  282.660041   \n",
       "  3   282.690695  282.605164  284.501807  282.605163  280.263205  282.605164   \n",
       "  4   269.794746  271.570922  270.571046  271.570922  268.258034  271.570922   \n",
       "  5   292.141287  294.827330  296.363870  294.827330  297.636415  294.827330   \n",
       "  6   268.295270  268.378094  272.289189  268.378094  267.061530  268.378094   \n",
       "  7   274.284449  271.793246  275.891790  271.793246  271.007436  271.793246   \n",
       "  8   295.561676  294.596168  295.346168  294.596168  293.901419  294.596168   \n",
       "  9   291.572767  290.309699  289.337801  290.309699  287.979840  290.309699   \n",
       "  10  289.359045  285.194429  290.753028  285.194429  285.165963  285.194429   \n",
       "  11  259.085891  255.011345  255.041535  255.011344  252.753361  255.011344   \n",
       "  12  294.703610  295.974131  298.873793  295.974131  294.749160  295.974131   \n",
       "  13  288.208942  285.712065  285.303854  285.712065  283.167061  285.712065   \n",
       "  14  297.971527  299.942350  303.764967  299.942350  296.928688  299.942350   \n",
       "  \n",
       "       demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "  0   279.497137  277.402834  279.543638  279.543638  \n",
       "  1   272.022711  278.462176  278.716262  278.716262  \n",
       "  2   284.073037  284.669504  282.660041  282.660041  \n",
       "  3   280.973891  281.791857  282.605164  282.605164  \n",
       "  4   273.396903  267.461509  271.570922  271.570922  \n",
       "  5   290.725323  299.869873  294.827330  294.827330  \n",
       "  6   264.194145  269.637850  268.378094  268.378094  \n",
       "  7   271.264363  278.902212  271.793246  271.793246  \n",
       "  8   293.952546  289.434761  294.596168  294.596168  \n",
       "  9   296.220290  291.572601  290.309699  290.309699  \n",
       "  10  280.959832  286.639870  285.194429  285.194429  \n",
       "  11  255.233465  254.206041  255.011344  255.011344  \n",
       "  12  295.417869  296.365897  295.974131  295.974131  \n",
       "  13  283.449034  289.498190  285.712065  285.712065  \n",
       "  14  293.866069  299.198634  299.942350  299.942350  ,\n",
       "      demand_t1  demand_t2  demand_t3  demand_t4  demand_t5  demand_t6  \\\n",
       "  0   65.625929  67.884966  68.750730  68.558033  74.175914  68.558033   \n",
       "  1   60.770111  61.058111  59.574148  60.117141  58.717761  60.117141   \n",
       "  2   66.073532  64.930685  65.683239  63.599781  63.459309  63.599781   \n",
       "  3   63.121389  66.381203  61.668540  67.299906  67.404706  67.299906   \n",
       "  4   64.915095  62.604395  65.471782  61.716297  63.127936  61.716297   \n",
       "  5   63.427651  63.458016  59.857699  65.210366  66.962546  65.210366   \n",
       "  6   60.438469  59.245399  60.450320  60.543380  56.855468  60.543380   \n",
       "  7   62.564427  62.207089  62.998637  61.999965  61.345170  61.999965   \n",
       "  8   60.300860  59.014437  58.383848  60.185218  60.029247  60.185218   \n",
       "  9   66.947411  67.567002  67.449213  67.936977  72.133012  67.936977   \n",
       "  10  65.746933  65.853934  70.574162  62.239247  55.130102  62.239247   \n",
       "  11  61.329502  63.260741  60.017189  63.453517  66.141381  63.453517   \n",
       "  12  66.822772  69.549069  66.237491  69.280813  70.547457  69.280813   \n",
       "  13  62.577572  67.210049  65.172995  67.044144  70.357863  67.044144   \n",
       "  14  59.277409  59.472203  62.933669  60.318389  57.697020  60.318389   \n",
       "  \n",
       "      demand_t7  demand_t8  demand_t9  demand_t10  \n",
       "  0   65.559446  71.308420  68.558033   68.558033  \n",
       "  1   57.979551  58.390955  60.117144   60.117141  \n",
       "  2   64.215938  63.806809  63.599781   63.599781  \n",
       "  3   70.525694  68.097560  67.299908   67.299906  \n",
       "  4   61.250627  60.709187  61.716291   61.716297  \n",
       "  5   68.788190  65.421392  65.210367   65.210366  \n",
       "  6   59.175878  58.100125  60.543382   60.543380  \n",
       "  7   64.147963  63.211996  61.999964   61.999965  \n",
       "  8   62.275329  58.171283  60.185214   60.185218  \n",
       "  9   64.609175  66.191955  67.936978   67.936977  \n",
       "  10  57.888206  63.679955  62.239243   62.239247  \n",
       "  11  65.584679  64.101433  63.453519   63.453517  \n",
       "  12  70.842404  73.111604  69.280814   69.280813  \n",
       "  13  68.535449  70.440907  67.044145   67.044144  \n",
       "  14  59.467526  57.168997  60.318390   60.318390  )]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AxUzUg3JmmDz",
    "outputId": "90d6c954-d522-46e7-bccd-09ce837a852f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of sum: 2779.8596331748327\n",
      "std of sum: 169.30737789635148\n",
      "95.0 percentile of sum: 3058.3454877772897\n",
      "Q_star: 3058.3454877772897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# demand_df_train_1 = demand_folds[0][0]\n",
    "# Q_star = calculate_Q_star(demand_df_train_1, service_level=0.95)\n",
    "# print(f\"Q_star: {Q_star}\\n\")\n",
    "\n",
    "# demand_df_train_2 = demand_folds[1][0]\n",
    "# Q_star = calculate_Q_star(demand_df_train_2, service_level=0.95)\n",
    "# print(f\"Q_star: {Q_star}\\n\")\n",
    "\n",
    "demand_df_train_1 = demand_folds[0][0]\n",
    "Q_star = calculate_Q_star(demand_df_train_1, service_level=0.95)\n",
    "print(f\"Q_star: {Q_star}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pl8jIyaJmbAj"
   },
   "source": [
    "## Data3: Qk hat df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFQx0fsxhSfc"
   },
   "source": [
    "### Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "kY0mTXa7hdfH"
   },
   "outputs": [],
   "source": [
    "# 計算條件分佈的函數\n",
    "def calculate_conditional_distribution(mu, covariance_matrix, x_observed, k):\n",
    "    mu_1 = mu[:k]\n",
    "    mu_2 = mu[k:]\n",
    "    Sigma_11 = covariance_matrix[:k, :k]\n",
    "    Sigma_22 = covariance_matrix[k:, k:]\n",
    "    Sigma_12 = covariance_matrix[k:, :k]\n",
    "    Sigma_21 = covariance_matrix[:k, k:]\n",
    "\n",
    "    # Compute conditional mean and covariance\n",
    "    Sigma_11_inv = np.linalg.pinv(Sigma_11)\n",
    "    mu_cond = mu_2 + np.dot(Sigma_12, np.dot(Sigma_11_inv, (x_observed - mu_1)))\n",
    "    sigma_cond = Sigma_22 - np.dot(Sigma_12, np.dot(Sigma_11_inv, Sigma_21))\n",
    "\n",
    "    return mu_cond, sigma_cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "uSbq87Meihmj"
   },
   "outputs": [],
   "source": [
    "def cal_Var_Y(sigma_cond):\n",
    "\n",
    "    # Extract the variances (diagonal elements)\n",
    "    variances = np.diag(sigma_cond)\n",
    "\n",
    "    # Calculate the sum of covariances (off-diagonal elements)\n",
    "    covariances_sum = np.sum(sigma_cond) - np.sum(variances)\n",
    "\n",
    "    # Total variance for the sum of mu_cond\n",
    "    total_variance = np.sum(variances) + covariances_sum\n",
    "\n",
    "    return total_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FySGAFQrrKX0"
   },
   "outputs": [],
   "source": [
    "def cal_Qk_hat(mu_cond, sigma_cond, service_level, x_observed):\n",
    "    # predict_quantity = mu_cond + norm.ppf(service_level) * np.sqrt(np.diag(sigma_cond))\n",
    "    # Qk_hat = x_observed.sum() + predict_quantity.sum()\n",
    "\n",
    "    mean_Y = np.sum(mu_cond)\n",
    "    var_Y = cal_Var_Y(sigma_cond)\n",
    "\n",
    "    sd_Y = np.sqrt(var_Y)\n",
    "    if sd_Y < 0 or np.isnan(sd_Y):  # scale must be positive\n",
    "        sd_Y = 1e-6\n",
    "\n",
    "    percentile_95_Y = norm.ppf(service_level, loc=mean_Y, scale=sd_Y)\n",
    "\n",
    "    # print(f\"        mean_Y: {mean_Y}\")\n",
    "    # print(f\"        sd_Y: {sd_Y}\")\n",
    "    # print(f\"    percentile_95_Y: {percentile_95_Y}\")\n",
    "\n",
    "    Qk_hat = x_observed.sum() + percentile_95_Y\n",
    "    \n",
    "    return Qk_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "rZp0UnPjm0Zb"
   },
   "outputs": [],
   "source": [
    "def cal_mu_and_cov_matrix(demand_df_train):\n",
    "\n",
    "    mu_matrix = demand_df_train.mean().values\n",
    "    covariance_matrix = demand_df_train.cov().values\n",
    "\n",
    "    # print(f\"mu_matrix: {mu_matrix}\")\n",
    "    # print(f\"covariance_matrix: \\n{covariance_matrix}\\n\")\n",
    "\n",
    "    return mu_matrix, covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "aaJEWprdphY9"
   },
   "outputs": [],
   "source": [
    "def make_Qk_hat_df(demand_df, T, service_level, mu_matrix, covariance_matrix):\n",
    "    results_df = pd.DataFrame(index=demand_df.index)\n",
    "\n",
    "    for index, row_data in demand_df.iterrows():\n",
    "        for k in range(2, T):\n",
    "            # print(f\"Now processing index: {index}, t={k}\")\n",
    "\n",
    "            x_observed = row_data[\n",
    "                : k - 1\n",
    "            ].values  # 取出前 k 個觀測值 -> Qk_hat_2(t=2): 則 observerd: T=1\n",
    "\n",
    "            mu_cond, sigma_cond = calculate_conditional_distribution(\n",
    "                mu_matrix, covariance_matrix, x_observed, len(x_observed)\n",
    "            )\n",
    "\n",
    "            Qk_hat = cal_Qk_hat(mu_cond, sigma_cond, service_level, x_observed)\n",
    "\n",
    "            results_df.loc[index, f\"Qk_hat_k{k}\"] = Qk_hat\n",
    "\n",
    "            # print(f\"    x_observed: {x_observed}\")\n",
    "            # print(f\"    mu_cond: {mu_cond}\")\n",
    "            # print(f\"    sigma_cond: \\n{sigma_cond}\")\n",
    "            # print(f\"    Qk_hat: {Qk_hat}\")\n",
    "            # print(\"\\n\")\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKbvvh-lkIlB"
   },
   "source": [
    "公式連結：https://jujueffectivelife.notion.site/Qk-eab4d89ec36345efbf3a0d4a4f488474?pvs=4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ixG_NmrKPrC"
   },
   "source": [
    "### Validate the consistency of condMVN in Python and R\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJwMUzx5hoWN"
   },
   "source": [
    "#### Given mu and sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eI8aDJT_FHnD",
    "outputId": "fa4f1da8-e77d-4e55-fa91-384b463f751c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigma_11: \n",
      "[[5 1]\n",
      " [1 8]]\n",
      "\n",
      "Sigma_22: \n",
      "[[10  1]\n",
      " [ 1  7]]\n",
      "\n",
      "Sigma_12: \n",
      "[[0 1]\n",
      " [2 0]]\n",
      "\n",
      "Sigma_21: \n",
      "[[0 2]\n",
      " [1 0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "# Define the mean vector and the covariance matrix\n",
    "mu = np.array([10, 20, 30, 40])\n",
    "covariance_matrix = np.array([[5, 1, 0, 2], [1, 8, 1, 0], [0, 1, 10, 1], [2, 0, 1, 7]])\n",
    "\n",
    "# Mean and covariance partitioning\n",
    "mu_1 = mu[:2]\n",
    "mu_2 = mu[2:]\n",
    "Sigma_11 = covariance_matrix[:2, :2]\n",
    "Sigma_22 = covariance_matrix[2:, 2:]\n",
    "Sigma_12 = covariance_matrix[2:, :2]\n",
    "Sigma_21 = covariance_matrix[:2, 2:]\n",
    "\n",
    "print(f\"Sigma_11: \\n{Sigma_11}\\n\")\n",
    "print(f\"Sigma_22: \\n{Sigma_22}\\n\")\n",
    "print(f\"Sigma_12: \\n{Sigma_12}\\n\")\n",
    "print(f\"Sigma_21: \\n{Sigma_21}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H7bmBDjVhH9J",
    "outputId": "8825f168-b07c-46c2-f8fb-e20f26e8b4be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu_cond: [31.38461538 37.84615385]\n",
      "sigma_cond: \n",
      "[[9.87179487 1.05128205]\n",
      " [1.05128205 6.17948718]]\n"
     ]
    }
   ],
   "source": [
    "# Observed values of X1 and X2\n",
    "x_observed = np.array([6, 30])\n",
    "\n",
    "mu_cond, sigma_cond = calculate_conditional_distribution(\n",
    "    mu, covariance_matrix, x_observed, len(x_observed)\n",
    ")\n",
    "print(f\"mu_cond: {mu_cond}\")\n",
    "print(f\"sigma_cond: \\n{sigma_cond}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K3-lRrG4q4lq",
    "outputId": "6b7a3ed8-4681-46fc-db04-d1e90ca512d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional density at X3 = 30, X4 = 40: 0.012061749355189695\n",
      "Conditional cumulative probability up to X3 = 30, X4 = 40: 0.2790601403798458\n",
      "Qk_hat of x_observed: 112.23905144741786\n"
     ]
    }
   ],
   "source": [
    "# Define the conditional distribution\n",
    "conditional_dist = multivariate_normal(mean=mu_cond, cov=sigma_cond)\n",
    "\n",
    "# Values at which to evaluate the PDF and CDF\n",
    "x3, x4 = 30, 40  # These can be any values of interest\n",
    "\n",
    "# Calculate the PDF\n",
    "pdf_value = conditional_dist.pdf([x3, x4])\n",
    "print(f\"Conditional density at X3 = {x3}, X4 = {x4}: {pdf_value}\")\n",
    "\n",
    "# Calculate the CDF\n",
    "cdf_value = conditional_dist.cdf([x3, x4])\n",
    "print(f\"Conditional cumulative probability up to X3 = {x3}, X4 = {x4}: {cdf_value}\")\n",
    "\n",
    "# Qk hat\n",
    "Qk_hat = cal_Qk_hat(mu_cond, sigma_cond, service_level, x_observed)\n",
    "print(f\"Qk_hat of x_observed: {Qk_hat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75v9w7MUqe4f"
   },
   "source": [
    "```\n",
    "R 中運行的結果\n",
    "```\n",
    "\n",
    "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAXYAAADcCAYAAABkropZAAAMQGlDQ1BJQ0MgUHJvZmlsZQAASImVVwdYU8kWnluSkEBoAQSkhN4EESkBpITQQu9NVEISIJQYA0HFji4quHaxgA1dFVGw0iwoYmdR7H2xoKCsiwW78iYFdN1XvjffN3f++8+Z/5w5d+beOwConeCIRLmoOgB5wgJxTJAfPSk5hU7qAQRABMrABBA43HwRMyoqDMAy1P69vLsBEGl71V6q9c/+/1o0ePx8LgBIFMTpvHxuHsSHAMAruSJxAQBEKW82tUAkxbACLTEMEOJFUpwpx5VSnC7H+2Q2cTEsiNsAUFLhcMSZAKhehjy9kJsJNVT7IXYU8gRCANToEHvn5U3mQZwGsTW0EUEs1Wek/6CT+TfN9GFNDidzGMvnIitK/oJ8US5n+v+Zjv9d8nIlQz4sYVXJEgfHSOcM83YrZ3KoFKtA3CdMj4iEWBPiDwKezB5ilJIlCY6X26MG3HwWzBnQgdiRx/EPhdgA4kBhbkSYgk/PEASyIYYrBJ0mKGDHQawL8SJ+fkCswmaLeHKMwhdanyFmMRX8OY5Y5lfq64EkJ56p0H+dxWcr9DHVoqy4RIgpEJsXChIiIFaF2CE/JzZUYTOuKIsVMWQjlsRI4zeHOIYvDPKT62OFGeLAGIV9aV7+0HyxLVkCdoQCHyjIiguW5wdr43Jk8cO5YJf5Qmb8kA4/PylsaC48vn+AfO5YD18YH6vQ+SAq8IuRj8UpotwohT1uys8NkvKmEDvnF8YqxuIJBXBByvXxDFFBVJw8TrwomxMSJY8HXw7CAAv4AzqQwJoOJoNsIOjoa+iDd/KeQMABYpAJ+MBewQyNSJT1COE1FhSBPyHig/zhcX6yXj4ohPzXYVZ+tQcZst5C2Ygc8BTiPBAKcuG9RDZKOOwtATyBjOAf3jmwcmG8ubBK+/89P8R+Z5iQCVMwkiGPdLUhS2IA0Z8YTAwk2uD6uDfuiYfBqy+sTjgDdx+ax3d7wlNCJ+ER4Tqhi3B7kqBY/FOU4aAL6gcqcpH+Yy5wS6jpgvvhXlAdKuM6uD6wx52hHybuAz27QJaliFuaFfpP2n+bwQ9PQ2FHdiSj5BFkX7L1zyNVbVVdhlWkuf4xP/JY04fzzRru+dk/64fs82Ab+rMltgg7iJ3FTmLnsaNYA6BjLVgj1o4dk+Lh1fVEtrqGvMXI4smBOoJ/+Bt6stJM5jvWOPY6fpH3FfCnSd/RgDVZNF0syMwqoDPhF4FPZwu5DqPoTo5OzgBIvy/y19ebaNl3A9Fp/87N/wMAr5bBwcEj37mQFgD2u8Ht3/Sds2bAT4cyAOeauBJxoZzDpRcCfEuowZ2mB4yAGbCG83ECrsAT+IIAEAIiQRxIBhNh9FlwnYvBVDATzAMloAwsB2vABrAZbAO7wF5wADSAo+AkOAMugsvgOrgLV083eAH6wTvwGUEQEkJFaIgeYoxYIHaIE8JAvJEAJAyJQZKRNCQTESISZCYyHylDViIbkK1INbIfaUJOIueRTuQ28hDpRV4jn1AMVUG1UEPUEh2NMlAmGorGoRPQTHQKWoQuQJei69AqdA9aj55EL6LX0S70BTqAAUwZ08FMMHuMgbGwSCwFy8DE2GysFCvHqrBarBk+56tYF9aHfcSJOA2n4/ZwBQfj8TgXn4LPxpfgG/BdeD3ehl/FH+L9+DcClWBAsCN4ENiEJEImYSqhhFBO2EE4TDgN91I34R2RSNQhWhHd4F5MJmYTZxCXEDcS64gniJ3Ex8QBEomkR7IjeZEiSRxSAamEtJ60h9RCukLqJn1QUlYyVnJSClRKURIqFSuVK+1WOq50RemZ0meyOtmC7EGOJPPI08nLyNvJzeRL5G7yZ4oGxYriRYmjZFPmUdZRaimnKfcob5SVlU2V3ZWjlQXKc5XXKe9TPqf8UPmjiqaKrQpLJVVForJUZafKCZXbKm+oVKol1ZeaQi2gLqVWU09RH1A/qNJUHVTZqjzVOaoVqvWqV1RfqpHVLNSYahPVitTK1Q6qXVLrUyerW6qz1Dnqs9Ur1JvUb6oPaNA0xmhEauRpLNHYrXFeo0eTpGmpGaDJ01yguU3zlOZjGkYzo7FoXNp82nbaaVq3FlHLSoutla1VprVXq0OrX1tT21k7QXuadoX2Me0uHUzHUoetk6uzTOeAzg2dTyMMRzBH8EcsHlE74sqI97ojdX11+bqlunW613U/6dH1AvRy9FboNejd18f1bfWj9afqb9I/rd83Umuk50juyNKRB0beMUANbA1iDGYYbDNoNxgwNDIMMhQZrjc8ZdhnpGPka5RttNrouFGvMc3Y21hgvNq4xfg5XZvOpOfS19Hb6P0mBibBJhKTrSYdJp9NrUzjTYtN60zvm1HMGGYZZqvNWs36zY3Nw81nmteY37EgWzAssizWWpy1eG9pZZloudCywbLHSteKbVVkVWN1z5pq7WM9xbrK+poN0YZhk2Oz0eayLWrrYptlW2F7yQ61c7UT2G206xxFGOU+SjiqatRNexV7pn2hfY39QwcdhzCHYocGh5ejzUenjF4x+uzob44ujrmO2x3vjtEcEzKmeEzzmNdOtk5cpwqna2OpYwPHzhnbOPaVs50z33mT8y0Xmku4y0KXVpevrm6uYtda1143c7c0t0q3mwwtRhRjCeOcO8Hdz32O+1H3jx6uHgUeBzz+8rT3zPHc7dkzzmocf9z2cY+9TL04Xlu9urzp3mneW7y7fEx8OD5VPo98zXx5vjt8nzFtmNnMPcyXfo5+Yr/Dfu9ZHqxZrBP+mH+Qf6l/R4BmQHzAhoAHgaaBmYE1gf1BLkEzgk4EE4JDg1cE32QbsrnsanZ/iFvIrJC2UJXQ2NANoY/CbMPEYc3haHhI+KrwexEWEcKIhkgQyY5cFXk/yipqStSRaGJ0VHRF9NOYMTEzY87G0mInxe6OfRfnF7cs7m68dbwkvjVBLSE1oTrhfaJ/4srErqTRSbOSLibrJwuSG1NIKQkpO1IGxgeMXzO+O9UltST1xgSrCdMmnJ+oPzF34rFJapM4kw6mEdIS03anfeFEcqo4A+ns9Mr0fi6Lu5b7gufLW83r5XvxV/KfZXhlrMzoyfTKXJXZm+WTVZ7VJ2AJNgheZQdnb85+nxOZszNnMDcxty5PKS8tr0moKcwRtk02mjxtcqfITlQi6priMWXNlH5xqHhHPpI/Ib+xQAv+yLdLrCW/SB4WehdWFH6YmjD14DSNacJp7dNtpy+e/qwosOi3GfgM7ozWmSYz5818OIs5a+tsZHb67NY5ZnMWzOmeGzR31zzKvJx5vxc7Fq8sfjs/cX7zAsMFcxc8/iXol5oS1RJxyc2Fngs3L8IXCRZ1LB67eP3ib6W80gtljmXlZV+WcJdc+HXMr+t+HVyasbRjmeuyTcuJy4XLb6zwWbFrpcbKopWPV4Wvql9NX126+u2aSWvOlzuXb15LWStZ27UubF3jevP1y9d/2ZC14XqFX0VdpUHl4sr3G3kbr2zy3VS72XBz2eZPWwRbbm0N2lpfZVlVvo24rXDb0+0J28/+xviteof+jrIdX3cKd3btitnVVu1WXb3bYPeyGrRGUtO7J3XP5b3+extr7Wu31unUle0D+yT7nu9P23/jQOiB1oOMg7WHLA5VHqYdLq1H6qfX9zdkNXQ1Jjd2NoU0tTZ7Nh8+4nBk51GToxXHtI8tO045vuD4YEtRy8AJ0Ym+k5knH7dOar17KunUtbboto7ToafPnQk8c+os82zLOa9zR897nG+6wLjQcNH1Yn27S/vh311+P9zh2lF/ye1S42X3y82d4zqPX/G5cvKq/9Uz19jXLl6PuN55I/7GrZupN7tu8W713M69/epO4Z3Pd+feI9wrva9+v/yBwYOqP2z+qOty7Tr20P9h+6PYR3cfcx+/eJL/5Ev3gqfUp+XPjJ9V9zj1HO0N7L38fPzz7heiF5/7Sv7U+LPypfXLQ3/5/tXen9Tf/Ur8avD1kjd6b3a+dX7bOhA18OBd3rvP70s/6H3Y9ZHx8eynxE/PPk/9Qvqy7qvN1+Zvod/uDeYNDoo4Yo7sVwCDFc3IAOD1TgCoyQDQ4PmMMl5+/pMVRH5mlSHwn7D8jCgrrgDUwv/36D74d3MTgH3b4fEL6qulAhBFBSDOHaBjxw7XobOa7FwpLUR4DtgS8zU9Lx38myI/c/4Q988tkKo6g5/bfwE3CHxK9X5EtgAAAIplWElmTU0AKgAAAAgABAEaAAUAAAABAAAAPgEbAAUAAAABAAAARgEoAAMAAAABAAIAAIdpAAQAAAABAAAATgAAAAAAAACQAAAAAQAAAJAAAAABAAOShgAHAAAAEgAAAHigAgAEAAAAAQAAAXagAwAEAAAAAQAAANwAAAAAQVNDSUkAAABTY3JlZW5zaG90v5biTQAAAAlwSFlzAAAWJQAAFiUBSVIk8AAAAdZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IlhNUCBDb3JlIDYuMC4wIj4KICAgPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4KICAgICAgPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIKICAgICAgICAgICAgeG1sbnM6ZXhpZj0iaHR0cDovL25zLmFkb2JlLmNvbS9leGlmLzEuMC8iPgogICAgICAgICA8ZXhpZjpQaXhlbFlEaW1lbnNpb24+MjIwPC9leGlmOlBpeGVsWURpbWVuc2lvbj4KICAgICAgICAgPGV4aWY6UGl4ZWxYRGltZW5zaW9uPjM3NDwvZXhpZjpQaXhlbFhEaW1lbnNpb24+CiAgICAgICAgIDxleGlmOlVzZXJDb21tZW50PlNjcmVlbnNob3Q8L2V4aWY6VXNlckNvbW1lbnQ+CiAgICAgIDwvcmRmOkRlc2NyaXB0aW9uPgogICA8L3JkZjpSREY+CjwveDp4bXBtZXRhPgpWaObRAAAAHGlET1QAAAACAAAAAAAAAG4AAAAoAAAAbgAAAG4AADIVO8I7DQAAMeFJREFUeAHsXQnUFMW1rn9hUaOJidEYMXEJ7qLyXIgo+jwPEZGDPiJHfXIkeDToQxQ4BkncQMEdUUDcicpBniuK4FFRXEDFBRdkcWMRWRRXFP51pl99Pfmm7/RU9/TM9PzzL3XP+f+a7q7l1q3qr27dul1VsbWmzlGa1qxdi0Dt13lvN7T/rASsBKwErARapgQqLLC3zIazXFsJWAlYCQRJwAJ7kGTsfSsBKwErgRYqAQvsLbThLNtWAlYCVgJBErDAHiQZe99KwErASqCFSsACe4ENl0goNXNmo/r5Z6UGDqxW225bYEZlSga+ly5NqiVLkurQQyvV4YdXlokTW6yUwMqVjtq61VG//nWF+v3vK9xHq1Y5au7chOrSpVIddFCF2nHH1H2Zzv62EsiQABZP8bf8k8/cP8dSJAk89FCD9iba4v7ddFN9pDTNIdLq1UnnvPPgCZXiHeGUKQ3NgTXLg5ZAly41btugjUgvvNCY0V79+tU6H3yQ4GMbWglkScBq7BnDXPSLJ59MqP/+7zo3wfDh1WrChPbRExcQ88svHXXXXY1uyv/932r1u9/lr7XdeGODGjWqIaP044+vUmPGtFM9eliNPUMwZbo45JBa9eGHSXXeedXq7rtTferjj5Nq5MgG9eqrSfXTTxrj/00XXlitbrutvaqu5h0bWgmkJGCBvcCe0KgxdvLkRvdFGzq0uuTT4zffTKo//7nW5Xbx4o7qsMPyA+J//rNBjR+fAvXtt69Q48a1U+efX606dChQADZZSSRgAnYWBPPfo48m1MUX16uvv04B/BlnVKkHH+yg2rVjLBtaCShlgb2F9IJigH3ixEY1fHi9W9Odd65Q773XMW2/bSHVbzNshgE7hYD1keOOq1WLFyfdW0OGVKupU0s7Y2TZNmwZErDA3jLaSRUK7GvWOGqPPWrStVy4sKM6+uj8tP10Yvuj5BKIAuxgAguqiEvTzIIFHVX37rZdS95ALaSAFgvsCxYk1YYNjtptt4o0UME2OWNGQn32WVIdcEClGjCgSnsRmDv7rFkJ1aAtE126VKh9961UMK08+2xCzZuXUGvXOmrXXSvUfvtVqsGDq9V226Va8+WXE2rTpuyWhX16l12Cbd7gE/yCTjmlSm2zjdL5OOpf/2p0tS7Yy3v3rlKwd7cPULwKBfZTT61TTz2l5/CasA6A9YAgwlT/iSdScfv2rVK4fuCBRvX++0k1bFh1WpazZydckwCA5JxzqlXHjqkcX389qdatS8numGPMckf+yBeeOJ07B8ssiMdc999+O6neeiup3nkn6bbpwQdXqAMPrHT//vCHClVpYGvhwlSa995Lqqoq5XoIHXWU2VMI/QTrK6Bu3SrV7rtXqDq91PLww41uG6NuvXpV6b/KnOa5Tz911KJFCbV6dcqsAm+X0aMbXLCWNvagOs+Zk9D9KbXOs88+FdrLaRtrbw8SVlu7X6xXzLx5jU7v3rXOm2827Sp9nz61rqcAPARqax3nwgszPT3o9TFjRmPWijFu8PkNN9Q7q1Yl094IvM8QXiSk7t1THgt8xvC558xlMN0zz3heDWvWJJ1XXkmky2ceCAcN8jwhkBZx589vdP9uv93zwpk6tSF9n8+RZ9Jj1S165cpkuhzIyf+c/DHU2l86/ooVCadr18z6/vhj0pk40eMDPI8a5XkEnXZaqk3QH4KI9b311ng9ccDbueea+wDLBO+Sfv7ZcWXO5/5w5Mh6py6zSZzvv/dkir61bl3S2Wsv7Z8ovIzw+4ADahzwZCKUe8YZKVn50/FaesWY8uC9yy6rT5cN7xlLVgKQgCoW2AFq7IxNCfAE9r59ax2AFnno1q3GOeKITED68svsF4zxhw2rc3be2Xsx8cKdfrqXnwR2vEQoD3/HHuuVkQ+wa9/3NK+dOm11Bg7MLH/aNA98xo3zXlryGxbW1GR26uuv99K/8UbugVcCO/hCWVI2EyZ4oL799imZwT2PVC5g37w5E1z32WerM3x4nXPXXQ3O5ZfXOxyQJbA3agyU/QTteeON9Q5kLgc09C1JEtghD5QFOUEeZ51Vl6Eg+Adq5JPQzTBggNe/kA5lDBlS5/Ts6d2PCuxff+0NNKbyJO/2d9uRQNHAvn590u3QEnCaAuAJ7CwXLwhmDyS82HwGzctPfMbwhBNqXe0L8fT0OJ1WArvMQ5t70nHyAXaWd8UVnjYIrY9ACXAgAeQBPviTWiHAhPdlWO+rJn2iAc4AlFwkgR18Atyh5ctBDHx++mnS0aYHt/7Im1QuYMfgTLlCazfNTMDzJ594AzxkyzQjRtRlyAdaOgc2xJk71+tXEtiZHgP9V1+l8m7Q4zKUCzyDrPw0dqw32KIMaO+S2GZRgR1pe/XyBgSUb8lKoGhgpwg/+iiRNb0sJcD7gV3bv8mKG8oXEJqQn/hSIoRGt2WLF6PUwH7BBR54s1RqceDFRNC4yfPixZl1NcUHuDH+2Wdnl2dK4wf2DRtSYCVNHDADgV59NcWPBK9yAPuSJZ5c0M7+wc1UT8iGMxGEMOX56bvvvIEbGjxJ9ivIF89k30G8O+/0Bo2tAtvfesvjFYOBiQoB9vHjvcFi7dpUm5nytvfajgRiA3aKDC8aQYrAUgqAl8Aup9jkAyE1J5g8/ETeEPq1clxjaow/vOAmKlRjB3CbgIRrBNK0IcvNF9jlFF3awWWe/t8S2DHjIV10UUojBogTqLCmAtmVG9jvu88D0Sef9DRr8m4KMctk+48Z45vmiARof8bjgCGBHXXH+oyfHnnEM7fJ/iNnkcuWmQfnQoD9gQc8GUQxufn5tdetTwKxAztF9OGHpQV4AjtMEUGEAcUPPozLFxY22EKoUGDHzMZEfOlhZjFRvsCOxU/WEbb2KCSBfflyj08CO0JScwF2yg11Na2lkF8ZcraBNNgaIoiwVQRlCHmCJLBDMzcRBhimwyBCoj0eC6tBVAiwP/WUVx4W6i1ZCZQM2Cna6dM9bYKdPeiFYJooIYHdv7gl0/JFMmnB5AVeMYVQocAOTxcTEaDiAnYJQLAhRyEJ7F984fFJYJeyai7ALhe6o9qXJfDOnh0MhPfc4/VdasJSrkEeV7NmeUCL9RMS+xxMVkFUCLDfe6/H5zvveANyUBn2fuuXQMmAHSYZv0sXwBj26zgoF7DDQ4QvEkxDfuIzCVb+OGHXzR3YwTtMBagnwC8KFQvsBFks5pkIG1dR7nG5O15yiWcuwQJpFHr/fY8PeM4E0dVXexo7Ne9CgV32R6xZmAhmHconn8VTyefGjdFkYCrf3ms9Eogd2PHy+m3scQI6RZ8L2AEcfElg8/QTn7UUYMeCKXl+7bVogyO9WQDwfn9svzxwXSyw05ME5frpm2+SDtY6WIe4gF1qq1deGW32JesZBLLg32TKKxTYkR8HWtPAhwVY6WaZD7DDHAm5Iv8o3k/gxVLrlkBswA5Ap8bGl7cUgM7mCAN2uLXxJYJpw++1gDzIY0sBdphwyDNMBFEI2ijT5HLJRH4S8AoxxQwdmtKe4WkCP3ESTCTSJQ88xQXs0nsF+QYtSpIXhtJnXNaVz+VAes45noZdDLATgMGnNNGgTJTBtkIYFdjlR2hRTW6sow1brwSKBnZ00P79PT9adMpSAjqbgsAO7RA8wIUN7nnSQwDgzkUvpmPIlygOYIdPN7xQ8Ce9IFiW/8tT3pdhLhs7gFK66MlFWHzhOHlyg+uCKPPctMkbDKAN+j9gknHxu1hgBw+UK/y14UEDgOTMgfwjTlzADr7pU4980ea4JnDCm+XttxMOvF+kPV2ahTD4SzMOeJa8ShfCYoBdmkwgE5jz4GQA10fyTvlFAXb0eTk7Rj0tWQlAAkUDu/zytCkAnc1GYOeLYArDPrFm/DiAnXkhBLD4KQ5gR57ycA+UBUCChwXLf/DBbE2eWjTimPznJa/FAjvAVAIi+UIIuQB4eC9OYEcd5AdHLMMf+t1i8aWpjIOPwKS5CM/kl8AopxhgxwAMOcgy5W98CJXP4qncZgIf2FmyEqAEigb2F19sbBINnQwzDAN2TPsXLAjXXviCFXr6kZwCy5fTBOx4YRlHan+sC0J8HYs4QV4xjAuPC/LOPBFCI3/33ew6A4gk2MJLKYjwFSTzlK6DXKCUsuLHNv76YnHcD44AHWrEzB+gBMIMh/vdRA2XLs2uJ/LCWgrkxzJkiG8a5BekiA/C18p+fpEO+Zg0YIAz88XMwERPP+21Nz/yYjzMIOVgjLzwbQNmECDa2eFDH0bS/RV5yK9qw9LZZ21DAi12d0fsaofd7fr0qdK7JLZXP/yg3J3tOnWqaBM73GE7XpxXit0gO3euVHvuGbxTInZ3xC6PpKbY4hXnqa5a5bg7OGL3zCB6/vmE3gnR4y0onrx/+ulV6pFHzCeEYGjSIOfu0IndO1H2HnuYd3WUeW7c6Kjly5OqQosRO4LutFOwPGW6Qn5jh8hly5IKbYgdLrGLaD6EE5V69KhLH7Zx883t9AlL9qSNfGTY2uO2eGDv169KzZplfslbe+PlU7+ZMxPqzDM9AB00qFqNGFHtbmdr2so2n7yLibtoUVJddFHqEJCo+fzXf1Xp06DaHpB9/rmj7rmnUd1wg3e84TXXtFOXX972ZBG1r7TVeBbY21DLY4YzeLB3rBqqjmPypk1rr/r31xuRW2qWEsAe85ih8jg8MIl2u+WWdu7ZqM2SactUWSVggb2s4m/6wmv1san339+oD0Fu0CYLbbfQNGVKe4WDkS01Twng8JeePVOzLZgacQgHDj751a9KZy5qnpKwXEWVgAX2qJJqhfG2bEnZenEO6h//aEGiuTbxt9/C/u9os1lFzlOZmmsdLF9NK4EWC+w40Ff7KKsOHSrSR9c1rehsaVYCVgJWAs1TAi0W2JunOC1XVgJWAlYC5ZeABfbyt4HlwErASsBKIFYJWGCPVZw2MysBKwErgfJLwAJ7+dvAcmAlYCVgJRCrBCywxypOm5mVgJWAlUD5JWCBvfxtYDmwErASsBKIVQIW2GMVp83MSsBKwEqg/BKwwF7+NrAcWAlYCVgJxCoBC+yxitNmZiVgJWAlUH4JxA7sY8eOVXV13i6Cpip27txZDRo0yPQo0r05c+ao119/PWfcUaNGqR122CFnPBvBSsBKwEqgNUkgdmCvwIbWOahnz57q+eefN8b67LPP1LPPPus+O+aYY9Rhhx2WFe/iiy9Wt99+e9Z9/40vvvhC7b777v7bBV+vXLlSPfnkk2ru3Ll6A61P1Jdffql32dte7brrruroo49Wf/3rX/U+2T1y5p9IJNSjjz6qNm3apNq1a6eGDBmSM02+EX7QG9SDVwyC7733ngLv4HXPPfdUe++9tzr//PPVSSedFJrtz3rfhltuucXN4+2331Y777yzOvbYY1W/fv3UwIEDQ9PKh4sWLVJvvfWWe+vcc89V2267rXyc9Rt948UXX1QLFy50/zp16qQOPvhgvW/5fuqCCy7Qe5h3zkizfv16NXv2bJfPjz/+2G0b1PWII45w/y677DK9YdavMtIUc/Hmm2+qp59+Ws2bN0+tWLFC/fTTT2nZ9urVS/3tb39zZewv44MPPlCvvvqq/3bg9cknn2zMJzBByINkMqkefPBB9dBDDym0Jahbt25uf7300kv11hzRtr5et26deuKJJ9z0vXv3Vn/605/c30H/lixZorfVnqXeeOMNtWDBAjfaoYceqve9OVCddtpp6sQTTwxKqn788Uf18MMPqwa9sT767SmnnBIY995771U1NTWBz/ngqKOOUkceeSQvW2+4tabOwd/yTz5z/4o9X0RLClsGOscff7xzxRVXGP+mTZuWVYzW8p3rrrvOTcs8br311qx4uPHMM88Y80V5urOk89DAbkxf6M2///3v6bzJoz+cPHlyaPb65XY04GTkE5qgwIeQkZ83//UZZ5yhz4rVB2caaJU+JUMDeWAew4cP1wdWm08Qktl9rfea1SCbzkcDg3yc8Rv56VlWOq6fX1w/9dRTGWkgb1M8eW+fffbRZ9+uyEhXzEXXrl1zlqmBLKsIrYzkTCf5fvzxx7PyKORGbW2tc8IJJwSWrQdrfZLVdzmz1gqJo5WydD6PPPJIaBo8l/Xx/x4xYkRgeq2UZPS/vn37BsbFA9nH/OXIa21RCM2ntTws+mg8vyAoxAkTJvgfBV5rDUgfF3ZAVicIAvbAjPQDCWilAPa99trLueGGG5yXX37Z+VyffPD+++871157bQbvWpvPYnHLli3O5ZdfnhGPssqKHMMNyAGdHQCsZ0AusC3XWwRqrS3jhdEanLE0Dj7IA2ALoJo4caKD+pNvrYEZ08qbp59+ejo+0gUBO0BdzwTScfv06aPPeH3I5Vtr/M4dd9zhDoiol6QxY8a4afr37+/cd999+vDsxfoYvk+d+++/31UuyCv4iIsA7ABDlIe+i0EQ8tHmxTT/kFM9TtIWFGUQIr8IX3jhBZG68J9ysNQzLTdfrQlnyGf8+PE5C5gyZUq6fuAvDNj1TC8dF+826o53BYrNzJkz3bYePXp0Vpl6FpyhnFEe+QA7FJKgP/ThtkBlB3Y9TUt3ADSiBILmBuzavBGo4d5zzz3pepi09i5duqSfAyz1NDh9XYqOtnXrVgeamomWLl2aLhszHD9Bu+ULNWnSpIzHehqffnbllVdmPPNfzJgxIx2X+QUB+2OPPZaOe9ZZZ0WaDaA8AMXatWv9RbvXAFZq15C5H2iNiSLc/P777wNjgXfWFUDmJ8yQwv6kVv/NN9/4k+d9DS2bMy9/W0PZgFzAb/fu3UPzln2C9QsCdrQH4wDUtckxNG8+hCLGdAjxzmgznHsvKrBfc801zK5Nh2UH9rvuusttODTg9OnT3cZg4zY3YA/rKQAs8q1tlllR+QINHjzY1VqlRpMVuQluUPPGy+MnvYaQrguA00+si7bT+x+lr/FyMx7lgtAE7AA6DnwItU01nU+xP8AjyweQlZqk+UHb/fMqDuYQykyvu+SVNiiytlOn629SODgQ4f0LIrSHVEQozyBgh4mFcYIGXVNZVDggAwC0tpk7mLkhLwvsJokF3ys7sGMqi+m1tNeyU7QkYH/ttdfSnRn2QT9hGqsX+dK3ywnsADjKGKYaPwFg+BymDklSc0OdTASg1ouIbh7QFu++++50fiZgh6mI5WGgj4ugrXIAA0A0BY0bNy5dl6+++iqvIjHoQw6QWRSbd9TMOWuB+QhtQwJgU5sPM1XJtS+9cJqunwnYMctgW2INJx/CegzMW3IAtsCejwS9uGUHdo8V7xc7RksBdu09kp7yg/ewqTprWS5gB9gNHTo0/fI999xzZCkjJDCjPlOnTnWf4YXDlB33oFXBNGWiO++8M50/QBuLgGxTE7DTTh5VdqYyTfekTRuDS6kJayusJ9Yo8iGsCTCt9gjKJ2nOuNdff306b6wDwFEBJDVr02Iv4sCcRL5gE9+4cWP62gTsL730Uvq59hpCFkWRBfbCxGeBvQC5LVu2zPnwww/dRSjYoKn14AXA4mQUaipgX716tfPRRx852s3O5U1OqWGmkBqc5BsvOl9ohBgMuKCK6yAzAxYumY7mhFzAzkVHaJYkLPTC3owZBQBkw4YNfBQplACDOsdlX2fhGOQgVyzWatfHjIVxmDXeffddRs0ZwtxFmWGhM27CzIEzF5QDzxYsouYqE6YQOjUgxHUuYIfHG/PlrANth4Vw9CGsReXjoZQvsKNs8ArTzUUXXZQ1A4hbts01PwvsebYMtB12XH+ofbUj59ZUwI7pt59PXMNrKQjUWQlo86a0fs8UxsfUnho9wA32XVAuYCeP8IqBVwTBxF92rsVa8gGgpK0ag+6aNWv4KLZw/vz5RtmgvG/1IaVRSfvAO3DHRF0xsFGbjpo+ajzIQCoglO3VV18d2A+goTMeBjBQLmCXsy8s3sMcwzxkiBmhNLkE1aMQYJfl4DfqffPNN8e6dhPEb3O5b4E9z5aA5oeOQuCQnQj3ogAmimwqYIft1MQr+IY2HGY20h8IGV/KoCn2jTfemI4P4CPlAnYCDl52apYIwZ/+uCgD6OEyGkb6A7c0gKHe+WiHYfn6n2FGQ75lH8BvADUWoKPQeeedl5ZZqXgFHzCBcQCR/KIfmki2vfT9zgXscp0AWjPKQjvoD9McDCLSxIeZQy5wjwrscEH+xz/+4WAWinK5riDrOnLkSFNVW+U9C+xFNCtcCuHLDkCTL3kUH/6mAnZWD9o0Xm74L9MDBZ0eWjLs7n6C+UO+FHzBeA/5SJLmhEsuuUQ+yqmxS9khf7jlQZMlQfOTbrCQuYlWaX9yzBSQB8DE5NFjSlfsPaw1oCxM/SkfhEF2a5YnFyJNHiuMV2yov/7M6J/yewHwCb5lH4DsOcACIKUZKyqwUw4YTDDYSpJ9P5fpkv0ul1eMzJ+/YRaEckBeEMKHvi2QBfaYWhmgKQEKJoUwkp07LF4pngHk5ZeIenuDjGJg35YvA+zVIGhF8j5NMshPDhbwdAKY8A/TYKbDRze8T5OFtPsDkGmblUxJ32j4x/sJHhUEI+SBNZByEBY+WVeAWhBBU2V/gflKeoUFpSnkPpQPqaljIRUk+QS/0rY/bNiwdB0ga7YXQpkO/YHP+DEgvv5m/RFibcdPqCvNbWEus0hXDLCzXDmTxKDWFsgCe4ytLD0b/J+++4spJ7CDF+nB4f+0m3ZyvJgEdfIvXxL6Pkv3SPlS5/rNmc2AAQPSYKD3gmFRWSEBCotwkuCVxIVdgDr8octJcmEy6OOcm266KV1nDKSlIpg/2A5+11V8OcxnCPV+Qi4bJjOGjGf6TY0aHlR8joE2iOiZFTb4IW0cwI61JA6i6B9tgSywx9jKWGBip6ZmFJR9uYEdnZ286s2c0mxipsH7WNT0E9LJqTymu1gkxYsT9Mf8EOLFYjx4SIBg+2QcDBxBRI3cr+XB+4bp43YVDOIl7L78ehS2aj9hXQNyAM8ERH+cuK4pM5TFxWyZNz6xp+zg0QJCf2Ab+UPyzTR8Ds8mEDyE+Ez2K/eh+Mc2o3IgHmX8jAPYkSH2riJfmMW0drLAHmMLSy8SaO9hVG5g37x5c7qjS5s4TCV8AYLsvvLzf5Mvs7/euRZPZZkwA5gImi/5ktscwOzD+2GDginPUt3DIh55Mu0bJPsJttQoFcHcQz6wl46JpM3cPxPKFd/U9nL2FqaN0xTj3+bAX2YcwI41GsrBaux+CUe8pgA5zY6YLCMa82gpHyiRebnAB//xMCoU2KFRQ7avvPJKoJtaWLl8Jjd0khuByUVQaXdlOoTywx8Aay7KBeywuXLRExogBh0/yTLlouQ555yTfmkBUuUmaMWsS5A2ym000M8LMRtBXvC6gUzC9pPB7IoaNkxVuPaT/AAJ5qFcJAcCE7AjPb9LQP3eeeedrCzlzBZ2+jCKA9ihCBBTzj777LDiWs2zsmvsGE2x8CX/2AiwCcr7Ya55bBEs6DE9F3T4rNgQU0t8weif0uLDDamlmbQQaDKyLldddVWaT3kfv6UXguQZtmS+qKij3zNFxgUoQ34mH27p8QKtSnqg+P30/RolQJU8IMzlrgaecgE74shP8eH7LPOVWw74F7+o+WFAwHpA2F++n/iDLz/BwwNggw+0sGgsCR/iEIjQPkEzHrQN+ygXkGU+uX7LdQ6YWqRHiz+t5Ad9VPYtLPj7F7396f3XUYBdbq+B9pFKjvSn9w/iqIf/XeAiP1wj/c/IGxZo8RwzSdlv8J7Kr24hc/rjM21rDcsO7FJ7YWcPCtFJclEpgZ2ABv5gf4adEBoANTTcB1CaPrWXaYPqx/umvWZQbzmFR1wsOgaRXJDEYhg0W/hMyxcZeZi8R6DBkxeE8FrBoqb0Qcb9sIFF8hUF2DHAw97MciFTLELKhTzIkAt8zF/KnmmDQm4yx7SFhPjalPmDHwz2MGFgwJFtHKYZ0tcb+Zi06Fx8SS8i5AGegkju7YO4GAjgU+7/cIhfCQflw/tRgB1xsQ2wlBNms/7+A3u8JG4CxnS5QgA9SJryWEd/P0fbyJmeLLc1/i47sMvtbnM1JBorF5US2KEVhPEIDRlatYnkSx+WB54FedRAG5H5mNz+WDY+KgkrB7v6hc1o0C6yLJkXNK18QBIDFdOHbQ2AmQ9mO4wrQyx+QcP0Uz7AHnUg8pchr2EKkwuSkkf8pmzCtGgAK9PJvKP+zkdjR57QaDmzYbkyxOwx6oIiwJRpoSGHkZyFMQ1CtJnJhOd3s5VpTL9phsL2DZC7KQ7uwQyFbUDaEpXsaDxtB1b64wAt16YlHAXHI7Q0cMV6NB5qojUWpQ/ZUBpklAZx91g8HNV20EEHqd/+9rclryzK1UCp9CDnHlMXdhShHghcXnEsnjZjqV/+8pdKzyjUvvvuqzQ45eRVzzyUfmnc499wjN9uu+3mHtV2+OGHl/QsWQ0eSr/4Ss8m3CPRDjnkELX//vurqqqqnDw3VQStCbvH9mlwcc/4hTxxTBzaJdfRf8XyqAcN92hJ9O+//OUv6je/+U3OLLVdXml7t9uW2jTipgHPOKYO7VoqQh9EuWhPHE+ItiyVjHCsJo6BxDuCcjWgu3877rhjqarXbPO1wN5sm8YyZiVgJWAlUJgESgbs0AagZZlI202VNhWYHkW6pxcw3cOETZH1F4qupodnpdDYTWXae1YCVgJWAs1JAiUD9rBKalu1O5UMixP27OKLL1b6I5CwKO4zC+w5RWQjWAlYCbRCCcQO7HrhT8GeF0a77LKLOuaYY8KihD7TvtYK9rRcpF29VMeOHXNFs8+tBKwErARalQRiB/ZWJR1bGSsBKwErgRYoAQvsLbDRLMtWAlYCVgJhErDAHiYd+8xKwErASqAFSsACewtsNMuylYCVgJVAmAQssIdJxz6zErASsBJogRKwwN4CG82ybCVgJWAlECYBC+xh0rHPrASsBKwEWqAELLC3wEazLFsJWAlYCYRJwAJ7mHTsMysBKwErgRYoAQvsBTaa3mBPzZzZqHd4VGrgwGq9o1+BGZUpGfheujSplixJ6h3+KtXhh1fGzslrryX1rn4JddZZ1XoHwYrY87cZllcC+uxrpY8PVb/+dYX6/e9T7YuPzm+7rUEdcEClOvjgStWpk233srTS1po6B3/LP/nM/WtLexYXU9eHHmrQ+z/jTMktzk031ReTVZOmXb06qQ/cqEvzDv6nTMk8CYgMffppKm63bjV6b3b9Buu4XbvW6MNF6pyxY+v1CUKMmR1+9RUOy07Jp3fv2uwI9k6Ll0CXLjVuG6M/kfSRAel2R/sjzuzZjfpAEcawYVNIIPaDNpqC6eZQxhNPNKY78PDhXscuFW9r1yadyy+vd/82bCjsLbnhhvo0zwTd44+v1eenJrLYvuMOb+BiXH+IlziI1q3zgB1lWGp9EjABe51+Fc46q04ffJFSBNhnunevcTZtKqzftj7Jlb5G1hRT4DwJU87JkxvVTz85aujQarXjjqWdcr75ZlL9+c+1LreLF3dUhx2Wn+nkn/9sUOPHN7jpt9++Qo0b106df3616tAhWwDvvZdUXbumykLc//mfKnXaaVVqp50q9JbISX34RlIfaJBU8+Z11JusZafnnaeeSujDKJLq3HOr9OEe+fHLPGzYfCVwyCG1bn8477xqdffd7bMYXbQoqS65pF6b45LuM5hn5s3roA+nKe27ksVIG7xhgb2FNHoxwD5xYqM+zarerenOO1doUO6Ytomaqj9sWL2aNEmPXJoWLeqojjzSgrJJTm39Xi5gh3ySGtMvvrjeVYJwDXBH/2ufPQ7gsaWYJGCBPSZBljqbQoF9zRpH7bFHTZq9hQs7qqOPDgdqzAxQHha+1q7dJp3W/rASkBKIAuyIX1en9DGOtertt1Oa+/jx7dTo0e1kVvZ3zBJoscC+YEFSbdjguN4WBCqYCWbMSOi92pOuZjBgQJU+i9QMYrNmJVSDtkx06VLhmglgWnn22YSeKiY0mDnudHG//SrV4MHVarvtUlJ/+eWE0kd/ZlGPHpVql12Cp5fgE/yCTjmlSm2jsXLTJkf961+NavHipPrd7ypU795V6vjjqwI1mUKB/dRT6xRMIqAJE9przb3a/R3278QT69QLL6TSfP75Nvp81OC6yXzgZaPPDJa33N/7718R2A5ZkfWNb7911Pz5SbVqVVJ7XSh9VmaFPqNTabNRhfrFL5QrK6R76aWEjqtUt26V7gxk7tyEevTRhDrzzCp10klVqkKzDZMR5PyLX1RozbFaYcZiIsT74IOkPnXLUdVaRPD0gHmtUncf9hFTumLuwavk1VcTLo/oI9BmDzwQfxX6/NRKY1/4+OOkgrcR+g3kBI8mmOV69qzSZ8Jmc4P+rI+7ddvwP/6jUmFpE237zDMJfX6vo447rkqdfHKVPlvWLBfm+Omnjp69JdTq1an2hWxGj25wTZFBphimRQi5HnRQrRsf1ytXbpOzTMSzVKAEivWKmTev0YHXg3ZrK/2KgCihT59adyGwX79ap1avzV14YaanBxdtZsxoFKm8n3yOBUUNIO7qPe/JEF4kJCwAyWf8/dxz5jKY7plnvIXWNWuS7mIl08pw0KDMRVjEnT+/0f27/XZvMXPq1Ib0fT7HAqjf82DlSm8BE3LyPyd//hBePuQLC2E1Nf4Y5uurr/bSMT1CLPpGpWuuMefB/Dp12prO6ogjUu3x8MONztChme2PNlm4MJGuB9Ijvp+wyNuzZ6ovsQx/iD4SJzXq7jJxotee/vJwjfaShLYLS4M6mBbV4cWE/M4/v86p19U47TRzXT/4wPz+/vyz45xxhjkN+ZZeMZJn/++5c7334Mor45Wpv6y2fl20VwxeIDZwUwI8gb1v31r3JSAPcM3jC897X37pgTMbnM+GDctcwUcnPv10ryNLYL/ssnoH5eHv2GM9kM8H2LXve1peAKmBAzPLnzbN8yEcNy4c5FgHhn4Avv56L/0bb5hfXMpDhnrGk3ZvRN4AhxUrcqcHwFI+CMlXVGCH2yXTIIQ3DQZs5EV3SxOwQ4aIzzj4DU+lvfZKeWZID41vv/X6gvbBdtBfWCbiDRhQ65x7bl1G+8YN7BgsZZnnnFPnYLC+9tr6NPD6gX3UKK8tUS8AI4Ae8WReP/zg1Q9tSmAfPLjO9VZhXMgU7yuvIVe/+2pCNznkwTiQL8obMqQuYzCMCuzgh540KA/5WyqNBIoG9vXrkxkdBp2gKQCewC47HWYPJLzYfDZyZLZ2wGcMTzih1oH2BtJTznRaCezMGyHAj2nzAXamueKKegeuYSCUS1DCS08CyGOQwh9BCun32Wdr+j6fI4RGJokvEQAr35cIAwF5ZQgwCXNxlGXjNwE1CrC/+KI34AGMMNuQdOmlKWAzATtlAlAbM8YDQNyHWypcRVkHOUABUHkfg7Yf2PgsTmB//HGvnmifH3/MrCfqjMFHzoDBM3nBYPf995lppGsq6iGJwM706Efvv+8hKuLz2fLl3n3kgW8V+AyDJ7R3Sexf+QC7VDbeeiuzPJm3/V2cBIoGdhb/0UeJrClbKQHeD+za/k1W3BCdn50S01Q/8RlCmFgkYJUa2C+4wANv8kXNCLyYSALt4sWZdTXFx9SddcQHRYUQypQDCvIDsOKDkygUFdghew5sSLN5cyZwoaxcwE6e5IdjkCkIgE1ZfPhhSnaPPOIBrGngRzqmiQvYwYesJxUJlBVGnJGAn6VLzW0vZ5DffOPJTwI7ypYDG8rEe8t6SsUIoMv70O5NVAiwL1jg5YsZnqXSSCA2YCd7S5YkMqZv6BylAHgJ7JiSmojTbKnlMR47LUK/Vo5rTDfx99133kvCtAgL1dgB3FgT8BPXCPCymChfYP/6a29gwzS+UAKvN9/saW6U2333mWUuy4kK7LNmeSB7773mfMOAHTLj+sFjj3l5SY2QfBPY2X8AdtI8I/lnmriAXWre+XzUhhkaeAF4BxFAkvy+9poH/hLYOfjJPDC4MJ18Lme8y5Z5+cm0hQC7fG/ikqvkyf5OSSB2YKdg8QJRC2XHiRPg+WLCBBFEKA9l4+X1E3mKYibwp8W17KD5mGKgIZmILxJeYhPlC+wSRDD9LZZgcuvf37O3Qn7Tp5tBmGVFBXa58ImtCEwUBuz33OPxQWD3y5HtjX4pNXgsJgYR08QFQE8+6YEv1lqiEMx15AO2/yCC6Ybx5KBLYOfsxZ9eKgCPPurxxMHkgAOC369CgB2zCfJZjMLhr4e9zpRAyYCdxeDlZ0MyvPNO70VkvHxDArt/kUnmw85p0oLJS6EvbaHADk8XE8UN7NIUNWJEMCCYeAm7N2GC154w04RRVGCXC4BB+YUBu5zSE9h79coEbLY3gB3eI7wOAxfGKbSP+OsibeEwSUQhCbyQQRDBPm7il8AOrxgT4TN/poN5isR7YQNfIcAuFY5bby0eB8ivDTMlUDJgh0nG7yYFMIb9Og7KBezwEGHnNGkrfFboS9vcgR0ypj0XXj5xEhbwKD+4igZRVGCnG6nJZIa8YQ4iQMk4mK2Bj3yBXYLgddeZwVKusxTaR/xykfsLSe8nfzx5LddK8D4FkVx8lpo35ZYPsMt3J2iWgHZnH8hn8VTyiYVkS6WRQOzADn9YvwkmTkCnGHIBO7QBdjypiTA9nxX60jY1sGPBlDxLGyrrYwq5oAaApweOKV6+9yZN8mSLFzWIogK77C8wk/iJ6w+ofxzADps6ZQkzkJ82bkymPXoQr9A+4s9XaqtBi+T+NLjmWhFmSPCBN9GNN3rrINInvRBgR/5UCvwzHzzDYjfzhXzyAXbphRNku0cZloqTQGzAjs4k/b/R4KUAdFY3DNg/+cRzH4Q5Rnq8MD1f7EJf2qYGdphwyLO0KbM+pvCuuzwAzrUOYEofdE/axE0fxTBdVGCXLzvs0JKg2bLeCOMAduRP4AKP0v8fLqMcEFkuXCjjIoI08oYHTxQaP94DbZOSgv5NWQP85SBOAM5HYwdPnA2BT7/3jnQTxfOowI7ZB9oPaUzm0SiysHGiSaBoYEej+xfVSgnorBaBHS8heECnAcg88IAHBHh5oSWZCJ0Lf3EAO0wBsIXiz+RF4//y1MRPLhs7NDW+vAjlIix8oSdPbnD05+kZWUv7KV5wCWAZEcUF4sCn//77G7L8pRFNyjds4RpxyS8+AqN8EPp96uX0HGnwxSg8k0aP9gCNQCzt+gSffE0x4E1+JITf+IgNC9QEXgIQ+gjaJi5Cu7EuyBu+4lBE0L7ow/iND7XkHv8SuJEWX3CSIE9pGoO5R1KhwC6/IsY7BkUG6xP88EzWISqwyw/QsFZjqXQSKBrYoQkSJJsC0CkKAjvLNoUvvJDZyZkWIePHAezMCyE6vJ/iAHbkKX20URZmI/BaYPkPPpj9skjt2uQ/7+cVIML8EAI84UeN7Q5kWXiWaypNYJf54TcAwk/0YPLHxTVABgvA+B0XsH/+uTcD8peJNoTpi4AZ5Mftr0PUa3wgJIHRXz6u/U4B8DGXaSBbOgcwvQlgCwV2KAuyPJbBEINLPouncs0C+Qa5mEaVoY0XLoGigR3aVlMCOqsTBuywC+byOmCnlZoR844S4stIdnIZIl8/yT0y8BWkifCRDPLByxpG8Pkm77JcvMDvvpsNmPCOkQCby0URpggCmsxf/oZGL+24QfxKrVeml7MNpsVXo35THtLDywXE6b+cwlO7lq6DXKDEQCGJ5cuyMTOQskEcACo9l/AdA+4hDggzDXwIx/15ooQow0QYOIL2qMEAalI4MBhxoZn1QYj+YBrUUS5nNaiLieR6A2XNeJjt+gdzlM+256ARlDfzgYuj7AtRTVBMb8P8JdBid3c85ZQ6NWdOQvXpU6V372uvfvhBubvyYatZ7M7X2gnb8eK8Uuxr3blzZehOedjdEbs8khYs6Ki6dzfvesk433/vuLsIYqdL7CKI3fz++McKtxycZVkqWrXKUR99lNrxErsWsi3/8z/rFHbXxC6Yc+caTgcpkCFsKYtdHbHbJnZW3GOP4F0OcU6sBtG8SsJBJZs3B299vG6do3c6dNR33zlq770r3LY0HX4iC928GTJy9Hm7jrsz6R/+UOHuZCnjxPUbu54uW5ZU6G+dO1co7HiaD6EfnXlmvXruudRuoXhfZ8/uUDJ+8+GtNcdt8cDer1+VmjUrvhe9tTb2zJnYztYD90GDqtWIEdUumGFr2nLS+vVO6MEfGMC6dEmd6HT11e3UVVeVZy/vGr2t/XHHpfiIKi8A+4svtr3+iYESW2OPHJna2hfy6tu3Sv3f/3Vwt62OKj8brzAJWGAvTG4tMhVmOIMH16uvv9YWhn8TgGfatPaqf3/DZt6MVOIQ+79jb/wrrqjWBzJUqXYCt7GPvTbDuFot2Pjii23U7rsHa9UlZtVmn0MCtXrcO+SQGvXJJ14fQ5ILL6xWt97a3rjHfI4s7eMCJGCBvQChteQkePHuv79R3XZbQ/rlmzKlvfvilate8mAP8NC1a6V7gAoO7oCZgjR1ans1ZEgbsLOxwi0wxMEo222XMldBaTj11Cp16aXVqpTmuxYoppKzbIG95CJuvgVs2ZKyn+JUIdjPy0Xz5yfUlCmN6vHHU3ZYPx84IWnMmHbqxBPLN6vw82SvzRJI6CZ8/vmEe6wi1izKbeYzc9n677ZYYMdClvbgcI9L49F1rb+5WncNsYC4YoXjHqOm3S5duzuO5dt33zIvArRusdvatUIJtFhgb4VtYatkJWAlYCUQiwQssMciRpuJlYCVgJVA85GABfbm0xaWEysBKwErgVgkYIE9FjHaTKwErASsBJqPBCywN5+2sJxYCVgJWAnEIgEL7LGI0WZiJWAlYCXQfCRggb35tIXlxErASsBKIBYJWGCPRYw2EysBKwErgeYjAQvszactLCdWAlYCVgKxSMACeyxitJlICaxfv15vETBF3jL+7tWrl+rRo4fxWSlvzpkzR73++us5ixg1apTaYYcdcsazEcwSmD59ulq+fLn54b/vVlVVqbFjx4bGKdXDSZMmqY0bN4Zmv9NOO6nhw4eHxmmOD/8fAAD//83l2OkAACm0SURBVO2dCbAdRdXHOyZgpLSgTClRjBYKBKwoRHEBAuKGoqKlREsBjRqVxYAKFZIgkAhKICymjBEQxai4VFgFNAhEMIACAiIE0IBsIogYxaAgiN7v/Ob7znzn9pv13jvv3vfeOVXvzdyZXv/d85/Tp3v6jHv8iSdbQeS+P/yBQ9h265clR//nCHSKwA033BBe85rXlEZfvHhxmD9/fmm4OgHuuuuusGrVqiTKjBkzwvTp04dE/8xnPhO+8pWvDLkeX7j//vvDlClT4sv+uyIC7373u8NFF11UGvq///1vGDduXGm4ogBPP/10uOaaa8IFF1wQrr322nD33XeHP//5z2GbbbYJO+64Y9hnn33CO9/5zrYkpk6dGtatW9d2Lf7x0pe+NPz+97+PLw/873FO7APfRiOugJbYZ82aFV784hdn1uGtb31r2HXXXTPv1b341FNPhVNOOSUsWLAgjfrlL385fPazn01/68mPf/zjcN111+nPtuPatWvD+eefn1xzYm+DpvYPJfYXvehF4WMf+1hm/Gc84xlh0aJFmfeqXvz3v/8dJk2aFB577LHCKF/4whfCUUcdlb5Eli9fHh5++OHMOPSRm266KYxUYg8QO393rLsr+Wu5OAJdIvCrX/2KUWDyx3nTIhpa6+Uvf3map+YtxF4764svvjhNR4i9dnyP8P8I7LXXXgmWHJuUJ59MrA4teYG0hLhbl112WevOO+9srVmzpiUjwrQ96Re33HJLpaIcfvjhSTwh9krhBy2QE/ugtcgoKM9wErsMvdse3Pe///3pbyf2/nam4SL2//znP62f/vSnLdHcMyssI7C0T8ioLjNMfNGJPUbEf495BIaT2E8//fTkoUVbO+ussxLsXWMfjC44XMReVtv77rsvJfZjjjmmLHhy34m9EkweaCwhMJzEjhkG84lMnqUQO7GnUPT1ZFCI/Qc/+EFK7DK3UgkTJ/ZKMHmgsYTAcBJ7Fq5O7FmoDP+1QSD2v/3tb4ntnT7x/Oc/v00BKELEib0IHb83JhFwYh+TzT6k0v0mdmzue+65Z6qty9LLIWXMu+DEnoeMXx+zCDixj9mmb6t4P4ld1sa3Zs+enZK6LKlsK1vZDyf2MoT8/phDwIl9zDV5ZoX7Sezz5s1LSf2QQw7JLF/RRSf2InT83phEwIl9TDb7kEr3i9jRznWe5YADDmixHLKuOLHXRczDj3oEnNhHfRNXqmA/iH3p0qUpqc+ZM6cjUqdyTuyVmtgDjSUEnNjHUmvn13W4iX3lypUpqR944IEt7OydihN7p8h5vFGLgBP7qG3aWhUbTmKXzd9SUpc9iHK/Qq1aASf2qkh5uDGDgBP7mGnqwooOJ7HLzo0JsbNW/a9//WthuarcdGKvgpKHGVMIdEvsfAI+d+7c1sc//vHWb37zm9rY6cSZ7xVTG7qeRuiW2H/5y1+2PvrRj7YOO+yw1vr163PLxoZf2uaym2duuDo3Rjqx+7a90iNceouA3bZXSD7ZD7tODm9/+9uDbOqURHnOc54TRAMLEyZMyExCdvYLGzZsaLsnWlvym21axdaa3ttoo43CZpttlv7OOmG71ne9613JLd+2Nwuh6td0214h+HDhhRdWjygh//nPf4YXvOAF6Va8733ve8N5552XmQZ7sHMfOeKII8Jb3vKWzHBc3GSTTcLrXve63Pt6Q5ZLhiVLlvi2vXXehh52dCPQjcbO14LycLX9/fznP88FTDcBi+Nk/WZr3zLxbXvLEKp+vxuN3fYhbUsh+8zMv/vd77b1Fw2fdWSzuCoy0jV237a3Sit7mFoI2IeS87rC0Ns+lMcee2xuEmeccUZbWBsvPn/lK1+Zm47ecGJXJLo/dkPsrD1/1ate1da2eS/473//+23h4na3v6vur+7E3n37ewqjDIFuiR04br311vRhZXe+4RIn9t4h3Q2xUwrI3Y7IhtPxiRN77/qBpzRKEOgFsd92220psYvPyWFDxom9d1B3S+yURImd1S7DKSOd2H3yVMZpLr1FwE6e4tRaJzPjXGTFQ5g5c2Z8OZk4E09IiVPq97znPYmD4iGBurjw9a9/PXcy7w/i1F3cpyWp++RpFyBLVJ08ZQJ8t912y0wMn6c/+tGPUj+kNhD4039wSo3z8YMPPtje7vr805/+dJAVWJnpyGqs8MADD/jk6XC+TT2vwUbAauzy1KSad3y+ePHiIRX54x//2BIiSOJgD2U/7V4Lm0LFZcn6PZxD/17XcRDSU409C1t7LesL0Z/85CdpG33wgx/s6ivSPCy22WabNA9bHnte1Safl0e/rrvGLq3o0lsEHn300bB69erSRKdNmxamTp3aFk6+IAy77LJL+NznPhdkHXuutt8WqeYPtDHyKRP56CVMnDixLJjfz0HgF7/4RXjooYdy7v7vZTR2XapoA65YsSIsW7YsyLr0wOitiXa4/PLLw9///neb7ZBzRht77LHHkOuDfsGJfdBbaAyWTybNwvjx48dgzb3KioD3AUWis6MTe2e4eSxHwBFwBAYWASf2gW0aL5gj4Ag4Ap0h4MTeGW4eyxFwBByBgUXAiX1gm8YL5gg4Ao5AZwg4sXeGm8dyBBwBR2BgEXBiH9im8YI5Ao6AI9AZAk7sneHmsRwBR8ARGFgEnNgHtmm8YI6AI+AIdIaAE3tnuHksR8ARcAQGFoGeE/sxxxwT8GpTJFtvvXVgA6jhlscffzx86UtfKs32ta99bWDzKRdHwBFwBEYiAj0n9nHjxpXiIF7Ew6WXXpoZjj08Vq1aldybMWNGmD59ema4Ti4+/PDDYfLkyaVRDzjggHDqqaeWhqsbgH0pTj755HDNNdcE2SgrbLrppuFtb3tbeOMb3xj22WefzB3u6uaRFZ78TjzxxHDjjTcmO9axY95OO+0UZGvSsMUWWwyJIlulhqeeemrI9awLz33uc8O+++6bdSvZj6VKW/7lL38Jsud6ZhpZF7fffvshuwVecsklQRwuhOuuuy6sW7cuvOlNbwq77757+NCHPhS22mqrIcnI5mLhrLPOGnI968Lee+8dXvjCF2bd6uoa/YF6i9eosOWWW6Yu+bpKNCcyOxV+5zvfCWvWrAns4TJlypTw5je/Ockzay+UXuJz5ZVXBtlfPymZbOgVnve85+WUMoR//OMfiVtEdnxkT5977rkncY9Hn331q1+d7PAonrBy47NbozhmCeIvNdx+++1BNvoKO++8c/jkJz+ZHLMiPvjgg+Giiy4KuEX83e9+l/Qf9oghT/7mz59f6lIxK92+Xnv8iSdb/N2x7q7kr9vdyKQyyY5p8lC1jjrqqMy/b33rW0OyES2/xW5/Gp9jJ86IhyRsLuBaK69MXNddBYXYTazenN50000tdoqz9bPn7DiYtctdt7kvWrQoN0/2uM5yFm3LVXbODnmx1G1LsCnLx94HKxV5AbV072wbRs9pU/Z2j8Xu965h845CTHH0rn+ff/75LfDXPNkJsSlhP3tcwmle8VGUmCFZ9wIf2W63NWvWrLZ8ZUvnIXnphaq7ggoJa5S2o90RMq4jv7Mctnz1q19tK19WPPr4b3/727a8Bv1Hz13jKTCnnHJK5bpfe+21LfxRalw99prYywqkrrh6TezijDl9aVA30dpb119/fUu02bZ6i2ZQVsRa98UhdIrprrvumnTsyy67LPH8rhjL6GlImnqvylF2YmyL30lb3nzzzWk5q+R59NFHp3kef/zxaVzZjbElTpNbkMfChQvT6xCoaH5pHE4scUH+hMn7o069EtGcW7KbYVo2rW9TxM42yPYF8sUvfjHBRzTiNkXjzDPPbKtiN/igoOCHVBUlrSPHImK/4oorElxES27BHzLSbPFSoqxiuk0xI92nn366rbzxds9wB/EXLFjQVg4xx7bFE4fnSboyKmt985vfbKFk3HnnnS3wQDnVsssOk23xBv1H34ldPIyn4AEiACqYo4XYZevRtE4QqxUZerY9YGIusre7Op89e3aSLw/CE0880ZaW3St7w4YNbff4wcOZ9/fYY4+lZIF/UpVu2jIvL70uZqQUQ8gbYb907Su8oBgpWPnGN76R3rflJIwlrjxfmjatXpzb8lJufLCqJt0UsStxkV+smUNgih/kjyNxlW7wiX3W7rnnnmk+RcT+pz/9qYXWnieylXOaThzOOrSGnK3wktB6xs8fI1ZxrmKDp+eMBlXZ4xni90iRvhO7ur6ig4vNM8FNG2E0EDuahdZnzpw5mf3inHPOScP0ss6vf/3rk3TRRmKxTqDFLhnfLvyN1qd1kjmRNGyTbSk28yRPhsX6gNkHFo0tFnxm6kgwfrl1Q1xxPlV/a56UBQfdvGwZZYBlE8QOUau2Tl+IRezQaTtSBtwCqmhZuV73xYdjDOIxmpM5j2R0ym/+iohd8847WqfVsXnsyCOPTNIHW9rdyh133JHWkzTqyKc+9ak0LqbckSJ9J3aGuXQoO7TSTtBLkqvSIPp27qUphqGk1ievU2Em0DBZNusqZc8KM2/evDTd2BPRfvvtl9zjQUArrir2gcekZKWptpRJv7QekJGKOOJIrqMU5ImOWsD33HPPTYPZetQlrjSRmifYnBnuW4JoktitzTl+lhjd6EtP+x4mIpVu8Dn77LNbjLBUMDtqHt0QO8+lphOPzmxdf/azn2nWydGO3LLmlNoCmx+8IHRejHYaSdJ3Ys8CSxsv7oxZYXt5rQlip5NpfWxnt+W+++670zCEjTutDVvnHBuj5k3dZPY/iW5NJieccELlJDHB8OIhTeyP9mWcl4jm32lbymqKtA6YFawwb0D6sjTVXm47t8QuS3HTe90QV5pID06aJPaTTjopxS6e/JNlv+k9bSPrBq6X+PSC2K0pTlaQDUEe27nWA2WFvo8wouQ392QF2pB4RRfsxKr4yS0KOnD3nNhNkzRB7JgItMPlzeaj4WgYjr3ytQnxYobRtNFsWf2jvyHG2PZu4Bhy+uEPfziJy4NStYyaVyfEju1fXySYEqwNmMIddNBBSXmwVWcJGpfGpxx2JGaJi/owYcf8zty5c5MRZJ1RTFbeVa81SeyHHnpo2tZWWYDktV0gfy0D17TevcSnW2K3E8C0VZ7pUBxep/WiLigCSuqYpBg9VxWrkNH31PxXNX6/wzmxmxZogthJXifIsoZzEKslHzokdsleyb/+9a9EU9EHWY+UJWvSNC9fO5w977zz8oINua75dULs+iIhDUY1sVibaxZm3/72t9sedIu/JS4toz3ysmA1RtOipNqEjf0DH/hAUn/ITYWXnY50qCMvSzu5zwoupJf4dEPs4j83mWTWtmGlV5HYyWKNw0hEvm0oitZ2D3ONfSHkvUjaIg3YDyd20yBNEbtdJXDwwQe3WPnCA8UyPzRF7YB6xF7YK2HVTdbyOrRTa+stys9qePKhR1HQIfe0TnWJnYl0jauT6nHirGbQMGhkaFloVuvXr28tXbo0vadhaF+VRx55pLVQlkQyD8FSOobpak/V8BybJvcmiZ3JS+pgTSx20hzCRZgr0Toz0Yj0Ep9OiZ3+aZccMrItEkYb8iFeWhetE4rTvffeWxQ1vYfpRiecIffYhJUGHPATJ3bTQE0ROySOXVA7WnxEc1q5cmV6v1frprGJ2xcHmpp2WsrAb9XQDAxtpwzhFRdGHvK1ZNv9sh9a1zrEbucc7IReVl7xyg7NT48QmZIDy+7K5KqrrmozTZAOywKbkiaJnZcV5YfYELvWm6WDKqzQUbzKtNNO8OmE2LGZa/kpG8sZy0RNc4Snr2q/5Tf9/pZbbilMgkUMOrqG1OtMtBYm3IebTuwGdO0I1hZrbnd1CrkzYaVLEOls5MeXoWiYfBXHNf6ylu51kjmTipom55hleHCt6QdyL7IfLlu2LE2jbBicVUbNvw6x6wiDh0snfLPS1musaWaVj760iMeLVEc+qonnLTfVdPRIW9l1/thum5ImiV0njsED0fkWcLIvaL7k1XaqMudSF5+6xB7PDeWtJrNtYkdotDejOV4O2peoHzjkzQ2xYkn7CeHKXgI270E8d2I3rdIksZtskoeKjzGs2C8o43W4NlzVcz7E0IcVzcdOnj300EOpZkKYPG0IGzydnDAQZyeiZahK7IxWNA52/TrCUBytC+JR4aWl6S1ZskQvlx7t2uesVRilCVQM0CSxLxRTk9bdrvDQD7y0iPoS0xeAXi861sGnLrFjrtRyZ20DEJdL9hpKw/PS4uteFdrfKji87GLBXKkjWzBgfmGkixO7acHhInaTZXqKOYbOrMPm9EaHJ/YT7HhdL0mynlgfHsJmiV0S1+n6Y82jKrHrh0g8YPHn31llLLsGiWkZymy0Ni37Qoi3TbDhuj1vktj1gzGtP8f4YzVbT/p/VbHxyvCpQ+x25GqXpxaVi72ntI7xklji8Q2HjuY4xmLXx69evTq+PSJ/O7GbZusXsdvNj5j86YWoyQeCzFtvriaZvJeJpsFLp1PRB64KsaM5aXhrA+40b+JZbZQ5h6pibfcjVWNnIlDx1KPVZsHC1tPuwVOGk41Xhk9VYmcFjBIwL7yqI1f96pQ65tnF7SjAmjrtCLHOiK4Mn37fHzXETkdD82QFCjbrTqQfxI5N02qp1vaZVQceTD6l52tJXXOcFc7uuZM1QYppBtLnYcibVNT7fCLeqSihVCF2u8QObbNbsZugHXfccZWTw5SjSwUpf12TUOWMJGAnGjsvauYPMK9ghigSOwEZtwH9R1981DNrSWlW2nXxqUrsVvOus6R2+fLl6QtM51XicltbuzXVzZo1K40bm0fjNEbS774TOxN6TFzYPyUDhlX2evxZvAKNpqckRNyylRQaLz42Sexs0xqXn+Vc1v5XNvSM61lkf7RL2Hi4LbmTr36OD15ZowTKqu0Qb6AV46a/u21LtpbQPGM7sOYRH3kZxBtCEcbOMdA3bP25j3aGInD11Ve32eTR5uxLkQm1qstCSbdI0EBtf+ZcX+psYhbfy0uLsitOlK9Is4UgNSx50UYqp512Wnovfrl3gw8jI1sXyFbLwMvW3rPY2k2+eF4wIeb92WWI9sWBxq9LNqknL6+ieuq2CsTLy0uv93KDPm2Dpo59J/YsO6B2gvhII2SJNWVoHNthsuJkXWuS2PXFwwOMTY+jlpUjQ0WrSWSVz2qgxEGrzBPqr52WsOTPkBlC1+Eu1wljH3ZNz+5xw8RuFem2Le2eMPpJeFm+X/va1xIcIThGFtRPl6xRP+oa7/ZHmvYLXMVBV0Xwmz9MUEw090rsiETzKDpCgFmiJjKNu3bt2qxgyTWIzRImePDhl60r5/EOh93go5uAafmKjtbkpqt4isLrvfh7ijguIxGeM5270njx0lXbVzRM3jHve4pc8Pt4o+/Ebj+YyANUr+fZetFYlJQ1bCcbO2kaTSx3VGLX8tkj5FRFIGubTtkyMD7KsENQmyfnvBisvdGWgdUlGp7PzqtIt21pt17N+pI0qwxK7FpWe4QA8+rHZlwWSxuPc7R2bL69FLuSJM4v63eemaWOxk75IXe7IZzNixd7Fkbd4IMCYfMoOmfbAxW7k2JRHO7FzyjPRl4dCc+zjWYfSx1iLxohx+n2+3djrvHEDhzkbSyYDo9I5w1iCw37779/kqGsV03cf9XJHddbot0F6TQ9d42HGzSZzAqiMQTRhhMXfTvuuGOQBytstNFGlYspD2GQYWqQl1yQNeiV3OmJRhdk6BrEhhqkw4WXvexlYdtttw3Tpk2rnO+gBhR7cxBtM8EUt2ayRDPssMMOiRs10U4Li01cWa+cuFAD14033jhxGYg7xmc+85mFcft5UxSZxLUkfXzmzJlh0qRJlYpDH5TRbfKHazzcI9IX8mQk4iNzUEG+6A6i1AQxJyYuB2VEEvBjPGHChLyqjrrro4bYaRnZgS0hdh5o/JvWlSaJvW5ZPLwj4Ag4Ap0i0Bix85bcbrvtMsslw6IgE4WZ9zq9iPYiHxkEsUsG+VIwcXobp4XGkud4mbA4s0Wa0NiThP2fI+AIOALDgEBjxF5Udpk4TIaSRWHq3BPfoeEd73hHEkUmbhJv9ePGjRuSBFr85MmTh1yPLzixx4j4b0fAERhJCPSc2GU3vIBtrkg233zzMGPGjKIgte6tWLEiyJ4mQbYfDTLpFSZOnJgZX76WC7IneuY9e5HRBnZWF0fAEXAERiICPSf2foDAZNL48eP7kbXn6Qg4Ao7AwCEwKoh94FD1AjkCjoAj0EcEnNj7CL5n7Qg4Ao5AEwg4sTeBqqfpCDgCjkAfEXBi7yP4nrUj4Ag4Ak0g4MTeBKqepiPgCDgCfUTAib2P4HvWjoAj4Ag0gYATexOoepqOgCPgCPQRASf2PoLvWTsCjoAj0AQCTuxNoOppOgKOgCPQRwR6Tuxs7iVu1wqrtPXWWwfxXlMYpomb4hw5iIPm0qTZ4lM8G5WG8wCOgCPgCAwiAj0n9qzNt+KKx5uAPfjgg8keLuyuyJ7a69atC+IEIdmtkR0b58+fHzbbbLM4mdq/B2UTMLZAOPvss8MjjzyS7MXOpmNNifhUDeJLMojjkXDllVcm2YirvLD77ruHj3zkI5l7VF9yySXJvvFlZdpiiy3C+973vtxg7D/PBm0IewMV7b/D/kLiNSlccMEFQRwMJ3vHs1OnONoO7FsvzhuC+AfNzYv9+MUDUxBnHcl+4wQURxtht912C3Pnzs3cX11cDQbxShXY30icIAdxLhLErVvS79jCWbxaJfvl52baxQ3xlhW+973vBXEoEtasWZPsCU9dX/GKV4SpU6eGz3/+82GTTTbpIofsqFXbBDwoV1VhEz67tzt9nG20wVf8EQf64R577BHe8IY3JP1u0003rZp0YK98cfGXhBcXfmGrrbbKjXvfffeFY489Nsnz9ttvT/rPzjvvHMTjUuAYC5yDn4Kq8olPfCI861nPqhq8f+Eef+LJFn93rLsr+evW84fUJPGeIsSRuB/DxVb8h9NaFRzyapy8o3T4lvVxqHHrHvGyEpfF/laPOkK0dZOuHB4v6vKyaqtz5cg1A1Jf68w4xne//fbLdMdX1bUZbZwlOMpevHhxWx1jR8o2nmzOVujNSMuND1y8AcWCaz/1Haph7VEckgzxeZrlTtHG0XPZNC7Oruvf+F+NXSNqfnrM857UaeZ120S2vm5rPy1X3vHcc89Ni4ZLv6J+t8suu7TKnLZrYvKCaMNq5cqVemvI0fpWzSpnlgck63M4K058baQ4vO67azweVsDbe++9W7jjwj8lfgnPPPPMFsShwOKqrGlp0jUeJHvkkUem9dF6cWxC4gcCX6BXXHFFS7T2lmi+aTnwfxmLJXZ8ZOb9ZbWJaNttvla1nkXEDukQDjdlvGhxRE0fEI2xJaO1tKyEEY9HcXHbXKJRH+LzENv+c9xxx7XFAwvS4yUr3r5a+FjFz6to74mTay03L3sZTbTF7eYHbuhQVDT9OXPmtHh5aH15HsAhdr7dTZ6dtEkVhUvrwBHMVSyp49MUrMGX/qJxIHde6GWyfPnyNA5x84gdXFUxw4cr/Y08FyxYkF4nvphj27Isch2pZbVHHMqPBOk7saPBxo50FTgaXsmWRqvSETRuJ0fNqwmN3TrVpS7WIXEnZS2Lg2d17ZD4NrWaLi8ZWx7r1Z10ldjzNPK8vMWMkuZJ3vZBLiJ2XkI46s5z5o3Heq0LJGyFuLx4uM9DaoV66sMOkVhB80JrzxPrALooXF78vOs4Lde6nHrqqXnBena90zahAPSZoj+r1esIQ0wmaf14SVkhLV68Wv8LL7zQ3h5yzihdw+oxj9itv9zYeTl9RuPbF5BmWFRH7qlWn+dzWdMZpGPfib0MDOvglge1SWmS2JVg0JzRLk4++eS0szVRJ+tQWHw/tmXBbyVDOvzhhx/edr9TYj/99NOTOqFxqkd3faCKiL0t84wfYjdNsZLJ+bYQDOk1D7TMWBQHylRHcBSu6TLK6YXIXFKaJpr6cEhTbcKIQvu0VYT22muvpI6MSiDFWCwGhM0TXvJW+dG2yCN2HQ1TJl72VqwT8TIH8DYe54waNe8sU04cflB+DzSx00AMqwAW80HT0iSxM6SkU6s0Sezr169PO2PWw8ODqJ2VIw+D1ZY7JXaG/BdffHGb6ULz6YbYeaA0HZlsVAjTo7YbtnRLJtRJX2BZZqM0gYwTixGmol4IZgGtx2233daLJEvTaKpNUFCoC/has5HijUKWJ7xkFQf7TNjwdo7GjgLyiN3a1xmtWhEn92l+WAiqCmYXcTafxOU5sn2rahr9CjfQxG7tfDLD3jhGShBWA2kq0yaJHfLTB4dObcVqIBqGozWHdUrsNh891zw6JXZGF0oEkEaWvfv4449P6yvLaFtKxIceemh6XVZmaJFKjzfeeGMaD42/V8KLBzxis1Cv0q+aTrdtwvyXprF69eo0Wyax9frSpUvT6/GJtidhs0ZDN998c5oOL0PMZppuHrFjO9cwKCrY1xFZBZSOLLD915FZs2YlaZLeSJk01foNLLFbGzFDsqbt6wAyWoidCUDt5FfIxJWKLDlLJ+4YAdmXi7UjK7GTBmQK/rNnz26ddNJJrXvvvVeTq3TUcnRC7GjcsrwtrUveChVZxpqO7MiPFSfWljtv3rxKZSUQZjLVOnmgMQP1SjRdNX1RPwho0aJFycQ69l9Zbtmr7HLT6aZN0Hg1fhauOsKWJaaZ+YOvxucYmzfoo6olc+R3FWInM2vzJ21s/LQh52DP5HhVYSGHlpNR6EiTgSR2Oo9tkF4+XEUNNFqI/bTTTks75a233ppWeeHChel1CNoOcS1pWmLXzm2PBx54YIslbVVE49Uldoa9vEw0PuRXJPQRJU6Nw5F4VYfQjz76aNukMhO6vZJYm0VT1T5uy8s5ZoUmRfOr2ya8dHRFD8+KjoxsWXVOjLpt2LDB3krOGVFp/hxRFqxYc5VOglYldtLRVXY2D1428m2Mzabw3L68xI9yYdhBvTlwxM7QSR9QOkcv1q9XBX+0EDtkph0bDQmB4PWaPtDXX399eu2MM85IYZKPp1pHH310iwk+bNOYDjSuHrmGNlUmGl7zLAuv99EGNe4hhxyil3OP1FNJR+NxZFRSRZiYt8sjwaCXgrao5bLkxmiIiT9Wy1iib1JL1HLUbRP5yCetQ95zyUoXTR/TE+GYK+PFq3Z5W0+r9TN60bh2krwqsfMCP/HEE9M0NC36RdWRJiYdO2KIl0f2sk80mdZAEfs999yT2lNp/DoTHb0AabQQ+wknnJB2bggPu7SuMKCOOlEqX6Om4cpWCzAhCxHYhxLNvUz04apDIvbFxHxHvMohzpOXlioD5KfL0zRvSLMoDR5eu/aapXO9FkvsWi7W1tvRBG2lpgzq05Ro/nXaxI7uslYf2bLGa881P470n6uvvjrtdxAxwmhA604ftabXqsR+0EEHpelix9fnmXzBM+sbCFtuztHQtbzMtYxUGRhiZ2ivDUvjV2mEXoOuHWGkT57aNb3gaCehb7jhhhQ2vhbUThyvJEgDRSfx5GvWZKaNoulXJREm3TQOI4YiQiYfSNlq6kykIkzqaTocrWaYBPi/f5Sfj+M0bNkLzsatc86IQPPgyJeyWcJIQcM1ZYLU9Ku2CWXXFycjtbI2p14//OEP2z6Eg2hpz7Vr17buv//+tI46GcqoTMtFG/Cy1j/bligtep10VGy/gUdYDEDfsB8gwSs2jsbVI6YfLQOjqJEsA0HsLCvSz+wBf7iWgsUNN1qI/fLLL087qNXeDzvssLYq82BrR5Z9NdruFf3QteHEjT9uiuNp+lVIhIdcwzMasNpsnK7+ttp9/EGM1QxJV/YE0Wjp0X4wFE/kpYF6dELf1vpBfFmC1q5hlPSywnVzTdOv0ibkY80bZe0dlws7fGwGsSYXXa2kz56WrcpRl/LycZSG5wX0wAMPpMVA87cjOOZt8kQn6nkJVTEz5qUzCNcHgtjtmmG7fGq4AdLONdI1dl6M2tH1SGeNV1zYrQXsWuQy3GWTpTR9XiJFovmXkQhzKxqWVS1qLipKm3s6yiNu1v4jVpOzexQR166PtzZd7jUh9mtfJbQ4H6vNNjV6UJzL2oSysdxUX0hKpHGZ6/5GwdAy6Dp2SBVSzvrT/DWOhmGuAqFd9V78cue+/SCPuFly1VVXpWlUwSUrjUG61ndi5wMKbZQlS5b0FZvRQuwMlSFyxZVjPBlnV2nUXVetmg3plmlwWoayh0VfMjx4VV8y1ryBOSVLrH3Wfu3JChjyonzkXWbyyUq77jX2wVE87KZZNh27BYCuCrH3e3GuZShrE/JiZZCGp2zdCpqwEjX9qIrYNswaxehXp5Qzb17OjswYFcVi05BdV+PbI+5334ldPwKgUWjATgUNiDc42gATfZ3ISCB2hpnsfcHEZ5Gpwn60k6Vp2TXsdSYL7cdPEGOZZq2kUEQibICl4eosL6P+ShKY8rLwsB+76EQdfcNqeUwMDofYemIeiIXy2/11eHFlCS9ulkQyd6J7tGSFy7umWBe1icbVLQmI0wsTqX25YSqrImXEbidr85aKWlt7Vp/VJb70p9EgfSd2XVoESTCBV/THhyhZgo1eH3A6YLwZVFacrGtNEjtaKBPE+mfXlOs1PdoVAbaccT2LbMJ2Tw6wtXZOO0kEbpZAmHDCZABpUB4VysRadyUFjvHXwIwCtA561PAMkfUaR4bHKnaTryOOOKKwDzDCs6KaPvkQ12KHZmbNHzau3eSL/Iv6Xd7SPluOqud2e+F4QzOWmCpefGyTJ4xsNRymqKLRRqdtonnbZadVFSbW6Nv+Rlq8jOw2AXU2mCsjdrtsl75uR5G8LO13HXmjBH32R9JGX9pGWce+E3tsMtAOm3XUjaXiimTtrW3JKg6f91sbtwkbu33xZNXNXoNossQOiwnPro1FYicjCY82qMseNb94NYw1bxCGB0UntjUOx6ydCa12Z8NmnfNCV7GreLLC2mv0FyuQrr0P0TFBphqY3ovb1H78pGHyjqzf7pWwWsPOC4At++Lb54A2si+oOO+4DVlpkiedtommp2vPwSZrRKTh7FFHHdSN+Py2/Z/17XXMHWXETt5xezJKpc3ti506MGrKEvo59+tuO5CV1iBcG1HEnqehorEoKevDiamirmgaMQnUTScrvO3YWsa8I1sCZAmka9OpMrlmtWGbH+mwdDEWbKDxw2DjQUB59mE+crJhi86tZkQ9isLae5BiLNRDR342rJ4zOmIkYkW/kNQwRcde9weWMdolmjZvTFFo2UVSR2PvtE00f0uYeq3sqMRu66XnpFdWvzh9Rnga/5xzzolvJ795NuzoQsPrkWcbzT5P9MXKCHA0SGOu8WSYGWS4K7gOj4g2EWTDq7D//vsnGcrqgjBlypRameMOTcwUQR7kIBpprbjDFVjMC0HIOggxBtF8QhVXhKL9hV//+teJu7CNN9447LTTTokLtgkTJuQWG7d98iAEIaEgdtyw3XbbJfHkAciN088bMtQPskY/iAYfxAwQJk2aFOQlEHbYYYeAC79BFNzUiXkowXjatGlJWV/ykpeUFlUUmXDppZcG+vjMmTOTupZGGsYAQtyJuznqh5tL+plo72H77bcPz372sxsticxBBZlXSfqAmPvClltumfQD/BgX9fdGC9WHxEcNsYMdPhYhdhlWBfyb1pWRQOx16+ThHQFHYOwh0Bixoy2h5WWJDIuCrBvOutXxNbQXtAIZtgWZeEocEceJyTrnsO+++8aX0984tkUGWWNPC+snjoAj4AjkINAYsefkl1yWD1CSoWRRmDr3Vq1aFfCSjsikWRCbbaaJAi1+8uTJpUk7sZdC5AEcAUdggBHoObHLxF/A3lkkm2++eZgxY0ZRkFr3VqxYEZYtWxZk4inIxE2YOHFiZnxszbJkL/OevchoY/r06faSnzsCjoAjMGIQ6Dmx96PmTCaNHz++H1l7no6AI+AIDBwCo4LYBw5VL5Aj4Ag4An1EwIm9j+B71o6AI+AINIGAE3sTqHqajoAj4Aj0EQEn9j6C71k7Ao6AI9AEAk7sTaDqaToCjoAj0EcEnNj7CL5n7Qg4Ao5AEwg4sTeBqqfpCDgCjkAfEXBi7yP4nrUj4Ag4Ak0g4MTeBKqepiPgCDgCfUTAib2P4HvWjoAj4Ag0gYATexOoepqOgCPgCPQRASf2PoLvWTsCjoAj0AQCTuxNoOppOgKOgCPQRwSc2PsIvmftCDgCjkATCDixN4Gqp+kIOAKOQB8R+B/vYDO0KfsGLAAAAABJRU5ErkJggg==)\n",
    "![image.png](data:image/png;base64,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)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_b25RnwonwV2",
    "outputId": "94fc223a-b8c1-4c38-cb37-f2d9faa004ca"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "mean_Y = np.sum(mu_cond)\n",
    "var_Y = cal_Var_Y(sigma_cond)\n",
    "\n",
    "percentile_95_Y = norm.ppf(service_level, loc=mean_Y, scale=np.sqrt(var_Y))\n",
    "\n",
    "# Generate normal distribution data\n",
    "x_values = np.linspace(mean_Y - 4 * np.sqrt(var_Y), mean_Y + 4 * np.sqrt(var_Y), 1000)\n",
    "y_values = norm.pdf(x_values, loc=mean_Y, scale=np.sqrt(var_Y))\n",
    "\n",
    "# Create dataframe\n",
    "data = pd.DataFrame({\"x\": x_values, \"y\": y_values})\n",
    "\n",
    "# Plot distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data[\"x\"], data[\"y\"], color=\"blue\")\n",
    "plt.axvline(x=percentile_95_Y, color=\"red\", linestyle=\"dashed\")\n",
    "plt.fill_between(\n",
    "    data[\"x\"], data[\"y\"], where=(data[\"x\"] <= percentile_95_Y), color=\"red\", alpha=0.3\n",
    ")\n",
    "plt.title(\"Distribution of X3 + X4\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.annotate(\n",
    "    \"95th Percentile\",\n",
    "    xy=(percentile_95_Y, max(y_values)),\n",
    "    xytext=(percentile_95_Y, max(y_values) * 1.1),\n",
    "    arrowprops=dict(facecolor=\"red\", shrink=0.05),\n",
    "    color=\"red\",\n",
    "    ha=\"center\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9unedSCMe4Lt"
   },
   "source": [
    "```\n",
    "以下為 R 程式結果\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fcBXYzDZZJg0"
   },
   "source": [
    "![image.png](data:image/png;base64,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)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbc-cfXeKUWl"
   },
   "source": [
    "P(X3,X4∣X1=10,X2=20) 的 R 計算如下\n",
    "\n",
    "```\n",
    "install.packages(\"condMVNorm\")\n",
    "install.packages(\"mvtnorm\")\n",
    "library(condMVNorm)\n",
    "library(mvtnorm)\n",
    "library(ggplot2)\n",
    "\n",
    "# Define the mean vector and covariance matrix\n",
    "mu <- c(10, 20, 30, 40)\n",
    "sigma <- matrix(c(\n",
    "    5, 1, 0, 2,\n",
    "    1, 8, 1, 0,\n",
    "    0, 1, 10, 1,\n",
    "    2, 0, 1, 7\n",
    "), nrow = 4, byrow = TRUE)\n",
    "\n",
    "# Observed values of X1 and X2\n",
    "x_observed <- c(6, 30)\n",
    "\n",
    "# Compute the conditional mean and covariance using condMVNorm\n",
    "conditional_results <- condMVN(mean = mu, sigma = sigma, dependent.ind = c(3, 4), given.ind = c(1, 2), X.given = x_observed)\n",
    "\n",
    "# Print the conditional mean and covariance\n",
    "print(conditional_results$condMean)\n",
    "print(conditional_results$condVar)\n",
    "\n",
    "# Extract the conditional mean and covariance\n",
    "mu_cond <- conditional_results$condMean\n",
    "Sigma_cond <- conditional_results$condVar\n",
    "\n",
    "# Print the conditional mean and covariance\n",
    "print(mu_cond)\n",
    "print(Sigma_cond)\n",
    "\n",
    "# Values at which to evaluate the PDF and CDF\n",
    "x_values <- c(30, 40)\n",
    "\n",
    "# Calculate the PDF\n",
    "pdf_value <- dmvnorm(x_values, mean = mu_cond, sigma = Sigma_cond)\n",
    "cat(\"Conditional density at X3 =\", x_values[1], \", X4 =\", x_values[2], \": \", pdf_value, \"\\n\")\n",
    "\n",
    "# Calculate the CDF\n",
    "cdf_value <- pmvnorm(upper = x_values, mean = mu_cond, sigma = Sigma_cond)\n",
    "cat(\"Conditional cumulative probability up to X3 =\", x_values[1], \", X4 =\", x_values[2], \": \", cdf_value, \"\\n\")\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gsOfLgI-tdM"
   },
   "source": [
    "#### Conditional mean and variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "77QPjnQS-zHN",
    "outputId": "7531e890-df7f-4c69-ad05-c1ca3455641a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "公式計算的Y的均值: 5\n",
      "公式計算的Y的方差: 3.0\n",
      "模擬計算的Y的均值: 5.01077089723792\n",
      "模擬計算的Y的方差: 2.9701945334779807\n"
     ]
    }
   ],
   "source": [
    "def cal_Var_Y(sigma_cond):\n",
    "    variances = np.diag(sigma_cond)\n",
    "    covariances_sum = np.sum(sigma_cond) - np.sum(variances)\n",
    "    total_variance = np.sum(variances) + covariances_sum\n",
    "\n",
    "    return total_variance\n",
    "\n",
    "\n",
    "def simulate_Y(mu_cond, sigma_cond, num_samples=10000):\n",
    "    samples = np.random.multivariate_normal(mu_cond, sigma_cond, num_samples)\n",
    "\n",
    "    Y = samples[:, 0] + samples[:, 1]\n",
    "\n",
    "    mean_Y = np.mean(Y)\n",
    "    var_Y = np.var(Y)\n",
    "\n",
    "    return mean_Y, var_Y\n",
    "\n",
    "\n",
    "mu_cond = [2, 3]\n",
    "sigma_cond = [[1, 0.5], [0.5, 1]]\n",
    "\n",
    "mean_Y_formula = np.sum(mu_cond)\n",
    "var_Y_formula = cal_Var_Y(sigma_cond)\n",
    "\n",
    "mean_Y_simulated, var_Y_simulated = simulate_Y(mu_cond, sigma_cond)\n",
    "\n",
    "print(f\"公式計算的Y的均值: {mean_Y_formula}\")\n",
    "print(f\"公式計算的Y的方差: {var_Y_formula}\")\n",
    "print(f\"模擬計算的Y的均值: {mean_Y_simulated}\")\n",
    "print(f\"模擬計算的Y的方差: {var_Y_simulated}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Teqw8lLAkV9"
   },
   "source": [
    "### Calculate Qk hat for 2~T-1 of demand_df_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_df_train = demand_folds[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZO2S6yw1pl0Q",
    "outputId": "6ab08c48-dc46-4e6f-8102-41f13107803f"
   },
   "outputs": [],
   "source": [
    "_, _ = cal_mu_and_cov_matrix(demand_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ZFqe6xB10hB",
    "outputId": "e49ad786-9c88-42d3-a91a-c742572252a7"
   },
   "outputs": [],
   "source": [
    "mu_matrix, covariance_matrix = cal_mu_and_cov_matrix(demand_df)\n",
    "Qk_hat_df = make_Qk_hat_df(demand_df, T, service_level, mu_matrix, covariance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u63PjHtxm9Di",
    "outputId": "d8b1fb44-98b2-4c85-c9b6-115c73b0d241"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Qk_hat_k2</th>\n",
       "      <th>Qk_hat_k3</th>\n",
       "      <th>Qk_hat_k4</th>\n",
       "      <th>Qk_hat_k5</th>\n",
       "      <th>Qk_hat_k6</th>\n",
       "      <th>Qk_hat_k7</th>\n",
       "      <th>Qk_hat_k8</th>\n",
       "      <th>Qk_hat_k9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2559.273366</td>\n",
       "      <td>2555.425299</td>\n",
       "      <td>2557.763194</td>\n",
       "      <td>2549.249085</td>\n",
       "      <td>2554.148448</td>\n",
       "      <td>2554.148449</td>\n",
       "      <td>2545.961968</td>\n",
       "      <td>2539.645932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2551.930233</td>\n",
       "      <td>2522.990411</td>\n",
       "      <td>2524.289216</td>\n",
       "      <td>2517.679819</td>\n",
       "      <td>2514.363727</td>\n",
       "      <td>2514.363727</td>\n",
       "      <td>2510.788668</td>\n",
       "      <td>2503.450474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3014.804803</td>\n",
       "      <td>2932.075551</td>\n",
       "      <td>2932.265875</td>\n",
       "      <td>2927.629736</td>\n",
       "      <td>2919.000411</td>\n",
       "      <td>2919.000411</td>\n",
       "      <td>2910.642312</td>\n",
       "      <td>2907.106851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2930.526293</td>\n",
       "      <td>2902.474153</td>\n",
       "      <td>2902.959321</td>\n",
       "      <td>2897.311015</td>\n",
       "      <td>2891.561732</td>\n",
       "      <td>2891.561732</td>\n",
       "      <td>2893.322961</td>\n",
       "      <td>2891.311413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3020.225009</td>\n",
       "      <td>2950.255189</td>\n",
       "      <td>2948.788280</td>\n",
       "      <td>2946.578934</td>\n",
       "      <td>2953.074687</td>\n",
       "      <td>2953.074688</td>\n",
       "      <td>2951.745745</td>\n",
       "      <td>2948.982952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>706.169241</td>\n",
       "      <td>669.069453</td>\n",
       "      <td>667.286387</td>\n",
       "      <td>638.766247</td>\n",
       "      <td>632.587325</td>\n",
       "      <td>632.587325</td>\n",
       "      <td>631.232001</td>\n",
       "      <td>627.830560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>662.169842</td>\n",
       "      <td>642.362767</td>\n",
       "      <td>643.332936</td>\n",
       "      <td>640.100084</td>\n",
       "      <td>639.989902</td>\n",
       "      <td>639.989902</td>\n",
       "      <td>637.757982</td>\n",
       "      <td>634.249271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>716.885029</td>\n",
       "      <td>705.000093</td>\n",
       "      <td>705.875232</td>\n",
       "      <td>699.058314</td>\n",
       "      <td>697.126057</td>\n",
       "      <td>697.126057</td>\n",
       "      <td>694.651961</td>\n",
       "      <td>694.234330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>674.601122</td>\n",
       "      <td>680.804922</td>\n",
       "      <td>680.885918</td>\n",
       "      <td>675.930202</td>\n",
       "      <td>675.975899</td>\n",
       "      <td>675.975900</td>\n",
       "      <td>674.927444</td>\n",
       "      <td>672.471691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>641.730161</td>\n",
       "      <td>605.137515</td>\n",
       "      <td>603.816064</td>\n",
       "      <td>609.452235</td>\n",
       "      <td>604.236425</td>\n",
       "      <td>604.236425</td>\n",
       "      <td>603.857140</td>\n",
       "      <td>597.290659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Qk_hat_k2    Qk_hat_k3    Qk_hat_k4    Qk_hat_k5    Qk_hat_k6  \\\n",
       "0   2559.273366  2555.425299  2557.763194  2549.249085  2554.148448   \n",
       "1   2551.930233  2522.990411  2524.289216  2517.679819  2514.363727   \n",
       "2   3014.804803  2932.075551  2932.265875  2927.629736  2919.000411   \n",
       "3   2930.526293  2902.474153  2902.959321  2897.311015  2891.561732   \n",
       "4   3020.225009  2950.255189  2948.788280  2946.578934  2953.074687   \n",
       "..          ...          ...          ...          ...          ...   \n",
       "85   706.169241   669.069453   667.286387   638.766247   632.587325   \n",
       "86   662.169842   642.362767   643.332936   640.100084   639.989902   \n",
       "87   716.885029   705.000093   705.875232   699.058314   697.126057   \n",
       "88   674.601122   680.804922   680.885918   675.930202   675.975899   \n",
       "89   641.730161   605.137515   603.816064   609.452235   604.236425   \n",
       "\n",
       "      Qk_hat_k7    Qk_hat_k8    Qk_hat_k9  \n",
       "0   2554.148449  2545.961968  2539.645932  \n",
       "1   2514.363727  2510.788668  2503.450474  \n",
       "2   2919.000411  2910.642312  2907.106851  \n",
       "3   2891.561732  2893.322961  2891.311413  \n",
       "4   2953.074688  2951.745745  2948.982952  \n",
       "..          ...          ...          ...  \n",
       "85   632.587325   631.232001   627.830560  \n",
       "86   639.989902   637.757982   634.249271  \n",
       "87   697.126057   694.651961   694.234330  \n",
       "88   675.975900   674.927444   672.471691  \n",
       "89   604.236425   603.857140   597.290659  \n",
       "\n",
       "[90 rows x 8 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qk_hat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5PqgJQzymc9c"
   },
   "source": [
    "### Plot the distribuction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H5rCKosmEf1a",
    "outputId": "8c1b9eb9-a602-473a-cb5a-9034f367148b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_star is: 3058.3454877772897\n",
      "Early bias: -1330.4694728557483\n",
      "Mid bias: -1347.85574711975\n",
      "Late bias: -1352.7191141247265\n"
     ]
    }
   ],
   "source": [
    "# 將 T 個時期分成三份\n",
    "early_values = Qk_hat_df.iloc[:, : T // 3].mean(axis=1)\n",
    "mid_values = Qk_hat_df.iloc[:, T // 3 : 2 * T // 3].mean(axis=1)\n",
    "late_values = Qk_hat_df.iloc[:, 2 * T // 3 :].mean(axis=1)\n",
    "\n",
    "# 計算與 Q_star 的差距\n",
    "early_diff = early_values - Q_star\n",
    "mid_diff = mid_values - Q_star\n",
    "late_diff = late_values - Q_star\n",
    "\n",
    "# 繪製直方圖\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# 早期\n",
    "plt.hist(early_diff, bins=10, alpha=0.5, label=\"Early\", color=\"blue\", edgecolor=\"black\")\n",
    "# 中期\n",
    "plt.hist(mid_diff, bins=10, alpha=0.5, label=\"Mid\", color=\"green\", edgecolor=\"black\")\n",
    "# 晚期\n",
    "plt.hist(late_diff, bins=10, alpha=0.5, label=\"Late\", color=\"red\", edgecolor=\"black\")\n",
    "\n",
    "plt.axvline(0, color=\"grey\", linestyle=\"--\")\n",
    "\n",
    "plt.xlabel(\"Difference from Q star\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of Differences from Q star at Different Times\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 計算偏差\n",
    "early_bias = np.mean(early_diff)\n",
    "mid_bias = np.mean(mid_diff)\n",
    "late_bias = np.mean(late_diff)\n",
    "\n",
    "print(f\"Q_star is: {Q_star}\")\n",
    "print(f\"Early bias: {early_bias}\")\n",
    "print(f\"Mid bias: {mid_bias}\")\n",
    "print(f\"Late bias: {late_bias}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EdNJAb6XEzwb",
    "outputId": "e157524f-5345-410d-e5a8-1bec824f9606"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 繪製直方圖\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 18))\n",
    "\n",
    "# 早期\n",
    "axes[0].hist(early_diff, bins=10, alpha=0.5, color=\"blue\", edgecolor=\"black\")\n",
    "axes[0].axvline(0, color=\"grey\", linestyle=\"--\")\n",
    "axes[0].set_title(\"Early\")\n",
    "axes[0].set_xlabel(\"Difference from Q star\")\n",
    "axes[0].set_ylabel(\"Frequency\")\n",
    "\n",
    "# 中期\n",
    "axes[1].hist(mid_diff, bins=10, alpha=0.5, color=\"green\", edgecolor=\"black\")\n",
    "axes[1].axvline(0, color=\"grey\", linestyle=\"--\")\n",
    "axes[1].set_title(\"Mid\")\n",
    "axes[1].set_xlabel(\"Difference from Q star\")\n",
    "axes[1].set_ylabel(\"Frequency\")\n",
    "\n",
    "# 晚期\n",
    "axes[2].hist(late_diff, bins=10, alpha=0.5, color=\"red\", edgecolor=\"black\")\n",
    "axes[2].axvline(0, color=\"grey\", linestyle=\"--\")\n",
    "axes[2].set_title(\"Late\")\n",
    "axes[2].set_xlabel(\"Difference from Q star\")\n",
    "axes[2].set_ylabel(\"Frequency\")\n",
    "\n",
    "fig.suptitle(\"Histogram of Differences from Q star at Different Times\")\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDilezxfOmIe"
   },
   "source": [
    "# Strategies utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the r and R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gurobipy as gp\n",
    "# from gurobipy import GRB\n",
    "\n",
    "# # 初始化模型\n",
    "# # model = gp.Model(\"Test_r_R_relationship\")\n",
    "# model = gp.Model(env=env)\n",
    "\n",
    "# # 設定參數\n",
    "# K = 4  # 候選數量\n",
    "# i = 0  # 單個 i 的例子\n",
    "\n",
    "# # 定義變數\n",
    "# r_vars = model.addVars(K, lb=0.0, ub=1.0, name=\"r_vars\")  # r_{i,k}\n",
    "# R_vars = model.addVars(K, vtype=GRB.BINARY, name=\"R_vars\")  # R_{i,k}\n",
    "# max_r_helper = model.addVar(lb=0.0, ub=1.0, name=\"max_r_helper\")  # 最大值輔助變數\n",
    "\n",
    "# # 假設 exp_tau_vars 是已知的輸入數值\n",
    "# exp_tau_vars = [0.1, 0.3, 0.5, 0.2]  # 例子數值\n",
    "\n",
    "# # 限制式 1: 定義 r_vars 與 exp_tau_vars 的關係\n",
    "# for k in range(K):\n",
    "#     model.addConstr(\n",
    "#         r_vars[k] * sum(exp_tau_vars) == exp_tau_vars[k],\n",
    "#         name=f\"softmax_relation_{k}\",\n",
    "#     )\n",
    "\n",
    "# # 限制式 2: 確保 r_vars 的加總為 1\n",
    "# model.addConstr(gp.quicksum(r_vars[k] for k in range(K)) == 1, name=\"sum_r_constraint\")\n",
    "\n",
    "# # 限制式 3: 找出 r_vars 中的最大值\n",
    "# model.addGenConstrMax(\n",
    "#     max_r_helper, [r_vars[k] for k in range(K)], name=\"max_r_constraint\"\n",
    "# )\n",
    "\n",
    "# # 限制式 4: 確保 R_vars 對應到最大值\n",
    "# for k in range(K):\n",
    "#     model.addGenConstrIndicator(\n",
    "#         R_vars[k], 1, r_vars[k] == max_r_helper, name=f\"indicator_R_{k}\"\n",
    "#     )\n",
    "\n",
    "# # 限制式 5: 確保僅有一個 R_vars[k] 為 1\n",
    "# model.addConstr(\n",
    "#     gp.quicksum(R_vars[k] for k in range(K)) == 1, name=\"unique_R_constraint\"\n",
    "# )\n",
    "\n",
    "# # 設定目標函數（範例：最大化 max_r_helper）\n",
    "# model.setObjective(max_r_helper, GRB.MAXIMIZE)\n",
    "\n",
    "# # 求解模型\n",
    "# model.optimize()\n",
    "\n",
    "# # 輸出結果\n",
    "# if model.Status == GRB.OPTIMAL:\n",
    "#     print(\"Optimal solution found!\")\n",
    "#     print(f\"max_r_helper: {max_r_helper.X}\")\n",
    "#     print(\"r_vars:\")\n",
    "#     for k in range(K):\n",
    "#         print(f\"  r_vars[{k}]: {r_vars[k].X}\")\n",
    "#     print(\"R_vars:\")\n",
    "#     for k in range(K):\n",
    "#         print(f\"  R_vars[{k}]: {R_vars[k].X}\")\n",
    "# else:\n",
    "#     print(\"No optimal solution found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "檢驗結果：目前的寫法可以成功讓 r 與 R 的關係實現\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8oJyOCv3Oqap"
   },
   "source": [
    "## S0 - One-time Procurement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "iMoKgd_XO05c"
   },
   "outputs": [],
   "source": [
    "def one_time_procurement(Q_star, demand_df, cost, price, salvage_value):\n",
    "\n",
    "    all_losses = []\n",
    "    all_lefts = []\n",
    "    all_operation_profits = []\n",
    "    all_profits = []\n",
    "\n",
    "    for i, row in demand_df.iterrows():\n",
    "        inventory = Q_star\n",
    "        losses = []\n",
    "        lefts = []\n",
    "        daily_operation_profits = []\n",
    "        daily_profits = []\n",
    "        total_sold = 0  # 追蹤總售出量\n",
    "        total_lost = 0  # 追蹤總丟失量\n",
    "\n",
    "        # print(\"=\" * 50)\n",
    "        # print(\n",
    "        #     f\"Processing row {i+1}/{len(demand_df)} with initial inventory Q_star={Q_star}\"\n",
    "        # )\n",
    "        # print(\"=\" * 50)\n",
    "\n",
    "        for day, demand in enumerate(row):\n",
    "            sales = min(inventory, demand)\n",
    "            loss = max(demand - inventory, 0)\n",
    "            left = max(inventory - sales, 0)\n",
    "            total_sold += sales\n",
    "            total_lost += loss\n",
    "\n",
    "            inventory -= sales\n",
    "\n",
    "            # print(\"-\" * 50)\n",
    "            # print(f\"Day {day+1}\")\n",
    "            # print(f\"Demand      : {demand}\")\n",
    "            # print(f\"Sales       : {sales}\")\n",
    "            # print(f\"Loss        : {loss}\")\n",
    "            # print(f\"Left        : {left}\")\n",
    "            # print(f\"Inventory   : {inventory}\")\n",
    "            # print(\"-\" * 50)\n",
    "\n",
    "            if day == len(row) - 1:\n",
    "                left_penalty_cost = (cost - salvage_value) * left\n",
    "                lefts.append(left)\n",
    "                # print(f\"End of period: Left Penalty Cost = {left_penalty_cost}\")\n",
    "                # print(\"-\" * 50)\n",
    "            else:\n",
    "                left_penalty_cost = 0\n",
    "\n",
    "        operation_profit = (price - cost) * total_sold\n",
    "        profit = operation_profit - left_penalty_cost - (price - cost) * total_lost\n",
    "\n",
    "        # print(\"=\" * 50)\n",
    "        # print(f\"Row {i+1} Summary\")\n",
    "        # print(f\"Total Sold         : {total_sold}\")\n",
    "        # print(f\"Total Lost         : {total_lost}\")\n",
    "        # print(f\"Operation Profit   : {operation_profit}\")\n",
    "        # print(f\"Profit             : {profit}\")\n",
    "        # print(\"=\" * 50)\n",
    "\n",
    "        all_losses.append(total_lost)\n",
    "        all_lefts.append(sum(lefts))\n",
    "        all_operation_profits.append(operation_profit)\n",
    "        all_profits.append(profit)\n",
    "\n",
    "    avg_losses = np.mean(all_losses)\n",
    "    avg_lefts = np.mean(all_lefts)\n",
    "    avg_operation_profits = np.mean(all_operation_profits)\n",
    "    avg_profits = np.mean(all_profits)\n",
    "\n",
    "    # print(\"=\" * 50)\n",
    "    # print(\"Overall Summary\")\n",
    "    # print(f\"Average Losses           : {avg_losses}\")\n",
    "    # print(f\"Average Lefts            : {avg_lefts}\")\n",
    "    # print(f\"Average Operation Profits: {avg_operation_profits}\")\n",
    "    # print(f\"Average Profits          : {avg_profits}\")\n",
    "    # print(\"=\" * 50)\n",
    "\n",
    "    stimulation_df = pd.DataFrame(\n",
    "        {\n",
    "            \"losses\": all_losses,\n",
    "            \"lefts\": all_lefts,\n",
    "            \"operation_profits\": all_operation_profits,\n",
    "            \"profits\": all_profits,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return avg_losses, avg_lefts, avg_profits, avg_operation_profits, stimulation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gmHkLPVROtLN"
   },
   "source": [
    "## S1 - Grid for Fixed F & Fixed Rk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "iCm5WosfO_l-"
   },
   "outputs": [],
   "source": [
    "def cal_fixed_F_fixed_R(\n",
    "    Q_star, assigned_F, assigned_R, demand_df, cost, price, salvage_value, Qk_hat_df\n",
    "):\n",
    "    all_losses = []\n",
    "    all_lefts = []\n",
    "    all_left0s = []\n",
    "    all_left1s = []\n",
    "    all_operation_profits = []\n",
    "    all_profits = []\n",
    "    all_q0s = []\n",
    "    all_q1s = []\n",
    "\n",
    "    Q0 = assigned_F * Q_star  # 期初庫存\n",
    "\n",
    "    # print(f\"\\n\")\n",
    "    # print(f\"====\" * 10)\n",
    "    # print(f\"\\n\")\n",
    "\n",
    "    for i, row in demand_df.iterrows():\n",
    "\n",
    "        # 第一階段計算\n",
    "        total_sold_0 = min(Q0, row[: assigned_R + 1].sum())  # 第一階段售出量\n",
    "        left_0 = max(Q0 - total_sold_0, 0)  # 第一階段剩餘\n",
    "        lost_0 = max((row[: assigned_R + 1].sum() - Q0), 0)\n",
    "\n",
    "        # 第二階段開始補貨，根據指定的 R\n",
    "        Qk_hat = Qk_hat_df.iloc[i, assigned_R]\n",
    "        Q1 = max((Qk_hat - Q0), 0)  # 二次訂貨量\n",
    "        total_sold_1 = min(Q1 + left_0, row[assigned_R + 1 :].sum())  # 第二階段售出量\n",
    "        left_1 = max((Q1 + left_0) - total_sold_1, 0)  # 第二階段剩餘\n",
    "        lost_1 = max(row[assigned_R + 1 :].sum() - (Q1 + left_0), 0)\n",
    "\n",
    "        # 統計\n",
    "        total_sold = total_sold_0 + total_sold_1\n",
    "        total_lost = lost_0 + lost_1\n",
    "        total_left = left_0 + left_1\n",
    "\n",
    "        # 計算運營利潤和總利潤\n",
    "        operation_profit = (price - cost) * total_sold\n",
    "\n",
    "        # left_penalty_cost = (cost - salvage_value) * left_1\n",
    "        left_penalty_cost = (cost - salvage_value) * total_left\n",
    "        lost_penalty_cost = (price - cost) * total_lost\n",
    "\n",
    "        profit = operation_profit - left_penalty_cost - lost_penalty_cost\n",
    "\n",
    "        all_losses.append(total_lost)\n",
    "        all_lefts.append(total_left)\n",
    "        all_operation_profits.append(operation_profit)\n",
    "        all_profits.append(profit)\n",
    "        all_q0s.append(Q0)\n",
    "        all_q1s.append(Q1)\n",
    "        all_left0s.append(left_0)\n",
    "        all_left1s.append(left_1)\n",
    "\n",
    "        # print(f\"這是第 {i+1} 筆模擬資料\\n\")\n",
    "        # print(f\"F: {assigned_F}, R: {assigned_R+2}\")\n",
    "        # print(f\"Q_star 為 {Q_star}\")\n",
    "        # print(f\"期初庫存 Q0: {Q0}\")\n",
    "        # print(f\"重新估計量 Qk_hat: {Qk_hat}\")\n",
    "        # print(f\"訂貨量 Q1 為 {Q1}\\n\")\n",
    "\n",
    "        # print(\n",
    "        #     f\"第一階段：期初庫存 Q0: {Q0}，需求量為 {row[:assigned_R + 1].sum()}，Sold_0 為 {total_sold_0}，Left_0 為 {left_0}，Lost_0 為 {lost_0}\"\n",
    "        # )\n",
    "        # print(\n",
    "        #     f\"第二階段：期初庫存 Q1+left_0 為 {Q1+left_0}，需求量為 {row[assigned_R + 1:].sum()}，Sold_1 為 {total_sold_1}，Left_1 為 {left_1}，Lost_1 為 {lost_1}\\n\"\n",
    "        # )\n",
    "        # print(\n",
    "        #     f\"統計結果：Sold 為 {total_sold}, Lost 為 {total_lost} Left_Penalty_Cost 為 {left_penalty_cost}，Lost_Penalty_Cost 為 {lost_penalty_cost}，Profit 為 {profit}\"\n",
    "        # )\n",
    "        # print(\"----\" * 10)\n",
    "\n",
    "    result_df = {\n",
    "        \"R(T)\": assigned_R + 2,\n",
    "        \"F\": assigned_F,\n",
    "        \"Q0\": all_q0s,\n",
    "        \"Q1\": all_q1s,\n",
    "        \"average_profits\": np.mean(all_profits),\n",
    "        \"average_losses\": np.mean(all_losses),\n",
    "        \"average_lefts\": np.mean(all_lefts),\n",
    "        \"average_operation_profits\": np.mean(all_operation_profits),\n",
    "    }\n",
    "\n",
    "    stimulation_result = {\n",
    "        \"R(T)\": assigned_R + 2,\n",
    "        \"F\": assigned_F,\n",
    "        \"profits\": all_profits,\n",
    "        \"losses\": all_losses,\n",
    "        \"lefts\": all_lefts,\n",
    "        \"Left0s\": all_left0s,\n",
    "        \"Left1s\": all_left1s,\n",
    "        \"operation_profits\": all_operation_profits,\n",
    "        \"Q0\": all_q0s,\n",
    "        \"Q1\": all_q1s,\n",
    "    }\n",
    "\n",
    "    return result_df, stimulation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "4OJpJmXYZ3nm"
   },
   "outputs": [],
   "source": [
    "def grid_fixed_F_fixed_R(\n",
    "    assigned_Ts,\n",
    "    assigned_Fs,\n",
    "    cost,\n",
    "    price,\n",
    "    salvage_value,\n",
    "    Qk_hat_df,\n",
    "    demand_df_train,\n",
    "    Q_star,\n",
    "):\n",
    "\n",
    "    results_list = []\n",
    "    max_profit = None\n",
    "    max_profit_stimulation_result = {}\n",
    "\n",
    "    for assigned_T in assigned_Ts:\n",
    "        for assigned_F in assigned_Fs:\n",
    "            assigned_R = assigned_T - 2\n",
    "            mean_result, stimulation_result = cal_fixed_F_fixed_R(\n",
    "                Q_star,\n",
    "                assigned_F,\n",
    "                assigned_R,\n",
    "                demand_df_train,\n",
    "                cost,\n",
    "                price,\n",
    "                salvage_value,\n",
    "                Qk_hat_df,\n",
    "            )\n",
    "            results_list.append(mean_result)\n",
    "\n",
    "            if max_profit is None or max_profit < mean_result[\"average_profits\"]:\n",
    "                # print(\n",
    "                #     f\"max_profit is changed from {max_profit} to {mean_result['average_profits']}\"\n",
    "                # )\n",
    "                max_profit = mean_result[\"average_profits\"]\n",
    "                max_profit_stimulation_result = stimulation_result\n",
    "\n",
    "    results_df_1 = pd.DataFrame(results_list).sort_values(\n",
    "        by=\"average_profits\", ascending=False\n",
    "    )\n",
    "\n",
    "    return results_df_1, pd.DataFrame(max_profit_stimulation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S8 - Grid for Fixed F & Fixed Rk(with holding cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_fixed_F_fixed_R_with_holding_cost(\n",
    "    Q_star,\n",
    "    assigned_F,\n",
    "    assigned_R,\n",
    "    demand_df,\n",
    "    cost,\n",
    "    price,\n",
    "    salvage_value,\n",
    "    Qk_hat_df,\n",
    "    holding_cost,\n",
    "):\n",
    "    all_losses = []\n",
    "    all_lefts = []\n",
    "    all_operation_profits = []\n",
    "    all_profits = []\n",
    "    all_q0s = []\n",
    "    all_q1s = []\n",
    "    all_holding_costs_0 = []\n",
    "    all_holding_costs_1 = []\n",
    "    all_left0s = []\n",
    "    all_left1s = []\n",
    "    all_lost0s = []\n",
    "    all_lost1s = []\n",
    "\n",
    "    Q0 = assigned_F * Q_star  # 期初庫存\n",
    "\n",
    "    # print(f\"\\n\")\n",
    "    # print(f\"====\" * 10)\n",
    "    # print(f\"\\n\")\n",
    "\n",
    "    for i, row in demand_df.iterrows():\n",
    "\n",
    "        # 第一階段計算\n",
    "        total_sold_0 = min(Q0, row[: assigned_R + 1].sum())  # 第一階段售出量\n",
    "        left_0 = max(Q0 - total_sold_0, 0)  # 第一階段剩餘\n",
    "        lost_0 = max(row[: assigned_R + 1].sum() - Q0, 0)\n",
    "\n",
    "        # 第二階段開始補貨，根據指定的 R\n",
    "        Qk_hat = Qk_hat_df.iloc[i, assigned_R]\n",
    "        Q1 = max((Qk_hat - Q0), 0)  # 二次訂貨量\n",
    "        total_sold_1 = min(Q1 + left_0, row[assigned_R + 1 :].sum())  # 第二階段售出量\n",
    "        left_1 = max((Q1 + left_0) - total_sold_1, 0)  # 第二階段剩餘\n",
    "        lost_1 = max(row[assigned_R + 1 :].sum() - (Q1 + left_0), 0)\n",
    "\n",
    "        # 統計\n",
    "        total_sold = total_sold_0 + total_sold_1\n",
    "        total_lost = lost_0 + lost_1\n",
    "\n",
    "        # 計算 holding_cost\n",
    "        \"\"\"\n",
    "        今天 T = 10, 假設 R = 5 (此時 assigned_R=3), 此時:\n",
    "        第一階段是 T=1~4 -> 高為 R-1 = (assigned_R+2) - 1\n",
    "        第二階段是 T=5~10 -> 高為 T - R = T - (assigned_R+2)\n",
    "        \"\"\"\n",
    "\n",
    "        first_holding_cost = (Q0 + left_0 + Q1) * ((assigned_R + 2) - 1) / 2\n",
    "        # T = 1 ~ R+1, R+1 才是代表 R(T)\n",
    "        second_holding_cost = (Q1 + left_0 + left_1) * (T - (assigned_R + 2)) / 2\n",
    "        # T = R+1 ~ T\n",
    "        holding_penalty = holding_cost * (first_holding_cost + second_holding_cost)\n",
    "\n",
    "        # 計算運營利潤和總利潤\n",
    "        operation_profit = (price - cost) * total_sold\n",
    "        left_penalty_cost = (cost - salvage_value) * left_1\n",
    "        lost_penalty_cost = (price - cost) * total_lost\n",
    "        profit = (\n",
    "            operation_profit - left_penalty_cost - lost_penalty_cost - holding_penalty\n",
    "        )\n",
    "\n",
    "        all_losses.append(total_lost)\n",
    "        all_lefts.append(left_1)\n",
    "        all_operation_profits.append(operation_profit)\n",
    "        all_profits.append(profit)\n",
    "        all_q0s.append(Q0)\n",
    "        all_q1s.append(Q1)\n",
    "        all_holding_costs_0.append(first_holding_cost)\n",
    "        all_holding_costs_1.append(second_holding_cost)\n",
    "        all_left0s.append(left_0)\n",
    "        all_left1s.append(left_1)\n",
    "        all_lost0s.append(lost_0)\n",
    "        all_lost1s.append(lost_1)\n",
    "\n",
    "        # print(f\"這是第 {i+1} 筆模擬資料\\n\")\n",
    "        # print(f\"F: {assigned_F}, R: {assigned_R+2}\")\n",
    "        # print(f\"Q_star 為 {Q_star}\")\n",
    "        # print(f\"期初庫存 Q0: {Q0}\")\n",
    "        # print(f\"重新估計量 Qk_hat: {Qk_hat}\")\n",
    "        # print(f\"訂貨量 Q1 為 {Q1}\\n\")\n",
    "\n",
    "        # print(\n",
    "        #     f\"第一階段：期初庫存 Q0: {Q0}，需求量為 {row[:assigned_R + 1].sum()}，Sold_0 為 {total_sold_0}，Left_0 為 {left_0}，Lost_0 為 {lost_0}, first_holding_cost 為 {first_holding_cost}\"\n",
    "        # )\n",
    "        # print(\n",
    "        #     f\"第二階段：期初庫存 Q1+left_0 為 {Q1+left_0}，需求量為 {row[assigned_R + 1:].sum()}，Sold_1 為 {total_sold_1}，Left_1 為 {left_1}，Lost_1 為 {lost_1}, second_holding_cost 為 {second_holding_cost}\\n\"\n",
    "        # )\n",
    "        # print(\n",
    "        #     f\"統計結果：Sold 為 {total_sold}, Lost 為 {total_lost} Left_Penalty_Cost 為 {left_penalty_cost}，Lost_Penalty_Cost 為 {lost_penalty_cost}，holding_penalty 為 {holding_penalty}，Profit 為 {profit}\"\n",
    "        # )\n",
    "        # print(\"----\" * 10)\n",
    "\n",
    "    result_df = {\n",
    "        \"R(T)\": assigned_R + 2,\n",
    "        \"F\": assigned_F,\n",
    "        \"Q0\": all_q0s,\n",
    "        \"Q1\": all_q1s,\n",
    "        \"average_profits\": np.mean(all_profits),\n",
    "        \"average_losses\": np.mean(all_losses),\n",
    "        \"average_lefts\": np.mean(all_lefts),\n",
    "        \"average_operation_profits\": np.mean(all_operation_profits),\n",
    "    }\n",
    "\n",
    "    stimulation_result = {\n",
    "        \"R(T)\": assigned_R + 2,\n",
    "        \"F\": assigned_F,\n",
    "        \"profits\": all_profits,\n",
    "        \"losses\": all_losses,\n",
    "        \"lefts\": all_lefts,\n",
    "        \"operation_profits\": all_operation_profits,\n",
    "        \"Q0\": all_q0s,\n",
    "        \"Q1\": all_q1s,\n",
    "        \"hc0\": all_holding_costs_0,\n",
    "        \"hc1\": all_holding_costs_1,\n",
    "        \"Left0s\": all_left0s,\n",
    "        \"Left1s\": all_left1s,\n",
    "        \"lost0s\": all_lost0s,\n",
    "        \"lost1s\": all_lost1s,\n",
    "    }\n",
    "\n",
    "    return result_df, stimulation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_fixed_F_fixed_R_with_holding_cost(\n",
    "    assigned_Ts,\n",
    "    assigned_Fs,\n",
    "    cost,\n",
    "    price,\n",
    "    salvage_value,\n",
    "    holding_cost,\n",
    "    Qk_hat_df,\n",
    "    demand_df_train,\n",
    "    Q_star,\n",
    "):\n",
    "\n",
    "    results_list = []\n",
    "    max_profit = None\n",
    "    max_profit_stimulation_result = {}\n",
    "\n",
    "    for assigned_T in assigned_Ts:\n",
    "        for assigned_F in assigned_Fs:\n",
    "            assigned_R = assigned_T - 2\n",
    "            mean_result, stimulation_result = cal_fixed_F_fixed_R_with_holding_cost(\n",
    "                Q_star,\n",
    "                assigned_F,\n",
    "                assigned_R,\n",
    "                demand_df_train,\n",
    "                cost,\n",
    "                price,\n",
    "                salvage_value,\n",
    "                Qk_hat_df,\n",
    "                holding_cost,\n",
    "            )\n",
    "            results_list.append(mean_result)\n",
    "\n",
    "            if max_profit is None or max_profit < mean_result[\"average_profits\"]:\n",
    "                # print(\n",
    "                #     f\"max_profit is changed from {max_profit} to {mean_result['average_profits']}\"\n",
    "                # )\n",
    "                max_profit = mean_result[\"average_profits\"]\n",
    "                max_profit_stimulation_result = stimulation_result\n",
    "\n",
    "    results_df_1 = pd.DataFrame(results_list).sort_values(\n",
    "        by=\"average_profits\", ascending=False\n",
    "    )\n",
    "\n",
    "    return results_df_1, pd.DataFrame(max_profit_stimulation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S2 - Grid for Fixed Rk & Flexible F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S17 - Grid for Fixed Rk & Flexible F with lasso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_flexible_F_fixed_R(\n",
    "    assigned_R,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_train,\n",
    "    Qk_hat_df,\n",
    "    training_df,\n",
    "    lambda_alpha,\n",
    "):\n",
    "    print(\n",
    "        f\"+++++++++++++++++++++++++++++++++++++++ THis is R={assigned_R} +++++++++++++++++++++++++++++++++++++++++++++++++\"\n",
    "    )\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "        model.setParam(\"NonConvex\", 2)\n",
    "        model.setParam(\"IntFeasTol\", 1e-9)\n",
    "        model.setParam(\"NumericFocus\", 3)\n",
    "\n",
    "        # ======================= Decision Variables =======================\n",
    "        alphas = model.addVars(\n",
    "            features_num + 1, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"alphas\"\n",
    "        )\n",
    "        abs_alphas = model.addVars(alphas.keys(), lb=0, name=\"abs_alpha\")\n",
    "\n",
    "        # 進行 L1 正則化處理：alphas\n",
    "        for i in alphas.keys():\n",
    "            model.addConstr(abs_alphas[i] >= alphas[i])\n",
    "            model.addConstr(abs_alphas[i] >= -alphas[i])\n",
    "\n",
    "        Sold_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_0\")\n",
    "        Left_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_0\")\n",
    "        Lost_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_0\")\n",
    "\n",
    "        Sold_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_1\")\n",
    "        Left_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_1\")\n",
    "        Lost_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_1\")\n",
    "\n",
    "        f_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"f_var\"\n",
    "        )\n",
    "        F_vars = model.addVars(len(demand_df_train), lb=0, ub=1, name=\"Fraction\")\n",
    "\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, ub=(Q_star + 1), name=\"Q0_var\"\n",
    "        )\n",
    "        Q1_vars = model.addVars(len(Qk_hat_df), lb=0.0, name=\"Q1_var\")\n",
    "\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, name=\"profits_vars\"\n",
    "        )\n",
    "\n",
    "        # ======================= Model Constraints =======================\n",
    "        for i, row in demand_df_train.iterrows():\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i].tolist()\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            model.addConstr(F_vars[i] >= 0, name=f\"Fraction_lower_bound_{i}\")\n",
    "            model.addConstr(F_vars[i] <= 1, name=f\"Fraction_upper_bound_{i}\")\n",
    "\n",
    "            # Calculate F using logistic regression\n",
    "            model.addConstr(\n",
    "                f_vars[i]\n",
    "                == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            )\n",
    "            model.addGenConstrLogistic(\n",
    "                xvar=f_vars[i], yvar=F_vars[i], options=\"FuncNonlinear=1\"\n",
    "            )\n",
    "\n",
    "            # Calculate initial order quantity\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star)\n",
    "\n",
    "            # Define demand variables for before and after reorder point\n",
    "            total_demand_before_R = demand_row[: assigned_R + 1].sum()\n",
    "            total_demand_after_R = demand_row[assigned_R + 1 :].sum()\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Left_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0s[i],\n",
    "                [total_demand_before_R, Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_before_R - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_before_R - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # Calculate Q1 based on reorder point estimate\n",
    "            Q_hat = Qk_hat_df_row[assigned_R]\n",
    "            Q_hat_adjusted = Q_hat - Q0_vars[i]\n",
    "            Q_hat_adjusted_var = model.addVar(\n",
    "                lb=-GRB.INFINITY, name=f\"Q_hat_adjusted_{i}\"\n",
    "            )\n",
    "            model.addConstr(Q_hat_adjusted_var == Q_hat_adjusted)\n",
    "\n",
    "            model.addGenConstrMax(\n",
    "                Q1_vars[i], [Q_hat_adjusted_var, 0], name=f\"max_Q1_constr_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1s[i],\n",
    "                [total_demand_after_R, Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_after_R - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_after_R - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # # Calculate holding costs directly in profit equation\n",
    "            # holding_cost_1 = (\n",
    "            #     (Q0_vars[i] + total_stock_second_period) * (assigned_R + 2 - 1) / 2\n",
    "            # )\n",
    "            # holding_cost_2 = (\n",
    "            #     (total_stock_second_period + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "            # )\n",
    "\n",
    "            # model.addConstr(\n",
    "            #     profits_vars[i]\n",
    "            #     == (\n",
    "            #         (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "            #         - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "            #         - (cost - salvage_value) * (Left_1s[i])  # left cost\n",
    "            #     ),\n",
    "            #     name=f\"Profit_Constraint_{i}\",\n",
    "            # )\n",
    "\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * (Left_0s[i] + Left_1s[i])  # left cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "        # Set objective\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train)))\n",
    "            - lambda_alpha * gp.quicksum(abs_alphas[i] for i in abs_alphas.keys()),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "\n",
    "        model.write(\"s17_model_debug.lp\")\n",
    "        model.write(\"s17_model.mps\")\n",
    "\n",
    "        # Solve model\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL or model.status == GRB.TIME_LIMIT:\n",
    "                print(f\"Model status: {model.status}\")\n",
    "\n",
    "                # Collect results\n",
    "                alpha_values = np.array([alpha.X for alpha in alphas.values()])\n",
    "\n",
    "                results = {\n",
    "                    \"losses\": [],\n",
    "                    \"lefts\": [],\n",
    "                    \"profits\": [],\n",
    "                    \"operation_profits\": [],\n",
    "                    \"Q0s\": [],\n",
    "                    \"Q1s\": [],\n",
    "                    \"Fs\": [],\n",
    "                    \"fs\": [],\n",
    "                }\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "                    sold0, sold1 = Sold_0s[i].X, Sold_1s[i].X\n",
    "                    lost0, lost1 = Lost_0s[i].X, Lost_1s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    print(\n",
    "                        f\"Lost0: {lost0}, Lost1: {lost1}, Left0: {left0}, Left1: {left1}\"\n",
    "                    )\n",
    "\n",
    "                    # Record results\n",
    "                    results[\"losses\"].append(lost0 + lost1)\n",
    "\n",
    "                    # results[\"lefts\"].append(left1)\n",
    "                    results[\"lefts\"].append(left0 + left1)\n",
    "\n",
    "                    results[\"operation_profits\"].append(\n",
    "                        (price - cost) * (sold0 + sold1)\n",
    "                    )\n",
    "                    results[\"profits\"].append(profits_vars[i].X)\n",
    "                    results[\"Q1s\"].append(Q1_vars[i].X)\n",
    "\n",
    "                    # Check f\n",
    "                    x_data = training_df.iloc[i].tolist()\n",
    "                    x_data.append(1)\n",
    "                    f_train, F_train, Q0_train = compute_f_F_Q(\n",
    "                        x_data, alpha_values, Q_star\n",
    "                    )\n",
    "                    print(\n",
    "                        f\"f_train: {f_train}, F_train: {F_train}, Q0_train: {Q0_train}\"\n",
    "                    )\n",
    "                    if (\n",
    "                        truncate_to_2(f_train) == truncate_to_2(f_vars[i].X)\n",
    "                        and truncate_to_2(F_train) == truncate_to_2(F_vars[i].X)\n",
    "                        and truncate_to_2(Q0_train) == truncate_to_2(Q0_vars[i].X)\n",
    "                    ):\n",
    "                        print(\"f_train, F_train, Q0_train 都相等\")\n",
    "                        results[\"Q0s\"].append(Q0_vars[i].X)\n",
    "                        results[\"Fs\"].append(F_vars[i].X)\n",
    "                        results[\"fs\"].append(f_vars[i].X)\n",
    "                    else:\n",
    "                        print(f\"f_train, F_train, Q0_train 不相等\")\n",
    "                        results[\"Q0s\"].append(-1)\n",
    "                        results[\"Fs\"].append(-1)\n",
    "                        results[\"fs\"].append(-1)\n",
    "                        # results[\"Q0s\"].append(Q0_vars[i].X)\n",
    "                        # results[\"Fs\"].append(F_vars[i].X)\n",
    "                        # results[\"fs\"].append(f_vars[i].X)\n",
    "                return (\n",
    "                    [assigned_R] * len(demand_df_train),  # Fixed R for all observations\n",
    "                    results[\"losses\"],\n",
    "                    results[\"lefts\"],\n",
    "                    results[\"profits\"],\n",
    "                    results[\"operation_profits\"],\n",
    "                    alpha_values,\n",
    "                    results[\"Fs\"],\n",
    "                    results[\"fs\"],\n",
    "                    results[\"Q0s\"],\n",
    "                    results[\"Q1s\"],\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_flexible_F_fixed_R(\n",
    "    assigned_Ts,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_train,\n",
    "    Qk_hat_df_train,\n",
    "    training_df,\n",
    "):\n",
    "    results_dict = {\n",
    "        \"R(T)\": [],\n",
    "        \"R\": [],\n",
    "        \"average_profits\": [],\n",
    "        \"average_losses\": [],\n",
    "        \"average_lefts\": [],\n",
    "        \"average_operation_profits\": [],\n",
    "        \"alpha_values\": [],\n",
    "        \"F_vars\": [],\n",
    "        \"f_vars\": [],\n",
    "        \"Q0_vars\": [],\n",
    "        \"Q1_vars\": [],\n",
    "    }\n",
    "\n",
    "    max_profit = None\n",
    "    max_profit_stimulation_result = {}\n",
    "\n",
    "    for assigned_T in assigned_Ts:\n",
    "        assigned_R = assigned_T - 2\n",
    "        result = cal_flexible_F_fixed_R(\n",
    "            assigned_R=assigned_R,\n",
    "            salvage_value=salvage_value,\n",
    "            cost=cost,\n",
    "            price=price,\n",
    "            Q_star=Q_star,\n",
    "            demand_df_train=demand_df_train,\n",
    "            Qk_hat_df=Qk_hat_df_train,\n",
    "            training_df=training_df,\n",
    "            lambda_alpha=LASSO_ALPHA,\n",
    "        )\n",
    "\n",
    "        if result is None:\n",
    "            print(f\"模型沒有最佳解\")\n",
    "            continue\n",
    "\n",
    "        (\n",
    "            all_Rs,\n",
    "            losses,\n",
    "            lefts,\n",
    "            profits,\n",
    "            operation_profits,\n",
    "            alpha_values,\n",
    "            F_vars,\n",
    "            f_vars,\n",
    "            Q0_vars,\n",
    "            Q1_vars,\n",
    "        ) = result\n",
    "\n",
    "        # 計算平均值\n",
    "        average_losses = sum(losses) / len(losses) if losses else 0\n",
    "        average_lefts = sum(lefts) / len(lefts) if lefts else 0\n",
    "        average_profits = sum(profits) / len(profits) if profits else 0\n",
    "        average_operation_profits = (\n",
    "            sum(operation_profits) / len(operation_profits) if operation_profits else 0\n",
    "        )\n",
    "\n",
    "        # 將結果存儲到字典中\n",
    "        results_dict[\"R(T)\"].append(assigned_T)\n",
    "        results_dict[\"R\"].append(all_Rs)\n",
    "        results_dict[\"average_losses\"].append(average_losses)\n",
    "        results_dict[\"average_lefts\"].append(average_lefts)\n",
    "        results_dict[\"average_profits\"].append(average_profits)\n",
    "        results_dict[\"average_operation_profits\"].append(average_operation_profits)\n",
    "        results_dict[\"alpha_values\"].append(alpha_values)\n",
    "        results_dict[\"F_vars\"].append(F_vars)\n",
    "        results_dict[\"f_vars\"].append(f_vars)\n",
    "        results_dict[\"Q0_vars\"].append(Q0_vars)\n",
    "        results_dict[\"Q1_vars\"].append(Q1_vars)\n",
    "\n",
    "        # print(f\"The average profits is {average_profits}\")\n",
    "\n",
    "        if max_profit is None or max_profit < average_profits:\n",
    "            # print(f\"max_profit is changed from {max_profit} to {average_profits}\")\n",
    "            max_profit = average_profits\n",
    "            max_profit_stimulation_result = {\n",
    "                \"R\": all_Rs,\n",
    "                \"F\": F_vars,\n",
    "                \"f\": f_vars,\n",
    "                \"profits\": profits,\n",
    "                \"losses\": losses,\n",
    "                \"lefts\": lefts,\n",
    "                \"operation_profits\": operation_profits,\n",
    "                \"Q0\": Q0_vars,\n",
    "                \"Q1\": Q1_vars,\n",
    "            }\n",
    "\n",
    "    return pd.DataFrame(results_dict).sort_values(\n",
    "        by=\"average_profits\", ascending=False\n",
    "    ), pd.DataFrame(max_profit_stimulation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S13 - Grid for Fixed Rk & Optimized F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_optimized_F_fixed_R(\n",
    "    assigned_R,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_train,\n",
    "    Qk_hat_df,\n",
    "    training_df,\n",
    "):\n",
    "    print(\n",
    "        f\"+++++++++++++++++++++++++++++++++++++++ THis is R={assigned_R} +++++++++++++++++++++++++++++++++++++++++++++++++\"\n",
    "    )\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "\n",
    "        # ======================= Decision Variables =======================\n",
    "        # alphas = model.addVars(\n",
    "        #     features_num + 1, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"alphas\"\n",
    "        # )\n",
    "        Sold_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_0\")\n",
    "        Sold_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_1\")\n",
    "        Lost_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_0\")\n",
    "        Lost_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_1\")\n",
    "        Left_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_1\")\n",
    "\n",
    "        # f_vars = model.addVars(\n",
    "        #     len(demand_df_train), lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"f_var\"\n",
    "        # )\n",
    "        F_vars = model.addVars(len(demand_df_train), lb=0, ub=1, name=\"Fraction\")\n",
    "\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, ub=(Q_star + 1), name=\"Q0_var\"\n",
    "        )\n",
    "        Q1_vars = model.addVars(len(Qk_hat_df), lb=0.0, name=\"Q1_var\")\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, name=\"profits_vars\"\n",
    "        )\n",
    "\n",
    "        # ======================= Model Constraints =======================\n",
    "        for i, row in demand_df_train.iterrows():\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i].tolist()\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            model.addConstr(F_vars[i] >= 0, name=f\"Fraction_lower_bound_{i}\")\n",
    "            model.addConstr(F_vars[i] <= 1, name=f\"Fraction_upper_bound_{i}\")\n",
    "\n",
    "            # Calculate F using logistic regression\n",
    "            # model.addConstr(\n",
    "            #     f_vars[i]\n",
    "            #     == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            # )\n",
    "            # model.addGenConstrLogistic(xvar=f_vars[i], yvar=F_vars[i])\n",
    "\n",
    "            # Calculate initial order quantity\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star)\n",
    "\n",
    "            # Define demand variables for before and after reorder point\n",
    "            total_demand_before_R = demand_row[: assigned_R + 1].sum()\n",
    "            total_demand_after_R = demand_row[assigned_R + 1 :].sum()\n",
    "\n",
    "            # Calculate first period sales and lost sales\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0s[i],\n",
    "                [total_demand_before_R, Q0_vars[i]],\n",
    "                name=f\"min_sales_constr_{i}\",\n",
    "            )\n",
    "\n",
    "            # Calculate lost sales\n",
    "            Lost_0_expr = total_demand_before_R - Q0_vars[i]\n",
    "            Lost_0_var = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_expr_{i}\")\n",
    "            model.addConstr(Lost_0_var == Lost_0_expr)\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_var, 0], name=f\"max_lost_constr_{i}\"\n",
    "            )\n",
    "\n",
    "            # Calculate inventory left after first period\n",
    "            left_0 = Q0_vars[i] - Sold_0s[i]\n",
    "\n",
    "            # Calculate Q1 based on reorder point estimate\n",
    "            Q_hat = Qk_hat_df_row[assigned_R]\n",
    "            Q_hat_adjusted = Q_hat - Q0_vars[i]\n",
    "            Q_hat_adjusted_var = model.addVar(\n",
    "                lb=-GRB.INFINITY, name=f\"Q_hat_adjusted_{i}\"\n",
    "            )\n",
    "            model.addConstr(Q_hat_adjusted_var == Q_hat_adjusted)\n",
    "\n",
    "            model.addGenConstrMax(\n",
    "                Q1_vars[i], [Q_hat_adjusted_var, 0], name=f\"max_Q1_constr_{i}\"\n",
    "            )\n",
    "\n",
    "            # Calculate second period sales and lost sales\n",
    "            total_stock_second_period = Q1_vars[i] + left_0\n",
    "            total_stock_second_period_var = model.addVar(\n",
    "                lb=0, name=f\"total_stock_second_period_{i}\"\n",
    "            )\n",
    "            model.addConstr(total_stock_second_period_var == total_stock_second_period)\n",
    "\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1s[i],\n",
    "                [total_demand_after_R, total_stock_second_period_var],\n",
    "                name=f\"min_sales2_constr_{i}\",\n",
    "            )\n",
    "\n",
    "            # Calculate second period lost sales\n",
    "            Lost_1_expr = total_demand_after_R - total_stock_second_period_var\n",
    "            Lost_1_var = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_1_expr_{i}\")\n",
    "            model.addConstr(Lost_1_var == Lost_1_expr)\n",
    "\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_var, 0], name=f\"max_lost2_constr_{i}\"\n",
    "            )\n",
    "\n",
    "            model.addConstr(Left_1s[i] == total_stock_second_period_var - Sold_1s[i])\n",
    "\n",
    "            # # Calculate holding costs directly in profit equation\n",
    "            # holding_cost_1 = (\n",
    "            #     (Q0_vars[i] + total_stock_second_period) * (assigned_R + 2 - 1) / 2\n",
    "            # )\n",
    "            # holding_cost_2 = (\n",
    "            #     (total_stock_second_period + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "            # )\n",
    "\n",
    "            # Calculate profit\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "                    - (cost - salvage_value) * Left_1s[i]  # Salvage cost\n",
    "                    # - holding_cost * (holding_cost_1 + holding_cost_2)  # Holding cost\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Set objective\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train))),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "\n",
    "        model.write(\"s2_model_debug.lp\")\n",
    "        model.write(\"s2_model.mps\")\n",
    "\n",
    "        # Solve model\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL or model.status == GRB.TIME_LIMIT:\n",
    "                print(f\"Model status: {model.status}\")\n",
    "\n",
    "                # Collect results\n",
    "                # alpha_values = np.array([alpha.X for alpha in alphas.values()])\n",
    "\n",
    "                results = {\n",
    "                    \"losses\": [],\n",
    "                    \"lefts\": [],\n",
    "                    \"profits\": [],\n",
    "                    \"operation_profits\": [],\n",
    "                    \"Q0s\": [],\n",
    "                    \"Q1s\": [],\n",
    "                    \"Fs\": [],\n",
    "                }\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "                    sold0, sold1 = Sold_0s[i].X, Sold_1s[i].X\n",
    "                    lost0, lost1 = Lost_0s[i].X, Lost_1s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "\n",
    "                    # Record results\n",
    "                    results[\"losses\"].append(lost0 + lost1)\n",
    "                    results[\"lefts\"].append(left1)\n",
    "                    results[\"operation_profits\"].append(\n",
    "                        (price - cost) * (sold0 + sold1)\n",
    "                    )\n",
    "                    results[\"profits\"].append(profits_vars[i].X)\n",
    "                    results[\"Q0s\"].append(Q0_vars[i].X)\n",
    "                    results[\"Q1s\"].append(Q1_vars[i].X)\n",
    "                    results[\"Fs\"].append(F_vars[i].X)\n",
    "\n",
    "                    print(f\"\\nObservation {i+1}:\")\n",
    "                    print(f\"Reorder day: {assigned_R}\")\n",
    "                    print(f\"Profit: {profits_vars[i].X:.2f}\")\n",
    "\n",
    "                return (\n",
    "                    [assigned_R] * len(demand_df_train),  # Fixed R for all observations\n",
    "                    results[\"losses\"],\n",
    "                    results[\"lefts\"],\n",
    "                    results[\"profits\"],\n",
    "                    results[\"operation_profits\"],\n",
    "                    None,\n",
    "                    results[\"Fs\"],\n",
    "                    results[\"Q0s\"],\n",
    "                    results[\"Q1s\"],\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "XHdZiv2bbIfP"
   },
   "outputs": [],
   "source": [
    "def grid_optimized_F_fixed_R(\n",
    "    assigned_Ts,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_train,\n",
    "    Qk_hat_df_train,\n",
    "    training_df,\n",
    "):\n",
    "    results_dict = {\n",
    "        \"R(T)\": [],\n",
    "        \"R\": [],\n",
    "        \"average_profits\": [],\n",
    "        \"average_losses\": [],\n",
    "        \"average_lefts\": [],\n",
    "        \"average_operation_profits\": [],\n",
    "        \"alpha_values\": [],\n",
    "        \"F_vars\": [],\n",
    "        \"Q0_vars\": [],\n",
    "        \"Q1_vars\": [],\n",
    "    }\n",
    "\n",
    "    max_profit = None\n",
    "    max_profit_stimulation_result = {}\n",
    "\n",
    "    for assigned_T in assigned_Ts:\n",
    "        assigned_R = assigned_T - 2\n",
    "        result = cal_optimized_F_fixed_R(\n",
    "            assigned_R=assigned_R,\n",
    "            salvage_value=salvage_value,\n",
    "            cost=cost,\n",
    "            price=price,\n",
    "            Q_star=Q_star,\n",
    "            demand_df_train=demand_df_train,\n",
    "            Qk_hat_df=Qk_hat_df_train,\n",
    "            training_df=training_df,\n",
    "        )\n",
    "\n",
    "        if result is None:\n",
    "            print(f\"模型沒有最佳解\")\n",
    "            results_dict[\"R(T)\"].append(None)\n",
    "            results_dict[\"R\"].append(None)\n",
    "            results_dict[\"average_losses\"].append(None)\n",
    "            results_dict[\"average_lefts\"].append(None)\n",
    "            results_dict[\"average_profits\"].append(None)\n",
    "            results_dict[\"average_operation_profits\"].append(None)\n",
    "            results_dict[\"alpha_values\"].append(None)\n",
    "            results_dict[\"F_vars\"].append(None)\n",
    "            results_dict[\"Q0_vars\"].append(None)\n",
    "            results_dict[\"Q1_vars\"].append(None)\n",
    "\n",
    "            continue\n",
    "\n",
    "        (\n",
    "            all_Rs,\n",
    "            losses,\n",
    "            lefts,\n",
    "            profits,\n",
    "            operation_profits,\n",
    "            alpha_values,\n",
    "            F_vars,\n",
    "            Q0_vars,\n",
    "            Q1_vars,\n",
    "        ) = result\n",
    "\n",
    "        # 計算平均值\n",
    "        average_losses = sum(losses) / len(losses) if losses else 0\n",
    "        average_lefts = sum(lefts) / len(lefts) if lefts else 0\n",
    "        average_profits = sum(profits) / len(profits) if profits else 0\n",
    "        average_operation_profits = (\n",
    "            sum(operation_profits) / len(operation_profits) if operation_profits else 0\n",
    "        )\n",
    "\n",
    "        # 將結果存儲到字典中\n",
    "        results_dict[\"R(T)\"].append(assigned_T)\n",
    "        results_dict[\"R\"].append(all_Rs)\n",
    "        results_dict[\"average_losses\"].append(average_losses)\n",
    "        results_dict[\"average_lefts\"].append(average_lefts)\n",
    "        results_dict[\"average_profits\"].append(average_profits)\n",
    "        results_dict[\"average_operation_profits\"].append(average_operation_profits)\n",
    "        results_dict[\"alpha_values\"].append(alpha_values)\n",
    "        results_dict[\"F_vars\"].append(F_vars)\n",
    "        results_dict[\"Q0_vars\"].append(Q0_vars)\n",
    "        results_dict[\"Q1_vars\"].append(Q1_vars)\n",
    "\n",
    "        print(f\"The average profits is {average_profits}\")\n",
    "\n",
    "        if max_profit is None or max_profit < average_profits:\n",
    "            print(f\"max_profit is changed from {max_profit} to {average_profits}\")\n",
    "            max_profit = average_profits\n",
    "            max_profit_stimulation_result = {\n",
    "                \"R\": all_Rs,\n",
    "                \"F\": F_vars,\n",
    "                \"profits\": profits,\n",
    "                \"losses\": losses,\n",
    "                \"lefts\": lefts,\n",
    "                \"operation_profits\": operation_profits,\n",
    "                \"Q0\": Q0_vars,\n",
    "                \"Q1\": Q1_vars,\n",
    "            }\n",
    "\n",
    "    return pd.DataFrame(results_dict).sort_values(\n",
    "        by=\"average_profits\", ascending=False\n",
    "    ), pd.DataFrame(max_profit_stimulation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HzqGevK3OwNQ"
   },
   "source": [
    "## S3 - Grid for Fixed F & Flexible Rk(with full beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "JEygghprPvw5"
   },
   "outputs": [],
   "source": [
    "def cal_fixed_F_flexible_R(\n",
    "    assigned_F,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_train,\n",
    "    Qk_hat_df,\n",
    "    training_df,\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        betas = model.addVars(\n",
    "            K, features_num + 1, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"betas\"\n",
    "        )  # Beta coefficients\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "        Sold_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Sold_0\",\n",
    "        )\n",
    "        Left_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Left_0\",\n",
    "        )\n",
    "        Lost_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Lost_0\",\n",
    "        )\n",
    "\n",
    "        Sold_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Sold_1\",\n",
    "        )\n",
    "        Left_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Left_1\",\n",
    "        )\n",
    "        Lost_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Lost_1\",\n",
    "        )\n",
    "\n",
    "        Holding_Cost_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Holding_Cost_0\",\n",
    "        )\n",
    "\n",
    "        Holding_Cost_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Holding_Cost_1\",\n",
    "        )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=-GRB.INFINITY,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"profits_vars\",\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Total_Demand_from_k_to_T\",\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=1,\n",
    "            name=\"Fraction_for_second_order_amount\",\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), vtype=GRB.CONTINUOUS, lb=0, ub=Q_star, name=\"Q0_var\"\n",
    "        )\n",
    "\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        tau_vars = model.addVars(\n",
    "            len(demand_df_train), K, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"tau\"\n",
    "        )  # Tau變量\n",
    "        r_vars = model.addVars(\n",
    "            len(demand_df_train), K, vtype=GRB.CONTINUOUS, lb=0.0, ub=1.0, name=\"r\"\n",
    "        )  # but t-1 is different from others\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=demand_df_train.max().max(),\n",
    "            name=\"Q1_var\",\n",
    "        )  # Every stimulation will have there own Q1 vars.\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=(-demand_df_train.max().max() * 100),\n",
    "            ub=demand_df_train.max().max() * 100,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=(-demand_df_train.max().max() * 100),\n",
    "            ub=demand_df_train.max().max() * 100,\n",
    "            name=f\"Q_hat_adjusted\",\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, row in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            model.addConstr(F_vars[i] == assigned_F)\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "            # 用線性回歸計算確定最佳補貨時間\n",
    "            exp_tau_vars = []\n",
    "            for k in range(K):\n",
    "\n",
    "                # 計算 tau_vars 作為 beta 和特徵的線性組合\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, k]\n",
    "                    == gp.quicksum(\n",
    "                        X_data[j] * betas[k, j] for j in range(features_num + 1)\n",
    "                    ),\n",
    "                    name=f\"tau_computation_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "                # 定義指數變數\n",
    "                exp_tau_var = model.addVar(\n",
    "                    vtype=GRB.CONTINUOUS, name=f\"exp_tau_var_{i}_{k}\"\n",
    "                )\n",
    "                neg_tau_var = model.addVar(\n",
    "                    vtype=GRB.CONTINUOUS, name=f\"neg_tau_var_{i}_{k}\"\n",
    "                )\n",
    "\n",
    "                # 設定約束條件\n",
    "                model.addConstr(\n",
    "                    neg_tau_var == -tau_vars[i, k], name=f\"neg_tau_constr_{i}_{k}\"\n",
    "                )\n",
    "                model.addGenConstrExp(xvar=neg_tau_var, yvar=exp_tau_var)\n",
    "\n",
    "                exp_tau_vars.append(exp_tau_var)\n",
    "\n",
    "                model.addConstr(\n",
    "                    r_vars[i, k] * gp.quicksum(exp_tau_vars) == exp_tau_vars[k],\n",
    "                    name=f\"softmax_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "            ### 找到最大 R 以及 r, R 的相關限制式 -> k: 0~7\n",
    "            max_r_helpers = model.addVar(vtype=GRB.CONTINUOUS, name=\"max_r_helper\")\n",
    "            model.addGenConstrMax(\n",
    "                max_r_helpers,\n",
    "                [r_vars[i, k] for k in range(K)],\n",
    "                name=f\"MaxRConstraint_{i}\",\n",
    "            )\n",
    "\n",
    "            ### 指定讓當 r_vars 中的值等於 max_r 時，R_vars 設為 1 -> k: 0~7\n",
    "            for k in range(K):\n",
    "                model.addConstr(\n",
    "                    r_vars[i, k] - max_r_helpers >= (R_vars[i, k] - 1),\n",
    "                    \"link_r_R_{}\".format(k),\n",
    "                )\n",
    "                model.addGenConstrIndicator(\n",
    "                    R_vars[i, k], 1, r_vars[i, k] == max_r_helpers\n",
    "                )\n",
    "\n",
    "            ## 只會有一個 R 為 1\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"Ensure_only_one_R_true_{i}\",\n",
    "            )  # 0~7\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "\n",
    "            ### 將 Q_hats(重新估計的值) 與原先 Q0 值進行比較。如果發現原先估計的比較少，則補足 Q_hat_adjusted，如果不用補充，則為 0\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            # ### 0~k-1 的需求量\n",
    "            total_demand_up_to_k_minus_1_var = model.addVar(\n",
    "                name=f\"Total_Demand_Up_to_K_Minus_1_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_var\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == total_demand_up_to_k_minus_1_var,\n",
    "                name=f\"Calculate_Total_Demand_Up_to_K_minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            total_demand_from_k_to_T_var = model.addVar(\n",
    "                name=f\"Total_Demand_from_K_to_T_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_var\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i] == total_demand_from_k_to_T_var,\n",
    "                name=f\"Calculate_Total_Demand_from_k_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Sold_0_aux = model.addVar(name=f\"Sold_0_aux_{i}\")\n",
    "            Left_0_aux = model.addVar(name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(name=f\"Lost_0_aux_{i}\")\n",
    "            Sold_1_aux = model.addVar(name=f\"Sold_1_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0_aux,\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "            model.addConstr(Sold_0s[i] == Sold_0_aux, name=f\"Constr_Sold_0_eq_aux_{i}\")\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1_aux,\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "            model.addConstr(Sold_1s[i] == Sold_1_aux, name=f\"Constr_Sold_1_eq_aux_{i}\")\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Holding_Cost_0\n",
    "            assigned_R_var = model.addVar(vtype=GRB.INTEGER, name=f\"assigned_R_{i}\")\n",
    "            model.addConstr(\n",
    "                assigned_R_var == gp.quicksum(k * R_vars[i, k] for k in range(K)),\n",
    "                name=f\"Calc_assigned_R_{i}\",\n",
    "            )\n",
    "\n",
    "            model.addConstr(\n",
    "                Holding_Cost_0s[i]\n",
    "                == ((Q0_vars[i] + Q1_plus_lefts[i]) * (assigned_R_var + 2 - 1) / 2),\n",
    "                name=f\"Constr_Holding_Cost_0_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Holding_Cost_1\n",
    "            model.addConstr(\n",
    "                Holding_Cost_1s[i]\n",
    "                == ((Q1_plus_lefts[i] + Left_1s[i]) * (T - (assigned_R_var + 2)) / 2),\n",
    "                name=f\"Constr_Holding_Cost_1_{i}\",\n",
    "            )\n",
    "\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "                    - holding_cost\n",
    "                    * (Holding_Cost_0s[i] + Holding_Cost_1s[i])  # holding cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train))),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                print(\"===================== 找到最佳解 ==================\")\n",
    "                print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                print(\"Beta values:\")\n",
    "                for key, beta in betas.items():\n",
    "                    print(f\"beta{key}: {beta.X}\")\n",
    "\n",
    "                beta_values = np.array(\n",
    "                    [[betas[i, j].X for j in range(1)] for i in range(K)]\n",
    "                )\n",
    "                tau_values = np.array(\n",
    "                    [\n",
    "                        [tau_vars[i, j].X for j in range(K)]\n",
    "                        for i in range(len(demand_df_train))\n",
    "                    ]\n",
    "                )\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                all_holding_costs_0 = []\n",
    "                all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    print(\"----------------------------------------------\")\n",
    "                    print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "                    all_Q0s.append(Q0_vars[i].X)\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    all_Fs.append(F_vars[i].X)\n",
    "                    all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    for k in range(K):\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        print(f\"第 {k+2} 天補貨策略: R_vars = {R_value}\")\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "                    all_Rs.append(reorder_day)\n",
    "\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "                    # print(f\"第一階段需求量: {demand_row[: (reorder_day-1)].sum()}\")\n",
    "                    # print(f\"第二階段需求量: {demand_row[(reorder_day-1): ].sum()}\\n\")\n",
    "\n",
    "                    # print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "                    # print(f\"F_var（重新訂貨量佔總訂貨量比例）: {F_vars[i].X}\")\n",
    "                    # print(f\"Q0_var（期初庫存量）: {Q0_vars[i].X}\\n\")\n",
    "                    # print(f\"Q1_var（二次訂貨量）: {Q1_vars[i].X}\")\n",
    "                    # print(f\"Holding_Cost_0: {Holding_Cost_0}\")\n",
    "                    # print(f\"Holding_Cost_1: {Holding_Cost_1}\\n\")\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    print(check_results_df)\n",
    "\n",
    "                    # for t in range(2):\n",
    "                    #     if t == 0:\n",
    "                    #         print(\n",
    "                    #             f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                    #         )\n",
    "                    #     else:\n",
    "                    #         print(\n",
    "                    #             f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                    #         )\n",
    "\n",
    "                    # print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                print(\"==========================================\")\n",
    "                print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    beta_values,\n",
    "                    tau_values,\n",
    "                    all_holding_costs_0,\n",
    "                    all_holding_costs_1,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "18afnulQbj_B"
   },
   "outputs": [],
   "source": [
    "def grid_fixed_F_flexible_R(\n",
    "    assigned_Fs,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_train,\n",
    "    Qk_hat_df_train,\n",
    "    training_df,\n",
    "):\n",
    "    results_dict = {\n",
    "        \"R(T)\": [],\n",
    "        \"average_losses\": [],\n",
    "        \"average_lefts\": [],\n",
    "        \"average_operation_profits\": [],\n",
    "        \"average_profits\": [],\n",
    "        \"beta_values\": [],\n",
    "        \"F_vars\": [],\n",
    "        \"Q0_vars\": [],\n",
    "        \"Q1_vars\": [],\n",
    "        \"tau_values\": [],\n",
    "    }\n",
    "\n",
    "    max_profit = None\n",
    "    max_profit_stimulation_result = {}\n",
    "\n",
    "    for assigned_F in assigned_Fs:\n",
    "        print(\n",
    "            f\"+++++++++++++++++++++++++++++++++++++++ THis is F={assigned_F} +++++++++++++++++++++++++++++++++++++++++++++++++\"\n",
    "        )\n",
    "        result = cal_fixed_F_flexible_R(\n",
    "            assigned_F=assigned_F,\n",
    "            salvage_value=salvage_value,\n",
    "            cost=cost,\n",
    "            price=price,\n",
    "            Q_star=Q_star,\n",
    "            demand_df_train=demand_df_train,\n",
    "            Qk_hat_df=Qk_hat_df_train,\n",
    "            training_df=training_df,\n",
    "        )\n",
    "\n",
    "        if result is None:\n",
    "            print(f\"模型沒有最佳解\")\n",
    "\n",
    "        else:\n",
    "            (\n",
    "                all_Rs,\n",
    "                losses,\n",
    "                lefts,\n",
    "                profits,\n",
    "                operation_profits,\n",
    "                F_vars,\n",
    "                Q0_vars,\n",
    "                Q1_vars,\n",
    "                beta_values,\n",
    "                tau_values,\n",
    "                holding_costs_0s,\n",
    "                holding_costs_1s,\n",
    "                all_left0s,\n",
    "                all_left1s,\n",
    "                all_lost0s,\n",
    "                all_lost1s,\n",
    "            ) = result\n",
    "\n",
    "            # 计算平均值\n",
    "            average_losses = sum(losses) / len(losses) if losses else 0\n",
    "            average_lefts = sum(lefts) / len(lefts) if lefts else 0\n",
    "            average_profits = sum(profits) / len(profits) if profits else 0\n",
    "            average_operation_profits = (\n",
    "                sum(operation_profits) / len(operation_profits)\n",
    "                if operation_profits\n",
    "                else 0\n",
    "            )\n",
    "\n",
    "            # 将结果存储到字典中\n",
    "            results_dict[\"R(T)\"].append(all_Rs)\n",
    "            results_dict[\"average_losses\"].append(average_losses)\n",
    "            results_dict[\"average_lefts\"].append(average_lefts)\n",
    "            results_dict[\"average_profits\"].append(average_profits)\n",
    "            results_dict[\"average_operation_profits\"].append(average_operation_profits)\n",
    "            results_dict[\"beta_values\"].append(beta_values)\n",
    "            results_dict[\"tau_values\"].append(tau_values)\n",
    "            results_dict[\"F_vars\"].append(F_vars)\n",
    "            results_dict[\"Q0_vars\"].append(Q0_vars)\n",
    "            results_dict[\"Q1_vars\"].append(Q1_vars)\n",
    "\n",
    "            if max_profit is None or max_profit < average_profits:\n",
    "                print(f\"max_profit is changed from {max_profit} to {average_profits}\")\n",
    "                max_profit = average_profits\n",
    "                max_profit_stimulation_result = {\n",
    "                    \"R(T)\": all_Rs,\n",
    "                    \"F\": F_vars,\n",
    "                    \"profits\": profits,\n",
    "                    \"losses\": losses,\n",
    "                    \"lefts\": lefts,\n",
    "                    \"operation_profits\": operation_profits,\n",
    "                    \"Q0\": Q0_vars,\n",
    "                    \"Q1\": Q1_vars,\n",
    "                    \"hc0\": holding_costs_0s,\n",
    "                    \"hc1\": holding_costs_1s,\n",
    "                    \"Left0s\": all_left0s,\n",
    "                    \"Left1s\": all_left1s,\n",
    "                    \"lost0s\": all_lost0s,\n",
    "                    \"lost1s\": all_lost1s,\n",
    "                }\n",
    "\n",
    "            print(f\"beta_values: \\n{beta_values}\")\n",
    "\n",
    "    print(max_profit_stimulation_result)\n",
    "\n",
    "    return pd.DataFrame(results_dict).sort_values(\n",
    "        by=\"average_profits\", ascending=False\n",
    "    ), pd.DataFrame(max_profit_stimulation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4Bnp-M_QC6e"
   },
   "source": [
    "## Fully flexible F & Rk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6BPJ4AakQC6e"
   },
   "source": [
    "### S5 - Simple beta with softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "bdApAjTOQC6e"
   },
   "outputs": [],
   "source": [
    "def __fully_flexible_simple_beta_with_softmax_5(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        alphas = model.addVars(\n",
    "            features_num + 1, name=\"alphas\"\n",
    "        )  # alpha coefficients with intercept\n",
    "        betas = model.addVars(\n",
    "            K, features_num + 1, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"betas\"\n",
    "        )  # Beta coefficients\n",
    "        betas = model.addVars(\n",
    "            K, 1, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"betas_with_ONLY_intercept\"\n",
    "        )  # Beta coefficients with ONLY intercept\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "\n",
    "        #### 1-1. 計算兩階段 Sold, Loss, Left 以及總合的 profit\n",
    "        Sold_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Sold_0\",\n",
    "        )\n",
    "        Left_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Left_0\",\n",
    "        )\n",
    "        Lost_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Lost_0\",\n",
    "        )\n",
    "\n",
    "        Sold_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Sold_1\",\n",
    "        )\n",
    "        Left_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Left_1\",\n",
    "        )\n",
    "        Lost_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Lost_1\",\n",
    "        )\n",
    "\n",
    "        Holding_Cost_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Holding_Cost_0\",\n",
    "        )\n",
    "\n",
    "        Holding_Cost_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Holding_Cost_1\",\n",
    "        )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=-GRB.INFINITY,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"profits_vars\",\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Total_Demand_from_k_to_T\",\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        f_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=-GRB.INFINITY,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"f_var\",\n",
    "        )\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=1,\n",
    "            name=\"Fraction_for_second_order_amount\",\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), vtype=GRB.CONTINUOUS, lb=0, ub=Q_star, name=\"Q0_var\"\n",
    "        )\n",
    "\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        tau_vars = model.addVars(\n",
    "            len(demand_df_train), K, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"tau\"\n",
    "        )  # Tau變量\n",
    "        r_vars = model.addVars(\n",
    "            len(demand_df_train), K, vtype=GRB.CONTINUOUS, lb=0.0, ub=1.0, name=\"r\"\n",
    "        )  # but t-1 is different from others\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=demand_df_train.max().max(),\n",
    "            name=\"Q1_var\",\n",
    "        )  # Every stimulation will have there own Q1 vars.\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=(-demand_df_train.max().max() * 100),\n",
    "            ub=demand_df_train.max().max() * 100,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=(-demand_df_train.max().max() * 100),\n",
    "            ub=demand_df_train.max().max() * 100,\n",
    "            name=f\"Q_hat_adjusted\",\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, row in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            ### 用線性回歸計算F_var\n",
    "            model.addConstr(\n",
    "                f_vars[i]\n",
    "                == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            )\n",
    "            model.addGenConstrLogistic(\n",
    "                xvar=f_vars[i], yvar=F_vars[i], name=f\"logistic_constraint_{i}\"\n",
    "            )\n",
    "\n",
    "            ### Q0_var = F_vars * Q_star\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "            # 用線性回歸計算確定最佳補貨時間\n",
    "\n",
    "            ### 訓練 beta(使用 softmax)\n",
    "            exp_tau_vars = []\n",
    "            for k in range(K):\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, k] == betas[k, 0], name=f\"tau_computation_{i}_{k}\"\n",
    "                )  # 只使用截距項\n",
    "\n",
    "                exp_tau_var = model.addVar(\n",
    "                    vtype=GRB.CONTINUOUS, name=f\"exp_tau_var_{i}_{k}\"\n",
    "                )\n",
    "                neg_tau_var = model.addVar(\n",
    "                    vtype=GRB.CONTINUOUS, name=f\"neg_tau_var_{i}_{k}\"\n",
    "                )\n",
    "\n",
    "                model.addConstr(\n",
    "                    neg_tau_var == -tau_vars[i, k], name=f\"neg_tau_constr_{i}_{k}\"\n",
    "                )\n",
    "                model.addGenConstrExp(xvar=neg_tau_var, yvar=exp_tau_var)\n",
    "\n",
    "                exp_tau_vars.append(exp_tau_var)\n",
    "\n",
    "            for k in range(K):\n",
    "                model.addConstr(\n",
    "                    r_vars[i, k] * gp.quicksum(exp_tau_vars) == exp_tau_vars[k],\n",
    "                    name=f\"softmax_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "            ### 找到最大 R 以及 r, R 的相關限制式 -> k: 0~7\n",
    "            max_r_helpers = model.addVar(vtype=GRB.CONTINUOUS, name=\"max_r_helper\")\n",
    "            model.addGenConstrMax(\n",
    "                max_r_helpers,\n",
    "                [r_vars[i, k] for k in range(K)],\n",
    "                name=f\"MaxRConstraint_{i}\",\n",
    "            )\n",
    "\n",
    "            ### 指定讓當 r_vars 中的值等於 max_r 時，R_vars 設為 1 -> k: 0~7\n",
    "            for k in range(K):\n",
    "                model.addConstr(\n",
    "                    r_vars[i, k] - max_r_helpers >= (R_vars[i, k] - 1),\n",
    "                    \"link_r_R_{}\".format(k),\n",
    "                )\n",
    "                model.addGenConstrIndicator(\n",
    "                    R_vars[i, k], 1, r_vars[i, k] == max_r_helpers\n",
    "                )\n",
    "\n",
    "            ## 只會有一個 R 為 1\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"Ensure_only_one_R_true_{i}\",\n",
    "            )  # 0~7\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "\n",
    "            ### 將 Q_hats(重新估計的值) 與原先 Q0 值進行比較。如果發現原先估計的比較少，則補足 Q_hat_adjusted，如果不用補充，則為 0\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            \"\"\"\n",
    "            計算每一個時間點 k 為界線。Rk = 1 時，代表選到該 k 的 timeline，其他非k則是 R=0。\n",
    "            因此意義上可以理解為，model 2 挑到一個最好的 timeline k 並且將其 R 設為 1, 因此只會計算到該時間線的數值。\n",
    "            \"\"\"\n",
    "            # ### 0~k-1 的需求量\n",
    "            total_demand_up_to_k_minus_1_var = model.addVar(\n",
    "                name=f\"Total_Demand_Up_to_K_Minus_1_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_var\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == total_demand_up_to_k_minus_1_var,\n",
    "                name=f\"Calculate_Total_Demand_Up_to_K_minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            total_demand_from_k_to_T_var = model.addVar(\n",
    "                name=f\"Total_Demand_from_K_to_T_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_var\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i] == total_demand_from_k_to_T_var,\n",
    "                name=f\"Calculate_Total_Demand_from_k_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Sold_0_aux = model.addVar(name=f\"Sold_0_aux_{i}\")\n",
    "            Left_0_aux = model.addVar(name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(name=f\"Lost_0_aux_{i}\")\n",
    "            Sold_1_aux = model.addVar(name=f\"Sold_1_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0_aux,\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "            model.addConstr(Sold_0s[i] == Sold_0_aux, name=f\"Constr_Sold_0_eq_aux_{i}\")\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1_aux,\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "            model.addConstr(Sold_1s[i] == Sold_1_aux, name=f\"Constr_Sold_1_eq_aux_{i}\")\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            assigned_R_var = model.addVar(vtype=GRB.INTEGER, name=f\"assigned_R_{i}\")\n",
    "            model.addConstr(\n",
    "                assigned_R_var == gp.quicksum(k * R_vars[i, k] for k in range(K)),\n",
    "                name=f\"Calc_assigned_R_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Holding_Cost_0\n",
    "            model.addConstr(\n",
    "                Holding_Cost_0s[i]\n",
    "                == ((Q0_vars[i] + Q1_plus_lefts[i]) * (assigned_R_var + 2 - 1) / 2),\n",
    "                name=f\"Constr_Holding_Cost_0_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Holding_Cost_1\n",
    "            model.addConstr(\n",
    "                Holding_Cost_1s[i]\n",
    "                == ((Q1_plus_lefts[i] + Left_1s[i]) * (T - (assigned_R_var + 2)) / 2),\n",
    "                name=f\"Constr_Holding_Cost_1_{i}\",\n",
    "            )\n",
    "\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "                    - holding_cost\n",
    "                    * (Holding_Cost_0s[i] + Holding_Cost_1s[i])  # holding cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train))),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                print(\"===================== 找到最佳解 ==================\")\n",
    "                print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                print(\"Alphas values:\")\n",
    "                for key, alpha in alphas.items():\n",
    "                    print(f\"alpha[{key}]: {alpha.X}\")\n",
    "\n",
    "                print(\"Beta values:\")\n",
    "                for key, beta in betas.items():\n",
    "                    print(f\"beta{key}: {beta.X}\")\n",
    "\n",
    "                alpha_values = np.array([alpha.X for _, alpha in alphas.items()])\n",
    "                beta_values = np.array(\n",
    "                    [[betas[i, j].X for j in range(1)] for i in range(K)]\n",
    "                )\n",
    "                f_values = np.array([f.X for _, f in f_vars.items()])\n",
    "                tau_values = np.array(\n",
    "                    [\n",
    "                        [tau_vars[i, j].X for j in range(K)]\n",
    "                        for i in range(len(demand_df_train))\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                print(f\"------------\")\n",
    "                print(f\"f_values:\\n{f_values}\")\n",
    "                print(f\"tau_values:\\n{tau_values}\")\n",
    "\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                all_holding_costs_0 = []\n",
    "                all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    print(\"----------------------------------------------\")\n",
    "                    print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "                    all_Q0s.append(Q0_vars[i].X)\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    all_Fs.append(F_vars[i].X)\n",
    "                    all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    for k in range(K):\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        print(f\"第 {k+2} 天補貨策略: R_vars = {R_value}\")\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "                    all_Rs.append(reorder_day)\n",
    "\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "                    # print(f\"第一階段需求量: {demand_row[: (reorder_day-1)].sum()}\")\n",
    "                    # print(f\"第二階段需求量: {demand_row[(reorder_day-1): ].sum()}\\n\")\n",
    "\n",
    "                    # print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "                    # print(f\"F_var（重新訂貨量佔總訂貨量比例）: {F_vars[i].X}\")\n",
    "                    # print(f\"Q0_var（期初庫存量）: {Q0_vars[i].X}\\n\")\n",
    "                    # print(f\"Q1_var（二次訂貨量）: {Q1_vars[i].X}\")\n",
    "                    # print(f\"Holding_Cost_0: {Holding_Cost_0}\")\n",
    "                    # print(f\"Holding_Cost_1: {Holding_Cost_1}\\n\")\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    print(check_results_df)\n",
    "\n",
    "                    # for t in range(2):\n",
    "                    #     if t == 0:\n",
    "                    #         print(\n",
    "                    #             f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                    #         )\n",
    "                    #     else:\n",
    "                    #         print(\n",
    "                    #             f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                    #         )\n",
    "\n",
    "                    # print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                print(\"==========================================\")\n",
    "                print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    alpha_values,\n",
    "                    beta_values,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    f_values,\n",
    "                    tau_values,\n",
    "                    all_holding_costs_0,\n",
    "                    all_holding_costs_1,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "rjpIHSWueRBJ"
   },
   "outputs": [],
   "source": [
    "def fully_flexible_simple_beta_with_softmax_5(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    result = __fully_flexible_simple_beta_with_softmax_5(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "\n",
    "    if result is None:\n",
    "        print(f\"找不到最佳解\")\n",
    "        return None, None\n",
    "    else:\n",
    "        (\n",
    "            all_Rs,\n",
    "            all_losses,\n",
    "            all_lefts,\n",
    "            all_profits,\n",
    "            all_operation_profits,\n",
    "            alpha_values,\n",
    "            beta_values,\n",
    "            all_Fs,\n",
    "            all_Q0s,\n",
    "            all_Q1s,\n",
    "            f_values,\n",
    "            tau_values,\n",
    "            holding_costs_0s,\n",
    "            holding_costs_1s,\n",
    "            all_left0s,\n",
    "            all_left1s,\n",
    "            all_lost0s,\n",
    "            all_lost1s,\n",
    "        ) = result\n",
    "        return make_s3_related_strtegies_result(\n",
    "            all_Rs=all_Rs,\n",
    "            losses=all_losses,\n",
    "            lefts=all_lefts,\n",
    "            profits=all_profits,\n",
    "            operation_profits=all_operation_profits,\n",
    "            alpha_values=alpha_values,\n",
    "            beta_values=beta_values,\n",
    "            F_vars=all_Fs,\n",
    "            Q0_vars=all_Q0s,\n",
    "            Q1_vars=all_Q1s,\n",
    "            f_values=f_values,\n",
    "            tau_values=tau_values,\n",
    "            holding_costs_0s=holding_costs_0s,\n",
    "            holding_costs_1s=holding_costs_1s,\n",
    "            all_left0s=all_left0s,\n",
    "            all_left1s=all_left1s,\n",
    "            all_lost0s=all_lost0s,\n",
    "            all_lost1s=all_lost1s,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8HSaPvrQC6f"
   },
   "source": [
    "### S6 - Simple beta and softmax with T is 1 - sum(T-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "FJ6F57YQQC6f"
   },
   "outputs": [],
   "source": [
    "def __fully_flexible_simple_beta_with_softmax_6(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        alphas = model.addVars(features_num + 1, lb=-GRB.INFINITY, name=\"alphas\")\n",
    "        betas = model.addVars(\n",
    "            K, 1, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"betas_with_ONLY_intercept\"\n",
    "        )\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "\n",
    "        #### 1-1. 計算兩階段 Sold, Loss, Left 以及總合的 profit\n",
    "        Sold_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_0\")\n",
    "        Left_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_0\")\n",
    "        Lost_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_0\")\n",
    "\n",
    "        Sold_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_1\")\n",
    "        Left_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_1\")\n",
    "        Lost_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_1\")\n",
    "        Holding_Cost_0s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_0\"\n",
    "        )\n",
    "\n",
    "        Holding_Cost_1s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_1\"\n",
    "        )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, name=\"profits_vars\"\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, name=\"Total_Demand_from_k_to_T\"\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        f_vars = model.addVars(len(demand_df_train), lb=-GRB.INFINITY, name=\"f_var\")\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=1, name=\"Fraction_for_second_order_amount\"\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=(Q_star + 1), name=\"Q0_var\"\n",
    "        )\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        r_vars = model.addVars(len(demand_df_train), K, lb=0.0, ub=1.0, name=\"r\")\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(len(Qk_hat_df), lb=0.0, name=\"Q1_var\")\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            # lb=0.0,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df), lb=-GRB.INFINITY, name=f\"Q_hat_adjusted\"\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, row in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            ### 用線性回歸計算F_var\n",
    "            model.addConstr(\n",
    "                f_vars[i]\n",
    "                == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            )\n",
    "            model.addGenConstrLogistic(\n",
    "                xvar=f_vars[i], yvar=F_vars[i], name=f\"logistic_constraint_{i}\"\n",
    "            )\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "            # 用線性回歸計算確定最佳補貨時間\n",
    "            exp_tau_vars = []\n",
    "            for p in range(K - 1):  # 一直到前一個\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, p] == betas[p, 0], name=f\"tau_computation_{i}_{p}\"\n",
    "                )  # 只使用截距項\n",
    "\n",
    "                # 定義指數變數\n",
    "                exp_tau_var = model.addVar(lb=0, name=f\"exp_tau_var_{i}_{p}\")\n",
    "                neg_tau_var = model.addVar(\n",
    "                    lb=-GRB.INFINITY, ub=0, name=f\"neg_tau_var_{i}_{p}\"\n",
    "                )\n",
    "                model.addConstr(\n",
    "                    neg_tau_var == -tau_vars[i, p], name=f\"neg_tau_constr_{i}_{p}\"\n",
    "                )\n",
    "                model.addGenConstrExp(xvar=neg_tau_var, yvar=exp_tau_var)\n",
    "                exp_tau_vars.append(exp_tau_var)\n",
    "\n",
    "            sum_exp_tau_vars = model.addVar(lb=0, name=f\"sum_exp_tau_vars_{i}\")\n",
    "            model.addConstr(\n",
    "                sum_exp_tau_vars == gp.quicksum(exp_tau_vars),\n",
    "                name=f\"sum_exp_tau_vars_computation_{i}\",\n",
    "            )\n",
    "\n",
    "            # 將 r_vars 的最後一個變量設為 1，其他變量根據 softmax 計算\n",
    "            for p in range(K):\n",
    "                if p == K - 1:  # 最後一個是特別處理\n",
    "                    r_sum_without_last = gp.quicksum(r_vars[i, p] for p in range(K - 1))\n",
    "                    model.addConstr(\n",
    "                        r_vars[i, p] == 1 - r_sum_without_last,\n",
    "                        name=f\"r_var_fixed_{i}_{p}\",\n",
    "                    )\n",
    "                else:\n",
    "                    model.addConstr(\n",
    "                        r_vars[i, p] * (sum_exp_tau_vars + 1) == exp_tau_vars[p],\n",
    "                        name=f\"softmax_{i}_{p}\",\n",
    "                    )\n",
    "\n",
    "            ### 找到最大 R 以及 r, R 的相關限制式 -> k: 0~7\n",
    "            max_r_helpers = model.addVar(lb=0.0, ub=1.0, name=\"max_r_helper\")\n",
    "            model.addGenConstrMax(\n",
    "                max_r_helpers,\n",
    "                [r_vars[i, k] for k in range(K)],\n",
    "                name=f\"MaxRConstraint_{i}\",\n",
    "            )\n",
    "\n",
    "            ### 指定讓當 r_vars 中的值等於 max_r 時，R_vars 設為 1 -> k: 0~7\n",
    "            eps = 1e-10\n",
    "            for k in range(K):\n",
    "                model.addGenConstrIndicator(\n",
    "                    R_vars[i, k], 1, r_vars[i, k] >= max_r_helpers - eps\n",
    "                )\n",
    "\n",
    "            ## 只會有一個 R 為 1\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"Ensure_only_one_R_true_{i}\",\n",
    "            )\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            \"\"\"\n",
    "            計算每一個時間點 k 為界線。Rk = 1 時，代表選到該 k 的 timeline，其他非k則是 R=0。\n",
    "            因此意義上可以理解為，model 2 挑到一個最好的 timeline k 並且將其 R 設為 1, 因此只會計算到該時間線的數值。\n",
    "            \"\"\"\n",
    "            # ### 0~k-1 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Left_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0s[i],\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1s[i],\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # assigned_R_var = model.addVar(vtype=GRB.INTEGER, name=f\"assigned_R_{i}\")\n",
    "            # model.addConstr(\n",
    "            #     assigned_R_var == gp.quicksum(k * R_vars[i, k] for k in range(K)),\n",
    "            #     name=f\"Calc_assigned_R_{i}\",\n",
    "            # )\n",
    "\n",
    "            # # 計算 Holding_Cost_0\n",
    "            # model.addConstr(\n",
    "            #     Holding_Cost_0s[i]\n",
    "            #     == ((Q0_vars[i] + Q1_plus_lefts[i]) * (assigned_R_var + 2 - 1) / 2),\n",
    "            #     name=f\"Constr_Holding_Cost_0_{i}\",\n",
    "            # )\n",
    "\n",
    "            # # 計算 Holding_Cost_1\n",
    "            # model.addConstr(\n",
    "            #     Holding_Cost_1s[i]\n",
    "            #     == ((Q1_plus_lefts[i] + Left_1s[i]) * (T - (assigned_R_var + 2)) / 2),\n",
    "            #     name=f\"Constr_Holding_Cost_1_{i}\",\n",
    "            # )\n",
    "\n",
    "            # model.addConstr(\n",
    "            #     profits_vars[i]\n",
    "            #     == (\n",
    "            #         (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "            #         - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "            #         - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "            #         # - holding_cost\n",
    "            #         # * (Holding_Cost_0s[i] + Holding_Cost_1s[i])  # holding cost\n",
    "            #     ),\n",
    "            #     name=f\"Profit_Constraint_{i}\",\n",
    "            # )\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train))),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "\n",
    "        model.write(\"s6_model_debug.lp\")\n",
    "        model.write(\"s6_model.mps\")\n",
    "\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                print(\"===================== 找到最佳解 ==================\")\n",
    "                print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                print(\"Alphas values:\")\n",
    "                for key, alpha in alphas.items():\n",
    "                    print(f\"alpha[{key}]: {alpha.X}\")\n",
    "\n",
    "                print(\"Beta values:\")\n",
    "                for key, beta in betas.items():\n",
    "                    print(f\"beta{key}: {beta.X}\")\n",
    "\n",
    "                alpha_values = np.array([alpha.X for _, alpha in alphas.items()])\n",
    "                beta_values = np.array(\n",
    "                    [[betas[k, j].X for j in range(features_num + 1)] for k in range(K)]\n",
    "                )\n",
    "                print(f\"beta_values:\\n{beta_values}\")\n",
    "\n",
    "                f_values = np.array([f.X for _, f in f_vars.items()])\n",
    "                tau_values = np.array(\n",
    "                    [\n",
    "                        [tau_vars[i, j].X for j in range(K)]\n",
    "                        for i in range(len(demand_df_train))\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                print(f\"------------\")\n",
    "                print(f\"f_values:\\n{f_values}\")\n",
    "                print(f\"tau_values:\\n{tau_values}\")\n",
    "\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                all_rs = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                all_holding_costs_0 = []\n",
    "                all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    print(\"----------------------------------------------\")\n",
    "                    print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "                    all_Q0s.append(Q0_vars[i].X)\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    all_Fs.append(F_vars[i].X)\n",
    "                    all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    rs = []\n",
    "                    for k in range(K):\n",
    "                        rs.append(r_vars[i, k].X)\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        print(\n",
    "                            f\"第 {k+2} 天補貨策略: R_vars = {R_value}, r_vars = {rs[k]}\"\n",
    "                        )\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "\n",
    "                    all_Rs.append(reorder_day)\n",
    "                    all_rs.append(rs)\n",
    "\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    print(check_results_df)\n",
    "\n",
    "                    for t in range(2):\n",
    "                        if t == 0:\n",
    "                            print(\n",
    "                                f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                            )\n",
    "                        else:\n",
    "                            print(\n",
    "                                f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                            )\n",
    "\n",
    "                    print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                print(\"==========================================\")\n",
    "                print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    alpha_values,\n",
    "                    beta_values,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    f_values,\n",
    "                    tau_values,\n",
    "                    all_holding_costs_0,\n",
    "                    all_holding_costs_1,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "iAQkhleJepdr"
   },
   "outputs": [],
   "source": [
    "def fully_flexible_simple_beta_with_softmax_6(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    result = __fully_flexible_simple_beta_with_softmax_6(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "\n",
    "    if result is None:\n",
    "        print(f\"找不到最佳解\")\n",
    "        return None, None\n",
    "    else:\n",
    "        (\n",
    "            all_Rs,\n",
    "            all_losses,\n",
    "            all_lefts,\n",
    "            all_profits,\n",
    "            all_operation_profits,\n",
    "            alpha_values,\n",
    "            beta_values,\n",
    "            all_Fs,\n",
    "            all_Q0s,\n",
    "            all_Q1s,\n",
    "            f_values,\n",
    "            tau_values,\n",
    "            holding_costs_0s,\n",
    "            holding_costs_1s,\n",
    "            all_left0s,\n",
    "            all_left1s,\n",
    "            all_lost0s,\n",
    "            all_lost1s,\n",
    "        ) = result\n",
    "        return make_s3_related_strtegies_result(\n",
    "            all_Rs=all_Rs,\n",
    "            losses=all_losses,\n",
    "            lefts=all_lefts,\n",
    "            profits=all_profits,\n",
    "            operation_profits=all_operation_profits,\n",
    "            alpha_values=alpha_values,\n",
    "            beta_values=beta_values,\n",
    "            F_vars=all_Fs,\n",
    "            Q0_vars=all_Q0s,\n",
    "            Q1_vars=all_Q1s,\n",
    "            f_values=f_values,\n",
    "            tau_values=tau_values,\n",
    "            holding_costs_0s=holding_costs_0s,\n",
    "            holding_costs_1s=holding_costs_1s,\n",
    "            all_left0s=all_left0s,\n",
    "            all_left1s=all_left1s,\n",
    "            all_lost0s=all_lost0s,\n",
    "            all_lost1s=all_lost1s,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMeeInmeQC6g"
   },
   "source": [
    "### S7 - Simple beat and softmax with T is 1 - sum(T-1) & tau with f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "fCSTKTWSQC6g"
   },
   "outputs": [],
   "source": [
    "def __fully_flexible_simple_beta_with_softmax_7(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        alphas = model.addVars(\n",
    "            features_num + 1, name=\"alphas\"\n",
    "        )  # alpha coefficients with intercept\n",
    "        betas = model.addVars(\n",
    "            K, 1, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"betas_with_ONLY_intercept\"\n",
    "        )  # Beta coefficients with ONLY intercept\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "        Sold_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Sold_0\",\n",
    "        )\n",
    "        Left_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Left_0\",\n",
    "        )\n",
    "        Lost_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Lost_0\",\n",
    "        )\n",
    "\n",
    "        Sold_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Sold_1\",\n",
    "        )\n",
    "        Left_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Left_1\",\n",
    "        )\n",
    "        Lost_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Lost_1\",\n",
    "        )\n",
    "\n",
    "        Holding_Cost_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Holding_Cost_0\",\n",
    "        )\n",
    "\n",
    "        Holding_Cost_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Holding_Cost_1\",\n",
    "        )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=-GRB.INFINITY,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"profits_vars\",\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Total_Demand_from_k_to_T\",\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        f_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=-GRB.INFINITY,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"f_var\",\n",
    "        )\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=1,\n",
    "            name=\"Fraction_for_second_order_amount\",\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), vtype=GRB.CONTINUOUS, lb=0, ub=Q_star, name=\"Q0_var\"\n",
    "        )\n",
    "\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        tau_vars = model.addVars(\n",
    "            len(demand_df_train), K, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"tau\"\n",
    "        )  # Tau變量\n",
    "        r_vars = model.addVars(\n",
    "            len(demand_df_train), K, vtype=GRB.CONTINUOUS, lb=0.0, ub=1.0, name=\"r\"\n",
    "        )  # but t-1 is different from others\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=demand_df_train.max().max(),\n",
    "            name=\"Q1_var\",\n",
    "        )  # Every stimulation will have there own Q1 vars.\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=(-demand_df_train.max().max() * 100),\n",
    "            ub=demand_df_train.max().max() * 100,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=(-demand_df_train.max().max() * 100),\n",
    "            ub=demand_df_train.max().max() * 100,\n",
    "            name=f\"Q_hat_adjusted\",\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, row in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            ### 用線性回歸計算F_var\n",
    "            model.addConstr(\n",
    "                f_vars[i]\n",
    "                == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            )\n",
    "            model.addGenConstrLogistic(\n",
    "                xvar=f_vars[i], yvar=F_vars[i], name=f\"logistic_constraint_{i}\"\n",
    "            )\n",
    "\n",
    "            ### Q0_var = F_vars * Q_star\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "            # 用線性回歸計算確定最佳補貨時間\n",
    "            exp_tau_vars = []\n",
    "            for p in range(K - 1):  # 一直到前一個\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, p] == betas[p, 0] + f_vars[i],\n",
    "                    name=f\"tau_computation_{i}_{p}\",\n",
    "                )  # 只使用截距項\n",
    "                exp_tau_var = model.addVar(\n",
    "                    vtype=GRB.CONTINUOUS, name=f\"exp_tau_var_{i}_{p}\"\n",
    "                )\n",
    "\n",
    "                neg_tau_var = model.addVar(\n",
    "                    vtype=GRB.CONTINUOUS, name=f\"neg_tau_var_{i}_{p}\"\n",
    "                )\n",
    "                model.addConstr(\n",
    "                    neg_tau_var == -tau_vars[i, p], name=f\"neg_tau_constr_{i}_{p}\"\n",
    "                )\n",
    "                model.addGenConstrExp(xvar=neg_tau_var, yvar=exp_tau_var)\n",
    "\n",
    "                exp_tau_vars.append(exp_tau_var)\n",
    "\n",
    "            sum_exp_tau_vars = model.addVar(\n",
    "                vtype=GRB.CONTINUOUS, name=f\"sum_exp_tau_vars_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                sum_exp_tau_vars == gp.quicksum(exp_tau_vars),\n",
    "                name=f\"sum_exp_tau_vars_computation_{i}\",\n",
    "            )\n",
    "\n",
    "            # 將 r_vars 的最後一個變量設為 1，其他變量根據 softmax 計算\n",
    "            for p in range(K):\n",
    "                if p == K - 1:  # 最後一個是特別處理\n",
    "                    r_sum_without_last = gp.quicksum(r_vars[i, p] for p in range(K - 1))\n",
    "                    model.addConstr(\n",
    "                        r_vars[i, p] == 1 - r_sum_without_last,\n",
    "                        name=f\"r_var_fixed_{i}_{p}\",\n",
    "                    )\n",
    "                else:\n",
    "                    model.addConstr(\n",
    "                        r_vars[i, p] * (sum_exp_tau_vars + 1) == exp_tau_vars[p],\n",
    "                        name=f\"softmax_{i}_{p}\",\n",
    "                    )\n",
    "\n",
    "            ### 找到最大 R 以及 r, R 的相關限制式 -> k: 0~7\n",
    "            max_r_helpers = model.addVar(vtype=GRB.CONTINUOUS, name=\"max_r_helper\")\n",
    "            model.addGenConstrMax(\n",
    "                max_r_helpers,\n",
    "                [r_vars[i, k] for k in range(K)],\n",
    "                name=f\"MaxRConstraint_{i}\",\n",
    "            )\n",
    "\n",
    "            ### 指定讓當 r_vars 中的值等於 max_r 時，R_vars 設為 1 -> k: 0~7\n",
    "            for k in range(K):\n",
    "                model.addConstr(\n",
    "                    r_vars[i, k] - max_r_helpers >= (R_vars[i, k] - 1),\n",
    "                    \"link_r_R_{}\".format(k),\n",
    "                )\n",
    "                model.addGenConstrIndicator(\n",
    "                    R_vars[i, k], 1, r_vars[i, k] == max_r_helpers\n",
    "                )\n",
    "\n",
    "            ## 只會有一個 R 為 1\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"Ensure_only_one_R_true_{i}\",\n",
    "            )  # 0~7\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "\n",
    "            ### 將 Q_hats(重新估計的值) 與原先 Q0 值進行比較。如果發現原先估計的比較少，則補足 Q_hat_adjusted，如果不用補充，則為 0\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            # ### 0~k-1 的需求量\n",
    "            total_demand_up_to_k_minus_1_var = model.addVar(\n",
    "                name=f\"Total_Demand_Up_to_K_Minus_1_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_var\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == total_demand_up_to_k_minus_1_var,\n",
    "                name=f\"Calculate_Total_Demand_Up_to_K_minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            total_demand_from_k_to_T_var = model.addVar(\n",
    "                name=f\"Total_Demand_from_K_to_T_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_var\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i] == total_demand_from_k_to_T_var,\n",
    "                name=f\"Calculate_Total_Demand_from_k_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Sold_0_aux = model.addVar(name=f\"Sold_0_aux_{i}\")\n",
    "            Left_0_aux = model.addVar(name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(name=f\"Lost_0_aux_{i}\")\n",
    "            Sold_1_aux = model.addVar(name=f\"Sold_1_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0_aux,\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "            model.addConstr(Sold_0s[i] == Sold_0_aux, name=f\"Constr_Sold_0_eq_aux_{i}\")\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1_aux,\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "            model.addConstr(Sold_1s[i] == Sold_1_aux, name=f\"Constr_Sold_1_eq_aux_{i}\")\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            assigned_R_var = model.addVar(vtype=GRB.INTEGER, name=f\"assigned_R_{i}\")\n",
    "            model.addConstr(\n",
    "                assigned_R_var == gp.quicksum(k * R_vars[i, k] for k in range(K)),\n",
    "                name=f\"Calc_assigned_R_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Holding_Cost_0\n",
    "            model.addConstr(\n",
    "                Holding_Cost_0s[i]\n",
    "                == ((Q0_vars[i] + Q1_plus_lefts[i]) * (assigned_R_var + 2 - 1) / 2),\n",
    "                name=f\"Constr_Holding_Cost_0_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Holding_Cost_1\n",
    "            model.addConstr(\n",
    "                Holding_Cost_1s[i]\n",
    "                == ((Q1_plus_lefts[i] + Left_1s[i]) * (T - (assigned_R_var + 2)) / 2),\n",
    "                name=f\"Constr_Holding_Cost_1_{i}\",\n",
    "            )\n",
    "\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "                    - holding_cost\n",
    "                    * (Holding_Cost_0s[i] + Holding_Cost_1s[i])  # holding cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train))),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                print(\"===================== 找到最佳解 ==================\")\n",
    "                print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                print(\"Alphas values:\")\n",
    "                for key, alpha in alphas.items():\n",
    "                    print(f\"alpha[{key}]: {alpha.X}\")\n",
    "\n",
    "                print(\"Beta values:\")\n",
    "                for key, beta in betas.items():\n",
    "                    print(f\"beta{key}: {beta.X}\")\n",
    "\n",
    "                alpha_values = np.array([alpha.X for _, alpha in alphas.items()])\n",
    "                beta_values = np.array(\n",
    "                    [[betas[i, j].X for j in range(1)] for i in range(K)]\n",
    "                )\n",
    "                f_values = np.array([f.X for _, f in f_vars.items()])\n",
    "                tau_values = np.array(\n",
    "                    [\n",
    "                        [tau_vars[i, j].X for j in range(K)]\n",
    "                        for i in range(len(demand_df_train))\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                print(f\"------------\")\n",
    "                print(f\"f_values:\\n{f_values}\")\n",
    "                print(f\"tau_values:\\n{tau_values}\")\n",
    "\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                all_holding_costs_0 = []\n",
    "                all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    print(\"----------------------------------------------\")\n",
    "                    print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "                    all_Q0s.append(Q0_vars[i].X)\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    all_Fs.append(F_vars[i].X)\n",
    "                    all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    for k in range(K):\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        print(f\"第 {k+2} 天補貨策略: R_vars = {R_value}\")\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "                    all_Rs.append(reorder_day)\n",
    "\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "                    # print(f\"第一階段需求量: {demand_row[: (reorder_day-1)].sum()}\")\n",
    "                    # print(f\"第二階段需求量: {demand_row[(reorder_day-1): ].sum()}\\n\")\n",
    "\n",
    "                    # print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "                    # print(f\"F_var（重新訂貨量佔總訂貨量比例）: {F_vars[i].X}\")\n",
    "                    # print(f\"Q0_var（期初庫存量）: {Q0_vars[i].X}\\n\")\n",
    "                    # print(f\"Q1_var（二次訂貨量）: {Q1_vars[i].X}\")\n",
    "                    # print(f\"Holding_Cost_0: {Holding_Cost_0}\")\n",
    "                    # print(f\"Holding_Cost_1: {Holding_Cost_1}\\n\")\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    print(check_results_df)\n",
    "\n",
    "                    # for t in range(2):\n",
    "                    #     if t == 0:\n",
    "                    #         print(\n",
    "                    #             f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                    #         )\n",
    "                    #     else:\n",
    "                    #         print(\n",
    "                    #             f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                    #         )\n",
    "\n",
    "                    # print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                print(\"==========================================\")\n",
    "                print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    alpha_values,\n",
    "                    beta_values,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    f_values,\n",
    "                    tau_values,\n",
    "                    all_holding_costs_0,\n",
    "                    all_holding_costs_1,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "m0dwZyvzcL4m"
   },
   "outputs": [],
   "source": [
    "def fully_flexible_simple_beta_with_softmax_7(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "    result = __fully_flexible_simple_beta_with_softmax_7(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "\n",
    "    if result is None:\n",
    "        print(f\"找不到最佳解\")\n",
    "        return None, None\n",
    "    else:\n",
    "        (\n",
    "            all_Rs,\n",
    "            all_losses,\n",
    "            all_lefts,\n",
    "            all_profits,\n",
    "            all_operation_profits,\n",
    "            alpha_values,\n",
    "            beta_values,\n",
    "            all_Fs,\n",
    "            all_Q0s,\n",
    "            all_Q1s,\n",
    "            f_values,\n",
    "            tau_values,\n",
    "            holding_costs_0s,\n",
    "            holding_costs_1s,\n",
    "            all_left0s,\n",
    "            all_left1s,\n",
    "            all_lost0s,\n",
    "            all_lost1s,\n",
    "        ) = result\n",
    "        return make_s3_related_strtegies_result(\n",
    "            all_Rs=all_Rs,\n",
    "            losses=all_losses,\n",
    "            lefts=all_lefts,\n",
    "            profits=all_profits,\n",
    "            operation_profits=all_operation_profits,\n",
    "            alpha_values=alpha_values,\n",
    "            beta_values=beta_values,\n",
    "            F_vars=all_Fs,\n",
    "            Q0_vars=all_Q0s,\n",
    "            Q1_vars=all_Q1s,\n",
    "            f_values=f_values,\n",
    "            tau_values=tau_values,\n",
    "            holding_costs_0s=holding_costs_0s,\n",
    "            holding_costs_1s=holding_costs_1s,\n",
    "            all_left0s=all_left0s,\n",
    "            all_left1s=all_left1s,\n",
    "            all_lost0s=all_lost0s,\n",
    "            all_lost1s=all_lost1s,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgQovzuG41d_"
   },
   "source": [
    "### S4 - Beta with softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "tVy2xESR44dH"
   },
   "outputs": [],
   "source": [
    "def __fully_flexible_beta_with_softmax_4(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "        model.setParam(\"IntFeasTol\", 1e-9)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        alphas = model.addVars(features_num + 1, lb=-GRB.INFINITY, name=\"alphas\")\n",
    "        betas = model.addVars(K, features_num + 1, lb=-GRB.INFINITY, name=\"betas\")\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "        Sold_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_0\")\n",
    "        Left_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_0\")\n",
    "        Lost_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_0\")\n",
    "\n",
    "        Sold_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_1\")\n",
    "        Left_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_1\")\n",
    "        Lost_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_1\")\n",
    "\n",
    "        Holding_Cost_0s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_0\"\n",
    "        )\n",
    "\n",
    "        Holding_Cost_1s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_1\"\n",
    "        )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, name=\"profits_vars\"\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, name=\"Total_Demand_from_k_to_T\"\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        f_vars = model.addVars(len(demand_df_train), lb=-GRB.INFINITY, name=\"f_var\")\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=1, name=\"Fraction_for_second_order_amount\"\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=(Q_star + 1), name=\"Q0_var\"\n",
    "        )\n",
    "\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        # tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        r_vars = model.addVars(len(demand_df_train), K, lb=0.0, ub=1.0, name=\"r\")\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(len(Qk_hat_df), lb=0.0, name=\"Q1_var\")\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            lb=0.0,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df), lb=-GRB.INFINITY, name=f\"Q_hat_adjusted\"\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, _ in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            ### 用線性回歸計算F_var\n",
    "            model.addConstr(\n",
    "                f_vars[i]\n",
    "                == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            )\n",
    "            model.addGenConstrLogistic(\n",
    "                xvar=f_vars[i], yvar=F_vars[i], name=f\"logistic_constraint_{i}\"\n",
    "            )\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "            # 用線性回歸計算確定最佳補貨時間\n",
    "            exp_tau_vars = []\n",
    "            for k in range(K):\n",
    "\n",
    "                # 計算 tau_vars 作為 beta 和特徵的線性組合\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, k]\n",
    "                    == gp.quicksum(\n",
    "                        X_data[j] * betas[k, j] for j in range(features_num + 1)\n",
    "                    ),\n",
    "                    name=f\"tau_computation_{i}_{k}\",\n",
    "                )\n",
    "                # model.addConstr(tau_vars[i, k] >= -5, name=f\"tau_lb_{i}_{k}\")\n",
    "\n",
    "                exp_tau_var = model.addVar(lb=1e-6, name=f\"exp_tau_var_{i}_{k}\")\n",
    "                exp_tau_var = model.addVar(\n",
    "                    lb=-GRB.INFINITY, name=f\"exp_tau_var_{i}_{k}\"\n",
    "                )\n",
    "                model.addGenConstrExp(xvar=tau_vars[i, k], yvar=exp_tau_var)\n",
    "                exp_tau_vars.append(exp_tau_var)\n",
    "\n",
    "            ### 找到最大 R 以及 r, R 的相關限制式 -> k: 0~7\n",
    "            for k in range(K):\n",
    "                model.addConstr(\n",
    "                    r_vars[i, k] * gp.quicksum(exp_tau_vars) == exp_tau_vars[k],\n",
    "                    name=f\"softmax_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "            model.addConstr(\n",
    "                gp.quicksum(r_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"sum_r_{i}\",\n",
    "            )\n",
    "\n",
    "            max_r_helpers = model.addVar(lb=0.0, ub=1.0, name=\"max_r_helper\")\n",
    "            model.addGenConstrMax(\n",
    "                max_r_helpers,\n",
    "                [r_vars[i, k] for k in range(K)],\n",
    "                name=f\"MaxRConstraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # 確保 R_vars 的邏輯行為\n",
    "            for k in range(K):\n",
    "                model.addGenConstrIndicator(\n",
    "                    R_vars[i, k], True, r_vars[i, k] == max_r_helpers\n",
    "                )\n",
    "\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"Ensure_only_one_R_true_{i}\",\n",
    "            )\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            # ### 0~k-1 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Left_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0s[i],\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1s[i],\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train))),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "        model.write(\"s4_model_debug.lp\")\n",
    "        model.write(\"s4_model.mps\")\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                print(\"===================== 找到最佳解 ==================\")\n",
    "                print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                print(\"Alphas values:\")\n",
    "                for key, alpha in alphas.items():\n",
    "                    print(f\"alpha[{key}]: {alpha.X}\")\n",
    "\n",
    "                alpha_values = np.array([alpha.X for _, alpha in alphas.items()])\n",
    "                beta_values = np.array(\n",
    "                    [[betas[k, j].X for j in range(features_num + 1)] for k in range(K)]\n",
    "                )\n",
    "                print(f\"beta_values:\\n{beta_values}\")\n",
    "\n",
    "                f_values = np.array([f.X for _, f in f_vars.items()])\n",
    "                tau_values = np.array(\n",
    "                    [\n",
    "                        [tau_vars[i, j].X for j in range(K)]\n",
    "                        for i in range(len(demand_df_train))\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                print(f\"------------\")\n",
    "                print(f\"f_values:\\n{f_values}\")\n",
    "                print(f\"tau_values:\\n{tau_values}\")\n",
    "\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                all_rs = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                all_holding_costs_0 = []\n",
    "                all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    print(\"----------------------------------------------\")\n",
    "                    print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "                    all_Q0s.append(Q0_vars[i].X)\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    all_Fs.append(F_vars[i].X)\n",
    "                    all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    rs = []\n",
    "                    for k in range(K):\n",
    "                        rs.append(r_vars[i, k].X)\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        print(\n",
    "                            f\"第 {k+2} 天補貨策略: R_vars = {R_value}, r_vars = {rs[k]}\"\n",
    "                        )\n",
    "                        # print(\n",
    "                        #     f\"第 {k+2} 天補貨策略: R_vars = {R_value}, tau_vars = {tau_vars[i, k].X}\"\n",
    "                        # )\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "\n",
    "                    all_Rs.append(reorder_day)\n",
    "                    all_rs.append(rs)\n",
    "\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    print(check_results_df)\n",
    "\n",
    "                    for t in range(2):\n",
    "                        if t == 0:\n",
    "                            print(\n",
    "                                f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                            )\n",
    "                        else:\n",
    "                            print(\n",
    "                                f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                            )\n",
    "\n",
    "                    print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                print(\"==========================================\")\n",
    "                print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    alpha_values,\n",
    "                    beta_values,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    f_values,\n",
    "                    tau_values,\n",
    "                    all_holding_costs_0,\n",
    "                    all_holding_costs_1,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "tSxMyuGNeyyb"
   },
   "outputs": [],
   "source": [
    "def fully_flexible_beta_with_softmax_4(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    result = __fully_flexible_beta_with_softmax_4(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "    if result is None:\n",
    "        print(f\"找不到最佳解\")\n",
    "        return None, None\n",
    "    else:\n",
    "        (\n",
    "            all_Rs,\n",
    "            all_losses,\n",
    "            all_lefts,\n",
    "            all_profits,\n",
    "            all_operation_profits,\n",
    "            alpha_values,\n",
    "            beta_values,\n",
    "            all_Fs,\n",
    "            all_Q0s,\n",
    "            all_Q1s,\n",
    "            f_values,\n",
    "            tau_values,\n",
    "            holding_costs_0s,\n",
    "            holding_costs_1s,\n",
    "            all_left0s,\n",
    "            all_left1s,\n",
    "            all_lost0s,\n",
    "            all_lost1s,\n",
    "        ) = result\n",
    "\n",
    "        print(f\"all_Rs: {all_Rs}\")\n",
    "\n",
    "        return make_s3_related_strtegies_result(\n",
    "            all_Rs=all_Rs,\n",
    "            losses=all_losses,\n",
    "            lefts=all_lefts,\n",
    "            profits=all_profits,\n",
    "            operation_profits=all_operation_profits,\n",
    "            alpha_values=alpha_values,\n",
    "            beta_values=beta_values,\n",
    "            F_vars=all_Fs,\n",
    "            Q0_vars=all_Q0s,\n",
    "            Q1_vars=all_Q1s,\n",
    "            f_values=f_values,\n",
    "            tau_values=tau_values,\n",
    "            holding_costs_0s=holding_costs_0s,\n",
    "            holding_costs_1s=holding_costs_1s,\n",
    "            all_left0s=all_left0s,\n",
    "            all_left1s=all_left1s,\n",
    "            all_lost0s=all_lost0s,\n",
    "            all_lost1s=all_lost1s,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S9 - Without beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __fully_flexible_beta_with_softmax_9(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "        model.setParam(\"IntFeasTol\", 1e-9)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        alphas = model.addVars(features_num + 1, lb=-GRB.INFINITY, name=\"alphas\")\n",
    "        # betas = model.addVars(K, features_num + 1, lb=-GRB.INFINITY, name=\"betas\")\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "        Sold_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_0\")\n",
    "        Left_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_0\")\n",
    "        Lost_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_0\")\n",
    "\n",
    "        Sold_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_1\")\n",
    "        Left_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_1\")\n",
    "        Lost_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_1\")\n",
    "\n",
    "        Holding_Cost_0s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_0\"\n",
    "        )\n",
    "\n",
    "        Holding_Cost_1s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_1\"\n",
    "        )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, name=\"profits_vars\"\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, name=\"Total_Demand_from_k_to_T\"\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        f_vars = model.addVars(len(demand_df_train), lb=-GRB.INFINITY, name=\"f_var\")\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=1, name=\"Fraction_for_second_order_amount\"\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=(Q_star + 1), name=\"Q0_var\"\n",
    "        )\n",
    "\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        # tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        # r_vars = model.addVars(len(demand_df_train), K, lb=0.0, ub=1.0, name=\"r\")\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(len(Qk_hat_df), lb=0.0, name=\"Q1_var\")\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            lb=0.0,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df), lb=-GRB.INFINITY, name=f\"Q_hat_adjusted\"\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, _ in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            ### 用線性回歸計算F_var\n",
    "            model.addConstr(\n",
    "                f_vars[i]\n",
    "                == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            )\n",
    "            model.addGenConstrLogistic(\n",
    "                xvar=f_vars[i], yvar=F_vars[i], name=f\"logistic_constraint_{i}\"\n",
    "            )\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"Ensure_only_one_R_true_{i}\",\n",
    "            )\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            # ### 0~k-1 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Left_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0s[i],\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1s[i],\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train))),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "        model.write(\"s4_model_debug.lp\")\n",
    "        model.write(\"s4_model.mps\")\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                print(\"===================== 找到最佳解 ==================\")\n",
    "                print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                print(\"Alphas values:\")\n",
    "                for key, alpha in alphas.items():\n",
    "                    print(f\"alpha[{key}]: {alpha.X}\")\n",
    "\n",
    "                # print(\"Beta values:\")\n",
    "                # for key, beta in betas.items():\n",
    "                #     print(f\"beta{key}: {beta.X}\")\n",
    "\n",
    "                alpha_values = np.array([alpha.X for _, alpha in alphas.items()])\n",
    "                # beta_values = np.array(\n",
    "                #     [[betas[k, j].X for j in range(features_num + 1)] for k in range(K)]\n",
    "                # )\n",
    "                # print(f\"beta_values:\\n{beta_values}\")\n",
    "\n",
    "                f_values = np.array([f.X for _, f in f_vars.items()])\n",
    "                # tau_values = np.array(\n",
    "                #     [\n",
    "                #         [tau_vars[i, j].X for j in range(K)]\n",
    "                #         for i in range(len(demand_df_train))\n",
    "                #     ]\n",
    "                # )\n",
    "\n",
    "                print(f\"------------\")\n",
    "                print(f\"f_values:\\n{f_values}\")\n",
    "                # print(f\"tau_values:\\n{tau_values}\")\n",
    "\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                # all_rs = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                all_holding_costs_0 = []\n",
    "                all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    # print(\"----------------------------------------------\")\n",
    "                    # print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "                    all_Q0s.append(Q0_vars[i].X)\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    all_Fs.append(F_vars[i].X)\n",
    "                    all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    rs = []\n",
    "                    for k in range(K):\n",
    "                        # rs.append(r_vars[i, k].X)\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        # print(\n",
    "                        #     f\"第 {k+2} 天補貨策略: R_vars = {R_value}, r_vars = {rs[k]}\"\n",
    "                        # )\n",
    "                        # print(f\"第 {k+2} 天補貨策略: R_vars = {R_value}\")\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    # print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "\n",
    "                    all_Rs.append(reorder_day)\n",
    "                    # all_rs.append(rs)\n",
    "\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    print(check_results_df)\n",
    "\n",
    "                #     for t in range(2):\n",
    "                #         if t == 0:\n",
    "                #             print(\n",
    "                #                 f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                #             )\n",
    "                #         else:\n",
    "                #             print(\n",
    "                #                 f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                #             )\n",
    "\n",
    "                #     print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                # print(\"==========================================\")\n",
    "                # print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    alpha_values,\n",
    "                    None,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    f_values,\n",
    "                    None,\n",
    "                    all_holding_costs_0,\n",
    "                    all_holding_costs_1,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_flexible_beta_with_softmax_9(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    result = __fully_flexible_beta_with_softmax_9(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "    if result is None:\n",
    "        print(f\"找不到最佳解\")\n",
    "        return None, None\n",
    "    else:\n",
    "        (\n",
    "            all_Rs,\n",
    "            all_losses,\n",
    "            all_lefts,\n",
    "            all_profits,\n",
    "            all_operation_profits,\n",
    "            alpha_values,\n",
    "            beta_values,\n",
    "            all_Fs,\n",
    "            all_Q0s,\n",
    "            all_Q1s,\n",
    "            f_values,\n",
    "            tau_values,\n",
    "            holding_costs_0s,\n",
    "            holding_costs_1s,\n",
    "            all_left0s,\n",
    "            all_left1s,\n",
    "            all_lost0s,\n",
    "            all_lost1s,\n",
    "        ) = result\n",
    "\n",
    "        print(f\"all_Rs: {all_Rs}\")\n",
    "\n",
    "        return make_s3_related_strtegies_result(\n",
    "            all_Rs=all_Rs,\n",
    "            losses=all_losses,\n",
    "            lefts=all_lefts,\n",
    "            profits=all_profits,\n",
    "            operation_profits=all_operation_profits,\n",
    "            alpha_values=alpha_values,\n",
    "            beta_values=beta_values,\n",
    "            F_vars=all_Fs,\n",
    "            Q0_vars=all_Q0s,\n",
    "            Q1_vars=all_Q1s,\n",
    "            f_values=f_values,\n",
    "            tau_values=tau_values,\n",
    "            holding_costs_0s=holding_costs_0s,\n",
    "            holding_costs_1s=holding_costs_1s,\n",
    "            all_left0s=all_left0s,\n",
    "            all_left1s=all_left1s,\n",
    "            all_lost0s=all_lost0s,\n",
    "            all_lost1s=all_lost1s,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S11 - Beta(Beta+Gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __fully_flexible_beta_with_softmax_11(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "        model.setParam(\"IntFeasTol\", 1e-9)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        alphas = model.addVars(features_num + 1, lb=-GRB.INFINITY, name=\"alphas\")\n",
    "        betas = model.addVars(K, lb=-GRB.INFINITY, name=\"betas\")  # for intercept\n",
    "        gammas = model.addVars(\n",
    "            features_num, lb=-GRB.INFINITY, name=\"gammas\"\n",
    "        )  # for features coefficients\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "        Sold_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_0\")\n",
    "        Left_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_0\")\n",
    "        Lost_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_0\")\n",
    "\n",
    "        Sold_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_1\")\n",
    "        Left_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_1\")\n",
    "        Lost_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_1\")\n",
    "\n",
    "        # Holding_Cost_0s = model.addVars(\n",
    "        #     len(demand_df_train), lb=0.0, name=\"Holding_Cost_0\"\n",
    "        # )\n",
    "\n",
    "        # Holding_Cost_1s = model.addVars(\n",
    "        #     len(demand_df_train), lb=0.0, name=\"Holding_Cost_1\"\n",
    "        # )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, name=\"profits_vars\"\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, name=\"Total_Demand_from_k_to_T\"\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        f_vars = model.addVars(len(demand_df_train), lb=-GRB.INFINITY, name=\"f_var\")\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=1, name=\"Fraction_for_second_order_amount\"\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=(Q_star + 1), name=\"Q0_var\"\n",
    "        )\n",
    "\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        r_vars = model.addVars(len(demand_df_train), K, lb=0.0, ub=1.0, name=\"r\")\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(len(Qk_hat_df), lb=0.0, name=\"Q1_var\")\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            lb=0.0,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df), lb=-GRB.INFINITY, name=f\"Q_hat_adjusted\"\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, _ in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            ### 用線性回歸計算F_var\n",
    "            model.addConstr(\n",
    "                f_vars[i]\n",
    "                == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            )\n",
    "            model.addGenConstrLogistic(\n",
    "                xvar=f_vars[i], yvar=F_vars[i], name=f\"logistic_constraint_{i}\"\n",
    "            )\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "            # 用線性回歸計算確定最佳補貨時間\n",
    "            exp_tau_vars = []\n",
    "            for k in range(K):\n",
    "\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, k]\n",
    "                    == gp.quicksum(\n",
    "                        X_data[j] * gammas[j]\n",
    "                        for j in range(features_num)  # features coefficient\n",
    "                    )\n",
    "                    + betas[k],  # intercept\n",
    "                    name=f\"tau_computation_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "                exp_tau_var = model.addVar(lb=0, name=f\"exp_tau_var_{i}_{k}\")\n",
    "                # neg_tau_var = model.addVar(\n",
    "                #     lb=-GRB.INFINITY, ub=0, name=f\"neg_tau_var_{i}_{k}\"\n",
    "                # )\n",
    "\n",
    "                # model.addConstr(\n",
    "                #     neg_tau_var == -tau_vars[i, k], name=f\"neg_tau_constr_{i}_{k}\"\n",
    "                # )\n",
    "                # model.addGenConstrExp(xvar=neg_tau_var, yvar=exp_tau_var)\n",
    "                model.addGenConstrExp(xvar=tau_vars[i, k], yvar=exp_tau_var)\n",
    "\n",
    "                exp_tau_vars.append(exp_tau_var)\n",
    "\n",
    "            ### 找到最大 R 以及 r, R 的相關限制式 -> k: 0~7\n",
    "            for k in range(K):\n",
    "                model.addConstr(\n",
    "                    r_vars[i, k] * gp.quicksum(exp_tau_vars) == exp_tau_vars[k],\n",
    "                    name=f\"softmax_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "            model.addConstr(\n",
    "                gp.quicksum(r_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"sum_r_{i}\",\n",
    "            )\n",
    "\n",
    "            max_r_helpers = model.addVar(lb=0.0, ub=1.0, name=\"max_r_helper\")\n",
    "            model.addGenConstrMax(\n",
    "                max_r_helpers,\n",
    "                [r_vars[i, k] for k in range(K)],\n",
    "                name=f\"MaxRConstraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # 確保 R_vars 的邏輯行為\n",
    "            # for k in range(K):\n",
    "            #     model.addGenConstrIndicator(\n",
    "            #         R_vars[i, k], 1, r_vars[i, k] == max_r_helpers\n",
    "            #     )\n",
    "\n",
    "            epsilon = 1e-3  # 可調整的小正數\n",
    "            for k in range(K):\n",
    "                for k2 in range(K):\n",
    "                    if k != k2:\n",
    "                        model.addGenConstrIndicator(\n",
    "                            R_vars[i, k],\n",
    "                            True,\n",
    "                            r_vars[i, k] >= r_vars[i, k2] + epsilon,\n",
    "                            name=f\"tau_diff_{i}_{k}_{k2}\",\n",
    "                        )\n",
    "\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"Ensure_only_one_R_true_{i}\",\n",
    "            )\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            # ### 0~k-1 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Left_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0s[i],\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1s[i],\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train))),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "        model.write(\"s4_model_debug.lp\")\n",
    "        model.write(\"s4_model.mps\")\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                print(\"===================== 找到最佳解 ==================\")\n",
    "                print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                print(\"Alphas values:\")\n",
    "                for key, alpha in alphas.items():\n",
    "                    print(f\"alpha[{key}]: {alpha.X}\")\n",
    "\n",
    "                # print(\"Beta values:\")\n",
    "                # for key, beta in betas.items():\n",
    "                #     print(f\"beta{key}: {beta.X}\")\n",
    "\n",
    "                alpha_values = np.array([alpha.X for _, alpha in alphas.items()])\n",
    "                beta_values = np.array([betas[k].X for k in range(K)])\n",
    "                print(f\"beta_values:\\n{beta_values}\")\n",
    "\n",
    "                gamma_values = np.array([gammas[j].X for j in range(features_num)])\n",
    "                print(f\"gamma_values:\\n{gamma_values}\")\n",
    "\n",
    "                f_values = np.array([f.X for _, f in f_vars.items()])\n",
    "                tau_values = np.array(\n",
    "                    [\n",
    "                        [tau_vars[i, j].X for j in range(K)]\n",
    "                        for i in range(len(demand_df_train))\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                print(f\"------------\")\n",
    "                print(f\"f_values:\\n{f_values}\")\n",
    "                print(f\"tau_values:\\n{tau_values}\")\n",
    "\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                all_rs = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                # all_holding_costs_0 = []\n",
    "                # all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    print(\"----------------------------------------------\")\n",
    "                    print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    # Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    # Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "                    all_Q0s.append(Q0_vars[i].X)\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    all_Fs.append(F_vars[i].X)\n",
    "                    # all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    # all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    rs = []\n",
    "                    for k in range(K):\n",
    "                        rs.append(r_vars[i, k].X)\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        print(\n",
    "                            f\"第 {k+2} 天補貨策略: R_vars = {R_value}, r_vars = {rs[k]}\"\n",
    "                        )\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "\n",
    "                    all_Rs.append(reorder_day)\n",
    "                    all_rs.append(rs)\n",
    "\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    print(check_results_df)\n",
    "\n",
    "                    # for t in range(2):\n",
    "                    #     if t == 0:\n",
    "                    #         print(\n",
    "                    #             f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                    #         )\n",
    "                    #     else:\n",
    "                    #         print(\n",
    "                    #             f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                    #         )\n",
    "\n",
    "                    # print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                print(\"==========================================\")\n",
    "                print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    alpha_values,\n",
    "                    beta_values,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    f_values,\n",
    "                    tau_values,\n",
    "                    None,\n",
    "                    None,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                    gamma_values,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_flexible_beta_with_softmax_11(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    result = __fully_flexible_beta_with_softmax_11(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "    if result is None:\n",
    "        print(f\"找不到最佳解\")\n",
    "        return None, None\n",
    "    else:\n",
    "        (\n",
    "            all_Rs,\n",
    "            all_losses,\n",
    "            all_lefts,\n",
    "            all_profits,\n",
    "            all_operation_profits,\n",
    "            alpha_values,\n",
    "            beta_values,\n",
    "            all_Fs,\n",
    "            all_Q0s,\n",
    "            all_Q1s,\n",
    "            f_values,\n",
    "            tau_values,\n",
    "            holding_costs_0s,\n",
    "            holding_costs_1s,\n",
    "            all_left0s,\n",
    "            all_left1s,\n",
    "            all_lost0s,\n",
    "            all_lost1s,\n",
    "            gamma_values,\n",
    "        ) = result\n",
    "\n",
    "        print(f\"all_Rs: {all_Rs}\")\n",
    "\n",
    "        return make_s3_related_strtegies_result(\n",
    "            all_Rs=all_Rs,\n",
    "            losses=all_losses,\n",
    "            lefts=all_lefts,\n",
    "            profits=all_profits,\n",
    "            operation_profits=all_operation_profits,\n",
    "            alpha_values=alpha_values,\n",
    "            beta_values=beta_values,\n",
    "            F_vars=all_Fs,\n",
    "            Q0_vars=all_Q0s,\n",
    "            Q1_vars=all_Q1s,\n",
    "            f_values=f_values,\n",
    "            tau_values=tau_values,\n",
    "            holding_costs_0s=holding_costs_0s,\n",
    "            holding_costs_1s=holding_costs_1s,\n",
    "            all_left0s=all_left0s,\n",
    "            all_left1s=all_left1s,\n",
    "            all_lost0s=all_lost0s,\n",
    "            all_lost1s=all_lost1s,\n",
    "            gamma_values=gamma_values,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S12 - Beta without r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __fully_flexible_beta_with_softmax_12(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "        model.setParam(\"IntFeasTol\", 1e-9)\n",
    "        model.setParam(\"NumericFocus\", 3)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        alphas = model.addVars(features_num + 1, lb=-GRB.INFINITY, name=\"alphas\")\n",
    "        betas = model.addVars(K, features_num + 1, lb=-GRB.INFINITY, name=\"betas\")\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "        Sold_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_0\")\n",
    "        Left_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_0\")\n",
    "        Lost_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_0\")\n",
    "\n",
    "        Sold_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_1\")\n",
    "        Left_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_1\")\n",
    "        Lost_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_1\")\n",
    "\n",
    "        Holding_Cost_0s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_0\"\n",
    "        )\n",
    "\n",
    "        Holding_Cost_1s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_1\"\n",
    "        )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, name=\"profits_vars\"\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, name=\"Total_Demand_from_k_to_T\"\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        f_vars = model.addVars(len(demand_df_train), lb=-GRB.INFINITY, name=\"f_var\")\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=1, name=\"Fraction_for_second_order_amount\"\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=(Q_star + 1), name=\"Q0_var\"\n",
    "        )\n",
    "\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        # tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        r_vars = model.addVars(len(demand_df_train), K, lb=0.0, ub=1.0, name=\"r\")\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(len(Qk_hat_df), lb=0.0, name=\"Q1_var\")\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            lb=0.0,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df), lb=-GRB.INFINITY, name=f\"Q_hat_adjusted\"\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, _ in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            ### 用線性回歸計算F_var\n",
    "            model.addConstr(\n",
    "                f_vars[i]\n",
    "                == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            )\n",
    "            model.addGenConstrLogistic(\n",
    "                xvar=f_vars[i],\n",
    "                yvar=F_vars[i],\n",
    "                options=\"FuncNonlinear=1\",\n",
    "                name=f\"logistic_constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model(Alternative Model) ===================\n",
    "\n",
    "            # Step 1: 利用線性回歸計算 tau\n",
    "            for k in range(K):\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, k]\n",
    "                    == gp.quicksum(\n",
    "                        X_data[j] * betas[k, j] for j in range(features_num + 1)\n",
    "                    ),\n",
    "                    name=f\"tau_computation_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "            delta = 1e-3\n",
    "            tau_star = model.addVar(lb=-GRB.INFINITY, name=f\"tau_star_{i}\")\n",
    "\n",
    "            for k in range(K):\n",
    "                # 如果候選 k 被選中 (R_vars[i,k] == 1)，則強制 tau_vars[i,k] 等於 tau_star\n",
    "                model.addGenConstrIndicator(\n",
    "                    R_vars[i, k],\n",
    "                    True,\n",
    "                    tau_vars[i, k] == tau_star,\n",
    "                    name=f\"tau_star_eq_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "                # 如果候選 k 未被選中 (R_vars[i,k] == 0)，則必須有 tau_vars[i,k] <= tau_star - delta\n",
    "                # 利用 Big-M 技巧：當 R_vars[i,k]==0 時，約束變為 tau_vars[i,k] <= tau_star - delta\n",
    "                # 當 R_vars[i,k]==1 時，由於前面的 indicator 約束已強制 tau_vars[i,k] == tau_star，\n",
    "                # 此約束則不會影響模型（因為 tau_star <= tau_star - delta + M 已經成立）\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, k] <= tau_star - delta + M * R_vars[i, k],\n",
    "                    name=f\"tau_gap_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "            # Step 3: 保證只有一個候選被選中 (即 R_vars 為 1 的只有一個)\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"one_R_{i}\",\n",
    "            )\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            # ### 0~k-1 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Left_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0s[i],\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1s[i],\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * (Left_0s[i] + Left_1s[i])  # left cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train))),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "        model.write(\"s4_model_debug.lp\")\n",
    "        model.write(\"s4_model.mps\")\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                # print(\"===================== 找到最佳解 ==================\")\n",
    "                # print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                # print(\"Alphas values:\")\n",
    "                # for key, alpha in alphas.items():\n",
    "                #     print(f\"alpha[{key}]: {alpha.X}\")\n",
    "\n",
    "                alpha_values = np.array([alpha.X for _, alpha in alphas.items()])\n",
    "                beta_values = np.array(\n",
    "                    [[betas[k, j].X for j in range(features_num + 1)] for k in range(K)]\n",
    "                )\n",
    "                # print(f\"beta_values:\\n{beta_values}\")\n",
    "\n",
    "                f_values = np.array([f.X for _, f in f_vars.items()])\n",
    "                tau_values = np.array(\n",
    "                    [\n",
    "                        [tau_vars[i, j].X for j in range(K)]\n",
    "                        for i in range(len(demand_df_train))\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                # print(f\"------------\")\n",
    "                # print(f\"f_values:\\n{f_values}\")\n",
    "                # print(f\"tau_values:\\n{tau_values}\")\n",
    "\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                all_rs = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                all_holding_costs_0 = []\n",
    "                all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    # print(\"----------------------------------------------\")\n",
    "                    # print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    # all_Fs.append(F_vars[i].X)\n",
    "                    all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    # Check f\n",
    "                    x_data = training_df.iloc[i].tolist()\n",
    "                    x_data.append(1)\n",
    "                    f_train, F_train, Q0_train = compute_f_F_Q(\n",
    "                        x_data, alpha_values, Q_star\n",
    "                    )\n",
    "                    if (\n",
    "                        truncate_to_2(f_train) == truncate_to_2(f_vars[i].X)\n",
    "                        and truncate_to_2(F_train) == truncate_to_2(F_vars[i].X)\n",
    "                        and truncate_to_2(Q0_train) == truncate_to_2(Q0_vars[i].X)\n",
    "                    ):\n",
    "                        print(\"f_train, F_train, Q0_train 都相等\")\n",
    "                        all_Q0s.append(Q0_vars[i].X)\n",
    "                        all_Fs.append(F_vars[i].X)\n",
    "                    else:\n",
    "                        print(f\"f_train, F_train, Q0_train 不相等\")\n",
    "                        all_Q0s.append(-1)\n",
    "                        all_Fs.append(-1)\n",
    "                        # results[\"Q0s\"].append(Q0_vars[i].X)\n",
    "                        # results[\"Fs\"].append(F_vars[i].X)\n",
    "                        # results[\"fs\"].append(f_vars[i].X)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    rs = []\n",
    "                    for k in range(K):\n",
    "                        rs.append(r_vars[i, k].X)\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        print(\n",
    "                            f\"第 {k+2} 天補貨策略: R_vars = {R_value}, tau_vars = {tau_vars[i, k].X}\"\n",
    "                        )\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "\n",
    "                    all_Rs.append(reorder_day)\n",
    "                    all_rs.append(rs)\n",
    "\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    # print(check_results_df)\n",
    "\n",
    "                    # for t in range(2):\n",
    "                    #     if t == 0:\n",
    "                    #         print(\n",
    "                    #             f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                    #         )\n",
    "                    #     else:\n",
    "                    #         print(\n",
    "                    #             f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                    #         )\n",
    "\n",
    "                    # print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                # print(\"==========================================\")\n",
    "                # print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    alpha_values,\n",
    "                    beta_values,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    f_values,\n",
    "                    tau_values,\n",
    "                    all_holding_costs_0,\n",
    "                    all_holding_costs_1,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_flexible_beta_with_softmax_12(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    result = __fully_flexible_beta_with_softmax_12(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "    if result is None:\n",
    "        print(f\"找不到最佳解\")\n",
    "        return None, None\n",
    "    else:\n",
    "        (\n",
    "            all_Rs,\n",
    "            all_losses,\n",
    "            all_lefts,\n",
    "            all_profits,\n",
    "            all_operation_profits,\n",
    "            alpha_values,\n",
    "            beta_values,\n",
    "            all_Fs,\n",
    "            all_Q0s,\n",
    "            all_Q1s,\n",
    "            f_values,\n",
    "            tau_values,\n",
    "            holding_costs_0s,\n",
    "            holding_costs_1s,\n",
    "            all_left0s,\n",
    "            all_left1s,\n",
    "            all_lost0s,\n",
    "            all_lost1s,\n",
    "        ) = result\n",
    "\n",
    "        print(f\"all_Rs: {all_Rs}\")\n",
    "\n",
    "        return make_s3_related_strtegies_result(\n",
    "            all_Rs=all_Rs,\n",
    "            losses=all_losses,\n",
    "            lefts=all_lefts,\n",
    "            profits=all_profits,\n",
    "            operation_profits=all_operation_profits,\n",
    "            alpha_values=alpha_values,\n",
    "            beta_values=beta_values,\n",
    "            F_vars=all_Fs,\n",
    "            Q0_vars=all_Q0s,\n",
    "            Q1_vars=all_Q1s,\n",
    "            f_values=f_values,\n",
    "            tau_values=tau_values,\n",
    "            holding_costs_0s=holding_costs_0s,\n",
    "            holding_costs_1s=holding_costs_1s,\n",
    "            all_left0s=all_left0s,\n",
    "            all_left1s=all_left1s,\n",
    "            all_lost0s=all_lost0s,\n",
    "            all_lost1s=all_lost1s,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S14 - Optimized F & Rk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __cal_optimized_F_R(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "        model.setParam(\"IntFeasTol\", 1e-9)\n",
    "        model.setParam(\"NumericFocus\", 3)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "        Sold_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_0\")\n",
    "        Left_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_0\")\n",
    "        Lost_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_0\")\n",
    "\n",
    "        Sold_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_1\")\n",
    "        Left_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_1\")\n",
    "        Lost_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_1\")\n",
    "\n",
    "        Holding_Cost_0s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_0\"\n",
    "        )\n",
    "\n",
    "        Holding_Cost_1s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_1\"\n",
    "        )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, name=\"profits_vars\"\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, name=\"Total_Demand_from_k_to_T\"\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=1, name=\"Fraction_for_second_order_amount\"\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=(Q_star + 1), name=\"Q0_var\"\n",
    "        )\n",
    "\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(len(Qk_hat_df), lb=0.0, name=\"Q1_var\")\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            lb=0.0,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df), lb=-GRB.INFINITY, name=f\"Q_hat_adjusted\"\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, _ in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            model.addConstr(F_vars[i] >= 0, name=f\"Fraction_lower_bound_{i}\")\n",
    "            model.addConstr(F_vars[i] <= 1, name=f\"Fraction_upper_bound_{i}\")\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"Ensure_only_one_R_true_{i}\",\n",
    "            )\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            # ### 0~k-1 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Left_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0s[i],\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1s[i],\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # model.addConstr(\n",
    "            #     profits_vars[i]\n",
    "            #     == (\n",
    "            #         (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "            #         - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "            #         - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "            #     ),\n",
    "            #     name=f\"Profit_Constraint_{i}\",\n",
    "            # )\n",
    "\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * (Left_0s[i] + Left_1s[i])  # left cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train))),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "        model.write(\"s4_model_debug.lp\")\n",
    "        model.write(\"s4_model.mps\")\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                # print(\"===================== 找到最佳解 ==================\")\n",
    "                # print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                # all_rs = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                all_holding_costs_0 = []\n",
    "                all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    # print(\"----------------------------------------------\")\n",
    "                    # print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "                    all_Q0s.append(Q0_vars[i].X)\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    all_Fs.append(F_vars[i].X)\n",
    "                    all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    rs = []\n",
    "                    for k in range(K):\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        print(f\"第 {k+2} 天補貨策略: R_vars = {R_value}\")\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    # print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "\n",
    "                    all_Rs.append(reorder_day)\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    # print(check_results_df)\n",
    "\n",
    "                #     for t in range(2):\n",
    "                #         if t == 0:\n",
    "                #             print(\n",
    "                #                 f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                #             )\n",
    "                #         else:\n",
    "                #             print(\n",
    "                #                 f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                #             )\n",
    "\n",
    "                #     print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                # print(\"==========================================\")\n",
    "                # print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    all_holding_costs_0,\n",
    "                    all_holding_costs_1,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_optimized_F_R(\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df,\n",
    "    Qk_hat_df,\n",
    "    training_df,\n",
    "):\n",
    "    results_dict = {\n",
    "        \"R(T)\": [],\n",
    "        \"average_profits\": [],\n",
    "        \"average_losses\": [],\n",
    "        \"average_lefts\": [],\n",
    "        \"average_operation_profits\": [],\n",
    "        \"alpha_values\": [],\n",
    "        \"F_vars\": [],\n",
    "        \"Q0_vars\": [],\n",
    "        \"Q1_vars\": [],\n",
    "    }\n",
    "\n",
    "    max_profit = None\n",
    "    max_profit_stimulation_result = {}\n",
    "\n",
    "    (\n",
    "        all_Rs,\n",
    "        losses,\n",
    "        lefts,\n",
    "        profits,\n",
    "        operation_profits,\n",
    "        F_vars,\n",
    "        Q0_vars,\n",
    "        Q1_vars,\n",
    "        all_holding_costs_0,\n",
    "        all_holding_costs_1,\n",
    "        all_left0s,\n",
    "        all_left1s,\n",
    "        all_lost0s,\n",
    "        all_lost1s,\n",
    "    ) = __cal_optimized_F_R(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df,\n",
    "        Qk_hat_df=Qk_hat_df,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "\n",
    "    # 計算平均值\n",
    "    average_losses = sum(losses) / len(losses) if losses else 0\n",
    "    average_lefts = sum(lefts) / len(lefts) if lefts else 0\n",
    "    average_profits = sum(profits) / len(profits) if profits else 0\n",
    "    average_operation_profits = (\n",
    "        sum(operation_profits) / len(operation_profits) if operation_profits else 0\n",
    "    )\n",
    "\n",
    "    # 將結果存儲到字典中\n",
    "    results_dict[\"R(T)\"].append(all_Rs)\n",
    "    results_dict[\"average_losses\"].append(average_losses)\n",
    "    results_dict[\"average_lefts\"].append(average_lefts)\n",
    "    results_dict[\"average_profits\"].append(average_profits)\n",
    "    results_dict[\"average_operation_profits\"].append(average_operation_profits)\n",
    "    results_dict[\"alpha_values\"].append(None)\n",
    "    results_dict[\"F_vars\"].append(F_vars)\n",
    "    results_dict[\"Q0_vars\"].append(Q0_vars)\n",
    "    results_dict[\"Q1_vars\"].append(Q1_vars)\n",
    "\n",
    "    # print(f\"The average profits is {average_profits}\")\n",
    "\n",
    "    if max_profit is None or max_profit < average_profits:\n",
    "        # print(f\"max_profit is changed from {max_profit} to {average_profits}\")\n",
    "        max_profit = average_profits\n",
    "        max_profit_stimulation_result = {\n",
    "            \"R\": all_Rs,\n",
    "            \"F\": F_vars,\n",
    "            \"profits\": profits,\n",
    "            \"losses\": losses,\n",
    "            \"lefts\": lefts,\n",
    "            \"operation_profits\": operation_profits,\n",
    "            \"Q0\": Q0_vars,\n",
    "            \"Q1\": Q1_vars,\n",
    "        }\n",
    "\n",
    "    return pd.DataFrame(results_dict).sort_values(\n",
    "        by=\"average_profits\", ascending=False\n",
    "    ), pd.DataFrame(max_profit_stimulation_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S15 - Beta with Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __fully_flexible_beta_with_lasso_15(\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_train,\n",
    "    Qk_hat_df,\n",
    "    training_df,\n",
    "    lambda_beta,\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "        model.setParam(\"IntFeasTol\", 1e-9)\n",
    "        model.setParam(\"NumericFocus\", 3)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        alphas = model.addVars(features_num + 1, lb=-GRB.INFINITY, name=\"alphas\")\n",
    "        betas = model.addVars(K, features_num + 1, lb=-GRB.INFINITY, name=\"betas\")\n",
    "        abs_betas = model.addVars(betas.keys(), lb=0, name=\"abs_beta\")\n",
    "\n",
    "        # 進行 lasso 處理\n",
    "        for k, j in betas.keys():\n",
    "            model.addConstr(abs_betas[k, j] >= betas[k, j])\n",
    "            model.addConstr(abs_betas[k, j] >= -betas[k, j])\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "        Sold_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_0\")\n",
    "        Left_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_0\")\n",
    "        Lost_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_0\")\n",
    "\n",
    "        Sold_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_1\")\n",
    "        Left_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_1\")\n",
    "        Lost_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_1\")\n",
    "\n",
    "        Holding_Cost_0s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_0\"\n",
    "        )\n",
    "\n",
    "        Holding_Cost_1s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_1\"\n",
    "        )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, name=\"profits_vars\"\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, name=\"Total_Demand_from_k_to_T\"\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        f_vars = model.addVars(len(demand_df_train), lb=-GRB.INFINITY, name=\"f_var\")\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=1, name=\"Fraction_for_second_order_amount\"\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=(Q_star + 1), name=\"Q0_var\"\n",
    "        )\n",
    "\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        # tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        r_vars = model.addVars(len(demand_df_train), K, lb=0.0, ub=1.0, name=\"r\")\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(len(Qk_hat_df), lb=0.0, name=\"Q1_var\")\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            lb=0.0,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df), lb=-GRB.INFINITY, name=f\"Q_hat_adjusted\"\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, _ in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            ### 用線性回歸計算F_var\n",
    "            model.addConstr(\n",
    "                f_vars[i]\n",
    "                == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            )\n",
    "            model.addGenConstrLogistic(\n",
    "                xvar=f_vars[i],\n",
    "                yvar=F_vars[i],\n",
    "                options=\"FuncNonlinear=1\",\n",
    "                name=f\"logistic_constraint_{i}\",\n",
    "            )\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model(Alternative Model) ===================\n",
    "\n",
    "            # Step 1: 利用線性回歸計算 tau\n",
    "            for k in range(K):\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, k]\n",
    "                    == gp.quicksum(\n",
    "                        X_data[j] * betas[k, j] for j in range(features_num + 1)\n",
    "                    ),\n",
    "                    name=f\"tau_computation_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "            delta = 1e-3\n",
    "            tau_star = model.addVar(lb=-GRB.INFINITY, name=f\"tau_star_{i}\")\n",
    "\n",
    "            for k in range(K):\n",
    "                # 如果候選 k 被選中 (R_vars[i,k] == 1)，則強制 tau_vars[i,k] 等於 tau_star\n",
    "                model.addGenConstrIndicator(\n",
    "                    R_vars[i, k],\n",
    "                    True,\n",
    "                    tau_vars[i, k] == tau_star,\n",
    "                    name=f\"tau_star_eq_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, k] <= tau_star - delta + M * R_vars[i, k],\n",
    "                    name=f\"tau_gap_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "            # Step 3: 保證只有一個候選被選中 (即 R_vars 為 1 的只有一個)\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"one_R_{i}\",\n",
    "            )\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            # ### 0~k-1 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Left_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0s[i],\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1s[i],\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train)))\n",
    "            - lambda_beta * gp.quicksum(abs_betas[k, j] for k, j in abs_betas.keys()),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "        model.write(\"s4_model_debug.lp\")\n",
    "        model.write(\"s4_model.mps\")\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                # print(\"===================== 找到最佳解 ==================\")\n",
    "                # print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                # print(\"Alphas values:\")\n",
    "                # for key, alpha in alphas.items():\n",
    "                #     print(f\"alpha[{key}]: {alpha.X}\")\n",
    "\n",
    "                alpha_values = np.array([alpha.X for _, alpha in alphas.items()])\n",
    "                beta_values = np.array(\n",
    "                    [[betas[k, j].X for j in range(features_num + 1)] for k in range(K)]\n",
    "                )\n",
    "                # print(f\"beta_values:\\n{beta_values}\")\n",
    "\n",
    "                f_values = np.array([f.X for _, f in f_vars.items()])\n",
    "                tau_values = np.array(\n",
    "                    [\n",
    "                        [tau_vars[i, j].X for j in range(K)]\n",
    "                        for i in range(len(demand_df_train))\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                # print(f\"------------\")\n",
    "                # print(f\"f_values:\\n{f_values}\")\n",
    "                # print(f\"tau_values:\\n{tau_values}\")\n",
    "\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                all_rs = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                all_holding_costs_0 = []\n",
    "                all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    # print(\"----------------------------------------------\")\n",
    "                    # print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "                    all_Q0s.append(Q0_vars[i].X)\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    all_Fs.append(F_vars[i].X)\n",
    "                    all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    rs = []\n",
    "                    for k in range(K):\n",
    "                        rs.append(r_vars[i, k].X)\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        # print(\n",
    "                        #     f\"第 {k+2} 天補貨策略: R_vars = {R_value}, tau_vars = {tau_vars[i, k].X}\"\n",
    "                        # )\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    # print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "\n",
    "                    all_Rs.append(reorder_day)\n",
    "                    all_rs.append(rs)\n",
    "\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    # print(check_results_df)\n",
    "\n",
    "                #     for t in range(2):\n",
    "                #         if t == 0:\n",
    "                #             print(\n",
    "                #                 f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                #             )\n",
    "                #         else:\n",
    "                #             print(\n",
    "                #                 f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                #             )\n",
    "\n",
    "                #     print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                # print(\"==========================================\")\n",
    "                # print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    alpha_values,\n",
    "                    beta_values,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    f_values,\n",
    "                    tau_values,\n",
    "                    all_holding_costs_0,\n",
    "                    all_holding_costs_1,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_flexible_beta_with_lasso_15(\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_train,\n",
    "    Qk_hat_df,\n",
    "    training_df,\n",
    "    lambda_beta,\n",
    "):\n",
    "\n",
    "    result = __fully_flexible_beta_with_lasso_15(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df,\n",
    "        training_df=training_df,\n",
    "        lambda_beta=lambda_beta,\n",
    "    )\n",
    "    if result is None:\n",
    "        print(f\"找不到最佳解\")\n",
    "        return None, None\n",
    "    else:\n",
    "        (\n",
    "            all_Rs,\n",
    "            all_losses,\n",
    "            all_lefts,\n",
    "            all_profits,\n",
    "            all_operation_profits,\n",
    "            alpha_values,\n",
    "            beta_values,\n",
    "            all_Fs,\n",
    "            all_Q0s,\n",
    "            all_Q1s,\n",
    "            f_values,\n",
    "            tau_values,\n",
    "            holding_costs_0s,\n",
    "            holding_costs_1s,\n",
    "            all_left0s,\n",
    "            all_left1s,\n",
    "            all_lost0s,\n",
    "            all_lost1s,\n",
    "        ) = result\n",
    "\n",
    "        # print(f\"all_Rs: {all_Rs}\")\n",
    "\n",
    "        return make_s3_related_strtegies_result(\n",
    "            all_Rs=all_Rs,\n",
    "            losses=all_losses,\n",
    "            lefts=all_lefts,\n",
    "            profits=all_profits,\n",
    "            operation_profits=all_operation_profits,\n",
    "            alpha_values=alpha_values,\n",
    "            beta_values=beta_values,\n",
    "            F_vars=all_Fs,\n",
    "            Q0_vars=all_Q0s,\n",
    "            Q1_vars=all_Q1s,\n",
    "            f_values=f_values,\n",
    "            tau_values=tau_values,\n",
    "            holding_costs_0s=holding_costs_0s,\n",
    "            holding_costs_1s=holding_costs_1s,\n",
    "            all_left0s=all_left0s,\n",
    "            all_left1s=all_left1s,\n",
    "            all_lost0s=all_lost0s,\n",
    "            all_lost1s=all_lost1s,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S16 - Beta with second Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __fully_flexible_beta_with_second_training_16(\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_train,\n",
    "    Qk_hat_df,\n",
    "    training_df,\n",
    "    lambda_beta,\n",
    "    last_beta_total,\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "        model.setParam(\"IntFeasTol\", 1e-9)\n",
    "        model.setParam(\"NumericFocus\", 3)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        alphas = model.addVars(features_num + 1, lb=-GRB.INFINITY, name=\"alphas\")\n",
    "        betas = model.addVars(K, features_num + 1, lb=-GRB.INFINITY, name=\"betas\")\n",
    "        abs_betas = model.addVars(betas.keys(), lb=0, name=\"abs_beta\")\n",
    "\n",
    "        # 進行絕對值處理\n",
    "        for k, j in betas.keys():\n",
    "            model.addConstr(abs_betas[k, j] >= betas[k, j])\n",
    "            model.addConstr(abs_betas[k, j] >= -betas[k, j])\n",
    "\n",
    "        # 設定 beta 的上限\n",
    "        model.addConstr(\n",
    "            gp.quicksum(abs_betas[k, j] for k, j in abs_betas.keys())\n",
    "            <= lambda_beta * last_beta_total,\n",
    "            name=\"beta_limit\",\n",
    "        )\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "        Sold_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_0\")\n",
    "        Left_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_0\")\n",
    "        Lost_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_0\")\n",
    "\n",
    "        Sold_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_1\")\n",
    "        Left_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_1\")\n",
    "        Lost_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_1\")\n",
    "\n",
    "        Holding_Cost_0s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_0\"\n",
    "        )\n",
    "\n",
    "        Holding_Cost_1s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_1\"\n",
    "        )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, name=\"profits_vars\"\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, name=\"Total_Demand_from_k_to_T\"\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        f_vars = model.addVars(len(demand_df_train), lb=-GRB.INFINITY, name=\"f_var\")\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=1, name=\"Fraction_for_second_order_amount\"\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=(Q_star + 1), name=\"Q0_var\"\n",
    "        )\n",
    "\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        # tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        r_vars = model.addVars(len(demand_df_train), K, lb=0.0, ub=1.0, name=\"r\")\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(len(Qk_hat_df), lb=0.0, name=\"Q1_var\")\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            lb=0.0,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df), lb=-GRB.INFINITY, name=f\"Q_hat_adjusted\"\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, _ in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            ### 用線性回歸計算F_var\n",
    "            model.addConstr(\n",
    "                f_vars[i]\n",
    "                == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            )\n",
    "            model.addGenConstrLogistic(\n",
    "                xvar=f_vars[i],\n",
    "                yvar=F_vars[i],\n",
    "                options=\"FuncNonlinear=1\",\n",
    "                name=f\"logistic_constraint_{i}\",\n",
    "            )\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model(Alternative Model) ===================\n",
    "\n",
    "            # Step 1: 利用線性回歸計算 tau\n",
    "            for k in range(K):\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, k]\n",
    "                    == gp.quicksum(\n",
    "                        X_data[j] * betas[k, j] for j in range(features_num + 1)\n",
    "                    ),\n",
    "                    name=f\"tau_computation_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "            delta = 1e-3\n",
    "            tau_star = model.addVar(lb=-GRB.INFINITY, name=f\"tau_star_{i}\")\n",
    "\n",
    "            for k in range(K):\n",
    "                # 如果候選 k 被選中 (R_vars[i,k] == 1)，則強制 tau_vars[i,k] 等於 tau_star\n",
    "                model.addGenConstrIndicator(\n",
    "                    R_vars[i, k],\n",
    "                    True,\n",
    "                    tau_vars[i, k] == tau_star,\n",
    "                    name=f\"tau_star_eq_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, k] <= tau_star - delta + M * R_vars[i, k],\n",
    "                    name=f\"tau_gap_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "            # Step 3: 保證只有一個候選被選中 (即 R_vars 為 1 的只有一個)\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"one_R_{i}\",\n",
    "            )\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            # ### 0~k-1 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Left_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0s[i],\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1s[i],\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train)))\n",
    "            - lambda_beta * gp.quicksum(abs_betas[k, j] for k, j in abs_betas.keys()),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "        model.write(\"s4_model_debug.lp\")\n",
    "        model.write(\"s4_model.mps\")\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                # print(\"===================== 找到最佳解 ==================\")\n",
    "                # print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                # print(\"Alphas values:\")\n",
    "                # for key, alpha in alphas.items():\n",
    "                #     print(f\"alpha[{key}]: {alpha.X}\")\n",
    "\n",
    "                alpha_values = np.array([alpha.X for _, alpha in alphas.items()])\n",
    "                beta_values = np.array(\n",
    "                    [[betas[k, j].X for j in range(features_num + 1)] for k in range(K)]\n",
    "                )\n",
    "                # print(f\"beta_values:\\n{beta_values}\")\n",
    "\n",
    "                f_values = np.array([f.X for _, f in f_vars.items()])\n",
    "                tau_values = np.array(\n",
    "                    [\n",
    "                        [tau_vars[i, j].X for j in range(K)]\n",
    "                        for i in range(len(demand_df_train))\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                # print(f\"------------\")\n",
    "                # print(f\"f_values:\\n{f_values}\")\n",
    "                # print(f\"tau_values:\\n{tau_values}\")\n",
    "\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                all_rs = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                all_holding_costs_0 = []\n",
    "                all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    # print(\"----------------------------------------------\")\n",
    "                    # print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "                    all_Q0s.append(Q0_vars[i].X)\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    all_Fs.append(F_vars[i].X)\n",
    "                    all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    rs = []\n",
    "                    for k in range(K):\n",
    "                        rs.append(r_vars[i, k].X)\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        # print(\n",
    "                        #     f\"第 {k+2} 天補貨策略: R_vars = {R_value}, tau_vars = {tau_vars[i, k].X}\"\n",
    "                        # )\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    # print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "\n",
    "                    all_Rs.append(reorder_day)\n",
    "                    all_rs.append(rs)\n",
    "\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    # print(check_results_df)\n",
    "\n",
    "                #     for t in range(2):\n",
    "                #         if t == 0:\n",
    "                #             print(\n",
    "                #                 f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                #             )\n",
    "                #         else:\n",
    "                #             print(\n",
    "                #                 f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                #             )\n",
    "\n",
    "                #     print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                # print(\"==========================================\")\n",
    "                # print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    alpha_values,\n",
    "                    beta_values,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    f_values,\n",
    "                    tau_values,\n",
    "                    all_holding_costs_0,\n",
    "                    all_holding_costs_1,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_flexible_beta_with_second_training_16(\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_train,\n",
    "    Qk_hat_df,\n",
    "    training_df,\n",
    "    lambda_beta,\n",
    "    last_beta_total,\n",
    "):\n",
    "\n",
    "    result = __fully_flexible_beta_with_second_training_16(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df,\n",
    "        training_df=training_df,\n",
    "        lambda_beta=lambda_beta,\n",
    "        last_beta_total=last_beta_total,\n",
    "    )\n",
    "    if result is None:\n",
    "        print(f\"找不到最佳解\")\n",
    "        return None, None\n",
    "    else:\n",
    "        (\n",
    "            all_Rs,\n",
    "            all_losses,\n",
    "            all_lefts,\n",
    "            all_profits,\n",
    "            all_operation_profits,\n",
    "            alpha_values,\n",
    "            beta_values,\n",
    "            all_Fs,\n",
    "            all_Q0s,\n",
    "            all_Q1s,\n",
    "            f_values,\n",
    "            tau_values,\n",
    "            holding_costs_0s,\n",
    "            holding_costs_1s,\n",
    "            all_left0s,\n",
    "            all_left1s,\n",
    "            all_lost0s,\n",
    "            all_lost1s,\n",
    "        ) = result\n",
    "\n",
    "        # print(f\"all_Rs: {all_Rs}\")\n",
    "\n",
    "        return make_s3_related_strtegies_result(\n",
    "            all_Rs=all_Rs,\n",
    "            losses=all_losses,\n",
    "            lefts=all_lefts,\n",
    "            profits=all_profits,\n",
    "            operation_profits=all_operation_profits,\n",
    "            alpha_values=alpha_values,\n",
    "            beta_values=beta_values,\n",
    "            F_vars=all_Fs,\n",
    "            Q0_vars=all_Q0s,\n",
    "            Q1_vars=all_Q1s,\n",
    "            f_values=f_values,\n",
    "            tau_values=tau_values,\n",
    "            holding_costs_0s=holding_costs_0s,\n",
    "            holding_costs_1s=holding_costs_1s,\n",
    "            all_left0s=all_left0s,\n",
    "            all_left1s=all_left1s,\n",
    "            all_lost0s=all_lost0s,\n",
    "            all_lost1s=all_lost1s,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S1 - Grid for Fixed F & Fixed Rk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_fixed_F_fixed_R(\n",
    "    assigned_T,\n",
    "    assigned_F,\n",
    "    cost,\n",
    "    price,\n",
    "    salvage_value,\n",
    "    Qk_hat_df_test,\n",
    "    demand_df_test,\n",
    "    Q_star,\n",
    "):\n",
    "    assigned_R = assigned_T - 2\n",
    "    result, stimulation_result = cal_fixed_F_fixed_R(\n",
    "        Q_star,\n",
    "        assigned_F,\n",
    "        assigned_R,\n",
    "        demand_df_test,\n",
    "        cost,\n",
    "        price,\n",
    "        salvage_value,\n",
    "        Qk_hat_df_test,\n",
    "    )\n",
    "\n",
    "    results_df_1 = pd.DataFrame([result]).sort_values(\n",
    "        by=\"average_profits\", ascending=False\n",
    "    )\n",
    "\n",
    "    return results_df_1, pd.DataFrame(stimulation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S2 - Grid for Fixed Rk & Flexible F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_flexible_F_fixed_R(\n",
    "    assigned_R,\n",
    "    alphas,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_test,\n",
    "    Qk_hat_df_test,\n",
    "    testing_df,\n",
    "):\n",
    "\n",
    "    # ======================= Global Variables =======================\n",
    "\n",
    "    # Category 1 - Some variables that is important to future work\n",
    "    K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "    n = len(demand_df_test)\n",
    "\n",
    "    # Initialize lists or numpy arrays to replace Gurobi variables\n",
    "    Sold_0s = np.zeros(n)\n",
    "    Left_0s = np.zeros(n)\n",
    "    Lost_0s = np.zeros(n)\n",
    "    Sold_1s = np.zeros(n)\n",
    "    Left_1s = np.zeros(n)\n",
    "    Lost_1s = np.zeros(n)\n",
    "    all_holding_costs_0 = np.zeros(n)\n",
    "    all_holding_costs_1 = np.zeros(n)\n",
    "    profits_vars = np.zeros(n)\n",
    "\n",
    "    # 1-2. Arrays for demand calculation up to certain periods\n",
    "    total_demand_up_to_k_minus_1_vars = np.zeros(n)\n",
    "    total_demand_from_k_to_T_vars = np.zeros(n)\n",
    "    Q1_plus_lefts = np.zeros(n)\n",
    "\n",
    "    # 2. Variables for Model 2: Optimal Fraction Model\n",
    "    f_vars = np.zeros(n)\n",
    "    F_vars = np.zeros(n)  # Assuming values will be between 0 and 1\n",
    "    Q0_vars = np.zeros(n)  # Replace Q_star with a specific value as needed\n",
    "\n",
    "    # 3. Variables for Model 3: Optimal Order Time Model (2D array for binary values)\n",
    "    R_vars = np.zeros((n, K), dtype=int)  # Use dtype=int to represent binary 0/1 values\n",
    "\n",
    "    # 4. Variables for Model 4: Re-estimate order-up-to-level\n",
    "    Q1_vars = np.zeros(n)\n",
    "    Q_hats = np.zeros(n)\n",
    "    Q_hat_adjusteds = np.zeros(n)\n",
    "\n",
    "    # ======================= Start Stimulation! =======================\n",
    "\n",
    "    for i, row in demand_df_test.iterrows():\n",
    "\n",
    "        ### Data for this stimulation\n",
    "        demand_row = demand_df_test.iloc[i]\n",
    "        Qk_hat_df_test_row = Qk_hat_df_test.iloc[i]\n",
    "        X_data = testing_df.iloc[i].tolist()\n",
    "        X_data.append(1)\n",
    "\n",
    "        # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "        ### 用線性回歸計算F_var\n",
    "        f_vars[i] = sum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "        F_vars[i] = 1 / (1 + np.exp(-(f_vars[i])))\n",
    "        print(f\"f_vars[i]: {f_vars[i]}, F_vars[i]: {F_vars[i]}\")\n",
    "        Q0_vars[i] = F_vars[i] * Q_star\n",
    "\n",
    "        # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "        # Ensure only one `R` is set to 1 in each row by setting `assigned_R` to 1 and all others to 0\n",
    "        R_vars[i, assigned_R] = 1\n",
    "\n",
    "        # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "        Q_hats[i] = sum(\n",
    "            R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
    "        )\n",
    "        Q_hat_adjusteds[i] = Q_hats[i] - Q0_vars[i]\n",
    "        Q1_vars[i] = max(Q_hat_adjusteds[i], 0)\n",
    "\n",
    "        # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "        # Calculate the demand up to k-1\n",
    "        total_demand_up_to_k_minus_1 = sum(\n",
    "            R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_up_to_k_minus_1_vars[i] = total_demand_up_to_k_minus_1\n",
    "\n",
    "        # Calculate the demand from k to T\n",
    "        total_demand_from_k_to_T = sum(\n",
    "            R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars[i] = total_demand_from_k_to_T\n",
    "\n",
    "        Sold_0s[i] = min(total_demand_up_to_k_minus_1_vars[i], Q0_vars[i])\n",
    "        Left_0s[i] = max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "        Lost_0s[i] = max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "        Q1_plus_lefts[i] = Q1_vars[i] + Left_0s[i]\n",
    "\n",
    "        Sold_1s[i] = min(total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i])\n",
    "        Left_1s[i] = max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "        Lost_1s[i] = max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "\n",
    "        # all_holding_costs_0[i] = (\n",
    "        #     (Q0_vars[i] + Left_0s[i] + Q1_vars[i]) * ((assigned_R + 2) - 1) / 2\n",
    "        # )\n",
    "        # all_holding_costs_1[i] = (\n",
    "        #     (Q1_vars[i] + Left_0s[i] + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "        # )\n",
    "\n",
    "        # profits_vars[i] = (\n",
    "        #     (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue from sales\n",
    "        #     - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "        #     - (cost - salvage_value) * Left_1s[i]\n",
    "        # )\n",
    "\n",
    "        profits_vars[i] = (\n",
    "            (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue from sales\n",
    "            - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "            - (cost - salvage_value) * (Left_0s[i] + Left_1s[i])  # 加上 Left_0s[i]\n",
    "        )\n",
    "\n",
    "    # Calculate the average profit\n",
    "    print(f\"assigned_R: {assigned_R}\")\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"average_profits\": [np.mean(profits_vars)],\n",
    "            \"average_loss_penalty\": [\n",
    "                np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))\n",
    "            ],\n",
    "            \"average_left_penalty\": [\n",
    "                np.mean((cost - salvage_value) * (Left_0s[i] + Left_1s[i]))\n",
    "            ],\n",
    "            \"average_loss\": [np.mean((Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"average_left\": [np.mean((Left_0s[i] + Left_1s[i]))],\n",
    "            \"alpha_values\": [alphas],\n",
    "            \"R(T)\": assigned_R + 2,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    stimulation_result = pd.DataFrame(\n",
    "        {\n",
    "            \"F\": F_vars,\n",
    "            \"R(T)\": assigned_R + 2,\n",
    "            \"Sold_0\": Sold_0s,\n",
    "            \"Left_0\": Left_0s,\n",
    "            \"Lost_0\": Lost_0s,\n",
    "            \"Sold_1\": Sold_1s,\n",
    "            \"Left_1\": Left_1s,\n",
    "            \"Lost_1\": Lost_1s,\n",
    "            \"profits\": profits_vars,\n",
    "            \"Q0\": Q0_vars,\n",
    "            \"Q1\": Q1_vars,\n",
    "            \"hc0\": all_holding_costs_0,\n",
    "            \"hc1\": all_holding_costs_1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return results_df, stimulation_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3 - Grid for Fixed F & Flexible Rk(原s6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_fixed_F_flexible_R(\n",
    "    assigned_F,\n",
    "    betas,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_test,\n",
    "    Qk_hat_df_test,\n",
    "    testing_df,\n",
    "):\n",
    "\n",
    "    # ======================= Global Variables =======================\n",
    "\n",
    "    # Category 1 - Some variables that is important to future work\n",
    "    K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "    n = len(demand_df_test)\n",
    "\n",
    "    # Initialize lists or numpy arrays to replace Gurobi variables\n",
    "    Sold_0s = np.zeros(n)\n",
    "    Left_0s = np.zeros(n)\n",
    "    Lost_0s = np.zeros(n)\n",
    "    Sold_1s = np.zeros(n)\n",
    "    Left_1s = np.zeros(n)\n",
    "    Lost_1s = np.zeros(n)\n",
    "    all_holding_costs_0 = np.zeros(n)\n",
    "    all_holding_costs_1 = np.zeros(n)\n",
    "    profits_vars = np.zeros(n)\n",
    "\n",
    "    # 1-2. Arrays for demand calculation up to certain periods\n",
    "    total_demand_up_to_k_minus_1_vars = np.zeros(n)\n",
    "    total_demand_from_k_to_T_vars = np.zeros(n)\n",
    "    Q1_plus_lefts = np.zeros(n)\n",
    "\n",
    "    # 2. Variables for Model 2: Optimal Fraction Model\n",
    "    f_vars = np.zeros(n)\n",
    "    F_vars = np.zeros(n)  # Assuming values will be between 0 and 1\n",
    "    Q0_vars = np.zeros(n)  # Replace Q_star with a specific value as needed\n",
    "\n",
    "    # 3. Variables for Model 3: Optimal Order Time Model (2D array for binary values)\n",
    "    tau_vars = np.zeros((n, K))\n",
    "    exp_tau_vars = np.zeros((n, K))\n",
    "    r_vars = np.zeros((n, K))\n",
    "    max_r_index = np.zeros(n, dtype=int)\n",
    "    R_vars = np.zeros(\n",
    "        (n, K), dtype=int\n",
    "    )  # Binary array to select one optimal replenishment time\n",
    "\n",
    "    # 4. Variables for Model 4: Re-estimate order-up-to-level\n",
    "    Q1_vars = np.zeros(n)\n",
    "    Q_hats = np.zeros(n)\n",
    "    Q_hat_adjusteds = np.zeros(n)\n",
    "\n",
    "    # ======================= Start Stimulation! =======================\n",
    "\n",
    "    for i, row in demand_df_test.iterrows():\n",
    "\n",
    "        ### Data for this stimulation\n",
    "        demand_row = demand_df_test.iloc[i]\n",
    "        Qk_hat_df_test_row = Qk_hat_df_test.iloc[i]\n",
    "        X_data = testing_df.iloc[i].tolist()\n",
    "        X_data.append(1)\n",
    "\n",
    "        # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "        F_vars[i] = assigned_F\n",
    "        Q0_vars[i] = F_vars[i] * Q_star\n",
    "\n",
    "        # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "        for k in range(K):\n",
    "            tau_vars[i, k] = betas[k, 0]\n",
    "            exp_tau_vars[i, k] = np.exp(-tau_vars[i, k])  # Calculate exp(-tau_vars)\n",
    "\n",
    "        sum_exp_tau_vars = np.sum(\n",
    "            exp_tau_vars[i]\n",
    "        )  # Sum of all exp_tau_vars for normalization\n",
    "\n",
    "        for k in range(K):\n",
    "            r_vars[i, k] = exp_tau_vars[i, k] / sum_exp_tau_vars\n",
    "\n",
    "        max_r_index[i] = np.argmax(\n",
    "            r_vars[i]\n",
    "        )  # Find index of the maximum value in r_vars\n",
    "        R_vars[i, max_r_index[i]] = (\n",
    "            1  # Set only this R_vars element to 1, ensuring only one is set\n",
    "        )\n",
    "\n",
    "        # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "        Q_hats[i] = sum(\n",
    "            R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
    "        )\n",
    "        Q_hat_adjusteds[i] = Q_hats[i] - Q0_vars[i]\n",
    "        Q1_vars[i] = max(Q_hat_adjusteds[i], 0)\n",
    "\n",
    "        # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "        # Calculate the demand up to k-1\n",
    "        total_demand_up_to_k_minus_1 = sum(\n",
    "            R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_up_to_k_minus_1_vars[i] = total_demand_up_to_k_minus_1\n",
    "\n",
    "        # Calculate the demand from k to T\n",
    "        total_demand_from_k_to_T = sum(\n",
    "            R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars[i] = total_demand_from_k_to_T\n",
    "\n",
    "        Sold_0s[i] = min(total_demand_up_to_k_minus_1_vars[i], Q0_vars[i])\n",
    "        Left_0s[i] = max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "        Lost_0s[i] = max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "        Q1_plus_lefts[i] = Q1_vars[i] + Left_0s[i]\n",
    "\n",
    "        Sold_1s[i] = min(total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i])\n",
    "        Left_1s[i] = max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "        Lost_1s[i] = max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "\n",
    "        assigned_R = max_r_index[i]\n",
    "\n",
    "        all_holding_costs_0[i] = (\n",
    "            (Q0_vars[i] + Left_0s[i] + Q1_vars[i]) * ((assigned_R + 2) - 1) / 2\n",
    "        )\n",
    "        all_holding_costs_1[i] = (\n",
    "            (Q1_vars[i] + Left_0s[i] + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "        )\n",
    "\n",
    "        profits_vars[i] = (\n",
    "            (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue from sales\n",
    "            - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "            - (cost - salvage_value) * Left_1s[i]\n",
    "            - holding_cost * (all_holding_costs_0[i] + all_holding_costs_1[i])\n",
    "        )\n",
    "\n",
    "    # Calculate the average profit\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"average_profits\": [np.mean(profits_vars)],\n",
    "            \"average_loss\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"average_left\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"beta_balues\": [betas],\n",
    "            \"F\": [assigned_F],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    stimulation_result = pd.DataFrame(\n",
    "        {\n",
    "            \"F\": F_vars,\n",
    "            \"R(T)\": [x + 2 for x in max_r_index],\n",
    "            \"Sold_0\": Sold_0s,\n",
    "            \"Left_0\": Left_0s,\n",
    "            \"Lost_0\": Lost_0s,\n",
    "            \"Sold_1\": Sold_1s,\n",
    "            \"Left_1\": Left_1s,\n",
    "            \"Lost_1\": Lost_1s,\n",
    "            \"profits\": profits_vars,\n",
    "            \"Q0\": Q0_vars,\n",
    "            \"Q1\": Q1_vars,\n",
    "            \"hc0\": all_holding_costs_0,\n",
    "            \"hc1\": all_holding_costs_1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return results_df, stimulation_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully flexible F & Rk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S5 - Simple beta with softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_fully_flexible_simple_beta_with_softmax_5(\n",
    "    alphas,\n",
    "    betas,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_test,\n",
    "    Qk_hat_df_test,\n",
    "    testing_df,\n",
    "):\n",
    "\n",
    "    # ======================= Global Variables =======================\n",
    "\n",
    "    # Category 1 - Some variables that is important to future work\n",
    "    K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "    n = len(demand_df_test)\n",
    "\n",
    "    # Initialize lists or numpy arrays to replace Gurobi variables\n",
    "    Sold_0s = np.zeros(n)\n",
    "    Left_0s = np.zeros(n)\n",
    "    Lost_0s = np.zeros(n)\n",
    "    Sold_1s = np.zeros(n)\n",
    "    Left_1s = np.zeros(n)\n",
    "    Lost_1s = np.zeros(n)\n",
    "    all_holding_costs_0 = np.zeros(n)\n",
    "    all_holding_costs_1 = np.zeros(n)\n",
    "    profits_vars = np.zeros(n)\n",
    "\n",
    "    # 1-2. Arrays for demand calculation up to certain periods\n",
    "    total_demand_up_to_k_minus_1_vars = np.zeros(n)\n",
    "    total_demand_from_k_to_T_vars = np.zeros(n)\n",
    "    Q1_plus_lefts = np.zeros(n)\n",
    "\n",
    "    # 2. Variables for Model 2: Optimal Fraction Model\n",
    "    f_vars = np.zeros(n)\n",
    "    F_vars = np.zeros(n)  # Assuming values will be between 0 and 1\n",
    "    Q0_vars = np.zeros(n)  # Replace Q_star with a specific value as needed\n",
    "\n",
    "    # 3. Variables for Model 3: Optimal Order Time Model (2D array for binary values)\n",
    "    tau_vars = np.zeros((n, K))\n",
    "    exp_tau_vars = np.zeros((n, K))\n",
    "    r_vars = np.zeros((n, K))\n",
    "    max_r_index = np.zeros(n, dtype=int)\n",
    "    R_vars = np.zeros(\n",
    "        (n, K), dtype=int\n",
    "    )  # Binary array to select one optimal replenishment time\n",
    "\n",
    "    # 4. Variables for Model 4: Re-estimate order-up-to-level\n",
    "    Q1_vars = np.zeros(n)\n",
    "    Q_hats = np.zeros(n)\n",
    "    Q_hat_adjusteds = np.zeros(n)\n",
    "\n",
    "    # ======================= Start Stimulation! =======================\n",
    "\n",
    "    for i, row in demand_df_test.iterrows():\n",
    "\n",
    "        ### Data for this stimulation\n",
    "        demand_row = demand_df_test.iloc[i]\n",
    "        Qk_hat_df_test_row = Qk_hat_df_test.iloc[i]\n",
    "        X_data = testing_df.iloc[i].tolist()\n",
    "        X_data.append(1)\n",
    "\n",
    "        # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "        ### 用線性回歸計算F_var\n",
    "        f_vars[i] = sum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "        F_vars[i] = 1 / (1 + np.exp(-(f_vars[i])))\n",
    "        Q0_vars[i] = F_vars[i] * Q_star\n",
    "\n",
    "        # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "        for k in range(K):\n",
    "            tau_vars[i, k] = betas[k, 0]\n",
    "            exp_tau_vars[i, k] = np.exp(-tau_vars[i, k])  # Calculate exp(-tau_vars)\n",
    "\n",
    "        sum_exp_tau_vars = np.sum(\n",
    "            exp_tau_vars[i]\n",
    "        )  # Sum of all exp_tau_vars for normalization\n",
    "\n",
    "        for k in range(K):\n",
    "            r_vars[i, k] = exp_tau_vars[i, k] / sum_exp_tau_vars\n",
    "\n",
    "        max_r_index[i] = np.argmax(\n",
    "            r_vars[i]\n",
    "        )  # Find index of the maximum value in r_vars\n",
    "        R_vars[i, max_r_index[i]] = (\n",
    "            1  # Set only this R_vars element to 1, ensuring only one is set\n",
    "        )\n",
    "\n",
    "        # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "        Q_hats[i] = sum(\n",
    "            R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
    "        )\n",
    "        Q_hat_adjusteds[i] = Q_hats[i] - Q0_vars[i]\n",
    "        Q1_vars[i] = max(Q_hat_adjusteds[i], 0)\n",
    "\n",
    "        # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "        # Calculate the demand up to k-1\n",
    "        total_demand_up_to_k_minus_1 = sum(\n",
    "            R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_up_to_k_minus_1_vars[i] = total_demand_up_to_k_minus_1\n",
    "\n",
    "        # Calculate the demand from k to T\n",
    "        total_demand_from_k_to_T = sum(\n",
    "            R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars[i] = total_demand_from_k_to_T\n",
    "\n",
    "        Sold_0s[i] = min(total_demand_up_to_k_minus_1_vars[i], Q0_vars[i])\n",
    "        Left_0s[i] = max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "        Lost_0s[i] = max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "        Q1_plus_lefts[i] = Q1_vars[i] + Left_0s[i]\n",
    "\n",
    "        Sold_1s[i] = min(total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i])\n",
    "        Left_1s[i] = max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "        Lost_1s[i] = max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "\n",
    "        assigned_R = max_r_index[i]\n",
    "\n",
    "        all_holding_costs_0[i] = (\n",
    "            (Q0_vars[i] + Left_0s[i] + Q1_vars[i]) * ((assigned_R + 2) - 1) / 2\n",
    "        )\n",
    "        all_holding_costs_1[i] = (\n",
    "            (Q1_vars[i] + Left_0s[i] + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "        )\n",
    "\n",
    "        profits_vars[i] = (\n",
    "            (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue from sales\n",
    "            - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "            - (cost - salvage_value) * Left_1s[i]\n",
    "            - holding_cost * (all_holding_costs_0[i] + all_holding_costs_1[i])\n",
    "        )\n",
    "\n",
    "    # Calculate the average profit\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"average_profits\": [np.mean(profits_vars)],\n",
    "            \"average_loss\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"average_left\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"alpha_values\": [alphas],\n",
    "            \"beta_balues\": [betas],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    stimulation_result = pd.DataFrame(\n",
    "        {\n",
    "            \"F\": F_vars,\n",
    "            \"R(T)\": [x + 2 for x in max_r_index],\n",
    "            \"Sold_0\": Sold_0s,\n",
    "            \"Left_0\": Left_0s,\n",
    "            \"Lost_0\": Lost_0s,\n",
    "            \"Sold_1\": Sold_1s,\n",
    "            \"Left_1\": Left_1s,\n",
    "            \"Lost_1\": Lost_1s,\n",
    "            \"profits\": profits_vars,\n",
    "            \"Q0\": Q0_vars,\n",
    "            \"Q1\": Q1_vars,\n",
    "            \"hc0\": all_holding_costs_0,\n",
    "            \"hc1\": all_holding_costs_1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return results_df, stimulation_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S6 - Simple beta and softmax with T is 1 - sum(T-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_fully_flexible_simple_beta_with_softmax_6(\n",
    "    alphas,\n",
    "    betas,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_test,\n",
    "    Qk_hat_df_test,\n",
    "    testing_df,\n",
    "):\n",
    "\n",
    "    # ======================= Global Variables =======================\n",
    "\n",
    "    # Category 1 - Some variables that is important to future work\n",
    "    K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "    n = len(demand_df_test)\n",
    "\n",
    "    # Initialize lists or numpy arrays to replace Gurobi variables\n",
    "    Sold_0s = np.zeros(n)\n",
    "    Left_0s = np.zeros(n)\n",
    "    Lost_0s = np.zeros(n)\n",
    "    Sold_1s = np.zeros(n)\n",
    "    Left_1s = np.zeros(n)\n",
    "    Lost_1s = np.zeros(n)\n",
    "    all_holding_costs_0 = np.zeros(n)\n",
    "    all_holding_costs_1 = np.zeros(n)\n",
    "    profits_vars = np.zeros(n)\n",
    "\n",
    "    # 1-2. Arrays for demand calculation up to certain periods\n",
    "    total_demand_up_to_k_minus_1_vars = np.zeros(n)\n",
    "    total_demand_from_k_to_T_vars = np.zeros(n)\n",
    "    Q1_plus_lefts = np.zeros(n)\n",
    "\n",
    "    # 2. Variables for Model 2: Optimal Fraction Model\n",
    "    f_vars = np.zeros(n)\n",
    "    F_vars = np.zeros(n)  # Assuming values will be between 0 and 1\n",
    "    Q0_vars = np.zeros(n)  # Replace Q_star with a specific value as needed\n",
    "\n",
    "    # 3. Variables for Model 3: Optimal Order Time Model (2D array for binary values)\n",
    "    tau_vars = np.zeros((n, K - 1))\n",
    "    exp_tau_vars = np.zeros((n, K - 1))\n",
    "    r_vars = np.zeros((n, K))\n",
    "    max_r_index = np.zeros(n, dtype=int)\n",
    "    R_vars = np.zeros(\n",
    "        (n, K), dtype=int\n",
    "    )  # Binary array to select one optimal replenishment time\n",
    "\n",
    "    # 4. Variables for Model 4: Re-estimate order-up-to-level\n",
    "    Q1_vars = np.zeros(n)\n",
    "    Q_hats = np.zeros(n)\n",
    "    Q_hat_adjusteds = np.zeros(n)\n",
    "\n",
    "    # ======================= Start Stimulation! =======================\n",
    "\n",
    "    for i, row in demand_df_test.iterrows():\n",
    "\n",
    "        ### Data for this stimulation\n",
    "        demand_row = demand_df_test.iloc[i]\n",
    "        Qk_hat_df_test_row = Qk_hat_df_test.iloc[i]\n",
    "        X_data = testing_df.iloc[i].tolist()\n",
    "        X_data.append(1)\n",
    "\n",
    "        # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "        ### 用線性回歸計算F_var\n",
    "        f_vars[i] = sum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "        F_vars[i] = 1 / (1 + np.exp(-(f_vars[i])))\n",
    "        Q0_vars[i] = F_vars[i] * Q_star\n",
    "\n",
    "        # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "        # Step 1: Calculate tau_vars based on betas\n",
    "        for p in range(K - 1):\n",
    "            tau_vars[i, p] = betas[p, 0]  # Only intercept term is used\n",
    "            exp_tau_vars[i, p] = np.exp(-tau_vars[i, p])  # Calculate exp(-tau_vars)\n",
    "\n",
    "        # Step 2: Calculate softmax-normalized r_vars\n",
    "        sum_exp_tau_vars = (\n",
    "            np.sum(exp_tau_vars[i]) + 1\n",
    "        )  # Adding 1 as in the softmax denominator for the last element\n",
    "\n",
    "        for p in range(K):\n",
    "            if p == K - 1:\n",
    "                # Set the last r_vars element to ensure the sum of all r_vars elements is 1\n",
    "                r_vars[i, p] = 1 - np.sum(r_vars[i, : K - 1])\n",
    "            else:\n",
    "                r_vars[i, p] = exp_tau_vars[i, p] / sum_exp_tau_vars\n",
    "\n",
    "        # Step 3: Find the maximum r_vars element and set corresponding R_vars to 1\n",
    "        max_r_index[i] = np.argmax(\n",
    "            r_vars[i]\n",
    "        )  # Find index of the maximum value in r_vars\n",
    "        R_vars[i, max_r_index[i]] = (\n",
    "            1  # Set only this R_vars element to 1, ensuring only one is set\n",
    "        )\n",
    "\n",
    "        # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "        Q_hats[i] = sum(\n",
    "            R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
    "        )\n",
    "        Q_hat_adjusteds[i] = Q_hats[i] - Q0_vars[i]\n",
    "        Q1_vars[i] = max(Q_hat_adjusteds[i], 0)\n",
    "\n",
    "        # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "        # Calculate the demand up to k-1\n",
    "        total_demand_up_to_k_minus_1 = sum(\n",
    "            R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_up_to_k_minus_1_vars[i] = total_demand_up_to_k_minus_1\n",
    "\n",
    "        # Calculate the demand from k to T\n",
    "        total_demand_from_k_to_T = sum(\n",
    "            R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars[i] = total_demand_from_k_to_T\n",
    "\n",
    "        Sold_0s[i] = min(total_demand_up_to_k_minus_1_vars[i], Q0_vars[i])\n",
    "        Left_0s[i] = max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "        Lost_0s[i] = max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "        Q1_plus_lefts[i] = Q1_vars[i] + Left_0s[i]\n",
    "\n",
    "        Sold_1s[i] = min(total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i])\n",
    "        Left_1s[i] = max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "        Lost_1s[i] = max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "\n",
    "        assigned_R = max_r_index[i]\n",
    "\n",
    "        # all_holding_costs_0[i] = (\n",
    "        #     (Q0_vars[i] + Left_0s[i] + Q1_vars[i]) * ((assigned_R + 2) - 1) / 2\n",
    "        # )\n",
    "        # all_holding_costs_1[i] = (\n",
    "        #     (Q1_vars[i] + Left_0s[i] + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "        # )\n",
    "\n",
    "        profits_vars[i] = (\n",
    "            (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue from sales\n",
    "            - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "            - (cost - salvage_value) * Left_1s[i]\n",
    "            # - holding_cost * (all_holding_costs_0[i] + all_holding_costs_1[i])\n",
    "        )\n",
    "\n",
    "    # Calculate the average profit\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"average_profits\": [np.mean(profits_vars)],\n",
    "            \"average_loss\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"average_left\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"alpha_values\": [alphas],\n",
    "            \"beta_balues\": [betas],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    stimulation_result = pd.DataFrame(\n",
    "        {\n",
    "            \"F\": F_vars,\n",
    "            \"R(T)\": [x + 2 for x in max_r_index],\n",
    "            \"Sold_0\": Sold_0s,\n",
    "            \"Left_0\": Left_0s,\n",
    "            \"Lost_0\": Lost_0s,\n",
    "            \"Sold_1\": Sold_1s,\n",
    "            \"Left_1\": Left_1s,\n",
    "            \"Lost_1\": Lost_1s,\n",
    "            \"profits\": profits_vars,\n",
    "            \"Q0\": Q0_vars,\n",
    "            \"Q1\": Q1_vars,\n",
    "            \"hc0\": all_holding_costs_0,\n",
    "            \"hc1\": all_holding_costs_1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return results_df, stimulation_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S7 - Simple beat and softmax with T is 1 - sum(T-1) & tau with f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_fully_flexible_simple_beta_with_softmax_7(\n",
    "    alphas,\n",
    "    betas,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_test,\n",
    "    Qk_hat_df_test,\n",
    "    testing_df,\n",
    "):\n",
    "\n",
    "    # ======================= Global Variables =======================\n",
    "\n",
    "    # Category 1 - Some variables that is important to future work\n",
    "    K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "    n = len(demand_df_test)\n",
    "\n",
    "    # Initialize lists or numpy arrays to replace Gurobi variables\n",
    "    Sold_0s = np.zeros(n)\n",
    "    Left_0s = np.zeros(n)\n",
    "    Lost_0s = np.zeros(n)\n",
    "    Sold_1s = np.zeros(n)\n",
    "    Left_1s = np.zeros(n)\n",
    "    Lost_1s = np.zeros(n)\n",
    "    all_holding_costs_0 = np.zeros(n)\n",
    "    all_holding_costs_1 = np.zeros(n)\n",
    "    profits_vars = np.zeros(n)\n",
    "\n",
    "    # 1-2. Arrays for demand calculation up to certain periods\n",
    "    total_demand_up_to_k_minus_1_vars = np.zeros(n)\n",
    "    total_demand_from_k_to_T_vars = np.zeros(n)\n",
    "    Q1_plus_lefts = np.zeros(n)\n",
    "\n",
    "    # 2. Variables for Model 2: Optimal Fraction Model\n",
    "    f_vars = np.zeros(n)\n",
    "    F_vars = np.zeros(n)  # Assuming values will be between 0 and 1\n",
    "    Q0_vars = np.zeros(n)  # Replace Q_star with a specific value as needed\n",
    "\n",
    "    # 3. Variables for Model 3: Optimal Order Time Model (2D array for binary values)\n",
    "    tau_vars = np.zeros((n, K - 1))\n",
    "    exp_tau_vars = np.zeros((n, K - 1))\n",
    "    r_vars = np.zeros((n, K))\n",
    "    max_r_index = np.zeros(n, dtype=int)\n",
    "    R_vars = np.zeros(\n",
    "        (n, K), dtype=int\n",
    "    )  # Binary array to select one optimal replenishment time\n",
    "\n",
    "    # 4. Variables for Model 4: Re-estimate order-up-to-level\n",
    "    Q1_vars = np.zeros(n)\n",
    "    Q_hats = np.zeros(n)\n",
    "    Q_hat_adjusteds = np.zeros(n)\n",
    "\n",
    "    # ======================= Start Stimulation! =======================\n",
    "\n",
    "    for i, row in demand_df_test.iterrows():\n",
    "\n",
    "        ### Data for this stimulation\n",
    "        demand_row = demand_df_test.iloc[i]\n",
    "        Qk_hat_df_test_row = Qk_hat_df_test.iloc[i]\n",
    "        X_data = testing_df.iloc[i].tolist()\n",
    "        X_data.append(1)\n",
    "\n",
    "        # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "        ### 用線性回歸計算F_var\n",
    "        f_vars[i] = sum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "        F_vars[i] = 1 / (1 + np.exp(-(f_vars[i])))\n",
    "        Q0_vars[i] = F_vars[i] * Q_star\n",
    "\n",
    "        # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "        # Step 1: Calculate tau_vars based on betas and f_vars\n",
    "        for p in range(K - 1):\n",
    "            tau_vars[i, p] = betas[p, 0] + f_vars[i]\n",
    "            exp_tau_vars[i, p] = np.exp(-tau_vars[i, p])  # Calculate exp(-tau_vars)\n",
    "\n",
    "        # Step 2: Calculate the sum of exp_tau_vars for softmax normalization\n",
    "        sum_exp_tau_vars = np.sum(exp_tau_vars[i]) + 1  # Adding 1 for the last r_var\n",
    "\n",
    "        # Step 3: Calculate r_vars with softmax normalization\n",
    "        for p in range(K):\n",
    "            if p == K - 1:\n",
    "                # Last r_var element ensures all r_vars sum to 1\n",
    "                r_vars[i, p] = 1 - np.sum(r_vars[i, : K - 1])\n",
    "            else:\n",
    "                r_vars[i, p] = exp_tau_vars[i, p] / sum_exp_tau_vars\n",
    "\n",
    "        # Step 4: Find the index of the maximum r_vars and set corresponding R_vars to 1\n",
    "        max_r_index[i] = np.argmax(\n",
    "            r_vars[i]\n",
    "        )  # Find index of the maximum value in r_vars\n",
    "        R_vars[i, max_r_index[i]] = (\n",
    "            1  # Set only this R_vars element to 1, ensuring only one is set\n",
    "        )\n",
    "\n",
    "        # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "        Q_hats[i] = sum(\n",
    "            R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
    "        )\n",
    "        Q_hat_adjusteds[i] = Q_hats[i] - Q0_vars[i]\n",
    "        Q1_vars[i] = max(Q_hat_adjusteds[i], 0)\n",
    "\n",
    "        # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "        # Calculate the demand up to k-1\n",
    "        total_demand_up_to_k_minus_1 = sum(\n",
    "            R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_up_to_k_minus_1_vars[i] = total_demand_up_to_k_minus_1\n",
    "\n",
    "        # Calculate the demand from k to T\n",
    "        total_demand_from_k_to_T = sum(\n",
    "            R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars[i] = total_demand_from_k_to_T\n",
    "\n",
    "        Sold_0s[i] = min(total_demand_up_to_k_minus_1_vars[i], Q0_vars[i])\n",
    "        Left_0s[i] = max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "        Lost_0s[i] = max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "        Q1_plus_lefts[i] = Q1_vars[i] + Left_0s[i]\n",
    "\n",
    "        Sold_1s[i] = min(total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i])\n",
    "        Left_1s[i] = max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "        Lost_1s[i] = max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "\n",
    "        assigned_R = max_r_index[i]\n",
    "\n",
    "        all_holding_costs_0[i] = (\n",
    "            (Q0_vars[i] + Left_0s[i] + Q1_vars[i]) * ((assigned_R + 2) - 1) / 2\n",
    "        )\n",
    "        all_holding_costs_1[i] = (\n",
    "            (Q1_vars[i] + Left_0s[i] + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "        )\n",
    "\n",
    "        profits_vars[i] = (\n",
    "            (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue from sales\n",
    "            - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "            - (cost - salvage_value) * Left_1s[i]\n",
    "            - holding_cost * (all_holding_costs_0[i] + all_holding_costs_1[i])\n",
    "        )\n",
    "\n",
    "    # Calculate the average profit\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"average_profits\": [np.mean(profits_vars)],\n",
    "            \"average_loss\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"average_left\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"alpha_values\": [alphas],\n",
    "            \"beta_balues\": [betas],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    stimulation_result = pd.DataFrame(\n",
    "        {\n",
    "            \"F\": F_vars,\n",
    "            \"R(T)\": [x + 2 for x in max_r_index],\n",
    "            \"Sold_0\": Sold_0s,\n",
    "            \"Left_0\": Left_0s,\n",
    "            \"Lost_0\": Lost_0s,\n",
    "            \"Sold_1\": Sold_1s,\n",
    "            \"Left_1\": Left_1s,\n",
    "            \"Lost_1\": Lost_1s,\n",
    "            \"profits\": profits_vars,\n",
    "            \"Q0\": Q0_vars,\n",
    "            \"Q1\": Q1_vars,\n",
    "            \"hc0\": all_holding_costs_0,\n",
    "            \"hc1\": all_holding_costs_1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return results_df, stimulation_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S4 - Beta with softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_fully_flexible_beta_with_softmax_4(\n",
    "    alphas,\n",
    "    betas,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_test,\n",
    "    Qk_hat_df_test,\n",
    "    testing_df,\n",
    "):\n",
    "\n",
    "    # ======================= Global Variables =======================\n",
    "\n",
    "    # Category 1 - Some variables that is important to future work\n",
    "    K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "    n = len(demand_df_test)\n",
    "\n",
    "    # Initialize lists or numpy arrays to replace Gurobi variables\n",
    "    Sold_0s = np.zeros(n)\n",
    "    Left_0s = np.zeros(n)\n",
    "    Lost_0s = np.zeros(n)\n",
    "    Sold_1s = np.zeros(n)\n",
    "    Left_1s = np.zeros(n)\n",
    "    Lost_1s = np.zeros(n)\n",
    "    all_holding_costs_0 = np.zeros(n)\n",
    "    all_holding_costs_1 = np.zeros(n)\n",
    "    profits_vars = np.zeros(n)\n",
    "\n",
    "    # 1-2. Arrays for demand calculation up to certain periods\n",
    "    total_demand_up_to_k_minus_1_vars = np.zeros(n)\n",
    "    total_demand_from_k_to_T_vars = np.zeros(n)\n",
    "    Q1_plus_lefts = np.zeros(n)\n",
    "\n",
    "    # 2. Variables for Model 2: Optimal Fraction Model\n",
    "    f_vars = np.zeros(n)\n",
    "    F_vars = np.zeros(n)  # Assuming values will be between 0 and 1\n",
    "    Q0_vars = np.zeros(n)  # Replace Q_star with a specific value as needed\n",
    "\n",
    "    # 3. Variables for Model 3: Optimal Order Time Model (2D array for binary values)\n",
    "    tau_vars = np.zeros((n, K))\n",
    "    exp_tau_vars = np.zeros((n, K))\n",
    "    r_vars = np.zeros((n, K))\n",
    "    max_r_index = np.zeros(n, dtype=int)\n",
    "    R_vars = np.zeros(\n",
    "        (n, K), dtype=int\n",
    "    )  # Binary array to select one optimal replenishment time\n",
    "\n",
    "    # 4. Variables for Model 4: Re-estimate order-up-to-level\n",
    "    Q1_vars = np.zeros(n)\n",
    "    Q_hats = np.zeros(n)\n",
    "    Q_hat_adjusteds = np.zeros(n)\n",
    "\n",
    "    # ======================= Start Stimulation! =======================\n",
    "\n",
    "    for i, row in demand_df_test.iterrows():\n",
    "\n",
    "        ### Data for this stimulation\n",
    "        demand_row = demand_df_test.iloc[i]\n",
    "        Qk_hat_df_test_row = Qk_hat_df_test.iloc[i]\n",
    "        X_data = testing_df.iloc[i].tolist()\n",
    "        X_data.append(1)\n",
    "\n",
    "        # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "        ### 用線性回歸計算F_var\n",
    "        f_vars[i] = sum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "        F_vars[i] = 1 / (1 + np.exp(-(f_vars[i])))\n",
    "        Q0_vars[i] = F_vars[i] * Q_star\n",
    "\n",
    "        # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "        # Step 1: Calculate tau_vars as a linear combination of X_data and betas\n",
    "        for k in range(K):\n",
    "            tau_vars[i, k] = sum(\n",
    "                X_data[j] * betas[k, j] for j in range(features_num + 1)\n",
    "            )\n",
    "\n",
    "        # Step 2: Calculate the exponentials of tau_vars\n",
    "        exp_tau_vars[i] = np.exp(tau_vars[i])\n",
    "\n",
    "        # Step 3: Softmax normalization\n",
    "        sum_exp_tau = np.sum(exp_tau_vars[i])  # Sum of exponentials for normalization\n",
    "        r_vars[i] = exp_tau_vars[i] / sum_exp_tau  # Normalize to get softmax\n",
    "\n",
    "        max_r_index[i] = np.argmax(r_vars[i])\n",
    "        R_vars[i, max_r_index[i]] = 1\n",
    "\n",
    "        # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "        Q_hats[i] = sum(\n",
    "            R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
    "        )\n",
    "        Q_hat_adjusteds[i] = Q_hats[i] - Q0_vars[i]\n",
    "        Q1_vars[i] = max(Q_hat_adjusteds[i], 0)\n",
    "\n",
    "        # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "        # Calculate the demand up to k-1\n",
    "        total_demand_up_to_k_minus_1 = sum(\n",
    "            R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_up_to_k_minus_1_vars[i] = total_demand_up_to_k_minus_1\n",
    "\n",
    "        # Calculate the demand from k to T\n",
    "        total_demand_from_k_to_T = sum(\n",
    "            R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars[i] = total_demand_from_k_to_T\n",
    "\n",
    "        Sold_0s[i] = min(total_demand_up_to_k_minus_1_vars[i], Q0_vars[i])\n",
    "        Left_0s[i] = max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "        Lost_0s[i] = max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "        Q1_plus_lefts[i] = Q1_vars[i] + Left_0s[i]\n",
    "\n",
    "        Sold_1s[i] = min(total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i])\n",
    "        Left_1s[i] = max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "        Lost_1s[i] = max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "\n",
    "        # assigned_R = max_r_index[i]\n",
    "\n",
    "        # all_holding_costs_0[i] = (\n",
    "        #     (Q0_vars[i] + Left_0s[i] + Q1_vars[i]) * ((assigned_R + 2) - 1) / 2\n",
    "        # )\n",
    "        # all_holding_costs_1[i] = (\n",
    "        #     (Q1_vars[i] + Left_0s[i] + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "        # )\n",
    "\n",
    "        profits_vars[i] = (\n",
    "            (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue from sales\n",
    "            - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "            - (cost - salvage_value) * Left_1s[i]\n",
    "            # - holding_cost * (all_holding_costs_0[i] + all_holding_costs_1[i])\n",
    "        )\n",
    "\n",
    "    # Calculate the average profit\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"average_profits\": [np.mean(profits_vars)],\n",
    "            \"average_loss\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"average_left\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"alpha_values\": [alphas],\n",
    "            \"beta_balues\": [betas],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    stimulation_result = pd.DataFrame(\n",
    "        {\n",
    "            \"F\": F_vars,\n",
    "            \"R(T)\": [x + 2 for x in max_r_index],\n",
    "            \"Sold_0\": Sold_0s,\n",
    "            \"Left_0\": Left_0s,\n",
    "            \"Lost_0\": Lost_0s,\n",
    "            \"Sold_1\": Sold_1s,\n",
    "            \"Left_1\": Left_1s,\n",
    "            \"Lost_1\": Lost_1s,\n",
    "            \"profits\": profits_vars,\n",
    "            \"Q0\": Q0_vars,\n",
    "            \"Q1\": Q1_vars,\n",
    "            \"hc0\": all_holding_costs_0,\n",
    "            \"hc1\": all_holding_costs_1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return results_df, stimulation_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S12 - Beta without r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_fully_flexible_beta_with_softmax_12(\n",
    "    alphas,\n",
    "    betas,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_test,\n",
    "    Qk_hat_df_test,\n",
    "    testing_df,\n",
    "):\n",
    "\n",
    "    # ======================= Global Variables =======================\n",
    "\n",
    "    # Category 1 - Some variables that is important to future work\n",
    "    K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "    n = len(demand_df_test)\n",
    "\n",
    "    # Initialize lists or numpy arrays to replace Gurobi variables\n",
    "    Sold_0s = np.zeros(n)\n",
    "    Left_0s = np.zeros(n)\n",
    "    Lost_0s = np.zeros(n)\n",
    "    Sold_1s = np.zeros(n)\n",
    "    Left_1s = np.zeros(n)\n",
    "    Lost_1s = np.zeros(n)\n",
    "    all_holding_costs_0 = np.zeros(n)\n",
    "    all_holding_costs_1 = np.zeros(n)\n",
    "    profits_vars = np.zeros(n)\n",
    "\n",
    "    # 1-2. Arrays for demand calculation up to certain periods\n",
    "    total_demand_up_to_k_minus_1_vars = np.zeros(n)\n",
    "    total_demand_from_k_to_T_vars = np.zeros(n)\n",
    "    Q1_plus_lefts = np.zeros(n)\n",
    "\n",
    "    # 2. Variables for Model 2: Optimal Fraction Model\n",
    "    f_vars = np.zeros(n)\n",
    "    F_vars = np.zeros(n)  # Assuming values will be between 0 and 1\n",
    "    Q0_vars = np.zeros(n)  # Replace Q_star with a specific value as needed\n",
    "\n",
    "    # 3. Variables for Model 3: Optimal Order Time Model (2D array for binary values)\n",
    "    tau_vars = np.zeros((n, K))\n",
    "    exp_tau_vars = np.zeros((n, K))\n",
    "    r_vars = np.zeros((n, K))\n",
    "    max_r_index = np.zeros(n, dtype=int)\n",
    "    R_vars = np.zeros(\n",
    "        (n, K), dtype=int\n",
    "    )  # Binary array to select one optimal replenishment time\n",
    "\n",
    "    # 4. Variables for Model 4: Re-estimate order-up-to-level\n",
    "    Q1_vars = np.zeros(n)\n",
    "    Q_hats = np.zeros(n)\n",
    "    Q_hat_adjusteds = np.zeros(n)\n",
    "\n",
    "    # ======================= Start Stimulation! =======================\n",
    "\n",
    "    for i, row in demand_df_test.iterrows():\n",
    "\n",
    "        ### Data for this stimulation\n",
    "        demand_row = demand_df_test.iloc[i]\n",
    "        Qk_hat_df_test_row = Qk_hat_df_test.iloc[i]\n",
    "        X_data = testing_df.iloc[i].tolist()\n",
    "        X_data.append(1)\n",
    "\n",
    "        # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "        ### 用線性回歸計算F_var\n",
    "        f_vars[i] = sum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "        F_vars[i] = 1 / (1 + np.exp(-(f_vars[i])))\n",
    "        Q0_vars[i] = F_vars[i] * Q_star\n",
    "\n",
    "        # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "        # Step 1: Calculate tau_vars as a linear combination of X_data and betas\n",
    "        for k in range(K):\n",
    "            tau_vars[i, k] = sum(\n",
    "                X_data[j] * betas[k, j] for j in range(features_num + 1)\n",
    "            )\n",
    "\n",
    "        max_r_index[i] = np.argmax(tau_vars[i])\n",
    "        R_vars[i, max_r_index[i]] = 1\n",
    "\n",
    "        print(f\"tau: {tau_vars[i]}\")\n",
    "        print(f\"R: {R_vars[i]}\")\n",
    "        print(f\"max_r_index: {max_r_index[i]}\")\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "        # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "        Q_hats[i] = sum(\n",
    "            R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
    "        )\n",
    "        Q_hat_adjusteds[i] = Q_hats[i] - Q0_vars[i]\n",
    "        Q1_vars[i] = max(Q_hat_adjusteds[i], 0)\n",
    "\n",
    "        # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "        # Calculate the demand up to k-1\n",
    "        total_demand_up_to_k_minus_1 = sum(\n",
    "            R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_up_to_k_minus_1_vars[i] = total_demand_up_to_k_minus_1\n",
    "\n",
    "        # Calculate the demand from k to T\n",
    "        total_demand_from_k_to_T = sum(\n",
    "            R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars[i] = total_demand_from_k_to_T\n",
    "\n",
    "        Sold_0s[i] = min(total_demand_up_to_k_minus_1_vars[i], Q0_vars[i])\n",
    "        Left_0s[i] = max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "        Lost_0s[i] = max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "        Q1_plus_lefts[i] = Q1_vars[i] + Left_0s[i]\n",
    "\n",
    "        Sold_1s[i] = min(total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i])\n",
    "        Left_1s[i] = max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "        Lost_1s[i] = max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "\n",
    "        # assigned_R = max_r_index[i]\n",
    "\n",
    "        # all_holding_costs_0[i] = (\n",
    "        #     (Q0_vars[i] + Left_0s[i] + Q1_vars[i]) * ((assigned_R + 2) - 1) / 2\n",
    "        # )\n",
    "        # all_holding_costs_1[i] = (\n",
    "        #     (Q1_vars[i] + Left_0s[i] + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "        # )\n",
    "\n",
    "        profits_vars[i] = (\n",
    "            (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue from sales\n",
    "            - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "            - (cost - salvage_value) * (Left_0s[i] + Left_1s[i])\n",
    "        )\n",
    "\n",
    "    # Calculate the average profit\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"average_profits\": [np.mean(profits_vars)],\n",
    "            \"average_loss\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"average_left\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"alpha_values\": [alphas],\n",
    "            \"beta_balues\": [betas],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    stimulation_result = pd.DataFrame(\n",
    "        {\n",
    "            \"F\": F_vars,\n",
    "            \"R(T)\": [x + 2 for x in max_r_index],\n",
    "            \"Sold_0\": Sold_0s,\n",
    "            \"Left_0\": Left_0s,\n",
    "            \"Lost_0\": Lost_0s,\n",
    "            \"Sold_1\": Sold_1s,\n",
    "            \"Left_1\": Left_1s,\n",
    "            \"Lost_1\": Lost_1s,\n",
    "            \"profits\": profits_vars,\n",
    "            \"Q0\": Q0_vars,\n",
    "            \"Q1\": Q1_vars,\n",
    "            \"hc0\": all_holding_costs_0,\n",
    "            \"hc1\": all_holding_costs_1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return results_df, stimulation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S15 - Beta with Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_fully_flexible_beta_with_lasso_15(\n",
    "    alphas,\n",
    "    betas,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_test,\n",
    "    Qk_hat_df_test,\n",
    "    testing_df,\n",
    "):\n",
    "\n",
    "    # ======================= Global Variables =======================\n",
    "\n",
    "    # Category 1 - Some variables that is important to future work\n",
    "    K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "    n = len(demand_df_test)\n",
    "\n",
    "    # Initialize lists or numpy arrays to replace Gurobi variables\n",
    "    Sold_0s = np.zeros(n)\n",
    "    Left_0s = np.zeros(n)\n",
    "    Lost_0s = np.zeros(n)\n",
    "    Sold_1s = np.zeros(n)\n",
    "    Left_1s = np.zeros(n)\n",
    "    Lost_1s = np.zeros(n)\n",
    "    all_holding_costs_0 = np.zeros(n)\n",
    "    all_holding_costs_1 = np.zeros(n)\n",
    "    profits_vars = np.zeros(n)\n",
    "\n",
    "    # 1-2. Arrays for demand calculation up to certain periods\n",
    "    total_demand_up_to_k_minus_1_vars = np.zeros(n)\n",
    "    total_demand_from_k_to_T_vars = np.zeros(n)\n",
    "    Q1_plus_lefts = np.zeros(n)\n",
    "\n",
    "    # 2. Variables for Model 2: Optimal Fraction Model\n",
    "    f_vars = np.zeros(n)\n",
    "    F_vars = np.zeros(n)  # Assuming values will be between 0 and 1\n",
    "    Q0_vars = np.zeros(n)  # Replace Q_star with a specific value as needed\n",
    "\n",
    "    # 3. Variables for Model 3: Optimal Order Time Model (2D array for binary values)\n",
    "    tau_vars = np.zeros((n, K))\n",
    "    exp_tau_vars = np.zeros((n, K))\n",
    "    r_vars = np.zeros((n, K))\n",
    "    max_r_index = np.zeros(n, dtype=int)\n",
    "    R_vars = np.zeros(\n",
    "        (n, K), dtype=int\n",
    "    )  # Binary array to select one optimal replenishment time\n",
    "\n",
    "    # 4. Variables for Model 4: Re-estimate order-up-to-level\n",
    "    Q1_vars = np.zeros(n)\n",
    "    Q_hats = np.zeros(n)\n",
    "    Q_hat_adjusteds = np.zeros(n)\n",
    "\n",
    "    # ======================= Start Stimulation! =======================\n",
    "\n",
    "    for i, row in demand_df_test.iterrows():\n",
    "\n",
    "        ### Data for this stimulation\n",
    "        demand_row = demand_df_test.iloc[i]\n",
    "        Qk_hat_df_test_row = Qk_hat_df_test.iloc[i]\n",
    "        X_data = testing_df.iloc[i].tolist()\n",
    "        X_data.append(1)\n",
    "\n",
    "        # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "        ### 用線性回歸計算F_var\n",
    "        f_vars[i] = sum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "        F_vars[i] = 1 / (1 + np.exp(-(f_vars[i])))\n",
    "        Q0_vars[i] = F_vars[i] * Q_star\n",
    "\n",
    "        # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "        # Step 1: Calculate tau_vars as a linear combination of X_data and betas\n",
    "        for k in range(K):\n",
    "            tau_vars[i, k] = sum(\n",
    "                X_data[j] * betas[k, j] for j in range(features_num + 1)\n",
    "            )\n",
    "\n",
    "        max_r_index[i] = np.argmax(tau_vars[i])\n",
    "        R_vars[i, max_r_index[i]] = 1\n",
    "\n",
    "        print(f\"tau: {tau_vars[i]}\")\n",
    "        print(f\"R: {R_vars[i]}\")\n",
    "        print(f\"max_r_index: {max_r_index[i]}\")\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "        # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "        Q_hats[i] = sum(\n",
    "            R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
    "        )\n",
    "        Q_hat_adjusteds[i] = Q_hats[i] - Q0_vars[i]\n",
    "        Q1_vars[i] = max(Q_hat_adjusteds[i], 0)\n",
    "\n",
    "        # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "        # Calculate the demand up to k-1\n",
    "        total_demand_up_to_k_minus_1 = sum(\n",
    "            R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_up_to_k_minus_1_vars[i] = total_demand_up_to_k_minus_1\n",
    "\n",
    "        # Calculate the demand from k to T\n",
    "        total_demand_from_k_to_T = sum(\n",
    "            R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars[i] = total_demand_from_k_to_T\n",
    "\n",
    "        Sold_0s[i] = min(total_demand_up_to_k_minus_1_vars[i], Q0_vars[i])\n",
    "        Left_0s[i] = max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "        Lost_0s[i] = max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "        Q1_plus_lefts[i] = Q1_vars[i] + Left_0s[i]\n",
    "\n",
    "        Sold_1s[i] = min(total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i])\n",
    "        Left_1s[i] = max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "        Lost_1s[i] = max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "\n",
    "        # assigned_R = max_r_index[i]\n",
    "\n",
    "        # all_holding_costs_0[i] = (\n",
    "        #     (Q0_vars[i] + Left_0s[i] + Q1_vars[i]) * ((assigned_R + 2) - 1) / 2\n",
    "        # )\n",
    "        # all_holding_costs_1[i] = (\n",
    "        #     (Q1_vars[i] + Left_0s[i] + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "        # )\n",
    "\n",
    "        profits_vars[i] = (\n",
    "            (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue from sales\n",
    "            - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "            - (cost - salvage_value) * Left_1s[i]\n",
    "            # - holding_cost * (all_holding_costs_0[i] + all_holding_costs_1[i])\n",
    "        )\n",
    "\n",
    "    # Calculate the average profit\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"average_profits\": [np.mean(profits_vars)],\n",
    "            \"average_loss\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"average_left\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"alpha_values\": [alphas],\n",
    "            \"beta_balues\": [betas],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    stimulation_result = pd.DataFrame(\n",
    "        {\n",
    "            \"F\": F_vars,\n",
    "            \"R(T)\": [x + 2 for x in max_r_index],\n",
    "            \"Sold_0\": Sold_0s,\n",
    "            \"Left_0\": Left_0s,\n",
    "            \"Lost_0\": Lost_0s,\n",
    "            \"Sold_1\": Sold_1s,\n",
    "            \"Left_1\": Left_1s,\n",
    "            \"Lost_1\": Lost_1s,\n",
    "            \"profits\": profits_vars,\n",
    "            \"Q0\": Q0_vars,\n",
    "            \"Q1\": Q1_vars,\n",
    "            \"hc0\": all_holding_costs_0,\n",
    "            \"hc1\": all_holding_costs_1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return results_df, stimulation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S16 - Beta with second Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_fully_flexible_beta_with_second_training_16(\n",
    "    alphas,\n",
    "    betas,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_test,\n",
    "    Qk_hat_df_test,\n",
    "    testing_df,\n",
    "):\n",
    "\n",
    "    # ======================= Global Variables =======================\n",
    "\n",
    "    # Category 1 - Some variables that is important to future work\n",
    "    K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "    n = len(demand_df_test)\n",
    "\n",
    "    # Initialize lists or numpy arrays to replace Gurobi variables\n",
    "    Sold_0s = np.zeros(n)\n",
    "    Left_0s = np.zeros(n)\n",
    "    Lost_0s = np.zeros(n)\n",
    "    Sold_1s = np.zeros(n)\n",
    "    Left_1s = np.zeros(n)\n",
    "    Lost_1s = np.zeros(n)\n",
    "    all_holding_costs_0 = np.zeros(n)\n",
    "    all_holding_costs_1 = np.zeros(n)\n",
    "    profits_vars = np.zeros(n)\n",
    "\n",
    "    # 1-2. Arrays for demand calculation up to certain periods\n",
    "    total_demand_up_to_k_minus_1_vars = np.zeros(n)\n",
    "    total_demand_from_k_to_T_vars = np.zeros(n)\n",
    "    Q1_plus_lefts = np.zeros(n)\n",
    "\n",
    "    # 2. Variables for Model 2: Optimal Fraction Model\n",
    "    f_vars = np.zeros(n)\n",
    "    F_vars = np.zeros(n)  # Assuming values will be between 0 and 1\n",
    "    Q0_vars = np.zeros(n)  # Replace Q_star with a specific value as needed\n",
    "\n",
    "    # 3. Variables for Model 3: Optimal Order Time Model (2D array for binary values)\n",
    "    tau_vars = np.zeros((n, K))\n",
    "    exp_tau_vars = np.zeros((n, K))\n",
    "    r_vars = np.zeros((n, K))\n",
    "    max_r_index = np.zeros(n, dtype=int)\n",
    "    R_vars = np.zeros(\n",
    "        (n, K), dtype=int\n",
    "    )  # Binary array to select one optimal replenishment time\n",
    "\n",
    "    # 4. Variables for Model 4: Re-estimate order-up-to-level\n",
    "    Q1_vars = np.zeros(n)\n",
    "    Q_hats = np.zeros(n)\n",
    "    Q_hat_adjusteds = np.zeros(n)\n",
    "\n",
    "    # ======================= Start Stimulation! =======================\n",
    "\n",
    "    for i, row in demand_df_test.iterrows():\n",
    "\n",
    "        ### Data for this stimulation\n",
    "        demand_row = demand_df_test.iloc[i]\n",
    "        Qk_hat_df_test_row = Qk_hat_df_test.iloc[i]\n",
    "        X_data = testing_df.iloc[i].tolist()\n",
    "        X_data.append(1)\n",
    "\n",
    "        # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "        ### 用線性回歸計算F_var\n",
    "        f_vars[i] = sum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "        F_vars[i] = 1 / (1 + np.exp(-(f_vars[i])))\n",
    "        Q0_vars[i] = F_vars[i] * Q_star\n",
    "\n",
    "        # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "        # Step 1: Calculate tau_vars as a linear combination of X_data and betas\n",
    "        for k in range(K):\n",
    "            tau_vars[i, k] = sum(\n",
    "                X_data[j] * betas[k, j] for j in range(features_num + 1)\n",
    "            )\n",
    "\n",
    "        max_r_index[i] = np.argmax(tau_vars[i])\n",
    "        R_vars[i, max_r_index[i]] = 1\n",
    "\n",
    "        print(f\"tau: {tau_vars[i]}\")\n",
    "        print(f\"R: {R_vars[i]}\")\n",
    "        print(f\"max_r_index: {max_r_index[i]}\")\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "        # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "        Q_hats[i] = sum(\n",
    "            R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
    "        )\n",
    "        Q_hat_adjusteds[i] = Q_hats[i] - Q0_vars[i]\n",
    "        Q1_vars[i] = max(Q_hat_adjusteds[i], 0)\n",
    "\n",
    "        # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "        # Calculate the demand up to k-1\n",
    "        total_demand_up_to_k_minus_1 = sum(\n",
    "            R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_up_to_k_minus_1_vars[i] = total_demand_up_to_k_minus_1\n",
    "\n",
    "        # Calculate the demand from k to T\n",
    "        total_demand_from_k_to_T = sum(\n",
    "            R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars[i] = total_demand_from_k_to_T\n",
    "\n",
    "        Sold_0s[i] = min(total_demand_up_to_k_minus_1_vars[i], Q0_vars[i])\n",
    "        Left_0s[i] = max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "        Lost_0s[i] = max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "        Q1_plus_lefts[i] = Q1_vars[i] + Left_0s[i]\n",
    "\n",
    "        Sold_1s[i] = min(total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i])\n",
    "        Left_1s[i] = max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "        Lost_1s[i] = max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "\n",
    "        # assigned_R = max_r_index[i]\n",
    "\n",
    "        # all_holding_costs_0[i] = (\n",
    "        #     (Q0_vars[i] + Left_0s[i] + Q1_vars[i]) * ((assigned_R + 2) - 1) / 2\n",
    "        # )\n",
    "        # all_holding_costs_1[i] = (\n",
    "        #     (Q1_vars[i] + Left_0s[i] + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "        # )\n",
    "\n",
    "        profits_vars[i] = (\n",
    "            (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue from sales\n",
    "            - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "            - (cost - salvage_value) * Left_1s[i]\n",
    "            # - holding_cost * (all_holding_costs_0[i] + all_holding_costs_1[i])\n",
    "        )\n",
    "\n",
    "    # Calculate the average profit\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"average_profits\": [np.mean(profits_vars)],\n",
    "            \"average_loss\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"average_left\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"alpha_values\": [alphas],\n",
    "            \"beta_balues\": [betas],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    stimulation_result = pd.DataFrame(\n",
    "        {\n",
    "            \"F\": F_vars,\n",
    "            \"R(T)\": [x + 2 for x in max_r_index],\n",
    "            \"Sold_0\": Sold_0s,\n",
    "            \"Left_0\": Left_0s,\n",
    "            \"Lost_0\": Lost_0s,\n",
    "            \"Sold_1\": Sold_1s,\n",
    "            \"Left_1\": Left_1s,\n",
    "            \"Lost_1\": Lost_1s,\n",
    "            \"profits\": profits_vars,\n",
    "            \"Q0\": Q0_vars,\n",
    "            \"Q1\": Q1_vars,\n",
    "            \"hc0\": all_holding_costs_0,\n",
    "            \"hc1\": all_holding_costs_1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return results_df, stimulation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting reasonable parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202504101622"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CURRENT_TIMESTAMP = int(datetime.now().strftime(\"%Y%m%d%H%M\"))\n",
    "CURRENT_TIMESTAMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service_lv: 0.6\n"
     ]
    }
   ],
   "source": [
    "status = \"train\"\n",
    "\n",
    "service_lv = calculate_service_level(\n",
    "    salvage_value=salvage_value, cost=cost, price=price\n",
    ")\n",
    "print(f\"service_lv: {service_lv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_df, testing_df = training_data_folds[0]\n",
    "# demand_df_train, demand_df_test = demand_folds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>251.794016</td>\n",
       "      <td>254.356464</td>\n",
       "      <td>247.741536</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>261.523870</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.087872</td>\n",
       "      <td>252.716034</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.356465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251.056784</td>\n",
       "      <td>251.010919</td>\n",
       "      <td>248.192143</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>250.249903</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>252.054546</td>\n",
       "      <td>246.842220</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>251.010920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>297.528249</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>294.250464</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>283.569719</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>285.767294</td>\n",
       "      <td>287.835884</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>291.630992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>289.066894</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.355508</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>285.816090</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>292.681865</td>\n",
       "      <td>290.851589</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.907838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298.072424</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>299.903104</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>296.615372</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>290.943971</td>\n",
       "      <td>295.944768</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>293.500607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>301.401948</td>\n",
       "      <td>298.930917</td>\n",
       "      <td>300.714683</td>\n",
       "      <td>298.930917</td>\n",
       "      <td>294.785980</td>\n",
       "      <td>298.930917</td>\n",
       "      <td>299.484772</td>\n",
       "      <td>298.727945</td>\n",
       "      <td>298.930917</td>\n",
       "      <td>298.930917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>291.672619</td>\n",
       "      <td>289.957928</td>\n",
       "      <td>291.788015</td>\n",
       "      <td>289.957928</td>\n",
       "      <td>285.872455</td>\n",
       "      <td>289.957928</td>\n",
       "      <td>290.444897</td>\n",
       "      <td>292.664979</td>\n",
       "      <td>289.957928</td>\n",
       "      <td>289.957928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>269.341662</td>\n",
       "      <td>273.073968</td>\n",
       "      <td>269.572013</td>\n",
       "      <td>273.073968</td>\n",
       "      <td>271.669642</td>\n",
       "      <td>273.073968</td>\n",
       "      <td>273.459253</td>\n",
       "      <td>273.376911</td>\n",
       "      <td>273.073968</td>\n",
       "      <td>273.073968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>291.803572</td>\n",
       "      <td>289.026459</td>\n",
       "      <td>288.668454</td>\n",
       "      <td>289.026459</td>\n",
       "      <td>282.672846</td>\n",
       "      <td>289.026459</td>\n",
       "      <td>287.717318</td>\n",
       "      <td>286.983188</td>\n",
       "      <td>289.026459</td>\n",
       "      <td>289.026459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>258.259455</td>\n",
       "      <td>255.913721</td>\n",
       "      <td>255.439341</td>\n",
       "      <td>255.913721</td>\n",
       "      <td>255.976937</td>\n",
       "      <td>255.913721</td>\n",
       "      <td>255.911150</td>\n",
       "      <td>251.612160</td>\n",
       "      <td>255.913721</td>\n",
       "      <td>255.913721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>278.551022</td>\n",
       "      <td>281.996051</td>\n",
       "      <td>281.029925</td>\n",
       "      <td>281.996051</td>\n",
       "      <td>289.535263</td>\n",
       "      <td>281.996051</td>\n",
       "      <td>285.332026</td>\n",
       "      <td>287.403702</td>\n",
       "      <td>281.996051</td>\n",
       "      <td>281.996051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>256.151738</td>\n",
       "      <td>257.167663</td>\n",
       "      <td>252.945792</td>\n",
       "      <td>257.167664</td>\n",
       "      <td>264.788247</td>\n",
       "      <td>257.167664</td>\n",
       "      <td>262.220107</td>\n",
       "      <td>256.201799</td>\n",
       "      <td>257.167664</td>\n",
       "      <td>257.167664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>295.186828</td>\n",
       "      <td>297.233446</td>\n",
       "      <td>298.436136</td>\n",
       "      <td>297.233446</td>\n",
       "      <td>301.105487</td>\n",
       "      <td>297.233446</td>\n",
       "      <td>295.272601</td>\n",
       "      <td>298.475322</td>\n",
       "      <td>297.233446</td>\n",
       "      <td>297.233446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>278.898077</td>\n",
       "      <td>276.092416</td>\n",
       "      <td>278.517826</td>\n",
       "      <td>276.092416</td>\n",
       "      <td>274.536813</td>\n",
       "      <td>276.092416</td>\n",
       "      <td>276.925605</td>\n",
       "      <td>274.583612</td>\n",
       "      <td>276.092416</td>\n",
       "      <td>276.092416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>276.126061</td>\n",
       "      <td>270.733097</td>\n",
       "      <td>271.699824</td>\n",
       "      <td>270.733097</td>\n",
       "      <td>268.070512</td>\n",
       "      <td>270.733097</td>\n",
       "      <td>266.551512</td>\n",
       "      <td>268.201901</td>\n",
       "      <td>270.733097</td>\n",
       "      <td>270.733097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "0   251.794016  254.356464  247.741536  254.356465  261.523870  254.356465   \n",
       "1   251.056784  251.010919  248.192143  251.010920  250.249903  251.010920   \n",
       "2   297.528249  291.630992  294.250464  291.630992  283.569719  291.630992   \n",
       "3   289.066894  288.907838  288.355508  288.907838  285.816090  288.907838   \n",
       "4   298.072424  293.500607  299.903104  293.500607  296.615372  293.500607   \n",
       "5   301.401948  298.930917  300.714683  298.930917  294.785980  298.930917   \n",
       "6   291.672619  289.957928  291.788015  289.957928  285.872455  289.957928   \n",
       "7   269.341662  273.073968  269.572013  273.073968  271.669642  273.073968   \n",
       "8   291.803572  289.026459  288.668454  289.026459  282.672846  289.026459   \n",
       "9   258.259455  255.913721  255.439341  255.913721  255.976937  255.913721   \n",
       "10  278.551022  281.996051  281.029925  281.996051  289.535263  281.996051   \n",
       "11  256.151738  257.167663  252.945792  257.167664  264.788247  257.167664   \n",
       "12  295.186828  297.233446  298.436136  297.233446  301.105487  297.233446   \n",
       "13  278.898077  276.092416  278.517826  276.092416  274.536813  276.092416   \n",
       "14  276.126061  270.733097  271.699824  270.733097  268.070512  270.733097   \n",
       "\n",
       "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "0   254.087872  252.716034  254.356465  254.356465  \n",
       "1   252.054546  246.842220  251.010920  251.010920  \n",
       "2   285.767294  287.835884  291.630992  291.630992  \n",
       "3   292.681865  290.851589  288.907838  288.907838  \n",
       "4   290.943971  295.944768  293.500607  293.500607  \n",
       "5   299.484772  298.727945  298.930917  298.930917  \n",
       "6   290.444897  292.664979  289.957928  289.957928  \n",
       "7   273.459253  273.376911  273.073968  273.073968  \n",
       "8   287.717318  286.983188  289.026459  289.026459  \n",
       "9   255.911150  251.612160  255.913721  255.913721  \n",
       "10  285.332026  287.403702  281.996051  281.996051  \n",
       "11  262.220107  256.201799  257.167664  257.167664  \n",
       "12  295.272601  298.475322  297.233446  297.233446  \n",
       "13  276.925605  274.583612  276.092416  276.092416  \n",
       "14  266.551512  268.201901  270.733097  270.733097  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of sum: 2779.8596331748327\n",
      "std of sum: 169.30737789635148\n",
      "60.0 percentile of sum: 2822.7531669043915\n",
      "Q_star: 2822.7531669043915\n"
     ]
    }
   ],
   "source": [
    "Q_star = calculate_Q_star(demand_df_train, service_level=service_lv)\n",
    "print(f\"Q_star: {Q_star}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Qk_hat_k2</th>\n",
       "      <th>Qk_hat_k3</th>\n",
       "      <th>Qk_hat_k4</th>\n",
       "      <th>Qk_hat_k5</th>\n",
       "      <th>Qk_hat_k6</th>\n",
       "      <th>Qk_hat_k7</th>\n",
       "      <th>Qk_hat_k8</th>\n",
       "      <th>Qk_hat_k9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2534.081315</td>\n",
       "      <td>2543.948337</td>\n",
       "      <td>2538.169538</td>\n",
       "      <td>2538.169539</td>\n",
       "      <td>2543.228824</td>\n",
       "      <td>2543.228823</td>\n",
       "      <td>2539.412604</td>\n",
       "      <td>2539.645653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2527.210887</td>\n",
       "      <td>2508.922414</td>\n",
       "      <td>2510.804283</td>\n",
       "      <td>2510.804283</td>\n",
       "      <td>2504.954162</td>\n",
       "      <td>2504.954163</td>\n",
       "      <td>2504.391943</td>\n",
       "      <td>2503.450194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2960.288461</td>\n",
       "      <td>2917.779397</td>\n",
       "      <td>2913.227722</td>\n",
       "      <td>2913.227722</td>\n",
       "      <td>2911.802544</td>\n",
       "      <td>2911.802544</td>\n",
       "      <td>2907.898303</td>\n",
       "      <td>2907.106573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2881.435279</td>\n",
       "      <td>2892.708128</td>\n",
       "      <td>2889.196078</td>\n",
       "      <td>2889.196078</td>\n",
       "      <td>2886.719816</td>\n",
       "      <td>2886.719816</td>\n",
       "      <td>2891.092232</td>\n",
       "      <td>2891.311134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2965.359748</td>\n",
       "      <td>2937.295369</td>\n",
       "      <td>2945.103421</td>\n",
       "      <td>2945.103421</td>\n",
       "      <td>2949.918090</td>\n",
       "      <td>2949.918090</td>\n",
       "      <td>2948.619230</td>\n",
       "      <td>2948.982677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2996.388296</td>\n",
       "      <td>2993.214630</td>\n",
       "      <td>2989.552936</td>\n",
       "      <td>2989.552937</td>\n",
       "      <td>2989.334267</td>\n",
       "      <td>2989.334267</td>\n",
       "      <td>2991.437954</td>\n",
       "      <td>2989.769915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2905.718591</td>\n",
       "      <td>2902.663421</td>\n",
       "      <td>2903.119411</td>\n",
       "      <td>2903.119411</td>\n",
       "      <td>2899.280034</td>\n",
       "      <td>2899.280034</td>\n",
       "      <td>2900.342555</td>\n",
       "      <td>2902.232607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2697.611597</td>\n",
       "      <td>2734.038448</td>\n",
       "      <td>2733.262880</td>\n",
       "      <td>2733.262878</td>\n",
       "      <td>2725.743234</td>\n",
       "      <td>2725.743234</td>\n",
       "      <td>2722.432589</td>\n",
       "      <td>2722.789323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2906.938973</td>\n",
       "      <td>2892.764411</td>\n",
       "      <td>2885.548336</td>\n",
       "      <td>2885.548336</td>\n",
       "      <td>2883.835781</td>\n",
       "      <td>2883.835781</td>\n",
       "      <td>2883.681181</td>\n",
       "      <td>2882.977674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2594.334133</td>\n",
       "      <td>2557.573980</td>\n",
       "      <td>2560.927624</td>\n",
       "      <td>2560.927623</td>\n",
       "      <td>2558.351789</td>\n",
       "      <td>2558.351789</td>\n",
       "      <td>2558.077087</td>\n",
       "      <td>2556.767651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2783.435609</td>\n",
       "      <td>2824.279231</td>\n",
       "      <td>2827.528743</td>\n",
       "      <td>2827.528743</td>\n",
       "      <td>2830.080320</td>\n",
       "      <td>2830.080320</td>\n",
       "      <td>2830.650460</td>\n",
       "      <td>2831.832195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2574.691858</td>\n",
       "      <td>2571.744830</td>\n",
       "      <td>2569.436321</td>\n",
       "      <td>2569.436323</td>\n",
       "      <td>2575.298932</td>\n",
       "      <td>2575.298932</td>\n",
       "      <td>2579.362663</td>\n",
       "      <td>2578.146004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2938.468259</td>\n",
       "      <td>2977.998016</td>\n",
       "      <td>2980.486511</td>\n",
       "      <td>2980.486512</td>\n",
       "      <td>2981.857422</td>\n",
       "      <td>2981.857422</td>\n",
       "      <td>2977.059368</td>\n",
       "      <td>2974.643605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2786.669883</td>\n",
       "      <td>2761.750741</td>\n",
       "      <td>2766.420356</td>\n",
       "      <td>2766.420355</td>\n",
       "      <td>2763.544241</td>\n",
       "      <td>2763.544241</td>\n",
       "      <td>2765.192205</td>\n",
       "      <td>2763.924015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2760.836871</td>\n",
       "      <td>2706.337694</td>\n",
       "      <td>2704.322900</td>\n",
       "      <td>2704.322898</td>\n",
       "      <td>2705.797118</td>\n",
       "      <td>2705.797118</td>\n",
       "      <td>2702.924363</td>\n",
       "      <td>2704.315296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Qk_hat_k2    Qk_hat_k3    Qk_hat_k4    Qk_hat_k5    Qk_hat_k6  \\\n",
       "0   2534.081315  2543.948337  2538.169538  2538.169539  2543.228824   \n",
       "1   2527.210887  2508.922414  2510.804283  2510.804283  2504.954162   \n",
       "2   2960.288461  2917.779397  2913.227722  2913.227722  2911.802544   \n",
       "3   2881.435279  2892.708128  2889.196078  2889.196078  2886.719816   \n",
       "4   2965.359748  2937.295369  2945.103421  2945.103421  2949.918090   \n",
       "5   2996.388296  2993.214630  2989.552936  2989.552937  2989.334267   \n",
       "6   2905.718591  2902.663421  2903.119411  2903.119411  2899.280034   \n",
       "7   2697.611597  2734.038448  2733.262880  2733.262878  2725.743234   \n",
       "8   2906.938973  2892.764411  2885.548336  2885.548336  2883.835781   \n",
       "9   2594.334133  2557.573980  2560.927624  2560.927623  2558.351789   \n",
       "10  2783.435609  2824.279231  2827.528743  2827.528743  2830.080320   \n",
       "11  2574.691858  2571.744830  2569.436321  2569.436323  2575.298932   \n",
       "12  2938.468259  2977.998016  2980.486511  2980.486512  2981.857422   \n",
       "13  2786.669883  2761.750741  2766.420356  2766.420355  2763.544241   \n",
       "14  2760.836871  2706.337694  2704.322900  2704.322898  2705.797118   \n",
       "\n",
       "      Qk_hat_k7    Qk_hat_k8    Qk_hat_k9  \n",
       "0   2543.228823  2539.412604  2539.645653  \n",
       "1   2504.954163  2504.391943  2503.450194  \n",
       "2   2911.802544  2907.898303  2907.106573  \n",
       "3   2886.719816  2891.092232  2891.311134  \n",
       "4   2949.918090  2948.619230  2948.982677  \n",
       "5   2989.334267  2991.437954  2989.769915  \n",
       "6   2899.280034  2900.342555  2902.232607  \n",
       "7   2725.743234  2722.432589  2722.789323  \n",
       "8   2883.835781  2883.681181  2882.977674  \n",
       "9   2558.351789  2558.077087  2556.767651  \n",
       "10  2830.080320  2830.650460  2831.832195  \n",
       "11  2575.298932  2579.362663  2578.146004  \n",
       "12  2981.857422  2977.059368  2974.643605  \n",
       "13  2763.544241  2765.192205  2763.924015  \n",
       "14  2705.797118  2702.924363  2704.315296  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_matrix, covariance_matrix = cal_mu_and_cov_matrix(demand_df_train)\n",
    "Qk_hat_df_train = make_Qk_hat_df(\n",
    "    demand_df_train, T, service_lv, mu_matrix, covariance_matrix\n",
    ")\n",
    "Qk_hat_df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-folds training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data_folds), len(demand_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Testing Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for single fold training.\n",
    "def perform_fold_training(\n",
    "    training_df, demand_df_train, Qk_hat_df_train, Q_star\n",
    ") -> dict[str, float]:\n",
    "\n",
    "    # 1. Baseline model\n",
    "    (\n",
    "        baseline_avg_losses,\n",
    "        baseline_avg_lefts,\n",
    "        baseline_avg_profits,\n",
    "        baseline_avg_operation_profits,\n",
    "        baseline_stimulation_df,\n",
    "    ) = one_time_procurement(\n",
    "        Q_star=Q_star,\n",
    "        demand_df=demand_df_train,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        salvage_value=salvage_value,\n",
    "    )\n",
    "\n",
    "    # 2. S1 - Grid F & Grid R\n",
    "\n",
    "    results_df_1, stimulation_results_df_1 = None, None\n",
    "\n",
    "    results_df_1, stimulation_results_df_1 = grid_fixed_F_fixed_R(\n",
    "        assigned_Ts=ASSIGNED_TS,\n",
    "        assigned_Fs=ASSIGNED_FS,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        salvage_value=salvage_value,\n",
    "        Qk_hat_df=Qk_hat_df_train,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Q_star=Q_star,\n",
    "    )\n",
    "\n",
    "    S1_profit_training = results_df_1.iloc[0][\"average_profits\"]\n",
    "\n",
    "    # 3. S2 - Grid R & Flexible F\n",
    "\n",
    "    results_df_2, stimulation_results_df_2 = None, None\n",
    "    results_df_2, stimulation_results_df_2 = grid_flexible_F_fixed_R(\n",
    "        assigned_Ts=ASSIGNED_TS,\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df_train=Qk_hat_df_train,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "\n",
    "    S2_profit_training = results_df_2.iloc[0][\"average_profits\"]\n",
    "\n",
    "    # 5. S14 - Optimized F & Rk\n",
    "    results_df_14, stimulation_results_df_14 = None, None\n",
    "    results_df_14, stimulation_results_df_14 = cal_optimized_F_R(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df_train,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "    S14_profit_training = results_df_14.iloc[0][\"average_profits\"]\n",
    "\n",
    "    # 4. S12 - Beta without r\n",
    "\n",
    "    results_df_12, stimulation_results_df_12 = None, None\n",
    "    results_df_12, stimulation_results_df_12 = fully_flexible_beta_with_softmax_12(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df_train,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "    if results_df_12 is not None:\n",
    "        S12_profit_training = results_df_12.iloc[0][\"average_profits\"]\n",
    "    else:\n",
    "        S12_profit_training = None\n",
    "\n",
    "    # # 6. S15 - Beta with Lasso\n",
    "    # results_df_15, stimulation_results_df_15 = None, None\n",
    "    # results_df_15, stimulation_results_df_15 = fully_flexible_beta_with_lasso_15(\n",
    "    #     salvage_value=salvage_value,\n",
    "    #     cost=cost,\n",
    "    #     price=price,\n",
    "    #     Q_star=Q_star,\n",
    "    #     demand_df_train=demand_df_train,\n",
    "    #     Qk_hat_df=Qk_hat_df_train,\n",
    "    #     training_df=training_df,\n",
    "    #     lambda_beta=LASSO_BETA,\n",
    "    # )\n",
    "    # if results_df_15 is not None:\n",
    "    #     S15_profit_training = results_df_15.iloc[0][\"average_profits\"]\n",
    "    # else:\n",
    "    #     S15_profit_training = None\n",
    "\n",
    "    # # 7. S16 - Beta with Second Training\n",
    "    # results_df_16, stimulation_results_df_16 = None, None\n",
    "    # if results_df_12 is not None:\n",
    "    #     last_beta_total = np.sum(np.abs(results_df_12.iloc[0][\"beta_values\"]))\n",
    "    #     results_df_16, stimulation_results_df_16 = (\n",
    "    #         fully_flexible_beta_with_second_training_16(\n",
    "    #             salvage_value=salvage_value,\n",
    "    #             cost=cost,\n",
    "    #             price=price,\n",
    "    #             Q_star=Q_star,\n",
    "    #             demand_df_train=demand_df_train,\n",
    "    #             Qk_hat_df=Qk_hat_df_train,\n",
    "    #             training_df=training_df,\n",
    "    #             lambda_beta=LASSO_BETA_SECOND_TRAIN,\n",
    "    #             last_beta_total=last_beta_total,\n",
    "    #         )\n",
    "    #     )\n",
    "    # if results_df_16 is not None:\n",
    "    #     S16_profit_training = results_df_16.iloc[0][\"average_profits\"]\n",
    "    # else:\n",
    "    #     S16_profit_training = None\n",
    "\n",
    "    # print(f\"baseline_profit: {baseline_avg_profits}\")\n",
    "    # print(f\"S1_profit_training: {S1_profit_training}\")\n",
    "    # print(f\"S2_profit_training: {S2_profit_training}\")\n",
    "    # print(f\"S12_profit_training: {S12_profit_training}\")\n",
    "    # print(f\"S14_profit_training: {S14_profit_training}\")\n",
    "    # print(f\"S15_profit_training: {S15_profit_training}\")\n",
    "    # print(f\"S16_profit_training: {S16_profit_training}\")\n",
    "\n",
    "    # 整理利潤結果\n",
    "    training_profits = {\n",
    "        \"baseline\": baseline_avg_profits,\n",
    "        \"S1\": S1_profit_training,\n",
    "        \"S2\": S2_profit_training,\n",
    "        \"S12\": S12_profit_training,\n",
    "        # \"S15\": S15_profit_training,\n",
    "        # \"S16\": S16_profit_training,\n",
    "        # \"S12\": None,\n",
    "        \"S15\": None,\n",
    "        \"S16\": None,\n",
    "        \"S14\": S14_profit_training,\n",
    "    }\n",
    "\n",
    "    training_results = {\n",
    "        \"S1\": results_df_1,\n",
    "        \"S2\": results_df_2,\n",
    "        \"S12\": results_df_12,\n",
    "        # \"S15\": results_df_15,\n",
    "        # \"S16\": results_df_16,\n",
    "        # \"S12\": None,\n",
    "        \"S15\": None,\n",
    "        \"S16\": None,\n",
    "        \"S14\": results_df_14,\n",
    "    }\n",
    "\n",
    "    training_stimulation_results = {\n",
    "        \"baseline\": baseline_stimulation_df,\n",
    "        \"S1\": stimulation_results_df_1,\n",
    "        \"S2\": stimulation_results_df_2,\n",
    "        \"S12\": stimulation_results_df_12,\n",
    "        # \"S15\": stimulation_results_df_15,\n",
    "        # \"S16\": stimulation_results_df_16,\n",
    "        # \"S12\": None,\n",
    "        \"S15\": None,\n",
    "        \"S16\": None,\n",
    "        \"S14\": stimulation_results_df_14,\n",
    "    }\n",
    "\n",
    "    return training_profits, training_results, training_stimulation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for single fold testing.\n",
    "\n",
    "\n",
    "def perform_fold_testing(\n",
    "    results_df_1,\n",
    "    results_df_2,\n",
    "    results_df_12,\n",
    "    results_df_15,\n",
    "    results_df_16,\n",
    "    demand_df_test,\n",
    "    Qk_hat_df_test,\n",
    "    Q_star,\n",
    "    testing_df,\n",
    ") -> dict[str, float]:\n",
    "\n",
    "    # 1. Baseline model\n",
    "\n",
    "    (\n",
    "        test_baseline_avg_loss,\n",
    "        test_baseline_avg_lefts,\n",
    "        test_baseline_avg_profits,\n",
    "        test_baseline_avg_operation_profits,\n",
    "        test_stimulation_df_baseline,\n",
    "    ) = one_time_procurement(\n",
    "        Q_star=Q_star,\n",
    "        demand_df=demand_df_test,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        salvage_value=salvage_value,\n",
    "    )\n",
    "\n",
    "    print(f\"baseline_profit: {test_baseline_avg_profits}\")\n",
    "\n",
    "    # 2. S1 - Grid F & Grid R\n",
    "    if results_df_1 is not None:\n",
    "        assigned_T = results_df_1.iloc[0][\"R(T)\"]\n",
    "        assigned_F = results_df_1.iloc[0][\"F\"]\n",
    "\n",
    "        test_results_df_1, test_stimulation_results_df_1 = cal_test_fixed_F_fixed_R(\n",
    "            assigned_T=int(assigned_T),\n",
    "            assigned_F=assigned_F,\n",
    "            salvage_value=salvage_value,\n",
    "            cost=cost,\n",
    "            price=price,\n",
    "            Q_star=Q_star,\n",
    "            demand_df_test=demand_df_test,\n",
    "            Qk_hat_df_test=Qk_hat_df_test,\n",
    "        )\n",
    "\n",
    "    S1_profit_testing = test_results_df_1.iloc[0][\"average_profits\"]\n",
    "\n",
    "    # 3. S2 - Grid R & Flexible F\n",
    "\n",
    "    if results_df_2 is not None and len(results_df_2) > 0:\n",
    "        assigned_R = results_df_2.iloc[0][\"R\"]\n",
    "        alphas = results_df_2.iloc[0][\"alpha_values\"]\n",
    "\n",
    "        test_results_df_2, test_stimulation_results_df_2 = cal_test_flexible_F_fixed_R(\n",
    "            assigned_R=assigned_R[0],\n",
    "            alphas=alphas,\n",
    "            salvage_value=salvage_value,\n",
    "            cost=cost,\n",
    "            price=price,\n",
    "            Q_star=Q_star,\n",
    "            demand_df_test=demand_df_test,\n",
    "            Qk_hat_df_test=Qk_hat_df_test,\n",
    "            testing_df=testing_df,\n",
    "        )\n",
    "\n",
    "    S2_profit_testing = test_results_df_2.iloc[0][\"average_profits\"]\n",
    "\n",
    "    # 5. S14 - Optimized F & Rk\n",
    "    test_results_df_14, test_stimulation_results_df_14 = cal_optimized_F_R(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df=demand_df_test,\n",
    "        Qk_hat_df=Qk_hat_df_test,\n",
    "        training_df=testing_df,\n",
    "    )\n",
    "\n",
    "    S14_profit_testing = test_results_df_14.iloc[0][\"average_profits\"]\n",
    "\n",
    "    # 4. S12 - Beta without r\n",
    "    test_results_df_12, test_stimulation_results_df_12 = None, None\n",
    "    if results_df_12 is not None:\n",
    "        alphas = results_df_12.iloc[0][\"alpha_values\"]\n",
    "        betas = results_df_12.iloc[0][\"beta_values\"]\n",
    "\n",
    "        test_results_df_12, test_stimulation_results_df_12 = (\n",
    "            cal_test_fully_flexible_beta_with_softmax_12(\n",
    "                alphas=alphas,\n",
    "                betas=betas,\n",
    "                salvage_value=salvage_value,\n",
    "                cost=cost,\n",
    "                price=price,\n",
    "                Q_star=Q_star,\n",
    "                demand_df_test=demand_df_test,\n",
    "                Qk_hat_df_test=Qk_hat_df_test,\n",
    "                testing_df=testing_df,\n",
    "            )\n",
    "        )\n",
    "        S12_profit_testing = test_results_df_12.iloc[0][\"average_profits\"]\n",
    "    else:\n",
    "        S12_profit_testing = None\n",
    "\n",
    "    # # 6. S15 - Beta with Lasso\n",
    "    # test_results_df_15, test_stimulation_results_df_15 = None, None\n",
    "    # if results_df_15 is not None:\n",
    "    #     alphas = results_df_15.iloc[0][\"alpha_values\"]\n",
    "    #     betas = results_df_15.iloc[0][\"beta_values\"]\n",
    "\n",
    "    #     test_results_df_15, test_stimulation_results_df_15 = (\n",
    "    #         cal_test_fully_flexible_beta_with_lasso_15(\n",
    "    #             alphas=alphas,\n",
    "    #             betas=betas,\n",
    "    #             salvage_value=salvage_value,\n",
    "    #             cost=cost,\n",
    "    #             price=price,\n",
    "    #             Q_star=Q_star,\n",
    "    #             demand_df_test=demand_df_test,\n",
    "    #             Qk_hat_df_test=Qk_hat_df_test,\n",
    "    #             testing_df=testing_df,\n",
    "    #         )\n",
    "    #     )\n",
    "    #     S15_profit_testing = test_results_df_15.iloc[0][\"average_profits\"]\n",
    "    # else:\n",
    "    #     S15_profit_testing = None\n",
    "\n",
    "    # # 7. S16 - Beta with Second Training\n",
    "    # test_results_df_16, test_stimulation_results_df_16 = None, None\n",
    "    # if results_df_16 is not None:\n",
    "    #     alphas = results_df_16.iloc[0][\"alpha_values\"]\n",
    "    #     betas = results_df_16.iloc[0][\"beta_values\"]\n",
    "\n",
    "    #     test_results_df_16, test_stimulation_results_df_16 = (\n",
    "    #         cal_test_fully_flexible_beta_with_second_training_16(\n",
    "    #             alphas=alphas,\n",
    "    #             betas=betas,\n",
    "    #             salvage_value=salvage_value,\n",
    "    #             cost=cost,\n",
    "    #             price=price,\n",
    "    #             Q_star=Q_star,\n",
    "    #             demand_df_test=demand_df_test,\n",
    "    #             Qk_hat_df_test=Qk_hat_df_test,\n",
    "    #             testing_df=testing_df,\n",
    "    #         )\n",
    "    #     )\n",
    "    #     S16_profit_testing = test_results_df_16.iloc[0][\"average_profits\"]\n",
    "    # else:\n",
    "    #     S16_profit_testing = None\n",
    "\n",
    "    # print(f\"baseline_profit: {test_baseline_avg_profits}\")\n",
    "    # print(f\"S1_profit_testing: {S1_profit_testing}\")\n",
    "    # print(f\"S2_profit_testing: {S2_profit_testing}\")\n",
    "    # print(f\"S12_profit_testing: {S12_profit_testing}\")\n",
    "    # print(f\"S14_profit_testing: {S14_profit_testing}\")\n",
    "    # print(f\"S15_profit_testing: {S15_profit_testing}\")\n",
    "    # print(f\"S16_profit_testing: {S16_profit_testing}\")\n",
    "\n",
    "    # 整理利潤結果\n",
    "    testing_profits = {\n",
    "        \"baseline\": test_baseline_avg_profits,\n",
    "        \"S1\": S1_profit_testing,\n",
    "        \"S2\": S2_profit_testing,\n",
    "        \"S12\": S12_profit_testing,\n",
    "        # \"S15\": S15_profit_testing,\n",
    "        # \"S16\": S16_profit_testing,\n",
    "        # \"S12\": None,\n",
    "        \"S15\": None,\n",
    "        \"S16\": None,\n",
    "        \"S14\": S14_profit_testing,\n",
    "    }\n",
    "\n",
    "    testing_stimulation_results = {\n",
    "        \"baseline\": test_stimulation_df_baseline,\n",
    "        \"S1\": test_stimulation_results_df_1,\n",
    "        \"S2\": test_stimulation_results_df_2,\n",
    "        \"S12\": test_stimulation_results_df_12,\n",
    "        # \"S15\": test_stimulation_results_df_15,\n",
    "        # \"S16\": test_stimulation_results_df_16,\n",
    "        # \"S12\": None,\n",
    "        \"S15\": None,\n",
    "        \"S16\": None,\n",
    "        \"S14\": test_stimulation_results_df_14,\n",
    "    }\n",
    "\n",
    "    return testing_profits, testing_stimulation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Processing Fold 1 =====\n",
      "training_df: \n",
      "           X1   X2          X3\n",
      "0   17.744068  0.0  254.356465\n",
      "1   18.575947  0.0  251.010920\n",
      "2   18.013817  0.0  291.630992\n",
      "3   17.724416  0.0  288.907838\n",
      "4   17.118274  0.0  293.500607\n",
      "5   18.229471  0.0  298.930917\n",
      "6   17.187936  0.0  289.957928\n",
      "7   19.458865  0.0  273.073968\n",
      "8   19.818314  0.0  289.026459\n",
      "9   16.917208  0.0  255.913721\n",
      "10  18.958625  0.0  281.996051\n",
      "11  17.644475  0.0  257.167664\n",
      "12  17.840223  0.0  297.233446\n",
      "13  19.627983  0.0  276.092416\n",
      "14  15.355180  0.0  270.733097\n",
      "demand_df_train: \n",
      "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
      "0   251.794016  254.356464  247.741536  254.356465  261.523870  254.356465   \n",
      "1   251.056784  251.010919  248.192143  251.010920  250.249903  251.010920   \n",
      "2   297.528249  291.630992  294.250464  291.630992  283.569719  291.630992   \n",
      "3   289.066894  288.907838  288.355508  288.907838  285.816090  288.907838   \n",
      "4   298.072424  293.500607  299.903104  293.500607  296.615372  293.500607   \n",
      "5   301.401948  298.930917  300.714683  298.930917  294.785980  298.930917   \n",
      "6   291.672619  289.957928  291.788015  289.957928  285.872455  289.957928   \n",
      "7   269.341662  273.073968  269.572013  273.073968  271.669642  273.073968   \n",
      "8   291.803572  289.026459  288.668454  289.026459  282.672846  289.026459   \n",
      "9   258.259455  255.913721  255.439341  255.913721  255.976937  255.913721   \n",
      "10  278.551022  281.996051  281.029925  281.996051  289.535263  281.996051   \n",
      "11  256.151738  257.167663  252.945792  257.167664  264.788247  257.167664   \n",
      "12  295.186828  297.233446  298.436136  297.233446  301.105487  297.233446   \n",
      "13  278.898077  276.092416  278.517826  276.092416  274.536813  276.092416   \n",
      "14  276.126061  270.733097  271.699824  270.733097  268.070512  270.733097   \n",
      "\n",
      "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
      "0   254.087872  252.716034  254.356465  254.356465  \n",
      "1   252.054546  246.842220  251.010920  251.010920  \n",
      "2   285.767294  287.835884  291.630992  291.630992  \n",
      "3   292.681865  290.851589  288.907838  288.907838  \n",
      "4   290.943971  295.944768  293.500607  293.500607  \n",
      "5   299.484772  298.727945  298.930917  298.930917  \n",
      "6   290.444897  292.664979  289.957928  289.957928  \n",
      "7   273.459253  273.376911  273.073968  273.073968  \n",
      "8   287.717318  286.983188  289.026459  289.026459  \n",
      "9   255.911150  251.612160  255.913721  255.913721  \n",
      "10  285.332026  287.403702  281.996051  281.996051  \n",
      "11  262.220107  256.201799  257.167664  257.167664  \n",
      "12  295.272601  298.475322  297.233446  297.233446  \n",
      "13  276.925605  274.583612  276.092416  276.092416  \n",
      "14  266.551512  268.201901  270.733097  270.733097  \n",
      "testing_df: \n",
      "           X1   X2         X3\n",
      "0   16.322778  1.0  66.706379\n",
      "1   18.871168  1.0  62.103826\n",
      "2   17.280752  1.0  61.289263\n",
      "3   17.842170  1.0  63.154284\n",
      "4   15.093949  1.0  63.637108\n",
      "5   18.088177  1.0  65.701968\n",
      "6   18.060479  1.0  64.386015\n",
      "7   18.084670  1.0  69.883738\n",
      "8   19.718740  1.0  61.020448\n",
      "9   18.409101  1.0  62.088768\n",
      "10  16.797540  1.0  61.613095\n",
      "11  17.185160  1.0  66.531083\n",
      "12  18.488156  1.0  62.532916\n",
      "13  15.301127  1.0  64.663108\n",
      "14  18.333834  1.0  62.444256\n",
      "demand_df_test: \n",
      "    demand_t1  demand_t2  demand_t3  demand_t4  demand_t5  demand_t6  \\\n",
      "0   69.049446  66.984864  65.276090  66.706379  64.399509  66.706379   \n",
      "1   62.472855  61.379065  62.263812  62.103826  59.547465  62.103826   \n",
      "2   57.026718  60.339037  58.994137  61.289263  61.559450  61.289263   \n",
      "3   62.944633  65.536993  64.153686  63.154284  59.520451  63.154284   \n",
      "4   66.458142  64.430325  65.691033  63.637108  58.415305  63.637108   \n",
      "5   65.340264  66.665934  65.624076  65.701968  65.763430  65.701968   \n",
      "6   60.459442  64.184997  61.973620  64.386015  65.111260  64.386015   \n",
      "7   71.557122  70.563024  74.662817  69.883738  69.277905  69.883738   \n",
      "8   63.840751  62.306341  66.968545  61.020448  59.275984  61.020448   \n",
      "9   62.969099  64.263725  64.029270  62.088768  60.721711  62.088768   \n",
      "10  60.057707  60.871552  60.104051  61.613095  62.302393  61.613095   \n",
      "11  68.193840  67.527301  72.362407  66.531083  64.621767  66.531083   \n",
      "12  55.740736  63.143807  63.924512  62.532916  65.056794  62.532916   \n",
      "13  67.989985  63.983761  64.570792  64.663108  66.958315  64.663108   \n",
      "14  58.797450  62.278203  63.120200  62.444256  58.121198  62.444256   \n",
      "\n",
      "    demand_t7  demand_t8  demand_t9  demand_t10  \n",
      "0   71.005184  64.088969  66.706381   66.706379  \n",
      "1   63.271804  55.331312  62.103825   62.103826  \n",
      "2   63.232738  60.581985  61.289264   61.289263  \n",
      "3   62.573906  68.894022  63.154284   63.154283  \n",
      "4   62.211406  62.929656  63.637111   63.637108  \n",
      "5   62.072328  64.226544  65.701970   65.701968  \n",
      "6   66.214844  63.597722  64.386018   64.386015  \n",
      "7   68.924536  69.361419  69.883738   69.883738  \n",
      "8   59.005480  60.829499  61.020442   61.020448  \n",
      "9   60.879685  62.634618  62.088772   62.088768  \n",
      "10  61.283812  63.885645  61.613092   61.613095  \n",
      "11  65.714526  66.642278  66.531082   66.531083  \n",
      "12  56.151613  66.725960  62.532920   62.532916  \n",
      "13  65.885875  61.730881  64.663100   64.663108  \n",
      "14  57.806186  61.151295  62.444260   62.444256  \n",
      "===== Processing Fold 2 =====\n",
      "training_df: \n",
      "           X1   X2          X3\n",
      "0   15.794848  0.0  251.959390\n",
      "1   15.551876  0.0  264.140348\n",
      "2   18.281648  0.0  256.009828\n",
      "3   15.690915  0.0  264.807010\n",
      "4   15.982912  0.0  255.936386\n",
      "5   16.843626  0.0  265.899159\n",
      "6   19.104966  0.0  270.713150\n",
      "7   15.485506  0.0  253.207375\n",
      "8   19.189725  0.0  284.623606\n",
      "9   15.480492  0.0  278.330073\n",
      "10  19.882297  0.0  263.269475\n",
      "11  17.343256  0.0  276.162403\n",
      "12  19.883805  0.0  254.697026\n",
      "13  18.024228  0.0  278.797325\n",
      "14  18.696318  0.0  296.464810\n",
      "demand_df_train: \n",
      "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
      "0   256.519623  251.959390  252.619473  251.959390  246.815799  251.959390   \n",
      "1   266.557046  264.140348  264.160430  264.140348  262.456134  264.140348   \n",
      "2   255.104623  256.009829  259.397400  256.009828  253.201453  256.009828   \n",
      "3   258.328805  264.807010  266.027383  264.807010  264.784493  264.807010   \n",
      "4   253.416118  255.936386  254.214539  255.936386  256.695107  255.936386   \n",
      "5   263.215996  265.899159  268.949097  265.899159  263.130433  265.899159   \n",
      "6   267.820993  270.713150  268.501904  270.713150  272.402984  270.713150   \n",
      "7   250.255196  253.207375  252.917631  253.207375  253.511599  253.207375   \n",
      "8   291.872275  284.623606  289.498687  284.623606  279.906507  284.623606   \n",
      "9   276.428735  278.330073  277.122965  278.330073  276.905217  278.330073   \n",
      "10  261.244738  263.269475  267.407733  263.269475  263.036084  263.269475   \n",
      "11  281.624515  276.162403  277.291903  276.162403  272.064668  276.162403   \n",
      "12  256.640801  254.697025  253.216210  254.697026  257.734949  254.697026   \n",
      "13  276.596581  278.797325  282.033169  278.797325  278.763871  278.797325   \n",
      "14  297.215013  296.464810  297.943972  296.464810  296.618148  296.464810   \n",
      "\n",
      "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
      "0   252.404141  247.642667  251.959390  251.959390  \n",
      "1   268.037060  263.302797  264.140348  264.140348  \n",
      "2   254.294350  257.262525  256.009828  256.009828  \n",
      "3   265.545294  267.617149  264.807010  264.807010  \n",
      "4   259.314176  259.850532  255.936386  255.936386  \n",
      "5   261.011138  267.280099  265.899159  265.899159  \n",
      "6   270.361907  270.006558  270.713150  270.713150  \n",
      "7   251.010061  255.083055  253.207375  253.207375  \n",
      "8   286.218363  285.561041  284.623606  284.623606  \n",
      "9   280.820443  281.184906  278.330073  278.330073  \n",
      "10  260.086461  263.477115  263.269475  263.269475  \n",
      "11  274.337136  273.932259  276.162403  276.162403  \n",
      "12  260.510507  256.621323  254.697026  254.697026  \n",
      "13  274.790903  280.071033  278.797325  278.797325  \n",
      "14  293.376616  299.036274  296.464810  296.464810  \n",
      "testing_df: \n",
      "           X1   X2         X3\n",
      "0   16.592845  1.0  65.761573\n",
      "1   18.337052  1.0  65.920419\n",
      "2   15.658989  1.0  65.722519\n",
      "3   18.581636  1.0  62.230816\n",
      "4   16.447030  1.0  69.527490\n",
      "5   15.915957  1.0  64.471254\n",
      "6   17.932565  1.0  68.464087\n",
      "7   15.100538  1.0  66.994793\n",
      "8   19.144700  1.0  62.974370\n",
      "9   15.023477  1.0  68.137978\n",
      "10  18.389083  1.0  63.965057\n",
      "11  16.350040  1.0  68.811032\n",
      "12  18.675970  1.0  65.812729\n",
      "13  19.810943  1.0  68.817354\n",
      "14  16.243766  1.0  66.925316\n",
      "demand_df_test: \n",
      "    demand_t1  demand_t2  demand_t3  demand_t4  demand_t5  demand_t6  \\\n",
      "0   68.370121  64.894454  67.199076  65.761573  63.053747  65.761573   \n",
      "1   66.587610  64.979976  69.411094  65.920419  65.768066  65.920419   \n",
      "2   70.933664  66.187890  69.618863  65.722519  60.188051  65.722519   \n",
      "3   63.476652  63.427189  58.172863  62.230816  63.207280  62.230816   \n",
      "4   72.298368  69.469709  69.557802  69.527490  69.049027  69.527490   \n",
      "5   61.418697  64.596306  63.090749  64.471254  64.412447  64.471254   \n",
      "6   68.349991  68.233833  65.527941  68.464087  66.683151  68.464087   \n",
      "7   69.173899  67.791676  68.980601  66.994793  66.269833  66.994793   \n",
      "8   65.242553  65.421038  68.671875  62.974370  57.570268  62.974370   \n",
      "9   67.587048  68.232925  69.938504  68.137978  72.345359  68.137978   \n",
      "10  61.458167  62.971443  63.673554  63.965057  63.243366  63.965057   \n",
      "11  62.593521  68.252412  63.791590  68.811032  69.928345  68.811032   \n",
      "12  64.041609  65.899146  66.197404  65.812729  69.316660  65.812729   \n",
      "13  74.367057  70.734412  75.902168  68.817354  67.054075  68.817354   \n",
      "14  66.151275  66.585163  64.513272  66.925316  65.898617  66.925316   \n",
      "\n",
      "    demand_t7  demand_t8  demand_t9  demand_t10  \n",
      "0   63.984974  62.127812  65.761570   65.761573  \n",
      "1   64.382597  68.059276  65.920415   65.920419  \n",
      "2   61.025759  66.547948  65.722519   65.722519  \n",
      "3   66.306121  62.062609  62.230823   62.230816  \n",
      "4   62.861684  67.820569  69.527490   69.527490  \n",
      "5   63.799314  63.693119  64.471254   64.471254  \n",
      "6   76.051808  69.090667  68.464087   68.464087  \n",
      "7   68.198098  71.791799  66.994793   66.994793  \n",
      "8   58.224097  57.855352  62.974371   62.974369  \n",
      "9   66.220593  70.069887  68.137978   68.137978  \n",
      "10  63.568947  62.804834  63.965054   63.965057  \n",
      "11  73.798658  71.999444  68.811034   68.811032  \n",
      "12  62.910571  70.182959  65.812727   65.812729  \n",
      "13  65.788339  68.993258  68.817352   68.817354  \n",
      "14  69.469320  67.743843  66.925316   66.925316  \n",
      "===== Processing Fold 3 =====\n",
      "training_df: \n",
      "           X1   X2          X3\n",
      "0   18.626271  0.0  279.543638\n",
      "1   17.506622  0.0  278.716262\n",
      "2   19.780418  0.0  282.660041\n",
      "3   18.219951  0.0  282.605164\n",
      "4   17.119275  0.0  271.570922\n",
      "5   18.031966  0.0  294.827330\n",
      "6   15.095966  0.0  268.378094\n",
      "7   16.507874  0.0  271.793246\n",
      "8   18.300868  0.0  294.596168\n",
      "9   16.450388  0.0  290.309699\n",
      "10  18.090077  0.0  285.194429\n",
      "11  17.143844  0.0  255.011344\n",
      "12  15.677370  0.0  295.974131\n",
      "13  16.491412  0.0  285.712065\n",
      "14  17.849825  0.0  299.942350\n",
      "demand_df_train: \n",
      "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
      "0   283.936601  279.543638  285.077369  279.543638  276.931626  279.543638   \n",
      "1   280.752154  278.716263  284.554707  278.716262  277.019908  278.716262   \n",
      "2   280.810270  282.660041  281.793406  282.660041  283.966752  282.660041   \n",
      "3   282.690695  282.605164  284.501807  282.605163  280.263205  282.605164   \n",
      "4   269.794746  271.570922  270.571046  271.570922  268.258034  271.570922   \n",
      "5   292.141287  294.827330  296.363870  294.827330  297.636415  294.827330   \n",
      "6   268.295270  268.378094  272.289189  268.378094  267.061530  268.378094   \n",
      "7   274.284449  271.793246  275.891790  271.793246  271.007436  271.793246   \n",
      "8   295.561676  294.596168  295.346168  294.596168  293.901419  294.596168   \n",
      "9   291.572767  290.309699  289.337801  290.309699  287.979840  290.309699   \n",
      "10  289.359045  285.194429  290.753028  285.194429  285.165963  285.194429   \n",
      "11  259.085891  255.011345  255.041535  255.011344  252.753361  255.011344   \n",
      "12  294.703610  295.974131  298.873793  295.974131  294.749160  295.974131   \n",
      "13  288.208942  285.712065  285.303854  285.712065  283.167061  285.712065   \n",
      "14  297.971527  299.942350  303.764967  299.942350  296.928688  299.942350   \n",
      "\n",
      "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
      "0   279.497137  277.402834  279.543638  279.543638  \n",
      "1   272.022711  278.462176  278.716262  278.716262  \n",
      "2   284.073037  284.669504  282.660041  282.660041  \n",
      "3   280.973891  281.791857  282.605164  282.605164  \n",
      "4   273.396903  267.461509  271.570922  271.570922  \n",
      "5   290.725323  299.869873  294.827330  294.827330  \n",
      "6   264.194145  269.637850  268.378094  268.378094  \n",
      "7   271.264363  278.902212  271.793246  271.793246  \n",
      "8   293.952546  289.434761  294.596168  294.596168  \n",
      "9   296.220290  291.572601  290.309699  290.309699  \n",
      "10  280.959832  286.639870  285.194429  285.194429  \n",
      "11  255.233465  254.206041  255.011344  255.011344  \n",
      "12  295.417869  296.365897  295.974131  295.974131  \n",
      "13  283.449034  289.498190  285.712065  285.712065  \n",
      "14  293.866069  299.198634  299.942350  299.942350  \n",
      "testing_df: \n",
      "           X1   X2         X3\n",
      "0   15.747242  1.0  68.558033\n",
      "1   19.340630  1.0  60.117141\n",
      "2   15.812465  1.0  63.599781\n",
      "3   18.077798  1.0  67.299906\n",
      "4   15.619100  1.0  61.716297\n",
      "5   19.240041  1.0  65.210366\n",
      "6   19.036595  1.0  60.543380\n",
      "7   17.845504  1.0  61.999965\n",
      "8   17.035916  1.0  60.185218\n",
      "9   15.345835  1.0  67.936977\n",
      "10  18.487144  1.0  62.239247\n",
      "11  17.267713  1.0  63.453517\n",
      "12  18.610278  1.0  69.280813\n",
      "13  19.331912  1.0  67.044144\n",
      "14  19.877608  1.0  60.318389\n",
      "demand_df_test: \n",
      "    demand_t1  demand_t2  demand_t3  demand_t4  demand_t5  demand_t6  \\\n",
      "0   65.625929  67.884966  68.750730  68.558033  74.175914  68.558033   \n",
      "1   60.770111  61.058111  59.574148  60.117141  58.717761  60.117141   \n",
      "2   66.073532  64.930685  65.683239  63.599781  63.459309  63.599781   \n",
      "3   63.121389  66.381203  61.668540  67.299906  67.404706  67.299906   \n",
      "4   64.915095  62.604395  65.471782  61.716297  63.127936  61.716297   \n",
      "5   63.427651  63.458016  59.857699  65.210366  66.962546  65.210366   \n",
      "6   60.438469  59.245399  60.450320  60.543380  56.855468  60.543380   \n",
      "7   62.564427  62.207089  62.998637  61.999965  61.345170  61.999965   \n",
      "8   60.300860  59.014437  58.383848  60.185218  60.029247  60.185218   \n",
      "9   66.947411  67.567002  67.449213  67.936977  72.133012  67.936977   \n",
      "10  65.746933  65.853934  70.574162  62.239247  55.130102  62.239247   \n",
      "11  61.329502  63.260741  60.017189  63.453517  66.141381  63.453517   \n",
      "12  66.822772  69.549069  66.237491  69.280813  70.547457  69.280813   \n",
      "13  62.577572  67.210049  65.172995  67.044144  70.357863  67.044144   \n",
      "14  59.277409  59.472203  62.933669  60.318389  57.697020  60.318389   \n",
      "\n",
      "    demand_t7  demand_t8  demand_t9  demand_t10  \n",
      "0   65.559446  71.308420  68.558033   68.558033  \n",
      "1   57.979551  58.390955  60.117144   60.117141  \n",
      "2   64.215938  63.806809  63.599781   63.599781  \n",
      "3   70.525694  68.097560  67.299908   67.299906  \n",
      "4   61.250627  60.709187  61.716291   61.716297  \n",
      "5   68.788190  65.421392  65.210367   65.210366  \n",
      "6   59.175878  58.100125  60.543382   60.543380  \n",
      "7   64.147963  63.211996  61.999964   61.999965  \n",
      "8   62.275329  58.171283  60.185214   60.185218  \n",
      "9   64.609175  66.191955  67.936978   67.936977  \n",
      "10  57.888206  63.679955  62.239243   62.239247  \n",
      "11  65.584679  64.101433  63.453519   63.453517  \n",
      "12  70.842404  73.111604  69.280814   69.280813  \n",
      "13  68.535449  70.440907  67.044145   67.044144  \n",
      "14  59.467526  57.168997  60.318390   60.318390  \n"
     ]
    }
   ],
   "source": [
    "for fold_idx in range(len(training_data_folds)):\n",
    "    print(f\"===== Processing Fold {fold_idx + 1} =====\")\n",
    "    # 取出該 fold 的訓練資料與需求資料\n",
    "    training_df, testing_df = training_data_folds[fold_idx]\n",
    "    demand_df_train, demand_df_test = demand_folds[fold_idx]\n",
    "\n",
    "    print(f\"training_df: \\n{training_df}\")\n",
    "    print(f\"demand_df_train: \\n{demand_df_train}\")\n",
    "    print(f\"testing_df: \\n{testing_df}\")\n",
    "    print(f\"demand_df_test: \\n{demand_df_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Processing Fold 1 =====\n",
      "mean of sum: 2779.8596331748327\n",
      "std of sum: 169.30737789635148\n",
      "60.0 percentile of sum: 2822.7531669043915\n",
      "Fold 1 Q_star: 2822.7531669043915\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=0 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x8968a4e0\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [3e+02, 3e+03]\n",
      "Presolve removed 67 rows and 106 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 226 rows, 158 columns, 596 nonzeros\n",
      "Presolved model has 37 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 121 continuous, 37 integer (37 binary)\n",
      "\n",
      "Root relaxation: objective 2.479241e+07, 96 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.4792e+07    0   22          - 2.4792e+07      -     -    0s\n",
      "H    0     0                    1.797238e+07 2.4792e+07  37.9%     -    0s\n",
      "     0     2 2.4792e+07    0   21 1.7972e+07 2.4792e+07  37.9%     -    0s\n",
      "H   72    72                    2.474273e+07 2.4768e+07  0.10%   3.5    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 4\n",
      "\n",
      "Explored 87 nodes (394 simplex iterations) in 0.03 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 2.47427e+07 1.79724e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.474272854381e+07, best bound 2.476847990700e+07, gap 0.1041%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 5.564336473907133, Left0: 4.1504160513618595, Left1: 0.0\n",
      "f_vars[i]: -2.3055, F_vars[i]: 0.0907, Q0_vars[i]: 255.9444\n",
      "f_train: -2.305458309916591, F_train: 0.09067191390773366, Q0_train: 255.94443213233754\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.6765654871784932, Left1: 23.760693792225993\n",
      "f_vars[i]: -2.3237, F_vars[i]: 0.0892, Q0_vars[i]: 251.7333\n",
      "f_train: -2.3236875265742256, F_train: 0.08918007853774236, Q0_train: 251.7333491171946\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1.4350002569650522, Left1: 53.18188932154726\n",
      "f_vars[i]: -2.1332, F_vars[i]: 0.1059, Q0_vars[i]: 298.9632\n",
      "f_train: -2.1331963340593907, F_train: 0.10591193462651939, Q0_train: 298.9632488799785\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 9.875853938779528, Left0: 6.779924021490785, Left1: 0.0\n",
      "f_vars[i]: -2.1449, F_vars[i]: 0.1048, Q0_vars[i]: 295.8468\n",
      "f_train: -2.1449092324204955, F_train: 0.10480789521214527, Q0_train: 295.8468181266667\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.0002011731295575, Left1: 16.377072023945175\n",
      "f_vars[i]: -2.1216, F_vars[i]: 0.1070, Q0_vars[i]: 302.0726\n",
      "f_train: -2.121616731184971, F_train: 0.10701347489294816, Q0_train: 302.072625155513\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 6.555117109515183, Left1: 6.6183828149018495\n",
      "f_vars[i]: -2.1000, F_vars[i]: 0.1091, Q0_vars[i]: 307.9571\n",
      "f_train: -2.09998663289268, F_train: 0.10909812041445166, Q0_train: 307.9570649032101\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.9299251074512505, Left1: 3.4859851168245086\n",
      "f_vars[i]: -2.1383, F_vars[i]: 0.1054, Q0_vars[i]: 297.6025\n",
      "f_train: -2.1382971402961024, F_train: 0.10542988588052066, Q0_train: 297.6025442556083\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 25.17772430219611, Left0: 6.1882428642018725, Left1: 0.0\n",
      "f_vars[i]: -2.2241, F_vars[i]: 0.0976, Q0_vars[i]: 275.5299\n",
      "f_train: -2.224062958921426, F_train: 0.0976103429061004, Q0_train: 275.5299045608185\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 2.4002015154441514, Left1: 23.96129995241847\n",
      "f_vars[i]: -2.1511, F_vars[i]: 0.1042, Q0_vars[i]: 294.2038\n",
      "f_train: -2.151128418679124, F_train: 0.1042258237298938, Q0_train: 294.2037740067766\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 37.56648328068104\n",
      "f_vars[i]: -2.2956, F_vars[i]: 0.0915, Q0_vars[i]: 258.2595\n",
      "f_train: -2.2955516346697116, F_train: 0.09149204339646055, Q0_train: 258.25945524391307\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 48.39658474516938, Left0: 7.871939103378907, Left1: 0.0\n",
      "f_vars[i]: -2.1810, F_vars[i]: 0.1015, Q0_vars[i]: 286.4230\n",
      "f_train: -2.1810039098685894, F_train: 0.10146936146473055, Q0_train: 286.4229614183346\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.454145403242819, Left0: 2.9237245670329055, Left1: 0.0\n",
      "f_vars[i]: -2.2921, F_vars[i]: 0.0918, Q0_vars[i]: 259.0755\n",
      "f_train: -2.2920787313428423, F_train: 0.0917811252924374, Q0_train: 259.0754620812764\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 36.17534411758777, Left0: 10.957052293581121, Left1: 0.0\n",
      "f_vars[i]: -2.1066, F_vars[i]: 0.1085, Q0_vars[i]: 306.1439\n",
      "f_train: -2.106612564525843, F_train: 0.10845577429890556, Q0_train: 306.14388037130357\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 22.745868728344703\n",
      "f_vars[i]: -2.2106, F_vars[i]: 0.0988, Q0_vars[i]: 278.8981\n",
      "f_train: -2.2105895630190404, F_train: 0.09880356523113057, Q0_train: 278.89807665761845\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 56.52157602011857\n",
      "f_vars[i]: -2.2217, F_vars[i]: 0.0978, Q0_vars[i]: 276.1261\n",
      "f_train: -2.2216675557854404, F_train: 0.09782153962426204, Q0_train: 276.1260607658491\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=1 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xf61f9c2b\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [5e+02, 2e+03]\n",
      "Presolve removed 66 rows and 101 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 227 rows, 163 columns, 603 nonzeros\n",
      "Presolved model has 40 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 123 continuous, 40 integer (40 binary)\n",
      "\n",
      "Root relaxation: objective 2.496975e+07, 84 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.4970e+07    0   24          - 2.4970e+07      -     -    0s\n",
      "H    0     0                    1.983770e+07 2.4970e+07  25.9%     -    0s\n",
      "     0     2 2.4970e+07    0   22 1.9838e+07 2.4970e+07  25.9%     -    0s\n",
      "H    9     8                    2.443276e+07 2.4967e+07  2.19%   2.1    0s\n",
      "H   70    66                    2.489709e+07 2.4964e+07  0.27%   7.6    0s\n",
      "H   78    66                    2.494617e+07 2.4964e+07  0.07%   7.5    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 4\n",
      "\n",
      "Explored 93 nodes (712 simplex iterations) in 0.03 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 4: 2.49462e+07 2.48971e+07 2.44328e+07 1.98377e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.494616838194e+07, best bound 2.496341860077e+07, gap 0.0691%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 3.84097433658485, Left1: 4.30268559726801\n",
      "f_vars[i]: -1.5118, F_vars[i]: 0.1807, Q0_vars[i]: 509.9915\n",
      "f_train: -1.511803666159872, F_train: 0.1806716437356777, Q0_train: 509.9914545247062\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.18817445432648583, Left1: 5.47222075265347\n",
      "f_vars[i]: -1.5304, F_vars[i]: 0.1779, Q0_vars[i]: 502.2559\n",
      "f_train: -1.5304270854170083, F_train: 0.17793120668640686, Q0_train: 502.2558771651748\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 10.672825485723024\n",
      "f_vars[i]: -1.3327, F_vars[i]: 0.2087, Q0_vars[i]: 589.1592\n",
      "f_train: -1.3326706879145056, F_train: 0.2087179452506995, Q0_train: 589.1592409461895\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.477859909031569, Left1: 1.39699497511333\n",
      "f_vars[i]: -1.3450, F_vars[i]: 0.2067, Q0_vars[i]: 583.4526\n",
      "f_train: -1.344955652880255, F_train: 0.20669628447003904, Q0_train: 583.4525915751738\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 11.687306927434292, Left0: 3.053588768709578, Left1: 0.0\n",
      "f_vars[i]: -1.3210, F_vars[i]: 0.2107, Q0_vars[i]: 594.6266\n",
      "f_train: -1.3209827182923508, F_train: 0.21065484122663017, Q0_train: 594.6266201962121\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.118051709979543, Left1: 3.444716451027034\n",
      "f_vars[i]: -1.2981, F_vars[i]: 0.2145, Q0_vars[i]: 605.4509\n",
      "f_train: -1.298073036171141, F_train: 0.2144895004374176, Q0_train: 605.4509166274614\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.912657804816698, Left1: 0.43081525038223845\n",
      "f_vars[i]: -1.3383, F_vars[i]: 0.2078, Q0_vars[i]: 586.5432\n",
      "f_train: -1.3382913988932408, F_train: 0.20779117780713233, Q0_train: 586.5432052098763\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.174349840270679, Left1: 11.249126627086298\n",
      "f_vars[i]: -1.4265, F_vars[i]: 0.1936, Q0_vars[i]: 546.5900\n",
      "f_train: -1.4265475505879295, F_train: 0.1936371858798023, Q0_train: 546.5899796726662\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.010222822091175254, Left1: 9.786737602076528\n",
      "f_vars[i]: -1.3506, F_vars[i]: 0.2058, Q0_vars[i]: 580.8403\n",
      "f_train: -1.3506089902534228, F_train: 0.20577082718116332, Q0_train: 580.840254082165\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 0.806330278365067\n",
      "f_vars[i]: -1.5018, F_vars[i]: 0.1822, Q0_vars[i]: 514.1732\n",
      "f_train: -1.5018277645846605, F_train: 0.18215307742106224, Q0_train: 514.1731761516843\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 7.552962579032851, Left0: 5.949803558840513, Left1: 0.0\n",
      "f_vars[i]: -1.3820, F_vars[i]: 0.2007, Q0_vars[i]: 566.4969\n",
      "f_train: -1.3819906427479052, F_train: 0.20068948407888906, Q0_train: 566.4968767480925\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 6.401172858184509, Left0: 2.49189990000175, Left1: 0.0\n",
      "f_vars[i]: -1.4979, F_vars[i]: 0.1827, Q0_vars[i]: 515.8113\n",
      "f_train: -1.4979370567231975, F_train: 0.18273340607313768, Q0_train: 515.8113006921756\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.690744688425399, Left1: 3.354412452252973\n",
      "f_vars[i]: -1.3051, F_vars[i]: 0.2133, Q0_vars[i]: 602.1110\n",
      "f_train: -1.3051098444168228, F_train: 0.21330629460416678, Q0_train: 602.1110186145529\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.1732735539931127, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.4125, F_vars[i]: 0.1958, Q0_vars[i]: 552.8172\n",
      "f_train: -1.4124794721879903, F_train: 0.19584327304197754, Q0_train: 552.8172191961636\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.12837792387631453, Left1: 2.02239896222477\n",
      "f_vars[i]: -1.4256, F_vars[i]: 0.1938, Q0_vars[i]: 546.9875\n",
      "f_train: -1.4256458005650412, F_train: 0.19377802567431837, Q0_train: 546.9875356486626\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=2 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xe6b8adb0\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [8e+02, 2e+03]\n",
      "Presolve removed 60 rows and 91 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 233 rows, 173 columns, 619 nonzeros\n",
      "Presolved model has 44 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 129 continuous, 44 integer (44 binary)\n",
      "\n",
      "Root relaxation: objective 2.498207e+07, 94 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.4982e+07    0   26          - 2.4982e+07      -     -    0s\n",
      "H    0     0                    2.151835e+07 2.4982e+07  16.1%     -    0s\n",
      "     0     2 2.4982e+07    0   24 2.1518e+07 2.4982e+07  16.1%     -    0s\n",
      "H   78    74                    2.492011e+07 2.4978e+07  0.23%   3.0    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 4\n",
      "\n",
      "Explored 93 nodes (372 simplex iterations) in 0.03 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 2.49201e+07 2.15184e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.492010781625e+07, best bound 2.497797421579e+07, gap 0.2322%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 1.4761130149195196, Left0: 8.978388726991852, Left1: 0.0\n",
      "f_vars[i]: -0.9933, F_vars[i]: 0.2703, Q0_vars[i]: 762.8704\n",
      "f_train: -0.9933161817275595, F_train: 0.2702575674971919, Q0_train: 762.8704045325757\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 7.354089155758402\n",
      "f_vars[i]: -1.0161, F_vars[i]: 0.2658, Q0_vars[i]: 750.2598\n",
      "f_train: -1.0160880576131082, F_train: 0.2657900995876906, Q0_train: 750.2598453429873\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 8.917712732190626, Left1: 6.12115003931126\n",
      "f_vars[i]: -0.7717, F_vars[i]: 0.3161, Q0_vars[i]: 892.3274\n",
      "f_train: -0.7716627270597145, F_train: 0.3161195348148382, Q0_train: 892.3274180189275\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 2.1150548445386903, Left0: 16.694834204691723, Left1: 0.0\n",
      "f_vars[i]: -0.7869, F_vars[i]: 0.3128, Q0_vars[i]: 883.0251\n",
      "f_train: -0.7869494880568706, F_train: 0.3128240484965983, Q0_train: 883.0250735776258\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.879255108934899, Left0: 9.522943925160595, Left1: 0.0\n",
      "f_vars[i]: -0.7575, F_vars[i]: 0.3192, Q0_vars[i]: 900.9991\n",
      "f_train: -0.7574893993033531, F_train: 0.3191915927995239, Q0_train: 900.9990794241131\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.21697727737409878, Left0: 17.639798744261, Left1: 0.0\n",
      "f_vars[i]: -0.7288, F_vars[i]: 0.3255, Q0_vars[i]: 918.6873\n",
      "f_train: -0.7288009300490641, F_train: 0.32545791019739856, Q0_train: 918.6873467037918\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 14.512648208629345, Left1: 0.8868056303670073\n",
      "f_vars[i]: -0.7789, F_vars[i]: 0.3146, Q0_vars[i]: 887.9312\n",
      "f_train: -0.7788763148047915, F_train: 0.3145621164633247, Q0_train: 887.9312104349979\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 11.30503895805009, Left1: 10.473558427822809\n",
      "f_vars[i]: -0.8873, F_vars[i]: 0.2917, Q0_vars[i]: 823.2927\n",
      "f_train: -0.8873209005614278, F_train: 0.2916630087605372, Q0_train: 823.2926816476696\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.690214414558362, Left1: 2.57066278415914\n",
      "f_vars[i]: -0.7933, F_vars[i]: 0.3115, Q0_vars[i]: 879.1887\n",
      "f_train: -0.7932793705294758, F_train: 0.31146495906746974, Q0_train: 879.1886995874469\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 4.1599751330738854\n",
      "f_vars[i]: -0.9812, F_vars[i]: 0.2726, Q0_vars[i]: 769.6125\n",
      "f_train: -0.9812387596338137, F_train: 0.27264605583327084, Q0_train: 769.6125175473568\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.303450596604307, Left0: 14.125892850620216, Left1: 0.0\n",
      "f_vars[i]: -0.8324, F_vars[i]: 0.3031, Q0_vars[i]: 855.7029\n",
      "f_train: -0.8323671511126756, F_train: 0.3031447812897548, Q0_train: 855.7028914161945\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 8.709682201592386, Left0: 6.173281586205685, Left1: 0.0\n",
      "f_vars[i]: -0.9762, F_vars[i]: 0.2736, Q0_vars[i]: 772.4385\n",
      "f_train: -0.9761962078909499, F_train: 0.27364719082146965, Q0_train: 772.4384745057938\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 22.36937885047104, Left1: 5.842907600725994\n",
      "f_vars[i]: -0.7376, F_vars[i]: 0.3235, Q0_vars[i]: 913.2258\n",
      "f_train: -0.7376278896864656, F_train: 0.32352307660797713, Q0_train: 913.2257890618196\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 2.496341801264407\n",
      "f_vars[i]: -0.8699, F_vars[i]: 0.2953, Q0_vars[i]: 833.5083\n",
      "f_train: -0.8698666889263253, F_train: 0.29528204202047625, Q0_train: 833.508319243295\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.626762590570479, Left1: 0.007604889118283609\n",
      "f_vars[i]: -0.8875, F_vars[i]: 0.2916, Q0_vars[i]: 823.1857\n",
      "f_train: -0.8875042803110857, F_train: 0.29162512474059965, Q0_train: 823.1857444104159\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=3 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x0ae5025e\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 2e+03]\n",
      "Presolve removed 56 rows and 72 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 237 rows, 192 columns, 635 nonzeros\n",
      "Presolved model has 59 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 133 continuous, 59 integer (59 binary)\n",
      "\n",
      "Root relaxation: objective 2.498207e+07, 101 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.4982e+07    0   26          - 2.4982e+07      -     -    0s\n",
      "H    0     0                    2.318616e+07 2.4982e+07  7.75%     -    0s\n",
      "     0     2 2.4982e+07    0   23 2.3186e+07 2.4982e+07  7.75%     -    0s\n",
      "H   40    38                    2.318616e+07 2.4978e+07  7.73%   3.4    0s\n",
      "H   45    46                    2.488862e+07 2.4978e+07  0.36%   3.3    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 6\n",
      "\n",
      "Explored 55 nodes (280 simplex iterations) in 0.03 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 3: 2.48886e+07 2.31862e+07 2.31862e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.488862455369e+07, best bound 2.497826944397e+07, gap 0.3602%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 1.4761125007164537, Left0: 38.85619723650186, Left1: 0.0\n",
      "f_vars[i]: -0.5281, F_vars[i]: 0.3710, Q0_vars[i]: 1047.1047\n",
      "f_train: -0.5281368042408274, F_train: 0.3709515536011657, Q0_train: 1047.1046726957948\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 31.285217722572725, Left1: 7.354089416479155\n",
      "f_vars[i]: -0.5503, F_vars[i]: 0.3658, Q0_vars[i]: 1032.5560\n",
      "f_train: -0.5502885149979666, F_train: 0.3657974738953474, Q0_train: 1032.5559778837182\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 6.121149948623497\n",
      "f_vars[i]: -0.3381, F_vars[i]: 0.4163, Q0_vars[i]: 1175.0407\n",
      "f_train: -0.33808517032530516, F_train: 0.41627468694056663, Q0_train: 1175.0406908636187\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 2.115055277489091, Left0: 11.388610932407932, Left1: 0.0\n",
      "f_vars[i]: -0.3504, F_vars[i]: 0.4133, Q0_vars[i]: 1166.6267\n",
      "f_train: -0.3503650272944667, F_train: 0.41329390571429203, Q0_train: 1166.6266812173028\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.879254585053104, Left0: 0.3250829266605173, Left1: 0.0\n",
      "f_vars[i]: -0.3231, F_vars[i]: 0.4199, Q0_vars[i]: 1185.3018\n",
      "f_train: -0.32314353524815087, F_train: 0.41990983583974967, Q0_train: 1185.3018189309564\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.21697672108075494, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -0.3018, F_vars[i]: 0.4251, Q0_vars[i]: 1199.9785\n",
      "f_train: -0.3018338621824803, F_train: 0.42510924165369135, Q0_train: 1199.9784581582815\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.135071285758446, Left1: 0.8868053879048148\n",
      "f_vars[i]: -0.3418, F_vars[i]: 0.4154, Q0_vars[i]: 1172.5116\n",
      "f_train: -0.3417736324113272, F_train: 0.4153787049837246, Q0_train: 1172.5115549574534\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 19.31495673391646, Left1: 10.473556520844113\n",
      "f_vars[i]: -0.4421, F_vars[i]: 0.3912, Q0_vars[i]: 1104.3766\n",
      "f_train: -0.44209903257891714, F_train: 0.3912409256209422, Q0_train: 1104.37656181912\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 2.570662756265847\n",
      "f_vars[i]: -0.3622, F_vars[i]: 0.4104, Q0_vars[i]: 1158.5249\n",
      "f_train: -0.3622138993886881, F_train: 0.41042374917142527, Q0_train: 1158.5249377464143\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 30.10722938543131, Left1: 4.159974101597072\n",
      "f_vars[i]: -0.5152, F_vars[i]: 0.3740, Q0_vars[i]: 1055.6335\n",
      "f_train: -0.515209910071831, F_train: 0.37397299737634465, Q0_train: 1055.6334626808045\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.303450648993021, Left0: 13.815278899448634, Left1: 0.0\n",
      "f_vars[i]: -0.3932, F_vars[i]: 0.4029, Q0_vars[i]: 1137.3883\n",
      "f_train: -0.3932473763916857, F_train: 0.4029358059813248, Q0_train: 1137.388322392958\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 8.709680380767395, Left0: 33.60212955428538, Left1: 0.0\n",
      "f_vars[i]: -0.5131, F_vars[i]: 0.3745, Q0_vars[i]: 1057.0350\n",
      "f_train: -0.5130897103108631, F_train: 0.3744695050784609, Q0_train: 1057.0349813693456\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.467424447746359, Left1: 5.842907979584652\n",
      "f_vars[i]: -0.3082, F_vars[i]: 0.4235, Q0_vars[i]: 1195.5573\n",
      "f_train: -0.3082458081208419, F_train: 0.42354297485420883, Q0_train: 1195.557273589825\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.5487528773417125, Left1: 2.4963408004809935\n",
      "f_vars[i]: -0.4276, F_vars[i]: 0.3947, Q0_vars[i]: 1114.1495\n",
      "f_train: -0.42758516038544037, F_train: 0.3947031201564218, Q0_train: 1114.1494824085842\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 23.419294034069253, Left1: 0.0076035548222535\n",
      "f_vars[i]: -0.4297, F_vars[i]: 0.3942, Q0_vars[i]: 1112.7114\n",
      "f_train: -0.42971810557866985, F_train: 0.3941936473617411, Q0_train: 1112.7113664639476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=4 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x034fc82b\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 1e+03]\n",
      "Presolve removed 56 rows and 72 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 237 rows, 192 columns, 635 nonzeros\n",
      "Presolved model has 59 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 133 continuous, 59 integer (59 binary)\n",
      "\n",
      "Root relaxation: objective 2.499585e+07, 101 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.4996e+07    0   26          - 2.4996e+07      -     -    0s\n",
      "H    0     0                    2.412823e+07 2.4996e+07  3.60%     -    0s\n",
      "     0     2 2.4996e+07    0   23 2.4128e+07 2.4996e+07  3.60%     -    0s\n",
      "H   45    43                    2.487306e+07 2.4993e+07  0.48%   7.2    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 7\n",
      "\n",
      "Explored 55 nodes (450 simplex iterations) in 0.03 seconds (0.03 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 2.48731e+07 2.41282e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.487306063323e+07, best bound 2.499342562857e+07, gap 0.4839%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 46.17846131890985, Left1: 3.5831722201314733\n",
      "f_vars[i]: -0.1354, F_vars[i]: 0.4662, Q0_vars[i]: 1315.9508\n",
      "f_train: -0.13543030435433234, F_train: 0.46619407869157187, Q0_train: 1315.9508120187095\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 44.0067226524402, Left1: 1.503968985369056\n",
      "f_vars[i]: -0.1645, F_vars[i]: 0.4590, Q0_vars[i]: 1295.5274\n",
      "f_train: -0.16453500720192316, F_train: 0.4589587946189149, Q0_train: 1295.5273909891644\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 8.012343387844243, Left1: 4.695972773454059\n",
      "f_vars[i]: 0.0783, F_vars[i]: 0.5196, Q0_vars[i]: 1466.6228\n",
      "f_train: 0.07832696059131061, F_train: 0.5195717349374459, Q0_train: 1466.6227602286845\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.591316957642675, Left0: 16.764889743104117, Left1: 0.0\n",
      "f_vars[i]: 0.0658, F_vars[i]: 0.5165, Q0_vars[i]: 1457.8191\n",
      "f_train: 0.06583536489725983, F_train: 0.5164528990100254, Q0_train: 1457.8190562375032\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 0.9354141000890195\n",
      "f_vars[i]: 0.0996, F_vars[i]: 0.5249, Q0_vars[i]: 1481.5921\n",
      "f_train: 0.09958156803665386, F_train: 0.5248748394836984, Q0_train: 1481.5921153810439\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.43564653714634005, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 0.1183, F_vars[i]: 0.5295, Q0_vars[i]: 1494.7644\n",
      "f_train: 0.11830307392271866, F_train: 0.5295413224278375, Q0_train: 1494.7644448899177\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 2.952571835949584, Left0: 17.257065330532246, Left1: 0.0\n",
      "f_vars[i]: 0.0782, F_vars[i]: 0.5195, Q0_vars[i]: 1466.5060\n",
      "f_train: 0.07816126611091634, F_train: 0.5195303746530496, Q0_train: 1466.5060103549208\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 21.913916527669656, Left1: 2.9539123810645833\n",
      "f_vars[i]: -0.0464, F_vars[i]: 0.4884, Q0_vars[i]: 1378.6452\n",
      "f_train: -0.04639057227197707, F_train: 0.4884044364108147, Q0_train: 1378.6451696087818\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 0.8581076172540634\n",
      "f_vars[i]: 0.0423, F_vars[i]: 0.5106, Q0_vars[i]: 1441.1978\n",
      "f_train: 0.04226461747932064, F_train: 0.5105645817924668, Q0_train: 1441.1977901639018\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 47.550356934316554, Left1: 1.5841401060674798\n",
      "f_vars[i]: -0.1168, F_vars[i]: 0.4708, Q0_vars[i]: 1329.0535\n",
      "f_train: -0.11678895920709298, F_train: 0.4708359016994779, Q0_train: 1329.0535326144861\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.7518734516529548, Left0: 6.255734321910631, Left1: 0.0\n",
      "f_vars[i]: 0.0113, F_vars[i]: 0.5028, Q0_vars[i]: 1419.3640\n",
      "f_train: 0.011318806408465498, F_train: 0.5028296713918124, Q0_train: 1419.3640473347332\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 2.847071258836195, Left0: 40.03747153913396, Left1: 0.0\n",
      "f_vars[i]: -0.1179, F_vars[i]: 0.4706, Q0_vars[i]: 1328.2586\n",
      "f_train: -0.11791934105961022, F_train: 0.47055427699075025, Q0_train: 1328.2585755760465\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1.7944748660779128, Left1: 7.213818778245468\n",
      "f_vars[i]: 0.1129, F_vars[i]: 0.5282, Q0_vars[i]: 1490.9898\n",
      "f_train: 0.11293631658057679, F_train: 0.5282041078123798, Q0_train: 1490.9898180993036\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.37977349292668805, Left0: 5.51461982249748, Left1: 0.0\n",
      "f_vars[i]: -0.0308, F_vars[i]: 0.4923, Q0_vars[i]: 1389.6522\n",
      "f_train: -0.030787149453837426, F_train: 0.4923038205279974, Q0_train: 1389.652168474536\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 45.218659304018956, Left1: 1.4818232456436817\n",
      "f_vars[i]: -0.0125, F_vars[i]: 0.4969, Q0_vars[i]: 1402.5813\n",
      "f_train: -0.012463642755193405, F_train: 0.49688412964665973, Q0_train: 1402.581250544641\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=5 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x8a0e7f85\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 2e+03]\n",
      "Presolve removed 56 rows and 73 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 237 rows, 191 columns, 635 nonzeros\n",
      "Presolved model has 58 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 133 continuous, 58 integer (58 binary)\n",
      "\n",
      "Root relaxation: objective 2.499585e+07, 102 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.4996e+07    0   25          - 2.4996e+07      -     -    0s\n",
      "H    0     0                    1.884295e+07 2.4996e+07  32.7%     -    0s\n",
      "     0     2 2.4996e+07    0   24 1.8843e+07 2.4996e+07  32.7%     -    0s\n",
      "H    9     8                    2.126482e+07 2.4995e+07  17.5%   1.9    0s\n",
      "H   70    70                    2.481314e+07 2.4993e+07  0.73%   3.0    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 6\n",
      "\n",
      "Explored 93 nodes (448 simplex iterations) in 0.03 seconds (0.03 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 3: 2.48131e+07 2.12648e+07 1.88429e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.481314057880e+07, best bound 2.499342553728e+07, gap 0.7266%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 3.583172084027069\n",
      "f_vars[i]: 0.1601, F_vars[i]: 0.5399, Q0_vars[i]: 1524.1288\n",
      "f_train: 0.1601174656019544, F_train: 0.5399440636732475, Q0_train: 1524.128815684886\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 1.5039693350369139\n",
      "f_vars[i]: 0.1294, F_vars[i]: 0.5323, Q0_vars[i]: 1502.5316\n",
      "f_train: 0.12935182581330507, F_train: 0.5322929421620353, Q0_train: 1502.5315882087411\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 11.410442166615583, Lost1: 0.0, Left0: 0.0, Left1: 16.106415027222425\n",
      "f_vars[i]: 0.4726, F_vars[i]: 0.6160, Q0_vars[i]: 1738.8307\n",
      "f_train: 0.47262656177849083, F_train: 0.6160052396331063, Q0_train: 1738.8307410040493\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 5.840705319443379, Lost1: 0.0, Left0: 0.0, Left1: 1.2493883360333549\n",
      "f_vars[i]: 0.4507, F_vars[i]: 0.6108, Q0_vars[i]: 1724.1210\n",
      "f_train: 0.45065149384299463, F_train: 0.610794121277843, Q0_train: 1724.1210401636165\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 23.895191747018945, Lost1: 0.0, Left0: 0.0, Left1: 24.830605844424046\n",
      "f_vars[i]: 0.4912, F_vars[i]: 0.6204, Q0_vars[i]: 1751.1960\n",
      "f_train: 0.49118615585438885, F_train: 0.6203858205142856, Q0_train: 1751.1960395592791\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 14.639807751697088, Lost1: 0.0, Left0: 0.0, Left1: 14.204161364759937\n",
      "f_vars[i]: 0.5333, F_vars[i]: 0.6303, Q0_vars[i]: 1779.0552\n",
      "f_train: 0.5333123307348631, F_train: 0.6302553286210734, Q0_train: 1779.0552248235028\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 8.027758377352257, Lost1: 0.0, Left0: 0.0, Left1: 5.0751866507933485\n",
      "f_vars[i]: 0.4612, F_vars[i]: 0.6133, Q0_vars[i]: 1731.1791\n",
      "f_train: 0.4611819691925434, F_train: 0.6132945346030926, Q0_train: 1731.1790897960345\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 2.9539121509258166\n",
      "f_vars[i]: 0.3120, F_vars[i]: 0.5774, Q0_vars[i]: 1629.8052\n",
      "f_train: 0.31203300241536525, F_train: 0.577381416236658, Q0_train: 1629.8052211937688\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 9.894838940863792, Lost1: 0.0, Left0: 0.0, Left1: 10.7529465574513\n",
      "f_vars[i]: 0.4450, F_vars[i]: 0.6095, Q0_vars[i]: 1720.3291\n",
      "f_train: 0.44500415543120964, F_train: 0.6094507727067071, Q0_train: 1720.329098730186\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.275317580879573, Lost1: 0.0, Left0: 0.0, Left1: 3.859457584881966\n",
      "f_vars[i]: 0.1758, F_vars[i]: 0.5438, Q0_vars[i]: 1535.1413\n",
      "f_train: 0.1758331224518539, F_train: 0.5438453737794507, Q0_train: 1535.141251142247\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 12.877843810662366, Lost1: 0.0, Left0: 0.0, Left1: 11.12597021578173\n",
      "f_vars[i]: 0.3886, F_vars[i]: 0.5960, Q0_vars[i]: 1682.2264\n",
      "f_train: 0.3886279239389876, F_train: 0.5959523563292208, Q0_train: 1682.2264011524426\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 4.483501356774132, Lost1: 0.0, Left0: 0.0, Left1: 1.6364303774726068\n",
      "f_vars[i]: 0.1841, F_vars[i]: 0.5459, Q0_vars[i]: 1540.9051\n",
      "f_train: 0.18406711771560236, F_train: 0.5458872947083284, Q0_train: 1540.905089910805\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 15.962283838406393, Lost1: 0.0, Left0: 0.0, Left1: 23.176102669818963\n",
      "f_vars[i]: 0.5203, F_vars[i]: 0.6272, Q0_vars[i]: 1770.4662\n",
      "f_train: 0.5202769771984723, F_train: 0.6272125305646266, Q0_train: 1770.4661569734171\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 13.349370715247915, Lost1: 0.0, Left0: 0.0, Left1: 12.969597116433306\n",
      "f_vars[i]: 0.3369, F_vars[i]: 0.5834, Q0_vars[i]: 1646.8805\n",
      "f_train: 0.33687228016783966, F_train: 0.5834305628971701, Q0_train: 1646.8804690867987\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.877373269349391, Lost1: 0.0, Left0: 0.0, Left1: 4.359196120568868\n",
      "f_vars[i]: 0.3054, F_vars[i]: 0.5758, Q0_vars[i]: 1625.2174\n",
      "f_train: 0.305375668332617, F_train: 0.5757561147797436, Q0_train: 1625.2173963590897\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=6 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x084c4759\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [7e+02, 2e+03]\n",
      "Presolve removed 60 rows and 98 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 233 rows, 166 columns, 619 nonzeros\n",
      "Presolved model has 37 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 129 continuous, 37 integer (37 binary)\n",
      "\n",
      "Root relaxation: objective 2.500898e+07, 92 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5009e+07    0   22          - 2.5009e+07      -     -    0s\n",
      "H    0     0                    1.217565e+07 2.5009e+07   105%     -    0s\n",
      "     0     2 2.5009e+07    0   22 1.2176e+07 2.5009e+07   105%     -    0s\n",
      "H   87    88                    2.479122e+07 2.5008e+07  0.87%   3.8    0s\n",
      "H  103    88                    2.479124e+07 2.5008e+07  0.87%   4.0    0s\n",
      "\n",
      "Explored 111 nodes (556 simplex iterations) in 0.03 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 3: 2.47912e+07 2.47912e+07 1.21757e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.479124213713e+07, best bound 2.500801058704e+07, gap 0.8744%\n",
      "Model status: 2\n",
      "Lost0: 14.209550341404247, Lost1: 0.0, Left0: 0.0, Left1: 13.976502675982488\n",
      "f_vars[i]: 0.5105, F_vars[i]: 0.6249, Q0_vars[i]: 1764.0071\n",
      "f_train: 0.5105027309782182, F_train: 0.6249243189489152, Q0_train: 1764.0071003886205\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 18.552382098278258, Lost1: 0.0, Left0: 0.0, Left1: 19.494132088651213\n",
      "f_vars[i]: 0.4684, F_vars[i]: 0.6150, Q0_vars[i]: 1736.0334\n",
      "f_train: 0.46843912249587216, F_train: 0.6150142511464151, Q0_train: 1736.0334251148759\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 0.7917310883983646\n",
      "f_vars[i]: 0.9508, F_vars[i]: 0.7213, Q0_vars[i]: 2036.0087\n",
      "f_train: 0.9508431531520944, F_train: 0.7212847113159743, Q0_train: 2036.008703106886\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 4.559129426617778, Lost1: 0.0, Left0: 0.0, Left1: 4.340228297832914\n",
      "f_vars[i]: 0.9195, F_vars[i]: 0.7149, Q0_vars[i]: 2018.0847\n",
      "f_train: 0.9194738824443975, F_train: 0.7149348934953854, Q0_train: 2018.084734744553\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 16.040639467917117, Lost1: 0.0, Left0: 0.0, Left1: 15.67719358083973\n",
      "f_vars[i]: 0.9756, F_vars[i]: 0.7262, Q0_vars[i]: 2049.9960\n",
      "f_train: 0.9756282229031874, F_train: 0.7262398994667462, Q0_train: 2049.9959761520845\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 9.442078073715493, Lost1: 0.0, Left0: 0.0, Left1: 11.110118095248277\n",
      "f_vars[i]: 1.0366, F_vars[i]: 0.7382, Q0_vars[i]: 2083.7363\n",
      "f_train: 1.0365970541196896, F_train: 0.7381928719006866, Q0_train: 2083.736266943911\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 3.5247463842399434, Lost1: 0.0, Left0: 0.0, Left1: 1.6346961173003187\n",
      "f_vars[i]: 0.9335, F_vars[i]: 0.7178, Q0_vars[i]: 2026.1260\n",
      "f_train: 0.9334941048992742, F_train: 0.7177836256411333, Q0_train: 2026.1260024306252\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.3567327174587236, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 0.7269, F_vars[i]: 0.6741, Q0_vars[i]: 1902.9077\n",
      "f_train: 0.7269327449789524, F_train: 0.674131824024341, Q0_train: 1902.9077411757426\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.6251819732757555, Lost1: 0.0, Left0: 0.0, Left1: 3.3286893227001544\n",
      "f_vars[i]: 0.9147, F_vars[i]: 0.7140, Q0_vars[i]: 2015.3138\n",
      "f_train: 0.9146622529412829, F_train: 0.7139532557051541, Q0_train: 2015.3138135634247\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 15.539495185183078, Lost1: 0.0, Left0: 0.0, Left1: 16.848933019178503\n",
      "f_vars[i]: 0.5314, F_vars[i]: 0.6298, Q0_vars[i]: 1777.7886\n",
      "f_train: 0.531387180489943, F_train: 0.6298065916392606, Q0_train: 1777.7885510869835\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 12.406255510956044, Lost1: 0.0, Left0: 0.0, Left1: 11.224522407440736\n",
      "f_vars[i]: 0.8340, F_vars[i]: 0.6972, Q0_vars[i]: 1968.0295\n",
      "f_train: 0.8340098118678609, F_train: 0.6972021152943355, Q0_train: 1968.0294789195264\n",
      "f_train, F_train, Q0_train 不相等\n",
      "Lost0: 21.488115021005477, Lost1: 0.0, Left0: 0.0, Left1: 22.70477424842636\n",
      "f_vars[i]: 0.5441, F_vars[i]: 0.6328, Q0_vars[i]: 1786.1207\n",
      "f_train: 0.5440686884528976, F_train: 0.6327583897337659, Q0_train: 1786.1207485063107\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 8.338548758978504, Lost1: 0.0, Left0: 0.0, Left1: 10.754312754509776\n",
      "f_vars[i]: 1.0177, F_vars[i]: 0.7345, Q0_vars[i]: 2073.3606\n",
      "f_train: 1.0176630519419727, F_train: 0.7345171404206458, Q0_train: 2073.3605842679353\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 12.540101058338905, Lost1: 0.0, Left0: 0.0, Left1: 13.808291997134688\n",
      "f_vars[i]: 0.7622, F_vars[i]: 0.6818, Q0_vars[i]: 1924.6129\n",
      "f_train: 0.7621538344154861, F_train: 0.681821171787346, Q0_train: 1924.6128719251942\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.390931458805582, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 0.7114, F_vars[i]: 0.6707, Q0_vars[i]: 1893.2563\n",
      "f_train: 0.7114100483646721, F_train: 0.6707126540572296, Q0_train: 1893.2562683228944\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=7 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xb99790d3\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [5e+02, 2e+03]\n",
      "Presolve removed 56 rows and 94 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 237 rows, 170 columns, 630 nonzeros\n",
      "Presolved model has 37 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 133 continuous, 37 integer (37 binary)\n",
      "Found heuristic solution: objective 2.467104e+07\n",
      "\n",
      "Root relaxation: objective 2.501874e+07, 68 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5019e+07    0   15 2.4671e+07 2.5019e+07  1.41%     -    0s\n",
      "     0     2 2.5019e+07    0   15 2.4671e+07 2.5019e+07  1.41%     -    0s\n",
      "H  563   316                    2.484030e+07 2.5010e+07  0.68%   2.5    0s\n",
      "\n",
      "Explored 673 nodes (1737 simplex iterations) in 0.04 seconds (0.05 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 2.48403e+07 2.4671e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.484029717978e+07, best bound 2.501001154234e+07, gap 0.6832%\n",
      "Model status: 2\n",
      "Lost0: 6.346067390935673, Lost1: 0.0, Left0: 0.0, Left1: 6.3460685550001035\n",
      "f_vars[i]: 0.9308, F_vars[i]: 0.7172, Q0_vars[i]: 2024.5867\n",
      "f_train: 0.9308035988180512, F_train: 0.7172382898279934, Q0_train: 2024.5866540370582\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 14.926061661680592, Lost1: 0.0, Left0: 0.0, Left1: 14.926062654771048\n",
      "f_vars[i]: 0.8652, F_vars[i]: 0.7037, Q0_vars[i]: 1986.5023\n",
      "f_train: 0.8652020713942257, F_train: 0.7037463690772685, Q0_train: 1986.5022920103263\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.252740273575935, Left1: 1.082469680113718e-06\n",
      "f_vars[i]: 1.5514, F_vars[i]: 0.8251, Q0_vars[i]: 2329.0973\n",
      "f_train: 1.5513974648232018, F_train: 0.8251154775347018, Q0_train: 2329.097327272909\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.8318415061978612, Lost1: 0.0, Left0: 0.0, Left1: 1.8318427214626498\n",
      "f_vars[i]: 1.5092, F_vars[i]: 0.8189, Q0_vars[i]: 2311.6636\n",
      "f_train: 1.5091779037906505, F_train: 0.8189393402751738, Q0_train: 2311.66361626434\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 16.151696518605945, Lost1: 0.0, Left0: 0.0, Left1: 16.151697629218358\n",
      "f_vars[i]: 1.5930, F_vars[i]: 0.8310, Q0_vars[i]: 2345.8298\n",
      "f_train: 1.5930385668519218, F_train: 0.8310431787604987, Q0_train: 2345.82976468049\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 15.951167880169692, Lost1: 0.0, Left0: 0.0, Left1: 15.951169041818432\n",
      "f_vars[i]: 1.6711, F_vars[i]: 0.8417, Q0_vars[i]: 2375.9569\n",
      "f_train: 1.6710528588616453, F_train: 0.8417161440943756, Q0_train: 2375.9569113769517\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.777225106268645, Lost1: 0.0, Left0: 0.0, Left1: 0.7772261413497524\n",
      "f_vars[i]: 1.5330, F_vars[i]: 0.8224, Q0_vars[i]: 2321.5395\n",
      "f_train: 1.5329533898447538, F_train: 0.8224380195226941, Q0_train: 2321.5395241902606\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.773283611624038, Left1: 1.2226390389002972e-06\n",
      "f_vars[i]: 1.2242, F_vars[i]: 0.7728, Q0_vars[i]: 2181.4147\n",
      "f_train: 1.224171480381699, F_train: 0.7727968192321117, Q0_train: 2181.414668861084\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.6319667381591216, Lost1: 0.0, Left0: 0.0, Left1: 2.63196791614983\n",
      "f_vars[i]: 1.4869, F_vars[i]: 0.8156, Q0_vars[i]: 2302.2928\n",
      "f_train: 1.4869470078526748, F_train: 0.8156195929099797, Q0_train: 2302.2927888759154\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.12061890827601474, Lost1: 0.0, Left0: 0.0, Left1: 0.12062015438249321\n",
      "f_vars[i]: 0.9664, F_vars[i]: 0.7244, Q0_vars[i]: 2044.8196\n",
      "f_train: 0.9664236967961424, F_train: 0.7244060911015673, Q0_train: 2044.8195877817802\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 12.825958446133711, Lost1: 0.0, Left0: 0.0, Left1: 12.825959633664585\n",
      "f_vars[i]: 1.3792, F_vars[i]: 0.7989, Q0_vars[i]: 2255.0141\n",
      "f_train: 1.3792496534436003, F_train: 0.7988704642684524, Q0_train: 2255.0141329601556\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 11.926625662514084, Lost1: 0.0, Left0: 0.0, Left1: 11.926626759423018\n",
      "f_vars[i]: 0.9790, F_vars[i]: 0.7269, Q0_vars[i]: 2051.8840\n",
      "f_train: 0.9789950952654571, F_train: 0.7269087757765526, Q0_train: 2051.884048873858\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 13.282390884403412, Lost1: 0.0, Left0: 0.0, Left1: 13.282392035608785\n",
      "f_vars[i]: 1.6472, F_vars[i]: 0.8385, Q0_vars[i]: 2366.8943\n",
      "f_train: 1.6471507483984658, F_train: 0.8385055940016627, Q0_train: 2366.8943209352415\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 6.580232262248728, Lost1: 0.0, Left0: 0.0, Left1: 6.580233534033029\n",
      "f_vars[i]: 1.2727, F_vars[i]: 0.7812, Q0_vars[i]: 2205.1589\n",
      "f_train: 1.2727232359091118, F_train: 0.7812085645741349, Q0_train: 2205.1589496644733\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 22.664556754048135, Left1: 1.2645363653973618e-06\n",
      "f_vars[i]: 1.2325, F_vars[i]: 0.7742, Q0_vars[i]: 2185.5137\n",
      "f_train: 1.2324605825651602, F_train: 0.7742489435875618, Q0_train: 2185.5136574841695\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 210 rows, 435 columns and 960 nonzeros\n",
      "Model fingerprint: 0x0ac6af69\n",
      "Model has 105 general constraints\n",
      "Variable types: 315 continuous, 120 integer (120 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Presolve removed 133 rows and 261 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 77 rows, 174 columns, 414 nonzeros\n",
      "Presolved model has 41 SOS constraint(s)\n",
      "Variable types: 77 continuous, 97 integer (97 binary)\n",
      "\n",
      "Root relaxation: objective 2.501874e+07, 58 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5019e+07    0   13          - 2.5019e+07      -     -    0s\n",
      "H    0     0                    2.501874e+07 2.5019e+07  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (63 simplex iterations) in 0.02 seconds (0.01 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.50187e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.501873669202e+07, best bound 2.501873669540e+07, gap 0.0000%\n",
      "\n",
      "model.status is optimal: True\n",
      "model.status is TIME_LIMIT: False\n",
      "\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 667 and 669 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 667 and 669 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 435 rows, 741 columns and 1830 nonzeros\n",
      "Model fingerprint: 0x2540d9ae\n",
      "Model has 240 general constraints\n",
      "Variable types: 621 continuous, 120 integer (120 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 5e+06]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e-03, 1e+00]\n",
      "  GenCon coe range [1e+00, 1e+00]\n",
      "Presolve removed 21 rows and 213 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 534 rows, 529 columns, 2037 nonzeros\n",
      "Presolved model has 195 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 333 continuous, 196 integer (196 binary)\n",
      "\n",
      "Root relaxation: objective 2.501874e+07, 240 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5019e+07    0   52          - 2.5019e+07      -     -    0s\n",
      "     0     2 2.5019e+07    0   52          - 2.5019e+07      -     -    0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27318/3679721425.py:107: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27318/2844647141.py:156: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 1686  1377              85    9201148.8131 2.5019e+07   172%   4.3    0s\n",
      "* 1955  1520              95    1.357059e+07 2.5019e+07  84.4%   4.2    0s\n",
      "H 2257  1659                    1.700037e+07 2.5019e+07  47.2%   4.0    0s\n",
      "H 2441  1528                    2.097895e+07 2.5019e+07  19.3%   3.9    0s\n",
      "H 2579  1445                    2.257560e+07 2.5019e+07  10.8%   3.9    0s\n",
      "H 2600  1445                    2.257561e+07 2.5019e+07  10.8%   3.9    0s\n",
      "* 5028  2321             114    2.491852e+07 2.5019e+07  0.40%   4.8    0s\n",
      "\n",
      "Explored 5269 nodes (25459 simplex iterations) in 0.47 seconds (0.72 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 7: 2.49185e+07 2.25756e+07 2.25756e+07 ... 9.20115e+06\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.491852052893e+07, best bound 2.501857421664e+07, gap 0.4015%\n",
      "\n",
      "model.status is optimal: True\n",
      "model.status is TIME_LIMIT: False\n",
      "\n",
      "f_vars[i]: 0.9411, F_vars[i]: 0.7193, Q0_vars[i]: 2030.4456\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.0009197119605083882\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.0009197119605083882\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.0009197119605083882\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.0009197119605083882\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.0009197119605083882\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.0009197119605083882\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0009197119605083882\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 8.028803949161178e-05\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.8944, F_vars[i]: 0.7098, Q0_vars[i]: 2003.5553\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.0009404505993689607\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.0009404505993689603\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.0009404505993689607\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.0009404505993689607\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.0009404505993689605\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.0009404505993689603\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0009404505993689607\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 5.95494006310395e-05\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.5791, F_vars[i]: 0.8291, Q0_vars[i]: 2340.2821\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.0009826543284901306\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.0009826543284901304\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.0009826543284901306\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.0009826543284901306\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.0009826543284901304\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.00098265432849013\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0009826543284901306\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 1.734567150987009e-05\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.5292, F_vars[i]: 0.8219, Q0_vars[i]: 2319.9763\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.0009697429666019495\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.0009697429666019495\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.0009697429666019495\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.0009697429666019497\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.0009697429666019495\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.0009697429666019491\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0009697429666019497\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 3.0257033398050955e-05\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.5999, F_vars[i]: 0.8320, Q0_vars[i]: 2348.5415\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.0009577902866748703\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.0009577902866748703\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.0009577902866748703\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.0009577902866748707\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.0009577902866748703\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.0009577902866748699\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0009577902866748707\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 4.220971332513022e-05\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.7061, F_vars[i]: 0.8463, Q0_vars[i]: 2388.9690\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.0010000000000000002\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.0010000000000000002\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.0010000000000000005\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.0009999999999999996\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0010000000000000005\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.5404, F_vars[i]: 0.8235, Q0_vars[i]: 2324.6140\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.000954745566244219\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.000954745566244219\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.000954745566244219\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.0009547455662442192\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.000954745566244219\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.0009547455662442185\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.0009547455662442192\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 4.525443375578145e-05\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.2809, F_vars[i]: 0.7826, Q0_vars[i]: 2209.1126\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.0009999999999999998\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.0010000000000000002\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.0009999999999999998\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0010000000000000002\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.5570, F_vars[i]: 0.8259, Q0_vars[i]: 2331.3802\n",
      "f_train, F_train, Q0_train 不相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.001034458749416364\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.001034458749416364\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.001034458749416364\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.001034458749416364\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.001034458749416364\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.001034458749416364\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.001034458749416364\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = -3.4458749416364056e-05\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.9574, F_vars[i]: 0.7226, Q0_vars[i]: 2039.7125\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.0008965072127320444\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.0008965072127320442\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.0008965072127320444\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.0008965072127320444\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.0008965072127320444\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.000896507212732044\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0008965072127320444\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.00010349278726795609\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.4267, F_vars[i]: 0.8064, Q0_vars[i]: 2276.2275\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.0009976564500303626\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.0009976564500303623\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.0009976564500303626\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.0009976564500303628\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.0009976564500303626\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.0009976564500303621\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0009976564500303628\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 2.3435499696378387e-06\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.9877, F_vars[i]: 0.7286, Q0_vars[i]: 2056.7534\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.0009207620775619867\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.0009207620775619867\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.0009207620775619867\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.0009207620775619869\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.0009207620775619867\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.0009207620775619864\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.0009207620775619869\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 7.923792243801356e-05\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.6724, F_vars[i]: 0.8419, Q0_vars[i]: 2376.4498\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.0009855141680147764\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.0009855141680147762\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.0009855141680147764\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.0009855141680147766\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.0009855141680147762\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.000985514168014776\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0009855141680147766\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 1.4485831985224137e-05\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.3344, F_vars[i]: 0.7916, Q0_vars[i]: 2234.4097\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.0010096365536973262\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.001009636553697326\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.0010096365536973262\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.0010096365536973264\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.0010096365536973262\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.0010096365536973258\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0010096365536973264\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = -9.636553697326169e-06\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.1905, F_vars[i]: 0.7668, Q0_vars[i]: 2164.5531\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.0008700780872236353\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.0008700780872236353\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.0008700780872236353\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.0008700780872236353\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.0008700780872236353\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.0008700780872236353\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0008700780872236353\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.00012992191277636482\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "all_Rs: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "Fold 1 Q_star: 2822.7531669043915\n",
      "baseline_profit: -491661.27713878395\n",
      "f_vars[i]: -2.4134194843756767, F_vars[i]: 0.08215510102609345\n",
      "f_vars[i]: -2.443214690801135, F_vars[i]: 0.07993616382709161\n",
      "f_vars[i]: -2.4424179072860186, F_vars[i]: 0.07999478398218571\n",
      "f_vars[i]: -2.435084217717537, F_vars[i]: 0.08053617656639302\n",
      "f_vars[i]: -2.424581975781561, F_vars[i]: 0.08131730256365317\n",
      "f_vars[i]: -2.423517275744948, F_vars[i]: 0.08139687622989676\n",
      "f_vars[i]: -2.429787404402949, F_vars[i]: 0.08092927860993623\n",
      "f_vars[i]: -2.4033202163924257, F_vars[i]: 0.08291986353823164\n",
      "f_vars[i]: -2.450964625509134, F_vars[i]: 0.07936803659731399\n",
      "f_vars[i]: -2.4419134791560673, F_vars[i]: 0.08003191554840437\n",
      "f_vars[i]: -2.439417900506598, F_vars[i]: 0.0802158497177904\n",
      "f_vars[i]: -2.416829876432843, F_vars[i]: 0.08189830441689859\n",
      "f_vars[i]: -2.4400045037342513, F_vars[i]: 0.08017258004458368\n",
      "f_vars[i]: -2.4202451938457314, F_vars[i]: 0.08164186980548735\n",
      "f_vars[i]: -2.439973632642838, F_vars[i]: 0.08017485666079505\n",
      "assigned_R: 1\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 210 rows, 435 columns and 960 nonzeros\n",
      "Model fingerprint: 0x3a86e8ae\n",
      "Model has 105 general constraints\n",
      "Variable types: 315 continuous, 120 integer (120 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Presolve removed 166 rows and 347 columns\n",
      "Presolve time: 0.02s\n",
      "Presolved: 44 rows, 88 columns, 236 nonzeros\n",
      "Presolved model has 12 SOS constraint(s)\n",
      "Variable types: 44 continuous, 44 integer (44 binary)\n",
      "\n",
      "Root relaxation: objective 5.736960e+06, 29 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5736959.90    0    7          - 5736959.90      -     -    0s\n",
      "H    0     0                    5713831.1439 5736959.90  0.40%     -    0s\n",
      "\n",
      "Explored 1 nodes (29 simplex iterations) in 0.03 seconds (0.01 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 5.71383e+06 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Warning: max constraint violation (2.8005e-06) exceeds tolerance\n",
      "Best objective 5.713831143947e+06, best bound 5.736959902414e+06, gap 0.4048%\n",
      "\n",
      "model.status is optimal: True\n",
      "model.status is TIME_LIMIT: False\n",
      "\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 1.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 1.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "tau: [-0.00060089 -0.00060089 -0.00060089 -0.00060089 -0.00060089 -0.00060089\n",
      " -0.00060089  0.00039911]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.0006727 -0.0006727 -0.0006727 -0.0006727 -0.0006727 -0.0006727\n",
      " -0.0006727  0.0003273]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.00062248 -0.00062248 -0.00062248 -0.00062248 -0.00062248 -0.00062248\n",
      " -0.00062248  0.00037752]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.00064252 -0.00064252 -0.00064252 -0.00064252 -0.00064252 -0.00064252\n",
      " -0.00064252  0.00035748]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.00055852 -0.00055852 -0.00055852 -0.00055852 -0.00055852 -0.00055852\n",
      " -0.00055852  0.00044148]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.00065384 -0.00065384 -0.00065384 -0.00065384 -0.00065384 -0.00065384\n",
      " -0.00065384  0.00034616]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.00065105 -0.00065105 -0.00065105 -0.00065105 -0.00065105 -0.00065105\n",
      " -0.00065105  0.00034895]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.00065986 -0.00065986 -0.00065986 -0.00065986 -0.00065986 -0.00065986\n",
      " -0.00065986  0.00034014]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.00069724 -0.00069724 -0.00069724 -0.00069724 -0.00069724 -0.00069724\n",
      " -0.00069724  0.00030276]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.00065843 -0.00065843 -0.00065843 -0.00065843 -0.00065843 -0.00065843\n",
      " -0.00065843  0.00034157]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.00060806 -0.00060806 -0.00060806 -0.00060806 -0.00060806 -0.00060806\n",
      " -0.00060806  0.00039194]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.00062722 -0.00062722 -0.00062722 -0.00062722 -0.00062722 -0.00062722\n",
      " -0.00062722  0.00037278]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.00066152 -0.00066152 -0.00066152 -0.00066152 -0.00066152 -0.00066152\n",
      " -0.00066152  0.00033848]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.00056641 -0.00056641 -0.00056641 -0.00056641 -0.00056641 -0.00056641\n",
      " -0.00056641  0.00043359]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.00065663 -0.00065663 -0.00065663 -0.00065663 -0.00065663 -0.00065663\n",
      " -0.00065663  0.00034337]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "===== Processing Fold 2 =====\n",
      "mean of sum: 2677.1537131644673\n",
      "std of sum: 131.02183264368077\n",
      "60.0 percentile of sum: 2710.3477149122873\n",
      "Fold 2 Q_star: 2710.3477149122873\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=0 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x2ea6aba2\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [3e+02, 3e+03]\n",
      "Presolve removed 54 rows and 84 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 239 rows, 180 columns, 635 nonzeros\n",
      "Presolved model has 45 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 135 continuous, 45 integer (45 binary)\n",
      "\n",
      "Root relaxation: objective 2.386824e+07, 104 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.3868e+07    0   25          - 2.3868e+07      -     -    0s\n",
      "H    0     0                    1.731693e+07 2.3868e+07  37.8%     -    0s\n",
      "     0     2 2.3868e+07    0   24 1.7317e+07 2.3868e+07  37.8%     -    0s\n",
      "H  116    98                    2.380783e+07 2.3849e+07  0.17%   2.9    0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27318/2788820283.py:74: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27318/3679721425.py:107: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27318/2062651650.py:90: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 6\n",
      "\n",
      "Explored 139 nodes (523 simplex iterations) in 0.03 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 2.38078e+07 1.73169e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.380782623302e+07, best bound 2.384866445636e+07, gap 0.1715%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 71.71421213212034\n",
      "f_vars[i]: -2.2582, F_vars[i]: 0.0946, Q0_vars[i]: 256.5196\n",
      "f_train: -2.2581994055824897, F_train: 0.09464454383052646, Q0_train: 256.5196230999832\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 3.7837465803586423, Left1: 31.415909298843417\n",
      "f_vars[i]: -2.2001, F_vars[i]: 0.0997, Q0_vars[i]: 270.3408\n",
      "f_train: -2.200072797012862, F_train: 0.0997439521144484, Q0_train: 270.34079268971584\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.111512378649283, Left1: 15.640155773282913\n",
      "f_vars[i]: -2.2466, F_vars[i]: 0.0956, Q0_vars[i]: 259.2161\n",
      "f_train: -2.2466428512039505, F_train: 0.09563943930322463, Q0_train: 259.2161357709873\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 42.7623085729756, Left0: 12.674728287192872, Left1: 0.0\n",
      "f_vars[i]: -2.1974, F_vars[i]: 0.1000, Q0_vars[i]: 271.0035\n",
      "f_train: -2.197352645166855, F_train: 0.09998847448567759, Q0_train: 271.0035333398218\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.2143164634680943, Left0: 7.3541849288209304, Left1: 0.0\n",
      "f_vars[i]: -2.2400, F_vars[i]: 0.0962, Q0_vars[i]: 260.7703\n",
      "f_train: -2.240030849869175, F_train: 0.09621285909775397, Q0_train: 260.77030280077537\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 6.115287128985983, Left0: 8.191855443616795, Left1: 0.0\n",
      "f_vars[i]: -2.1957, F_vars[i]: 0.1001, Q0_vars[i]: 271.4079\n",
      "f_train: -2.1956960660822666, F_train: 0.10013765014597477, Q0_train: 271.4078512498288\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 14.806900740373294, Left0: 7.479170628394304, Left1: 0.0\n",
      "f_vars[i]: -2.1799, F_vars[i]: 0.1016, Q0_vars[i]: 275.3002\n",
      "f_train: -2.1798595567780774, F_train: 0.10157374353993237, Q0_train: 275.3001636985424\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.8518311932246805, Left1: 3.0791080406315814\n",
      "f_vars[i]: -2.2514, F_vars[i]: 0.0952, Q0_vars[i]: 258.1070\n",
      "f_train: -2.251383121112305, F_train: 0.0952302264695033, Q0_train: 258.10702670219786\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 45.21997853759194\n",
      "f_vars[i]: -2.1146, F_vars[i]: 0.1077, Q0_vars[i]: 291.8723\n",
      "f_train: -2.114576343805447, F_train: 0.10768812934473894, Q0_train: 291.872275292692\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 19.83474965502768, Left0: 10.67952846776218, Left1: 0.0\n",
      "f_vars[i]: -2.1330, F_vars[i]: 0.1059, Q0_vars[i]: 287.1083\n",
      "f_train: -2.133001172932075, F_train: 0.105930416752182, Q0_train: 287.10826298398274\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 2.1342387119866544, Left0: 4.936099483871343, Left1: 0.0\n",
      "f_vars[i]: -2.2173, F_vars[i]: 0.0982, Q0_vars[i]: 266.1808\n",
      "f_train: -2.217283679714916, F_train: 0.09820911029118624, Q0_train: 266.1808376612854\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1.4401031005924763, Left1: 50.34663672781198\n",
      "f_vars[i]: -2.1489, F_vars[i]: 0.1044, Q0_vars[i]: 283.0646\n",
      "f_train: -2.148852638438422, F_train: 0.10443848840276392, Q0_train: 283.0646183913246\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 30.3798365056673\n",
      "f_vars[i]: -2.2577, F_vars[i]: 0.0947, Q0_vars[i]: 256.6408\n",
      "f_train: -2.257677740493202, F_train: 0.09468925317633077, Q0_train: 256.64080097321914\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 20.474055491699346, Left0: 9.103394036301697, Left1: 0.0\n",
      "f_vars[i]: -2.1385, F_vars[i]: 0.1054, Q0_vars[i]: 285.7000\n",
      "f_train: -2.138499307102247, F_train: 0.10541082015535456, Q0_train: 285.69997553509535\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 17.683164671576833, Left0: 9.915056473543698, Left1: 0.0\n",
      "f_vars[i]: -2.0573, F_vars[i]: 0.1133, Q0_vars[i]: 307.1301\n",
      "f_train: -2.0572924669030983, F_train: 0.11331758941298954, Q0_train: 307.130069524865\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=1 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xc670bed6\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [5e+02, 2e+03]\n",
      "Presolve removed 51 rows and 77 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 242 rows, 187 columns, 649 nonzeros\n",
      "Presolved model has 49 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 138 continuous, 49 integer (49 binary)\n",
      "\n",
      "Root relaxation: objective 2.406332e+07, 97 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.4063e+07    0   27          - 2.4063e+07      -     -    0s\n",
      "H    0     0                    1.913993e+07 2.4063e+07  25.7%     -    0s\n",
      "     0     2 2.4063e+07    0   24 1.9140e+07 2.4063e+07  25.7%     -    0s\n",
      "H    9     8                    2.335126e+07 2.4062e+07  3.04%   2.0    0s\n",
      "H   33    38                    2.335126e+07 2.4060e+07  3.04%   4.4    0s\n",
      "H   43    38                    2.335126e+07 2.4060e+07  3.04%   5.4    0s\n",
      "H   74    68                    2.399833e+07 2.4060e+07  0.26%   5.0    0s\n",
      "H   90    68                    2.402945e+07 2.4060e+07  0.13%   4.7    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 3\n",
      "\n",
      "Explored 93 nodes (525 simplex iterations) in 0.03 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 6: 2.40295e+07 2.39983e+07 2.33513e+07 ... 1.91399e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.402945086816e+07, best bound 2.405986791822e+07, gap 0.1266%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 8.11983549384945\n",
      "f_vars[i]: -1.4656, F_vars[i]: 0.1876, Q0_vars[i]: 508.4790\n",
      "f_train: -1.4656377462264563, F_train: 0.1876065607055648, Q0_train: 508.4790131108809\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.6822831063732337, Left0: 2.851827917408695, Left1: 0.0\n",
      "f_vars[i]: -1.4061, F_vars[i]: 0.1969, Q0_vars[i]: 533.5492\n",
      "f_train: -1.406059165814345, F_train: 0.19685637353464322, Q0_train: 533.54922217554\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 3.920662764585302, Left1: 1.7709542264259994\n",
      "f_vars[i]: -1.4498, F_vars[i]: 0.1900, Q0_vars[i]: 515.0351\n",
      "f_train: -1.449844647222714, F_train: 0.1900254761100145, Q0_train: 515.0351149498972\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.6431226119452731, Left0: 11.709712332114156, Left1: 0.0\n",
      "f_vars[i]: -1.4030, F_vars[i]: 0.1973, Q0_vars[i]: 534.8455\n",
      "f_train: -1.4030368366319583, F_train: 0.1973346535275725, Q0_train: 534.8455272614641\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.827968072919475, Left0: 7.035765696015675, Left1: 0.0\n",
      "f_vars[i]: -1.4466, F_vars[i]: 0.1905, Q0_vars[i]: 516.3883\n",
      "f_train: -1.4466042134499155, F_train: 0.19052473108956194, Q0_train: 516.3882695428722\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.236171012529212, Left1: 5.8975391582002885\n",
      "f_vars[i]: -1.3995, F_vars[i]: 0.1979, Q0_vars[i]: 536.3513\n",
      "f_train: -1.399533001195651, F_train: 0.19789022755670016, Q0_train: 536.3513260617748\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 6.411066979588879, Left1: 4.383006954696157\n",
      "f_vars[i]: -1.3797, F_vars[i]: 0.2011, Q0_vars[i]: 544.9452\n",
      "f_train: -1.379676279503789, F_train: 0.20106099571289948, Q0_train: 544.9452102884463\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.727352323423343, Left1: 2.942447602127004\n",
      "f_vars[i]: -1.4591, F_vars[i]: 0.1886, Q0_vars[i]: 511.1899\n",
      "f_train: -1.4590885549235055, F_train: 0.18860676794611575, Q0_train: 511.18992251974686\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.5822379016489094, Lost1: 2.0091701152346104, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.3122, F_vars[i]: 0.2121, Q0_vars[i]: 574.9136\n",
      "f_train: -1.3122053726908998, F_train: 0.21211803946830193, Q0_train: 574.9136435645866\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.20309270121970258, Left0: 9.009869373926856, Left1: 0.0\n",
      "f_vars[i]: -1.3370, F_vars[i]: 0.2080, Q0_vars[i]: 563.7687\n",
      "f_train: -1.3369866893493356, F_train: 0.20800603315212973, Q0_train: 563.7686766418443\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.333138959224925, Left1: 1.4630103645918098\n",
      "f_vars[i]: -1.4171, F_vars[i]: 0.1951, Q0_vars[i]: 528.8474\n",
      "f_train: -1.4170683284431471, F_train: 0.1951215886467057, Q0_train: 528.8473519186541\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 6.709455202000186\n",
      "f_vars[i]: -1.3504, F_vars[i]: 0.2058, Q0_vars[i]: 557.7869\n",
      "f_train: -1.3504364586938753, F_train: 0.2057990253062305, Q0_train: 557.7869179699178\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 8.505466228670912, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.4587, F_vars[i]: 0.1887, Q0_vars[i]: 511.3378\n",
      "f_train: -1.4587320082044182, F_train: 0.1886613378657697, Q0_train: 511.33782597678385\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.611652147988096, Left1: 2.1594540194884075\n",
      "f_vars[i]: -1.3387, F_vars[i]: 0.2077, Q0_vars[i]: 563.0056\n",
      "f_train: -1.338696649057528, F_train: 0.20772447585447595, Q0_train: 563.0055584635315\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 8.0937168464002, Left1: 0.5840462602900516\n",
      "f_vars[i]: -1.2539, F_vars[i]: 0.2220, Q0_vars[i]: 601.7735\n",
      "f_train: -1.2538860568889139, F_train: 0.2220281687379615, Q0_train: 601.7735397850937\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=2 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x2bf98625\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [8e+02, 2e+03]\n",
      "Presolve removed 54 rows and 82 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 239 rows, 182 columns, 641 nonzeros\n",
      "Presolved model has 47 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 135 continuous, 47 integer (47 binary)\n",
      "\n",
      "Root relaxation: objective 2.406471e+07, 93 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.4065e+07    0   26          - 2.4065e+07      -     -    0s\n",
      "H    0     0                    2.075402e+07 2.4065e+07  16.0%     -    0s\n",
      "     0     2 2.4065e+07    0   24 2.0754e+07 2.4065e+07  16.0%     -    0s\n",
      "H    9     8                    2.328335e+07 2.4063e+07  3.35%   1.9    0s\n",
      "H   72    52                    2.397942e+07 2.4061e+07  0.34%   2.7    0s\n",
      "H   78    52                    2.401788e+07 2.4061e+07  0.18%   2.8    0s\n",
      "H   80    52                    2.402889e+07 2.4061e+07  0.14%   2.8    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 3\n",
      "\n",
      "Explored 93 nodes (345 simplex iterations) in 0.03 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 5: 2.40289e+07 2.40179e+07 2.39794e+07 ... 2.0754e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.402889119126e+07, best bound 2.406145629557e+07, gap 0.1355%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 8.15964293771981\n",
      "f_vars[i]: -0.9404, F_vars[i]: 0.2808, Q0_vars[i]: 761.0985\n",
      "f_train: -0.9404367998845145, F_train: 0.28081211948697093, Q0_train: 761.0984863711878\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.2831075043018245, Left0: 4.48027833731696, Left1: 0.0\n",
      "f_vars[i]: -0.8716, F_vars[i]: 0.2949, Q0_vars[i]: 799.3381\n",
      "f_train: -0.8716029601972535, F_train: 0.2949208688316901, Q0_train: 799.3381029179177\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.45807280902022285, Left1: 0.6990556698592627\n",
      "f_vars[i]: -0.9225, F_vars[i]: 0.2845, Q0_vars[i]: 770.9699\n",
      "f_train: -0.9224731084948208, F_train: 0.2844542495029241, Q0_train: 770.9699251373399\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.9647407740219478, Left0: 12.13482985091812, Left1: 0.0\n",
      "f_vars[i]: -0.8681, F_vars[i]: 0.2956, Q0_vars[i]: 801.2980\n",
      "f_train: -0.8681279043214036, F_train: 0.29564399542849984, Q0_train: 801.2980274371732\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.086562591091706, Left0: 9.609873010420179, Left1: 0.0\n",
      "f_vars[i]: -0.9185, F_vars[i]: 0.2853, Q0_vars[i]: 773.1769\n",
      "f_train: -0.918475945516587, F_train: 0.28526853265217933, Q0_train: 773.1769156102155\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.44730218315317, Left1: 5.049646681434524\n",
      "f_vars[i]: -0.8642, F_vars[i]: 0.2965, Q0_vars[i]: 803.5116\n",
      "f_train: -0.864209122363609, F_train: 0.29646069017451965, Q0_train: 803.5115541758289\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.356450499048655, Left1: 5.5288097142279184\n",
      "f_vars[i]: -0.8415, F_vars[i]: 0.3012, Q0_vars[i]: 816.3925\n",
      "f_train: -0.8415273886202523, F_train: 0.3012131958470872, Q0_train: 816.3924970655801\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 8.884090312013996, Left1: 3.1022517909104863\n",
      "f_vars[i]: -0.9328, F_vars[i]: 0.2823, Q0_vars[i]: 765.2643\n",
      "f_train: -0.9328388928092923, F_train: 0.2823491198008108, Q0_train: 765.2642916596232\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 4.4782729605089875, Lost1: -8.943956686380261e-13, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -0.7636, F_vars[i]: 0.3179, Q0_vars[i]: 861.5163\n",
      "f_train: -0.7636150814527152, F_train: 0.3178619079868461, Q0_train: 861.5162959698081\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 13.142901515160355, Left1: 0.7308317860582747\n",
      "f_vars[i]: -0.7918, F_vars[i]: 0.3118, Q0_vars[i]: 845.0247\n",
      "f_train: -0.7918237030249193, F_train: 0.31177721921302487, Q0_train: 845.0246736557292\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 0.19666637942509624\n",
      "f_vars[i]: -0.8848, F_vars[i]: 0.2922, Q0_vars[i]: 791.9219\n",
      "f_train: -0.8847973823748356, F_train: 0.29218463072377476, Q0_train: 791.9219462146734\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.8195144235297851, Left1: 6.9967725079911816\n",
      "f_vars[i]: -0.8076, F_vars[i]: 0.3084, Q0_vars[i]: 835.8983\n",
      "f_train: -0.8075632337624636, F_train: 0.3084099987484246, Q0_train: 835.898335363894\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 7.725170624082693, Left0: 0.6686477708895294, Left1: 0.0\n",
      "f_vars[i]: -0.9329, F_vars[i]: 0.2823, Q0_vars[i]: 765.2227\n",
      "f_train: -0.9329146567106437, F_train: 0.28233376815901673, Q0_train: 765.2226833723665\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 6.285688326894659, Left1: 1.4670091471256228\n",
      "f_vars[i]: -0.7941, F_vars[i]: 0.3113, Q0_vars[i]: 843.7128\n",
      "f_train: -0.7940804890659379, F_train: 0.311293181515859, Q0_train: 843.7127631892843\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.98297585873817, Left1: 0.9151102134118219\n",
      "f_vars[i]: -0.6962, F_vars[i]: 0.3327, Q0_vars[i]: 901.6068\n",
      "f_train: -0.696207798250978, F_train: 0.3326535433621822, Q0_train: 901.6067711091661\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=3 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xe895776b\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 2e+03]\n",
      "Presolve removed 50 rows and 63 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 243 rows, 201 columns, 657 nonzeros\n",
      "Presolved model has 62 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 139 continuous, 62 integer (62 binary)\n",
      "\n",
      "Root relaxation: objective 2.406471e+07, 102 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.4065e+07    0   26          - 2.4065e+07      -     -    0s\n",
      "H    0     0                    2.236003e+07 2.4065e+07  7.62%     -    0s\n",
      "     0     2 2.4065e+07    0   24 2.2360e+07 2.4065e+07  7.62%     -    0s\n",
      "H   43    36                    2.401812e+07 2.4061e+07  0.18%   2.7    0s\n",
      "H   44    36                    2.401894e+07 2.4061e+07  0.18%   2.8    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 5\n",
      "\n",
      "Explored 47 nodes (237 simplex iterations) in 0.03 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 3: 2.40189e+07 2.40181e+07 2.236e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.401894302705e+07, best bound 2.406145629978e+07, gap 0.1770%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 8.15964146595411\n",
      "f_vars[i]: -0.5161, F_vars[i]: 0.3738, Q0_vars[i]: 1013.0579\n",
      "f_train: -0.5160594112320314, F_train: 0.3737741358499919, Q0_train: 1013.0578749943404\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.2831076883435344, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -0.4443, F_vars[i]: 0.3907, Q0_vars[i]: 1058.9982\n",
      "f_train: -0.44426951832148753, F_train: 0.39072410005935704, Q0_train: 1058.9981717570383\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.358550680537746, Left1: 0.6990535358386296\n",
      "f_vars[i]: -0.4802, F_vars[i]: 0.3822, Q0_vars[i]: 1035.8802\n",
      "f_train: -0.4802436666768395, F_train: 0.3821945885443758, Q0_train: 1035.8802297130908\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.9647403060655506, Left0: 8.021819641901857, Left1: 0.0\n",
      "f_vars[i]: -0.4396, F_vars[i]: 0.3918, Q0_vars[i]: 1061.9920\n",
      "f_train: -0.43963182430777614, F_train: 0.3918287016467748, Q0_train: 1061.9920261453844\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.086563219509344, Left0: 9.261401559943405, Left1: 0.0\n",
      "f_vars[i]: -0.4914, F_vars[i]: 0.3796, Q0_vars[i]: 1028.7648\n",
      "f_train: -0.4913766561939541, F_train: 0.37956931630282287, Q0_train: 1028.7648290921752\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.724493674941186, Left1: 5.049646506498675\n",
      "f_vars[i]: -0.4277, F_vars[i]: 0.3947, Q0_vars[i]: 1069.6879\n",
      "f_train: -0.4277315579797809, F_train: 0.39466814447056126, Q0_train: 1069.6879035144582\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 17.513291422557216, Left1: 5.528809453149506\n",
      "f_vars[i]: -0.3884, F_vars[i]: 0.4041, Q0_vars[i]: 1095.2625\n",
      "f_train: -0.38839368046144673, F_train: 0.40410404916202963, Q0_train: 1095.2624862331097\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.29988548464803, Left1: 3.102252562346621\n",
      "f_vars[i]: -0.5100, F_vars[i]: 0.3752, Q0_vars[i]: 1016.8875\n",
      "f_train: -0.5100274705409247, F_train: 0.37518708581758653, Q0_train: 1016.8874607102958\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.33945022105642686, Lost1: 4.13882253439624, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -0.3047, F_vars[i]: 0.4244, Q0_vars[i]: 1150.2787\n",
      "f_train: -0.3047257647584909, F_train: 0.424402639134902, Q0_train: 1150.2787231820257\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 3.857092367917851, Left1: 0.7308307558857905\n",
      "f_vars[i]: -0.3597, F_vars[i]: 0.4110, Q0_vars[i]: 1114.0689\n",
      "f_train: -0.35965613572453403, F_train: 0.41104280833371254, Q0_train: 1114.0689362984072\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 13.456123375480047, Left1: 0.1966667266424338\n",
      "f_vars[i]: -0.4293, F_vars[i]: 0.3943, Q0_vars[i]: 1068.6475\n",
      "f_train: -0.42933852528547556, F_train: 0.39428429667920256, Q0_train: 1068.647542530275\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 6.996772510504115\n",
      "f_vars[i]: -0.3640, F_vars[i]: 0.4100, Q0_vars[i]: 1111.2412\n",
      "f_train: -0.3639674221148623, F_train: 0.40999950533552737, Q0_train: 1111.2412224013146\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 7.725168515740506, Left0: 16.36935361594675, Left1: 0.0\n",
      "f_vars[i]: -0.4806, F_vars[i]: 0.3821, Q0_vars[i]: 1035.6204\n",
      "f_train: -0.4806496669905327, F_train: 0.3820987275712376, Q0_train: 1035.6204131435964\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.456314068999171, Left1: 1.4670097816861016\n",
      "f_vars[i]: -0.3450, F_vars[i]: 0.4146, Q0_vars[i]: 1123.6807\n",
      "f_train: -0.34502594382933727, F_train: 0.41458913415989834, Q0_train: 1123.6807123977442\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.8227749765704795, Left1: 0.9151098335701136\n",
      "f_vars[i]: -0.2361, F_vars[i]: 0.4412, Q0_vars[i]: 1195.9114\n",
      "f_train: -0.23613475972595976, F_train: 0.4412390971520605, Q0_train: 1195.911378696048\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=4 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x88ca66d8\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 1e+03]\n",
      "Presolve removed 48 rows and 59 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 245 rows, 205 columns, 660 nonzeros\n",
      "Presolved model has 64 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 141 continuous, 64 integer (64 binary)\n",
      "\n",
      "Root relaxation: objective 2.406696e+07, 111 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.4067e+07    0   27          - 2.4067e+07      -     -    0s\n",
      "H    0     0                    2.336418e+07 2.4067e+07  3.01%     -    0s\n",
      "     0     2 2.4067e+07    0   26 2.3364e+07 2.4067e+07  3.01%     -    0s\n",
      "H   76    61                    2.400026e+07 2.4064e+07  0.27%   7.7    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 7\n",
      "\n",
      "Explored 95 nodes (765 simplex iterations) in 0.03 seconds (0.03 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 2.40003e+07 2.33642e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.400026226004e+07, best bound 2.406400638041e+07, gap 0.2656%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 8.842379774400868, Left1: 4.041094337791492\n",
      "f_vars[i]: -0.1278, F_vars[i]: 0.4681, Q0_vars[i]: 1268.7161\n",
      "f_train: -0.1277701609443478, F_train: 0.46810084467232643, Q0_train: 1268.7160547061515\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.7358470262345236, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -0.0498, F_vars[i]: 0.4876, Q0_vars[i]: 1321.4543\n",
      "f_train: -0.04977444362703509, F_train: 0.4875589575391427, Q0_train: 1321.4543064512322\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.5066964442826247, Left0: 15.738186547933447, Left1: 0.0\n",
      "f_vars[i]: -0.0882, F_vars[i]: 0.4780, Q0_vars[i]: 1295.4613\n",
      "f_train: -0.08818237801113882, F_train: 0.47796868018448974, Q0_train: 1295.4613201376735\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 2.73427357577566, Left0: 6.138947768146545, Left1: 0.0\n",
      "f_vars[i]: -0.0447, F_vars[i]: 0.4888, Q0_vars[i]: 1324.8936\n",
      "f_train: -0.04469574170214918, F_train: 0.4888279243925103, Q0_train: 1324.8936478625567\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.274832303137373, Left0: 10.676014186933266, Left1: 0.0\n",
      "f_vars[i]: -0.1009, F_vars[i]: 0.4748, Q0_vars[i]: 1286.8746\n",
      "f_train: -0.10088332663951616, F_train: 0.474800536896157, Q0_train: 1286.8745502156262\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 6.766542805397949, Left1: 2.2055258115133256\n",
      "f_vars[i]: -0.0315, F_vars[i]: 0.4921, Q0_vars[i]: 1333.8604\n",
      "f_train: -0.03145755496728486, F_train: 0.49213625972936015, Q0_train: 1333.8603869829512\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 13.085870314491967, Left1: 5.711003209398768\n",
      "f_vars[i]: 0.0119, F_vars[i]: 0.5030, Q0_vars[i]: 1363.2381\n",
      "f_train: 0.011901481874613928, F_train: 0.5029753353485547, Q0_train: 1363.2380508191966\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.989634372395825, Left1: 3.1677729957327756\n",
      "f_vars[i]: -0.1213, F_vars[i]: 0.4697, Q0_vars[i]: 1273.0888\n",
      "f_train: -0.12129168049904959, F_train: 0.46971420033642547, Q0_train: 1273.088809543683\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 5.690361259151091, Lost1: 0.0, Left0: 0.0, Left1: 1.4542116908659908\n",
      "f_vars[i]: 0.1029, F_vars[i]: 0.5257, Q0_vars[i]: 1424.8343\n",
      "f_train: 0.10289737319359693, F_train: 0.5257016701385169, Q0_train: 1424.8343203855022\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 3.3471801874914036, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 0.0422, F_vars[i]: 0.5106, Q0_vars[i]: 1383.7699\n",
      "f_train: 0.0422090036737548, F_train: 0.5105506845399922, Q0_train: 1383.769881189872\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 14.982770888488709, Left1: 3.0682110041029773\n",
      "f_vars[i]: -0.0324, F_vars[i]: 0.4919, Q0_vars[i]: 1333.2103\n",
      "f_train: -0.03241725118906169, F_train: 0.49189639684861286, Q0_train: 1333.2102751722255\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.38407920590291, Lost1: 0.0, Left0: 0.0, Left1: 6.953177047620304\n",
      "f_vars[i]: 0.0380, F_vars[i]: 0.5095, Q0_vars[i]: 1380.9218\n",
      "f_train: 0.038004059495420295, F_train: 0.5094998715059171, Q0_train: 1380.9218124841666\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.1969896941768638, Left0: 18.457598959099414, Left1: 0.0\n",
      "f_vars[i]: -0.0882, F_vars[i]: 0.4780, Q0_vars[i]: 1295.4436\n",
      "f_train: -0.08820856735753457, F_train: 0.4779621455634217, Q0_train: 1295.443609042394\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 3.2018765307875583\n",
      "f_vars[i]: 0.0588, F_vars[i]: 0.5147, Q0_vars[i]: 1394.9883\n",
      "f_train: 0.058776037051560426, F_train: 0.5146897805357932, Q0_train: 1394.9882705638936\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 9.67686867547254, Lost1: 0.0, Left0: 0.0, Left1: 12.180226829944012\n",
      "f_vars[i]: 0.1773, F_vars[i]: 0.5442, Q0_vars[i]: 1475.0299\n",
      "f_train: 0.17734996082747, F_train: 0.5442216422813896, Q0_train: 1475.0298845631764\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=5 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x42389f81\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 2e+03]\n",
      "Presolve removed 51 rows and 66 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 242 rows, 198 columns, 648 nonzeros\n",
      "Presolved model has 60 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 138 continuous, 60 integer (60 binary)\n",
      "\n",
      "Root relaxation: objective 2.406696e+07, 108 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.4067e+07    0   26          - 2.4067e+07      -     -    0s\n",
      "H    0     0                    1.807402e+07 2.4067e+07  33.2%     -    0s\n",
      "     0     2 2.4067e+07    0   24 1.8074e+07 2.4067e+07  33.2%     -    0s\n",
      "H   91    78                    2.393919e+07 2.4064e+07  0.52%   3.3    0s\n",
      "H   96    78                    2.393919e+07 2.4064e+07  0.52%   3.3    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 6\n",
      "\n",
      "Explored 115 nodes (482 simplex iterations) in 0.03 seconds (0.03 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 3: 2.39392e+07 2.39392e+07 1.8074e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.393919044547e+07, best bound 2.406424578630e+07, gap 0.5224%\n",
      "Model status: 2\n",
      "Lost0: 6.9573895096255, Lost1: 0.0, Left0: 0.0, Left1: 10.998483790631553\n",
      "f_vars[i]: 0.2218, F_vars[i]: 0.5552, Q0_vars[i]: 1504.8752\n",
      "f_train: 0.22183841688854233, F_train: 0.5552332768199422, Q0_train: 1504.8752430721918\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 8.976966954114914, Lost1: 0.0, Left0: 0.0, Left1: 8.24111992331268\n",
      "f_vars[i]: 0.3298, F_vars[i]: 0.5817, Q0_vars[i]: 1576.6172\n",
      "f_train: 0.3297679622744343, F_train: 0.5817029174179746, Q0_train: 1576.6171729816185\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.5911733732345965, Lost1: 0.0, Left0: 0.0, Left1: 2.0844765669414755\n",
      "f_vars[i]: 0.2642, F_vars[i]: 0.5657, Q0_vars[i]: 1533.1414\n",
      "f_train: 0.26417466143571255, F_train: 0.5656622377260266, Q0_train: 1533.1413534329074\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.7987997002981047, Lost1: 0.0, Left0: 0.0, Left1: 0.06452633147000597\n",
      "f_vars[i]: 0.3361, F_vars[i]: 0.5832, Q0_vars[i]: 1580.7629\n",
      "f_train: 0.33605744861970965, F_train: 0.5832325133217247, Q0_train: 1580.7629097440865\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 3.2748324461048504, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 0.2577, F_vars[i]: 0.5641, Q0_vars[i]: 1528.8601\n",
      "f_train: 0.25774807426227486, F_train: 0.5640826382233329, Q0_train: 1528.8600895303048\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 3.9186304872824858, Lost1: 0.0, Left0: 0.0, Left1: 6.124156429765662\n",
      "f_vars[i]: 0.3487, F_vars[i]: 0.5863, Q0_vars[i]: 1589.0723\n",
      "f_train: 0.34868363408848735, F_train: 0.5862983272577813, Q0_train: 1589.072331540024\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 5.7110031163338135\n",
      "f_vars[i]: 0.3973, F_vars[i]: 0.5980, Q0_vars[i]: 1620.8653\n",
      "f_train: 0.39725745408497026, F_train: 0.5980285560086901, Q0_train: 1620.865330230448\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 4.5104091661664825, Lost1: 0.0, Left0: 0.0, Left1: 7.678182328319167\n",
      "f_vars[i]: 0.2322, F_vars[i]: 0.5578, Q0_vars[i]: 1511.7943\n",
      "f_train: 0.2321819513471648, F_train: 0.5577861240395325, Q0_train: 1511.7943467003286\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 14.459008516881113, Lost1: 0.0, Left0: 0.0, Left1: 10.222859031820027\n",
      "f_vars[i]: 0.5214, F_vars[i]: 0.6275, Q0_vars[i]: 1700.6888\n",
      "f_train: 0.5214208008742709, F_train: 0.62747993701396, Q0_train: 1700.6888134390924\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 6.519020246436177, Lost1: 0.0, Left0: 0.0, Left1: 3.1718400410479637\n",
      "f_vars[i]: 0.4560, F_vars[i]: 0.6121, Q0_vars[i]: 1658.9263\n",
      "f_train: 0.4560276817105864, F_train: 0.6120714098317885, Q0_train: 1658.9263470007302\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.825806702258433, Lost1: 0.0, Left0: 0.0, Left1: 5.8940176738560695\n",
      "f_vars[i]: 0.3329, F_vars[i]: 0.5825, Q0_vars[i]: 1578.6702\n",
      "f_train: 0.33288173379819463, F_train: 0.5824603814180879, Q0_train: 1578.6701638034538\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 9.976592853444505, Lost1: 0.0, Left0: 0.0, Left1: 14.545690852757776\n",
      "f_vars[i]: 0.4414, F_vars[i]: 0.6086, Q0_vars[i]: 1649.4910\n",
      "f_train: 0.4413898789911075, F_train: 0.6085901612103644, Q0_train: 1649.4909527546115\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 3.6543068736866546, Lost1: 0.0, Left0: 0.0, Left1: 2.4573172797431653\n",
      "f_vars[i]: 0.2565, F_vars[i]: 0.5638, Q0_vars[i]: 1528.0281\n",
      "f_train: 0.2564998532826275, F_train: 0.5637756843902098, Q0_train: 1528.028137910116\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 8.077316086339351, Lost1: 0.0, Left0: 0.0, Left1: 11.279192670158226\n",
      "f_vars[i]: 0.4666, F_vars[i]: 0.6146, Q0_vars[i]: 1665.7082\n",
      "f_train: 0.4665785506131148, F_train: 0.6145736261745351, Q0_train: 1665.7082233475096\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 15.34623279342232, Lost1: 0.0, Left0: 0.0, Left1: 17.849590764086276\n",
      "f_vars[i]: 0.6257, F_vars[i]: 0.6515, Q0_vars[i]: 1765.8253\n",
      "f_train: 0.6256940827256714, F_train: 0.6515124685325435, Q0_train: 1765.8253303240429\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=6 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xbfaf8b61\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [8e+02, 2e+03]\n",
      "Presolve removed 48 rows and 85 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 245 rows, 179 columns, 661 nonzeros\n",
      "Presolved model has 38 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 141 continuous, 38 integer (38 binary)\n",
      "\n",
      "Root relaxation: objective 2.408439e+07, 100 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.4084e+07    0   23          - 2.4084e+07      -     -    0s\n",
      "H    0     0                    1.165763e+07 2.4084e+07   107%     -    0s\n",
      "     0     2 2.4084e+07    0   23 1.1658e+07 2.4084e+07   107%     -    0s\n",
      "*  588   496              29    2.402751e+07 2.4084e+07  0.23%   4.3    0s\n",
      "*  899   496              34    2.402756e+07 2.4084e+07  0.23%   3.6    0s\n",
      "* 1008   496              30    2.402960e+07 2.4084e+07  0.22%   3.5    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 3\n",
      "\n",
      "Explored 1023 nodes (3749 simplex iterations) in 0.05 seconds (0.05 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 4: 2.40296e+07 2.40276e+07 2.40275e+07 1.16576e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.402960475539e+07, best bound 2.408350380557e+07, gap 0.2243%\n",
      "Model status: 2\n",
      "Lost0: 5.339018706273414, Lost1: 0.0, Left0: 0.0, Left1: 7.061540376743324\n",
      "f_vars[i]: 0.6145, F_vars[i]: 0.6490, Q0_vars[i]: 1758.8982\n",
      "f_train: 0.6144562204668236, F_train: 0.6489566548242149, Q0_train: 1758.898186479933\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 5.739564090153146, Lost1: 0.0, Left0: 0.0, Left1: 7.520573487460865\n",
      "f_vars[i]: 0.7620, F_vars[i]: 0.6818, Q0_vars[i]: 1847.8922\n",
      "f_train: 0.7620172617930039, F_train: 0.6817915428419604, Q0_train: 1847.8921501882303\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.5662747713113276, Left0: 6.917781459776279, Left1: 0.0\n",
      "f_vars[i]: 0.6767, F_vars[i]: 0.6630, Q0_vars[i]: 1796.9451\n",
      "f_train: 0.6766665610379308, F_train: 0.6629943027549278, Q0_train: 1796.9450934716835\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 3.984069395175993, Left1: 1.4382656001614578\n",
      "f_vars[i]: 0.7709, F_vars[i]: 0.6837, Q0_vars[i]: 1853.0911\n",
      "f_train: 0.7708730356793883, F_train: 0.683709718620117, Q0_train: 1853.091073525357\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.188776966772366, Lost1: 0.0, Left0: 0.0, Left1: 0.43064414137404583\n",
      "f_vars[i]: 0.6640, F_vars[i]: 0.6602, Q0_vars[i]: 1789.2603\n",
      "f_train: 0.6640025832558458, F_train: 0.6601589392751578, Q0_train: 1789.2602725433433\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.7010169271595714, Left0: 10.325111252703891, Left1: 0.0\n",
      "f_vars[i]: 0.7901, F_vars[i]: 0.6879, Q0_vars[i]: 1864.3293\n",
      "f_train: 0.7901154347632047, F_train: 0.6878561161274908, Q0_train: 1864.3292525345855\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 13.51021685523665, Left1: 2.542497092680833\n",
      "f_vars[i]: 0.8605, F_vars[i]: 0.7028, Q0_vars[i]: 1904.7375\n",
      "f_train: 0.8604993812820667, F_train: 0.7027649788460909, Q0_train: 1904.7374545358844\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.3854427748863145, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 0.6281, F_vars[i]: 0.6521, Q0_vars[i]: 1767.3166\n",
      "f_train: 0.6281183703045605, F_train: 0.6520626860436736, Q0_train: 1767.316611098039\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 3.612897116398017, Lost1: 0.0, Left0: 0.0, Left1: 3.2040499321413614\n",
      "f_vars[i]: 1.0309, F_vars[i]: 0.7371, Q0_vars[i]: 1997.7532\n",
      "f_train: 1.030865867488619, F_train: 0.737083727867439, Q0_train: 1997.7531975245436\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.254357611523119, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 0.9350, F_vars[i]: 0.7181, Q0_vars[i]: 1946.2676\n",
      "f_train: 0.934996078363715, F_train: 0.718087781296922, Q0_train: 1946.2675771445467\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 13.073014950685774, Left1: 1.755831511321503\n",
      "f_vars[i]: 0.7735, F_vars[i]: 0.6843, Q0_vars[i]: 1854.6565\n",
      "f_train: 0.7735451239122244, F_train: 0.6842872758160218, Q0_train: 1854.6564543515087\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 3.130278529741141, Left1: 0.3421921285339522\n",
      "f_vars[i]: 0.9181, F_vars[i]: 0.7146, Q0_vars[i]: 1936.9357\n",
      "f_train: 0.9180505697353407, F_train: 0.7146447293894647, Q0_train: 1936.9357092748455\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.04902772163109148, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 0.6688, F_vars[i]: 0.6612, Q0_vars[i]: 1792.1935\n",
      "f_train: 0.6688302717365704, F_train: 0.661241188015356, Q0_train: 1792.1935429433063\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.925108031939317, Left1: 1.096953886306892\n",
      "f_vars[i]: 0.9537, F_vars[i]: 0.7219, Q0_vars[i]: 1956.5016\n",
      "f_train: 0.9537250147816216, F_train: 0.7218636912024317, Q0_train: 1956.5016059286597\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 4.693774056801274, Lost1: 0.0, Left0: 0.0, Left1: 4.097436432802013\n",
      "f_vars[i]: 1.1730, F_vars[i]: 0.7637, Q0_vars[i]: 2069.8542\n",
      "f_train: 1.1729944792200158, F_train: 0.7636858553458411, Q0_train: 2069.854212947436\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=7 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x96b131be\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [5e+02, 2e+03]\n",
      "Presolve removed 47 rows and 82 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 246 rows, 182 columns, 657 nonzeros\n",
      "Presolved model has 40 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 142 continuous, 40 integer (40 binary)\n",
      "Found heuristic solution: objective 2.380724e+07\n",
      "\n",
      "Root relaxation: objective 2.409438e+07, 54 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.4094e+07    0   15 2.3807e+07 2.4094e+07  1.21%     -    0s\n",
      "     0     2 2.4094e+07    0   15 2.3807e+07 2.4094e+07  1.21%     -    0s\n",
      "H  632   263                    2.380793e+07 2.4083e+07  1.15%   1.9    0s\n",
      "H  644   263                    2.381789e+07 2.4083e+07  1.11%   1.9    0s\n",
      "H  662   263                    2.383285e+07 2.4083e+07  1.05%   1.9    0s\n",
      "H  869   401                    2.388094e+07 2.4083e+07  0.85%   2.0    0s\n",
      "H  882   401                    2.393120e+07 2.4083e+07  0.63%   1.9    0s\n",
      "\n",
      "Explored 994 nodes (1954 simplex iterations) in 0.06 seconds (0.06 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 6: 2.39312e+07 2.38809e+07 2.38329e+07 ... 2.38072e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.393119718590e+07, best bound 2.408280186383e+07, gap 0.6335%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 14.223057964493648, Left1: 0.0\n",
      "f_vars[i]: 1.0856, F_vars[i]: 0.7475, Q0_vars[i]: 2026.1029\n",
      "f_train: 1.0855537639461188, F_train: 0.7475435420927542, Q0_train: 2026.1029311085335\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 22.968931676447653, Left1: 0.0\n",
      "f_vars[i]: 1.3221, F_vars[i]: 0.7895, Q0_vars[i]: 2139.9034\n",
      "f_train: 1.3221005064707345, F_train: 0.7895309637840019, Q0_train: 2139.9034435444655\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 28.666564168282264, Left1: 1.0389784392828005e-06\n",
      "f_vars[i]: 1.1855, F_vars[i]: 0.7659, Q0_vars[i]: 2075.9564\n",
      "f_train: 1.1855112643211356, F_train: 0.7659372963966063, Q0_train: 2075.9564010546374\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 29.5528775832596, Left1: 0.0\n",
      "f_vars[i]: 1.3363, F_vars[i]: 0.7919, Q0_vars[i]: 2146.2770\n",
      "f_train: 1.3363104383923634, F_train: 0.7918825395892573, Q0_train: 2146.277031654682\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 14.637357085744384, Left1: 0.0\n",
      "f_vars[i]: 1.1650, F_vars[i]: 0.7622, Q0_vars[i]: 2065.9370\n",
      "f_train: 1.165002852318282, F_train: 0.7622405703528051, Q0_train: 2065.936988069164\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 38.693644119889655, Left1: 0.0\n",
      "f_vars[i]: 1.3673, F_vars[i]: 0.7969, Q0_vars[i]: 2159.9779\n",
      "f_train: 1.3672627920759073, F_train: 0.7969375564555897, Q0_train: 2159.9778850671896\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 46.66556448784911, Left1: 0.0\n",
      "f_vars[i]: 1.4803, F_vars[i]: 0.8146, Q0_vars[i]: 2207.8994\n",
      "f_train: 1.4803039716080777, F_train: 0.814618489432194, Q0_train: 2207.899361357846\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 14.831863955986819, Left1: 0.0\n",
      "f_vars[i]: 1.1074, F_vars[i]: 0.7516, Q0_vars[i]: 2037.2315\n",
      "f_train: 1.1074291212854712, F_train: 0.7516495095677324, Q0_train: 2037.231530671845\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 23.33570676646367, Left1: 0.0\n",
      "f_vars[i]: 1.7534, F_vars[i]: 0.8524, Q0_vars[i]: 2310.2634\n",
      "f_train: 1.7534415079156158, F_train: 0.8523863511315584, Q0_train: 2310.2633990118416\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 27.383915665082288, Left1: 0.0\n",
      "f_vars[i]: 1.5994, F_vars[i]: 0.8319, Q0_vars[i]: 2254.8364\n",
      "f_train: 1.5994121380985185, F_train: 0.8319362072882562, Q0_train: 2254.8363983765203\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 43.29463814736863, Left1: 0.0\n",
      "f_vars[i]: 1.3410, F_vars[i]: 0.7926, Q0_vars[i]: 2148.3552\n",
      "f_train: 1.3409692600505991, F_train: 0.7926492907132823, Q0_train: 2148.3551938115897\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 36.77489717423803, Left1: 0.0\n",
      "f_vars[i]: 1.5724, F_vars[i]: 0.8281, Q0_vars[i]: 2244.5126\n",
      "f_train: 1.5724118975776937, F_train: 0.8281271715536694, Q0_train: 2244.5125870772636\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 21.08681393609851, Left1: 0.0\n",
      "f_vars[i]: 1.1731, F_vars[i]: 0.7637, Q0_vars[i]: 2069.9017\n",
      "f_train: 1.173091525382942, F_train: 0.763703368796336, Q0_train: 2069.901680487965\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 37.5388223327592, Left1: 0.0\n",
      "f_vars[i]: 1.6297, F_vars[i]: 0.8361, Q0_vars[i]: 2266.1864\n",
      "f_train: 1.6296657522268188, F_train: 0.836123845037756, Q0_train: 2266.1863527817577\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 8.309923355933112, Left1: 0.0\n",
      "f_vars[i]: 1.9813, F_vars[i]: 0.8788, Q0_vars[i]: 2381.8944\n",
      "f_train: 1.9812566267373741, F_train: 0.878815055511873, Q0_train: 2381.89437753712\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 210 rows, 435 columns and 960 nonzeros\n",
      "Model fingerprint: 0xc1795776\n",
      "Model has 105 general constraints\n",
      "Variable types: 315 continuous, 120 integer (120 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Presolve removed 198 rows and 409 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 12 rows, 26 columns, 61 nonzeros\n",
      "Presolved model has 6 SOS constraint(s)\n",
      "Variable types: 12 continuous, 14 integer (14 binary)\n",
      "Found heuristic solution: objective 2.409410e+07\n",
      "\n",
      "Root relaxation: interrupted, 11 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0          -    0      2.4094e+07 2.4094e+07  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (11 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.40941e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.409410376379e+07, best bound 2.409438341721e+07, gap 0.0012%\n",
      "\n",
      "model.status is optimal: True\n",
      "model.status is TIME_LIMIT: False\n",
      "\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 1.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 667 and 669 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 667 and 669 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 435 rows, 741 columns and 1830 nonzeros\n",
      "Model fingerprint: 0x80c35100\n",
      "Model has 240 general constraints\n",
      "Variable types: 621 continuous, 120 integer (120 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 5e+06]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e-03, 1e+00]\n",
      "  GenCon coe range [1e+00, 1e+00]\n",
      "Presolve removed 20 rows and 207 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 535 rows, 535 columns, 2039 nonzeros\n",
      "Presolved model has 200 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 335 continuous, 200 integer (200 binary)\n",
      "\n",
      "Root relaxation: objective 2.409438e+07, 232 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.4094e+07    0   54          - 2.4094e+07      -     -    0s\n",
      "     0     2 2.4094e+07    0   54          - 2.4094e+07      -     -    0s\n",
      "* 1814  1430              91    7451386.9197 2.4094e+07   223%   4.0    0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27318/3679721425.py:107: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27318/2844647141.py:156: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H 2049  1519                    1.659413e+07 2.4094e+07  45.2%   3.9    0s\n",
      "H 2144  1510                    1.770077e+07 2.4094e+07  36.1%   3.8    0s\n",
      "* 2161  1510             110    1.770078e+07 2.4094e+07  36.1%   3.8    0s\n",
      "H 2384  1637                    1.907681e+07 2.4094e+07  26.3%   3.7    0s\n",
      "* 2401  1637             128    1.907681e+07 2.4094e+07  26.3%   3.7    0s\n",
      "H 2687  1824                    1.916442e+07 2.4094e+07  25.7%   3.6    0s\n",
      "H 3027  1773                    1.916442e+07 2.4094e+07  25.7%   3.7    0s\n",
      "H 4041  2272                    1.916443e+07 2.4094e+07  25.7%   4.5    0s\n",
      "H 5096  2381                    1.965131e+07 2.4094e+07  22.6%   4.6    0s\n",
      "H 5112  2297                    1.965132e+07 2.4094e+07  22.6%   4.6    0s\n",
      "H 5122  2351                    1.985216e+07 2.4094e+07  21.4%   4.6    0s\n",
      "H 5216  2248                    1.985216e+07 2.4094e+07  21.4%   4.6    0s\n",
      "H 5261  2157                    2.031213e+07 2.4094e+07  18.6%   4.6    0s\n",
      "* 5285  2085             125    2.031214e+07 2.4094e+07  18.6%   4.6    0s\n",
      "* 5646  1652             129    2.396814e+07 2.4094e+07  0.53%   4.6    0s\n",
      "\n",
      "Explored 5942 nodes (27059 simplex iterations) in 0.62 seconds (0.73 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 10: 2.39681e+07 2.03121e+07 2.03121e+07 ... 1.91644e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.396813849300e+07, best bound 2.409437932900e+07, gap 0.5267%\n",
      "\n",
      "model.status is optimal: True\n",
      "model.status is TIME_LIMIT: False\n",
      "\n",
      "f_vars[i]: 1.0579, F_vars[i]: 0.7423, Q0_vars[i]: 2011.8487\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.2727, F_vars[i]: 0.7812, Q0_vars[i]: 2117.3445\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0009999999999999998\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.1299, F_vars[i]: 0.7558, Q0_vars[i]: 2048.5118\n",
      "f_train, F_train, Q0_train 不相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0009999999999999998\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.2845, F_vars[i]: 0.7832, Q0_vars[i]: 2122.7883\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.0009999999999999998\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.1281, F_vars[i]: 0.7555, Q0_vars[i]: 2047.6234\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0009999999999999998\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.3040, F_vars[i]: 0.7865, Q0_vars[i]: 2131.7159\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0009999999999999998\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.3894, F_vars[i]: 0.8005, Q0_vars[i]: 2169.6303\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0009999999999999998\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.0798, F_vars[i]: 0.7465, Q0_vars[i]: 2023.1698\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0009999999999999998\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.6348, F_vars[i]: 0.8368, Q0_vars[i]: 2268.1037\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.5230, F_vars[i]: 0.8210, Q0_vars[i]: 2225.1547\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0009999999999999998\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.2583, F_vars[i]: 0.7787, Q0_vars[i]: 2110.6184\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0009999999999999998\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.4852, F_vars[i]: 0.8154, Q0_vars[i]: 2209.8929\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.0009999999999999998\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.1070, F_vars[i]: 0.7516, Q0_vars[i]: 2037.0272\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.5318, F_vars[i]: 0.8223, Q0_vars[i]: 2228.6398\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0009999999999999998\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.8436, F_vars[i]: 0.8634, Q0_vars[i]: 2340.0545\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0009999999999999998\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "all_Rs: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "Fold 2 Q_star: 2710.3477149122873\n",
      "baseline_profit: -420569.42922120873\n",
      "f_vars[i]: -1.656084845572893, F_vars[i]: 0.16028826019496203\n",
      "f_vars[i]: -1.6452160881390792, F_vars[i]: 0.16175655761036195\n",
      "f_vars[i]: -1.661342169255906, F_vars[i]: 0.159581908956637\n",
      "f_vars[i]: -1.6890369589370848, F_vars[i]: 0.15590253138036406\n",
      "f_vars[i]: -1.6108261278622975, F_vars[i]: 0.1664739481775156\n",
      "f_vars[i]: -1.6753124817967524, F_vars[i]: 0.15771717172665542\n",
      "f_vars[i]: -1.6162126852583563, F_vars[i]: 0.16572784967801865\n",
      "f_vars[i]: -1.6486584540855416, F_vars[i]: 0.16129034578068732\n",
      "f_vars[i]: -1.677071361309344, F_vars[i]: 0.15748365847891427\n",
      "f_vars[i]: -1.6350875533888911, F_vars[i]: 0.16313460884981584\n",
      "f_vars[i]: -1.6688368035071008, F_vars[i]: 0.1585793247572311\n",
      "f_vars[i]: -1.6200749853689533, F_vars[i]: 0.165194529051452\n",
      "f_vars[i]: -1.644796797365653, F_vars[i]: 0.1618134178855274\n",
      "f_vars[i]: -1.6022820514440697, F_vars[i]: 0.16766290831972164\n",
      "f_vars[i]: -1.6436552277865455, F_vars[i]: 0.16196830856077396\n",
      "assigned_R: 6\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 210 rows, 435 columns and 960 nonzeros\n",
      "Model fingerprint: 0xde7d7fb7\n",
      "Model has 105 general constraints\n",
      "Variable types: 315 continuous, 120 integer (120 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Presolve removed 199 rows and 413 columns\n",
      "Presolve time: 0.02s\n",
      "Presolved: 11 rows, 22 columns, 59 nonzeros\n",
      "Presolved model has 3 SOS constraint(s)\n",
      "Variable types: 11 continuous, 11 integer (11 binary)\n",
      "\n",
      "Root relaxation: objective 5.972127e+06, 6 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5972126.91    0    1          - 5972126.91      -     -    0s\n",
      "H    0     0                    5953567.6826 5972126.91  0.31%     -    0s\n",
      "\n",
      "Explored 1 nodes (6 simplex iterations) in 0.02 seconds (0.01 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 5.95357e+06 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 5.953567682588e+06, best bound 5.972126910374e+06, gap 0.3117%\n",
      "\n",
      "model.status is optimal: True\n",
      "model.status is TIME_LIMIT: False\n",
      "\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 1.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "tau: [-0.001 -0.001 -0.001 -0.001 -0.001 -0.001 -0.001  0.   ]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.001 -0.001 -0.001 -0.001 -0.001 -0.001 -0.001  0.   ]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.001 -0.001 -0.001 -0.001 -0.001 -0.001 -0.001  0.   ]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.001 -0.001 -0.001 -0.001 -0.001 -0.001 -0.001  0.   ]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.001 -0.001 -0.001 -0.001 -0.001 -0.001 -0.001  0.   ]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.001 -0.001 -0.001 -0.001 -0.001 -0.001 -0.001  0.   ]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.001 -0.001 -0.001 -0.001 -0.001 -0.001 -0.001  0.   ]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.001 -0.001 -0.001 -0.001 -0.001 -0.001 -0.001  0.   ]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.001 -0.001 -0.001 -0.001 -0.001 -0.001 -0.001  0.   ]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.001 -0.001 -0.001 -0.001 -0.001 -0.001 -0.001  0.   ]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.001 -0.001 -0.001 -0.001 -0.001 -0.001 -0.001  0.   ]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.001 -0.001 -0.001 -0.001 -0.001 -0.001 -0.001  0.   ]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.001 -0.001 -0.001 -0.001 -0.001 -0.001 -0.001  0.   ]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.001 -0.001 -0.001 -0.001 -0.001 -0.001 -0.001  0.   ]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.001 -0.001 -0.001 -0.001 -0.001 -0.001 -0.001  0.   ]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "===== Processing Fold 3 =====\n",
      "mean of sum: 2825.330566520376\n",
      "std of sum: 120.7948325515889\n",
      "60.0 percentile of sum: 2855.933587421095\n",
      "Fold 3 Q_star: 2855.933587421095\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=0 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27318/2788820283.py:74: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27318/3679721425.py:107: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27318/2062651650.py:90: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27318/3639980328.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sd_Y = np.sqrt(var_Y)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27318/3639980328.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sd_Y = np.sqrt(var_Y)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27318/3639980328.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sd_Y = np.sqrt(var_Y)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27318/3639980328.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sd_Y = np.sqrt(var_Y)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27318/3639980328.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sd_Y = np.sqrt(var_Y)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27318/3639980328.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sd_Y = np.sqrt(var_Y)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27318/3639980328.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sd_Y = np.sqrt(var_Y)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27318/3639980328.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sd_Y = np.sqrt(var_Y)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27318/3639980328.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sd_Y = np.sqrt(var_Y)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27318/3639980328.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sd_Y = np.sqrt(var_Y)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27318/3639980328.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sd_Y = np.sqrt(var_Y)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27318/3639980328.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sd_Y = np.sqrt(var_Y)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27318/3639980328.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sd_Y = np.sqrt(var_Y)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27318/3639980328.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sd_Y = np.sqrt(var_Y)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27318/3639980328.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sd_Y = np.sqrt(var_Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x1b182bdd\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [3e+02, 3e+03]\n",
      "Presolve removed 62 rows and 97 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 231 rows, 167 columns, 612 nonzeros\n",
      "Presolved model has 41 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 126 continuous, 41 integer (41 binary)\n",
      "\n",
      "Root relaxation: objective 2.526280e+07, 96 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5263e+07    0   24          - 2.5263e+07      -     -    0s\n",
      "H    0     0                    1.837560e+07 2.5263e+07  37.5%     -    0s\n",
      "     0     2 2.5263e+07    0   23 1.8376e+07 2.5263e+07  37.5%     -    0s\n",
      "H   47    42                    2.521248e+07 2.5247e+07  0.14%   3.1    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 6\n",
      "\n",
      "Explored 55 nodes (258 simplex iterations) in 0.14 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 2.52125e+07 1.83756e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.521248454498e+07, best bound 2.524682906173e+07, gap 0.1362%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.060053955115222, Left1: 36.98013902744424\n",
      "f_vars[i]: -2.1879, F_vars[i]: 0.1008, Q0_vars[i]: 287.9967\n",
      "f_train: -2.1879092390044566, F_train: 0.10084150994459902, Q0_train: 287.9966552570387\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.787564348438821, Left1: 17.65883923238772\n",
      "f_vars[i]: -2.1935, F_vars[i]: 0.1003, Q0_vars[i]: 286.5397\n",
      "f_train: -2.1935481437537554, F_train: 0.10033136594714728, Q0_train: 286.53971788029503\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 23.950137039603305, Left0: 9.872340148496908, Left1: 0.0\n",
      "f_vars[i]: -2.1776, F_vars[i]: 0.1018, Q0_vars[i]: 290.6826\n",
      "f_train: -2.177579615911198, F_train: 0.10178199208539633, Q0_train: 290.68260979131145\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 6.515511457487264, Left1: 1.1929361545426218\n",
      "f_vars[i]: -2.1832, F_vars[i]: 0.1013, Q0_vars[i]: 289.2062\n",
      "f_train: -2.1832470233647334, F_train: 0.1012650320831993, Q0_train: 289.2062063576837\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 18.52839886017364, Left0: 12.738649214080937, Left1: 0.0\n",
      "f_vars[i]: -2.2092, F_vars[i]: 0.0989, Q0_vars[i]: 282.5334\n",
      "f_train: -2.2091865780015167, F_train: 0.09892855934560975, Q0_train: 282.53339539030793\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 27.037615877432472, Left0: 3.2888684533512365, Left1: 0.0\n",
      "f_vars[i]: -2.1595, F_vars[i]: 0.1034, Q0_vars[i]: 295.4302\n",
      "f_train: -2.159526722746368, F_train: 0.10344433666010124, Q0_train: 295.43015549607844\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 10.330585983085257, Left0: 10.800221369836542, Left1: 0.0\n",
      "f_vars[i]: -2.2228, F_vars[i]: 0.0977, Q0_vars[i]: 279.0955\n",
      "f_train: -2.2227643965641244, F_train: 0.09772478339015149, Q0_train: 279.0954912073848\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.807816447849632, Left1: 5.711934684325456\n",
      "f_vars[i]: -2.2109, F_vars[i]: 0.0988, Q0_vars[i]: 282.0923\n",
      "f_train: -2.2109205403091607, F_train: 0.09877409845606026, Q0_train: 282.09226534790065\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 18.63196479163662\n",
      "f_vars[i]: -2.1590, F_vars[i]: 0.1035, Q0_vars[i]: 295.5617\n",
      "f_train: -2.1590302726288435, F_train: 0.10349038829938181, Q0_train: 295.56167591945564\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 9.624653434906463\n",
      "f_vars[i]: -2.1742, F_vars[i]: 0.1021, Q0_vars[i]: 291.5728\n",
      "f_train: -2.174174930531133, F_train: 0.10209367894210351, Q0_train: 291.5727667541392\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1.0722277325696912, Left1: 35.7239876263352\n",
      "f_vars[i]: -2.1785, F_vars[i]: 0.1017, Q0_vars[i]: 290.4313\n",
      "f_train: -2.178542605490295, F_train: 0.10169398700437146, Q0_train: 290.4312731245488\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 15.167211664113097, Left1: 24.802197373810486\n",
      "f_vars[i]: -2.2421, F_vars[i]: 0.0960, Q0_vars[i]: 274.2531\n",
      "f_train: -2.2421444031504554, F_train: 0.09602922985746526, Q0_train: 274.2531029241157\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.8846871863621004, Lost1: 8.3115379161577, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -2.1656, F_vars[i]: 0.1029, Q0_vars[i]: 293.8189\n",
      "f_train: -2.165624568849525, F_train: 0.10288016641264773, Q0_train: 293.8189227373523\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1.0085534925042383, Left1: 24.290380924166584\n",
      "f_vars[i]: -2.1832, F_vars[i]: 0.1013, Q0_vars[i]: 289.2175\n",
      "f_train: -2.183203589269767, F_train: 0.10126898510711792, Q0_train: 289.2174959314647\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 6.286913241360878, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -2.1500, F_vars[i]: 0.1043, Q0_vars[i]: 297.9715\n",
      "f_train: -2.1499682164789147, F_train: 0.10433419320622409, Q0_train: 297.9715266941372\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=1 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xe813c422\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [5e+02, 2e+03]\n",
      "Presolve removed 55 rows and 83 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 238 rows, 181 columns, 635 nonzeros\n",
      "Presolved model has 47 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 134 continuous, 47 integer (47 binary)\n",
      "\n",
      "Root relaxation: objective 2.539216e+07, 96 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5392e+07    0   27          - 2.5392e+07      -     -    0s\n",
      "H    0     0                    2.021465e+07 2.5392e+07  25.6%     -    0s\n",
      "     0     2 2.5392e+07    0   25 2.0215e+07 2.5392e+07  25.6%     -    0s\n",
      "H    9     8                    2.496805e+07 2.5390e+07  1.69%   2.1    0s\n",
      "H   69    48                    2.535098e+07 2.5388e+07  0.15%   5.0    0s\n",
      "H   78    48                    2.536595e+07 2.5388e+07  0.09%   5.1    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 7\n",
      "\n",
      "Explored 93 nodes (565 simplex iterations) in 0.03 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 4: 2.53659e+07 2.5351e+07 2.49681e+07 2.02146e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.536594985536e+07, best bound 2.538816320492e+07, gap 0.0876%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1.6509233943988875, Left1: 1.332026656104972\n",
      "f_vars[i]: -1.3996, F_vars[i]: 0.1979, Q0_vars[i]: 565.1312\n",
      "f_train: -1.399599587920067, F_train: 0.19787965847949895, Q0_train: 565.1311629190166\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 3.5445045182577815, Left1: 4.179683795646724\n",
      "f_vars[i]: -1.4043, F_vars[i]: 0.1971, Q0_vars[i]: 563.0129\n",
      "f_train: -1.4042791069146987, F_train: 0.19713795973656073, Q0_train: 563.0129205673113\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.4943610967070526, Left0: 7.606436190936964, Left1: 0.0\n",
      "f_vars[i]: -1.3865, F_vars[i]: 0.2000, Q0_vars[i]: 571.0767\n",
      "f_train: -1.3865350410105632, F_train: 0.19996149399796434, Q0_train: 571.076746899688\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.628808079755117, Left1: 3.807774725673653\n",
      "f_vars[i]: -1.3891, F_vars[i]: 0.1996, Q0_vars[i]: 569.9247\n",
      "f_train: -1.3890585587017643, F_train: 0.19955809512199388, Q0_train: 569.9246665006762\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.724340443913093, Left1: 6.702636206277816\n",
      "f_vars[i]: -1.4309, F_vars[i]: 0.1930, Q0_vars[i]: 551.0900\n",
      "f_train: -1.4308699410270553, F_train: 0.19296317353322526, Q0_train: 551.0900084289033\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.845951177695952, Left0: 3.3958092645252993, Left1: 0.0\n",
      "f_vars[i]: -1.3448, F_vars[i]: 0.2067, Q0_vars[i]: 590.3644\n",
      "f_train: -1.3448412741277287, F_train: 0.20671504011846142, Q0_train: 590.3644260994131\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.936046206859146, Left1: 0.8369143515958513\n",
      "f_vars[i]: -1.4455, F_vars[i]: 0.1907, Q0_vars[i]: 544.6094\n",
      "f_train: -1.4455070180978027, F_train: 0.19069400356661037, Q0_train: 544.6094097056807\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 8.565508626546034, Left0: 4.967379547359613, Left1: 0.0\n",
      "f_vars[i]: -1.4310, F_vars[i]: 0.1929, Q0_vars[i]: 551.0451\n",
      "f_train: -1.430970975329678, F_train: 0.19294744011231044, Q0_train: 551.0450748236676\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 7.223925849980674\n",
      "f_vars[i]: -1.3453, F_vars[i]: 0.2066, Q0_vars[i]: 590.1578\n",
      "f_train: -1.345282438128392, F_train: 0.20664270567113363, Q0_train: 590.1578437217621\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.2752086234244143, Lost1: 2.146915156855357, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.3636, F_vars[i]: 0.2036, Q0_vars[i]: 581.6073\n",
      "f_train: -1.363643764037441, F_train: 0.20364873333268418, Q0_train: 581.6072575605747\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.40495027274846507, Lost1: 0.19055914424596293, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.3798, F_vars[i]: 0.2010, Q0_vars[i]: 574.1485\n",
      "f_train: -1.379825222153968, F_train: 0.2010370713053023, Q0_train: 574.1485242575825\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 10.690312559156837, Left1: 4.161348693613036\n",
      "f_vars[i]: -1.4911, F_vars[i]: 0.1838, Q0_vars[i]: 524.7875\n",
      "f_train: -1.4911217770574734, F_train: 0.18375341452047714, Q0_train: 524.7875483323418\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.6376606011212971, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.3442, F_vars[i]: 0.2068, Q0_vars[i]: 590.6777\n",
      "f_train: -1.3441723976322357, F_train: 0.20682474663361253, Q0_train: 590.6777406207921\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 3.1138721000688747\n",
      "f_vars[i]: -1.3803, F_vars[i]: 0.2010, Q0_vars[i]: 573.9210\n",
      "f_train: -1.3803212737835224, F_train: 0.20095740672951254, Q0_train: 573.9210075198569\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1.0910902037981007, Left1: 6.785318866206467\n",
      "f_vars[i]: -1.3265, F_vars[i]: 0.2097, Q0_vars[i]: 599.0050\n",
      "f_train: -1.3264902597002663, F_train: 0.20974051003249516, Q0_train: 599.0049672446341\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=2 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xc51f1d70\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [8e+02, 2e+03]\n",
      "Presolve removed 55 rows and 83 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 238 rows, 181 columns, 635 nonzeros\n",
      "Presolved model has 47 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 134 continuous, 47 integer (47 binary)\n",
      "\n",
      "Root relaxation: objective 2.539194e+07, 97 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5392e+07    0   27          - 2.5392e+07      -     -    0s\n",
      "H    0     0                    2.192218e+07 2.5392e+07  15.8%     -    0s\n",
      "     0     2 2.5392e+07    0   25 2.1922e+07 2.5392e+07  15.8%     -    0s\n",
      "H    9     8                    2.491100e+07 2.5390e+07  1.92%   1.7    0s\n",
      "H   29    26                    2.491100e+07 2.5389e+07  1.92%   6.4    0s\n",
      "H   30    26                    2.491100e+07 2.5389e+07  1.92%   6.3    0s\n",
      "H  144   100                    2.521362e+07 2.5388e+07  0.69%   6.4    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 7\n",
      "\n",
      "Explored 173 nodes (1294 simplex iterations) in 0.03 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 5: 2.52136e+07 2.4911e+07 2.4911e+07 ... 2.19222e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.521361505711e+07, best bound 2.538784799529e+07, gap 0.6910%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.986591430260887, Left1: 1.6894784176856774\n",
      "f_vars[i]: -0.8477, F_vars[i]: 0.2999, Q0_vars[i]: 856.5442\n",
      "f_train: -0.8476911853568848, F_train: 0.2999174082545109, Q0_train: 856.5441996863425\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 18.204039374747026, Left1: 4.821362397714438\n",
      "f_vars[i]: -0.8382, F_vars[i]: 0.3019, Q0_vars[i]: 862.2272\n",
      "f_train: -0.8382319449278091, F_train: 0.30190728744437584, Q0_train: 862.2271624995881\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.8577910975809573, Left0: 7.592916616946465, Left1: 0.0\n",
      "f_vars[i]: -0.8538, F_vars[i]: 0.2986, Q0_vars[i]: 852.8566\n",
      "f_train: -0.8538482942034122, F_train: 0.2986262135902069, Q0_train: 852.8566334766579\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 12.014630966228651, Left1: 3.8131883063683745\n",
      "f_vars[i]: -0.8389, F_vars[i]: 0.3018, Q0_vars[i]: 861.8123\n",
      "f_train: -0.838921284046026, F_train: 0.30176202267215335, Q0_train: 861.8122959575288\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 45.71257714245439, Left1: 6.4102002592935605\n",
      "f_vars[i]: -0.8458, F_vars[i]: 0.3003, Q0_vars[i]: 857.6493\n",
      "f_train: -0.8458489750068168, F_train: 0.3003043540714707, Q0_train: 857.6492912415101\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 8.702107413295266, Lost1: 0.0, Left0: 0.0, Left1: 3.9300240147216465\n",
      "f_vars[i]: -0.8177, F_vars[i]: 0.3063, Q0_vars[i]: 874.6304\n",
      "f_train: -0.8177087193907926, F_train: 0.3062502515136345, Q0_train: 874.6303794539468\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 57.35193698082935, Left1: 1.389254652016234\n",
      "f_vars[i]: -0.8315, F_vars[i]: 0.3033, Q0_vars[i]: 866.3145\n",
      "f_train: -0.8314504970664722, F_train: 0.30333845757963135, Q0_train: 866.3144893581782\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 8.244358266112158, Left0: 39.426399749246, Left1: 0.0\n",
      "f_vars[i]: -0.8396, F_vars[i]: 0.3016, Q0_vars[i]: 861.3959\n",
      "f_train: -0.839613378815391, F_train: 0.3016162171349419, Q0_train: 861.3958850265747\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 12.665166813674261, Lost1: 0.0, Left0: 0.0, Left1: 19.474710993618224\n",
      "f_vars[i]: -0.8207, F_vars[i]: 0.3056, Q0_vars[i]: 872.8388\n",
      "f_train: -0.8206629650754492, F_train: 0.3056229489323628, Q0_train: 872.838844942617\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.1637467407099393, Left0: 8.29925951450744, Left1: 0.0\n",
      "f_vars[i]: -0.8097, F_vars[i]: 0.3080, Q0_vars[i]: 879.5195\n",
      "f_train: -0.8096636359912373, F_train: 0.30796217746086874, Q0_train: 879.5195262658308\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.26522495544134017, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -0.8336, F_vars[i]: 0.3029, Q0_vars[i]: 865.0413\n",
      "f_train: -0.8335609881340829, F_train: 0.30289264486465384, Q0_train: 865.0412778517746\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 72.67706537401318, Left1: 3.6910013991255255\n",
      "f_vars[i]: -0.8724, F_vars[i]: 0.2948, Q0_vars[i]: 841.8158\n",
      "f_train: -0.8723752701545531, F_train: 0.29476029816972044, Q0_train: 841.8158357811614\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.4351419070092106, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -0.7932, F_vars[i]: 0.3115, Q0_vars[i]: 889.5515\n",
      "f_train: -0.7932331719027953, F_train: 0.3114748666589204, Q0_train: 889.5515333287177\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 15.618625076689796, Left1: 2.413551467104867\n",
      "f_vars[i]: -0.8174, F_vars[i]: 0.3063, Q0_vars[i]: 874.8435\n",
      "f_train: -0.8173575307492139, F_train: 0.3063248704924017, Q0_train: 874.8434863016672\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 21.04630347741471, Lost1: 0.0, Left0: 0.0, Left1: 28.243486925168895\n",
      "f_vars[i]: -0.8078, F_vars[i]: 0.3084, Q0_vars[i]: 880.6325\n",
      "f_train: -0.8078356498616128, F_train: 0.3083518972602533, Q0_train: 880.6325401305762\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=3 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xc90c97b0\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 2e+03]\n",
      "Presolve removed 52 rows and 65 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 241 rows, 199 columns, 647 nonzeros\n",
      "Presolved model has 62 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 137 continuous, 62 integer (62 binary)\n",
      "\n",
      "Root relaxation: objective 2.539194e+07, 104 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5392e+07    0   27          - 2.5392e+07      -     -    0s\n",
      "H    0     0                    2.361692e+07 2.5392e+07  7.52%     -    0s\n",
      "     0     2 2.5392e+07    0   24 2.3617e+07 2.5392e+07  7.52%     -    0s\n",
      "H    9     8                    2.489699e+07 2.5390e+07  1.98%   1.8    0s\n",
      "H   36    38                    2.489699e+07 2.5389e+07  1.97%   8.0    0s\n",
      "H   74    68                    2.535666e+07 2.5388e+07  0.12%   6.6    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 5\n",
      "\n",
      "Explored 93 nodes (755 simplex iterations) in 0.03 seconds (0.03 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 4: 2.53567e+07 2.4897e+07 2.4897e+07 2.36169e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.535666184250e+07, best bound 2.538784802657e+07, gap 0.1230%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1.7423521889034261, Left1: 1.689478064302905\n",
      "f_vars[i]: -0.4238, F_vars[i]: 0.3956, Q0_vars[i]: 1129.8436\n",
      "f_train: -0.4237795124487773, F_train: 0.39561270066634363, Q0_train: 1129.8435994433787\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.7965952452939622, Left1: 4.821362451091578\n",
      "f_vars[i]: -0.4330, F_vars[i]: 0.3934, Q0_vars[i]: 1123.5360\n",
      "f_train: -0.43302550969091613, F_train: 0.3934040996881462, Q0_train: 1123.5359817285334\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.8577912144478432, Left0: 17.204999793589177, Left1: 0.0\n",
      "f_vars[i]: -0.4014, F_vars[i]: 0.4010, Q0_vars[i]: 1145.1288\n",
      "f_train: -0.40144683628825706, F_train: 0.4009647716100944, Q0_train: 1145.128758613897\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 8.150148062594791, Left1: 3.8131884187810208\n",
      "f_vars[i]: -0.4081, F_vars[i]: 0.3994, Q0_vars[i]: 1140.5530\n",
      "f_train: -0.40812177321406473, F_train: 0.39936257009327103, Q0_train: 1140.552977488184\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 11.54146729874531, Left1: 6.410200437849134\n",
      "f_vars[i]: -0.4750, F_vars[i]: 0.3834, Q0_vars[i]: 1095.0491\n",
      "f_train: -0.4750170240611684, F_train: 0.3834294707900621, Q0_train: 1095.049104036434\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.7720833550229145, Left0: 9.528169538898698, Left1: 0.0\n",
      "f_vars[i]: -0.3398, F_vars[i]: 0.4159, Q0_vars[i]: 1187.6880\n",
      "f_train: -0.33976398603849756, F_train: 0.4158668088165124, Q0_train: 1187.687987192705\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 1.3892544946293128\n",
      "f_vars[i]: -0.5013, F_vars[i]: 0.3772, Q0_vars[i]: 1077.3406\n",
      "f_train: -0.5013269285821393, F_train: 0.37722888636428364, Q0_train: 1077.3406467132131\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 8.244358316867874, Left0: 0.45178284005530245, Left1: 0.0\n",
      "f_vars[i]: -0.4763, F_vars[i]: 0.3831, Q0_vars[i]: 1094.2145\n",
      "f_train: -0.47625330971500124, F_train: 0.3831372410287377, Q0_train: 1094.2145152458236\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.441684055039726, Left1: 6.8095440614731615\n",
      "f_vars[i]: -0.3400, F_vars[i]: 0.4158, Q0_vars[i]: 1187.5419\n",
      "f_train: -0.3399746115021567, F_train: 0.41581564424744166, Q0_train: 1187.54186458141\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.1637465616656755, Left0: 4.018326786193496, Left1: 0.0\n",
      "f_vars[i]: -0.3718, F_vars[i]: 0.4081, Q0_vars[i]: 1165.5483\n",
      "f_train: -0.37176487236986544, F_train: 0.40811463511679075, Q0_train: 1165.5482939481474\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.26522452100582955, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -0.3940, F_vars[i]: 0.4028, Q0_vars[i]: 1150.2357\n",
      "f_train: -0.3940074549680126, F_train: 0.40275296088390306, Q0_train: 1150.2357084216333\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 8.45930608160535, Left1: 3.691001444577809\n",
      "f_vars[i]: -0.5686, F_vars[i]: 0.3616, Q0_vars[i]: 1032.6094\n",
      "f_train: -0.5685722821935666, F_train: 0.3615663285075837, Q0_train: 1032.6094216653375\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.43514184545324497, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -0.3429, F_vars[i]: 0.4151, Q0_vars[i]: 1185.5257\n",
      "f_train: -0.3428815861511143, F_train: 0.4151096755943247, Q0_train: 1185.5256649933067\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 2.831490205266965, Left1: 2.413551206114107\n",
      "f_vars[i]: -0.3976, F_vars[i]: 0.4019, Q0_vars[i]: 1147.7684\n",
      "f_train: -0.39760024397686555, F_train: 0.40188904336105635, Q0_train: 1147.7684173513737\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.666494391596925, Left1: 7.197183336380476\n",
      "f_vars[i]: -0.3116, F_vars[i]: 0.4227, Q0_vars[i]: 1207.2877\n",
      "f_train: -0.31157801870617674, F_train: 0.4227296092081473, Q0_train: 1207.2876893349417\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=4 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x64029659\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 1e+03]\n",
      "Presolve removed 56 rows and 73 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 237 rows, 191 columns, 639 nonzeros\n",
      "Presolved model has 58 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 133 continuous, 58 integer (58 binary)\n",
      "\n",
      "Root relaxation: objective 2.540358e+07, 95 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5404e+07    0   25          - 2.5404e+07      -     -    0s\n",
      "H    0     0                    2.483526e+07 2.5404e+07  2.29%     -    0s\n",
      "     0     2 2.5404e+07    0   22 2.4835e+07 2.5404e+07  2.29%     -    0s\n",
      "H   33    32                    2.483526e+07 2.5401e+07  2.28%  13.0    0s\n",
      "H   69    55                    2.532089e+07 2.5401e+07  0.32%   8.8    0s\n",
      "H   70    55                    2.535289e+07 2.5401e+07  0.19%   8.6    0s\n",
      "H   86    55                    2.535765e+07 2.5401e+07  0.17%   8.0    0s\n",
      "H   88    55                    2.536047e+07 2.5401e+07  0.16%   7.9    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 9\n",
      "\n",
      "Explored 93 nodes (808 simplex iterations) in 0.04 seconds (0.03 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 6: 2.53605e+07 2.53576e+07 2.53529e+07 ... 2.48353e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.536046510641e+07, best bound 2.540086163672e+07, gap 0.1593%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.044270626615343645, Left0: 1.5551930550016095, Left1: 0.0\n",
      "f_vars[i]: -0.0299, F_vars[i]: 0.4925, Q0_vars[i]: 1406.5881\n",
      "f_train: -0.02994513100064644, F_train: 0.4925142766189395, Q0_train: 1406.5880648804334\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1.314470559241954, Left1: 3.9735896354927718\n",
      "f_vars[i]: -0.0377, F_vars[i]: 0.4906, Q0_vars[i]: 1401.0738\n",
      "f_train: -0.037670637383447225, F_train: 0.49058345419470406, Q0_train: 1401.0737642677136\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 12.256071376458749, Left1: 0.2542948950626851\n",
      "f_vars[i]: -0.0054, F_vars[i]: 0.4987, Q0_vars[i]: 1424.1466\n",
      "f_train: -0.0053505744110315945, F_train: 0.4986623595884768, Q0_train: 1424.1465815313868\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.55430382009463, Left1: 1.4142064545967514\n",
      "f_vars[i]: -0.0080, F_vars[i]: 0.4980, Q0_vars[i]: 1422.2203\n",
      "f_train: -0.008048488865982417, F_train: 0.4979878886452341, Q0_train: 1422.2203373108403\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 11.458920189726769, Left1: 2.2199238035420876\n",
      "f_vars[i]: -0.0907, F_vars[i]: 0.4773, Q0_vars[i]: 1363.2246\n",
      "f_train: -0.09073967297565577, F_train: 0.4773306339963847, Q0_train: 1363.2245899352806\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 10.310771817111522, Left1: 1.208751934558677\n",
      "f_vars[i]: 0.0815, F_vars[i]: 0.5204, Q0_vars[i]: 1486.1070\n",
      "f_train: 0.08147580098721852, F_train: 0.5203576897778212, Q0_train: 1486.1070037093261\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 1.0641162352530955\n",
      "f_vars[i]: -0.1172, F_vars[i]: 0.4707, Q0_vars[i]: 1344.4022\n",
      "f_train: -0.1171738815569503, F_train: 0.4707399995834241, Q0_train: 1344.4021757528933\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.022285338199907, Lost1: 5.775496615093516, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -0.0900, F_vars[i]: 0.4775, Q0_vars[i]: 1363.7479\n",
      "f_train: -0.09000525564589079, F_train: 0.4775138639539651, Q0_train: 1363.7478825253563\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 11.176598692590892, Left1: 7.57986390964993\n",
      "f_vars[i]: 0.0802, F_vars[i]: 0.5200, Q0_vars[i]: 1485.1782\n",
      "f_train: 0.08017279604745342, F_train: 0.5200324699736046, Q0_train: 1485.1781975471697\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 5.026929325021456, Left0: 11.264008407266308, Left1: 0.0\n",
      "f_vars[i]: 0.0460, F_vars[i]: 0.5115, Q0_vars[i]: 1460.7738\n",
      "f_train: 0.045957364730821126, F_train: 0.5114873194096753, Q0_train: 1460.7738150420735\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 2.601641160733152\n",
      "f_vars[i]: 0.0108, F_vars[i]: 0.5027, Q0_vars[i]: 1435.6669\n",
      "f_train: 0.01078481022265354, F_train: 0.5026961764225452, Q0_train: 1435.6668945133072\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 3.9287458972503373\n",
      "f_vars[i]: -0.2124, F_vars[i]: 0.4471, Q0_vars[i]: 1276.9035\n",
      "f_train: -0.21237281761989601, F_train: 0.4471054514154814, Q0_train: 1276.903475816544\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.7437060145430223, Left0: 9.369774183822505, Left1: 0.0\n",
      "f_vars[i]: 0.0864, F_vars[i]: 0.5216, Q0_vars[i]: 1489.6446\n",
      "f_train: 0.08643926956538461, F_train: 0.5215963721792425, Q0_train: 1489.6445983836927\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 8.59984712088383, Left1: 0.6543544472428948\n",
      "f_vars[i]: 0.0122, F_vars[i]: 0.5031, Q0_vars[i]: 1436.7038\n",
      "f_train: 0.01223718867184953, F_train: 0.5030592589913642, Q0_train: 1436.7038342166045\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 14.131323021803258, Left1: 2.0456162854748072\n",
      "f_vars[i]: 0.1188, F_vars[i]: 0.5297, Q0_vars[i]: 1512.6812\n",
      "f_train: 0.11878988395799528, F_train: 0.5296625983560724, Q0_train: 1512.6812046458365\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=5 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xf0ec38b8\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 2e+03]\n",
      "Presolve removed 56 rows and 73 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 237 rows, 191 columns, 639 nonzeros\n",
      "Presolved model has 58 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 133 continuous, 58 integer (58 binary)\n",
      "\n",
      "Root relaxation: objective 2.540358e+07, 95 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5404e+07    0   25          - 2.5404e+07      -     -    0s\n",
      "H    0     0                    1.898036e+07 2.5404e+07  33.8%     -    0s\n",
      "     0     2 2.5404e+07    0   22 1.8980e+07 2.5404e+07  33.8%     -    0s\n",
      "H    9     8                    2.174246e+07 2.5402e+07  16.8%   1.8    0s\n",
      "H   70    68                    2.535152e+07 2.5401e+07  0.19%   2.8    0s\n",
      "H   86    68                    2.536316e+07 2.5401e+07  0.15%   2.7    0s\n",
      "H   92    68                    2.536430e+07 2.5401e+07  0.14%   2.6    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 4\n",
      "\n",
      "Explored 93 nodes (333 simplex iterations) in 0.03 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 5: 2.53643e+07 2.53632e+07 2.53515e+07 ... 1.89804e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.536429829810e+07, best bound 2.540086183113e+07, gap 0.1442%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.044270701084769826, Left0: 2.5483635889604557, Left1: 0.0\n",
      "f_vars[i]: 0.3670, F_vars[i]: 0.5907, Q0_vars[i]: 1687.1249\n",
      "f_train: 0.36704078496510384, F_train: 0.5907437346959709, Q0_train: 1687.1248734767996\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1.92551611844965, Left1: 3.973589645122729\n",
      "f_vars[i]: 0.3573, F_vars[i]: 0.5884, Q0_vars[i]: 1680.4011\n",
      "f_train: 0.3573112491020951, F_train: 0.5883894078177072, Q0_train: 1680.4010722693984\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 13.33222912878955, Left1: 0.25429486149232616\n",
      "f_vars[i]: 0.3972, F_vars[i]: 0.5980, Q0_vars[i]: 1707.8828\n",
      "f_train: 0.39718890918400174, F_train: 0.5980120783616643, Q0_train: 1707.882780276573\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 10.002617754750418, Left1: 1.414206508322195\n",
      "f_vars[i]: 0.3934, F_vars[i]: 0.5971, Q0_vars[i]: 1705.2738\n",
      "f_train: 0.39339019976672907, F_train: 0.5970985537816518, Q0_train: 1705.2738147455805\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 12.329472571243969, Left1: 2.2199238678497295\n",
      "f_vars[i]: 0.2930, F_vars[i]: 0.5727, Q0_vars[i]: 1635.6661\n",
      "f_train: 0.29297998391379076, F_train: 0.5727255253037942, Q0_train: 1635.6660640884961\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 8.169172297504705, Left1: 1.2087519381427683\n",
      "f_vars[i]: 0.5016, F_vars[i]: 0.6228, Q0_vars[i]: 1778.7927\n",
      "f_train: 0.5016247220997063, F_train: 0.62284107089077, Q0_train: 1778.7927339822734\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 1.0641161758576345\n",
      "f_vars[i]: 0.2603, F_vars[i]: 0.5647, Q0_vars[i]: 1612.7803\n",
      "f_train: 0.2603084147870809, F_train: 0.5647121054770834, Q0_train: 1612.7802692552866\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.4229605964503662, Lost1: 6.3748213641806615, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 0.2937, F_vars[i]: 0.5729, Q0_vars[i]: 1636.1405\n",
      "f_train: 0.29365880430351243, F_train: 0.5728916319121468, Q0_train: 1636.1404535303827\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.199138997555687, Left1: 7.579863854253517\n",
      "f_vars[i]: 0.5001, F_vars[i]: 0.6225, Q0_vars[i]: 1777.7969\n",
      "f_train: 0.5001406477588226, F_train: 0.6224923833779578, Q0_train: 1777.7969056029185\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 5.026929269582297, Left0: 9.631074763593206, Left1: 0.0\n",
      "f_vars[i]: 0.4581, F_vars[i]: 0.6126, Q0_vars[i]: 1749.4506\n",
      "f_train: 0.45811526227258614, F_train: 0.6125669688385352, Q0_train: 1749.450580850704\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 2.6016412696092175\n",
      "f_vars[i]: 0.4161, F_vars[i]: 0.6026, Q0_vars[i]: 1720.8613\n",
      "f_train: 0.4161286176776411, F_train: 0.602556491954094, Q0_train: 1720.861323690326\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 3.9287458978493532\n",
      "f_vars[i]: 0.1458, F_vars[i]: 0.5364, Q0_vars[i]: 1531.9148\n",
      "f_train: 0.14584683730322645, F_train: 0.5363972141822371, Q0_train: 1531.9148201821579\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.7437060246500096, Left0: 6.028233533303869, Left1: 0.0\n",
      "f_vars[i]: 0.5068, F_vars[i]: 0.6241, Q0_vars[i]: 1782.2772\n",
      "f_train: 0.5068218475528581, F_train: 0.6240611463342195, Q0_train: 1782.2771884204085\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.8719701406432705, Left1: 0.654354382480733\n",
      "f_vars[i]: 0.4173, F_vars[i]: 0.6028, Q0_vars[i]: 1721.6880\n",
      "f_train: 0.41733748815867333, F_train: 0.6028459589526035, Q0_train: 1721.6880222138193\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 10.37050197328958, Left1: 2.045616279306614\n",
      "f_vars[i]: 0.5467, F_vars[i]: 0.6334, Q0_vars[i]: 1808.8627\n",
      "f_train: 0.546701721532505, F_train: 0.6333700271927953, Q0_train: 1808.8627339257166\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=6 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xe84dbc9b\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [8e+02, 2e+03]\n",
      "Presolve removed 53 rows and 91 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 240 rows, 173 columns, 650 nonzeros\n",
      "Presolved model has 37 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 136 continuous, 37 integer (37 binary)\n",
      "\n",
      "Root relaxation: objective 2.540900e+07, 89 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5409e+07    0   20          - 2.5409e+07      -     -    0s\n",
      "H    0     0                    1.223711e+07 2.5409e+07   108%     -    0s\n",
      "     0     2 2.5409e+07    0   20 1.2237e+07 2.5409e+07   108%     -    0s\n",
      "H   55    56                    2.173796e+07 2.5407e+07  16.9%   4.9    0s\n",
      "H   72    72                    2.509978e+07 2.5407e+07  1.22%   4.5    0s\n",
      "H  479   222                    2.535130e+07 2.5407e+07  0.22%   5.5    0s\n",
      "H  489   222                    2.536761e+07 2.5407e+07  0.16%   5.5    0s\n",
      "\n",
      "Explored 567 nodes (2996 simplex iterations) in 0.05 seconds (0.05 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 5: 2.53676e+07 2.53513e+07 2.50998e+07 ... 1.22371e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Warning: max constraint violation (1.5285e-06) exceeds tolerance\n",
      "Best objective 2.536761404879e+07, best bound 2.540694491852e+07, gap 0.1550%\n",
      "Model status: 2\n",
      "Lost0: 1.0975872678472456, Lost1: 0.0, Left0: 0.0, Left1: 3.852612831301883\n",
      "f_vars[i]: 0.7877, F_vars[i]: 0.6873, Q0_vars[i]: 1962.9761\n",
      "f_train: 0.7876779796516375, F_train: 0.6873325304605233, Q0_train: 1962.9760594693416\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 8.15747127220095, Left1: 1.7603474818016593\n",
      "f_vars[i]: 0.7806, F_vars[i]: 0.6858, Q0_vars[i]: 1958.6557\n",
      "f_train: 0.7806481020348484, F_train: 0.6858197779532377, Q0_train: 1958.655738774329\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 3.604562260927062, Left1: 1.3033977922208153\n",
      "f_vars[i]: 0.8192, F_vars[i]: 0.6941, Q0_vars[i]: 1982.2282\n",
      "f_train: 0.8192335291181516, F_train: 0.6940736153959218, Q0_train: 1982.2281503520044\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.19354760015891, Left1: 0.9206417650101353\n",
      "f_vars[i]: 0.8212, F_vars[i]: 0.6945, Q0_vars[i]: 1983.4386\n",
      "f_train: 0.8212304346376293, F_train: 0.6944974647894093, Q0_train: 1983.4386360708734\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 14.447266869500027, Left1: 2.951072865084143\n",
      "f_vars[i]: 0.7046, F_vars[i]: 0.6692, Q0_vars[i]: 1911.1808\n",
      "f_train: 0.7045531965858594, F_train: 0.6691965002472907, Q0_train: 1911.1807616408867\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.28398810024060595, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 0.9528, F_vars[i]: 0.7217, Q0_vars[i]: 2061.0649\n",
      "f_train: 0.95280108101753, F_train: 0.7216781489921037, Q0_train: 2061.0648650144344\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 14.54661797299525, Left1: 0.3803585621859611\n",
      "f_vars[i]: 0.6736, F_vars[i]: 0.6623, Q0_vars[i]: 1891.5210\n",
      "f_train: 0.6736173991749497, F_train: 0.6623126815727037, Q0_train: 1891.5210326784172\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.7670031726120214, Left0: 5.501912956215163, Left1: 0.0\n",
      "f_vars[i]: 0.7080, F_vars[i]: 0.6699, Q0_vars[i]: 1913.3297\n",
      "f_train: 0.7079541475178357, F_train: 0.6699489437051135, Q0_train: 1913.3296901847182\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 3.1662774761463197, Lost1: 0.0, Left0: 0.0, Left1: 9.887902856052829\n",
      "f_vars[i]: 0.9499, F_vars[i]: 0.7211, Q0_vars[i]: 2059.3840\n",
      "f_train: 0.9498728654500632, F_train: 0.7210896095191404, Q0_train: 2059.3840353660753\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.5674106742207528, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 0.9069, F_vars[i]: 0.7124, Q0_vars[i]: 2034.4715\n",
      "f_train: 0.906905557421009, F_train: 0.7123665269530813, Q0_train: 2034.4714908798198\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.4955650748287326, Lost1: 0.0, Left0: 0.0, Left1: 3.3151568033743617\n",
      "f_vars[i]: 0.8493, F_vars[i]: 0.7004, Q0_vars[i]: 2000.3256\n",
      "f_train: 0.849252917530388, F_train: 0.7004104013977106, Q0_train: 2000.325590330813\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 8.395986537704061, Left1: 2.0935091230876424\n",
      "f_vars[i]: 0.5267, F_vars[i]: 0.6287, Q0_vars[i]: 1795.5443\n",
      "f_train: 0.5266720719304177, F_train: 0.6287065916862393, Q0_train: 1795.544271829771\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.3319747420901535, Lost1: 0.0, Left0: 0.0, Left1: 1.664436137260124\n",
      "f_vars[i]: 0.9690, F_vars[i]: 0.7249, Q0_vars[i]: 2070.3348\n",
      "f_train: 0.9690194845258606, F_train: 0.7249240171240106, Q0_train: 2070.334848832687\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.6519827042103543, Left0: 7.9716679073427485, Left1: 0.0\n",
      "f_vars[i]: 0.8575, F_vars[i]: 0.7021, Q0_vars[i]: 2005.2368\n",
      "f_train: 0.8574615973856385, F_train: 0.7021300366069886, Q0_train: 2005.2367542831018\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.2894128340340103, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 1.0080, F_vars[i]: 0.7326, Q0_vars[i]: 2092.3583\n",
      "f_train: 1.0080353553656085, F_train: 0.7326354891463832, Q0_train: 2092.358300789839\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=7 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xd3f70659\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [5e+02, 2e+03]\n",
      "Presolve removed 53 rows and 90 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 240 rows, 174 columns, 639 nonzeros\n",
      "Presolved model has 38 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 136 continuous, 38 integer (38 binary)\n",
      "Found heuristic solution: objective 2.524514e+07\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.52451e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.524514127959e+07, best bound 2.542797509868e+07, gap 0.7242%\n",
      "Model status: 2\n",
      "Lost0: 10.014793751860907, Lost1: 0.0, Left0: 0.0, Left1: 10.014794055471384\n",
      "f_vars[i]: 1.2735, F_vars[i]: 0.7813, Q0_vars[i]: 2231.4617\n",
      "f_train: 1.2735057752192374, F_train: 0.7813422881235575, Q0_train: 2231.4616839245186\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.19434734856668, Lost1: 0.0, Left0: 0.0, Left1: 2.194347591066048\n",
      "f_vars[i]: 1.2639, F_vars[i]: 0.7797, Q0_vars[i]: 2226.7661\n",
      "f_train: 1.2639080959099358, F_train: 0.7796981310568509, Q0_train: 2226.7660805347155\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 8.019705899363451, Lost1: 0.0, Left0: 0.0, Left1: 8.019706174674411\n",
      "f_vars[i]: 1.3230, F_vars[i]: 0.7897, Q0_vars[i]: 2255.2734\n",
      "f_train: 1.3229970866771303, F_train: 0.7896799114746096, Q0_train: 2255.2733824920547\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.2548893336885874e-06, Lost1: 0.0, Left0: 0.0, Left1: 1.4747593013453297e-06\n",
      "f_vars[i]: 1.3288, F_vars[i]: 0.7906, Q0_vars[i]: 2258.0369\n",
      "f_train: 1.3288332138194239, F_train: 0.7906475691772322, Q0_train: 2258.036948626101\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.8983678273798432e-06, Lost1: 0.0, Left0: 0.0, Left1: 2.1154513092369598e-06\n",
      "f_vars[i]: 1.1406, F_vars[i]: 0.7578, Q0_vars[i]: 2164.1950\n",
      "f_train: 1.1405956301493223, F_train: 0.7577889806308682, Q0_train: 2164.19500196129\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 8.02143225400214, Lost1: 0.0, Left0: 0.0, Left1: 8.021432500755328\n",
      "f_vars[i]: 1.5435, F_vars[i]: 0.8240, Q0_vars[i]: 2353.1973\n",
      "f_train: 1.5434645320255003, F_train: 0.8239678019434487, Q0_train: 2353.197320523828\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 7.374830386837213, Lost1: 0.0, Left0: 0.0, Left1: 7.374830675329463\n",
      "f_vars[i]: 1.0936, F_vars[i]: 0.7491, Q0_vars[i]: 2139.2374\n",
      "f_train: 1.0935527217199956, F_train: 0.7490501317430419, Q0_train: 2139.23742990715\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 19.10624018125054, Lost1: 0.0, Left0: 0.0, Left1: 19.10624044143026\n",
      "f_vars[i]: 1.1471, F_vars[i]: 0.7590, Q0_vars[i]: 2167.6237\n",
      "f_train: 1.1471477127000993, F_train: 0.7589895494625019, Q0_train: 2167.6237468115637\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.9516384752103686, Lost1: 0.0, Left0: 0.0, Left1: 0.951638760791705\n",
      "f_vars[i]: 1.5382, F_vars[i]: 0.8232, Q0_vars[i]: 2351.0334\n",
      "f_train: 1.5382495004756453, F_train: 0.8232101100001037, Q0_train: 2351.0334026539103\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 5.00089999272268, Lost1: 0.0, Left0: 0.0, Left1: 5.00090021878683\n",
      "f_vars[i]: 1.4713, F_vars[i]: 0.8133, Q0_vars[i]: 2322.6115\n",
      "f_train: 1.471321922405397, F_train: 0.81325822857909, Q0_train: 2322.6114902456056\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 9.03290474494483, Lost1: 0.0, Left0: 0.0, Left1: 9.032904927264866\n",
      "f_vars[i]: 1.3747, F_vars[i]: 0.7981, Q0_vars[i]: 2279.4281\n",
      "f_train: 1.374695036554698, F_train: 0.7981376483438661, Q0_train: 2279.428117290534\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 40.103057717502644, Lost1: 0.0, Left0: 0.0, Left1: 40.10305796655007\n",
      "f_vars[i]: 0.8508, F_vars[i]: 0.7007, Q0_vars[i]: 2001.2513\n",
      "f_train: 0.8507980533747093, F_train: 0.7007345255812077, Q0_train: 2001.2512674729578\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.40013623403623, Lost1: 0.0, Left0: 0.0, Left1: 2.400136497735579\n",
      "f_vars[i]: 1.5738, F_vars[i]: 0.8283, Q0_vars[i]: 2365.6326\n",
      "f_train: 1.573781215115587, F_train: 0.8283219824623304, Q0_train: 2365.6325709133966\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.0887470125453547e-06, Lost1: 0.0, Left0: 0.0, Left1: 1.3741884004048188e-06\n",
      "f_vars[i]: 1.3907, F_vars[i]: 0.8007, Q0_vars[i]: 2286.7633\n",
      "f_train: 1.3907129803011866, F_train: 0.8007060420010472, Q0_train: 2286.763279001797\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.0509214115930603, Lost1: 0.0, Left0: 0.0, Left1: 2.0509216658473064\n",
      "f_vars[i]: 1.6337, F_vars[i]: 0.8367, Q0_vars[i]: 2389.5060\n",
      "f_train: 1.6337391391027172, F_train: 0.8366812196993645, Q0_train: 2389.5059973038633\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 210 rows, 435 columns and 960 nonzeros\n",
      "Model fingerprint: 0x24e5cdcb\n",
      "Model has 105 general constraints\n",
      "Variable types: 315 continuous, 120 integer (120 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Presolve removed 199 rows and 410 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 11 rows, 25 columns, 59 nonzeros\n",
      "Presolved model has 6 SOS constraint(s)\n",
      "Variable types: 11 continuous, 14 integer (14 binary)\n",
      "Found heuristic solution: objective 2.541808e+07\n",
      "\n",
      "Root relaxation: interrupted, 7 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0          -    0      2.5418e+07 2.5428e+07  0.04%     -    0s\n",
      "\n",
      "Explored 1 nodes (7 simplex iterations) in 0.02 seconds (0.01 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.54181e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.541808183612e+07, best bound 2.542797509810e+07, gap 0.0389%\n",
      "\n",
      "model.status is optimal: True\n",
      "model.status is TIME_LIMIT: False\n",
      "\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = 1.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = -0.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 667 and 669 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 667 and 669 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 435 rows, 741 columns and 1830 nonzeros\n",
      "Model fingerprint: 0xacd692f4\n",
      "Model has 240 general constraints\n",
      "Variable types: 621 continuous, 120 integer (120 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 5e+06]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e-03, 1e+00]\n",
      "  GenCon coe range [1e+00, 1e+00]\n",
      "Presolve removed 20 rows and 210 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 535 rows, 532 columns, 2040 nonzeros\n",
      "Presolved model has 197 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 334 continuous, 198 integer (198 binary)\n",
      "\n",
      "Root relaxation: objective 2.542798e+07, 258 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5428e+07    0   59          - 2.5428e+07      -     -    0s\n",
      "     0     2 2.5428e+07    0   54          - 2.5428e+07      -     -    0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27318/3679721425.py:107: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27318/2844647141.py:156: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 1828  1241              92    1.635207e+07 2.5428e+07  55.5%   3.6    0s\n",
      "H 1972  1308                    2.131560e+07 2.5428e+07  19.3%   3.6    0s\n",
      "H 2280  1428                    2.153497e+07 2.5428e+07  18.1%   3.6    0s\n",
      "* 2577  1617             103    2.251553e+07 2.5428e+07  12.9%   3.6    0s\n",
      "H 2923  1642                    2.290310e+07 2.5428e+07  11.0%   3.5    0s\n",
      "H 3042  1642                    2.290310e+07 2.5428e+07  11.0%   3.4    0s\n",
      "* 5499  2374             124    2.467795e+07 2.5428e+07  3.04%   4.4    0s\n",
      "H 6235  2072                    2.495568e+07 2.5428e+07  1.89%   4.5    0s\n",
      "* 6262  1788             105    2.522134e+07 2.5428e+07  0.82%   4.6    0s\n",
      "\n",
      "Explored 6473 nodes (29874 simplex iterations) in 0.60 seconds (0.78 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 9: 2.52213e+07 2.49557e+07 2.46779e+07 ... 1.63521e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.522133596550e+07, best bound 2.542790469522e+07, gap 0.8190%\n",
      "\n",
      "model.status is optimal: True\n",
      "model.status is TIME_LIMIT: False\n",
      "\n",
      "f_vars[i]: 1.2732, F_vars[i]: 0.7813, Q0_vars[i]: 2231.3252\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.0010000000000000002\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.0010000000000000002\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.0010000000000000002\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.2616, F_vars[i]: 0.7793, Q0_vars[i]: 2225.6131\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.0009815671341390332\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.000981567134139033\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.0009815671341390332\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.000981567134139033\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.000981567134139033\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.000981567134139033\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.0009815671341390332\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 1.8432865860966994e-05\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.3263, F_vars[i]: 0.7902, Q0_vars[i]: 2256.8174\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.0010249058111163891\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.0010249058111163891\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.0010249058111163891\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.0010249058111163891\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.0010249058111163891\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.0010249058111163891\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.0010249058111163891\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = -2.4905811116389094e-05\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.3299, F_vars[i]: 0.7908, Q0_vars[i]: 2258.5362\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.0010020807871213694\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.0010020807871213692\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.0010020807871213694\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.0010020807871213692\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.0010020807871213692\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.0010020807871213692\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.0010020807871213694\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = -2.0807871213691757e-06\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.1333, F_vars[i]: 0.7564, Q0_vars[i]: 2160.3492\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.0009572964733879305\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.0009572964733879305\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.0009572964733879305\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.0009572964733879305\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.0009572964733879305\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.0009572964733879305\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.0009572964733879305\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 4.2703526612069545e-05\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.5518, F_vars[i]: 0.8252, Q0_vars[i]: 2356.6606\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.0010312330354313155\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.0010312330354313155\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.0010312330354313155\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.0010312330354313155\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.0010312330354313155\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.0010312330354313155\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.0010312330354313155\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = -3.123303543131552e-05\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.0814, F_vars[i]: 0.7468, Q0_vars[i]: 2132.7136\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.0009195577478838599\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.0009195577478838599\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.0009195577478838599\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.0009195577478838599\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.0009195577478838599\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.0009195577478838599\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.0009195577478838599\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 8.044225211614015e-05\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.1391, F_vars[i]: 0.7575, Q0_vars[i]: 2163.4178\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.0009489895634445432\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.0009489895634445432\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.0009489895634445432\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.000948989563444543\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.0009489895634445432\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.000948989563444543\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.0009489895634445432\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 5.1010436555456804e-05\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.5469, F_vars[i]: 0.8245, Q0_vars[i]: 2354.6035\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.0010345385560100156\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.0010345385560100156\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.0010345385560100156\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.0010345385560100154\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.0010345385560100156\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.0010345385560100154\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.0010345385560100156\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = -3.4538556010015346e-05\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.4747, F_vars[i]: 0.8138, Q0_vars[i]: 2324.0766\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.0009964589195100677\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.0009964589195100677\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.0009964589195100677\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.0009964589195100675\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.0009964589195100677\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.0009964589195100675\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.0009964589195100677\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 3.541080489932562e-06\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.3772, F_vars[i]: 0.7985, Q0_vars[i]: 2280.5700\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001006947797287448\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001006947797287448\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001006947797287448\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.0010069477972874479\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001006947797287448\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.0010069477972874479\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.001006947797287448\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = -6.947797287447854e-06\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.8332, F_vars[i]: 0.6970, Q0_vars[i]: 1990.6918\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.0009144536614240545\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.0009144536614240545\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.0009144536614240545\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.0009144536614240545\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.0009144536614240545\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.0009144536614240545\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.0009144536614240545\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 8.554633857594552e-05\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.5796, F_vars[i]: 0.8291, Q0_vars[i]: 2367.9935\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.3913, F_vars[i]: 0.8008, Q0_vars[i]: 2287.0295\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.0009850610971661768\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.0009850610971661768\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.0009850610971661768\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.0009850610971661765\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.0009850610971661768\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.0009850610971661765\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.0009850610971661768\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 1.4938902833823474e-05\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.6450, F_vars[i]: 0.8382, Q0_vars[i]: 2393.9013\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.0010419294008017813\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.0010419294008017811\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.0010419294008017813\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.0010419294008017811\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.0010419294008017811\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.0010419294008017811\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.0010419294008017813\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = -4.19294008017811e-05\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "all_Rs: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "Fold 3 Q_star: 2855.933587421095\n",
      "baseline_profit: -503059.0186827384\n",
      "f_vars[i]: -1.4734153519782758, F_vars[i]: 0.18642405224547978\n",
      "f_vars[i]: -1.5700212634668402, F_vars[i]: 0.1722133604796949\n",
      "f_vars[i]: -1.5267722541127557, F_vars[i]: 0.17846643447126123\n",
      "f_vars[i]: -1.4907895008161036, F_vars[i]: 0.18380325723873123\n",
      "f_vars[i]: -1.546679320132477, F_vars[i]: 0.17556639508432115\n",
      "f_vars[i]: -1.5151562201461959, F_vars[i]: 0.18017589836989012\n",
      "f_vars[i]: -1.56493980276741, F_vars[i]: 0.17293895980157142\n",
      "f_vars[i]: -1.5473228389085545, F_vars[i]: 0.17547326979748037\n",
      "f_vars[i]: -1.5654704099835426, F_vars[i]: 0.17286307965061656\n",
      "f_vars[i]: -1.4794198671842063, F_vars[i]: 0.18551506091867626\n",
      "f_vars[i]: -1.5458165206257077, F_vars[i]: 0.1756913140915549\n",
      "f_vars[i]: -1.5307549176718909, F_vars[i]: 0.17788325917061631\n",
      "f_vars[i]: -1.470398199583554, F_vars[i]: 0.18688209713804182\n",
      "f_vars[i]: -1.495614754551213, F_vars[i]: 0.18308047867458993\n",
      "f_vars[i]: -1.568749935467537, F_vars[i]: 0.17239467134315287\n",
      "assigned_R: 6\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 210 rows, 435 columns and 960 nonzeros\n",
      "Model fingerprint: 0xbf584024\n",
      "Model has 105 general constraints\n",
      "Variable types: 315 continuous, 120 integer (120 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Presolve removed 188 rows and 391 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 22 rows, 44 columns, 118 nonzeros\n",
      "Presolved model has 6 SOS constraint(s)\n",
      "Variable types: 22 continuous, 22 integer (22 binary)\n",
      "Found heuristic solution: objective 5736743.7805\n",
      "\n",
      "Root relaxation: interrupted, 17 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0          -    0      5736743.78 5753829.74  0.30%     -    0s\n",
      "\n",
      "Explored 1 nodes (17 simplex iterations) in 0.02 seconds (0.01 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 5.73674e+06 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 5.736743780539e+06, best bound 5.753829742369e+06, gap 0.2978%\n",
      "\n",
      "model.status is optimal: True\n",
      "model.status is TIME_LIMIT: False\n",
      "\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 1.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 1.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "tau: [-0.00040774 -0.00040774 -0.00040774 -0.00040774 -0.00040774 -0.00040774\n",
      " -0.00040774  0.00059226]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.00043795 -0.00043795 -0.00043795 -0.00043795 -0.00043795 -0.00043795\n",
      " -0.00043795  0.00056205]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.00039576 -0.00039576 -0.00039576 -0.00039576 -0.00039576 -0.00039576\n",
      " -0.00039576  0.00060424]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.00043834 -0.00043834 -0.00043834 -0.00043834 -0.00043834 -0.00043834\n",
      " -0.00043834  0.00056166]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.00038803 -0.00038803 -0.00038803 -0.00038803 -0.00038803 -0.00038803\n",
      " -0.00038803  0.00061197]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.00044978 -0.00044978 -0.00044978 -0.00044978 -0.00044978 -0.00044978\n",
      " -0.00044978  0.00055022]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.00043465 -0.00043465 -0.00043465 -0.00043465 -0.00043465 -0.00043465\n",
      " -0.00043465  0.00056535]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.00042113 -0.00042113 -0.00042113 -0.00042113 -0.00042113 -0.00042113\n",
      " -0.00042113  0.00057887]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.00040463 -0.00040463 -0.00040463 -0.00040463 -0.00040463 -0.00040463\n",
      " -0.00040463  0.00059537]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.00040029 -0.00040029 -0.00040029 -0.00040029 -0.00040029 -0.00040029\n",
      " -0.00040029  0.00059971]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.00043108 -0.00043108 -0.00043108 -0.00043108 -0.00043108 -0.00043108\n",
      " -0.00043108  0.00056892]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.00041653 -0.00041653 -0.00041653 -0.00041653 -0.00041653 -0.00041653\n",
      " -0.00041653  0.00058347]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.00045124 -0.00045124 -0.00045124 -0.00045124 -0.00045124 -0.00045124\n",
      " -0.00045124  0.00054876]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.0004559 -0.0004559 -0.0004559 -0.0004559 -0.0004559 -0.0004559\n",
      " -0.0004559  0.0005441]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.00044628 -0.00044628 -0.00044628 -0.00044628 -0.00044628 -0.00044628\n",
      " -0.00044628  0.00055372]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "All train fold profits:\n",
      "       baseline            S1            S2           S12   S15   S16  \\\n",
      "0  1.571096e+06  1.640882e+06  1.663078e+06  1.661235e+06  None  None   \n",
      "1  1.528869e+06  1.584606e+06  1.601974e+06  1.597876e+06  None  None   \n",
      "2  1.632055e+06  1.678226e+06  1.691174e+06  1.681422e+06  None  None   \n",
      "\n",
      "            S14  \n",
      "0  1.667916e+06  \n",
      "1  1.606274e+06  \n",
      "2  1.694539e+06  \n",
      "All test fold profits:\n",
      "        baseline             S1             S2            S12   S15   S16  \\\n",
      "0 -491661.277139  203490.419982  338027.430671  -23115.376841  None  None   \n",
      "1 -420569.429221  230356.417165  356113.927942  -25237.276777  None  None   \n",
      "2 -503059.018683  201982.954009  357952.273378 -126782.011400  None  None   \n",
      "\n",
      "             S14  \n",
      "0  380922.076263  \n",
      "1  396904.512173  \n",
      "2  382449.585369  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27318/2788820283.py:74: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27318/3679721425.py:107: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27318/2062651650.py:90: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n"
     ]
    }
   ],
   "source": [
    "train_all_fold_profits = []\n",
    "train_all_fold_stimulation_results = []\n",
    "test_all_fold_profits = []\n",
    "test_all_fold_stimulation_results = []\n",
    "beta_records = {\"S12\": [], \"S15\": [], \"S16\": []}\n",
    "\n",
    "# 迴圈遍歷所有 fold\n",
    "for fold_idx in range(len(training_data_folds)):\n",
    "    print(f\"===== Processing Fold {fold_idx + 1} =====\")\n",
    "    # 取出該 fold 的訓練資料與需求資料\n",
    "    training_df, testing_df = training_data_folds[fold_idx]\n",
    "    demand_df_train, demand_df_test = demand_folds[fold_idx]\n",
    "\n",
    "    Q_star = calculate_Q_star(demand_df_train, service_level=service_lv)\n",
    "    print(f\"Fold {fold_idx + 1} Q_star: {Q_star}\")\n",
    "\n",
    "    # ====訓練階段====\n",
    "\n",
    "    mu_matrix, covariance_matrix = cal_mu_and_cov_matrix(demand_df_train)\n",
    "    Qk_hat_df_train = make_Qk_hat_df(\n",
    "        demand_df_train, T, service_lv, mu_matrix, covariance_matrix\n",
    "    )\n",
    "    training_profits, training_results, training_stimulation_results = (\n",
    "        perform_fold_training(training_df, demand_df_train, Qk_hat_df_train, Q_star)\n",
    "    )\n",
    "    train_all_fold_profits.append(training_profits)\n",
    "    train_all_fold_stimulation_results.append(training_stimulation_results)\n",
    "\n",
    "    if training_results[\"S12\"] is not None:\n",
    "        beta_records[\"S12\"].append(training_results[\"S12\"].iloc[0][\"beta_values\"])\n",
    "    else:\n",
    "        beta_records[\"S12\"].append(None)\n",
    "\n",
    "    if training_results[\"S15\"] is not None:\n",
    "        beta_records[\"S15\"].append(training_results[\"S15\"].iloc[0][\"beta_values\"])\n",
    "    else:\n",
    "        beta_records[\"S15\"].append(None)\n",
    "\n",
    "    if training_results[\"S16\"] is not None:\n",
    "        beta_records[\"S16\"].append(training_results[\"S16\"].iloc[0][\"beta_values\"])\n",
    "    else:\n",
    "        beta_records[\"S16\"].append(None)\n",
    "\n",
    "    # ====測試階段====\n",
    "    print(f\"Fold {fold_idx + 1} Q_star: {Q_star}\")\n",
    "\n",
    "    mu_matrix, covariance_matrix = cal_mu_and_cov_matrix(demand_df_test)\n",
    "    Qk_hat_df_test = make_Qk_hat_df(\n",
    "        demand_df_test, T, service_lv, mu_matrix, covariance_matrix\n",
    "    )\n",
    "    testing_profits, testing_stimulation_results = perform_fold_testing(\n",
    "        training_results[\"S1\"],\n",
    "        training_results[\"S2\"],\n",
    "        training_results[\"S12\"],\n",
    "        training_results[\"S15\"],\n",
    "        training_results[\"S16\"],\n",
    "        demand_df_test,\n",
    "        Qk_hat_df_test,\n",
    "        Q_star,\n",
    "        testing_df,\n",
    "    )\n",
    "\n",
    "    test_all_fold_profits.append(testing_profits)\n",
    "    test_all_fold_stimulation_results.append(testing_stimulation_results)\n",
    "\n",
    "\n",
    "# 將所有 fold 的結果轉換為 DataFrame 便於檢查與保存\n",
    "train_all_fold_profit_df = pd.DataFrame(train_all_fold_profits)\n",
    "print(\"All train fold profits:\")\n",
    "print(train_all_fold_profit_df)\n",
    "\n",
    "test_all_fold_profit_df = pd.DataFrame(test_all_fold_profits)\n",
    "print(\"All test fold profits:\")\n",
    "print(test_all_fold_profit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S12</th>\n",
       "      <th>S15</th>\n",
       "      <th>S16</th>\n",
       "      <th>S14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.571096e+06</td>\n",
       "      <td>1.640882e+06</td>\n",
       "      <td>1.663078e+06</td>\n",
       "      <td>1.661235e+06</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.667916e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.528869e+06</td>\n",
       "      <td>1.584606e+06</td>\n",
       "      <td>1.601974e+06</td>\n",
       "      <td>1.597876e+06</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.606274e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.632055e+06</td>\n",
       "      <td>1.678226e+06</td>\n",
       "      <td>1.691174e+06</td>\n",
       "      <td>1.681422e+06</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.694539e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       baseline            S1            S2           S12   S15   S16  \\\n",
       "0  1.571096e+06  1.640882e+06  1.663078e+06  1.661235e+06  None  None   \n",
       "1  1.528869e+06  1.584606e+06  1.601974e+06  1.597876e+06  None  None   \n",
       "2  1.632055e+06  1.678226e+06  1.691174e+06  1.681422e+06  None  None   \n",
       "\n",
       "            S14  \n",
       "0  1.667916e+06  \n",
       "1  1.606274e+06  \n",
       "2  1.694539e+06  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all_fold_profit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S12</th>\n",
       "      <th>S15</th>\n",
       "      <th>S16</th>\n",
       "      <th>S14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-491661.277139</td>\n",
       "      <td>203490.419982</td>\n",
       "      <td>338027.430671</td>\n",
       "      <td>-23115.376841</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>380922.076263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-420569.429221</td>\n",
       "      <td>230356.417165</td>\n",
       "      <td>356113.927942</td>\n",
       "      <td>-25237.276777</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>396904.512173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-503059.018683</td>\n",
       "      <td>201982.954009</td>\n",
       "      <td>357952.273378</td>\n",
       "      <td>-126782.011400</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>382449.585369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        baseline             S1             S2            S12   S15   S16  \\\n",
       "0 -491661.277139  203490.419982  338027.430671  -23115.376841  None  None   \n",
       "1 -420569.429221  230356.417165  356113.927942  -25237.276777  None  None   \n",
       "2 -503059.018683  201982.954009  357952.273378 -126782.011400  None  None   \n",
       "\n",
       "             S14  \n",
       "0  380922.076263  \n",
       "1  396904.512173  \n",
       "2  382449.585369  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_all_fold_profit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S12': [array([[-3.08238228e-05,  0.00000000e+00, -1.46554941e-06,\n",
       "           0.00000000e+00],\n",
       "         [-3.08238228e-05,  0.00000000e+00, -1.46554941e-06,\n",
       "           0.00000000e+00],\n",
       "         [-3.08238228e-05,  0.00000000e+00, -1.46554941e-06,\n",
       "           0.00000000e+00],\n",
       "         [-3.08238228e-05,  0.00000000e+00, -1.46554941e-06,\n",
       "           0.00000000e+00],\n",
       "         [-3.08238228e-05,  0.00000000e+00, -1.46554941e-06,\n",
       "           0.00000000e+00],\n",
       "         [-3.08238228e-05,  0.00000000e+00, -1.46554941e-06,\n",
       "           0.00000000e+00],\n",
       "         [-3.08238228e-05,  0.00000000e+00, -1.46554941e-06,\n",
       "           0.00000000e+00],\n",
       "         [-3.08238228e-05,  0.00000000e+00, -1.46554941e-06,\n",
       "           1.00000000e-03]]),\n",
       "  array([[ 0.   ,  0.   ,  0.   , -0.001],\n",
       "         [ 0.   ,  0.   ,  0.   , -0.001],\n",
       "         [ 0.   ,  0.   ,  0.   , -0.001],\n",
       "         [ 0.   ,  0.   ,  0.   , -0.001],\n",
       "         [ 0.   ,  0.   ,  0.   , -0.001],\n",
       "         [ 0.   ,  0.   ,  0.   , -0.001],\n",
       "         [ 0.   ,  0.   ,  0.   , -0.001],\n",
       "         [ 0.   ,  0.   ,  0.   ,  0.   ]]),\n",
       "  array([[-1.45353022e-05,  0.00000000e+00, -2.60875734e-06,\n",
       "           0.00000000e+00],\n",
       "         [-1.45353022e-05,  0.00000000e+00, -2.60875734e-06,\n",
       "           0.00000000e+00],\n",
       "         [-1.45353022e-05,  0.00000000e+00, -2.60875734e-06,\n",
       "           0.00000000e+00],\n",
       "         [-1.45353022e-05,  0.00000000e+00, -2.60875734e-06,\n",
       "           0.00000000e+00],\n",
       "         [-1.45353022e-05,  0.00000000e+00, -2.60875734e-06,\n",
       "           0.00000000e+00],\n",
       "         [-1.45353022e-05,  0.00000000e+00, -2.60875734e-06,\n",
       "           0.00000000e+00],\n",
       "         [-1.45353022e-05,  0.00000000e+00, -2.60875734e-06,\n",
       "           0.00000000e+00],\n",
       "         [-1.45353022e-05,  0.00000000e+00, -2.60875734e-06,\n",
       "           1.00000000e-03]])],\n",
       " 'S15': [None, None, None],\n",
       " 'S16': [None, None, None]}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABdYAAAN6CAYAAACDghtkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAADIaklEQVR4nOzdd3xO9///8eeVkIREEhGRmEHUjN1Saitiq1W0Vmlrq+Jj1GqJokYprZaiSo0aRbXEqtnWaFB7Ru2VIUYSyfn94Zfr65KEHE2a4HG/3a7bLdc573PO632tJM/rfd7HYhiGIQAAAAAAAAAAkCx2aV0AAAAAAAAAAADPEoJ1AAAAAAAAAABMIFgHAAAAAAAAAMAEgnUAAAAAAAAAAEwgWAcAAAAAAAAAwASCdQAAAAAAAAAATCBYBwAAAAAAAADABIJ1AAAAAAAAAABMIFgHAAAAAAAAAMAEgnUAAJCk3bt3q1KlSnJ2dpbFYlFwcLBGjhwpi8Xyr/f9559/ysHBQSEhISlQafJZLBaNHDnyPz3msywmJkZ58uTRjBkz0rqUNGexWNSzZ8+0LgOpaO7cubJYLDp79qx1WfXq1VW9evU0qyklnT17VhaLRZ999llalwIAAPDMI1gHAKRLM2bMkMViUYUKFdK6lHTH19dXFovFevPy8lKVKlW0YsWKFD1OTEyMWrZsqZs3b2ry5MmaP3++8uXLl2jbwMBArVy50tT+hw4dqjZt2ihfvnzWMOtJN19f33/fsWfEf/2Y7Ny5UyNHjlRYWJjN8owZM6pfv34aM2aM7t27lyLHehphYWFq166dsmbNqgIFCmj27NkJ2uzZs0eZM2fWmTNnTO371KlTeu+991SgQAE5OTnJ1dVVlStX1ueff667d++mVBeghJ9fTk5OKlSokAYMGKCbN2+mdXnpVvPmzVW/fv1E1z36mCZ1mzt37n9b9H8k/suCh2+urq4qXbq0vvjiC8XGxqbasWfMmPHcPq4AAODJMqR1AQAAJGbBggXy9fXVn3/+qZMnT8rPzy+tS0pXSpcurQ8//FCSdPHiRc2cOVNvvPGGvvzyS73//vspcoxTp04pJCRE33zzjbp06WJd/tFHH2nQoEE2bQMDA9WiRQs1bdo0WfsODg7Whg0btHPnTklS1apVNX/+fJs2Xbp00SuvvKJ3333XuszFxeUpe/N/7t69qwwZ0v+fQP/lYyI9CNZHjRqljh07yt3d3WZdp06dNGjQIC1cuFCdO3dOkeOZ1b9/f23ZskWjRo3SyZMn1bVrVxUtWlSVKlWSJBmGod69e6tv377Knz9/svf7888/q2XLlnJ0dFT79u1VokQJRUdHa/v27RowYIAOHTqkr7/+OrW69UJ6+PPr3r172rt3r6ZMmaLffvtNf/75ZxpXl9D69evT9PgxMTEKCgrS2LFjE10/ZcoURUZGWu+vXbtWP/zwgyZPnixPT0/r8vj3yvOqTZs21i8fwsPDtXbtWvXq1UshISGaMGFCqhxzxowZ8vT0VMeOHVNl/wAAIH1L//9VAgBeOGfOnNHOnTu1fPlyvffee1qwYIFGjBjxn9YQFxen6OhoOTk5/afHTa5cuXLprbfest5v3769/Pz8NHny5CSD9fv37ysuLk4ODg7JOsbVq1clKUHImiFDhn8dTM+ZM0d58+ZVxYoVJUkFChRQgQIFbNq8//77KlCggE0/H2W2T5LS7XP6qKd9TFKDu7u76tSpo7lz56ZZsL5mzRqNHz9e7du3lyQdOHBAq1evtoaFCxYsUEhIiIYMGZLsfZ45c0Zvvvmm8uXLp02bNsnHx8e6rkePHjp58qR+/vnnlO0IEnx+denSRS4uLvrss8904sQJFSpUKA2rS8jM50tq2LZtm27duqUGDRokuv7RLzQvX76sH374QU2bNk1wRsvDU9ykB/fu3ZODg4Ps7P79idRly5a1eV11795dFSpU0MKFC1MtWAcAAC82poIBAKQ7CxYsUNasWdWgQQO1aNFCCxYssK6LiYmRh4eHOnXqlGC7iIgIOTk5qX///tZlUVFRGjFihPz8/OTo6Kg8efJo4MCBioqKstk2fu7kBQsWqHjx4nJ0dNSvv/4qSfrss89UqVIlZcuWTZkyZVK5cuX0448/Jjj+3bt31bt3b3l6eipLlixq3LixLly4kOic3hcuXFDnzp2VI0cOOTo6qnjx4vr222+f+jHz9vZW0aJFrVNgPDyP7pQpU1SwYEE5Ojrq8OHDkqRNmzapSpUqcnZ2lru7u5o0aaIjR45Y99exY0dVq1ZNktSyZUtZLBbrHMOPzrFusVh0+/ZtzZs3z3oa/pNG761cuVI1a9Y0NVf74/oUHR2t4cOHq1y5cnJzc5Ozs7OqVKmizZs3J9jPo89HfH9OnjxpHa3t5uamTp066c6dO4+tqWfPnnJxcUm0XZs2beTt7W2dhmDPnj2qW7euPD09lSlTJuXPnz9FQurkvpamTZum4sWLK3PmzMqaNavKly+vhQsXWh+DAQMGSJLy589vfR4fDuFef/11bd++Pc2m67h7966yZs1qve/h4WF93G/fvq1BgwZp7Nixpkbwjx8/XpGRkZo9e7ZNqB7Pz89Pffr0SbB85cqVKlGihPXxjv+siBcSEqLu3burcOHCypQpk7Jly6aWLVsmCDXjp/vZsWOH+vXrp+zZs8vZ2VnNmjXTtWvXbNrGxcVp5MiRypkzpzJnzqwaNWro8OHD8vX1TfB+CwsLU9++fZUnTx45OjrKz89P48aNU1xc3GMfj4YNGyb4Mifeq6++qvLly1vvBwUF6bXXXpO7u7tcXFxUuHBhU19qPMrb21uSbL60O3DggDp27Gidosfb21udO3fWjRs3bLa9deuW+vbtK19fXzk6OsrLy0uvv/669u3bZ9Pujz/+UL169eTm5qbMmTOrWrVq2rFjxxNre3SO9S1btshisWjJkiUaM2aMcufOLScnJ9WqVUsnT55MsP3THjfezz//rGLFiqX4VFhff/219XP05Zdf1u7duxO0OXr0qFq0aCEPDw85OTmpfPnyWrVqVYJ2p0+fVsuWLeXh4aHMmTOrYsWKCb6Uin/cFi1apI8++ki5cuVS5syZFRwcLIvFosmTJyfY786dO2WxWPTDDz+Y7p/FYlGOHDkS/SL4l19+sf4OzJIlixo0aKBDhw7ZtLl8+bI6deqk3Llzy9HRUT4+PmrSpIn1fezr66tDhw7pt99+s35mPi9z8QMAgORhxDoAIN1ZsGCB3njjDTk4OKhNmzb68ssvtXv3br388svKmDGjmjVrpuXLl2vmzJk2IwlXrlypqKgovfnmm5IeBFGNGzfW9u3b9e6776po0aI6ePCgJk+erOPHjyeYE3zTpk1asmSJevbsKU9PT2uI8fnnn6tx48Zq166doqOjtWjRIrVs2VJr1qyxGUHYsWNHLVmyRG+//bYqVqyo3377LdERhleuXFHFihWtYX727Nn1yy+/6J133lFERIT69u1r+jGLiYnRP//8o2zZstksnzNnju7du6d3331Xjo6O8vDw0IYNGxQQEKACBQpo5MiRunv3rqZNm6bKlStr37598vX11XvvvadcuXIpMDBQvXv31ssvv6wcOXIkeuz58+cnmKKkYMGCSdZ64cIFnTt3TmXLljXdz6T6FBERoVmzZqlNmzbq2rWrbt26pdmzZ6tu3br6888/Vbp06Sfut1WrVsqfP7/Gjh2rffv2adasWfLy8tK4ceOS3KZ169aaPn26dTqReHfu3NHq1avVsWNH2dvb6+rVq6pTp46yZ8+uQYMGyd3dXWfPntXy5cuf6jGIl9zX0jfffKPevXurRYsW6tOnj+7du6cDBw7ojz/+UNu2bfXGG2/o+PHjCaaPyJ49u/VY5cqVk2EY2rlzpxo2bPiv6n4aL7/8siZNmqQiRYro9OnT+vXXX/XNN99IejAVUa5cufT222+b2ufq1atVoEABU1NkbN++XcuXL1f37t2VJUsWTZ06Vc2bN9e5c+es77/du3dr586devPNN5U7d26dPXtWX375papXr67Dhw8rc+bMNvvs1auXsmbNqhEjRujs2bOaMmWKevbsqcWLF1vbDB48WOPHj1ejRo1Ut25d7d+/X3Xr1k0w7/2dO3dUrVo1XbhwQe+9957y5s2rnTt3avDgwbp06ZKmTJmSZN9at26t9u3bWz9v44WEhOj333+3jvo9dOiQGjZsqJIlS+rjjz+Wo6OjTp48meywOCYmRtevX5f0YMTyX3/9pUmTJqlq1ao20/gEBQXp9OnT6tSpk7y9va3T8hw6dEi///679Yu5999/Xz/++KN69uypYsWK6caNG9q+fbuOHDli/ZzZtGmTAgICVK5cOY0YMUJ2dnaaM2eOatasqW3btumVV15JVu0P+/TTT2VnZ6f+/fsrPDxc48ePV7t27fTHH39Y26TEcdeuXZvi77mFCxfq1q1beu+992SxWDR+/Hi98cYbOn36tDJmzCjpwfNcuXJl5cqVS4MGDZKzs7OWLFmipk2batmyZWrWrJmkB59DlSpV0p07d9S7d29ly5ZN8+bNU+PGjfXjjz9a28X75JNP5ODgoP79+ysqKkpFihRR5cqVtWDBAn3wwQc2bRcsWKAsWbKoSZMmT+zTnTt3rK+riIgI/fLLL/r11181ePBgm3bz589Xhw4dVLduXY0bN0537tzRl19+qddee01//fWX9Xd/8+bNdejQIfXq1Uu+vr66evWqgoKCdO7cOfn6+mrKlCnq1auXXFxcNHToUElK8vckAAB4ThkAAKQje/bsMSQZQUFBhmEYRlxcnJE7d26jT58+1jbr1q0zJBmrV6+22bZ+/fpGgQIFrPfnz59v2NnZGdu2bbNp99VXXxmSjB07dliXSTLs7OyMQ4cOJajpzp07Nvejo6ONEiVKGDVr1rQu27t3ryHJ6Nu3r03bjh07GpKMESNGWJe98847ho+Pj3H9+nWbtm+++abh5uaW4HiPypcvn1GnTh3j2rVrxrVr14z9+/cbb775piHJ6NWrl2EYhnHmzBlDkuHq6mpcvXrVZvvSpUsbXl5exo0bN6zL9u/fb9jZ2Rnt27e3Ltu8ebMhyVi6dKnN9iNGjDAe/RPC2dnZ6NChw2Prjrdhw4ZEn79HPbrPx/Xp/v37RlRUlM2y0NBQI0eOHEbnzp1tlj/6fMT359F2zZo1M7Jly/bYGuPi4oxcuXIZzZs3t1m+ZMkSQ5KxdetWwzAMY8WKFYYkY/fu3Y/d35M8+pgk97XUpEkTo3jx4o/d94QJEwxJxpkzZxJdf/HiRUOSMW7cuH/Vh6d14MABI3fu3IYkQ5LRvHlzIzY21jh9+rSRKVMmY9euXab2Fx4ebkgymjRpkuxtJBkODg7GyZMnrcv2799vSDKmTZtmXZbYe3jXrl2GJOO7776zLpszZ44hyahdu7YRFxdnXf7BBx8Y9vb2RlhYmGEYhnH58mUjQ4YMRtOmTW32OXLkSEOSzWvik08+MZydnY3jx4/btB00aJBhb29vnDt3Lsn+hYeHG46OjsaHH35os3z8+PGGxWIxQkJCDMMwjMmTJxuSjGvXriW5r6Tky5fP+hw+fKtcuXKC13Fij+MPP/xg894yDMNwc3MzevTokeQx4+LijEKFChl169a1eZzv3Llj5M+f33j99dety+Kfk4ffB9WqVTOqVatmvR//2Vi0aFGbz53PP//ckGQcPHjQ9HGTcvr0aUOSsXnz5ie2jfe493L852i2bNmMmzdvWpf/9NNPCT6Xa9WqZfj7+xv37t2zLouLizMqVapkFCpUyLqsb9++hiSb37W3bt0y8ufPb/j6+hqxsbGGYfzf41agQIEEz+3MmTMNScaRI0esy6Kjow1PT88n/m6J71Nit27dutk89rdu3TLc3d2Nrl272uzj8uXLhpubm3V5aGioIcmYMGHCY49dvHhxm9cGAAB4sTAVDAAgXVmwYIFy5MihGjVqSHpwKnfr1q21aNEi65QaNWvWlKenp81oztDQUAUFBal169bWZUuXLlXRokVVpEgRXb9+3XqrWbOmJCWYJqRatWoqVqxYgpoyZcpkc5zw8HBVqVLFZpqB+KkgunfvbrNtr169bO4bhqFly5apUaNGMgzDpq66desqPDw8wfQFiVm/fr2yZ8+u7Nmzq1SpUlq6dKnefvvtBKOrmzdvbjPq+NKlSwoODlbHjh3l4eFhXV6yZEm9/vrrWrt27ROP/W/FT+Pw8LQeZjzaJ0myt7e3nr0QFxenmzdv6v79+ypfvnyyHk9JCeamr1Klim7cuKGIiIgkt7FYLGrZsqXWrl1rc/HAxYsXK1euXHrttdck/d889WvWrFFMTEyy6nkSM68ld3d3nT9/PtGpHpIr/vmKHxH6X/P399eJEye0e/dunThxQj/++KPs7Oz04Ycfqnnz5qpYsaKWL1+uUqVKKX/+/Pr4449lGEaS+4t/XrNkyWKqjtq1a9uckVGyZEm5urrq9OnT1mUPf2bExMToxo0b8vPzk7u7e6Kvx3fffddmWqQqVaooNjZWISEhkqSNGzfq/v37T/x8kR587lWpUkVZs2a1eU3Url1bsbGx2rp1a5J9c3V1VUBAgJYsWWLz2C1evFgVK1ZU3rx5Jf3f6/mnn3564vQyialQoYKCgoIUFBSkNWvWaMyYMTp06JAaN26su3fvWts9/Djeu3dP169ft16X4eHH0d3dXX/88YcuXryY6PGCg4N14sQJtW3bVjdu3LA+Jrdv31atWrW0devWp+pHp06dbM6aqlKliiRZXwspcdyff/5Zbm5u1s+SlNK6dWubz+BHa79586Y2bdqkVq1a6datW9bab9y4obp16+rEiRO6cOGCpAcj6l955RWbGl1cXPTuu+/q7Nmz1inI4nXo0MHmuZUenDHk5ORkM/XbunXrdP369WRfU+Ldd9+1vq6WLVumHj16aObMmerXr5+1TVBQkMLCwtSmTRub94e9vb0qVKhg/bsgU6ZMcnBw0JYtWxQaGpqs4wMAgBcPU8Ek09atWzVhwgTt3btXly5d0ooVKxJcKOhJDMPQxIkT9fXXXyskJESenp7q3r279dRBAHjRxcbGatGiRapRo4Z1rnDpQQgzceJEbdy4UXXq1FGGDBnUvHlzLVy4UFFRUXJ0dNTy5csVExNjE6yfOHFCR44cSRDCxou/OGe8h6cgeNiaNWs0evRoBQcH28zN/nAQFhISIjs7uwT78PPzs7l/7do1hYWF6euvv9bXX3+drLoSU6FCBY0ePVoWi0WZM2dW0aJFE1xkNLE+xQd1hQsXTtC2aNGiWrdunW7fvi1nZ+cn1vBvPS70fJyknqd58+Zp4sSJOnr0qE14nVT7R8WHhvHiQ6fQ0FC5uromuV3r1q01ZcoUrVq1Sm3btlVkZKTWrl1rnWJBevClTfPmzTVq1ChNnjxZ1atXV9OmTdW2bVs5Ojomq75HmXkt/e9//9OGDRv0yiuvyM/PT3Xq1FHbtm1VuXLlZB8v/vl60rz4ly9fTvY+HxU/z3ZS4ud4jrdp0yatX79ex44d07Fjx/Tmm29q5syZ8vX1VZs2bZQnT55Er8cgyfqc3rp1y1SNj75OpAevlYfDt7t372rs2LGaM2eOLly4YPNaDw8Pf+I+H37tSf/3vn3088TDwyPBF1QnTpzQgQMHkv2596jWrVtr5cqV2rVrlypVqqRTp05p7969NlPItG7dWrNmzVKXLl00aNAg1apVS2+88YZatGiRrItQenp6qnbt2tb7DRo0UOHChdWiRQvNmjXL+oXBzZs3NWrUKC1atChB3Q8/juPHj1eHDh2UJ08elStXTvXr11f79u2t88WfOHFC0oNANynh4eGmv+x70vOWEsf9+eefrb/3UtKTaj958qQMw9CwYcM0bNiwRPdx9epV5cqVSyEhIapQoUKC9UWLFpX04PVbokQJ6/LEPpPd3d3VqFEjLVy4UJ988omkB1+058qVy/pl+JMUKlTI5nX1xhtvyGKxaMqUKercubP1yzlJSe4z/nPB0dFR48aN04cffqgcOXKoYsWKatiwodq3b//EzykAAPDiIFhPptu3b6tUqVLq3Lmz3njjjafaR58+fbR+/Xp99tln8vf3182bN9PsAmAAkB5t2rRJly5d0qJFi7Ro0aIE6xcsWKA6depIkjVA++WXX9S0aVMtWbJERYoUUalSpazt4+Li5O/vr0mTJiV6vDx58tjcf3QEnSRt27ZNjRs3VtWqVTVjxgz5+PgoY8aMmjNnjvXCj2bEj0586623kgxbSpYs+cT9PBpMJSWxPqW1+Hmon3YUYGJ9+v7779WxY0c1bdpUAwYMkJeXl+zt7TV27FidOnUqWfu1t7dPdPmTvgCoWLGifH19tWTJErVt21arV6/W3bt3bb7ksVgs+vHHH/X7779r9erVWrdunTp37qyJEyfq999/N3XBzXhmXktFixbVsWPHtGbNGv36669atmyZZsyYoeHDh2vUqFHJOl788xU//3pSErsIaHKZ+bIlNjZWffr00aBBg5QrVy598sknqlSpkjVIf++997RgwYLHBus5c+bU33//barG5LxOevXqpTlz5qhv37569dVX5ebmJovFojfffDPREcpP+9pLTFxcnF5//XUNHDgw0fUvvfTSY7dv1KiRMmfOrCVLlqhSpUpasmSJ7OzsbK4hkClTJm3dulWbN2/Wzz//rF9//VWLFy9WzZo1tX79+iT78zi1atWS9GAwS3yw3qpVK+3cuVMDBgxQ6dKl5eLiori4ONWrV8/mcWzVqpWqVKmiFStWaP369ZowYYLGjRun5cuXKyAgwNp2woQJSV5v4Wneg0963v7tce/cuaMtW7boyy+/NF3bkyS39v79+6tu3bqJtn30i57kSur3Uvv27bV06VLt3LlT/v7+WrVqlbp3756sL2uSUqtWLX3xxRfaunWr/P39rf2aP39+ogH5w19g9O3bV40aNdLKlSu1bt06DRs2TGPHjtWmTZtUpkyZp64JAAA8PwjWkykgIEABAQFJro+KitLQoUP1ww8/KCwsTCVKlNC4ceOsV4Y/cuSIvvzyS/3999/WUYLJHUEHAC+KBQsWyMvLS9OnT0+wbvny5VqxYoW++uorZcqUSVWrVpWPj48WL16s1157TZs2bUpwBlDBggW1f/9+1apV64mjbJOybNkyOTk5ad26dTYji+fMmWPTLl++fIqLi9OZM2dUqFAh6/KTJ0/atMuePbuyZMmi2NjYZAXjKS1fvnySpGPHjiVYd/ToUXl6ej7VaHUzj2+RIkUkyeashH/rxx9/VIECBbR8+XKbWkaMGJFix3icVq1a6fPPP1dERIQWL14sX19f65QVD6tYsaIqVqyoMWPGaOHChWrXrp0WLVqkLl26mD6m2deSs7OzWrdurdatWys6OlpvvPGGxowZo8GDB8vJyemJz2H88xU/CjUpQUFBye/Ev/Dll1/q1q1b6t+/vyTp4sWLypkzp3V9zpw5rVNVJKVhw4b6+uuvtWvXLr366qspVtuPP/6oDh06aOLEidZl9+7dU1hY2FPtL/59e/LkSZu/H2/cuJHgC6qCBQsqMjLyqT9fnJ2d1bBhQy1dulSTJk3S4sWLVaVKFZvHVpLs7OxUq1Yt1apVS5MmTVJgYKCGDh2qzZs3P9Wx79+/L0nWKZVCQ0O1ceNGjRo1SsOHD7e2ix9x/CgfHx91795d3bt319WrV1W2bFmNGTNGAQEB1ql7XF1d/9PP3X973E2bNikqKuqx/4OklvjR/hkzZnxi7fny5Uvyd0r8+uSoV6+esmfPrgULFqhChQq6c+eO6QsSP+rR11X8c+Ll5ZWs56RgwYL68MMP9eGHH+rEiRMqXbq0Jk6cqO+//16Sud99AADg+cMc6ymkZ8+e2rVrlxYtWqQDBw6oZcuWqlevnvWP/9WrV6tAgQJas2aN8ufPL19fX3Xp0oUR6wDw/929e1fLly9Xw4YN1aJFiwS3nj176tatW1q1apWkB6FOixYttHr1as2fP1/379+3GSEsPQg7L1y4oG+++SbR492+ffuJddnb28tisVjnd5eks2fPauXKlTbt4kf0zZgxw2b5tGnTEuyvefPmWrZsWaIjZa9du/bEmv4NHx8flS5dWvPmzbMJ+f7++2+tX79e9evXf6r9Ojs7Jzs0zJUrl/LkyaM9e/Y81bESEz/68uERvn/88Yd27dqVYsd4nNatWysqKkrz5s3Tr7/+qlatWtmsDw0NTTD6OH4E68PTC5lh5rUUP699PAcHBxUrVkyGYVinzYn/QiWp53Hv3r2yWCxPDKBr16791LfkunnzpkaMGKEJEybIyclJkpQjRw5rkCc9GNTwpCkbBg4cKGdnZ3Xp0kVXrlxJsP7UqVP6/PPPk11XPHt7+wTP97Rp02w+R8yoVauWMmTIkGDk8hdffJGgbatWrbRr1y6tW7cuwbqwsDBr0Pg4rVu31sWLFzVr1izt378/wWdrYn+//tvX8+rVqyXJetZRYu9pSTZT0kgPzlx4dHodLy8v5cyZ01pLuXLlVLBgQX322Wc210KIl1qfu//2uGvXrlX58uWVI0eOVKnvcby8vFS9enXNnDlTly5dSrD+4drr16+vP//80+bz9vbt2/r666/l6+ub6LVLEpMhQwa1adNGS5Ys0dy5c+Xv75+sM7ge59HXVd26deXq6qrAwMBEr3cR3687d+7o3r17NusKFiyoLFmy2LzGzfzuAwAAzx9GrKeAc+fOac6cOTp37px1NE///v3166+/as6cOQoMDNTp06cVEhKipUuX6rvvvlNsbKw++OADtWjRQps2bUrjHgBA2lu1apVu3bqlxo0bJ7q+YsWK1pFs8SFP69atNW3aNI0YMUL+/v4JRtK+/fbbWrJkid5//31t3rxZlStXVmxsrI4ePaolS5Zo3bp1NvM1J6ZBgwaaNGmS6tWrp7Zt2+rq1auaPn26/Pz8dODAAWu7cuXKqXnz5poyZYpu3LihihUr6rffftPx48cl2Y5q+/TTT7V582ZVqFBBXbt2VbFixXTz5k3t27dPGzZsSPUvXSdMmKCAgAC9+uqreuedd3T37l1NmzZNbm5uGjly5FPts1y5ctqwYYMmTZqknDlzKn/+/InOuRuvSZMmWrFihQzDSJERfw0bNtTy5cvVrFkzNWjQQGfOnNFXX32lYsWKJRpopbSyZcvKz89PQ4cOVVRUVIIgct68eZoxY4aaNWumggUL6tatW/rmm2/k6ur61F9mSMl/LdWpU0fe3t6qXLmycuTIoSNHjuiLL75QgwYNrBfvLFeunCRp6NChevPNN5UxY0Y1atTIGrgHBQWpcuXK1ql80tKwYcPk7+9vMz1J8+bN9fHHH6tbt27Kly+fZs6cmeQ0UPEKFiyohQsXqnXr1ipatKjat2+vEiVKKDo6Wjt37tTSpUvVsWNH0/U1bNhQ8+fPl5ubm4oVK6Zdu3Zpw4YNT/3Y5ciRQ3369NHEiRPVuHFj1atXT/v379cvv/wiT09Pm/fQgAEDtGrVKjVs2FAdO3ZUuXLldPv2bR08eFA//vijzp49+8TpfOrXr68sWbKof//+1i9wHvbxxx9r69atatCggfLly6erV69qxowZyp07d7IusnnhwgXriN/o6Gjt379fM2fOlKenp3UaGFdXV1WtWlXjx49XTEyMcuXKpfXr1yc40+XWrVvKnTu3WrRooVKlSsnFxUUbNmzQ7t27rWcM2NnZadasWQoICFDx4sXVqVMn5cqVSxcuXNDmzZvl6upqDWBT0r897tq1a5Ocyui/MH36dL322mvy9/dX165dVaBAAV25ckW7du3S+fPntX//fknSoEGD9MMPPyggIEC9e/eWh4eH5s2bpzNnzmjZsmWmpnJp3769pk6dqs2bNye4GPeT7Nu3z/q6unXrljZu3Khly5apUqVK1mnkXF1d9eWXX+rtt99W2bJl9eabbyp79uw6d+6cfv75Z1WuXFlffPGFjh8/rlq1aqlVq1YqVqyYMmTIoBUrVujKlSt68803rccsV66cvvzyS40ePVp+fn7y8vJK9pzwAADgOWDANEnGihUrrPfXrFljSDKcnZ1tbhkyZDBatWplGIZhdO3a1ZBkHDt2zLrd3r17DUnG0aNH/+suAEC606hRI8PJycm4fft2km06duxoZMyY0bh+/bphGIYRFxdn5MmTx5BkjB49OtFtoqOjjXHjxhnFixc3HB0djaxZsxrlypUzRo0aZYSHh1vbSTJ69OiR6D5mz55tFCpUyHB0dDSKFClizJkzxxgxYoTx6K/R27dvGz169DA8PDwMFxcXo2nTpsaxY8cMScann35q0/bKlStGjx49jDx58hgZM2Y0vL29jVq1ahlff/31Ex+rfPnyGQ0aNHhsmzNnzhiSjAkTJiS6fsOGDUblypWNTJkyGa6urkajRo2Mw4cP27TZvHmzIclYunSpzfLE+n706FGjatWqRqZMmQxJRocOHR5b3759+wxJxrZt25Js4+zsbLOfx/UpLi7OCAwMNPLly2c4OjoaZcqUMdasWWN06NDByJcvn01bScaIESMS9OfatWs27ebMmWNIMs6cOfPYvsQbOnSoIcnw8/NLtL9t2rQx8ubNazg6OhpeXl5Gw4YNjT179iRr3/EefUwMI3mvpZkzZxpVq1Y1smXLZjg6OhoFCxY0BgwYYPMeMAzD+OSTT4xcuXIZdnZ2Nn0PCwszHBwcjFmzZpmqNzUcOHDAcHBwMP76668E6+bOnWv4+voa2bJlM/r162fcv38/Wfs8fvy40bVrV8PX19dwcHAwsmTJYlSuXNmYNm2ace/ePWu7pD4n8uXLZ/O8hIaGGp06dTI8PT0NFxcXo27dusbRo0cTtIt/je3evdtmf/Hvvc2bN1uX3b9/3xg2bJjh7e1tZMqUyahZs6Zx5MgRI1u2bMb7779vs/2tW7eMwYMHG35+foaDg4Ph6elpVKpUyfjss8+M6OjoZD0m7dq1MyQZtWvXTrBu48aNRpMmTYycOXMaDg4ORs6cOY02bdoYx48ff+J+8+XLZ0iy3uzs7AwvLy+jTZs2xsmTJ23anj9/3mjWrJnh7u5uuLm5GS1btjQuXrxo8x6OiooyBgwYYJQqVcrIkiWL4ezsbJQqVcqYMWNGgmP/9ddfxhtvvGF9H+TLl89o1aqVsXHjRmubxN731apVM6pVq2a9n9RnY/xn1Jw5c0wf91F///23Icn4888/n/CIJjRhwoQkP7se9zn66GejYRjGqVOnjPbt2xve3t5GxowZjVy5chkNGzY0fvzxxwTtWrRoYbi7uxtOTk7GK6+8YqxZs8amTVKP26OKFy9u2NnZGefPn09Wf+P79PAtQ4YMRoECBYwBAwYYt27dSrDN5s2bjbp16xpubm6Gk5OTUbBgQaNjx47Wz+Tr168bPXr0MIoUKWI4Ozsbbm5uRoUKFYwlS5bY7Ofy5ctGgwYNjCxZshiSbF4nAADg+WcxjKe4KtILzmKxaMWKFWratKkkafHixWrXrp0OHTqU4EJALi4u8vb21ogRIxKccnj37l1lzpxZ69ev1+uvv/5fdgEA8B8JDg5WmTJl9P3336tdu3ZpXU66UqtWLeXMmVPz589P61LwBFOmTNH48eN16tSpdHlB3BdVWFiYsmbNqtGjRye4xgSebePHj9ekSZN06dKlF24e7zJlysjDw0MbN25M61IAAAAeiznWU0CZMmUUGxurq1evys/Pz+YWP7dn5cqVdf/+fZ06dcq6Xfz0AMm9oA8AIH27e/dugmVTpkyRnZ2dqlatmgYVpW+BgYFavHixQkJC0roUPEZMTIwmTZqkjz76iFA9DSX1+SJJ1atX/2+LQarz9fXV5MmTX7hQfc+ePQoODlb79u3TuhQAAIAnYsR6MkVGRurkyZOSHgTpkyZNUo0aNeTh4aG8efPqrbfe0o4dOzRx4kSVKVNG165d08aNG1WyZEk1aNBAcXFxevnll+Xi4qIpU6YoLi5OPXr0kKurq9avX5/GvQMApIRRo0Zp7969qlGjhjJkyKBffvlFv/zyi959913NnDkzrcsD8AybO3eu5s6dq/r168vFxUXbt2/XDz/8oDp16iR6oVLgWfL3339r7969mjhxoq5fv67Tp09bL0wMAACQXhGsJ9OWLVtUo0aNBMs7dOiguXPnKiYmRqNHj9Z3332nCxcuyNPTUxUrVtSoUaPk7+8vSbp48aJ69eql9evXy9nZWQEBAZo4caI8PDz+6+4AAFJBUFCQRo0apcOHDysyMlJ58+bV22+/raFDhypDBq4XDuDp7du3TwMHDlRwcLAiIiKUI0cONW/eXKNHj5aLi0talwf8KyNHjtTHH3+swoUL66uvvlK1atXSuiQAAIAnIlgHAAAAAAAAAMAE5lgHAAAAAAAAAMAEgnUAAAAAAAAAAExgwtcniIuL08WLF5UlSxZZLJa0LgcAAAAAAAB4IRmGoVu3bilnzpyys2O8MNIWwfoTXLx4UXny5EnrMgAAAAAAAABI+ueff5Q7d+60LgMvOIL1J8iSJYukB29YV1fXNK4GAAAAAAAAeDFFREQoT5481rwOSEsE608QP/2Lq6srwToAAAAAAEgXOnbsqIULF8rBwcG6LCgoSK+++mqi7WNiYvTBBx9owYIFslgsateunSZPnqwMGR5EQ1OmTFFgYKBcXV317bffqmrVqpKksLAwVa5cWVu2bFH27NlTv2NAMjBdM9IDJiMCAAB4gdy9e1d+fn5yd3dPdP25c+fk4uJic8uQIYMaN25sbTNgwAB5eHioVKlSOnz4sHX56dOnVbp0ad27dy+1uwEAACR1795dkZGR1ltSobokjR49Wtu3b9fhw4d16NAhbdu2TYGBgZKky5cva/To0dq/f78mTZqkHj16WLf73//+p/79+xOqA8AjCNYBAABeIMOHD1e+fPmSXJ83b16bf9Bv3rwpd3d3vfnmm5Kk3bt3a+XKlTp79qzeeecd/e9//7Nu2717d02aNElOTk6p3g8AAGDOt99+q48++kg+Pj7y8fHR0KFDNXv2bElSSEiIChUqJB8fH9WpU0enTp2SJO3YsUMnTpxQp06d0rJ0AEiXCNYBAABeEHv37tWvv/5qE4Y/ycqVKxUXF6c33nhD0oNR6eXLl5erq6vNP94LFy6Ut7e3atasmSq1AzDvSWeoPOzKlSvy8PBQ6dKlrctiY2P19ttvy93dXa+99pouXrxoXbdz505Vr15dhmGkQuUAkuu7776Th4eHihcvrokTJyouLi7RdqGhoTp//rzNe7x06dI6d+6cwsPDVahQIZ05c0bnz59XUFCQ/P39FRMTo969e+urr776j3oDAM8W5lgHAAB4Ady/f19du3bV9OnTk/ynOzGzZ89Wu3btrKPQS5QooY8++khhYWHasGGD/P39FRoaqsDAQP3222+pVT6ApxB/hsr169ef2LZnz54qU6aMbty4YV22fPlynT17VleuXNGQIUM0duxYTZs2TTExMerVq5d1nmYAaaN3796aMGGCPDw8tHv3brVq1Up2dnb64IMPErSNjIyUJJsv2uJ/vnXrlnLnzq1p06apadOmcnV11axZszRu3Dg1bdpUMTExCggI0N27d9WnTx81a9bsv+gegKcUGxurmJiYtC7jmZUxY0bZ29snqy3BOgAAwAtgwoQJKlOmjKpWraotW7Yka5uQkBBt2LBB48ePty4rXry4+vTpo+rVqytPnjyaMWOGBgwYoP/97386fPiwRowYIYvFolGjRum1115Lpd4AeJL4M1QmTpyoVq1aPbbtTz/9pJs3b+rtt9/WlClTrMtPnz6t1157TY6Ojnr99dc1depUSQ8+Txo1aqQiRYqkZhcAPEHZsmWtP1esWFGDBg3Sd999l2iw7uLiIkkKDw+Xp6en9WdJypIliySpZcuWatmypSTpxIkTWr58uX7//XdVrVpV48ePl7+/v0qWLKnq1asra9asqdo3AOYZhqHLly8rLCwsrUt55rm7u8vb2/uJAwgI1gEAAJ5zJ0+e1FdffaW//vrL1HZz5sxRmTJlVKpUKZvlPXv2VM+ePSVJW7du1blz59SuXTvly5dPv/32mwzDUM2aNXX27FlGswJpwMwZKuHh4erXr59+/fVX7dixw2adv7+/AgMDdffuXW3cuFH+/v46efKkli5dqt9//z01uwDgKdjZJT3bb9asWZU7d24FBwerYMGCkqTg4GDlyZNHbm5uCdp369ZNU6dOlYODg/bv368KFSrI0dFRuXPn1okTJ/TKK6+kWj8APJ34UN3Ly0uZM2fm7/CnYBiG7ty5o6tXr0qSfHx8HtueOdYB4AXXq1cv5cmTR66ursqVK5f69u2r6OjoJNvPmjVLhQsXlrOzs3x9ffXTTz9JYh5WID3bvn27rly5opdeekmenp5q0qSJIiIi5OnpqT/++CPRbeLi4jRnzhx16dIlyf1GR0erb9++mjFjhq5du6b79++rQIECKliwoKKjo3Xt2rXU6hKAx3j4DJUnGThwoDp27KhChQolWFe/fn1Vr15dFSpU0IULFzRo0CB1795dn3/+udasWaPq1asrICBAR44cSY1uAHiCJUuWKCIiQoZhaM+ePfr000/VvHnzJNt36tRJY8aM0eXLl3X58mUFBgYm+nt+3rx5KliwoPXMswIFCigoKEgXL17UiRMnHnsRdABpIzY21hqqZ8uWTZkyZZKTkxM3k7dMmTIpW7Zs8vLyUlhYmGJjYx/7uDNiHQBecN27d9enn34qZ2dnXb9+XS1bttT48eP10UcfJWj79ddfa/LkyVq0aJFKly6tq1ev6vbt25KYhxVIz1q1aqXatWtb7+/atUtdunRRcHCwvLy8Et0mKChI169fV5s2bZLc79ixY9WyZUv5+fkpNjZWUVFR2r9/vywWi6Kjo5UtW7YU7wuAxzNzhsq2bdu0Y8cO7du3L8k2o0eP1ujRoyVJ8+fPV968eVWiRAmVLFlSBw8e1P79+9W5c2ft2rUrxfoAIHm++OILvfvuu7p//75y5cql7t2768MPP7Suf//99yXJevHRYcOG6caNGypatKgk6a233tKQIUNs9nn9+nVNmDBB27dvty6bPn26OnfurMjISI0YMUI5cuRI7a4BMCl+TvXMmTOncSXPh/jHMSYm5rHzrROsA8ALLv4Pa+nBaU92dnY6ceJEgnaxsbEaPny4vvvuO5UpU0aSbP6oZh5WIP3KnDmzzR/Z2bNnl8ViUe7cuSVJAQEBqlKlis0/17Nnz1aLFi0SPT1cko4dO6bVq1dbwzR7e3t9+eWXCggIkMVi0cyZM5N90R8AKefhM1SkB/8Q3rp1S56envr5559VoUIFa9uNGzfq9OnTypkzpyQpKipKd+/elaenpw4ePGhz+vONGzc0btw4bdu2TcePH1eePHmUNWtWvfrqq9q/f/9/20kAkh5Mx/Y48YF6vIwZM2r69OmaPn16ktt4enrq77//tllWvXp1nT59+ukLBfCfYTBbykju42gxOC//sSIiIuTm5qbw8HC5urqmdTkAkCo+/fRTjR49Wrdv31a2bNn066+/qnz58jZtDh8+rOLFi2vs2LH66quvdP/+fQUEBGjixIlydXXV2rVrFRgYqKCgIA0fPlx2dnbq2rWrWrZsqd9//12Ojo5p1DsAAF4cd+7c0c2bN633489QOXTokLy8vOTg4GBdFxERoYiICOv9pUuXatasWVq3bp18fHxsvhzr1KmT6tSpozZt2ujy5csqXry4Dhw4oL/++kuDBw/WwYMH/5sOAgBeaOR0ibt3757OnDmj/Pnzy8nJKa3LeeYl9/FkjnUAgAYNGqTIyEgdPnxY77//vry9vRO0if8nfcOGDdqzZ4+Cg4N15swZffDBB5KYhxUAgPQgc+bMyp07t/X28BkqDg4OCggIUGBgoCTJ1dXVpm3WrFmVMWNG5c6d2yZU37Jliy5fvmydGsrb21vDhg1T6dKl1adPn8eOfgUAAHheMWL9CfgmDMCLZunSpZo5c6Y2bNhgszw4OFhlypTRhg0bVKtWLUkPTiFv06aN9YrZD5s/f75+++03jR8/3mYe1sGDBzMPKwAAAADANHK6xKXEiPWOHTtq3rx5kqQMGTLIw8NDJUuWVJs2bdSxY0fZ2SVvfPbcuXPVt29fhYWFPVUdT6tjx44KCwvTypUr//W+GLEOAHgqMTExic6xXrhw4WT/go6fh3XChAk6ceIE87ACAAAAAJDO1atXT5cuXdLZs2f1yy+/qEaNGurTp48aNmyo+/fvp3V56Q7BOgC8wCIjIzVnzhyFhYXJMAwdPHhQo0ePVt26dRO0zZQpk9566y2NGzdOoaGhCgsL07hx49SkSZMEbfv376+hQ4cqa9asypcvn44fP64LFy4oKChIBQsW/C+6BgAAADxXFi1apFatWqV1GYqNjZW/vz9TPALPIUdHR3l7eytXrlwqW7ashgwZop9++km//PKL5s6dK0maNGmS/P395ezsrDx58qh79+6KjIyU9GD6uE6dOik8PFwWi0UWi0UjR46U9OCs9vLlyytLlizy9vZW27Ztbc5+Dw0NVbt27ZQ9e3ZlypRJhQoV0pw5c6zr//nnH7Vq1Uru7u7y8PBQkyZNdPbsWUnSyJEjNW/ePP3000/W427ZsiXVHy+CdQB4gVksFi1cuFAFCxZUlixZ1KRJEzVo0EBTpkyRJJt5WCVpypQpypkzp/Lnz6/ChQsrX758mjRpks0+mYcVSFvp5Z/uxIwZM0ZDhw5N6zIAAHjmxMXFaciQIRo2bJikB9NhtG3bVq6ursqRI4c++eSTx27/pPYDBgyQh4eHSpUqpcOHD1uXnz59WqVLl9a9e/esy+zt7dW/f38NGTIkBXsIIL2qWbOmSpUqpeXLl0uS7OzsNHXqVB06dEjz5s3Tpk2bNHDgQElSpUqVNGXKFLm6uurSpUu6dOmS+vfvL+nB2fGffPKJ9u/fr5UrV+rs2bPq2LGj9TjDhg3T4cOH9csvv+jIkSP68ssv5enpad22bt26ypIli7Zt26YdO3bIxcVF9erVU3R0tPr3769WrVpZR9xfunRJlSpVSv0Hx8BjhYeHG5KM8PDwtC4FAADgsWJjY438+fMbBw4cSLLNihUrDD8/PyNTpkxG5cqVjSNHjiTZdu3atUaJEiUMd3d3I2vWrEbt2rVt9r1582ajQIECRvbs2Y2pU6fabFuvXj1jw4YNNstu3bpleHl5GZcuXXrKHgIA8GJavXq1Ua5cOev99u3bG3Xr1jVCQ0ONY8eOGXny5DHmzZuX5PaPa//nn38afn5+Rnh4uPH5558bDRs2tG5Xt25dY+PGjQn2FxkZaWTJksUICQlJwV4CT0ZOl7i7d+8ahw8fNu7evfvU++jQoYPRpEmTRNe1bt3aKFq0aKLrli5damTLls16f86cOYabm9sTj7d7925DknHr1i3DMAyjUaNGRqdOnRJtO3/+fKNw4cJGXFycdVlUVJSRKVMmY926dU+s36zkPp6MWAcAAHhOrF27Vh4eHvL39090/bFjx9SuXTtNnjxZN2/eVM2aNdWkSZMk50ssXbq01q9fr9DQUF29elUNGjRQs2bNrOt79OihL774Qvv27dPIkSN15coVSdIPP/wgLy8v64WO47m4uCggIECzZ89OoR4DLzbOUAFeHKtWrVLNmjUlSXfu3NGiRYs0evRoubu766WXXlKvXr2S/P36pPanT59W+fLl5erqqjp16ujUqVOSpIULF8rb29t63Ic5Ozvr5Zdf1s8//5xKPQaQnhiGIYvFIknasGGDatWqpVy5cilLlix6++23dePGDd25c+ex+9i7d68aNWqkvHnzKkuWLKpWrZok6dy5c5Kkbt26adGiRSpdurQGDhyonTt3Wrfdv3+/Tp48qSxZssjFxUUuLi7y8PDQvXv3rJ9ZaYFgHQAA4Dnx8D/difn+++9Vo0YNNWzYUE5OTho2bJiuXr2qbdu2Jdrex8dHPj4+kh78MW1vb6+zZ88qJiZG0oN/xGvWrKncuXOrUKFCCgkJUWhoqEaPHq2JEycmus9atWpp1apV/7KnAB6dFiIxK1euVKFChZQ5c2a99tprOnr06GP3ef78ebVs2VLu7u5yd3e3uebKli1bVLBgQXl5eWnatGk22wUEBGjjxo02y/r06aNZs2bp8uXLT9E7AI8KDg5WkSJFJD34ojw6OlqlS5e2ri9durQOHDiQ6LZPal+iRAnt2bNHYWFh2rBhg/z9/RUaGqrAwMAkf59LUrFixRQcHPyv+wYg/Tty5Ijy58+vs2fPqmHDhipZsqSWLVumvXv3Wqd7jY6OTnL727dvq27dunJ1ddWCBQu0e/durVixwma7gIAAhYSE6IMPPtDFixdVq1Yt6zQykZGRKleunIKDg21ux48fV9u2bVO590kjWAcAAHhOPPxPd2IOHDhg8091xowZVaxYsST/EZcejCBxd3eXk5OT+vTpo8GDBytjxoySJH9/f61fv17nz59XSEiI/Pz8NHDgQA0cONA6H+Kj+CccSBkpfYbK7du3VaNGDZUqVUr//POPrl+/rtGjR1vXc4YKkLZCQ0Pl6uoq6UHA5OzsrAwZMljXu7u769atW4lu+6T2xYsXV58+fVS9enWtW7dOn332mQYMGKD//e9/Onz4sGrWrKlatWpp+/btNvt1dXVVaGhoSncVQDqzadMmHTx4UM2bN9fevXsVFxeniRMnqmLFinrppZd08eJFm/YODg6KjY21WXb06FHduHFDn376qapUqaIiRYrYXLg0Xvbs2dWhQwd9//33mjJlir7++mtJUtmyZXXixAl5eXnJz8/P5ubm5pbkcVMbwToAAMBz4uF/uhMTGRkpd3d3m2WP+0dckvLmzauwsDCFhYVp6tSpKl++vHXd7NmzNXnyZDVt2tR6AaOzZ8+qSZMmevvtt1W1alWNGjXKZn+urq6Kjo5+4qmiAB4vpc9QmTt3rjw9PfXRRx8pS5YsypAhg15++WXres5QAdJW1qxZFRERIenBF1d37tyx+aIsPDxcWbJkSXTb5LTv2bOngoODtXr1ap05c0bnzp1Tu3bt1LZtW82aNUtff/212rVrJ8MwrNtEREQoa9asKd1VAGkoKipKly9f1oULF7Rv3z4FBgaqSZMmatiwodq3by8/Pz/FxMRo2rRpOn36tObPn6+vvvrKZh++vr6KjIzUxo0bdf36dd25c0d58+aVg4ODdbtVq1YluIjy8OHD9dNPP+nkyZM6dOiQ1qxZo6JFi0qS2rVrJ09PTzVp0kTbtm3TmTNntGXLFvXu3Vvnz5+3HvfAgQM6duyYrl+/bj3LNjURrAPACyA9z8HatWtXffPNN2ldBvBcePif7sDAQOv8gwEBAZIe/GMdHh5us83j/hF/WJYsWdS9e3d16tRJZ86ckfRgxPqmTZu0Z88eNWnSRH369NGMGTP06aefqlChQtqyZYt+++03rVu3zrqfiIgIOTg4KHPmzCnVbeCFlNJnqPz222/KnTu3AgIC5OHhoXLlymnt2rXW9ZyhAqSt0qVLW6dzKly4sDJmzKj9+/db1wcHByd5BouZ9tHR0erbt69mzJiha9eu6f79+ypQoIAKFiyo6OhoXbt2zdr28OHDNp8zAJ59v/76q3x8fOTr66t69epp8+bNmjp1qn766SfZ29urVKlSmjRpksaNG6cSJUpowYIFGjt2rM0+KlWqpPfff1+tW7dW9uzZNX78eGXPnl1z587V0qVLVaxYMX366af67LPPbLZzcHDQ4MGDVbJkSVWtWlX29vZatGiRJClz5szaunWr8ubNqzfeeENFixbVO++8o3v37lkHFnXt2lWFCxdW+fLllT17du3YsSP1H7AUuVTqc4yrDQN41sXGxhr58+c3Dhw4kOj6gwcPGnXq1DGyZctmSDJCQ0Mfu79vv/3WeOmllwxXV1cjW7ZsRrNmzYyQkBDr+kWLFhk5c+Y0cubMaSxdutS6PDo62ihXrpxx+PBhm/2dOXPG8PHxMe7du/f0nQRgGIZhdO3a1RgwYECS6z/66COjYcOG1vvR0dFG1qxZjY0bNyZr//fv3zcyZcpkbNq0KcG6UaNGGaNHjzYMwzDq1atn/Prrr4ZhGMagQYOMcePGWdt99913xiuvvJKs4wFImp+fn83v2UfVrFnTmDBhgs2y+vXrG5988kmi7WvVqmXY2dkZK1asMKKjo40VK1YYmTJlMk6cOGEYhmEcOHDAqFGjhlGuXDljyZIlxtatW43atWsboaGhxltvvWVUqVLFGDlypM0+jx8/bkgybt++/S97C2DVqlVG+fLlrffffvttIyAgwAgLCzOOHz9u5M2b15g3b16S2ye3/ciRI43AwEDDMB783s+aNasRHBxs7N+/3/Dw8DDu379vGIZh3L5928iSJYtx9uzZFO4p8HjkdIm7e/eucfjwYePu3btpXcpzIbmPJyPWAeA596Q5WDNmzKhWrVpp7ty5ydpfzZo1tWPHDoWHh+v8+fMqWLCgOnfuLEmKjY1Vt27dtG7dOv3888967733rHOcffbZZ2rQoIH1VK54vr6+eumll/Tjjz8+fScBSJIaNWqkzZs3J7n+rbfe0qZNm7R27VpFRUVpzJgx8vT0VNWqVRNtv2jRIp08eVJxcXEKCwtTnz595OzsrLJly9q0O378uFatWqWBAwdKkgoUKKANGzYoKipKW7duVcGCBa1tN23apIYNG6ZAb4EXW0qfoeLi4qJKlSqpadOmypgxo5o2bapy5cpp/fr1kjhDBUhr9evX1/Xr1/X3339Lkr744gu5ubkpd+7cqly5st555x21b9/e2j4gIECBgYHW+09qLz24NsPq1autFwu0t7fXl19+qYCAAAUEBGjmzJmyt7eXJC1btkw1atRQvnz5UrvrAJBuZXhyEwDAs+xJc7AWLlxYhQsX1tmzZ5O1v4f/eDYMQ3Z2djpx4oQk6fr163J0dFSJEiUkPQjtb9y4oVu3bmnJkiX6/fffE91n/Bys7dq1S2avACSmfv366t27t/7++2/r+/BhhQsX1vfff68+ffro/PnzKlu2rFatWmW9mNm2bdsUEBCgyMhISdLZs2c1ePBgXb16Vc7OznrllVcUFBRkvUBQvG7dumnq1KnWi5oOHjxYrVu3Vo4cOdSkSRM1bdpU0oOLI65du5apIYAU8PC0EEOGDNGQIUNs1pcsWdLmvRYTE6PDhw8n+UV7qVKltGnTpmQd+9NPP1Xz5s1VqFAh7d+/X3379pWdnZ0qVKig/fv3q27dupKYJgJISfb29goMDNQnn3yixYsXy9XVVT/88EOS7X/55Reb+09qLz34O2HPnj02y1q3bq3WrVvbLIuLi9OECROsUzQAwIuKEesA8Jx70hysT2P79u1yd3dX5syZNWnSJA0dOlTSgyt429nZaf/+/dq/f7/s7e3l6empbt26afLkyXJ0dEx0f8zBCqSMh//pTkqzZs104sQJ3b17Vzt27LD5fKhSpYo1VJekQYMG6cyZM7p9+7auXr2qNWvWJBqSbdy4UZUqVbLez507t3bs2KGwsDDNmzfPOrrt888/V5cuXeTj45MCvQVebCl9hkr79u21b98+rVmzRnFxcVqzZo327dtnDcnjcYYKkHbatGmjxYsXp3UZsrOz04EDB1SsWLG0LgUA0hTBOhIVExOjnj17KmvWrPLw8FCvXr1sriBupu2UKVPk5eUlPz8/bd261bo8LCxMxYsXt7n4CYCUFxoaar2YR0p57bXXFBYWpmvXrumTTz6x/lFtZ2enBQsWqFu3burWrZsWLFighQsXKk+ePPLz81OzZs1UrVq1BFcNd3V1VWhoaIrWCLyo0ss/3YkZMmSIxowZk9ZlAM+FR6eFeNTDZ6i4u7srKCgowRkqLi4u1vYFCxbUjz/+qIEDB8rV1VUfffSRli1bZhOUS4mfobJz507lyJFDfn5+Cc5Q6dKlSyr0HgAAIO1ZDMMw0rqI9CwiIkJubm4KDw9P8WAqPRsxYoR++ukn6+ljAQEBeuONNzR8+HBTbS9fvqwSJUro4MGD2r17t4YOHaqDBw9Kkt577z1VrFhRnTp1+u86BryAXnnlFb3//vvq3LmzAgMDrXMtVqlSxeYU0bNnzyp//vwKDQ2Vu7t7svd/7do1FSpUSBcuXJCzs7PNups3b6pq1araunWrunfvrvr166tVq1YqW7asli1bZp1vfdmyZRoyZIiOHTv27zsMAMAL4ocfftDKlSvT5ZdpgYGBun37Nl+mAQBS1Iua0z3JvXv3dObMGeXPn19OTk5pXc4zL7mPJyPWkahvv/1WH330kXx8fOTj46OhQ4dq9uzZptuGhISoUKFC8vHxUZ06dXTq1ClJ0o4dO3TixAlCdeA/8OgcrJGRkYqMjEww7+LTiomJUXh4uK5evZpgXf/+/TV48GB5eHho//79qlChgpycnFSqVCnrl2wSc7ACAPA0OEMFAAAg7RCsI4HQ0FCdP3/eJuQqXbq0zp07p/DwcFNtCxUqpDNnzuj8+fMKCgqSv7+/YmJi1Lt37wRTQQBIHU+ag9UwDN27d09RUVGSpKioKN27d09JndA0Z84cnT9/XoZh6PLly+rdu7deeukl+fr62rTbsmWLLl68aL0gaYECBRQUFKSIiAj9+eefzMEKAAAAAACeWQTrSCD+omUPTwUR//OtW7dMtfXw8NC0adPUtGlTTZ48WbNmzdK4cePUtGlTxcTEKCAgQNWrV9eKFStSrT/Ai+5Jc7CGhIQoU6ZM1gsYent7K1OmTAoJCZEkLViwQMWLF7e2Dw4OVoUKFeTi4qKyZcsqY8aM+uWXX2SxWKxtoqKi1K9fP82YMcO6bNy4cZo5c6Z8fX3VsmVLlStXznr8o0ePqmXLlinedwAAAAAAgNTAHOtP8CLO3RQaGioPDw+dPHnSOqL05MmTKlSokMLCwuTm5vZUbSXpxIkTat26tX7//XdVrVpV48ePl7+/v0qWLKkDBw4oa9as/11HgRdIep6D9d1339XLL7+srl27pnUpAAAAAIB07EXM6ZKDOdZTFnOs46llzZpVuXPnVnBwsHVZcHCw8uTJkyAoN9NWkrp166apU6fKwcHBOt9y/D5OnDiRWl0CXnjpeQ7Wr7/+mlAdAAAAAACkCF9fX02ZMiXVj5Mh1Y+AZ1KnTp00ZswYVa5cWZIUGBioLl26/Ku28+bNU8GCBfXaa69J+r/5lsuWLasTJ04oX758qdQbAAAAAAAA4MVTbsB3/+nx9k5on+y2D08pm5gRI0Zo5MiRpmvYvXu3nJ2dTW9nFsE6EjVs2DDduHFDRYsWlSS99dZbGjJkiCTp/ffflyTrxUcf1zbe9evXNWHCBG3fvt26bPr06ercubMiIyM1YsQI5ciRI9X7BQAAAADA0/qvAyo8mZkQD0D6cunSJevPixcv1vDhw3Xs2DHrMhcXF+vPhmEoNjZWGTI8Oc7Onj17yhaaBIJ1JCpjxoyaPn26pk+fnmBdfKCenLbxPD09E1w4sXr16jp9+nTKFAwAQDrDP97pD/94AwAAAOmHt7e39Wc3NzdZLBbrsi1btqhGjRpau3atPvroIx08eFDr169Xnjx51K9fP/3++++6ffu2ihYtqrFjx6p27drWffn6+qpv377q27evpAcj47/55hv9/PPPWrdunXLlyqWJEyeqcePG/6p+5lgHAAAAAAAAAKQ7gwYN0qeffqojR46oZMmSioyMVP369bVx40b99ddfqlevnho1aqRz5849dj+jRo1Sq1atdODAAdWvX1/t2rXTzZs3/1VtjFgHAAAAgH+BM1TSH85QAQDg+fDxxx/r9ddft9738PBQqVKlrPc/+eQTrVixQqtWrVLPnj2T3E/Hjh3Vpk0bSQ+uDzl16lT9+eefqlev3lPXxoh1AAAAAAAAAEC6U758eZv7kZGR6t+/v4oWLSp3d3e5uLjoyJEjTxyxXrJkSevPzs7OcnV11dWrV/9VbYxYBwAAAAAAAACkO87Ozjb3+/fvr6CgIH322Wfy8/NTpkyZ1KJFC0VHRz92PxkzZrS5b7FYFBcX969qY8T6C2zRokVq1apVWpeRqDFjxmjo0KFpXQYAAAAAAACAdGLHjh3q2LGjmjVrJn9/f3l7e+vs2bNpUgsj1l9QcXFxGjJkiH766acnth0yZIjGjh2rFStWqGnTpom2uX//vvr3768lS5bo9u3b8vf31+eff65y5cpJenAl33feeUe3bt3SsGHD1KtXL+u2AQEB6t+/v2rVqmVd1qdPHxUsWFC9evWyuUIw8DxgHtb0hTlYAQAAAAB4NhQqVEjLly9Xo0aNZLFYNGzYsH898vxpMWL9BbV27Vp5eHjI39//se3279+v1atXy8fH57HtvvjiC61evVq7du3SzZs3Va9ePTVu3FiGYUiSevTooS+++EL79u3TyJEjdeXKFUnSDz/8IC8vL5tQXZJcXFwUEBCg2bNn/4teAgAAAAAAAHheTJo0SVmzZlWlSpXUqFEj1a1bV2XLlk2TWhix/oJatWqVatas+dg2sbGx6tKli7744gt16NDhsW1Pnz6tWrVqKV++fJKkTp06adiwYbpx44Y8PT11+vRp1axZU46OjipUqJBCQkLk4OCg0aNH67fffkt0n7Vq1dIXX3zBlDAAAAAAAADAU3hWztLu2LGjOnbsaL1fvXp164Ddh/n6+mrTpk02y3r06GFz/9GpYRLbT1hY2FPXGo8R6y+o4OBgFSlS5LFtJk+erJIlS6patWpP3N8777yjvXv36tSpU4qJidGsWbP06quvytPTU5Lk7++v9evX6/z58woJCZGfn58GDhyogQMHWts8qlixYgoODjbdNwAAAAAAAABITYxYf0GFhobK1dU1yfWnT5+2Tt2SHAUKFFDp0qXl5+cne3t75ciRQ7/88ot1/ezZs9WnTx9FRERo6tSpOnTokM6ePasJEybo7bffVkhIiGrVqqURI0ZYt3F1dVV0dLTu3LmjzJkzP31nAQAAAAAAACAFMWL9BZU1a1ZFRERIkgIDA+Xi4mKd11yS3n33XY0ePVoeHh7J2l/37t0VEhKiixcv6t69e/r8889Vs2ZNXbx4UdKDEeubNm3Snj171KRJE/Xp00czZszQp59+qkKFCmnLli367bfftG7dOus+IyIi5ODgQKgOAAAAAAAAIF0hWH9BlS5dWkePHpUkDRkyRJGRkYqMjLSOMt+4caP69u0rT09PeXp66p9//lH79u31wQcfJLq/v/76Sx07dpSPj48yZMigFi1ayM3NTTt37kzQ9tNPP1Xz5s1VqFAh7d+/XxUqVJCdnZ0qVKig/fv3W9sdPnxYpUuXTvnOAwAAAAAAAMC/QLD+gmrUqJE2b96c5Pp//vlHwcHB1lvOnDk1efJkDR8+PNH2r776qr777jtdu3ZNcXFxWrFihc6fPy9/f3+bdsePH9eqVas0cOBASQ+mkNmwYYOioqK0detWFSxY0Np206ZNatiwYQr0FgAAAAAAAABSDsH6C6p+/fq6fv26/v7770TX586d2+Zmb2+vbNmyKWvWrJKkBQsWqHjx4tb2n332mfLkyaOSJUvK3d1dI0aM0HfffafChQvb7Ldbt26aOnWqMmbMKEkaPHiwdu7cqRw5csjPz09NmzaVJN2+fVtr165Vly5dUqH3AAAAAAAAAPD0uHjpC8re3l6BgYH65JNPtHjx4ie2P3v2rM39du3aqV27dtb7bm5umj179hP3s3HjRpv7uXPn1o4dOxK0+/zzz9WlSxf5+Pg8cZ8AAAAAAAAA8F8iWH+BtWnTRm3atEnrMhI1ZMiQtC4BAAAAAAAAABLFVDAAAAAAAAAAAJhAsA4AAAAAAAAAgAlMBQMAAAAAAAAAz6FzH/v/p8fLO/xgsttaLJbHrh8xYoRGjhz5VHVYLBatWLFCTZs2fartk4NgHQAAAAAAAADwn7p06ZL158WLF2v48OE6duyYdZmLi0talJVsTAUDAAAAAAAAAPhPeXt7W29ubm6yWCw2yxYtWqSiRYvKyclJRYoU0YwZM6zbRkdHq2fPnvLx8ZGTk5Py5cunsWPHSpJ8fX0lSc2aNZPFYrHeT2mMWAcAAAAAAAAApBsLFizQ8OHD9cUXX6hMmTL666+/1LVrVzk7O6tDhw6aOnWqVq1apSVLlihv3rz6559/9M8//0iSdu/eLS8vL82ZM0f16tWTvb19qtRIsA4AAAAAAAAASDdGjBihiRMn6o033pAk5c+fX4cPH9bMmTPVoUMHnTt3ToUKFdJrr70mi8WifPnyWbfNnj27JMnd3V3e3t6pViPBOgAAAAAAAAAgXbh9+7ZOnTqld955R127drUuv3//vtzc3CRJHTt21Ouvv67ChQurXr16atiwoerUqfOf1kmwnk6UG/BdWpeAR+yd0D6tSwAAAAAAAABeKJGRkZKkb775RhUqVLBZFz+tS9myZXXmzBn98ssv2rBhg1q1aqXatWvrxx9//M/qJFgHAAAAAAAAAKQLOXLkUM6cOXX69Gm1a9cuyXaurq5q3bq1WrdurRYtWqhevXq6efOmPDw8lDFjRsXGxqZqnQTrAAAAAAAAAIB0Y9SoUerdu7fc3NxUr149RUVFac+ePQoNDVW/fv00adIk+fj4qEyZMrKzs9PSpUvl7e0td3d3SZKvr682btyoypUry9HRUVmzZk3xGu1SfI8AAAAAAAAAADylLl26aNasWZozZ478/f1VrVo1zZ07V/nz55ckZcmSRePHj1f58uX18ssv6+zZs1q7dq3s7B7E3RMnTlRQUJDy5MmjMmXKpEqNjFgHAAAAAAAAgOdQ3uEH07qEZOnYsaM6duxos6xt27Zq27Ztou27du1qc2HTRzVq1EiNGjVKyRITYMQ6AAAAAAAAAAAmEKwDAAAAAAAAAGACwToAAAAAAAAAACYQrAMAAAAAAAAAYALBOgAAAAAAAAAAJhCsAwAAAAAAAMAzLi4uLq1LeC4k93HMkMp1AAAAAAAAAABSiYODg+zs7HTx4kVlz55dDg4OslgsaV3WM8cwDEVHR+vatWuys7OTg4PDY9sTrAMAAAAAAADAM8rOzk758+fXpUuXdPHixbQu55mXOXNm5c2bV3Z2j5/shWAdAAAAAAAAAJ5hDg4Oyps3r+7fv6/Y2Ni0LueZZW9vrwwZMiRrxD/BOgAAAAAAAAA84ywWizJmzKiMGTOmdSkvBC5eCgAAAAAAAACACQTrAAAAAAAAAACYQLAOAAAAAAAAAIAJBOsAAAAAAAAAAJhAsA4AAAAAAAAAgAkE6wAAAAAAAAAAmPBMBetbt25Vo0aNlDNnTlksFq1cufKx7bds2SKLxZLgdvny5f+mYAAAAAAAAADAc+eZCtZv376tUqVKafr06aa2O3bsmC5dumS9eXl5pVKFAAAAAAAAAIDnXYa0LsCMgIAABQQEmN7Oy8tL7u7uKV8QAAAAAAAAAOCF80yNWH9apUuXlo+Pj15//XXt2LEjrcsBAAAAAAAAADzDnqkR62b5+Pjoq6++Uvny5RUVFaVZs2apevXq+uOPP1S2bNlEt4mKilJUVJT1fkRExH9VLgAAAAAAAADgGfBcB+uFCxdW4cKFrfcrVaqkU6dOafLkyZo/f36i24wdO1ajRo36r0oEAAAAAAAAADxjXoipYB72yiuv6OTJk0muHzx4sMLDw623f/755z+sDgAAAAAAAACQ3j3XI9YTExwcLB8fnyTXOzo6ytHR8T+sCAAAAAAAAADwLHmmgvXIyEib0eZnzpxRcHCwPDw8lDdvXg0ePFgXLlzQd999J0maMmWK8ufPr+LFi+vevXuaNWuWNm3apPXr16dVFwAAAAAAAAAAz7hnKljfs2ePatSoYb3fr18/SVKHDh00d+5cXbp0SefOnbOuj46O1ocffqgLFy4oc+bMKlmypDZs2GCzDwAAAAAAAAAAzHimgvXq1avLMIwk18+dO9fm/sCBAzVw4MBUrgoAAAAAAAAA8CJ54S5eCgAAAAAAAADAv0GwDgAAAAAAAACACQTrAAAAAAAAAACYQLAOAAAAAAAAAIAJBOsAAAAAAAAAAJhAsA4AAAAAAAAAgAkE6wAAAAAAAAAAmECwDgAAAAAAAACACQTrAAAAAAAAAACYQLAOAAAAAAAAAIAJBOsAAAAAAAAAAJhAsA4AAAAAAAAAgAkE6wAAAAAAAAAAmECwDgAAAAAAAACACQTrAAAAAAAAAACYQLAOAAAAAAAAAIAJBOsAAAAAAAAAAJhAsA4AAAAAAAAAgAkE6wAAAAAAAAAAmECwDgAAAAAAAACACQTrAAAAAAAAAACYQLAOAAAAAAAAAIAJBOsAAAAAAAAAAJhAsA4AAAAAAAAAgAkE6wAAAAAAAAAAmECwDgAAAAAAAACACQTrAAAAAAAAAACYQLAOAAAAAAAAAIAJBOsAAAAAAAAAAJhAsA4AAAAAAAAAgAkE6wAAAAAAAAAAmECwDgAAAAAAAACACQTrAAAAAAAAAACYQLAOAAAAAAAAAIAJBOsAAAAAAAAAAJhAsA4AAAAAAAAAgAkE6wAAAAAAAAAAmECwDgAAAAAAAACACQTrAAAAAAAAAACYQLAOAAAAAAAAAIAJBOsAAAAAAAAAAJhAsA4AAAAAAAAAgAkE6wAAAAAAAAAAmECwDgAAAAAAAACACQTrAAAAAAAAAACYQLAOAAAAAAAAAIAJBOsAAAAAAAAAAJhAsA4AAAAAAAAAgAkE6wAAAAAAAAAAmECwDgAAAAAAAACACQTrAAAAAAAAAACYQLAOAAAAAAAAAIAJBOsAAAAAAAAAAJhAsA4AAAAAAAAAgAkE6wAAAAAAAAAAmECwDgAAAAAAAACACQTrAAAAAAAAAACYQLAOAAAAAAAAAIAJBOsAAAAAAAAAAJhAsA4AAAAAAAAAgAkE6wAAAAAAAAAAmECwDgAAAAAAAACACQTrAAAAAAAAAACYQLAOAAAAAAAAAIAJBOsAAAAAAAAAAJhAsA4AAAAAAAAAgAkE6wAAAAAAAAAAmECwDgAAAAAAAACACQTrAAAAAAAAAACYQLAOAAAAAAAAAIAJBOsAAAAAAAAAAJhAsA4AAAAAAAAAgAkE6wAAAAAAAAAAmECwDgAAAAAAAACACQTrAAAAAAAAAACYQLAOAAAAAAAAAIAJBOsAAAAAAAAAAJhAsA4AAAAAAAAAgAkE6wAAAAAAAAAAmECwDgAAAAAAAACACQTrAAAAAAAAAACYQLAOAAAAAAAAAIAJBOsAAAAAAAAAAJhAsA4AAAAAAAAAgAkE6wAAAAAAAAAAmECwDgAAAAAAAACACQTrAAAAAAAAAACYQLAOAAAAAAAAAIAJBOsAAAAAAAAAAJhAsA4AAAAAAAAAgAkE6wAAAAAAAAAAmECwDgAAAAAAAACACQTrAAAAAAAAAACYQLAOAAAAAAAAAIAJBOsAAAAAAAAAAJhAsA4AAAAAAAAAgAkE6wAAAAAAAAAAmECwDgAAAAAAAACACQTrAAAAAAAAAACYQLAOAAAAAAAAAIAJBOsAAAAAAAAAAJhAsA4AAAAAAAAAgAkE6wAAAAAAAAAAmECwDgAAAAAAAACACQTrAAAAAAAAAACYQLAOAAAAAAAAAIAJBOsAAAAAAAAAAJhAsA4AAAAAAAAAgAkE6wAAAAAAAAAAmECwDgAAAAAAAACACQTrAAAAAAAAAACYQLAOAAAAAAAAAIAJBOsAAAAAAAAAAJhAsA4AAAAAAAAAgAkE6wAAAAAAAAAAmECwDgAAAAAAAACACQTrAAAAAAAAAACYQLAOAAAAAAAAAIAJBOsAAAAAAAAAAJhAsA4AAAAAAAAAgAkE6wAAAAAAAAAAmECwDgAAAAAAAACACQTrAAAAAAAAAACYQLAOAAAAAAAAAIAJBOsAAAAAAAAAAJhAsA4AAAAAAAAAgAkE6wAAAAAAAAAAmECwDgAAAAAAAACACQTrAAAAAAAAAACYQLAOAAAAAAAAAIAJBOsAAAAAAAAAAJhAsA4AAAAAAAAAgAkE6wAAAAAAAAAAmECwDgAAAAAAAACACQTrAAAAAAAAAACYQLAOAAAAAAAAAIAJBOsAAAAAAAAAAJhAsA4AAAAAAAAAgAkE6wAAAAAAAAAAmECwDgAAAAAAAACACQTrAAAAAAAAAACYQLAOAAAAAAAAAIAJBOsAAAAAAAAAAJhAsA4AAAAAAAAAgAkE6wAAAAAAAAAAmECwDgAAAAAAAACACQTrAAAAAAAAAACYQLAOAAAAAAAAAIAJBOsAAAAAAAAAAJhAsA4AAAAAAAAAgAkE6wAAAAAAAAAAmECwDgAAAAAAAACACQTrAAAAAAAAAACYQLAOAAAAAAAAAIAJBOsAAAAAAAAAAJjwTAXrW7duVaNGjZQzZ05ZLBatXLnyidts2bJFZcuWlaOjo/z8/DR37txUrxMAAAAAAAAA8Px6poL127dvq1SpUpo+fXqy2p85c0YNGjRQjRo1FBwcrL59+6pLly5at25dKlcKAAAAAAAAAHheZUjrAswICAhQQEBAstt/9dVXyp8/vyZOnChJKlq0qLZv367Jkyerbt26qVUmAAAAAAAAAOA59kyNWDdr165dql27ts2yunXrateuXWlUEQAAAAAAAADgWfdMjVg36/Lly8qRI4fNshw5cigiIkJ3795VpkyZEmwTFRWlqKgo6/2IiIhUrxMAAAAAAAAA8Ox4rkesP42xY8fKzc3NesuTJ09alwQAAAAAAAAASEee62Dd29tbV65csVl25coVubq6JjpaXZIGDx6s8PBw6+2ff/75L0oFAAAAAAAAADwjnuupYF599VWtXbvWZllQUJBeffXVJLdxdHSUo6NjapcGAAAAAAAAAHhGPVMj1iMjIxUcHKzg4GBJ0pkzZxQcHKxz585JejDavH379tb277//vk6fPq2BAwfq6NGjmjFjhpYsWaIPPvggLcoHAAAAAAAAADwHnqlgfc+ePSpTpozKlCkjSerXr5/KlCmj4cOHS5IuXbpkDdklKX/+/Pr5558VFBSkUqVKaeLEiZo1a5bq1q2bJvUDAAAAAAAAAJ59z9RUMNWrV5dhGEmunzt3bqLb/PXXX6lYFQAAAAAAAADgRfJMjVgHAAAAAAAAACCtEawDAAAAAAAAAGACwToAAAAAAAAAACYQrAMAAAAAAAAAYALBOgAAAAAAAAAAJhCsAwAAAAAAAABgAsE6AAAAAAAAAAAmEKwDAAAAAAAAAGACwToAAAAAAAAAACYQrAMAAAAAAAAAYALBOgAAAAAAAAAAJhCsAwAAAAAAAABgAsE6AAAAAAAAAAAmEKwDAAAAAAAAAGACwToAAAAAAAAAACYQrAMAAAAAAAAAYALBOgAAAAAAAAAAJhCsAwAAAAAAAABgAsE6AAAAAAAAAAAmEKwDAAAAAAAAAGACwToAAAAAAAAAACYQrAMAAAAAAAAAYALBOgAAAAAAAAAAJhCsAwAAAAAAAABgAsE6AAAAAAAAAAAmEKwDAAAAAAAAAGACwToAAAAAAAAAACYQrAMAAAAAAAAAYALBOgAAAAAAAAAAJhCsAwAAAAAAAABgAsE6AAAAAAAAAAAmEKwDAAAAAAAAAGACwToAAAAAAAAAACYQrAMAAAAAAAAAYALBOgAAAAAAAAAAJhCsAwAAAAAAAABgAsE6AAAAAAAAAAAmEKwDAAAAAAAAAGACwToAAAAAAAAAACYQrAMAAAAAAAAAYALBOgAAAAAAAAAAJhCsAwAAAAAAAABgAsE6AAAAAAAAAAAmEKwDAAAAAAAAAGACwToAAAAAAAAAACYQrAMAAAAAAAAAYALBOgAAAAAAAAAAJhCsAwAAAAAAAABgAsE6AAAAAAAAAAAmEKwDAAAAAAAAAGACwToAAAAAAAAAACYQrAMAAAAAAAAAYALBOgAAAAAAAAAAJhCsAwAAAAAAAABgAsE6AAAAAAAAAAAmEKwDAAAAAAAAAGACwToAAAAAAAAAACYQrAMAAAAAAAAAYALBOgAAAAAAAAAAJhCsAwAAAAAAAABgAsE6AAAAAAAAAAAmEKwDAAAAAAAAAGACwToAAAAAAAAAACYQrAMAAAAAAAAAYALBOgAAAAAAAAAAJhCsAwAAAAAAAABgAsE6AAAAAAAAAAAmEKwDAAAAAAAAAGACwToAAAAAAAAAACYQrAMAAAAAAAAAYALBOgAAAAAAAAAAJhCsAwAAAAAAAABgAsE6AAAAAAAAAAAmEKwDAAAAAAAAAGACwToAAAAAAAAAACYQrAMAAAAAAAAAYALBOgAAAAAAAAAAJhCsAwAAAAAAAABgAsE6AAAAAAAAAAAmEKwDAAAAAAAAAGACwToAAAAAAAAAACaYDtZr1qypsLCwBMsjIiJUs2bNlKgJAAAAAAAAAIB0y3SwvmXLFkVHRydYfu/ePW3bti1FigIAAAAAAAAAIL3KkNyGBw4csP58+PBhXb582Xo/NjZWv/76q3LlypWy1QEAAAAAAAAAkM4kO1gvXbq0LBaLLBZLolO+ZMqUSdOmTUvR4gAAAAAAAAAASG+SHayfOXNGhmGoQIEC+vPPP5U9e3brOgcHB3l5ecne3j5VigQAAAAAAAAAIL1IdrCeL18+SVJcXFyqFQMAAAAAAAAAQHqXrGB91apVCggIUMaMGbVq1arHtm3cuHGKFAYAAAAAAAAAQHqUrGC9adOmunz5sry8vNS0adMk21ksFsXGxqZUbQAAAAAAAAAApDvJCtYfnv6FqWAAAAAAAAAAAC8yu+Q08vDw0PXr1yVJnTt31q1bt1K1KAAAAAAAAAAA0qtkBevR0dGKiIiQJM2bN0/37t1L1aIAAAAAAAAAAEivkjUVzKuvvqqmTZuqXLlyMgxDvXv3VqZMmRJt++2336ZogQAAAAAAAAAApCfJCta///57TZ48WadOnZLFYlF4eDij1gEAAAAAAAAAL6RkBes5cuTQp59+KknKnz+/5s+fr2zZsqVqYQAAAAAAAAAApEfJCtYfdubMmdSoAwAAAAAAAACAZ0KyLl76qN9++02NGjWSn5+f/Pz81LhxY23bti2lawMAAAAAAAAAIN0xHax///33ql27tjJnzqzevXtbL2Raq1YtLVy4MDVqBAAAAAAAAAAg3TA9FcyYMWM0fvx4ffDBB9ZlvXv31qRJk/TJJ5+obdu2KVogAAAAAAAAAADpiekR66dPn1ajRo0SLG/cuDHzrwMAAAAAAAAAnnumg/U8efJo48aNCZZv2LBBefLkSZGiAAAAAAAAAABIr0xPBfPhhx+qd+/eCg4OVqVKlSRJO3bs0Ny5c/X555+neIEAAAAAAAAAAKQnpoP1bt26ydvbWxMnTtSSJUskSUWLFtXixYvVpEmTFC8QAAAAAAAAAID0xFSwfv/+fQUGBqpz587avn17atUEAAAAAAAAAEC6ZWqO9QwZMmj8+PG6f/9+atUDAAAAAAAAAEC6ZvripbVq1dJvv/2WGrUAAAAAAAAAAJDumZ5jPSAgQIMGDdLBgwdVrlw5OTs726xv3LhxihUHAAAAAAAAAEB6YzpY7969uyRp0qRJCdZZLBbFxsb++6oAAAAAAAAAAEinTAfrcXFxqVEHAAAAAAAAAADPBFPB+tmzZxUUFKSYmBhVq1ZNxYsXT626AAAAAAAAAABIl5IdrG/evFkNGzbU3bt3H2yYIYO+/fZbvfXWW6lWHAAAAAAAAAAA6Y1dchsOGzZMr7/+ui5cuKAbN26oa9euGjhwYGrWBgAAAAAAAABAupPsYP3vv/9WYGCgfHx8lDVrVk2YMEFXr17VjRs3UrM+AAAAAAAAAADSlWQH6xEREfL09LTez5w5szJlyqTw8PBUKQwAAAAAAAAAgPTI1MVL161bJzc3N+v9uLg4bdy4UX///bd1WePGjVOuOgAAAAAAAAAA0hlTwXqHDh0SLHvvvfesP1ssFsXGxv77qgAAAAAAAAAASKeSHazHxcWlZh0AAAAAAAAAADwTkj3HOgAAAAAAAAAAIFgHAAAAAAAAAMAUgnUAAAAAAAAAAEwgWAcAAAAAAAAAwASCdQAAAAAAAAAATHiqYD0sLEyzZs3S4MGDdfPmTUnSvn37dOHChRQtDgAAAAAAAACA9CaD2Q0OHDig2rVry83NTWfPnlXXrl3l4eGh5cuX69y5c/ruu+9So04AAAAAAAAAANIF0yPW+/Xrp44dO+rEiRNycnKyLq9fv762bt2aosUBAAAAAAAAAJDemA7Wd+/erffeey/B8ly5cuny5cspUhQAAAAAAAAAAOmV6WDd0dFRERERCZYfP35c2bNnT5GiAAAAAAAAAABIr0wH640bN9bHH3+smJgYSZLFYtG5c+f0v//9T82bN0/xAgEAAAAAAAAASE9MB+sTJ05UZGSkvLy8dPfuXVWrVk1+fn7KkiWLxowZkxo1AgAAAAAAAACQbmQwu4Gbm5uCgoK0fft2HThwQJGRkSpbtqxq166dGvUBAAAAAAAAAJCumA7W47322mt67bXXUrIWAAAAAAAAAADSPdPB+tSpUxNdbrFY5OTkJD8/P1WtWlX29vb/ujgAAAAAAAAAANIb08H65MmTde3aNd25c0dZs2aVJIWGhipz5sxycXHR1atXVaBAAW3evFl58uRJ8YIBAAAAAAAAAEhLpi9eGhgYqJdfflknTpzQjRs3dOPGDR0/flwVKlTQ559/rnPnzsnb21sffPBBatQLAAAAAAAAAECaMj1i/aOPPtKyZctUsGBB6zI/Pz999tlnat68uU6fPq3x48erefPmKVooAAAAAAAAAADpgekR65cuXdL9+/cTLL9//74uX74sScqZM6du3br176sDAAAAAAAAACCdMR2s16hRQ++9957++usv67K//vpL3bp1U82aNSVJBw8eVP78+VOuSgAAAAAAAAAA0gnTwfrs2bPl4eGhcuXKydHRUY6Ojipfvrw8PDw0e/ZsSZKLi4smTpyY4sUCAAAAAAAAAJDWTM+x7u3traCgIB09elTHjx+XJBUuXFiFCxe2tqlRo0bKVQgAAAAAAAAAQDpiOliPV6RIERUpUiQlawEAAAAAAAAAIN17qmD9/PnzWrVqlc6dO6fo6GibdZMmTUqRwgAAAAAAAAAASI9MB+sbN25U48aNVaBAAR09elQlSpTQ2bNnZRiGypYtmxo1AgAAAAAAAACQbpi+eOngwYPVv39/HTx4UE5OTlq2bJn++ecfVatWTS1btkyNGgEAAAAAAAAASDdMB+tHjhxR+/btJUkZMmTQ3bt35eLioo8//ljjxo1L8QIBAAAAAAAAAEhPTAfrzs7O1nnVfXx8dOrUKeu669evp1xlAAAAAAAAAACkQ6bnWK9YsaK2b9+uokWLqn79+vrwww918OBBLV++XBUrVkyNGgEAAAAAAAAASDdMB+uTJk1SZGSkJGnUqFGKjIzU4sWLVahQIU2aNCnFCwQAAAAAAAAAID0xFazHxsbq/PnzKlmypKQH08J89dVXqVIYAAAAAAAAAADpkak51u3t7VWnTh2FhoamVj0AAAAAAAAAAKRrpi9eWqJECZ0+fTo1agEAAAAAAAAAIN0zHayPHj1a/fv315o1a3Tp0iVFRETY3AAAAAAAAAAAeJ6Zvnhp/fr1JUmNGzeWxWKxLjcMQxaLRbGxsSlXHQAAAAAAAAAA6YzpYH3z5s2pUQcAAAAAAAAAAM8E08F6tWrVUqMOAAAAAAAAAACeCabnWJekbdu26a233lKlSpV04cIFSdL8+fO1ffv2FC0OAAAAAAAAAID0xnSwvmzZMtWtW1eZMmXSvn37FBUVJUkKDw9XYGBgihf4qOnTp8vX11dOTk6qUKGC/vzzzyTbzp07VxaLxebm5OSU6jUCAAAAAAAAAJ5fpoP10aNH66uvvtI333yjjBkzWpdXrlxZ+/btS9HiHrV48WL169dPI0aM0L59+1SqVCnVrVtXV69eTXIbV1dXXbp0yXoLCQlJ1RoBAAAAAAAAAM8308H6sWPHVLVq1QTL3dzcFBYWlhI1JWnSpEnq2rWrOnXqpGLFiumrr75S5syZ9e233ya5jcVikbe3t/WWI0eOVK0RAAAAAAAAAPB8Mx2se3t76+TJkwmWb9++XQUKFEiRohITHR2tvXv3qnbt2tZldnZ2ql27tnbt2pXkdpGRkcqXL5/y5MmjJk2a6NChQ6lWIwAAAAAAAADg+Wc6WO/atav69OmjP/74QxaLRRcvXtSCBQvUv39/devWLTVqlCRdv35dsbGxCUac58iRQ5cvX050m8KFC+vbb7/VTz/9pO+//15xcXGqVKmSzp8/n+RxoqKiFBERYXMDAAAAAAAAACBeBrMbDBo0SHFxcapVq5bu3LmjqlWrytHRUf3791evXr1So8an9uqrr+rVV1+13q9UqZKKFi2qmTNn6pNPPkl0m7Fjx2rUqFH/VYkAAAAAAAAAgGeM6RHrFotFQ4cO1c2bN/X333/r999/17Vr15IMqlOKp6en7O3tdeXKFZvlV65ckbe3d7L2kTFjRpUpUybRqWziDR48WOHh4dbbP//886/qBgAAAAAAAAA8X0wH699//73u3LkjBwcHFStWTK+88opcXFxSozYbDg4OKleunDZu3GhdFhcXp40bN9qMSn+c2NhYHTx4UD4+Pkm2cXR0lKurq80NAAAAAAAAAIB4poP1Dz74QF5eXmrbtq3Wrl2r2NjY1KgrUf369dM333yjefPm6ciRI+rWrZtu376tTp06SZLat2+vwYMHW9t//PHHWr9+vU6fPq19+/bprbfeUkhIiLp06fKf1QwAAAAAAIDnw6VLl9S4cWPlzJlTFotFwcHBCdqMGTNG+fLlk6urq8qUKaP169db182bN0+vvPKK3Nzc5OPjo3feeUdhYWGPPebMmTOVN29eOTs7q0GDBrp06ZJ13ZYtW1SwYEF5eXlp2rRpNtsFBATYDFAFkLJMB+uXLl3SokWLZLFY1KpVK/n4+KhHjx7auXNnatRno3Xr1vrss880fPhwlS5dWsHBwfr111+tFzQ9d+6czYdLaGiounbtqqJFi6p+/fqKiIjQzp07VaxYsVSvFQAAAAAAAM8XOzs71atXTytXrkx0/cqVK/XZZ59pzZo1Cg8PV79+/dSsWTPdvHlTknTnzh2NHz9eV65c0aFDh3Tp0iV17949yeNt2rRJ//vf/7R06VJdvXpVOXLkULt27azre/TooS+++EL79u3TyJEjrVMo//DDD/Ly8lKtWrVSrvMAbJi+eGmGDBnUsGFDNWzYUHfu3NGKFSu0cOFC1ahRQ7lz59apU6dSo06rnj17qmfPnomu27Jli839yZMna/LkyalaDwAAAAAAAF4MOXLkeGwQfvr0ab388svy9/eXJL399tt65513dPr0aXl4eKhbt27Wtk5OTv+vvfsOz7K6/wf+TgKEEcKQKaCIuEAQcVBaB6Kte0+Ke6PUVRxg3VatWrfWWa0trp+rWkWLe2/BhdYJWkBFhDBkJfn9Yc1XCqhPBcN4va4rl3nuc+7zfE68bgjvnJyTQw89dIE5V5Jcf/312XPPPdOrV68kydlnn53ll18+H3zwQTp16pQPPvggffv2TWlpaVZZZZWMHj069erVy5lnnpnHH398Ic0amJ+CV6x/W8OGDbP55ptnyy23zCqrrJKPPvpoIZUFAAAAAEuW3XffPePHj8+rr76aysrKXH/99Wnfvn3WXHPN+fZ//PHH07179wWO99prr6VHjx41r1u3bp02bdrk9ddfT5J069Yt//znP/PJJ59k9OjR6dy5c4477rgcd9xxadGixUKdGzC3glesJ6lZqT506NA8/PDD6dChQ/r165fbb799YdcHAAAAAEuEVq1aZeutt866666boqKiNGrUKHfeeWfq168/T99hw4bl2muvzVNPPbXA8aZOnZqmTZvOda1p06aZMmVKkuS6667LkUcemYqKilxyySV5880389FHH+W8887LXnvtldGjR2fTTTfNKaecslDnCfwPK9b32GOPtGrVKkcffXQ6deqUxx57LO+9917OOOOMrL766ouiRgAAAAD4yQ0dOjRlZWUpKytL165dv7f/6aefnvvvvz//+te/MmvWrPz973/P7rvvPs8hp4888kj23HPP3HnnnTXbxsxPWVlZJk+ePNe1yZMnp3Hjxkm+XrH+yCOP5KWXXsr222+fI488MldccUXOOeecrLLKKnnsscfy+OOP58EHHyx88sB3KjhYLykpyW233ZZx48blsssuS+/evWva3njjjYVaHAAAAADUlv79+2fq1KmZOnVq3nzzze/t/+qrr2bXXXfNyiuvnOLi4vTp0ydrrbVWHnrooZo+jzzySHbZZZfcdNNN33u4aPfu3ecK5T/77LOMGzduvmH8Oeeck5133jmrrLJKRo4cmV69eqW4uDi9evXKyJEjf/ikgR+k4GB96NCh2WqrrVJSUpIkmTJlSq6++uqsv/76WWuttRZ6gQAAAACwuJgxY0ZmzJiRJJk1a1ZmzJiRqqqqJEnv3r1z++23Z/To0amurs7TTz+dF154oWaf9Mceeyw777xz/vrXv2bzzTf/3vfab7/98re//S0vvPBCpk+fniFDhmTjjTdOp06d5ur3r3/9K/fcc0+OO+64JEmnTp3y0EMPZebMmXniiSey8sorL8SvAJD8iMNLn3jiieyzzz5p27Ztzj///PTt2zfPPffcwqwNAAAAABYrDRo0SIMGDZIkvXr1SoMGDfLEE08kSY477rhsuumm2WCDDVJeXp799tsvZ511VjbbbLMkyWmnnZaKiorsvvvuNVvMlJWV1Yw9dOjQubac6du3b84+++zstNNOadmyZcaOHZuhQ4fOU9OAAQNyySWXpG7dukmSwYMH55lnnknr1q3TuXPn7LDDDovqywHLrIIOLx0/fnxuuOGGXHfddamoqMhuu+2WmTNn5u67706XLl0WVY0AAAAAsFiorq5eYFvdunXzxz/+MX/84x/n2/7oo49+59j9+/dP//7957p26KGH5tBDD/3O+x5++OG5Xrdv3z5PP/30d94D/Dg/eMX6tttum9VWWy2vvfZaLrrooowdOzaXXnrpoqwNAAAAAAAWOz94xfqwYcNyxBFHZMCAAVlllVUWZU0AAAAAALDY+sEr1p966qlMmTIl66yzTnr16pXLLrssEyZMWJS1AQDAEm3cuHHZbrvtsvzyy6eoqCgjRoyYq/3QQw+da3/Vhg0bpqioKK+88so8Yw0ZMiRFRUW5++67F/h+119/fVZbbbU0adIkLVq0yE477ZQxY8bUtN96661p165d2rVrl9tvv73m+uzZs7Puuutm1KhRP3rOAACwLPjBwfrPfvazXHPNNRk3blwOOeSQ3HLLLVl++eVTVVWV4cOHZ8qUKYuyTgAAWOIUFxdniy22WGAYfuWVV2bq1Kk1H2eccUZWXXXV9OzZc65+I0eOzL333pu2bdt+5/v17ds3Tz/9dCZPnpxPPvkkK6+8cvbff/8kSWVlZQYMGJAHH3ww9913Xw455JBUVlYmSc4///xsvfXWWWONNX78pAEAYBnwg4P1bzRq1Cj7779/nnrqqbz++uv57W9/m3POOSetWrXKdttttyhqBACAJVLr1q1z2GGHZf311/9B/a+77rqaIPwblZWVOfDAA3PZZZelXr1633n/iiuumBYtWiT5+mC14uLivPvuu0mSCRMmpLS0NGuuuWZ69OiRunXr5osvvsj777+f2267LUOGDPkfZggAy65bbrklu+22W22XkcrKynTr1s1vnsFPrOBg/dtWW221nHvuufnkk09y8803L6yaAABgmfPss8/m3Xffzb777jvX9QsvvDDdu3fPxhtv/IPGeeqpp9K0adM0bNgwF1xwQU488cQkScuWLVNcXJyRI0dm5MiRKSkpSYsWLTJgwIBceOGFKS0tXdhTAoClVlVVVYYMGZKTTjopSVJRUZFf//rXKS8vT+vWrXPGGWd85/3f1//YY49N8+bNs9Zaa+Wtt96quf7BBx+kR48emTFjRs21kpKSDBo0yA/J4Sf2gw8v/S4lJSXZYYcdssMOOyyM4QAAYJlz7bXXZptttknr1q1rrn3wwQe57LLL5rvn+oJssMEGmTRpUiZMmJBrr702Xbp0SfL1tjRDhw7NgAEDkiRDhw7NTTfdlA4dOqRz587ZcccdM3HixPTr1y+HHnrowp0cACxl7r///jRv3jzdunVLkvzmN7/JxIkTM2bMmHz22WfZbLPNsuKKK2bvvfee7/3f1f/FF1/M3XffnY8++ig33HBDjj/++Nx7771JksMOOywXXHBB6tevP9d4u+yyS37zm99kzJgxWWGFFRbt5IEkP3LFOgAA8H+GDh1acxBp165df/B9U6dOzW233ZYDDjhgrusHH3xwzjzzzDRv3rzgWlq0aJEDDjgg22yzTaZNm5Yk6dOnT5555pk888wz6d69e84555ycd955GTRoUHbcccc8+OCDueSSS/wqOQB8j3vuuSd9+/ZNkkyfPj233HJLzjzzzDRt2jSrrrpqfvOb3+S6666b773f1/+DDz7Iuuuum/Ly8vzqV7/K+++/nyS56aab0qZNm5r3/bZGjRplvfXWy3333beIZgz8N8E6AAAsJP379685iPTNN9/8wffdcsstKS8vz5ZbbjnX9YcffjhHHXVUWrRokRYtWuTjjz/O3nvvnaOPPvoHjTt79uxMnjw5n3322TxtgwYNyuDBg9O8efOMHDkyvXr1Sv369bPWWmvl9ddf/8G1A8CyaMSIEVl99dWTJO+8805mzZqVHj161LT36NEjr7322nzv/b7+a665Zl566aVMmjQpDz30ULp165Yvv/wyZ511Vv74xz8usKYuXbpkxIgRP3puwA8jWAcAgEVoxowZNfugzpo1KzNmzEhVVdVcfa677rrsu+++KSkpmev6xx9/nBEjRtR8LL/88rnwwgtz8sknz/e9rr/++nzyySeprq7O+PHjc8QRR2TVVVdNx44d5+r32GOPZezYsenfv3+SpFOnThk+fHgqKirywgsvZOWVV15IsweApdOXX36Z8vLyJF//5lmjRo1Sp87/7bjctGnTTJkyZb73fl//rl275sgjj0yfPn3y4IMP5vzzz8+xxx6b448/Pm+99Vb69u2bTTfdNE899dRc45aXl+fLL79c2FMFFkCwDgAAi1CDBg3SoEGDJEmvXr3SoEGDPPHEEzXtb731Vp5//vl5toFJkvbt28/1UVJSkuWWWy7NmjVL8vXWM9/ecmbEiBHp1atXysrK0rNnz9StWzfDhg1LUVFRTZ+ZM2fmmGOOyRVXXFFz7Q9/+EOuuuqqdOzYMbvuumvWWWedhf51AIClSbNmzVJRUZEkKSsry/Tp0zNnzpya9smTJ6dx48bzvfeH9B84cGBGjBiRe++9Nx9++GHGjBmT/v3759e//nWuvfbaXH311enfv3+qq6tr7qmoqKj5HgFY9BbK4aUAAMD8ffsfvPPTpUuXeVawL8hHH3001+v+/fvXrDpPkosvvjgXX3zxd45RWlo6z2Goa665pu1fAKAAPXr0yNtvv50kWW211VK3bt2MHDmy5ofTI0aMqDnY9L8V0n/WrFk56qijctttt+Xzzz/PnDlz0qlTp5q2zz//PK1atUry9Q/rd9lll4U+V2D+rFgHAAAAgAJsu+22efTRR5MkDRs2zO67756TTjopkydPzrvvvptLL700Bx544HzvLaT/2WefnV133TWdO3dOixYtMnPmzIwcOTKvvfZaZs2aleWWWy7J1weivvjii9lqq60W3aSBuQjWAQAAAKAAW221VSZMmJA33ngjSXLZZZelSZMmad++fX7xi1/kgAMOyN57713Tf8stt8xZZ51V8/r7+idfH3J67733ZtCgQUmSkpKS/OlPf8qWW26ZLbfcMldddVXN+Sx33HFHNtlkk6y44oqLeurAf9gKBgAAAAAKUFJSkrPOOitnnHFGbr311pSXl+fmm29eYP9hw4bN9fr7+idfbxnz0ksvzXVt9913z+677z7Xtaqqqpx33nm55ZZbCpwF8GMI1gEAAACgQP369Uu/fv1qu4wUFxfntddeq+0yYJljKxgAAFiEbrnlluy22261XcZ8HXTQQbnmmmtquwwAAFjiCNYBAGARqaqqypAhQ3LSSSfNt33OnDk58cQT06FDh5SXl2fHHXfMZ599tsDxrr/++qy22mpp0qRJWrRokZ122iljxoypab/11lvTrl27tGvXLrfffnvN9dmzZ2fdddfNqFGj5hrvxBNPzCmnnJKZM2f+yJkCAMCyRbAOAACLyP3335/mzZunW7du820/77zzct999+W5557Lp59+miZNmmTPPfdc4Hh9+/bN008/ncmTJ+eTTz7JyiuvnP333z9JUllZmQEDBuTBBx/Mfffdl0MOOSSVlZVJkvPPPz9bb7111lhjjbnG69ixY1ZdddW5QngAAOD72WMdAAAWkXvuuSd9+/ZdYPtdd92VI444Iu3atUuSnHbaaenYsWM++uijdOzYcZ7+K664Ys3n1dXVKS4uzrvvvpskmTBhQkpLS7PmmmsmSerWrZsvvvgiU6ZMyW233ZbnnntuvjVsuummueeee9K/f///dZoAALDMsWIdAAAWkREjRmT11VdfYHtVVVWqq6vnep3kOw8ge+qpp9K0adM0bNgwF1xwQU488cQkScuWLVNcXJyRI0dm5MiRKSkpSYsWLTJgwIBceOGFKS0tne94Xbp0yYgRI/6H2QEAwLLLinUAAFhEvvzyy5SXly+wfeutt87FF1+cX/7yl2nevHlOPvnkFBUVpaKiYoH3bLDBBpk0aVImTJiQa6+9Nl26dEmSFBcXZ+jQoRkwYECSZOjQobnpppvSoUOHdO7cOTvuuGMmTpyYfv365dBDD60Zr7y8PF9++eVCmjEAACwbrFgHAIBFpFmzZjUh+VlnnZWysrKUlZVlyy23TJIMHjw4m222WTbccMOsuuqq6dGjR8rKyrLccst979gtWrTIAQcckG222SbTpk1LkvTp0yfPPPNMnnnmmXTv3j3nnHNOzjvvvAwaNCg77rhjHnzwwVxyySVzHWJaUVGRZs2aLYLZAwDA0kuwDgAAi0iPHj3y9ttvJ0mGDBmSqVOnZurUqRk2bFiSpH79+rngggsyevTojB07NltttVVmzZqVXr16/aDxZ8+encmTJ+ezzz6bp23QoEEZPHhwmjdvnpEjR6ZXr16pX79+1lprrbz++us1/d5666306NHjx08WAACWIbaCAQCARWTbbbfN6aefvsD2cePGZdasWVlhhRXy3nvv5YADDsgxxxyT5s2bz7f/9ddfn1/+8pdp165dPv300xxxxBFZddVV5zno9LHHHsvYsWNrDiTt1KlThg8fnrZt2+aFF17IoEGDavo+8sgj2X///X/8ZAGgFow5vVttl8C3rHDy69/fCZYSVqwDAMAistVWW2XChAl544035ts+ZsyY9O3bN40aNcpmm22WbbbZJr///e9r2ocOHZquXbvWvB4xYkR69eqVsrKy9OzZM3Xr1s2wYcNSVFRU02fmzJk55phjcsUVV9Rc+8Mf/pCrrroqHTt2zK677pp11lknSTJ69Oi8/fbb2XXXXRf21AEAYKlmxToAACwiJSUlOeuss3LGGWfk1ltvnae9V69eef/99xd4f//+/WtWnSfJxRdfnIsvvvg737O0tDSvvPLKXNfWXHPNubZ/+cbvf//7nH766alfv/73TQUAAPgWwToAACxC/fr1S79+/Wq7jPm6+uqra7sEAABYItkKBgAAAAAACiBYBwAAAACAAgjWAQAAAACgAIJ1AAAAAAAogGAdAAAAAAAKIFgHAAAAAIACCNYBAAAAAKAAgnUAAAAAAChAndouAAAAfgpjTu9W2yXwX1Y4+fXaLgEAAP4nVqwDAAAAAEABBOsAAAAAAFAAwToAAAAAABRAsA4AAAAAAAUQrAMAAAAAQAEE6wAAAAAAUADBOgAAAAAAFECwDgAAAAAABRCsAwAAAABAAQTrAAAAAABQAME6AAAAAAAUQLAOAD+xcePGZbvttsvyyy+foqKijBgxYoF9hwwZkqKiotx9993zbf/1r3/9vWN89tln2WOPPdKyZcu0bNkygwYNSmVlZU37RRddlFatWqVz58554oknaq5PmjQpXbt2zeeff17oFAEAAGCpJlgHgJ9YcXFxtthiiwWG5d8YOXJk7r333rRt23a+7ffdd18+/fTT732/vfbaK6WlpRk9enRGjhyZhx9+OH/4wx+SJOPHj8+ZZ56ZkSNH5oILLsjhhx9ec9/xxx+fQYMGpWXLlj98cgAAALAMEKwDwE+sdevWOeyww7L++usvsE9lZWUOPPDAXHbZZalXr9487VOmTMnRRx+dK6+88jvfa9q0aRk+fHhOOeWUNGzYMMsvv3yOOuqoXH311UmS0aNHZ5VVVknbtm3zq1/9Ku+//36S5Omnn867776b/fbb70fMFAAAAJZOdWq7AABgXhdeeGG6d++ejTfeeL7tgwcPzl577ZVVVlnlO8eprq6u+fhGVVVVRo8enYqKiqyyyir58MMP88knn+TVV19Nt27dMnv27BxxxBG5+eabF+qcAAAAYGkhWAeAxcwHH3yQyy67LK+88sp825955pk89thjC2z/trKysmy00UY55ZRTcuWVV2bixIm5+OKLkyQVFRVp3759Lr300uywww4pLy/Ptddemz/84Q/ZYYcdMnv27Gy55Zb56quvcuSRR2bHHXdcqPMEAACAJZWtYABgERs6dGjKyspSVlaWrl27fm//gw8+OGeeeWaaN28+T9usWbNy8MEH509/+tN8t4hZ0Pt/9dVX6dy5czbbbLOaA0+bNWuWJNl1113z0ksv5ZFHHkn9+vVz55135vjjj88BBxyQwYMH56677soRRxyRL7/8srCJAwAAwFJKsA4Ai1j//v0zderUTJ06NW+++eb39n/44Ydz1FFHpUWLFmnRokU+/vjj7L333jn66KMzduzYjBo1KjvuuGNNe5JssskmueCCC+Y7Xvv27XPHHXdk/Pjx+de//pXGjRtn3XXXTaNGjebpO2DAgFxyySWpV69eRo4cmV69eqVZs2Zp37593n333R/3hQAAAIClhK1gAKAWzJgxo+bzWbNmZcaMGalXr16Ki4vz8ccfz9W3d+/eOfXUU7PTTjulvLw8o0ePnqu9Q4cOufXWW9O7d+/5vtfbb7+dNm3apHHjxnnyySdz5pln5rrrrpun31/+8pesvPLK2WCDDZIknTp1yvDhw9OzZ8+8++67WXHFFX/stAEAAGCpIFgHgFrQoEGDms979eqVJHn00UfTp0+ftG/ffq6+JSUlWW655Wq2bvnv9iRp1apVGjdunCQ566yz8uSTT2bYsGE145566qmZMmVKVllllVxxxRXZYost5rp/woQJOe+88/LUU0/VXLv88suz//77Z+rUqTnllFPSunXrhTBzAAAAWPIJ1gGgFlRXV//gvh999FFBYw0ZMmSu1wMGDMiAAQO+c4wWLVrkjTfemOtanz598sEHH/zgOgEAAGBZYY91AAAAAAAogGAdAAAAAAAKIFgHAAAAAIACCNYBAAAAAKAAgnUA+Anccsst2W233Wq7jP/JQQcdlGuuuaa2ywAAAIDFhmAdABaxqqqqDBkyJCeddNL39h0yZEiKiopy991311y74YYbUlJSkrKyspqPc889d4FjnH/++enevXvKy8vTvn37DBo0KLNmzappv/XWW9OuXbu0a9cut99+e8312bNnZ911182oUaPmGu/EE0/MKaeckpkzZxYwawAAAFh6CdYBYBG7//7707x583Tr1u07+40cOTL33ntv2rZtO09bt27dMnXq1JqP4447boHjVFZW5rrrrssXX3yR5557Lo899lhOPfXUmrYBAwbkwQcfzH333ZdDDjkklZWVSb4O5LfeeuusscYac43XsWPHrLrqqnOF8AAAALAsE6wDwCJ2zz33pG/fvt/Zp7KyMgceeGAuu+yy1KtX70e93/HHH5/11lsvdevWTfv27bP33nvnqaeeSpJMmDAhpaWlWXPNNdOjR4/UrVs3X3zxRd5///3cdtttGTJkyHzH3HTTTXPPPff8qLoAAABgaSFYB4BFbMSIEVl99dW/s8+FF16Y7t27Z+ONN55v+zvvvJNWrVplpZVWymGHHZZJkyb94Pd//PHH07179yRJy5YtU1xcnJEjR2bkyJEpKSlJixYtMmDAgFx44YUpLS2d7xhdunTJiBEjfvB7AgAAwNKsTm0XAABLuy+//DLl5eULbP/ggw9y2WWX5ZVXXplv+0YbbZTXX389nTp1yujRo3PQQQdln332yd///vfvfe9rrrkmTz/9dF599dUkSXFxcYYOHZoBAwYkSYYOHZqbbropHTp0SOfOnbPjjjtm4sSJ6devXw499NCaccrLy/Pll18WMm0AAABYagnWAWARa9asWSoqKpIkZ511Vs4666wkyYYbbphhw4bl4IMPzplnnpnmzZvP9/5OnTrVfL7SSivlkksuSbdu3TJ9+vQ0bNhwge87dOjQ/O53v8vw4cPn2re9T58+eeaZZ5IkEydOzMCBA/PEE0/ksMMOy4477pjddtstPXv2zMYbb1yz33pFRUWaNWv2474QAAAAsJSwFQwALGI9evTI22+/nSQZMmRIzQGkw4YNS5I8/PDDOeqoo9KiRYu0aNEiH3/8cfbee+8cffTR8x2vuPjrv76rq6sX+J5Dhw7NUUcdlQceeKBmG5j5GTRoUAYPHpzmzZtn5MiR6dWrV+rXr5+11lorr7/+ek2/t956Kz169Ch06gAAALBUEqwDwCK27bbb5tFHH11g+8cff5wRI0bUfCy//PK58MILc/LJJydJ7r///owbNy5J8sknn+TII4/MFltskUaNGs13vJtvvjlHHHFEhg0blrXXXnuB7/vYY49l7Nix6d+/f5KvV8YPHz48FRUVeeGFF7LyyivX9H3kkUeyzTbbFDx3AAAAWBoJ1gFgEdtqq60yYcKEvPHGG/Ntb9++/VwfJSUlWW655Wq2Xnn00Uez9tprp2HDhundu3c6deqUv/71rzX3Dx06NF27dq15PWTIkFRUVKRPnz4pKytLWVnZXO1JMnPmzBxzzDG54ooraq794Q9/yFVXXZWOHTtm1113zTrrrJMkGT16dN5+++3suuuuC+1rAgAAAEsye6wDwCJWUlKSs846K2eccUZuvfXW7+3/0UcfzfX6vPPOy3nnnbfA/v37969ZdZ4kH3744fe+R2lp6TyHpa655ppzbf/yjd///vc5/fTTU79+/e8dFwAAAJYFgnUA+An069cv/fr1q+0y/idXX311bZcAAAAAixVbwQAAAAAAQAEE6wAAAAAAUADBOgAAAAAAFECwDgAAAAAABRCsAwAAAABAAQTrAAAAAABQAME6AAAAAAAUQLAOAAAAAAAFqFPbBQBAbRpzerfaLoH/ssLJr9d2CQAAAPCdrFgHAAAAAIACCNYBAAAAAKAAgnUAAAAAACiAYB0AAAAAAAogWAcAAAAAgAII1gEAAAAAoACCdQAAAAAAKIBgHQAAAAAACiBYBwAAAACAAgjWAQAAAACgAIJ1AAAAAAAogGAdAAAAAAAKIFgHAAAAAIACCNYBAAAAAKAAgnUAAAAAACiAYB0AAAAAAAogWAcAAAAAgAII1gEAAAAAoACCdQAAAAAAKIBgHQAAAAAACiBYBwAAAACAAgjWAQAAAACgAIJ1AAAAAAAogGAdAAAAAAAKIFgHAAAAAIACCNYBAAAAAKAAgnUAAAAAACiAYB0AAAAAAAogWAcAAAAAgAII1gEAAAAAoACCdQAAAAAAKIBgHQAAAAAACiBYBwAAAACAAgjWAQAAAACgAIJ1AAAAAAAogGAdAAAAAAAKIFgHAAAAAIACCNYBAAAAAKAAgnUAAAAAACiAYB0AAAAAAAogWAcAAAAAgAII1gEAAAAAoACCdQAAAAAAKIBgHQAAAAAACiBYBwAAAACAAgjWAQAAAACgAIJ1AAAAAAAogGAdAAAAAAAKIFgHAAAAAIACCNYBAAAAAKAAgnUAAAAAACiAYB0AAAAAAAogWAcAAAAAgAII1gEAAAAAoACCdQAAAAAAKIBgHQAAABaBa6+9NquuumoaN26c1VdfPTfddFNN21lnnZWysrKaj0aNGqWoqCh33nnnAsebNGlSDjzwwLRo0SLl5eVZd911M3369CTJG2+8ke7du6d58+Y54YQT5rrv0EMPzXXXXbdoJgkAyyjBOgAAACxkr776ag477LBcddVVqaioyOWXX579998/b731VpJkyJAhmTp1as3HjTfemCZNmmTLLbec73hVVVXZZpttUrdu3fzrX//KpEmTcs0116Ru3bpJkuOPPz4DBgzIhx9+mNtuuy0vv/xykuTpp5/Ov/71r+y///4/zcQBYBkhWAcAAICF7MMPP0zHjh2zySabpKioKJtuumk6dOhQE6z/t+uuuy79+vVLgwYN5ts+bNiwjBkzJpdeemmaN2+e4uLirL322jXB+gcffJC+ffumSZMmWX/99fP+++9n9uzZOeKII/KnP/0pRUVFi2yuALAsEqwDAADAQrb55puncePGGT58eKqqqvLggw9m0qRJ2WCDDebp+8knn+TBBx/MgQceuMDxHn/88XTu3Dl77bVXlltuuXTt2jV/+ctfatq7deuW4cOHZ9KkSXn55Zez5ppr5txzz812222X1VZbbZHMEQCWZYJ1AAAAWMgaNmyYPffcM9ttt13q1auX7bbbLhdddFHatGkzT9/rr78+3bt3zzrrrLPA8SZOnJhHH300v/jFLzJu3LhcffXVGThwYJ544okkyR//+Mc8+OCD6dOnT4488sjUq1cvd9xxR377299m4MCB2WijjfKb3/wms2fPXmRzBoBliWAdAAAAfqShQ4fWHETatWvX/PnPf87555+f5557LrNmzcoLL7yQE044Iffdd99c91VXV+f666/PAQcc8J3jl5WVpX379hk4cGDq1auXX/ziF9lhhx3yj3/8I0nSoUOH3HvvvRkxYkQGDhyYAQMG5OKLL87f/va3TJ8+PU888USmTJmSP//5z4vsawAAyxLBOgAAAPxI/fv3rzmI9M0338yrr76aLbfcMmuttVaKi4uz1lpr5Ve/+lWGDRs2130PP/xwxo0blz333PM7x19rrbV+cC033nhjOnbsmA033DAjR45Mr169kiS9e/fOyJEjC58cADAPwToAAAAsZL17986DDz6YN998M0ny5ptv5sEHH8zaa689V7/rrrsuO+20U5o2bfqd4+24446ZMWNGrrzyylRWVub555/P3//+92y33XZz9fviiy9y7rnn5txzz02SdOrUKY888khmz56dRx55JCuvvPLCmyQALMME6wAAALCQ9e/fP4cddli23XbblJWVZauttsr++++f/fffv6bPxIkTc9ddd8330NIxY8akrKwsY8aMSZI0bdo09913X6677rqUl5dn7733zuWXXz7PYai//e1v87vf/S7NmjVLkhxyyCGZMmVKWrRokWnTpuWQQw5ZhLMGgGVHndouAAAAAJZGgwcPzuDBgxfY3rx588yYMWO+bSussEKmTp0617X1118/L7744ne+5w033DDX6/Ly8tx///0/rGAA4Adb4lasX3755enYsWPq16+fXr165YUXXvjO/v/v//2/rL766qlfv366devmGwoAAAAAAH6UJSpYv/XWW3PMMcfklFNOySuvvJK11lorm2++eT777LP59n/mmWfSr1+/HHDAAXn11Vezww47ZIcddsgbb7zxE1cOAAAAAMDSYokK1i+44IIcdNBB2W+//dKlS5dceeWVadiwYf785z/Pt//FF1+cLbbYIscee2zWWGONnHHGGenZs2cuu+yyn7hyAAAAAACWFktMsD5r1qy8/PLL2WyzzWquFRcXZ7PNNsuzzz4733ueffbZufonyeabb77A/gAAAAAA8H2WmGB9woQJqaysTOvWree63rp164wfP36+94wfP76g/kkyc+bMVFRUzPUBAADAsu2WW27JbrvtVttlLBK/+tWv8tBDD9V2GQCwRKlT2wUsbs4+++ycdtppP/n7vnze3j/5e/LdxpzerbZL4FtWOPn12i5hofG8L278/2DR8Kwvjvw/YdHwvC9+Fvb38lVV1Tnukn/l2n4rznfsdz6dkTMfHJ/Xx32VL6dX5rUT1kiTBiU17c98ODUXP/Z53hz3VYqKktcHd5nr/gsf/TSXPvF5Suv839q3c7dvl23XbDLfev7xxuRc99yEvDV+RjotV5phAzrP1X7dsxNy+ZOfp6y0JOdt3y69OjZKkkz+qjI7X/dBbt1vpSzX6P/igAPbT8uRe207zzgL09Ly/bznfXHk/wlQO5aYFestWrRISUlJPv3007muf/rpp2nTps1872nTpk1B/ZNk8ODBmTx5cs3Hxx9//OOLBwAAYIn16LtT0rRBSVZvXX++7XVKirJ11/L8cYd2821vWLc4u/dsmt9tvuB/i266auOMOrFLzceCQvUkadqgJAf8rEUGbthynrbPpszOpU98nmEDOuekzdvkpPvG1rSdM3x8Dv5Fi7lC9STptWLDVMyozItjpi3wPQGAuS0xwXq9evWyzjrr5OGHH665VlVVlYcffji9e/ee7z29e/eeq3+SDB8+fIH9k6S0tDTl5eVzfQAAALDsGv7OlPx8pbIFtq/cojR7rNM8q7aaf/Deo33D7LRWs6zYvN5CqWeDlcuyzZpN0qa87jxt/548Ox2b10vrxnWz4cplGf3lrCTJi2Om5cOJs7Lb2s3muaeoqCg/X6lRHnp7ykKpDwCWBUvUVjDHHHNM9tlnn6y77rpZf/31c9FFF2XatGnZb7/9kiR777132rVrl7PPPjtJcuSRR2bjjTfOH//4x2y99da55ZZb8tJLL+Xqq6+uzWkAAACwBHlr/Iz0X7f5In2PZz6clrXOGZVmDUuyVZcmOWLjlqlft/C1cCs1r5dPJs3OuMmz8+b4r7J6q/qZXVmdU+8fl0t36bDA+1ZpWT9Pvj/1x0wBAJYpS1Swvvvuu+fzzz/PySefnPHjx6dHjx554IEHag4oHTNmTIqL/+8bj5///Oe56aab8rvf/S5DhgzJKquskrvvvjtrrrlmbU0BAACAJczkrypTVrrofuF7665NskfP5mnduE7e/Xxmjrrzk0yfVZVTt2pb8FhNG9bJaVu1zUG3jE5ZaUn+sH27/Ompz/Or1cszp6o6e//1o8ycU5X9ftYiW6zxf7+h3bi0OJNnVC7MaQHAUm2JCtaTZODAgRk4cOB82x577LF5ru26667ZddddF3FVAAAALK2aNCjJ1JlVSZLLnvgslz85IUmy3goNc+NeHX/0+N/eQma11vVz7Katc9zf//0/BevJ10H91l2/3qP9wy9m5oFRFbn7wE7Z7foPM/iXbbJ66/rZ/Ip307tjo5pDVqfMrEqT+iXfNSwA8C1LXLAOAAAAP6Uubern/QkzkyQDN2qVgRu1WqTvV1y08MY68R9jc9qWbVOvTnHeGj8jPdo3SGmd4rQpr5sPv5iZHu0bJkne/XxGurSZ/x7xAMC8lpjDSwEAAKA2bLZa4zz74bQFtldXV2fG7KrMqqxOksyq/Pp1dfXXr6uqvn49+z/tM2ZXZcbsqpr7HxhVkS+nz0mSvD9hZs59+NO5tmn5b5X/GW9OZXWqq78eb+acqnn63T7iy6zYrF7WW7FRkmSFZvXy1PtT82nF7Hw0cVbaNf2/w1Sf/WhaNl2t8Q/9kgDAMs+KdQAAAPgOm6zSOKfcPy7vfDojq7Wed1X3J5NmZ4OL/lXzet3z3k6SPHXUqunQrF6eHz0te9zwUU37ame+lSQZfdrX53/d9+bknHDPvzNjdlValNXJtl2b5Mg+/7cq/rInPssLo6fXbDtz58hJGXT3v+car33Tunn66NVqrk2cNidXPT0ht+/fqebaGVu3zbF//3emz6rKkRu3SsuyryOBF0ZPS+PSkqz/nwAeAPh+RdXf/Aid+aqoqEiTJk0yefLklJcveMUAS58xp3er7RL4lhVOfr22SwAAYAmxKL6X//vrk/LPURW5fLcVFvrYtW2vGz/Kwb9okQ1XLltk7+H7eWBhkNOxOLFiHQAAAL7H9t2aZvtuTWu7jEXir3t3rO0SAGCJY491AAAAAAAogGAdAAAAAAAKIFgHAAAAAIACCNYBAAAAAKAAgnUAAAAAACiAYB0AAAAAAAogWAcAAAAAgAII1gEAAAAAoAB1arsAAAAAWJhWOPn12i4BAFjKWbEOAAAAAAAFEKwDAAAAAEABBOsAAAAAAFAAwToAAAAAABRAsA4AAAAAAAUQrAMAAAAAQAEE6wAAAAAAUADBOgAAAAAAFECwDgAAAAAABRCsAwAAAABAAQTrAAAAAABQAME6AAAAAAAUQLAOAAAAAAAFEKwDAAAAAEABBOsAAAAAAFAAwToAAAAAABRAsA4AAAAAAAUQrAMAAAAAQAEE6wAAAAAAUADBOgAAAAAAFECwDgAAAAAABRCsAwAAAABAAQTrAAAAAABQAME6AAAAAAAUQLAOAAAAAAAFEKwDAAAAAEABBOsAAAAAAFAAwToAAAAAABRAsA4AAAAAAAUQrAMAAAAAQAEE6wAAAAAAUADBOgAAAAAAFECwDgAAAAAABRCsAwAAAABAAQTrAAAAAABQAME6AAAAAAAUQLAOAAAAAAAFEKwDAAAAAEABBOsAAAAAAFAAwToAAAAAABRAsA4AAAAAAAUQrAMAAAAAQAEE6wAAAAAAUADBOgAAAAAAFECwDgAAAAAABRCsAwAAAABAAQTrAAAAAABQAME6AAAAAAAUQLAOAAAAAAAFEKwDAAAAAEABBOsAAAAAAFAAwToAAAAAABRAsA4AAAAAAAUQrAMAAAAAQAEE6wAAAAAAUADBOgAAAAAAFECwDgAAAAAABRCsAwAAAABAAQTrAAAAAABQAME6AAAAAAAUQLAOAAAAAAAFEKwDAAAAAEABBOsAAAAAAFAAwToAAAAAABRAsA4AAAAAAAUQrAMAAAAAQAEE6wAAAAAAUADBOgAAAAAAFECwDgAAAAAABRCsAwAAAABAAQTrAAAAAABQAME6AAAAAAAUQLAOAAAAAAAFEKwDAAAAAEABBOsAAAAAAFAAwToAAAAAABRAsA4AAAAAAAUQrAMAAAAAQAEE6wAAAAAAUADBOgAAAAAAFECwDgAAAAAABRCsAwAAAABAAQTrAAAAAABQAME6AAAAAAAUQLAOAAAAAAAFEKwDAAAAAEABBOsAAAAAAFAAwToAAAAAABRAsA4AAAAAAAUQrAMAAAAAQAEE6wAAAAAAUADBOgAAAAAAFECwDgAAAAAABRCsAwAAAABAAQTrAAAAAABQAME6AAAAAAAUQLAOAAAAAAAFEKwDAAAAAEABBOsAAAAAAFAAwToAAAAAABRAsA4AAAAAAAUQrAMAAAAAQAHq1HYBwA/34phpOekf4/LhxJnptFxpztxm+azToeH/1H98xewcdtvHeffzGfnlauU5f4d2KS4uSpJc8eTnmT6rKoM2bf2TzAsAAAAAliRWrMMSYtL0Odl/6Ojss37zvHbCGtl7vebZf+joTP6q8n/qf9kTn2f9FRvmxUGr58OJM/PA2xVJkjETZ+XeNybnNxu3/MnmBgAAAABLEsE6LCEeGFWRNuV102/d5imtU5x+6zZPy7I6efA/gXih/cd8OSu9V2qU+nWL02vFRhkzcVaS5MR/jM1JW7RJaR1/PAAAAADA/EjOYAnx9qcz06VN/bmudWlTP2+Pn/E/9V+9df089f60zJhdlRdGT89qrevnrtcmpXXjOvn5SmWLZhIAAAAAsBQQrMMSYtqsypTXL5nrWnn9kkydVfU/9T98w5b5dMrsbH/N+/n5So2ydrsGueLJz3Pi5m1ywSOfZtc/f5Cj7/wkU2bMf6sZAAAAAFhWObwUFlN3vTYpQ+4dmyRp16RuNuhUlklfzZmrz5SZlVmu4fwf40b1Sr6zf5MGJblklw41bcfe/UkGbNAyI//9VV76eHpu3XelXPz4Z7niyc9z/C/bLMypAQAAAMASzYp1WEzt2L1pRp3YJaNO7JKHBq6S1VuX5q3/2vblrfEzslrr+vO9v5D+z300LeMr5mSntZpm1PgZWWv5BikuLkrPDg3z1qfz32oGAAAAAJZVgnVYQmyxRnnGVczOLS9PzKw5Vbnl5Yn5bMqcbLFG+Y/qP3NOVU5/YFx+v83ySZIVmtfL86OnZ+acqjz1/rSs2KzeIp8bAAAAACxJBOuwhGjasE7+/OsVc/3zX2TNs0flhucn5rpfr5gmDb7eR/3fk2Zljd+/lX9PmvWD+n/jiic/zzZdm2SF5l8H6FusUZ4OzepmnXPfziufTM/hG7b8aScKAAAAAIu5ourq6uraLmJxVlFRkSZNmmTy5MkpL5//ymCWTmNO71bbJfAtK5z8em2XAAAAANQiOR2LEyvWAQAAAACgAIJ1AAAAAAAogGAdAAAAAAAKIFgHAAAAAIACCNbhJ3TP65Ny2G1jaruMRWLPGz/MU+9Pre0yAAAAAGCRq1PbBcCyoqqqOuc+/Gmu7bfifNtvH/FlbnxhYj6YMDP16xZnk1XK8rvN26ZJg5IkyVVPT8idI7/MJ5Nmp6y0ONuu2STHbdo69ep8/fOx3z84Pg+9U5FPp8xJs4Yl+fU6zXP4Ri0XWM/syuqc/sC43P3apBQVFWWHbk1y8hZtU6ekKEly3bMTcvmTn6estCTnbd8uvTo2SpJM/qoyO1/3QW7db6Us1+j//ggZuFGrnDZsXIYN6LxQvl4AAAAAsLiyYh1+Io++OyVNG5Rk9db159v+1ayqDP5l67x07Op56PDO+WzqnPzuvrE17VVV1Tl3+3YZcfwaufvAlfPcR9Ny0WOf1bSX1inKVXuskNcHr5G/7NkxN708MTe9NHGB9Vz6+Gd5acz0PDRwlQw/vHNeHDM9lz/5eZLksymzc+kTn2fYgM45afM2OelbdZwzfHwO/kWLuUL1JOm1YsNUzKjMi2Om/U9fHwAAAABYUgjW4Scy/J0p+flKZQts32v95dJ7pbLUr1ucpg3rZM91m+elMdNr2gds2DJrtWuYuiVFadukbnZeq1le/Fb7oE1bZ9VW9VNSXJTOLUuz+Rrlc7X/t9te/TIDN2qZ1o3rpnXjuhm4Ucvc+sqXSZJ/T56djs3rpXXjutlw5bKM/nJWkuTFMdPy4cRZ2W3tZvOMV1RUlJ+v1CgPvT2l4K8NAAAAACxJBOvwE3lr/Iys3KL0B/d/7qNpC1zd/n3t1dXVeWH0gtsnf1WZcRVz0rXN/7V3aVM//548OxUzKrNS83r5ZNLsjJs8O099MDWrt6qf2ZXVOfX+cTlrm+UXWNMqLevnrfEzfuAMAQAAAGDJZI91+IlM/qoyZaU/7GdZj747Jbe+8mVuP6DTfNtvfmliXv54eu47dOX5tp/38Gf5anZ19lqv+Xzbp82qTJKU1y+pufbN59NmVqVtk7o5bau2OeiW0SkrLckftm+XPz31eX61ennmVFVn779+lJlzqrLfz1pkizXKa8ZoXFqcyTMqf9AcAQAAAGBJJViHn0iTBiWZOrMqSXLZE5/l8icnJEnWW6FhbtyrY02/pz+YmqPu+CRX7rHCfFec3/XapJz/yKf5294rpXXjuvO0X/Hk57n3jUm5bb9OaVhv/kF+o3pfh+hTZlam+X/2Sp/yn0C80X/C/627NsnWXZskST78YmYeGFWRuw/slN2u/zCDf9kmq7eun82veDe9OzaqOWB1ysyqNPlWWA8AAAAASyPBOvxEurSpn/cnzEySDNyoVQZu1GqePk9/MDUDbvs4l+7SPht0mnc/9rtem5TTh43LX/fumDXazBu6X/Hk5xn60sTcut9Kadtk3tD9G00alKRteZ28OX5GVmz+9fY0b46fkeWb1J1rFfs3TvzH2Jy2ZdvUq1Oct8bPSI/2DVJapzhtyuvmwy9mpkf7hkmSdz+fkS7zqQsAAAAAlib2WIefyGarNc6zH05bYPuzH07NobeOyYU7tc/GnRvP0/731yfl1PvH5S97dsyabRvM037lU5/nry9OzM37rpT2Tet9bz27rt0slz3xeT6bMjufTZmdy5/8PHv0nPdQ0ttHfJkVm9XLeis2SpKs0Kxennp/aj6tmJ2PJs5Ku2+917MfTcumq81bOwAAAAAsTaxYh5/IJqs0zin3j8s7n87IavPZ4uWixz7P1JlVGfj/Pp7r+qgTuyRJzn3o00ydWZndb/iwpq1dk7p5aOAqSZKzh3+auiVF2fyK92rav73NzJB7/50kOWvbdkmSIzZulS+nV2bTy95NkuzYvWkO37DlXO89cdqcXPX0hNy+///t9X7G1m1z7N//nemzqnLkxq3SsuzrP0ZeGD0tjUtLsv5/AngAAAAAWFoVVVdXV9d2EYuzioqKNGnSJJMnT055efn338BSY8zp3Rb6mH9/fVL+Oaoil++2wkIfu7btdeNHOfgXLbLhyvNuYbMwrHDy64tkXAAAAGDJIKdjcWLFOvyEtu/WNNt3a1rbZSwSf927Y22XAAAAAAA/CXusAwAAAABAAQTrAAAAAABQAME6AAAAAAAUQLAOAAAAAAAFEKwDAAAAAEABBOsAAAAAAFAAwToAAAAAABRAsA4AAAAAAAWoU9sFwOJqhZNfr+0SAAAAAIDFkBXrAAAAAABQAME6AAAAAAAUQLAOAAAAAAAFEKwDAAAAAEABlphgfeLEienfv3/Ky8vTtGnTHHDAAZk6dep33tOnT58UFRXN9XHooYf+RBUDAAAAALA0qlPbBfxQ/fv3z7hx4zJ8+PDMnj07++23Xw4++ODcdNNN33nfQQcdlNNPP73mdcOGDRd1qQAAAAAALMWWiGB91KhReeCBB/Liiy9m3XXXTZJceuml2WqrrXL++edn+eWXX+C9DRs2TJs2bX6qUgEAAAAAWMotEVvBPPvss2natGlNqJ4km222WYqLi/P8889/571Dhw5NixYtsuaaa2bw4MGZPn36oi4XAAAAAICl2BKxYn38+PFp1arVXNfq1KmT5s2bZ/z48Qu879e//nVWXHHFLL/88nnttddy/PHH55133smdd965wHtmzpyZmTNn1ryuqKj48RMAAAAAAGCpUavB+gknnJA//OEP39ln1KhR//P4Bx98cM3n3bp1S9u2bbPpppvm/fffz8orrzzfe84+++ycdtpp//N7AgAAAACwdKvVYP23v/1t9t133+/s06lTp7Rp0yafffbZXNfnzJmTiRMnFrR/eq9evZIk77333gKD9cGDB+eYY46peV1RUZEOHTr84PcAAAAAAGDpVqvBesuWLdOyZcvv7de7d+9MmjQpL7/8ctZZZ50kySOPPJKqqqqasPyHGDFiRJKkbdu2C+xTWlqa0tLSHzwmAAAAAADLliXi8NI11lgjW2yxRQ466KC88MILefrppzNw4MDsscceWX755ZMk//73v7P66qvnhRdeSJK8//77OeOMM/Lyyy/no48+yj333JO99947G220Ubp3716b0wEAAAAAYAm2RATrSTJ06NCsvvrq2XTTTbPVVltlgw02yNVXX13TPnv27LzzzjuZPn16kqRevXp56KGH8qtf/Sqrr756fvvb32bnnXfOvffeW1tTAAAAAABgKVBUXV1dXdtFLM4qKirSpEmTTJ48OeXl5bVdDgAAAAAsk+R0LE6WmBXrAAAAAACwOBCsAwAAAABAAQTrAAAAAABQAME6AAAAAAAUQLAOAAAAAAAFEKwDAAAAAEABBOsAAAAAAFAAwToAAAAAABRAsA4AAAAAAAUQrAMAAAAAQAEE6wAAAAAAUADBOgAAAAAAFECwDgAAAAAABRCsAwAAAABAAQTrAAAAAABQAME6AAAAAAAUQLAOAAAAAAAFEKwDAAAAAEABBOsAAAAAAFCAOrVdwOKuuro6SVJRUVHLlQAAAADAsuubfO6bvA5qk2D9e0yZMiVJ0qFDh1quBAAAAACYMmVKmjRpUttlsIwrqvYjnu9UVVWVsWPHpnHjxikqKqrtcviJVFRUpEOHDvn4449TXl5e2+UAi4hnHZYdnndYdnjeYdnheV/2VFdXZ8qUKVl++eVTXGyHa2qXFevfo7i4OO3bt6/tMqgl5eXl/nKGZYBnHZYdnndYdnjeYdnheV+2WKnO4sKPdgAAAAAAoACCdQAAAAAAKIBgHeajtLQ0p5xySkpLS2u7FGAR8qzDssPzDssOzzssOzzvQG1yeCkAAAAAABTAinUAAAAAACiAYB0AAAAAAAogWAcAAAAAgAII1gEAAAAAoACCdQAAAACWGjNnzqztEoBlgGAdAP6jurq6tksAFrGxY8fWdglALbjxxhtz++23580336ztUoBF5Jvv5YcMGZI+ffpk3LhxtVwRsLQTrMMiVFlZOd/rwjtYfNxxxx1ZbbXVMmrUqBQVFXk+YSl18803Z911183OO++crbfeOv/4xz+SJFVVVbVcGbAoDR06NK1atcqf/vSnHH/88dlpp51y9dVXJ/H8w9KmqKgoM2fOzK233prnn38+f/nLX2q7JGApV1QtQYBForq6OkVFRUmSf/zjHykpKckKK6yQrl271nJlQJJMnTo15513Xm644YaMHz8+m222We67777aLgtYyCZOnJhjjz02DzzwQE444YSUlZXl/vvvz/DhwzNhwoTUqVOntksEFoGqqqr8+c9/zkUXXZQjjzwyBxxwQN5+++387W9/y913350XX3wxjRo1qu0ygYVs5MiROeuss7L++uvnpJNOyquvvprVVluttssCllJWrMMiUlRUlBEjRqR79+75zW9+k9NOOy0bbLBBrr/++kybNq22y4NlVmVlZaqrq/PFF19k7NixOfHEE3PXXXflwQcfzL333pvECjZYGlRWVqaysjKvvvpqXn/99fz973/Pb37zm+y333658MIL06pVq9x88821XSawiFRWVqaioiLbbLNN9tlnnxQXF6dLly7p1q1b6tWrl88//7y2SwQWgfr16+edd97JIYcckpVXXjmnnnpqbZcELMUs0YFFpLKyMqecckp+9rOf1fy66amnnprDDz88rVq1ytZbb13LFcKy56qrrsqLL76YXXfdNZtvvnkGDBiQHj16pKioKPvss0+OPvrobLvttiku9nNnWJJ986zvsssu6dSpU4488sisvfbaNe316tXLjBkz0rJly1qsElgUqqqqUlxcnLp162annXbKCiuskOLi4prfJm3VqlUmT56c1q1b13apwI/07d8S/8Yrr7ySDh06pKysLGeffXa23377DBgwIP/617/Sq1evdOvWrZaqBZZGkgP4kRa0j/qzzz6bUaNG5bLLLkuSnHLKKbn44ouz/fbbp2fPnj9libDMGz58eFZaaaVcdtlladKkSWbMmJE5c+akZ8+eNSH6Mccck4kTJ+bcc89NsuBnG1h8fftZLy8vz5w5c7Liiiumf//+KSkpSfL1s/3VV1+luro6rVq1quWKgYXh2+elFBcX1/zmWceOHWtefxO+DRs2LF27dk2DBg0ye/bs2iwb+B8s6Hykb/5bVFSU5s2bJ0m22Wab9OzZM5tsskmuuOKKeUJ4gB/LinX4Eaqrq2v+of7OO++kSZMmadOmTZKkcePGSb4+MOmMM85IkyZNcvPNN2eLLbZIksyYMSP169evncJhGfL444/nmGOOySGHHJKjjjoqRUVFKS0trWn/ZmXbGmuskUGDBuWMM87IgQceWPMNObBk+O9nPclcf89+8w/ukpKSvPLKKykvL/eDbljC/fd5KYMGDcp99903z2+eFRcXp7KyMiUlJXnxxRez5ZZbJknq1q1b0+eb7weAxdOCnvdvwvJv/vvmm29m9dVXz7hx47LddtvlnXfeSXFxcfbff/+sueaatTkFYCnkOwf4gT777LOaz79ZyVpUVJR3330366yzTjbffPNssMEGueuuuzJnzpyUlpamadOmGTBgQE444YQ8//zzNaH6zTffnL/+9a+1Mg9Y1tx///1p27ZtDj300NSvX3+uUD1JzT+ii4uLs++++6ZDhw757W9/myR59dVX8+STT8Y537D4++9n/b9/eF1UVFTzj+577rkn6623Xk3b+PHjM2XKlJ+0XuB/97+cl1JcXJypU6fmo48+yiabbJIk+de//pW99tqrph1Y/PzQ5/3bK9ZPO+20dOjQIV27ds27776bY489NmeddVbGjh1bm1MBlkK+e4Af4MILL8x+++2Xjz/+OMnXq92mT5+eF154IX/84x+zySab5Lbbbsv6669f85Pz1VZbLT//+c/TuXPn9OrVK/Xq1UuSjBgxItddd13efvvtzJw5szanBcuE1157Lc2bN0/Tpk2TJA888EAuuuiiHHPMMTnvvPPyzjvvJPl6Nevyyy+f0047LX/729+y0047ZZ111skzzzwjWIclwA991isqKvL8889nm222SVVVVU488cQsv/zy+cc//lGL1QM/1FVXXZVDDjkk//znP7PiiitmwIABOfDAA7PlllvWnJeSzBuUFxUV5cknn0zLli2z2mqr5aijjkr37t0zduzYzJo1y9/1sBj6X573Tp06Za+99soTTzyRG264Ia1bt86xxx5b8+93gIWpqNp3ELBAn3zySdq3b58RI0akefPmWWGFFWra9tlnn9x9993p2bNn/t//+39p0aJFkqRv375p3rx5Lr/88kyaNClDhgzJP//5z/zyl79M/fr1c9ddd2XffffNhRdeaCsY+An885//zBZbbJGNN944H330UUpLS7PCCivk008/zfTp01NcXFwTuE2bNi0XXnhhTj755PTq1SvnnHNONt5441qeAfBD/NBn/eOPP07fvn3Tr1+/3HjjjWnQoEGuuOKKmhWswOJp+PDhOfjgg1NWVpZf/epX2WijjbL11lunTp2vdzetrq7OW2+9lQ033DCDBw/OscceW7P9yzcOO+ywXHnllWnSpEmWX3753HjjjVlnnXVqa0rAAvwvz/vs2bNTt27dVFdXp7KysqbvNyZNmlTzw3eAhUWwDvMxZcqUHH300fn8889z11131fwE/IUXXsj06dPTp0+ffPTRR+nTp0/atWuXf/7zn2nUqFGSr38V/aijjsrAgQNzxBFHJEkuvvjifPHFF5kwYUIOPfTQdO/evdbmBsuie++9N0899VSaNWuWjTbaKK1bt87KK6+cJ554Iv369cu5556b/v3759hjj81ll12WSy65JAcddFBtlw0UaEHP+pNPPpk99tgjl156aYqLi7PTTjuldevWOfHEEzNw4MDaLhv4Ho8//ngGDhyY/v37f+d5KVVVVTnnnHNy9tlnZ/To0TXnpVRXV6eoqCiHHHJI7rnnnlx66aXZZZddams6wHf4sc87wE9JsA4LcPrpp+fBBx/MwIED069fv4wbNy6bbbZZevbsmT/+8Y9p1apVzZYRl112WTbffPOae/fee+98+umn+d3vfpcNN9ywFmcBfJfHHnssu+yyS/76179myy23zMsvv2zlGiyFHnvssey8887529/+lg4dOmT48OE1vz4OLP6OP/74vPrqq7ntttu+d8Xp2LFj88tf/jLrr79+rr/++rzyyiuZPn16Nthgg7z//vtZeeWVf5qigf/Jj3neX3311UydOjUbbLBBzbkqAIuSPdbhv3xz0NH++++ftm3b5uabb8748ePTtm3b7L///nnvvfdq9mEdMmRISktLc8cdd2TcuHE1Y5xwwgl5+eWX89BDD2XOnDm1Mg/gu02fPj333XdfevbsmbXXXjtJhOqwFPr2s77eeutlzTXXFKrDEqbQ81JOPfXUmvNS1l133Tz11FOprq4WqsMS4Mc8785HAn5qdb6/CywbvvmVsuLi4lRXV6d9+/bZfvvtc8UVV+T666/P4MGDM2DAgDz00EMZNmxYevfunTXWWCPHHXdcTjrppPTt2zd77LFHkqRLly659tprs+mmm86ztxtQez788MM888wzmTp1as4///yUlpbmz3/+c9q0aVPbpQEL0YKe9W/OQwGWLEcffXS22GKLfPrpp/M9Q+Haa6/NO++8k6KiokybNi3vvPNOKisrM27cuDz66KPOS4EliOcdWJLYCoZlXnV1daqqqmoONqqoqEh5eXmSr/daP+aYY/Lee+/loosuylprrZXbbrst55xzTvbYY48cd9xxSZLNN988c+bMySWXXJKuXbvW2lyA73bvvffm97//fUpKStKvXz97K8NSyrMOSx/npcCyw/MOLCkE6/AfH3/8cX77299mwoQJad26dQ444IBsttlmeeyxx3LSSSelZ8+eufjii5P83x7qJ510UjbYYIM8+uijGTRoUG655ZasssoqtTwT4LuMGjUqq6yyit8mgaWcZx2WDc5LgWWH5x1Y3NhjHZIMGzYs66+/fkpLS7PPPvukdevW2WOPPXLPPfekT58+2WijjfLiiy/m/vvvT5Icfvjh+eKLLzJ06NBMnz49m2yySV5++WWhOiwB1lhjDUEbLAM867D0c14KLDs878DiyL82WKZUVVWlqKhonhPChw0bll133TWXXHJJkqRly5a55JJLMmLEiGy33Xbp169fXn311dx8883p27dvevXqlV/84hdp2rRpSkpKUl1d7dRxAABYxJyXAssOzzuwuLMVDMuMysrKmn3U33vvvcyaNStdunRJdXV1Vl111fztb39L8+bNs8suu+TLL7/MiSeemIMPPrgmML/00ktz9dVX58ADD8yRRx6Z2bNnp27durU5JQAAWKY4QwGWHZ53YHFnxTrLjJKSkkyYMCGHHnpoXn755Rx++OFZbrnl0qJFi6y11lrZeeedM2XKlBx44IEZPHhwWrRokVmzZuWZZ55Jnz59stNOO2XkyJHp0qVLkgjVAQDgJ7btttumc+fOzlCAZYDnHVjc+ZOJZcazzz6bvfbaK927d89tt92Wtm3bpnXr1qmqqkrPnj3z0ksv5eKLL86+++6bb36R44knnshFF12UFVdcMSuttFKuueYaW74AAEAtWmONNWq7BOAn4nkHFmeCdZY6/72P+jf7n48YMSJt2rTJnXfemSSZM2dOkqS4uDjbb799HnvssVx44YXp0KFDWrRokX/+85+55JJLsvPOO6dly5ZJIlQHAAAAAATrLF2+vY/6tGnT0qhRo5ow/N13301xcXFuuummvP/++5k4cWKeeuqpdOvWLZdffnmuvPLKHHzwwTnwwAPTsGHDzJ49O5deeml22GGHWpwRAAAAALC4cXgpS52pU6fmhBNOyDvvvJOuXbtmq622yq9+9as8++yzueaaa3Lbbbdlyy23zEorrZQ6derkrrvuyoYbbpirr746s2bNyldffZX33nsv66yzTm1PBQAAAABYDAnWWarccccdGThwYNZaa61stNFGeeutt/L3v/89b7/9dtq1a5fp06dn9uzZKSsrq1nZvsMOO2TVVVfNH/7wh1RVVdVcBwAAAACYn+LaLgAK8fnnnyf5esuXysrKudo+/fTTPPPMMznxxBPzwAMPZMiQIdlzzz0zbdq0DB48OLNmzUrDhg3TpEmTTJ8+PV999VWuvvrqvPHGG9lkk01SVFQkVAcAAAAAvpcV6ywxzjzzzLz88su54IILstJKKyVJ/v3vf+ff//53evbsmTp16uSRRx7Jz372s0ycODEDBgzI888/n+233z5//vOfc8cdd2SHHXbI888/n6FDh+aZZ57J2LFjc/HFF2fXXXet5dkBAAAAAEsKK9ZZYmy55ZYZM2ZMHnjggSTJUUcdlVVWWSW77rprfvnLX+a2225L3759kyQHHXRQGjRokOeeey7XXHNN1l9//Vx00UWZMmVK1l577XTq1CmHHHJIxo4dK1QHAAAAAApSp7YLgB9qnXXWyc9+9rM8+uijmTJlSj744IM88sgjmTJlSm655ZYcfPDB6dSpUyorK/Pqq6/m/vvvT6dOnTJ27NhMnTo1zz//fC6++OL87ne/yxFHHJHiYj9XAgAAAAAKZysYliifffZZttpqq3z55Zc5/PDDc8wxxyT5en/1Qw45JBMnTswNN9yQzp0754knnsh6662XG2+8MR988EG6du2arl27Zu21167lWQAAAAAASzIr1lmitGrVKgcddFAOO+ywNGjQoOZ6y5Yt85vf/Ca77bZb3n777ey5557ZZpttag4qve6667LddtvVYuUAAAAAwNLCXhgscfbbb7+su+66efrpp/PZZ58lSYqLi9OmTZs0b948RUVFueaaa3LTTTfl1FNPzeeffy5UBwAAAAAWGsE6S5x69erljDPOyJtvvpmbbrqp5vqMGTMyderUtGjRIqWlpdlqq62y33771WKlAAAAAMDSyB7rLJGqq6uzyy67ZPjw4dljjz3SpUuXnH/++enRo0f++te/plmzZrVdIgAAAACwlBKss8T68MMP07t376y22mrp2bNnOnfunMMPP7y2ywIAAAAAlnKCdZZoRx55ZHr37p3ddtstxcV2NgIAAAAAFj3BOku0qqoqgToAAAAA8JMSrAMAAAAAQAEs9QUAAAAAgAII1gEAAAAAoACCdQAAAAAAKIBgHQAAAAAACiBYBwAAAACAAgjWAQAAAACgAIJ1AACWCX369MlRRx210Mc99dRT06NHj4U+LgAAsPgSrAMAUOv23XffFBUV5dBDD52n7fDDD09RUVH23XffHzTWY489lqKiokyaNGnhFgkAAPAfgnUAABYLHTp0yC233JKvvvqq5tqMGTNy0003ZYUVVqjFygAAAOYmWAcAYLHQs2fPdOjQIXfeeWfNtTvvvDMrrLBC1l577ZprVVVVOfvss7PSSiulQYMGWWuttXL77bcnST766KNssskmSZJmzZrNs9K9qqoqxx13XJo3b542bdrk1FNPnauGMWPGZPvtt09ZWVnKy8uz22675dNPP52rzznnnJPWrVuncePGOeCAAzJjxoyF/JUAAAAWd4J1AAAWG/vvv3+uv/76mtd//vOfs99++83V5+yzz86NN96YK6+8Mm+++WaOPvro7Lnnnnn88cfToUOH3HHHHUmSd955J+PGjcvFF19cc+9f/vKXNGrUKM8//3zOPffcnH766Rk+fHiSr0P37bffPhMnTszjjz+e4cOH54MPPsjuu+9ec/9tt92WU089NWeddVZeeumltG3bNldcccWi/JIAAACLoaLq6urq2i4CAIBl27777ptJkyblmmuuSYcOHfLOO+8kSVZfffV8/PHHOfDAA9O0adNcddVVad68eR566KH07t275v4DDzww06dPz0033ZTHHnssm2yySb788ss0bdq0pk+fPn1SWVmZJ598suba+uuvn759++acc87J8OHDs+WWW+bDDz9Mhw4dkiRvvfVWunbtmhdeeCHrrbdefv7zn2fttdfO5ZdfXjPGz372s8yYMSMjRoxYtF8kAABgsVGntgsAAIBvtGzZMltvvXVuuOGGVFdXZ+utt06LFi1q2t97771Mnz49v/zlL+e6b9asWXNtF7Mg3bt3n+t127Zt89lnnyVJRo0alQ4dOtSE6knSpUuXNG3aNKNGjcp6662XUaNGzXPAau/evfPoo48WPFcAAGDJJVgHAGCxsv/++2fgwIFJMtfK8CSZOnVqkuS+++5Lu3bt5morLS393rHr1q071+uioqJUVVX9mHIBAIBlkD3WAQBYrGyxxRaZNWtWZs+enc0333yuti5duqS0tDRjxoxJ586d5/r4ZqV5vXr1kiSVlZUFve8aa6yRjz/+OB9//HHNtbfeeiuTJk1Kly5davo8//zzc9333HPPFTxHAABgyWbFOgAAi5WSkpKMGjWq5vNva9y4cQYNGpSjjz46VVVV2WCDDTJ58uQ8/fTTKS8vzz777JMVV1wxRUVF+cc//pGtttoqDRo0SFlZ2fe+72abbZZu3bqlf//+ueiiizJnzpwcdthh2XjjjbPuuusmSY488sjsu+++WXfddfOLX/wiQ4cOzZtvvplOnTot/C8EAACw2LJiHQCAxU55eXnKy8vn23bGGWfkpJNOytlnn5011lgjW2yxRe67776stNJKSZJ27drltNNOywknnJDWrVvXbCvzfYqKivL3v/89zZo1y0YbbZTNNtssnTp1yq233lrTZ/fdd89JJ52U4447Luuss05Gjx6dAQMG/PgJAwAAS5Si6urq6touAgAAAAAAlhRWrAMAAAAAQAEE6wAAAAAAUADBOgAAAAAAFECwDgAAAAAABRCsAwAAAABAAQTrAAAAAABQAME6AAAAAAAUQLAOAAAAAAAFEKwDAAAAAEABBOsAAAAAAFAAwToAAAAAABRAsA4AAAAAAAX4/4LELue22qt/AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1500x900 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# train_all_fold_profit_df = train_all_fold_profit_df.drop(columns=[\"S12\", \"S15\", \"S16\"])\n",
    "# test_all_fold_profit_df = test_all_fold_profit_df.drop(columns=[\"S12\", \"S15\", \"S16\"])\n",
    "\n",
    "train_all_fold_profit_df = train_all_fold_profit_df.drop(columns=[\"S15\", \"S16\"])\n",
    "test_all_fold_profit_df = test_all_fold_profit_df.drop(columns=[\"S15\", \"S16\"])\n",
    "\n",
    "# 1️⃣ 計算平均 profit\n",
    "train_means = train_all_fold_profit_df.mean()\n",
    "test_means = test_all_fold_profit_df.mean()\n",
    "\n",
    "# 2️⃣ 定義 baseline & theory best\n",
    "baseline_train = train_means[\"baseline\"]\n",
    "baseline_test = test_means[\"baseline\"]\n",
    "theory_best_train = train_means[\"S14\"]\n",
    "theory_best_test = test_means[\"S14\"]\n",
    "\n",
    "# 3️⃣ 計算百分比變化：baseline & theory\n",
    "train_pct_base = (train_means - baseline_train) / baseline_train * 100\n",
    "test_pct_base = (test_means - baseline_test) / baseline_test * 100\n",
    "train_pct_theory = (train_means - theory_best_train) / theory_best_train * 100\n",
    "test_pct_theory = (test_means - theory_best_test) / theory_best_test * 100\n",
    "\n",
    "# 4️⃣ 建 DataFrame\n",
    "avg_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Method\": train_means.index,\n",
    "        \"Train\": train_means.values,\n",
    "        \"Test\": test_means.values,\n",
    "        \"Train_%_Base\": train_pct_base.values,\n",
    "        \"Test_%_Base\": test_pct_base.values,\n",
    "        \"Train_%_Theory\": train_pct_theory.values,\n",
    "        \"Test_%_Theory\": test_pct_theory.values,\n",
    "    }\n",
    ")\n",
    "\n",
    "avg_df_melted = avg_df.melt(\n",
    "    id_vars=[\n",
    "        \"Method\",\n",
    "        \"Train_%_Base\",\n",
    "        \"Test_%_Base\",\n",
    "        \"Train_%_Theory\",\n",
    "        \"Test_%_Theory\",\n",
    "    ],\n",
    "    value_vars=[\"Train\", \"Test\"],\n",
    "    var_name=\"Dataset\",\n",
    "    value_name=\"Average Profit\",\n",
    ")\n",
    "\n",
    "# 5️⃣ 畫圖\n",
    "plt.figure(figsize=(15, 9))\n",
    "ax = sns.barplot(x=\"Method\", y=\"Average Profit\", hue=\"Dataset\", data=avg_df_melted)\n",
    "\n",
    "# 6️⃣ 標註：baseline (%) 在第一行、theory (%) 括號內第二行\n",
    "for patch, (method, ds) in zip(\n",
    "    ax.patches, zip(avg_df_melted[\"Method\"], avg_df_melted[\"Dataset\"])\n",
    "):\n",
    "    if ds == \"Train\":\n",
    "        pct_base = avg_df.loc[avg_df.Method == method, \"Train_%_Base\"].values[0]\n",
    "        pct_theory = avg_df.loc[avg_df.Method == method, \"Train_%_Theory\"].values[0]\n",
    "    else:\n",
    "        pct_base = avg_df.loc[avg_df.Method == method, \"Test_%_Base\"].values[0]\n",
    "        pct_theory = avg_df.loc[avg_df.Method == method, \"Test_%_Theory\"].values[0]\n",
    "\n",
    "    ax.annotate(\n",
    "        f\"{pct_base:.1f}%\\n({pct_theory:.1f}%)\",\n",
    "        (patch.get_x() + patch.get_width() / 2, patch.get_height()),\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=9,\n",
    "        xytext=(0, 5),\n",
    "        textcoords=\"offset points\",\n",
    "    )\n",
    "\n",
    "plt.title(\"Average Profit (Train vs Test) — % Change vs Baseline / Theory Best\")\n",
    "plt.ylabel(\"Average Profit\")\n",
    "plt.xlabel(\"Method\")\n",
    "plt.xticks(rotation=30)\n",
    "plt.legend(title=\"Dataset\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 計算 baseline（訓練與測試）\n",
    "baseline_train = train_all_fold_profit_df[\"baseline\"].to_numpy().reshape(-1, 1)\n",
    "baseline_test = test_all_fold_profit_df[\"baseline\"].to_numpy().reshape(-1, 1)\n",
    "\n",
    "# # 計算百分比變化\n",
    "# train_relative = (\n",
    "#     (train_all_fold_profit_df.to_numpy() - baseline_train) / baseline_train * 100\n",
    "# )\n",
    "# test_relative = (\n",
    "#     (test_all_fold_profit_df.to_numpy() - baseline_test) / baseline_test * 100\n",
    "# )\n",
    "\n",
    "train_relative = (\n",
    "    (train_all_fold_profit_df.to_numpy() - baseline_train)\n",
    "    / np.abs(baseline_train)\n",
    "    * 100\n",
    ")\n",
    "test_relative = (\n",
    "    (test_all_fold_profit_df.to_numpy() - baseline_test) / np.abs(baseline_test) * 100\n",
    ")\n",
    "\n",
    "# 轉回 DataFrame，並保留 column names\n",
    "train_relative = pd.DataFrame(\n",
    "    train_relative,\n",
    "    columns=train_all_fold_profit_df.columns,\n",
    "    index=train_all_fold_profit_df.index,\n",
    ")\n",
    "test_relative = pd.DataFrame(\n",
    "    test_relative,\n",
    "    columns=test_all_fold_profit_df.columns,\n",
    "    index=test_all_fold_profit_df.index,\n",
    ")\n",
    "\n",
    "# 加入 fold 編號\n",
    "train_relative[\"Fold\"] = train_relative.index + 1\n",
    "test_relative[\"Fold\"] = test_relative.index + 1\n",
    "\n",
    "# 轉換成長格式\n",
    "train_long = train_relative.melt(\n",
    "    id_vars=\"Fold\", var_name=\"Method\", value_name=\"Relative Profit (%)\"\n",
    ")\n",
    "train_long[\"Dataset\"] = \"Train\"\n",
    "\n",
    "test_long = test_relative.melt(\n",
    "    id_vars=\"Fold\", var_name=\"Method\", value_name=\"Relative Profit (%)\"\n",
    ")\n",
    "test_long[\"Dataset\"] = \"Test\"\n",
    "\n",
    "# 合併數據\n",
    "fold_long = pd.concat([train_long, test_long], axis=0)\n",
    "\n",
    "# # === 1. 使用線圖 (Line Plot) 觀察不同 Fold 上的變化趨勢 ===\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.lineplot(\n",
    "#     data=fold_long,\n",
    "#     x=\"Fold\",\n",
    "#     y=\"Relative Profit (%)\",\n",
    "#     hue=\"Method\",\n",
    "#     style=\"Dataset\",\n",
    "#     markers=True,\n",
    "#     dashes=False,\n",
    "# )\n",
    "# plt.axhline(0, color=\"gray\", linestyle=\"--\", linewidth=1)  # 基準線\n",
    "# plt.title(\"Strategy Performance Across Folds (Relative to Baseline)\")\n",
    "# plt.legend(title=\"Method & Dataset\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "# plt.show()\n",
    "\n",
    "# # === 2. 使用箱型圖 (Box Plot) 查看策略穩定性 ===\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.boxplot(data=fold_long, x=\"Method\", y=\"Relative Profit (%)\", hue=\"Dataset\")\n",
    "# plt.axhline(0, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "# plt.title(\"Strategy Performance Distribution Across Folds\")\n",
    "# plt.xticks(rotation=30)\n",
    "# plt.legend(title=\"Dataset\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "# plt.show()\n",
    "\n",
    "# 3️⃣ Heatmap：同時顯示 vs Baseline & vs Theory Best（每 Fold 的 S14）\n",
    "theory_best_train = train_all_fold_profit_df[\"S14\"].to_numpy().reshape(-1, 1)\n",
    "theory_best_test = test_all_fold_profit_df[\"S14\"].to_numpy().reshape(-1, 1)\n",
    "\n",
    "# vs Theory (%) 計算\n",
    "# train_theory_rel = (\n",
    "#     (train_all_fold_profit_df.to_numpy() - theory_best_train) / theory_best_train * 100\n",
    "# )\n",
    "# test_theory_rel = (\n",
    "#     (test_all_fold_profit_df.to_numpy() - theory_best_test) / theory_best_test * 100\n",
    "# )\n",
    "train_theory_rel = (\n",
    "    (train_all_fold_profit_df.to_numpy() - theory_best_train)\n",
    "    / np.abs(theory_best_train)\n",
    "    * 100\n",
    ")\n",
    "test_theory_rel = (\n",
    "    (test_all_fold_profit_df.to_numpy() - theory_best_test)\n",
    "    / np.abs(theory_best_test)\n",
    "    * 100\n",
    ")\n",
    "\n",
    "# 回 DataFrame 並 melt\n",
    "train_theory_rel = pd.DataFrame(\n",
    "    train_theory_rel,\n",
    "    columns=train_all_fold_profit_df.columns,\n",
    "    index=train_all_fold_profit_df.index,\n",
    ")\n",
    "train_theory_rel[\"Fold\"] = train_theory_rel.index + 1\n",
    "train_theory_long = train_theory_rel.melt(\n",
    "    id_vars=\"Fold\", var_name=\"Method\", value_name=\"Relative vs Theory (%)\"\n",
    ")\n",
    "train_theory_long[\"Dataset\"] = \"Train\"\n",
    "\n",
    "test_theory_rel = pd.DataFrame(\n",
    "    test_theory_rel,\n",
    "    columns=test_all_fold_profit_df.columns,\n",
    "    index=test_all_fold_profit_df.index,\n",
    ")\n",
    "test_theory_rel[\"Fold\"] = test_theory_rel.index + 1\n",
    "test_theory_long = test_theory_rel.melt(\n",
    "    id_vars=\"Fold\", var_name=\"Method\", value_name=\"Relative vs Theory (%)\"\n",
    ")\n",
    "test_theory_long[\"Dataset\"] = \"Test\"\n",
    "\n",
    "# 合併 baseline (%) 與 theory (%) 資料\n",
    "merged = fold_long.merge(\n",
    "    pd.concat([train_theory_long, test_theory_long], axis=0),\n",
    "    on=[\"Fold\", \"Method\", \"Dataset\"],\n",
    ")\n",
    "\n",
    "# Pivot heatmap values + annotations\n",
    "heatmap_data = merged.pivot(\n",
    "    index=\"Fold\", columns=[\"Method\", \"Dataset\"], values=\"Relative Profit (%)\"\n",
    ")\n",
    "annot = merged.assign(\n",
    "    annot=merged[\"Relative Profit (%)\"].round(1).astype(str)\n",
    "    + \"\\n(\"\n",
    "    + merged[\"Relative vs Theory (%)\"].round(1).astype(str)\n",
    "    + \"%)\"\n",
    ").pivot(index=\"Fold\", columns=[\"Method\", \"Dataset\"], values=\"annot\")\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.heatmap(heatmap_data, annot=annot, fmt=\"\", cmap=\"coolwarm\", linewidths=0.5)\n",
    "plt.title(\"Relative Profit (%) Across Folds\\n(vs Baseline / (vs Theory Best))\")\n",
    "plt.ylabel(\"Fold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved as plots/plot_strategies_profits_scatter_train_med_with_holding_cost_0.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 訓練階段分佈\n",
    "\n",
    "baseline_data = []\n",
    "S1_data = []\n",
    "S2_data = []\n",
    "S12_data = []\n",
    "S14_data = []\n",
    "S15_data = []\n",
    "\n",
    "for result in train_all_fold_stimulation_results:\n",
    "    baseline_data.append(result[\"baseline\"])\n",
    "    S1_data.append(result[\"S1\"])\n",
    "    S2_data.append(result[\"S2\"])\n",
    "    # S12_data.append(result[\"S12\"])\n",
    "    # S14_data.append(result[\"S14\"])\n",
    "    # S15_data.append(result[\"S15\"])\n",
    "\n",
    "# 合併數據\n",
    "baseline_df = pd.concat(baseline_data, ignore_index=True)\n",
    "S1_df = pd.concat(S1_data, ignore_index=True)\n",
    "S2_df = pd.concat(S2_data, ignore_index=True)\n",
    "# S12_df = pd.concat(S12_data, ignore_index=True)\n",
    "# S14_df = pd.concat(S14_data, ignore_index=True)\n",
    "# S15_df = pd.concat(S15_data, ignore_index=True)\n",
    "\n",
    "\n",
    "dfs = {\n",
    "    \"baseline\": baseline_df,\n",
    "    \"S1\": S1_df,\n",
    "    \"S2\": S2_df,\n",
    "    # \"S12\": S12_df,\n",
    "    # \"S15\": S15_df,\n",
    "    # \"S14\": S14_df,\n",
    "}\n",
    "\n",
    "# 調用繪圖函數\n",
    "plot_strategies_profits_scatter(f\"{status}_{model_prefix}\", dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved as plots/plot_strategies_profits_scatter_train_med_with_holding_cost_0.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 測試結果分布圖\n",
    "\n",
    "baseline_data = []\n",
    "S1_data = []\n",
    "S2_data = []\n",
    "S12_data = []\n",
    "S14_data = []\n",
    "S15_data = []\n",
    "\n",
    "for result in test_all_fold_stimulation_results:\n",
    "    baseline_data.append(result[\"baseline\"])\n",
    "    S1_data.append(result[\"S1\"])\n",
    "    S2_data.append(result[\"S2\"])\n",
    "    # S12_data.append(result[\"S12\"])\n",
    "    # S14_data.append(result[\"S14\"])\n",
    "    # S15_data.append(result[\"S15\"])\n",
    "# 合併數據\n",
    "baseline_df = pd.concat(baseline_data, ignore_index=True)\n",
    "S1_df = pd.concat(S1_data, ignore_index=True)\n",
    "S2_df = pd.concat(S2_data, ignore_index=True)\n",
    "# S12_df = pd.concat(S12_data, ignore_index=True)\n",
    "# S14_df = pd.concat(S14_data, ignore_index=True)\n",
    "# S15_df = pd.concat(S15_data, ignore_index=True)\n",
    "\n",
    "dfs = {\n",
    "    \"baseline\": baseline_df,\n",
    "    \"S1\": S1_df,\n",
    "    \"S2\": S2_df,\n",
    "    # \"S12\": S12_df,\n",
    "    # \"S15\": S15_df,\n",
    "    # \"S14\": S14_df,\n",
    "}\n",
    "\n",
    "# 調用繪圖函數\n",
    "plot_strategies_profits_scatter(f\"{status}_{model_prefix}\", dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ast\n",
    "\n",
    "# summary_df = pd.read_csv(\n",
    "#     \"/Users/hanyuan/Github/Two-Phase-Newsvendor/results/summary.csv\"\n",
    "# )\n",
    "\n",
    "# records_str = summary_df.loc[0, \"train_df\"]\n",
    "# records = ast.literal_eval(records_str)\n",
    "\n",
    "# df_reconstructed = pd.DataFrame(records)\n",
    "# df_reconstructed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Processing Fold 1 =====\n",
      "training_df: \n",
      "           X1   X2          X3\n",
      "0   17.744068  0.0  254.356465\n",
      "1   18.575947  0.0  251.010920\n",
      "2   18.013817  0.0  291.630992\n",
      "3   17.724416  0.0  288.907838\n",
      "4   17.118274  0.0  293.500607\n",
      "5   18.229471  0.0  298.930917\n",
      "6   17.187936  0.0  289.957928\n",
      "7   19.458865  0.0  273.073968\n",
      "8   19.818314  0.0  289.026459\n",
      "9   16.917208  0.0  255.913721\n",
      "10  18.958625  0.0  281.996051\n",
      "11  17.644475  0.0  257.167664\n",
      "12  17.840223  0.0  297.233446\n",
      "13  19.627983  0.0  276.092416\n",
      "14  15.355180  0.0  270.733097\n",
      "demand_df_train: \n",
      "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
      "0   251.794016  254.356464  247.741536  254.356465  261.523870  254.356465   \n",
      "1   251.056784  251.010919  248.192143  251.010920  250.249903  251.010920   \n",
      "2   297.528249  291.630992  294.250464  291.630992  283.569719  291.630992   \n",
      "3   289.066894  288.907838  288.355508  288.907838  285.816090  288.907838   \n",
      "4   298.072424  293.500607  299.903104  293.500607  296.615372  293.500607   \n",
      "5   301.401948  298.930917  300.714683  298.930917  294.785980  298.930917   \n",
      "6   291.672619  289.957928  291.788015  289.957928  285.872455  289.957928   \n",
      "7   269.341662  273.073968  269.572013  273.073968  271.669642  273.073968   \n",
      "8   291.803572  289.026459  288.668454  289.026459  282.672846  289.026459   \n",
      "9   258.259455  255.913721  255.439341  255.913721  255.976937  255.913721   \n",
      "10  278.551022  281.996051  281.029925  281.996051  289.535263  281.996051   \n",
      "11  256.151738  257.167663  252.945792  257.167664  264.788247  257.167664   \n",
      "12  295.186828  297.233446  298.436136  297.233446  301.105487  297.233446   \n",
      "13  278.898077  276.092416  278.517826  276.092416  274.536813  276.092416   \n",
      "14  276.126061  270.733097  271.699824  270.733097  268.070512  270.733097   \n",
      "\n",
      "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
      "0   254.087872  252.716034  254.356465  254.356465  \n",
      "1   252.054546  246.842220  251.010920  251.010920  \n",
      "2   285.767294  287.835884  291.630992  291.630992  \n",
      "3   292.681865  290.851589  288.907838  288.907838  \n",
      "4   290.943971  295.944768  293.500607  293.500607  \n",
      "5   299.484772  298.727945  298.930917  298.930917  \n",
      "6   290.444897  292.664979  289.957928  289.957928  \n",
      "7   273.459253  273.376911  273.073968  273.073968  \n",
      "8   287.717318  286.983188  289.026459  289.026459  \n",
      "9   255.911150  251.612160  255.913721  255.913721  \n",
      "10  285.332026  287.403702  281.996051  281.996051  \n",
      "11  262.220107  256.201799  257.167664  257.167664  \n",
      "12  295.272601  298.475322  297.233446  297.233446  \n",
      "13  276.925605  274.583612  276.092416  276.092416  \n",
      "14  266.551512  268.201901  270.733097  270.733097  \n",
      "testing_df: \n",
      "           X1   X2         X3\n",
      "0   16.322778  1.0  66.706379\n",
      "1   18.871168  1.0  62.103826\n",
      "2   17.280752  1.0  61.289263\n",
      "3   17.842170  1.0  63.154284\n",
      "4   15.093949  1.0  63.637108\n",
      "5   18.088177  1.0  65.701968\n",
      "6   18.060479  1.0  64.386015\n",
      "7   18.084670  1.0  69.883738\n",
      "8   19.718740  1.0  61.020448\n",
      "9   18.409101  1.0  62.088768\n",
      "10  16.797540  1.0  61.613095\n",
      "11  17.185160  1.0  66.531083\n",
      "12  18.488156  1.0  62.532916\n",
      "13  15.301127  1.0  64.663108\n",
      "14  18.333834  1.0  62.444256\n",
      "demand_df_test: \n",
      "    demand_t1  demand_t2  demand_t3  demand_t4  demand_t5  demand_t6  \\\n",
      "0   69.049446  66.984864  65.276090  66.706379  64.399509  66.706379   \n",
      "1   62.472855  61.379065  62.263812  62.103826  59.547465  62.103826   \n",
      "2   57.026718  60.339037  58.994137  61.289263  61.559450  61.289263   \n",
      "3   62.944633  65.536993  64.153686  63.154284  59.520451  63.154284   \n",
      "4   66.458142  64.430325  65.691033  63.637108  58.415305  63.637108   \n",
      "5   65.340264  66.665934  65.624076  65.701968  65.763430  65.701968   \n",
      "6   60.459442  64.184997  61.973620  64.386015  65.111260  64.386015   \n",
      "7   71.557122  70.563024  74.662817  69.883738  69.277905  69.883738   \n",
      "8   63.840751  62.306341  66.968545  61.020448  59.275984  61.020448   \n",
      "9   62.969099  64.263725  64.029270  62.088768  60.721711  62.088768   \n",
      "10  60.057707  60.871552  60.104051  61.613095  62.302393  61.613095   \n",
      "11  68.193840  67.527301  72.362407  66.531083  64.621767  66.531083   \n",
      "12  55.740736  63.143807  63.924512  62.532916  65.056794  62.532916   \n",
      "13  67.989985  63.983761  64.570792  64.663108  66.958315  64.663108   \n",
      "14  58.797450  62.278203  63.120200  62.444256  58.121198  62.444256   \n",
      "\n",
      "    demand_t7  demand_t8  demand_t9  demand_t10  \n",
      "0   71.005184  64.088969  66.706381   66.706379  \n",
      "1   63.271804  55.331312  62.103825   62.103826  \n",
      "2   63.232738  60.581985  61.289264   61.289263  \n",
      "3   62.573906  68.894022  63.154284   63.154283  \n",
      "4   62.211406  62.929656  63.637111   63.637108  \n",
      "5   62.072328  64.226544  65.701970   65.701968  \n",
      "6   66.214844  63.597722  64.386018   64.386015  \n",
      "7   68.924536  69.361419  69.883738   69.883738  \n",
      "8   59.005480  60.829499  61.020442   61.020448  \n",
      "9   60.879685  62.634618  62.088772   62.088768  \n",
      "10  61.283812  63.885645  61.613092   61.613095  \n",
      "11  65.714526  66.642278  66.531082   66.531083  \n",
      "12  56.151613  66.725960  62.532920   62.532916  \n",
      "13  65.885875  61.730881  64.663100   64.663108  \n",
      "14  57.806186  61.151295  62.444260   62.444256  \n",
      "===== Processing Fold 2 =====\n",
      "training_df: \n",
      "           X1   X2          X3\n",
      "0   15.794848  0.0  251.959390\n",
      "1   15.551876  0.0  264.140348\n",
      "2   18.281648  0.0  256.009828\n",
      "3   15.690915  0.0  264.807010\n",
      "4   15.982912  0.0  255.936386\n",
      "5   16.843626  0.0  265.899159\n",
      "6   19.104966  0.0  270.713150\n",
      "7   15.485506  0.0  253.207375\n",
      "8   19.189725  0.0  284.623606\n",
      "9   15.480492  0.0  278.330073\n",
      "10  19.882297  0.0  263.269475\n",
      "11  17.343256  0.0  276.162403\n",
      "12  19.883805  0.0  254.697026\n",
      "13  18.024228  0.0  278.797325\n",
      "14  18.696318  0.0  296.464810\n",
      "demand_df_train: \n",
      "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
      "0   256.519623  251.959390  252.619473  251.959390  246.815799  251.959390   \n",
      "1   266.557046  264.140348  264.160430  264.140348  262.456134  264.140348   \n",
      "2   255.104623  256.009829  259.397400  256.009828  253.201453  256.009828   \n",
      "3   258.328805  264.807010  266.027383  264.807010  264.784493  264.807010   \n",
      "4   253.416118  255.936386  254.214539  255.936386  256.695107  255.936386   \n",
      "5   263.215996  265.899159  268.949097  265.899159  263.130433  265.899159   \n",
      "6   267.820993  270.713150  268.501904  270.713150  272.402984  270.713150   \n",
      "7   250.255196  253.207375  252.917631  253.207375  253.511599  253.207375   \n",
      "8   291.872275  284.623606  289.498687  284.623606  279.906507  284.623606   \n",
      "9   276.428735  278.330073  277.122965  278.330073  276.905217  278.330073   \n",
      "10  261.244738  263.269475  267.407733  263.269475  263.036084  263.269475   \n",
      "11  281.624515  276.162403  277.291903  276.162403  272.064668  276.162403   \n",
      "12  256.640801  254.697025  253.216210  254.697026  257.734949  254.697026   \n",
      "13  276.596581  278.797325  282.033169  278.797325  278.763871  278.797325   \n",
      "14  297.215013  296.464810  297.943972  296.464810  296.618148  296.464810   \n",
      "\n",
      "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
      "0   252.404141  247.642667  251.959390  251.959390  \n",
      "1   268.037060  263.302797  264.140348  264.140348  \n",
      "2   254.294350  257.262525  256.009828  256.009828  \n",
      "3   265.545294  267.617149  264.807010  264.807010  \n",
      "4   259.314176  259.850532  255.936386  255.936386  \n",
      "5   261.011138  267.280099  265.899159  265.899159  \n",
      "6   270.361907  270.006558  270.713150  270.713150  \n",
      "7   251.010061  255.083055  253.207375  253.207375  \n",
      "8   286.218363  285.561041  284.623606  284.623606  \n",
      "9   280.820443  281.184906  278.330073  278.330073  \n",
      "10  260.086461  263.477115  263.269475  263.269475  \n",
      "11  274.337136  273.932259  276.162403  276.162403  \n",
      "12  260.510507  256.621323  254.697026  254.697026  \n",
      "13  274.790903  280.071033  278.797325  278.797325  \n",
      "14  293.376616  299.036274  296.464810  296.464810  \n",
      "testing_df: \n",
      "           X1   X2         X3\n",
      "0   16.592845  1.0  65.761573\n",
      "1   18.337052  1.0  65.920419\n",
      "2   15.658989  1.0  65.722519\n",
      "3   18.581636  1.0  62.230816\n",
      "4   16.447030  1.0  69.527490\n",
      "5   15.915957  1.0  64.471254\n",
      "6   17.932565  1.0  68.464087\n",
      "7   15.100538  1.0  66.994793\n",
      "8   19.144700  1.0  62.974370\n",
      "9   15.023477  1.0  68.137978\n",
      "10  18.389083  1.0  63.965057\n",
      "11  16.350040  1.0  68.811032\n",
      "12  18.675970  1.0  65.812729\n",
      "13  19.810943  1.0  68.817354\n",
      "14  16.243766  1.0  66.925316\n",
      "demand_df_test: \n",
      "    demand_t1  demand_t2  demand_t3  demand_t4  demand_t5  demand_t6  \\\n",
      "0   68.370121  64.894454  67.199076  65.761573  63.053747  65.761573   \n",
      "1   66.587610  64.979976  69.411094  65.920419  65.768066  65.920419   \n",
      "2   70.933664  66.187890  69.618863  65.722519  60.188051  65.722519   \n",
      "3   63.476652  63.427189  58.172863  62.230816  63.207280  62.230816   \n",
      "4   72.298368  69.469709  69.557802  69.527490  69.049027  69.527490   \n",
      "5   61.418697  64.596306  63.090749  64.471254  64.412447  64.471254   \n",
      "6   68.349991  68.233833  65.527941  68.464087  66.683151  68.464087   \n",
      "7   69.173899  67.791676  68.980601  66.994793  66.269833  66.994793   \n",
      "8   65.242553  65.421038  68.671875  62.974370  57.570268  62.974370   \n",
      "9   67.587048  68.232925  69.938504  68.137978  72.345359  68.137978   \n",
      "10  61.458167  62.971443  63.673554  63.965057  63.243366  63.965057   \n",
      "11  62.593521  68.252412  63.791590  68.811032  69.928345  68.811032   \n",
      "12  64.041609  65.899146  66.197404  65.812729  69.316660  65.812729   \n",
      "13  74.367057  70.734412  75.902168  68.817354  67.054075  68.817354   \n",
      "14  66.151275  66.585163  64.513272  66.925316  65.898617  66.925316   \n",
      "\n",
      "    demand_t7  demand_t8  demand_t9  demand_t10  \n",
      "0   63.984974  62.127812  65.761570   65.761573  \n",
      "1   64.382597  68.059276  65.920415   65.920419  \n",
      "2   61.025759  66.547948  65.722519   65.722519  \n",
      "3   66.306121  62.062609  62.230823   62.230816  \n",
      "4   62.861684  67.820569  69.527490   69.527490  \n",
      "5   63.799314  63.693119  64.471254   64.471254  \n",
      "6   76.051808  69.090667  68.464087   68.464087  \n",
      "7   68.198098  71.791799  66.994793   66.994793  \n",
      "8   58.224097  57.855352  62.974371   62.974369  \n",
      "9   66.220593  70.069887  68.137978   68.137978  \n",
      "10  63.568947  62.804834  63.965054   63.965057  \n",
      "11  73.798658  71.999444  68.811034   68.811032  \n",
      "12  62.910571  70.182959  65.812727   65.812729  \n",
      "13  65.788339  68.993258  68.817352   68.817354  \n",
      "14  69.469320  67.743843  66.925316   66.925316  \n",
      "===== Processing Fold 3 =====\n",
      "training_df: \n",
      "           X1   X2          X3\n",
      "0   18.626271  0.0  279.543638\n",
      "1   17.506622  0.0  278.716262\n",
      "2   19.780418  0.0  282.660041\n",
      "3   18.219951  0.0  282.605164\n",
      "4   17.119275  0.0  271.570922\n",
      "5   18.031966  0.0  294.827330\n",
      "6   15.095966  0.0  268.378094\n",
      "7   16.507874  0.0  271.793246\n",
      "8   18.300868  0.0  294.596168\n",
      "9   16.450388  0.0  290.309699\n",
      "10  18.090077  0.0  285.194429\n",
      "11  17.143844  0.0  255.011344\n",
      "12  15.677370  0.0  295.974131\n",
      "13  16.491412  0.0  285.712065\n",
      "14  17.849825  0.0  299.942350\n",
      "demand_df_train: \n",
      "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
      "0   283.936601  279.543638  285.077369  279.543638  276.931626  279.543638   \n",
      "1   280.752154  278.716263  284.554707  278.716262  277.019908  278.716262   \n",
      "2   280.810270  282.660041  281.793406  282.660041  283.966752  282.660041   \n",
      "3   282.690695  282.605164  284.501807  282.605163  280.263205  282.605164   \n",
      "4   269.794746  271.570922  270.571046  271.570922  268.258034  271.570922   \n",
      "5   292.141287  294.827330  296.363870  294.827330  297.636415  294.827330   \n",
      "6   268.295270  268.378094  272.289189  268.378094  267.061530  268.378094   \n",
      "7   274.284449  271.793246  275.891790  271.793246  271.007436  271.793246   \n",
      "8   295.561676  294.596168  295.346168  294.596168  293.901419  294.596168   \n",
      "9   291.572767  290.309699  289.337801  290.309699  287.979840  290.309699   \n",
      "10  289.359045  285.194429  290.753028  285.194429  285.165963  285.194429   \n",
      "11  259.085891  255.011345  255.041535  255.011344  252.753361  255.011344   \n",
      "12  294.703610  295.974131  298.873793  295.974131  294.749160  295.974131   \n",
      "13  288.208942  285.712065  285.303854  285.712065  283.167061  285.712065   \n",
      "14  297.971527  299.942350  303.764967  299.942350  296.928688  299.942350   \n",
      "\n",
      "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
      "0   279.497137  277.402834  279.543638  279.543638  \n",
      "1   272.022711  278.462176  278.716262  278.716262  \n",
      "2   284.073037  284.669504  282.660041  282.660041  \n",
      "3   280.973891  281.791857  282.605164  282.605164  \n",
      "4   273.396903  267.461509  271.570922  271.570922  \n",
      "5   290.725323  299.869873  294.827330  294.827330  \n",
      "6   264.194145  269.637850  268.378094  268.378094  \n",
      "7   271.264363  278.902212  271.793246  271.793246  \n",
      "8   293.952546  289.434761  294.596168  294.596168  \n",
      "9   296.220290  291.572601  290.309699  290.309699  \n",
      "10  280.959832  286.639870  285.194429  285.194429  \n",
      "11  255.233465  254.206041  255.011344  255.011344  \n",
      "12  295.417869  296.365897  295.974131  295.974131  \n",
      "13  283.449034  289.498190  285.712065  285.712065  \n",
      "14  293.866069  299.198634  299.942350  299.942350  \n",
      "testing_df: \n",
      "           X1   X2         X3\n",
      "0   15.747242  1.0  68.558033\n",
      "1   19.340630  1.0  60.117141\n",
      "2   15.812465  1.0  63.599781\n",
      "3   18.077798  1.0  67.299906\n",
      "4   15.619100  1.0  61.716297\n",
      "5   19.240041  1.0  65.210366\n",
      "6   19.036595  1.0  60.543380\n",
      "7   17.845504  1.0  61.999965\n",
      "8   17.035916  1.0  60.185218\n",
      "9   15.345835  1.0  67.936977\n",
      "10  18.487144  1.0  62.239247\n",
      "11  17.267713  1.0  63.453517\n",
      "12  18.610278  1.0  69.280813\n",
      "13  19.331912  1.0  67.044144\n",
      "14  19.877608  1.0  60.318389\n",
      "demand_df_test: \n",
      "    demand_t1  demand_t2  demand_t3  demand_t4  demand_t5  demand_t6  \\\n",
      "0   65.625929  67.884966  68.750730  68.558033  74.175914  68.558033   \n",
      "1   60.770111  61.058111  59.574148  60.117141  58.717761  60.117141   \n",
      "2   66.073532  64.930685  65.683239  63.599781  63.459309  63.599781   \n",
      "3   63.121389  66.381203  61.668540  67.299906  67.404706  67.299906   \n",
      "4   64.915095  62.604395  65.471782  61.716297  63.127936  61.716297   \n",
      "5   63.427651  63.458016  59.857699  65.210366  66.962546  65.210366   \n",
      "6   60.438469  59.245399  60.450320  60.543380  56.855468  60.543380   \n",
      "7   62.564427  62.207089  62.998637  61.999965  61.345170  61.999965   \n",
      "8   60.300860  59.014437  58.383848  60.185218  60.029247  60.185218   \n",
      "9   66.947411  67.567002  67.449213  67.936977  72.133012  67.936977   \n",
      "10  65.746933  65.853934  70.574162  62.239247  55.130102  62.239247   \n",
      "11  61.329502  63.260741  60.017189  63.453517  66.141381  63.453517   \n",
      "12  66.822772  69.549069  66.237491  69.280813  70.547457  69.280813   \n",
      "13  62.577572  67.210049  65.172995  67.044144  70.357863  67.044144   \n",
      "14  59.277409  59.472203  62.933669  60.318389  57.697020  60.318389   \n",
      "\n",
      "    demand_t7  demand_t8  demand_t9  demand_t10  \n",
      "0   65.559446  71.308420  68.558033   68.558033  \n",
      "1   57.979551  58.390955  60.117144   60.117141  \n",
      "2   64.215938  63.806809  63.599781   63.599781  \n",
      "3   70.525694  68.097560  67.299908   67.299906  \n",
      "4   61.250627  60.709187  61.716291   61.716297  \n",
      "5   68.788190  65.421392  65.210367   65.210366  \n",
      "6   59.175878  58.100125  60.543382   60.543380  \n",
      "7   64.147963  63.211996  61.999964   61.999965  \n",
      "8   62.275329  58.171283  60.185214   60.185218  \n",
      "9   64.609175  66.191955  67.936978   67.936977  \n",
      "10  57.888206  63.679955  62.239243   62.239247  \n",
      "11  65.584679  64.101433  63.453519   63.453517  \n",
      "12  70.842404  73.111604  69.280814   69.280813  \n",
      "13  68.535449  70.440907  67.044145   67.044144  \n",
      "14  59.467526  57.168997  60.318390   60.318390  \n"
     ]
    }
   ],
   "source": [
    "for fold_idx in range(len(training_data_folds)):\n",
    "    print(f\"===== Processing Fold {fold_idx + 1} =====\")\n",
    "    # 取出該 fold 的訓練資料與需求資料\n",
    "    training_df, testing_df = training_data_folds[fold_idx]\n",
    "    demand_df_train, demand_df_test = demand_folds[fold_idx]\n",
    "\n",
    "    print(f\"training_df: \\n{training_df}\")\n",
    "    print(f\"demand_df_train: \\n{demand_df_train}\")\n",
    "    print(f\"testing_df: \\n{testing_df}\")\n",
    "    print(f\"demand_df_test: \\n{demand_df_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>283.936601</td>\n",
       "      <td>279.543638</td>\n",
       "      <td>285.077369</td>\n",
       "      <td>279.543638</td>\n",
       "      <td>276.931626</td>\n",
       "      <td>279.543638</td>\n",
       "      <td>279.497137</td>\n",
       "      <td>277.402834</td>\n",
       "      <td>279.543638</td>\n",
       "      <td>279.543638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>280.752154</td>\n",
       "      <td>278.716263</td>\n",
       "      <td>284.554707</td>\n",
       "      <td>278.716262</td>\n",
       "      <td>277.019908</td>\n",
       "      <td>278.716262</td>\n",
       "      <td>272.022711</td>\n",
       "      <td>278.462176</td>\n",
       "      <td>278.716262</td>\n",
       "      <td>278.716262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>280.810270</td>\n",
       "      <td>282.660041</td>\n",
       "      <td>281.793406</td>\n",
       "      <td>282.660041</td>\n",
       "      <td>283.966752</td>\n",
       "      <td>282.660041</td>\n",
       "      <td>284.073037</td>\n",
       "      <td>284.669504</td>\n",
       "      <td>282.660041</td>\n",
       "      <td>282.660041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>282.690695</td>\n",
       "      <td>282.605164</td>\n",
       "      <td>284.501807</td>\n",
       "      <td>282.605163</td>\n",
       "      <td>280.263205</td>\n",
       "      <td>282.605164</td>\n",
       "      <td>280.973891</td>\n",
       "      <td>281.791857</td>\n",
       "      <td>282.605164</td>\n",
       "      <td>282.605164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>269.794746</td>\n",
       "      <td>271.570922</td>\n",
       "      <td>270.571046</td>\n",
       "      <td>271.570922</td>\n",
       "      <td>268.258034</td>\n",
       "      <td>271.570922</td>\n",
       "      <td>273.396903</td>\n",
       "      <td>267.461509</td>\n",
       "      <td>271.570922</td>\n",
       "      <td>271.570922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "0  283.936601  279.543638  285.077369  279.543638  276.931626  279.543638   \n",
       "1  280.752154  278.716263  284.554707  278.716262  277.019908  278.716262   \n",
       "2  280.810270  282.660041  281.793406  282.660041  283.966752  282.660041   \n",
       "3  282.690695  282.605164  284.501807  282.605163  280.263205  282.605164   \n",
       "4  269.794746  271.570922  270.571046  271.570922  268.258034  271.570922   \n",
       "\n",
       "    demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "0  279.497137  277.402834  279.543638  279.543638  \n",
       "1  272.022711  278.462176  278.716262  278.716262  \n",
       "2  284.073037  284.669504  282.660041  282.660041  \n",
       "3  280.973891  281.791857  282.605164  282.605164  \n",
       "4  273.396903  267.461509  271.570922  271.570922  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.625929</td>\n",
       "      <td>67.884966</td>\n",
       "      <td>68.750730</td>\n",
       "      <td>68.558033</td>\n",
       "      <td>74.175914</td>\n",
       "      <td>68.558033</td>\n",
       "      <td>65.559446</td>\n",
       "      <td>71.308420</td>\n",
       "      <td>68.558033</td>\n",
       "      <td>68.558033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60.770111</td>\n",
       "      <td>61.058111</td>\n",
       "      <td>59.574148</td>\n",
       "      <td>60.117141</td>\n",
       "      <td>58.717761</td>\n",
       "      <td>60.117141</td>\n",
       "      <td>57.979551</td>\n",
       "      <td>58.390955</td>\n",
       "      <td>60.117144</td>\n",
       "      <td>60.117141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.073532</td>\n",
       "      <td>64.930685</td>\n",
       "      <td>65.683239</td>\n",
       "      <td>63.599781</td>\n",
       "      <td>63.459309</td>\n",
       "      <td>63.599781</td>\n",
       "      <td>64.215938</td>\n",
       "      <td>63.806809</td>\n",
       "      <td>63.599781</td>\n",
       "      <td>63.599781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63.121389</td>\n",
       "      <td>66.381203</td>\n",
       "      <td>61.668540</td>\n",
       "      <td>67.299906</td>\n",
       "      <td>67.404706</td>\n",
       "      <td>67.299906</td>\n",
       "      <td>70.525694</td>\n",
       "      <td>68.097560</td>\n",
       "      <td>67.299908</td>\n",
       "      <td>67.299906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64.915095</td>\n",
       "      <td>62.604395</td>\n",
       "      <td>65.471782</td>\n",
       "      <td>61.716297</td>\n",
       "      <td>63.127936</td>\n",
       "      <td>61.716297</td>\n",
       "      <td>61.250627</td>\n",
       "      <td>60.709187</td>\n",
       "      <td>61.716291</td>\n",
       "      <td>61.716297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   demand_t1  demand_t2  demand_t3  demand_t4  demand_t5  demand_t6  \\\n",
       "0  65.625929  67.884966  68.750730  68.558033  74.175914  68.558033   \n",
       "1  60.770111  61.058111  59.574148  60.117141  58.717761  60.117141   \n",
       "2  66.073532  64.930685  65.683239  63.599781  63.459309  63.599781   \n",
       "3  63.121389  66.381203  61.668540  67.299906  67.404706  67.299906   \n",
       "4  64.915095  62.604395  65.471782  61.716297  63.127936  61.716297   \n",
       "\n",
       "   demand_t7  demand_t8  demand_t9  demand_t10  \n",
       "0  65.559446  71.308420  68.558033   68.558033  \n",
       "1  57.979551  58.390955  60.117144   60.117141  \n",
       "2  64.215938  63.806809  63.599781   63.599781  \n",
       "3  70.525694  68.097560  67.299908   67.299906  \n",
       "4  61.250627  60.709187  61.716291   61.716297  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Qk_hat_k2</th>\n",
       "      <th>Qk_hat_k3</th>\n",
       "      <th>Qk_hat_k4</th>\n",
       "      <th>Qk_hat_k5</th>\n",
       "      <th>Qk_hat_k6</th>\n",
       "      <th>Qk_hat_k7</th>\n",
       "      <th>Qk_hat_k8</th>\n",
       "      <th>Qk_hat_k9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>667.825323</td>\n",
       "      <td>679.441327</td>\n",
       "      <td>674.336130</td>\n",
       "      <td>686.341734</td>\n",
       "      <td>688.364627</td>\n",
       "      <td>688.364627</td>\n",
       "      <td>686.123725</td>\n",
       "      <td>687.537538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>619.725973</td>\n",
       "      <td>615.200743</td>\n",
       "      <td>617.411438</td>\n",
       "      <td>601.269391</td>\n",
       "      <td>602.480994</td>\n",
       "      <td>602.480994</td>\n",
       "      <td>597.018099</td>\n",
       "      <td>596.959203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>672.259056</td>\n",
       "      <td>647.406803</td>\n",
       "      <td>648.811197</td>\n",
       "      <td>641.621708</td>\n",
       "      <td>641.893589</td>\n",
       "      <td>641.893589</td>\n",
       "      <td>643.407440</td>\n",
       "      <td>642.568633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>643.016582</td>\n",
       "      <td>667.674964</td>\n",
       "      <td>672.068531</td>\n",
       "      <td>670.587870</td>\n",
       "      <td>667.499784</td>\n",
       "      <td>667.499784</td>\n",
       "      <td>667.856550</td>\n",
       "      <td>666.398720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>660.784144</td>\n",
       "      <td>624.692052</td>\n",
       "      <td>623.360680</td>\n",
       "      <td>621.516161</td>\n",
       "      <td>624.134902</td>\n",
       "      <td>624.134902</td>\n",
       "      <td>625.562706</td>\n",
       "      <td>624.944206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Qk_hat_k2   Qk_hat_k3   Qk_hat_k4   Qk_hat_k5   Qk_hat_k6   Qk_hat_k7  \\\n",
       "0  667.825323  679.441327  674.336130  686.341734  688.364627  688.364627   \n",
       "1  619.725973  615.200743  617.411438  601.269391  602.480994  602.480994   \n",
       "2  672.259056  647.406803  648.811197  641.621708  641.893589  641.893589   \n",
       "3  643.016582  667.674964  672.068531  670.587870  667.499784  667.499784   \n",
       "4  660.784144  624.692052  623.360680  621.516161  624.134902  624.134902   \n",
       "\n",
       "    Qk_hat_k8   Qk_hat_k9  \n",
       "0  686.123725  687.537538  \n",
       "1  597.018099  596.959203  \n",
       "2  643.407440  642.568633  \n",
       "3  667.856550  666.398720  \n",
       "4  625.562706  624.944206  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_matrix, covariance_matrix = cal_mu_and_cov_matrix(demand_df_test)\n",
    "Qk_hat_df_test = make_Qk_hat_df(\n",
    "    demand_df_test, T, service_lv, mu_matrix, covariance_matrix\n",
    ")\n",
    "Qk_hat_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2855.933587421095)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2855.933587421095)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R(T)</th>\n",
       "      <th>F</th>\n",
       "      <th>Q0</th>\n",
       "      <th>Q1</th>\n",
       "      <th>average_profits</th>\n",
       "      <th>average_losses</th>\n",
       "      <th>average_lefts</th>\n",
       "      <th>average_operation_profits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[571.186717484219, 571.186717484219, 571.18671...</td>\n",
       "      <td>[2230.709066304353, 2219.3859345507494, 2253.9...</td>\n",
       "      <td>1.678226e+06</td>\n",
       "      <td>7.321858</td>\n",
       "      <td>20.465014</td>\n",
       "      <td>1.690805e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[285.5933587421095, 285.5933587421095, 285.593...</td>\n",
       "      <td>[2551.950537417802, 2518.4584487296, 2519.0696...</td>\n",
       "      <td>1.677615e+06</td>\n",
       "      <td>8.250008</td>\n",
       "      <td>19.208939</td>\n",
       "      <td>1.690248e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>[856.7800762263287, 856.7800762263287, 856.780...</td>\n",
       "      <td>[1945.4731593238243, 1934.4342544107076, 1967....</td>\n",
       "      <td>1.669760e+06</td>\n",
       "      <td>11.364008</td>\n",
       "      <td>29.503168</td>\n",
       "      <td>1.688380e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[1142.373434968438, 1142.373434968438, 1142.37...</td>\n",
       "      <td>[1659.8798002283322, 1648.8408957219751, 1682....</td>\n",
       "      <td>1.662185e+06</td>\n",
       "      <td>14.524186</td>\n",
       "      <td>38.961222</td>\n",
       "      <td>1.686484e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[1427.9667937105476, 1427.9667937105476, 1427....</td>\n",
       "      <td>[1372.5526927953044, 1362.399764164267, 1400.9...</td>\n",
       "      <td>1.655684e+06</td>\n",
       "      <td>16.865181</td>\n",
       "      <td>48.190286</td>\n",
       "      <td>1.685079e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[571.186717484219, 571.186717484219, 571.18671...</td>\n",
       "      <td>[2232.1320652116947, 2216.966598236908, 2258.7...</td>\n",
       "      <td>-5.550410e+05</td>\n",
       "      <td>1406.224944</td>\n",
       "      <td>1406.923493</td>\n",
       "      <td>8.514634e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[285.5933587421095, 285.5933587421095, 285.593...</td>\n",
       "      <td>[2514.926127689273, 2504.7731991423348, 2543.2...</td>\n",
       "      <td>-5.624402e+05</td>\n",
       "      <td>1410.801862</td>\n",
       "      <td>1411.690689</td>\n",
       "      <td>8.487172e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[571.186717484219, 571.186717484219, 571.18671...</td>\n",
       "      <td>[2229.3770399518585, 2215.2062509976017, 2257....</td>\n",
       "      <td>-1.007574e+06</td>\n",
       "      <td>1689.232531</td>\n",
       "      <td>1689.232532</td>\n",
       "      <td>6.816588e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[285.5933587421095, 285.5933587421095, 285.593...</td>\n",
       "      <td>[2517.7254239538042, 2502.5599569790174, 2544....</td>\n",
       "      <td>-1.011990e+06</td>\n",
       "      <td>1691.818303</td>\n",
       "      <td>1692.516852</td>\n",
       "      <td>6.801074e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[285.5933587421095, 285.5933587421095, 285.593...</td>\n",
       "      <td>[2514.970398693968, 2500.7996097397113, 2543.0...</td>\n",
       "      <td>-1.464523e+06</td>\n",
       "      <td>1974.825890</td>\n",
       "      <td>1974.825890</td>\n",
       "      <td>5.103028e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    R(T)    F                                                 Q0  \\\n",
       "10     3  0.2  [571.186717484219, 571.186717484219, 571.18671...   \n",
       "0      2  0.1  [285.5933587421095, 285.5933587421095, 285.593...   \n",
       "20     4  0.3  [856.7800762263287, 856.7800762263287, 856.780...   \n",
       "30     5  0.4  [1142.373434968438, 1142.373434968438, 1142.37...   \n",
       "40     6  0.5  [1427.9667937105476, 1427.9667937105476, 1427....   \n",
       "..   ...  ...                                                ...   \n",
       "55     8  0.2  [571.186717484219, 571.186717484219, 571.18671...   \n",
       "45     7  0.1  [285.5933587421095, 285.5933587421095, 285.593...   \n",
       "64     9  0.2  [571.186717484219, 571.186717484219, 571.18671...   \n",
       "54     8  0.1  [285.5933587421095, 285.5933587421095, 285.593...   \n",
       "63     9  0.1  [285.5933587421095, 285.5933587421095, 285.593...   \n",
       "\n",
       "                                                   Q1  average_profits  \\\n",
       "10  [2230.709066304353, 2219.3859345507494, 2253.9...     1.678226e+06   \n",
       "0   [2551.950537417802, 2518.4584487296, 2519.0696...     1.677615e+06   \n",
       "20  [1945.4731593238243, 1934.4342544107076, 1967....     1.669760e+06   \n",
       "30  [1659.8798002283322, 1648.8408957219751, 1682....     1.662185e+06   \n",
       "40  [1372.5526927953044, 1362.399764164267, 1400.9...     1.655684e+06   \n",
       "..                                                ...              ...   \n",
       "55  [2232.1320652116947, 2216.966598236908, 2258.7...    -5.550410e+05   \n",
       "45  [2514.926127689273, 2504.7731991423348, 2543.2...    -5.624402e+05   \n",
       "64  [2229.3770399518585, 2215.2062509976017, 2257....    -1.007574e+06   \n",
       "54  [2517.7254239538042, 2502.5599569790174, 2544....    -1.011990e+06   \n",
       "63  [2514.970398693968, 2500.7996097397113, 2543.0...    -1.464523e+06   \n",
       "\n",
       "    average_losses  average_lefts  average_operation_profits  \n",
       "10        7.321858      20.465014               1.690805e+06  \n",
       "0         8.250008      19.208939               1.690248e+06  \n",
       "20       11.364008      29.503168               1.688380e+06  \n",
       "30       14.524186      38.961222               1.686484e+06  \n",
       "40       16.865181      48.190286               1.685079e+06  \n",
       "..             ...            ...                        ...  \n",
       "55     1406.224944    1406.923493               8.514634e+05  \n",
       "45     1410.801862    1411.690689               8.487172e+05  \n",
       "64     1689.232531    1689.232532               6.816588e+05  \n",
       "54     1691.818303    1692.516852               6.801074e+05  \n",
       "63     1974.825890    1974.825890               5.103028e+05  \n",
       "\n",
       "[72 rows x 8 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_1, stimulation_results_df_1 = None, None\n",
    "\n",
    "results_df_1, stimulation_results_df_1 = grid_fixed_F_fixed_R(\n",
    "    assigned_Ts=ASSIGNED_TS,\n",
    "    assigned_Fs=ASSIGNED_FS,\n",
    "    cost=cost,\n",
    "    price=price,\n",
    "    salvage_value=salvage_value,\n",
    "    Qk_hat_df=Qk_hat_df_train,\n",
    "    demand_df_train=demand_df_train,\n",
    "    Q_star=Q_star,\n",
    ")\n",
    "\n",
    "results_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R: 3, F: 0.2\n",
      "R: 2, F: 0.1\n",
      "R: 4, F: 0.30000000000000004\n",
      "R: 5, F: 0.4\n",
      "R: 6, F: 0.5\n",
      "R: 7, F: 0.6000000000000001\n",
      "R: 8, F: 0.7000000000000001\n",
      "R: 9, F: 0.8\n",
      "R: 3, F: 0.30000000000000004\n",
      "R: 4, F: 0.4\n",
      "R: 5, F: 0.5\n",
      "R: 6, F: 0.6000000000000001\n",
      "R: 7, F: 0.7000000000000001\n",
      "R: 8, F: 0.8\n",
      "R: 9, F: 0.9\n",
      "R: 2, F: 0.2\n",
      "R: 3, F: 0.4\n",
      "R: 4, F: 0.5\n",
      "R: 5, F: 0.6000000000000001\n",
      "R: 6, F: 0.7000000000000001\n",
      "R: 7, F: 0.8\n",
      "R: 8, F: 0.9\n",
      "R: 2, F: 0.30000000000000004\n",
      "R: 3, F: 0.5\n",
      "R: 4, F: 0.6000000000000001\n",
      "R: 5, F: 0.7000000000000001\n",
      "R: 6, F: 0.8\n",
      "R: 7, F: 0.9\n",
      "R: 2, F: 0.4\n",
      "R: 9, F: 0.7000000000000001\n",
      "R: 8, F: 0.6000000000000001\n",
      "R: 7, F: 0.5\n",
      "R: 6, F: 0.4\n",
      "R: 5, F: 0.30000000000000004\n",
      "R: 4, F: 0.2\n",
      "R: 3, F: 0.1\n",
      "R: 3, F: 0.6000000000000001\n",
      "R: 4, F: 0.7000000000000001\n",
      "R: 5, F: 0.8\n",
      "R: 6, F: 0.9\n",
      "R: 2, F: 0.5\n",
      "R: 3, F: 0.7000000000000001\n",
      "R: 4, F: 0.8\n",
      "R: 5, F: 0.9\n",
      "R: 2, F: 0.6000000000000001\n",
      "R: 3, F: 0.8\n",
      "R: 4, F: 0.9\n",
      "R: 2, F: 0.7000000000000001\n",
      "R: 3, F: 0.9\n",
      "R: 2, F: 0.8\n",
      "R: 9, F: 0.6000000000000001\n",
      "R: 8, F: 0.5\n",
      "R: 7, F: 0.4\n",
      "R: 6, F: 0.30000000000000004\n",
      "R: 5, F: 0.2\n",
      "R: 4, F: 0.1\n",
      "R: 2, F: 0.9\n",
      "R: 9, F: 0.5\n",
      "R: 8, F: 0.4\n",
      "R: 7, F: 0.30000000000000004\n",
      "R: 6, F: 0.2\n",
      "R: 5, F: 0.1\n",
      "R: 9, F: 0.4\n",
      "R: 8, F: 0.30000000000000004\n",
      "R: 7, F: 0.2\n",
      "R: 6, F: 0.1\n",
      "R: 9, F: 0.30000000000000004\n",
      "R: 8, F: 0.2\n",
      "R: 7, F: 0.1\n",
      "R: 9, F: 0.2\n",
      "R: 8, F: 0.1\n",
      "R: 9, F: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "result = results_df_1.iloc[:, 0:2]\n",
    "for i in range(len(result)):\n",
    "    print(f\"R: {result.iloc[i, 0]}, F: {result.iloc[i, 1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R(T)</th>\n",
       "      <th>F</th>\n",
       "      <th>Q0</th>\n",
       "      <th>Q1</th>\n",
       "      <th>average_profits</th>\n",
       "      <th>average_losses</th>\n",
       "      <th>average_lefts</th>\n",
       "      <th>average_operation_profits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[285.5933587421095, 285.5933587421095, 285.593...</td>\n",
       "      <td>[400.7483750048721, 315.67603254339434, 356.02...</td>\n",
       "      <td>3.693994e+05</td>\n",
       "      <td>1.002283e+00</td>\n",
       "      <td>32.466334</td>\n",
       "      <td>382987.280229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[571.186717484219, 571.186717484219, 571.18671...</td>\n",
       "      <td>[116.35082099292742, 25.77248565647926, 71.381...</td>\n",
       "      <td>3.596662e+05</td>\n",
       "      <td>3.843170e-07</td>\n",
       "      <td>59.806058</td>\n",
       "      <td>383588.649541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[285.5933587421095, 285.5933587421095, 285.593...</td>\n",
       "      <td>[388.74277142604416, 331.81807912174264, 363.2...</td>\n",
       "      <td>3.416014e+05</td>\n",
       "      <td>2.023757e+00</td>\n",
       "      <td>98.896975</td>\n",
       "      <td>382374.395368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[571.186717484219, 571.186717484219, 571.18671...</td>\n",
       "      <td>[114.93700720959157, 25.831381486595205, 72.22...</td>\n",
       "      <td>3.335338e+05</td>\n",
       "      <td>2.412024e-01</td>\n",
       "      <td>124.413564</td>\n",
       "      <td>383443.928345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[285.5933587421095, 285.5933587421095, 285.593...</td>\n",
       "      <td>[402.77126797877787, 316.88763569452675, 356.3...</td>\n",
       "      <td>3.295148e+05</td>\n",
       "      <td>3.363651e+01</td>\n",
       "      <td>34.274979</td>\n",
       "      <td>363406.741464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[2570.3402286789856, 2570.3402286789856, 2570....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>-1.289266e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4182.136168</td>\n",
       "      <td>383588.649771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[2570.3402286789856, 2570.3402286789856, 2570....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>-1.314975e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4246.408495</td>\n",
       "      <td>383588.649771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[2570.3402286789856, 2570.3402286789856, 2570....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>-1.340561e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4310.375373</td>\n",
       "      <td>383588.649771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[2570.3402286789856, 2570.3402286789856, 2570....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>-1.366034e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4374.056950</td>\n",
       "      <td>383588.649771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[2570.3402286789856, 2570.3402286789856, 2570....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>-1.391626e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4438.036770</td>\n",
       "      <td>383588.649771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    R(T)    F                                                 Q0  \\\n",
       "27     5  0.1  [285.5933587421095, 285.5933587421095, 285.593...   \n",
       "64     9  0.2  [571.186717484219, 571.186717484219, 571.18671...   \n",
       "18     4  0.1  [285.5933587421095, 285.5933587421095, 285.593...   \n",
       "55     8  0.2  [571.186717484219, 571.186717484219, 571.18671...   \n",
       "36     6  0.1  [285.5933587421095, 285.5933587421095, 285.593...   \n",
       "..   ...  ...                                                ...   \n",
       "44     6  0.9  [2570.3402286789856, 2570.3402286789856, 2570....   \n",
       "35     5  0.9  [2570.3402286789856, 2570.3402286789856, 2570....   \n",
       "26     4  0.9  [2570.3402286789856, 2570.3402286789856, 2570....   \n",
       "17     3  0.9  [2570.3402286789856, 2570.3402286789856, 2570....   \n",
       "8      2  0.9  [2570.3402286789856, 2570.3402286789856, 2570....   \n",
       "\n",
       "                                                   Q1  average_profits  \\\n",
       "27  [400.7483750048721, 315.67603254339434, 356.02...     3.693994e+05   \n",
       "64  [116.35082099292742, 25.77248565647926, 71.381...     3.596662e+05   \n",
       "18  [388.74277142604416, 331.81807912174264, 363.2...     3.416014e+05   \n",
       "55  [114.93700720959157, 25.831381486595205, 72.22...     3.335338e+05   \n",
       "36  [402.77126797877787, 316.88763569452675, 356.3...     3.295148e+05   \n",
       "..                                                ...              ...   \n",
       "44      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]    -1.289266e+06   \n",
       "35      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]    -1.314975e+06   \n",
       "26      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]    -1.340561e+06   \n",
       "17      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]    -1.366034e+06   \n",
       "8       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]    -1.391626e+06   \n",
       "\n",
       "    average_losses  average_lefts  average_operation_profits  \n",
       "27    1.002283e+00      32.466334              382987.280229  \n",
       "64    3.843170e-07      59.806058              383588.649541  \n",
       "18    2.023757e+00      98.896975              382374.395368  \n",
       "55    2.412024e-01     124.413564              383443.928345  \n",
       "36    3.363651e+01      34.274979              363406.741464  \n",
       "..             ...            ...                        ...  \n",
       "44    0.000000e+00    4182.136168              383588.649771  \n",
       "35    0.000000e+00    4246.408495              383588.649771  \n",
       "26    0.000000e+00    4310.375373              383588.649771  \n",
       "17    0.000000e+00    4374.056950              383588.649771  \n",
       "8     0.000000e+00    4438.036770              383588.649771  \n",
       "\n",
       "[72 rows x 8 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_1, stimulation_results_df_1 = None, None\n",
    "\n",
    "results_df_1, stimulation_results_df_1 = grid_fixed_F_fixed_R(\n",
    "    assigned_Ts=ASSIGNED_TS,\n",
    "    assigned_Fs=ASSIGNED_FS,\n",
    "    cost=cost,\n",
    "    price=price,\n",
    "    salvage_value=salvage_value,\n",
    "    Qk_hat_df=Qk_hat_df_test,\n",
    "    demand_df_train=demand_df_test,\n",
    "    Q_star=Q_star,\n",
    ")\n",
    "\n",
    "results_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R: 5, F: 0.1\n",
      "R: 9, F: 0.2\n",
      "R: 4, F: 0.1\n",
      "R: 8, F: 0.2\n",
      "R: 6, F: 0.1\n",
      "R: 3, F: 0.1\n",
      "R: 7, F: 0.2\n",
      "R: 6, F: 0.2\n",
      "R: 2, F: 0.1\n",
      "R: 5, F: 0.2\n",
      "R: 4, F: 0.2\n",
      "R: 7, F: 0.1\n",
      "R: 3, F: 0.2\n",
      "R: 2, F: 0.2\n",
      "R: 9, F: 0.30000000000000004\n",
      "R: 8, F: 0.30000000000000004\n",
      "R: 8, F: 0.1\n",
      "R: 7, F: 0.30000000000000004\n",
      "R: 6, F: 0.30000000000000004\n",
      "R: 5, F: 0.30000000000000004\n",
      "R: 4, F: 0.30000000000000004\n",
      "R: 9, F: 0.1\n",
      "R: 3, F: 0.30000000000000004\n",
      "R: 2, F: 0.30000000000000004\n",
      "R: 9, F: 0.4\n",
      "R: 8, F: 0.4\n",
      "R: 7, F: 0.4\n",
      "R: 6, F: 0.4\n",
      "R: 5, F: 0.4\n",
      "R: 4, F: 0.4\n",
      "R: 3, F: 0.4\n",
      "R: 2, F: 0.4\n",
      "R: 9, F: 0.5\n",
      "R: 8, F: 0.5\n",
      "R: 7, F: 0.5\n",
      "R: 6, F: 0.5\n",
      "R: 5, F: 0.5\n",
      "R: 4, F: 0.5\n",
      "R: 3, F: 0.5\n",
      "R: 2, F: 0.5\n",
      "R: 9, F: 0.6000000000000001\n",
      "R: 8, F: 0.6000000000000001\n",
      "R: 7, F: 0.6000000000000001\n",
      "R: 6, F: 0.6000000000000001\n",
      "R: 5, F: 0.6000000000000001\n",
      "R: 4, F: 0.6000000000000001\n",
      "R: 3, F: 0.6000000000000001\n",
      "R: 2, F: 0.6000000000000001\n",
      "R: 9, F: 0.7000000000000001\n",
      "R: 8, F: 0.7000000000000001\n",
      "R: 7, F: 0.7000000000000001\n",
      "R: 6, F: 0.7000000000000001\n",
      "R: 5, F: 0.7000000000000001\n",
      "R: 4, F: 0.7000000000000001\n",
      "R: 3, F: 0.7000000000000001\n",
      "R: 2, F: 0.7000000000000001\n",
      "R: 9, F: 0.8\n",
      "R: 8, F: 0.8\n",
      "R: 7, F: 0.8\n",
      "R: 6, F: 0.8\n",
      "R: 5, F: 0.8\n",
      "R: 4, F: 0.8\n",
      "R: 3, F: 0.8\n",
      "R: 2, F: 0.8\n",
      "R: 9, F: 0.9\n",
      "R: 8, F: 0.9\n",
      "R: 7, F: 0.9\n",
      "R: 6, F: 0.9\n",
      "R: 5, F: 0.9\n",
      "R: 4, F: 0.9\n",
      "R: 3, F: 0.9\n",
      "R: 2, F: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "result = results_df_1.iloc[:, 0:2]\n",
    "for i in range(len(result)):\n",
    "    print(f\"R: {result.iloc[i, 0]}, F: {result.iloc[i, 1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.626271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>279.543638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.506622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>278.716262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.780418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282.660041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.219951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282.605164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.119275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>271.570922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X1   X2          X3\n",
       "0  18.626271  0.0  279.543638\n",
       "1  17.506622  0.0  278.716262\n",
       "2  19.780418  0.0  282.660041\n",
       "3  18.219951  0.0  282.605164\n",
       "4  17.119275  0.0  271.570922"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>283.936601</td>\n",
       "      <td>279.543638</td>\n",
       "      <td>285.077369</td>\n",
       "      <td>279.543638</td>\n",
       "      <td>276.931626</td>\n",
       "      <td>279.543638</td>\n",
       "      <td>279.497137</td>\n",
       "      <td>277.402834</td>\n",
       "      <td>279.543638</td>\n",
       "      <td>279.543638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>280.752154</td>\n",
       "      <td>278.716263</td>\n",
       "      <td>284.554707</td>\n",
       "      <td>278.716262</td>\n",
       "      <td>277.019908</td>\n",
       "      <td>278.716262</td>\n",
       "      <td>272.022711</td>\n",
       "      <td>278.462176</td>\n",
       "      <td>278.716262</td>\n",
       "      <td>278.716262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>280.810270</td>\n",
       "      <td>282.660041</td>\n",
       "      <td>281.793406</td>\n",
       "      <td>282.660041</td>\n",
       "      <td>283.966752</td>\n",
       "      <td>282.660041</td>\n",
       "      <td>284.073037</td>\n",
       "      <td>284.669504</td>\n",
       "      <td>282.660041</td>\n",
       "      <td>282.660041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>282.690695</td>\n",
       "      <td>282.605164</td>\n",
       "      <td>284.501807</td>\n",
       "      <td>282.605163</td>\n",
       "      <td>280.263205</td>\n",
       "      <td>282.605164</td>\n",
       "      <td>280.973891</td>\n",
       "      <td>281.791857</td>\n",
       "      <td>282.605164</td>\n",
       "      <td>282.605164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>269.794746</td>\n",
       "      <td>271.570922</td>\n",
       "      <td>270.571046</td>\n",
       "      <td>271.570922</td>\n",
       "      <td>268.258034</td>\n",
       "      <td>271.570922</td>\n",
       "      <td>273.396903</td>\n",
       "      <td>267.461509</td>\n",
       "      <td>271.570922</td>\n",
       "      <td>271.570922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "0  283.936601  279.543638  285.077369  279.543638  276.931626  279.543638   \n",
       "1  280.752154  278.716263  284.554707  278.716262  277.019908  278.716262   \n",
       "2  280.810270  282.660041  281.793406  282.660041  283.966752  282.660041   \n",
       "3  282.690695  282.605164  284.501807  282.605163  280.263205  282.605164   \n",
       "4  269.794746  271.570922  270.571046  271.570922  268.258034  271.570922   \n",
       "\n",
       "    demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "0  279.497137  277.402834  279.543638  279.543638  \n",
       "1  272.022711  278.462176  278.716262  278.716262  \n",
       "2  284.073037  284.669504  282.660041  282.660041  \n",
       "3  280.973891  281.791857  282.605164  282.605164  \n",
       "4  273.396903  267.461509  271.570922  271.570922  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.625929</td>\n",
       "      <td>67.884966</td>\n",
       "      <td>68.750730</td>\n",
       "      <td>68.558033</td>\n",
       "      <td>74.175914</td>\n",
       "      <td>68.558033</td>\n",
       "      <td>65.559446</td>\n",
       "      <td>71.308420</td>\n",
       "      <td>68.558033</td>\n",
       "      <td>68.558033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60.770111</td>\n",
       "      <td>61.058111</td>\n",
       "      <td>59.574148</td>\n",
       "      <td>60.117141</td>\n",
       "      <td>58.717761</td>\n",
       "      <td>60.117141</td>\n",
       "      <td>57.979551</td>\n",
       "      <td>58.390955</td>\n",
       "      <td>60.117144</td>\n",
       "      <td>60.117141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.073532</td>\n",
       "      <td>64.930685</td>\n",
       "      <td>65.683239</td>\n",
       "      <td>63.599781</td>\n",
       "      <td>63.459309</td>\n",
       "      <td>63.599781</td>\n",
       "      <td>64.215938</td>\n",
       "      <td>63.806809</td>\n",
       "      <td>63.599781</td>\n",
       "      <td>63.599781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63.121389</td>\n",
       "      <td>66.381203</td>\n",
       "      <td>61.668540</td>\n",
       "      <td>67.299906</td>\n",
       "      <td>67.404706</td>\n",
       "      <td>67.299906</td>\n",
       "      <td>70.525694</td>\n",
       "      <td>68.097560</td>\n",
       "      <td>67.299908</td>\n",
       "      <td>67.299906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64.915095</td>\n",
       "      <td>62.604395</td>\n",
       "      <td>65.471782</td>\n",
       "      <td>61.716297</td>\n",
       "      <td>63.127936</td>\n",
       "      <td>61.716297</td>\n",
       "      <td>61.250627</td>\n",
       "      <td>60.709187</td>\n",
       "      <td>61.716291</td>\n",
       "      <td>61.716297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   demand_t1  demand_t2  demand_t3  demand_t4  demand_t5  demand_t6  \\\n",
       "0  65.625929  67.884966  68.750730  68.558033  74.175914  68.558033   \n",
       "1  60.770111  61.058111  59.574148  60.117141  58.717761  60.117141   \n",
       "2  66.073532  64.930685  65.683239  63.599781  63.459309  63.599781   \n",
       "3  63.121389  66.381203  61.668540  67.299906  67.404706  67.299906   \n",
       "4  64.915095  62.604395  65.471782  61.716297  63.127936  61.716297   \n",
       "\n",
       "   demand_t7  demand_t8  demand_t9  demand_t10  \n",
       "0  65.559446  71.308420  68.558033   68.558033  \n",
       "1  57.979551  58.390955  60.117144   60.117141  \n",
       "2  64.215938  63.806809  63.599781   63.599781  \n",
       "3  70.525694  68.097560  67.299908   67.299906  \n",
       "4  61.250627  60.709187  61.716291   61.716297  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Qk_hat_k2</th>\n",
       "      <th>Qk_hat_k3</th>\n",
       "      <th>Qk_hat_k4</th>\n",
       "      <th>Qk_hat_k5</th>\n",
       "      <th>Qk_hat_k6</th>\n",
       "      <th>Qk_hat_k7</th>\n",
       "      <th>Qk_hat_k8</th>\n",
       "      <th>Qk_hat_k9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2837.543896</td>\n",
       "      <td>2801.895784</td>\n",
       "      <td>2802.253236</td>\n",
       "      <td>2802.253235</td>\n",
       "      <td>2800.519487</td>\n",
       "      <td>2800.519486</td>\n",
       "      <td>2803.318783</td>\n",
       "      <td>2800.563757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2804.051807</td>\n",
       "      <td>2790.572652</td>\n",
       "      <td>2791.214331</td>\n",
       "      <td>2791.214331</td>\n",
       "      <td>2790.366558</td>\n",
       "      <td>2790.366558</td>\n",
       "      <td>2788.153316</td>\n",
       "      <td>2786.392968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804.663037</td>\n",
       "      <td>2825.118813</td>\n",
       "      <td>2824.755383</td>\n",
       "      <td>2824.755383</td>\n",
       "      <td>2828.867469</td>\n",
       "      <td>2828.867469</td>\n",
       "      <td>2829.916572</td>\n",
       "      <td>2828.613175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2824.440209</td>\n",
       "      <td>2827.055047</td>\n",
       "      <td>2827.060461</td>\n",
       "      <td>2827.060461</td>\n",
       "      <td>2824.661479</td>\n",
       "      <td>2824.661479</td>\n",
       "      <td>2824.167915</td>\n",
       "      <td>2823.247273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2688.808448</td>\n",
       "      <td>2714.039483</td>\n",
       "      <td>2713.747047</td>\n",
       "      <td>2713.747047</td>\n",
       "      <td>2709.556771</td>\n",
       "      <td>2709.556771</td>\n",
       "      <td>2710.287920</td>\n",
       "      <td>2707.336847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Qk_hat_k2    Qk_hat_k3    Qk_hat_k4    Qk_hat_k5    Qk_hat_k6  \\\n",
       "0  2837.543896  2801.895784  2802.253236  2802.253235  2800.519487   \n",
       "1  2804.051807  2790.572652  2791.214331  2791.214331  2790.366558   \n",
       "2  2804.663037  2825.118813  2824.755383  2824.755383  2828.867469   \n",
       "3  2824.440209  2827.055047  2827.060461  2827.060461  2824.661479   \n",
       "4  2688.808448  2714.039483  2713.747047  2713.747047  2709.556771   \n",
       "\n",
       "     Qk_hat_k7    Qk_hat_k8    Qk_hat_k9  \n",
       "0  2800.519486  2803.318783  2800.563757  \n",
       "1  2790.366558  2788.153316  2786.392968  \n",
       "2  2828.867469  2829.916572  2828.613175  \n",
       "3  2824.661479  2824.167915  2823.247273  \n",
       "4  2709.556771  2710.287920  2707.336847  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qk_hat_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Qk_hat_k2</th>\n",
       "      <th>Qk_hat_k3</th>\n",
       "      <th>Qk_hat_k4</th>\n",
       "      <th>Qk_hat_k5</th>\n",
       "      <th>Qk_hat_k6</th>\n",
       "      <th>Qk_hat_k7</th>\n",
       "      <th>Qk_hat_k8</th>\n",
       "      <th>Qk_hat_k9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>667.825323</td>\n",
       "      <td>679.441327</td>\n",
       "      <td>674.336130</td>\n",
       "      <td>686.341734</td>\n",
       "      <td>688.364627</td>\n",
       "      <td>688.364627</td>\n",
       "      <td>686.123725</td>\n",
       "      <td>687.537538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>619.725973</td>\n",
       "      <td>615.200743</td>\n",
       "      <td>617.411438</td>\n",
       "      <td>601.269391</td>\n",
       "      <td>602.480994</td>\n",
       "      <td>602.480994</td>\n",
       "      <td>597.018099</td>\n",
       "      <td>596.959203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>672.259056</td>\n",
       "      <td>647.406803</td>\n",
       "      <td>648.811197</td>\n",
       "      <td>641.621708</td>\n",
       "      <td>641.893589</td>\n",
       "      <td>641.893589</td>\n",
       "      <td>643.407440</td>\n",
       "      <td>642.568633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>643.016582</td>\n",
       "      <td>667.674964</td>\n",
       "      <td>672.068531</td>\n",
       "      <td>670.587870</td>\n",
       "      <td>667.499784</td>\n",
       "      <td>667.499784</td>\n",
       "      <td>667.856550</td>\n",
       "      <td>666.398720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>660.784144</td>\n",
       "      <td>624.692052</td>\n",
       "      <td>623.360680</td>\n",
       "      <td>621.516161</td>\n",
       "      <td>624.134902</td>\n",
       "      <td>624.134902</td>\n",
       "      <td>625.562706</td>\n",
       "      <td>624.944206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Qk_hat_k2   Qk_hat_k3   Qk_hat_k4   Qk_hat_k5   Qk_hat_k6   Qk_hat_k7  \\\n",
       "0  667.825323  679.441327  674.336130  686.341734  688.364627  688.364627   \n",
       "1  619.725973  615.200743  617.411438  601.269391  602.480994  602.480994   \n",
       "2  672.259056  647.406803  648.811197  641.621708  641.893589  641.893589   \n",
       "3  643.016582  667.674964  672.068531  670.587870  667.499784  667.499784   \n",
       "4  660.784144  624.692052  623.360680  621.516161  624.134902  624.134902   \n",
       "\n",
       "    Qk_hat_k8   Qk_hat_k9  \n",
       "0  686.123725  687.537538  \n",
       "1  597.018099  596.959203  \n",
       "2  643.407440  642.568633  \n",
       "3  667.856550  666.398720  \n",
       "4  625.562706  624.944206  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qk_hat_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++++++++++++++++++++++ THis is R=0 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x1b182bdd\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [3e+02, 3e+03]\n",
      "Presolve removed 62 rows and 97 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 231 rows, 167 columns, 612 nonzeros\n",
      "Presolved model has 41 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 126 continuous, 41 integer (41 binary)\n",
      "\n",
      "Root relaxation: objective 2.526280e+07, 96 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5263e+07    0   24          - 2.5263e+07      -     -    0s\n",
      "H    0     0                    1.837560e+07 2.5263e+07  37.5%     -    0s\n",
      "     0     2 2.5263e+07    0   23 1.8376e+07 2.5263e+07  37.5%     -    0s\n",
      "H   47    42                    2.521248e+07 2.5247e+07  0.14%   3.1    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 6\n",
      "\n",
      "Explored 55 nodes (258 simplex iterations) in 0.04 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 2.52125e+07 1.83756e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.521248454498e+07, best bound 2.524682906173e+07, gap 0.1362%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.060053955115222, Left1: 36.98013902744424\n",
      "f_vars[i]: -2.1879, F_vars[i]: 0.1008, Q0_vars[i]: 287.9967\n",
      "f_train: -2.1879092390044566, F_train: 0.10084150994459902, Q0_train: 287.9966552570387\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.787564348438821, Left1: 17.65883923238772\n",
      "f_vars[i]: -2.1935, F_vars[i]: 0.1003, Q0_vars[i]: 286.5397\n",
      "f_train: -2.1935481437537554, F_train: 0.10033136594714728, Q0_train: 286.53971788029503\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 23.950137039603305, Left0: 9.872340148496908, Left1: 0.0\n",
      "f_vars[i]: -2.1776, F_vars[i]: 0.1018, Q0_vars[i]: 290.6826\n",
      "f_train: -2.177579615911198, F_train: 0.10178199208539633, Q0_train: 290.68260979131145\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 6.515511457487264, Left1: 1.1929361545426218\n",
      "f_vars[i]: -2.1832, F_vars[i]: 0.1013, Q0_vars[i]: 289.2062\n",
      "f_train: -2.1832470233647334, F_train: 0.1012650320831993, Q0_train: 289.2062063576837\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 18.52839886017364, Left0: 12.738649214080937, Left1: 0.0\n",
      "f_vars[i]: -2.2092, F_vars[i]: 0.0989, Q0_vars[i]: 282.5334\n",
      "f_train: -2.2091865780015167, F_train: 0.09892855934560975, Q0_train: 282.53339539030793\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 27.037615877432472, Left0: 3.2888684533512365, Left1: 0.0\n",
      "f_vars[i]: -2.1595, F_vars[i]: 0.1034, Q0_vars[i]: 295.4302\n",
      "f_train: -2.159526722746368, F_train: 0.10344433666010124, Q0_train: 295.43015549607844\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 10.330585983085257, Left0: 10.800221369836542, Left1: 0.0\n",
      "f_vars[i]: -2.2228, F_vars[i]: 0.0977, Q0_vars[i]: 279.0955\n",
      "f_train: -2.2227643965641244, F_train: 0.09772478339015149, Q0_train: 279.0954912073848\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.807816447849632, Left1: 5.711934684325456\n",
      "f_vars[i]: -2.2109, F_vars[i]: 0.0988, Q0_vars[i]: 282.0923\n",
      "f_train: -2.2109205403091607, F_train: 0.09877409845606026, Q0_train: 282.09226534790065\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 18.63196479163662\n",
      "f_vars[i]: -2.1590, F_vars[i]: 0.1035, Q0_vars[i]: 295.5617\n",
      "f_train: -2.1590302726288435, F_train: 0.10349038829938181, Q0_train: 295.56167591945564\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 9.624653434906463\n",
      "f_vars[i]: -2.1742, F_vars[i]: 0.1021, Q0_vars[i]: 291.5728\n",
      "f_train: -2.174174930531133, F_train: 0.10209367894210351, Q0_train: 291.5727667541392\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1.0722277325696912, Left1: 35.7239876263352\n",
      "f_vars[i]: -2.1785, F_vars[i]: 0.1017, Q0_vars[i]: 290.4313\n",
      "f_train: -2.178542605490295, F_train: 0.10169398700437146, Q0_train: 290.4312731245488\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 15.167211664113097, Left1: 24.802197373810486\n",
      "f_vars[i]: -2.2421, F_vars[i]: 0.0960, Q0_vars[i]: 274.2531\n",
      "f_train: -2.2421444031504554, F_train: 0.09602922985746526, Q0_train: 274.2531029241157\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.8846871863621004, Lost1: 8.3115379161577, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -2.1656, F_vars[i]: 0.1029, Q0_vars[i]: 293.8189\n",
      "f_train: -2.165624568849525, F_train: 0.10288016641264773, Q0_train: 293.8189227373523\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1.0085534925042383, Left1: 24.290380924166584\n",
      "f_vars[i]: -2.1832, F_vars[i]: 0.1013, Q0_vars[i]: 289.2175\n",
      "f_train: -2.183203589269767, F_train: 0.10126898510711792, Q0_train: 289.2174959314647\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 6.286913241360878, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -2.1500, F_vars[i]: 0.1043, Q0_vars[i]: 297.9715\n",
      "f_train: -2.1499682164789147, F_train: 0.10433419320622409, Q0_train: 297.9715266941372\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=1 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xe813c422\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [5e+02, 2e+03]\n",
      "Presolve removed 55 rows and 83 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 238 rows, 181 columns, 635 nonzeros\n",
      "Presolved model has 47 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 134 continuous, 47 integer (47 binary)\n",
      "\n",
      "Root relaxation: objective 2.539216e+07, 96 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5392e+07    0   27          - 2.5392e+07      -     -    0s\n",
      "H    0     0                    2.021465e+07 2.5392e+07  25.6%     -    0s\n",
      "     0     2 2.5392e+07    0   25 2.0215e+07 2.5392e+07  25.6%     -    0s\n",
      "H    9     8                    2.496805e+07 2.5390e+07  1.69%   2.1    0s\n",
      "H   69    48                    2.535098e+07 2.5388e+07  0.15%   5.0    0s\n",
      "H   78    48                    2.536595e+07 2.5388e+07  0.09%   5.1    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 7\n",
      "\n",
      "Explored 93 nodes (565 simplex iterations) in 0.05 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 4: 2.53659e+07 2.5351e+07 2.49681e+07 2.02146e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.536594985536e+07, best bound 2.538816320492e+07, gap 0.0876%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1.6509233943988875, Left1: 1.332026656104972\n",
      "f_vars[i]: -1.3996, F_vars[i]: 0.1979, Q0_vars[i]: 565.1312\n",
      "f_train: -1.399599587920067, F_train: 0.19787965847949895, Q0_train: 565.1311629190166\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 3.5445045182577815, Left1: 4.179683795646724\n",
      "f_vars[i]: -1.4043, F_vars[i]: 0.1971, Q0_vars[i]: 563.0129\n",
      "f_train: -1.4042791069146987, F_train: 0.19713795973656073, Q0_train: 563.0129205673113\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.4943610967070526, Left0: 7.606436190936964, Left1: 0.0\n",
      "f_vars[i]: -1.3865, F_vars[i]: 0.2000, Q0_vars[i]: 571.0767\n",
      "f_train: -1.3865350410105632, F_train: 0.19996149399796434, Q0_train: 571.076746899688\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.628808079755117, Left1: 3.807774725673653\n",
      "f_vars[i]: -1.3891, F_vars[i]: 0.1996, Q0_vars[i]: 569.9247\n",
      "f_train: -1.3890585587017643, F_train: 0.19955809512199388, Q0_train: 569.9246665006762\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.724340443913093, Left1: 6.702636206277816\n",
      "f_vars[i]: -1.4309, F_vars[i]: 0.1930, Q0_vars[i]: 551.0900\n",
      "f_train: -1.4308699410270553, F_train: 0.19296317353322526, Q0_train: 551.0900084289033\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.845951177695952, Left0: 3.3958092645252993, Left1: 0.0\n",
      "f_vars[i]: -1.3448, F_vars[i]: 0.2067, Q0_vars[i]: 590.3644\n",
      "f_train: -1.3448412741277287, F_train: 0.20671504011846142, Q0_train: 590.3644260994131\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.936046206859146, Left1: 0.8369143515958513\n",
      "f_vars[i]: -1.4455, F_vars[i]: 0.1907, Q0_vars[i]: 544.6094\n",
      "f_train: -1.4455070180978027, F_train: 0.19069400356661037, Q0_train: 544.6094097056807\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 8.565508626546034, Left0: 4.967379547359613, Left1: 0.0\n",
      "f_vars[i]: -1.4310, F_vars[i]: 0.1929, Q0_vars[i]: 551.0451\n",
      "f_train: -1.430970975329678, F_train: 0.19294744011231044, Q0_train: 551.0450748236676\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 7.223925849980674\n",
      "f_vars[i]: -1.3453, F_vars[i]: 0.2066, Q0_vars[i]: 590.1578\n",
      "f_train: -1.345282438128392, F_train: 0.20664270567113363, Q0_train: 590.1578437217621\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.2752086234244143, Lost1: 2.146915156855357, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.3636, F_vars[i]: 0.2036, Q0_vars[i]: 581.6073\n",
      "f_train: -1.363643764037441, F_train: 0.20364873333268418, Q0_train: 581.6072575605747\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.40495027274846507, Lost1: 0.19055914424596293, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.3798, F_vars[i]: 0.2010, Q0_vars[i]: 574.1485\n",
      "f_train: -1.379825222153968, F_train: 0.2010370713053023, Q0_train: 574.1485242575825\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 10.690312559156837, Left1: 4.161348693613036\n",
      "f_vars[i]: -1.4911, F_vars[i]: 0.1838, Q0_vars[i]: 524.7875\n",
      "f_train: -1.4911217770574734, F_train: 0.18375341452047714, Q0_train: 524.7875483323418\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.6376606011212971, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.3442, F_vars[i]: 0.2068, Q0_vars[i]: 590.6777\n",
      "f_train: -1.3441723976322357, F_train: 0.20682474663361253, Q0_train: 590.6777406207921\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 3.1138721000688747\n",
      "f_vars[i]: -1.3803, F_vars[i]: 0.2010, Q0_vars[i]: 573.9210\n",
      "f_train: -1.3803212737835224, F_train: 0.20095740672951254, Q0_train: 573.9210075198569\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1.0910902037981007, Left1: 6.785318866206467\n",
      "f_vars[i]: -1.3265, F_vars[i]: 0.2097, Q0_vars[i]: 599.0050\n",
      "f_train: -1.3264902597002663, F_train: 0.20974051003249516, Q0_train: 599.0049672446341\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=2 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xc51f1d70\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [8e+02, 2e+03]\n",
      "Presolve removed 55 rows and 83 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 238 rows, 181 columns, 635 nonzeros\n",
      "Presolved model has 47 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 134 continuous, 47 integer (47 binary)\n",
      "\n",
      "Root relaxation: objective 2.539194e+07, 97 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5392e+07    0   27          - 2.5392e+07      -     -    0s\n",
      "H    0     0                    2.192218e+07 2.5392e+07  15.8%     -    0s\n",
      "     0     2 2.5392e+07    0   25 2.1922e+07 2.5392e+07  15.8%     -    0s\n",
      "H    9     8                    2.491100e+07 2.5390e+07  1.92%   1.7    0s\n",
      "H   29    26                    2.491100e+07 2.5389e+07  1.92%   6.4    0s\n",
      "H   30    26                    2.491100e+07 2.5389e+07  1.92%   6.3    0s\n",
      "H  144   100                    2.521362e+07 2.5388e+07  0.69%   6.4    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 7\n",
      "\n",
      "Explored 173 nodes (1294 simplex iterations) in 0.03 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 5: 2.52136e+07 2.4911e+07 2.4911e+07 ... 2.19222e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.521361505711e+07, best bound 2.538784799529e+07, gap 0.6910%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.986591430260887, Left1: 1.6894784176856774\n",
      "f_vars[i]: -0.8477, F_vars[i]: 0.2999, Q0_vars[i]: 856.5442\n",
      "f_train: -0.8476911853568848, F_train: 0.2999174082545109, Q0_train: 856.5441996863425\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 18.204039374747026, Left1: 4.821362397714438\n",
      "f_vars[i]: -0.8382, F_vars[i]: 0.3019, Q0_vars[i]: 862.2272\n",
      "f_train: -0.8382319449278091, F_train: 0.30190728744437584, Q0_train: 862.2271624995881\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.8577910975809573, Left0: 7.592916616946465, Left1: 0.0\n",
      "f_vars[i]: -0.8538, F_vars[i]: 0.2986, Q0_vars[i]: 852.8566\n",
      "f_train: -0.8538482942034122, F_train: 0.2986262135902069, Q0_train: 852.8566334766579\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 12.014630966228651, Left1: 3.8131883063683745\n",
      "f_vars[i]: -0.8389, F_vars[i]: 0.3018, Q0_vars[i]: 861.8123\n",
      "f_train: -0.838921284046026, F_train: 0.30176202267215335, Q0_train: 861.8122959575288\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 45.71257714245439, Left1: 6.4102002592935605\n",
      "f_vars[i]: -0.8458, F_vars[i]: 0.3003, Q0_vars[i]: 857.6493\n",
      "f_train: -0.8458489750068168, F_train: 0.3003043540714707, Q0_train: 857.6492912415101\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 8.702107413295266, Lost1: 0.0, Left0: 0.0, Left1: 3.9300240147216465\n",
      "f_vars[i]: -0.8177, F_vars[i]: 0.3063, Q0_vars[i]: 874.6304\n",
      "f_train: -0.8177087193907926, F_train: 0.3062502515136345, Q0_train: 874.6303794539468\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 57.35193698082935, Left1: 1.389254652016234\n",
      "f_vars[i]: -0.8315, F_vars[i]: 0.3033, Q0_vars[i]: 866.3145\n",
      "f_train: -0.8314504970664722, F_train: 0.30333845757963135, Q0_train: 866.3144893581782\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 8.244358266112158, Left0: 39.426399749246, Left1: 0.0\n",
      "f_vars[i]: -0.8396, F_vars[i]: 0.3016, Q0_vars[i]: 861.3959\n",
      "f_train: -0.839613378815391, F_train: 0.3016162171349419, Q0_train: 861.3958850265747\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 12.665166813674261, Lost1: 0.0, Left0: 0.0, Left1: 19.474710993618224\n",
      "f_vars[i]: -0.8207, F_vars[i]: 0.3056, Q0_vars[i]: 872.8388\n",
      "f_train: -0.8206629650754492, F_train: 0.3056229489323628, Q0_train: 872.838844942617\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.1637467407099393, Left0: 8.29925951450744, Left1: 0.0\n",
      "f_vars[i]: -0.8097, F_vars[i]: 0.3080, Q0_vars[i]: 879.5195\n",
      "f_train: -0.8096636359912373, F_train: 0.30796217746086874, Q0_train: 879.5195262658308\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.26522495544134017, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -0.8336, F_vars[i]: 0.3029, Q0_vars[i]: 865.0413\n",
      "f_train: -0.8335609881340829, F_train: 0.30289264486465384, Q0_train: 865.0412778517746\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 72.67706537401318, Left1: 3.6910013991255255\n",
      "f_vars[i]: -0.8724, F_vars[i]: 0.2948, Q0_vars[i]: 841.8158\n",
      "f_train: -0.8723752701545531, F_train: 0.29476029816972044, Q0_train: 841.8158357811614\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.4351419070092106, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -0.7932, F_vars[i]: 0.3115, Q0_vars[i]: 889.5515\n",
      "f_train: -0.7932331719027953, F_train: 0.3114748666589204, Q0_train: 889.5515333287177\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 15.618625076689796, Left1: 2.413551467104867\n",
      "f_vars[i]: -0.8174, F_vars[i]: 0.3063, Q0_vars[i]: 874.8435\n",
      "f_train: -0.8173575307492139, F_train: 0.3063248704924017, Q0_train: 874.8434863016672\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 21.04630347741471, Lost1: 0.0, Left0: 0.0, Left1: 28.243486925168895\n",
      "f_vars[i]: -0.8078, F_vars[i]: 0.3084, Q0_vars[i]: 880.6325\n",
      "f_train: -0.8078356498616128, F_train: 0.3083518972602533, Q0_train: 880.6325401305762\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=3 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xc90c97b0\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 2e+03]\n",
      "Presolve removed 52 rows and 65 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 241 rows, 199 columns, 647 nonzeros\n",
      "Presolved model has 62 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 137 continuous, 62 integer (62 binary)\n",
      "\n",
      "Root relaxation: objective 2.539194e+07, 104 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5392e+07    0   27          - 2.5392e+07      -     -    0s\n",
      "H    0     0                    2.361692e+07 2.5392e+07  7.52%     -    0s\n",
      "     0     2 2.5392e+07    0   24 2.3617e+07 2.5392e+07  7.52%     -    0s\n",
      "H    9     8                    2.489699e+07 2.5390e+07  1.98%   1.8    0s\n",
      "H   36    38                    2.489699e+07 2.5389e+07  1.97%   8.0    0s\n",
      "H   74    68                    2.535666e+07 2.5388e+07  0.12%   6.6    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 5\n",
      "\n",
      "Explored 93 nodes (755 simplex iterations) in 0.03 seconds (0.03 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 4: 2.53567e+07 2.4897e+07 2.4897e+07 2.36169e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.535666184250e+07, best bound 2.538784802657e+07, gap 0.1230%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1.7423521889034261, Left1: 1.689478064302905\n",
      "f_vars[i]: -0.4238, F_vars[i]: 0.3956, Q0_vars[i]: 1129.8436\n",
      "f_train: -0.4237795124487773, F_train: 0.39561270066634363, Q0_train: 1129.8435994433787\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.7965952452939622, Left1: 4.821362451091578\n",
      "f_vars[i]: -0.4330, F_vars[i]: 0.3934, Q0_vars[i]: 1123.5360\n",
      "f_train: -0.43302550969091613, F_train: 0.3934040996881462, Q0_train: 1123.5359817285334\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.8577912144478432, Left0: 17.204999793589177, Left1: 0.0\n",
      "f_vars[i]: -0.4014, F_vars[i]: 0.4010, Q0_vars[i]: 1145.1288\n",
      "f_train: -0.40144683628825706, F_train: 0.4009647716100944, Q0_train: 1145.128758613897\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 8.150148062594791, Left1: 3.8131884187810208\n",
      "f_vars[i]: -0.4081, F_vars[i]: 0.3994, Q0_vars[i]: 1140.5530\n",
      "f_train: -0.40812177321406473, F_train: 0.39936257009327103, Q0_train: 1140.552977488184\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 11.54146729874531, Left1: 6.410200437849134\n",
      "f_vars[i]: -0.4750, F_vars[i]: 0.3834, Q0_vars[i]: 1095.0491\n",
      "f_train: -0.4750170240611684, F_train: 0.3834294707900621, Q0_train: 1095.049104036434\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.7720833550229145, Left0: 9.528169538898698, Left1: 0.0\n",
      "f_vars[i]: -0.3398, F_vars[i]: 0.4159, Q0_vars[i]: 1187.6880\n",
      "f_train: -0.33976398603849756, F_train: 0.4158668088165124, Q0_train: 1187.687987192705\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 1.3892544946293128\n",
      "f_vars[i]: -0.5013, F_vars[i]: 0.3772, Q0_vars[i]: 1077.3406\n",
      "f_train: -0.5013269285821393, F_train: 0.37722888636428364, Q0_train: 1077.3406467132131\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 8.244358316867874, Left0: 0.45178284005530245, Left1: 0.0\n",
      "f_vars[i]: -0.4763, F_vars[i]: 0.3831, Q0_vars[i]: 1094.2145\n",
      "f_train: -0.47625330971500124, F_train: 0.3831372410287377, Q0_train: 1094.2145152458236\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.441684055039726, Left1: 6.8095440614731615\n",
      "f_vars[i]: -0.3400, F_vars[i]: 0.4158, Q0_vars[i]: 1187.5419\n",
      "f_train: -0.3399746115021567, F_train: 0.41581564424744166, Q0_train: 1187.54186458141\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.1637465616656755, Left0: 4.018326786193496, Left1: 0.0\n",
      "f_vars[i]: -0.3718, F_vars[i]: 0.4081, Q0_vars[i]: 1165.5483\n",
      "f_train: -0.37176487236986544, F_train: 0.40811463511679075, Q0_train: 1165.5482939481474\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.26522452100582955, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -0.3940, F_vars[i]: 0.4028, Q0_vars[i]: 1150.2357\n",
      "f_train: -0.3940074549680126, F_train: 0.40275296088390306, Q0_train: 1150.2357084216333\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 8.45930608160535, Left1: 3.691001444577809\n",
      "f_vars[i]: -0.5686, F_vars[i]: 0.3616, Q0_vars[i]: 1032.6094\n",
      "f_train: -0.5685722821935666, F_train: 0.3615663285075837, Q0_train: 1032.6094216653375\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.43514184545324497, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -0.3429, F_vars[i]: 0.4151, Q0_vars[i]: 1185.5257\n",
      "f_train: -0.3428815861511143, F_train: 0.4151096755943247, Q0_train: 1185.5256649933067\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 2.831490205266965, Left1: 2.413551206114107\n",
      "f_vars[i]: -0.3976, F_vars[i]: 0.4019, Q0_vars[i]: 1147.7684\n",
      "f_train: -0.39760024397686555, F_train: 0.40188904336105635, Q0_train: 1147.7684173513737\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.666494391596925, Left1: 7.197183336380476\n",
      "f_vars[i]: -0.3116, F_vars[i]: 0.4227, Q0_vars[i]: 1207.2877\n",
      "f_train: -0.31157801870617674, F_train: 0.4227296092081473, Q0_train: 1207.2876893349417\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=4 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x64029659\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 1e+03]\n",
      "Presolve removed 56 rows and 73 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 237 rows, 191 columns, 639 nonzeros\n",
      "Presolved model has 58 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 133 continuous, 58 integer (58 binary)\n",
      "\n",
      "Root relaxation: objective 2.540358e+07, 95 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5404e+07    0   25          - 2.5404e+07      -     -    0s\n",
      "H    0     0                    2.483526e+07 2.5404e+07  2.29%     -    0s\n",
      "     0     2 2.5404e+07    0   22 2.4835e+07 2.5404e+07  2.29%     -    0s\n",
      "H   33    32                    2.483526e+07 2.5401e+07  2.28%  13.0    0s\n",
      "H   69    55                    2.532089e+07 2.5401e+07  0.32%   8.8    0s\n",
      "H   70    55                    2.535289e+07 2.5401e+07  0.19%   8.6    0s\n",
      "H   86    55                    2.535765e+07 2.5401e+07  0.17%   8.0    0s\n",
      "H   88    55                    2.536047e+07 2.5401e+07  0.16%   7.9    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 9\n",
      "\n",
      "Explored 93 nodes (808 simplex iterations) in 0.04 seconds (0.03 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 6: 2.53605e+07 2.53576e+07 2.53529e+07 ... 2.48353e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.536046510641e+07, best bound 2.540086163672e+07, gap 0.1593%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.044270626615343645, Left0: 1.5551930550016095, Left1: 0.0\n",
      "f_vars[i]: -0.0299, F_vars[i]: 0.4925, Q0_vars[i]: 1406.5881\n",
      "f_train: -0.02994513100064644, F_train: 0.4925142766189395, Q0_train: 1406.5880648804334\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1.314470559241954, Left1: 3.9735896354927718\n",
      "f_vars[i]: -0.0377, F_vars[i]: 0.4906, Q0_vars[i]: 1401.0738\n",
      "f_train: -0.037670637383447225, F_train: 0.49058345419470406, Q0_train: 1401.0737642677136\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 12.256071376458749, Left1: 0.2542948950626851\n",
      "f_vars[i]: -0.0054, F_vars[i]: 0.4987, Q0_vars[i]: 1424.1466\n",
      "f_train: -0.0053505744110315945, F_train: 0.4986623595884768, Q0_train: 1424.1465815313868\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.55430382009463, Left1: 1.4142064545967514\n",
      "f_vars[i]: -0.0080, F_vars[i]: 0.4980, Q0_vars[i]: 1422.2203\n",
      "f_train: -0.008048488865982417, F_train: 0.4979878886452341, Q0_train: 1422.2203373108403\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 11.458920189726769, Left1: 2.2199238035420876\n",
      "f_vars[i]: -0.0907, F_vars[i]: 0.4773, Q0_vars[i]: 1363.2246\n",
      "f_train: -0.09073967297565577, F_train: 0.4773306339963847, Q0_train: 1363.2245899352806\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 10.310771817111522, Left1: 1.208751934558677\n",
      "f_vars[i]: 0.0815, F_vars[i]: 0.5204, Q0_vars[i]: 1486.1070\n",
      "f_train: 0.08147580098721852, F_train: 0.5203576897778212, Q0_train: 1486.1070037093261\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 1.0641162352530955\n",
      "f_vars[i]: -0.1172, F_vars[i]: 0.4707, Q0_vars[i]: 1344.4022\n",
      "f_train: -0.1171738815569503, F_train: 0.4707399995834241, Q0_train: 1344.4021757528933\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.022285338199907, Lost1: 5.775496615093516, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -0.0900, F_vars[i]: 0.4775, Q0_vars[i]: 1363.7479\n",
      "f_train: -0.09000525564589079, F_train: 0.4775138639539651, Q0_train: 1363.7478825253563\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 11.176598692590892, Left1: 7.57986390964993\n",
      "f_vars[i]: 0.0802, F_vars[i]: 0.5200, Q0_vars[i]: 1485.1782\n",
      "f_train: 0.08017279604745342, F_train: 0.5200324699736046, Q0_train: 1485.1781975471697\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 5.026929325021456, Left0: 11.264008407266308, Left1: 0.0\n",
      "f_vars[i]: 0.0460, F_vars[i]: 0.5115, Q0_vars[i]: 1460.7738\n",
      "f_train: 0.045957364730821126, F_train: 0.5114873194096753, Q0_train: 1460.7738150420735\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 2.601641160733152\n",
      "f_vars[i]: 0.0108, F_vars[i]: 0.5027, Q0_vars[i]: 1435.6669\n",
      "f_train: 0.01078481022265354, F_train: 0.5026961764225452, Q0_train: 1435.6668945133072\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 3.9287458972503373\n",
      "f_vars[i]: -0.2124, F_vars[i]: 0.4471, Q0_vars[i]: 1276.9035\n",
      "f_train: -0.21237281761989601, F_train: 0.4471054514154814, Q0_train: 1276.903475816544\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.7437060145430223, Left0: 9.369774183822505, Left1: 0.0\n",
      "f_vars[i]: 0.0864, F_vars[i]: 0.5216, Q0_vars[i]: 1489.6446\n",
      "f_train: 0.08643926956538461, F_train: 0.5215963721792425, Q0_train: 1489.6445983836927\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 8.59984712088383, Left1: 0.6543544472428948\n",
      "f_vars[i]: 0.0122, F_vars[i]: 0.5031, Q0_vars[i]: 1436.7038\n",
      "f_train: 0.01223718867184953, F_train: 0.5030592589913642, Q0_train: 1436.7038342166045\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 14.131323021803258, Left1: 2.0456162854748072\n",
      "f_vars[i]: 0.1188, F_vars[i]: 0.5297, Q0_vars[i]: 1512.6812\n",
      "f_train: 0.11878988395799528, F_train: 0.5296625983560724, Q0_train: 1512.6812046458365\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=5 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xf0ec38b8\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 2e+03]\n",
      "Presolve removed 56 rows and 73 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 237 rows, 191 columns, 639 nonzeros\n",
      "Presolved model has 58 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 133 continuous, 58 integer (58 binary)\n",
      "\n",
      "Root relaxation: objective 2.540358e+07, 95 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5404e+07    0   25          - 2.5404e+07      -     -    0s\n",
      "H    0     0                    1.898036e+07 2.5404e+07  33.8%     -    0s\n",
      "     0     2 2.5404e+07    0   22 1.8980e+07 2.5404e+07  33.8%     -    0s\n",
      "H    9     8                    2.174246e+07 2.5402e+07  16.8%   1.8    0s\n",
      "H   70    68                    2.535152e+07 2.5401e+07  0.19%   2.8    0s\n",
      "H   86    68                    2.536316e+07 2.5401e+07  0.15%   2.7    0s\n",
      "H   92    68                    2.536430e+07 2.5401e+07  0.14%   2.6    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 4\n",
      "\n",
      "Explored 93 nodes (333 simplex iterations) in 0.08 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 5: 2.53643e+07 2.53632e+07 2.53515e+07 ... 1.89804e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.536429829810e+07, best bound 2.540086183113e+07, gap 0.1442%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.044270701084769826, Left0: 2.5483635889604557, Left1: 0.0\n",
      "f_vars[i]: 0.3670, F_vars[i]: 0.5907, Q0_vars[i]: 1687.1249\n",
      "f_train: 0.36704078496510384, F_train: 0.5907437346959709, Q0_train: 1687.1248734767996\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1.92551611844965, Left1: 3.973589645122729\n",
      "f_vars[i]: 0.3573, F_vars[i]: 0.5884, Q0_vars[i]: 1680.4011\n",
      "f_train: 0.3573112491020951, F_train: 0.5883894078177072, Q0_train: 1680.4010722693984\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 13.33222912878955, Left1: 0.25429486149232616\n",
      "f_vars[i]: 0.3972, F_vars[i]: 0.5980, Q0_vars[i]: 1707.8828\n",
      "f_train: 0.39718890918400174, F_train: 0.5980120783616643, Q0_train: 1707.882780276573\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 10.002617754750418, Left1: 1.414206508322195\n",
      "f_vars[i]: 0.3934, F_vars[i]: 0.5971, Q0_vars[i]: 1705.2738\n",
      "f_train: 0.39339019976672907, F_train: 0.5970985537816518, Q0_train: 1705.2738147455805\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 12.329472571243969, Left1: 2.2199238678497295\n",
      "f_vars[i]: 0.2930, F_vars[i]: 0.5727, Q0_vars[i]: 1635.6661\n",
      "f_train: 0.29297998391379076, F_train: 0.5727255253037942, Q0_train: 1635.6660640884961\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 8.169172297504705, Left1: 1.2087519381427683\n",
      "f_vars[i]: 0.5016, F_vars[i]: 0.6228, Q0_vars[i]: 1778.7927\n",
      "f_train: 0.5016247220997063, F_train: 0.62284107089077, Q0_train: 1778.7927339822734\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 1.0641161758576345\n",
      "f_vars[i]: 0.2603, F_vars[i]: 0.5647, Q0_vars[i]: 1612.7803\n",
      "f_train: 0.2603084147870809, F_train: 0.5647121054770834, Q0_train: 1612.7802692552866\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.4229605964503662, Lost1: 6.3748213641806615, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 0.2937, F_vars[i]: 0.5729, Q0_vars[i]: 1636.1405\n",
      "f_train: 0.29365880430351243, F_train: 0.5728916319121468, Q0_train: 1636.1404535303827\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.199138997555687, Left1: 7.579863854253517\n",
      "f_vars[i]: 0.5001, F_vars[i]: 0.6225, Q0_vars[i]: 1777.7969\n",
      "f_train: 0.5001406477588226, F_train: 0.6224923833779578, Q0_train: 1777.7969056029185\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 5.026929269582297, Left0: 9.631074763593206, Left1: 0.0\n",
      "f_vars[i]: 0.4581, F_vars[i]: 0.6126, Q0_vars[i]: 1749.4506\n",
      "f_train: 0.45811526227258614, F_train: 0.6125669688385352, Q0_train: 1749.450580850704\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 2.6016412696092175\n",
      "f_vars[i]: 0.4161, F_vars[i]: 0.6026, Q0_vars[i]: 1720.8613\n",
      "f_train: 0.4161286176776411, F_train: 0.602556491954094, Q0_train: 1720.861323690326\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 3.9287458978493532\n",
      "f_vars[i]: 0.1458, F_vars[i]: 0.5364, Q0_vars[i]: 1531.9148\n",
      "f_train: 0.14584683730322645, F_train: 0.5363972141822371, Q0_train: 1531.9148201821579\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.7437060246500096, Left0: 6.028233533303869, Left1: 0.0\n",
      "f_vars[i]: 0.5068, F_vars[i]: 0.6241, Q0_vars[i]: 1782.2772\n",
      "f_train: 0.5068218475528581, F_train: 0.6240611463342195, Q0_train: 1782.2771884204085\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.8719701406432705, Left1: 0.654354382480733\n",
      "f_vars[i]: 0.4173, F_vars[i]: 0.6028, Q0_vars[i]: 1721.6880\n",
      "f_train: 0.41733748815867333, F_train: 0.6028459589526035, Q0_train: 1721.6880222138193\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 10.37050197328958, Left1: 2.045616279306614\n",
      "f_vars[i]: 0.5467, F_vars[i]: 0.6334, Q0_vars[i]: 1808.8627\n",
      "f_train: 0.546701721532505, F_train: 0.6333700271927953, Q0_train: 1808.8627339257166\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=6 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xe84dbc9b\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [8e+02, 2e+03]\n",
      "Presolve removed 53 rows and 91 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 240 rows, 173 columns, 650 nonzeros\n",
      "Presolved model has 37 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 136 continuous, 37 integer (37 binary)\n",
      "\n",
      "Root relaxation: objective 2.540900e+07, 89 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5409e+07    0   20          - 2.5409e+07      -     -    0s\n",
      "H    0     0                    1.223711e+07 2.5409e+07   108%     -    0s\n",
      "     0     2 2.5409e+07    0   20 1.2237e+07 2.5409e+07   108%     -    0s\n",
      "H   55    56                    2.173796e+07 2.5407e+07  16.9%   4.9    0s\n",
      "H   72    72                    2.509978e+07 2.5407e+07  1.22%   4.5    0s\n",
      "H  479   222                    2.535130e+07 2.5407e+07  0.22%   5.5    0s\n",
      "H  489   222                    2.536761e+07 2.5407e+07  0.16%   5.5    0s\n",
      "\n",
      "Explored 567 nodes (2996 simplex iterations) in 0.06 seconds (0.05 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 5: 2.53676e+07 2.53513e+07 2.50998e+07 ... 1.22371e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Warning: max constraint violation (1.5285e-06) exceeds tolerance\n",
      "Best objective 2.536761404879e+07, best bound 2.540694491852e+07, gap 0.1550%\n",
      "Model status: 2\n",
      "Lost0: 1.0975872678472456, Lost1: 0.0, Left0: 0.0, Left1: 3.852612831301883\n",
      "f_vars[i]: 0.7877, F_vars[i]: 0.6873, Q0_vars[i]: 1962.9761\n",
      "f_train: 0.7876779796516375, F_train: 0.6873325304605233, Q0_train: 1962.9760594693416\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 8.15747127220095, Left1: 1.7603474818016593\n",
      "f_vars[i]: 0.7806, F_vars[i]: 0.6858, Q0_vars[i]: 1958.6557\n",
      "f_train: 0.7806481020348484, F_train: 0.6858197779532377, Q0_train: 1958.655738774329\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 3.604562260927062, Left1: 1.3033977922208153\n",
      "f_vars[i]: 0.8192, F_vars[i]: 0.6941, Q0_vars[i]: 1982.2282\n",
      "f_train: 0.8192335291181516, F_train: 0.6940736153959218, Q0_train: 1982.2281503520044\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.19354760015891, Left1: 0.9206417650101353\n",
      "f_vars[i]: 0.8212, F_vars[i]: 0.6945, Q0_vars[i]: 1983.4386\n",
      "f_train: 0.8212304346376293, F_train: 0.6944974647894093, Q0_train: 1983.4386360708734\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 14.447266869500027, Left1: 2.951072865084143\n",
      "f_vars[i]: 0.7046, F_vars[i]: 0.6692, Q0_vars[i]: 1911.1808\n",
      "f_train: 0.7045531965858594, F_train: 0.6691965002472907, Q0_train: 1911.1807616408867\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.28398810024060595, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 0.9528, F_vars[i]: 0.7217, Q0_vars[i]: 2061.0649\n",
      "f_train: 0.95280108101753, F_train: 0.7216781489921037, Q0_train: 2061.0648650144344\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 14.54661797299525, Left1: 0.3803585621859611\n",
      "f_vars[i]: 0.6736, F_vars[i]: 0.6623, Q0_vars[i]: 1891.5210\n",
      "f_train: 0.6736173991749497, F_train: 0.6623126815727037, Q0_train: 1891.5210326784172\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.7670031726120214, Left0: 5.501912956215163, Left1: 0.0\n",
      "f_vars[i]: 0.7080, F_vars[i]: 0.6699, Q0_vars[i]: 1913.3297\n",
      "f_train: 0.7079541475178357, F_train: 0.6699489437051135, Q0_train: 1913.3296901847182\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 3.1662774761463197, Lost1: 0.0, Left0: 0.0, Left1: 9.887902856052829\n",
      "f_vars[i]: 0.9499, F_vars[i]: 0.7211, Q0_vars[i]: 2059.3840\n",
      "f_train: 0.9498728654500632, F_train: 0.7210896095191404, Q0_train: 2059.3840353660753\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.5674106742207528, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 0.9069, F_vars[i]: 0.7124, Q0_vars[i]: 2034.4715\n",
      "f_train: 0.906905557421009, F_train: 0.7123665269530813, Q0_train: 2034.4714908798198\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.4955650748287326, Lost1: 0.0, Left0: 0.0, Left1: 3.3151568033743617\n",
      "f_vars[i]: 0.8493, F_vars[i]: 0.7004, Q0_vars[i]: 2000.3256\n",
      "f_train: 0.849252917530388, F_train: 0.7004104013977106, Q0_train: 2000.325590330813\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 8.395986537704061, Left1: 2.0935091230876424\n",
      "f_vars[i]: 0.5267, F_vars[i]: 0.6287, Q0_vars[i]: 1795.5443\n",
      "f_train: 0.5266720719304177, F_train: 0.6287065916862393, Q0_train: 1795.544271829771\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.3319747420901535, Lost1: 0.0, Left0: 0.0, Left1: 1.664436137260124\n",
      "f_vars[i]: 0.9690, F_vars[i]: 0.7249, Q0_vars[i]: 2070.3348\n",
      "f_train: 0.9690194845258606, F_train: 0.7249240171240106, Q0_train: 2070.334848832687\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.6519827042103543, Left0: 7.9716679073427485, Left1: 0.0\n",
      "f_vars[i]: 0.8575, F_vars[i]: 0.7021, Q0_vars[i]: 2005.2368\n",
      "f_train: 0.8574615973856385, F_train: 0.7021300366069886, Q0_train: 2005.2367542831018\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.2894128340340103, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 1.0080, F_vars[i]: 0.7326, Q0_vars[i]: 2092.3583\n",
      "f_train: 1.0080353553656085, F_train: 0.7326354891463832, Q0_train: 2092.358300789839\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=7 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xd3f70659\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [5e+02, 2e+03]\n",
      "Presolve removed 53 rows and 90 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 240 rows, 174 columns, 639 nonzeros\n",
      "Presolved model has 38 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 136 continuous, 38 integer (38 binary)\n",
      "Found heuristic solution: objective 2.524514e+07\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.52451e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.524514127959e+07, best bound 2.542797509868e+07, gap 0.7242%\n",
      "Model status: 2\n",
      "Lost0: 10.014793751860907, Lost1: 0.0, Left0: 0.0, Left1: 10.014794055471384\n",
      "f_vars[i]: 1.2735, F_vars[i]: 0.7813, Q0_vars[i]: 2231.4617\n",
      "f_train: 1.2735057752192374, F_train: 0.7813422881235575, Q0_train: 2231.4616839245186\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.19434734856668, Lost1: 0.0, Left0: 0.0, Left1: 2.194347591066048\n",
      "f_vars[i]: 1.2639, F_vars[i]: 0.7797, Q0_vars[i]: 2226.7661\n",
      "f_train: 1.2639080959099358, F_train: 0.7796981310568509, Q0_train: 2226.7660805347155\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 8.019705899363451, Lost1: 0.0, Left0: 0.0, Left1: 8.019706174674411\n",
      "f_vars[i]: 1.3230, F_vars[i]: 0.7897, Q0_vars[i]: 2255.2734\n",
      "f_train: 1.3229970866771303, F_train: 0.7896799114746096, Q0_train: 2255.2733824920547\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.2548893336885874e-06, Lost1: 0.0, Left0: 0.0, Left1: 1.4747593013453297e-06\n",
      "f_vars[i]: 1.3288, F_vars[i]: 0.7906, Q0_vars[i]: 2258.0369\n",
      "f_train: 1.3288332138194239, F_train: 0.7906475691772322, Q0_train: 2258.036948626101\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.8983678273798432e-06, Lost1: 0.0, Left0: 0.0, Left1: 2.1154513092369598e-06\n",
      "f_vars[i]: 1.1406, F_vars[i]: 0.7578, Q0_vars[i]: 2164.1950\n",
      "f_train: 1.1405956301493223, F_train: 0.7577889806308682, Q0_train: 2164.19500196129\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 8.02143225400214, Lost1: 0.0, Left0: 0.0, Left1: 8.021432500755328\n",
      "f_vars[i]: 1.5435, F_vars[i]: 0.8240, Q0_vars[i]: 2353.1973\n",
      "f_train: 1.5434645320255003, F_train: 0.8239678019434487, Q0_train: 2353.197320523828\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 7.374830386837213, Lost1: 0.0, Left0: 0.0, Left1: 7.374830675329463\n",
      "f_vars[i]: 1.0936, F_vars[i]: 0.7491, Q0_vars[i]: 2139.2374\n",
      "f_train: 1.0935527217199956, F_train: 0.7490501317430419, Q0_train: 2139.23742990715\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 19.10624018125054, Lost1: 0.0, Left0: 0.0, Left1: 19.10624044143026\n",
      "f_vars[i]: 1.1471, F_vars[i]: 0.7590, Q0_vars[i]: 2167.6237\n",
      "f_train: 1.1471477127000993, F_train: 0.7589895494625019, Q0_train: 2167.6237468115637\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.9516384752103686, Lost1: 0.0, Left0: 0.0, Left1: 0.951638760791705\n",
      "f_vars[i]: 1.5382, F_vars[i]: 0.8232, Q0_vars[i]: 2351.0334\n",
      "f_train: 1.5382495004756453, F_train: 0.8232101100001037, Q0_train: 2351.0334026539103\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 5.00089999272268, Lost1: 0.0, Left0: 0.0, Left1: 5.00090021878683\n",
      "f_vars[i]: 1.4713, F_vars[i]: 0.8133, Q0_vars[i]: 2322.6115\n",
      "f_train: 1.471321922405397, F_train: 0.81325822857909, Q0_train: 2322.6114902456056\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 9.03290474494483, Lost1: 0.0, Left0: 0.0, Left1: 9.032904927264866\n",
      "f_vars[i]: 1.3747, F_vars[i]: 0.7981, Q0_vars[i]: 2279.4281\n",
      "f_train: 1.374695036554698, F_train: 0.7981376483438661, Q0_train: 2279.428117290534\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 40.103057717502644, Lost1: 0.0, Left0: 0.0, Left1: 40.10305796655007\n",
      "f_vars[i]: 0.8508, F_vars[i]: 0.7007, Q0_vars[i]: 2001.2513\n",
      "f_train: 0.8507980533747093, F_train: 0.7007345255812077, Q0_train: 2001.2512674729578\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.40013623403623, Lost1: 0.0, Left0: 0.0, Left1: 2.400136497735579\n",
      "f_vars[i]: 1.5738, F_vars[i]: 0.8283, Q0_vars[i]: 2365.6326\n",
      "f_train: 1.573781215115587, F_train: 0.8283219824623304, Q0_train: 2365.6325709133966\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.0887470125453547e-06, Lost1: 0.0, Left0: 0.0, Left1: 1.3741884004048188e-06\n",
      "f_vars[i]: 1.3907, F_vars[i]: 0.8007, Q0_vars[i]: 2286.7633\n",
      "f_train: 1.3907129803011866, F_train: 0.8007060420010472, Q0_train: 2286.763279001797\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.0509214115930603, Lost1: 0.0, Left0: 0.0, Left1: 2.0509216658473064\n",
      "f_vars[i]: 1.6337, F_vars[i]: 0.8367, Q0_vars[i]: 2389.5060\n",
      "f_train: 1.6337391391027172, F_train: 0.8366812196993645, Q0_train: 2389.5059973038633\n",
      "f_train, F_train, Q0_train 都相等\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R(T)</th>\n",
       "      <th>R</th>\n",
       "      <th>average_profits</th>\n",
       "      <th>average_losses</th>\n",
       "      <th>average_lefts</th>\n",
       "      <th>average_operation_profits</th>\n",
       "      <th>alpha_values</th>\n",
       "      <th>F_vars</th>\n",
       "      <th>f_vars</th>\n",
       "      <th>Q0_vars</th>\n",
       "      <th>Q1_vars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]</td>\n",
       "      <td>1.691174e+06</td>\n",
       "      <td>1.176747</td>\n",
       "      <td>6.529898</td>\n",
       "      <td>1.694492e+06</td>\n",
       "      <td>[-0.0016573616512193699, 0.0, 0.01073942902038...</td>\n",
       "      <td>[0.6873325304605234, 0.6858197779532377, 0.694...</td>\n",
       "      <td>[0.787677979651638, 0.7806481020348484, 0.8192...</td>\n",
       "      <td>[1962.9760594693419, 1958.655738774329, 1982.2...</td>\n",
       "      <td>[840.3427232265767, 829.4975769467967, 847.688...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1.691063e+06</td>\n",
       "      <td>1.370741</td>\n",
       "      <td>6.225277</td>\n",
       "      <td>1.694376e+06</td>\n",
       "      <td>[0.0014891215553074011, 0.0, 0.003640698049256...</td>\n",
       "      <td>[0.19787965847949968, 0.19713795973656162, 0.1...</td>\n",
       "      <td>[-1.399599587920067, -1.4042791069146987, -1.3...</td>\n",
       "      <td>[565.1311629190186, 563.0129205673138, 571.076...</td>\n",
       "      <td>[2236.7646208695537, 2227.5597314676547, 2254....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]</td>\n",
       "      <td>1.690953e+06</td>\n",
       "      <td>0.907513</td>\n",
       "      <td>7.890226</td>\n",
       "      <td>1.694654e+06</td>\n",
       "      <td>[0.002121765763254438, 0.0, 0.0088882264986746...</td>\n",
       "      <td>[0.5907437346959723, 0.5883894078177092, 0.598...</td>\n",
       "      <td>[0.36704078496510384, 0.3573112491020951, 0.39...</td>\n",
       "      <td>[1687.124873476804, 1680.401072269404, 1707.88...</td>\n",
       "      <td>[1113.3946129545789, 1109.9654856150403, 1120....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]</td>\n",
       "      <td>1.690698e+06</td>\n",
       "      <td>0.907513</td>\n",
       "      <td>8.529092</td>\n",
       "      <td>1.694654e+06</td>\n",
       "      <td>[0.0014705272072909157, 0.0, 0.007347365814852...</td>\n",
       "      <td>[0.4925142766189404, 0.4905834541947054, 0.498...</td>\n",
       "      <td>[-0.02994513100064639, -0.03767063738344742, -...</td>\n",
       "      <td>[1406.5880648804361, 1401.0737642677175, 1424....</td>\n",
       "      <td>[1393.9314216254159, 1389.292793607097, 1404.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]</td>\n",
       "      <td>1.690444e+06</td>\n",
       "      <td>1.382556</td>\n",
       "      <td>7.737839</td>\n",
       "      <td>1.694369e+06</td>\n",
       "      <td>[0.004078629892319441, 0.0, 0.0056556674535386...</td>\n",
       "      <td>[0.39561270033847323, 0.3934040993676069, 0.40...</td>\n",
       "      <td>[-0.4237795138200308, -0.4330255110341269, -0....</td>\n",
       "      <td>[1129.8435985070025, 1123.5359808130945, 1145....</td>\n",
       "      <td>[1672.4096366897677, 1667.6783498773186, 1679....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]</td>\n",
       "      <td>1.683009e+06</td>\n",
       "      <td>7.618061</td>\n",
       "      <td>7.618061</td>\n",
       "      <td>1.690628e+06</td>\n",
       "      <td>[-0.004355199039511223, 0.0, 0.017493838761694...</td>\n",
       "      <td>[0.7813422892899958, 0.7796981364740222, 0.789...</td>\n",
       "      <td>[1.273505775505294, 1.2639080976497397, 1.3229...</td>\n",
       "      <td>[2231.461687255789, 2226.766096005797, 2255.27...</td>\n",
       "      <td>[569.1020701802887, 559.6268724760239, 573.339...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>1.680908e+06</td>\n",
       "      <td>3.891989</td>\n",
       "      <td>24.050687</td>\n",
       "      <td>1.692863e+06</td>\n",
       "      <td>[-0.00962156310179257, 0.0, 0.0015875954694073...</td>\n",
       "      <td>[0.2999174082545109, 0.30190728744437584, 0.29...</td>\n",
       "      <td>[-0.8476911853568848, -0.838231944927809, -0.8...</td>\n",
       "      <td>[856.5441996863425, 862.2271624995881, 852.856...</td>\n",
       "      <td>[1945.7090358638102, 1928.9871681374527, 1971....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>1.680832e+06</td>\n",
       "      <td>6.355325</td>\n",
       "      <td>16.849070</td>\n",
       "      <td>1.691385e+06</td>\n",
       "      <td>[0.003561687935941336, 0.0, 0.0019955418438969...</td>\n",
       "      <td>[0.10084150994460041, 0.1003313659471484, 0.10...</td>\n",
       "      <td>[-2.1879092390044566, -2.193548143753756, -2.1...</td>\n",
       "      <td>[287.9966552570427, 286.5397178802982, 290.682...</td>\n",
       "      <td>[2549.547240902869, 2517.5120895914115, 2513.9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R(T)                                              R  average_profits  \\\n",
       "6     8  [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]     1.691174e+06   \n",
       "1     3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]     1.691063e+06   \n",
       "5     7  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]     1.690953e+06   \n",
       "4     6  [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]     1.690698e+06   \n",
       "3     5  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]     1.690444e+06   \n",
       "7     9  [7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]     1.683009e+06   \n",
       "2     4  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]     1.680908e+06   \n",
       "0     2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]     1.680832e+06   \n",
       "\n",
       "   average_losses  average_lefts  average_operation_profits  \\\n",
       "6        1.176747       6.529898               1.694492e+06   \n",
       "1        1.370741       6.225277               1.694376e+06   \n",
       "5        0.907513       7.890226               1.694654e+06   \n",
       "4        0.907513       8.529092               1.694654e+06   \n",
       "3        1.382556       7.737839               1.694369e+06   \n",
       "7        7.618061       7.618061               1.690628e+06   \n",
       "2        3.891989      24.050687               1.692863e+06   \n",
       "0        6.355325      16.849070               1.691385e+06   \n",
       "\n",
       "                                        alpha_values  \\\n",
       "6  [-0.0016573616512193699, 0.0, 0.01073942902038...   \n",
       "1  [0.0014891215553074011, 0.0, 0.003640698049256...   \n",
       "5  [0.002121765763254438, 0.0, 0.0088882264986746...   \n",
       "4  [0.0014705272072909157, 0.0, 0.007347365814852...   \n",
       "3  [0.004078629892319441, 0.0, 0.0056556674535386...   \n",
       "7  [-0.004355199039511223, 0.0, 0.017493838761694...   \n",
       "2  [-0.00962156310179257, 0.0, 0.0015875954694073...   \n",
       "0  [0.003561687935941336, 0.0, 0.0019955418438969...   \n",
       "\n",
       "                                              F_vars  \\\n",
       "6  [0.6873325304605234, 0.6858197779532377, 0.694...   \n",
       "1  [0.19787965847949968, 0.19713795973656162, 0.1...   \n",
       "5  [0.5907437346959723, 0.5883894078177092, 0.598...   \n",
       "4  [0.4925142766189404, 0.4905834541947054, 0.498...   \n",
       "3  [0.39561270033847323, 0.3934040993676069, 0.40...   \n",
       "7  [0.7813422892899958, 0.7796981364740222, 0.789...   \n",
       "2  [0.2999174082545109, 0.30190728744437584, 0.29...   \n",
       "0  [0.10084150994460041, 0.1003313659471484, 0.10...   \n",
       "\n",
       "                                              f_vars  \\\n",
       "6  [0.787677979651638, 0.7806481020348484, 0.8192...   \n",
       "1  [-1.399599587920067, -1.4042791069146987, -1.3...   \n",
       "5  [0.36704078496510384, 0.3573112491020951, 0.39...   \n",
       "4  [-0.02994513100064639, -0.03767063738344742, -...   \n",
       "3  [-0.4237795138200308, -0.4330255110341269, -0....   \n",
       "7  [1.273505775505294, 1.2639080976497397, 1.3229...   \n",
       "2  [-0.8476911853568848, -0.838231944927809, -0.8...   \n",
       "0  [-2.1879092390044566, -2.193548143753756, -2.1...   \n",
       "\n",
       "                                             Q0_vars  \\\n",
       "6  [1962.9760594693419, 1958.655738774329, 1982.2...   \n",
       "1  [565.1311629190186, 563.0129205673138, 571.076...   \n",
       "5  [1687.124873476804, 1680.401072269404, 1707.88...   \n",
       "4  [1406.5880648804361, 1401.0737642677175, 1424....   \n",
       "3  [1129.8435985070025, 1123.5359808130945, 1145....   \n",
       "7  [2231.461687255789, 2226.766096005797, 2255.27...   \n",
       "2  [856.5441996863425, 862.2271624995881, 852.856...   \n",
       "0  [287.9966552570427, 286.5397178802982, 290.682...   \n",
       "\n",
       "                                             Q1_vars  \n",
       "6  [840.3427232265767, 829.4975769467967, 847.688...  \n",
       "1  [2236.7646208695537, 2227.5597314676547, 2254....  \n",
       "5  [1113.3946129545789, 1109.9654856150403, 1120....  \n",
       "4  [1393.9314216254159, 1389.292793607097, 1404.7...  \n",
       "3  [1672.4096366897677, 1667.6783498773186, 1679....  \n",
       "7  [569.1020701802887, 559.6268724760239, 573.339...  \n",
       "2  [1945.7090358638102, 1928.9871681374527, 1971....  \n",
       "0  [2549.547240902869, 2517.5120895914115, 2513.9...  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_2, stimulation_results_df_2 = None, None\n",
    "results_df_2, stimulation_results_df_2 = grid_flexible_F_fixed_R(\n",
    "    assigned_Ts=ASSIGNED_TS,\n",
    "    salvage_value=salvage_value,\n",
    "    cost=cost,\n",
    "    price=price,\n",
    "    Q_star=Q_star,\n",
    "    demand_df_train=demand_df_train,\n",
    "    Qk_hat_df_train=Qk_hat_df_train,\n",
    "    training_df=training_df,\n",
    ")\n",
    "\n",
    "results_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++++++++++++++++++++++ THis is R=0 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 481 nonzeros\n",
      "Model fingerprint: 0x3b4c75e5\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 7e+02]\n",
      "  GenCon const rng [6e+01, 6e+02]\n",
      "Presolve removed 46 rows and 84 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 247 rows, 180 columns, 675 nonzeros\n",
      "Presolved model has 37 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 143 continuous, 37 integer (37 binary)\n",
      "Found heuristic solution: objective 1872352.5875\n",
      "\n",
      "Root relaxation: objective 5.677591e+06, 95 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5677590.52    0   21 1872352.59 5677590.52   203%     -    0s\n",
      "     0     2 5677590.52    0   21 1872352.59 5677590.52   203%     -    0s\n",
      "H  551   266                    2418574.6180 5566444.15   130%   4.3    0s\n",
      "H 1102   396                    5529496.3613 5566444.15  0.67%   3.1    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 9\n",
      "\n",
      "Explored 1203 nodes (3549 simplex iterations) in 0.06 seconds (0.07 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 3: 5.5295e+06 2.41857e+06 1.87235e+06 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 5.529496361296e+06, best bound 5.566444152036e+06, gap 0.6682%\n",
      "Model status: 2\n",
      "Lost0: 0.685144301618152, Lost1: 19.027070598108025, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -3.7607, F_vars[i]: 0.0227, Q0_vars[i]: 64.9408\n",
      "f_train: -3.7606768319456156, F_train: 0.022738898151707508, Q0_train: 64.94078297240894\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 6.866804110662088, Left1: 22.766769280235053\n",
      "f_vars[i]: -3.7190, F_vars[i]: 0.0237, Q0_vars[i]: 67.6369\n",
      "f_train: -3.7190322977901937, F_train: 0.02368294311480143, Q0_train: 67.63691269054458\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 3.100149986444137, Left1: 29.690421215899278\n",
      "f_vars[i]: -3.6960, F_vars[i]: 0.0242, Q0_vars[i]: 69.1737\n",
      "f_train: -3.6960144332818805, F_train: 0.024221039412677232, Q0_train: 69.17367998091503\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 23.38213602437304, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -3.7897, F_vars[i]: 0.0221, Q0_vars[i]: 63.1214\n",
      "f_train: -3.789744669544647, F_train: 0.022101840026202236, Q0_train: 63.121387274638906\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 6.232886100787113, Left1: 35.83994015892563\n",
      "f_vars[i]: -3.6672, F_vars[i]: 0.0249, Q0_vars[i]: 71.1480\n",
      "f_train: -3.667164255327781, F_train: 0.024912336508826644, Q0_train: 71.1479785766948\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 2.7067011329625075, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -3.7848, F_vars[i]: 0.0222, Q0_vars[i]: 63.4276\n",
      "f_train: -3.784794791141196, F_train: 0.022209076928116737, Q0_train: 63.42764874462751\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.218660484596967, Left1: 20.001707302584236\n",
      "f_vars[i]: -3.7187, F_vars[i]: 0.0237, Q0_vars[i]: 67.6571\n",
      "f_train: -3.7187262307225266, F_train: 0.023690021048109133, Q0_train: 67.65712679800757\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.359761562643989, Left1: 13.024443359858878\n",
      "f_vars[i]: -3.7147, F_vars[i]: 0.0238, Q0_vars[i]: 67.9242\n",
      "f_train: -3.71469096702551, F_train: 0.023783531474599204, Q0_train: 67.92418636579464\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 10.32999546847168, Left1: 16.161930412874653\n",
      "f_vars[i]: -3.6746, F_vars[i]: 0.0247, Q0_vars[i]: 70.6309\n",
      "f_train: -3.674644789250646, F_train: 0.024731265886129967, Q0_train: 70.6308529036401\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.9738357534513256, Lost1: 0.0, Left0: 0.0, Left1: 5.243425897344196\n",
      "f_vars[i]: -3.7445, F_vars[i]: 0.0231, Q0_vars[i]: 65.9736\n",
      "f_train: -3.7445282927075043, F_train: 0.023100527662775094, Q0_train: 65.97357283926952\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1.1379378263305853, Left1: 41.193652477815135\n",
      "f_vars[i]: -3.7305, F_vars[i]: 0.0234, Q0_vars[i]: 66.8849\n",
      "f_train: -3.7304830897098853, F_train: 0.02341961631815187, Q0_train: 66.88486884752508\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 8.981967182898742, Left0: 6.067736002259167, Left1: 0.0\n",
      "f_vars[i]: -3.7227, F_vars[i]: 0.0236, Q0_vars[i]: 67.3972\n",
      "f_train: -3.7226681255079748, F_train: 0.023599020713192576, Q0_train: 67.39723588505281\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 5.934017810260116, Lost1: 8.619374749073586, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -3.8266, F_vars[i]: 0.0213, Q0_vars[i]: 60.8888\n",
      "f_train: -3.826554965626433, F_train: 0.021320086801052684, Q0_train: 60.888751981859535\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.7543057410596603, Lost1: 34.08731352841767, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -3.8110, F_vars[i]: 0.0216, Q0_vars[i]: 61.8233\n",
      "f_train: -3.810989290304729, F_train: 0.0216473045176093, Q0_train: 61.8232640489728\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.491383946263078, Left1: 7.649614041557925\n",
      "f_vars[i]: -3.7323, F_vars[i]: 0.0234, Q0_vars[i]: 66.7688\n",
      "f_train: -3.73226171629808, F_train: 0.023378971567783898, Q0_train: 66.76879013979685\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=1 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 481 nonzeros\n",
      "Model fingerprint: 0x6e3286db\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 7e+02]\n",
      "  GenCon const rng [1e+02, 6e+02]\n",
      "Presolve removed 34 rows and 67 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 259 rows, 197 columns, 723 nonzeros\n",
      "Presolved model has 43 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 154 continuous, 43 integer (43 binary)\n",
      "Found heuristic solution: objective 2361838.6191\n",
      "\n",
      "Root relaxation: objective 5.727013e+06, 95 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5727012.93    0   21 2361838.62 5727012.93   142%     -    0s\n",
      "     0     2 5727012.93    0   21 2361838.62 5727012.93   142%     -    0s\n",
      "H  346   216                    2477445.6925 5694885.19   130%   4.5    0s\n",
      "H  545   264                    2690159.4243 5694885.19   112%   3.7    0s\n",
      "H 1186   366                    3103109.1481 5694885.19  83.5%   2.9    0s\n",
      "H 1318   412                    3778147.4473 5694885.19  50.7%   2.8    0s\n",
      "* 1354   412              42    5645881.1461 5694885.19  0.87%   2.8    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 3\n",
      "\n",
      "Explored 1455 nodes (4077 simplex iterations) in 0.08 seconds (0.07 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 6: 5.64588e+06 3.77815e+06 3.10311e+06 ... 2.36184e+06\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 5.645881146092e+06, best bound 5.694885186736e+06, gap 0.8680%\n",
      "Model status: 2\n",
      "Lost0: 3.2540478584599684e-06, Lost1: 8.096207585423713, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -3.0151, F_vars[i]: 0.0467, Q0_vars[i]: 133.5109\n",
      "f_train: -3.015094399361634, F_train: 0.046748598185057284, Q0_train: 133.51089172155795\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 3.1757040408436694, Lost1: 0.0, Left0: 0.0, Left1: 21.41724365968298\n",
      "f_vars[i]: -3.1385, F_vars[i]: 0.0415, Q0_vars[i]: 118.6526\n",
      "f_train: -3.1385207696433084, F_train: 0.04154598219749401, Q0_train: 118.65256598022202\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 5.906366240135426, Lost1: 0.0, Left0: 0.0, Left1: 10.744534219435138\n",
      "f_vars[i]: -3.0833, F_vars[i]: 0.0438, Q0_vars[i]: 125.0979\n",
      "f_train: -3.083266645711846, F_train: 0.04380279078291492, Q0_train: 125.0978614197059\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1.2116841874580473, Left1: 1.2762455407133189\n",
      "f_vars[i]: -3.0373, F_vars[i]: 0.0458, Q0_vars[i]: 130.7143\n",
      "f_train: -3.0372903347015376, F_train: 0.04576936860056467, Q0_train: 130.7142770614091\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 5.429010641775392, Lost1: 0.0, Left0: 0.0, Left1: 5.176859394521443\n",
      "f_vars[i]: -3.1087, F_vars[i]: 0.0427, Q0_vars[i]: 122.0905\n",
      "f_train: -3.1087014340753387, F_train: 0.04274975286596131, Q0_train: 122.09045506385013\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 12.552363236220913, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -3.0684, F_vars[i]: 0.0444, Q0_vars[i]: 126.8857\n",
      "f_train: -3.0684216590185014, F_train: 0.04442878768981213, Q0_train: 126.88566701173534\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.2907888743524154, Lost1: 0.0, Left0: 0.0, Left1: 0.4036326072637735\n",
      "f_vars[i]: -3.1320, F_vars[i]: 0.0418, Q0_vars[i]: 119.3931\n",
      "f_train: -3.13202867552121, F_train: 0.041805267631727115, Q0_train: 119.39306796057741\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.7768458450194045, Lost1: 0.0, Left0: 0.0, Left1: 2.6910102574438497\n",
      "f_vars[i]: -3.1095, F_vars[i]: 0.0427, Q0_vars[i]: 121.9947\n",
      "f_train: -3.1095213161867687, F_train: 0.04271621405208392, Q0_train: 121.99467043881543\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.581511099810427, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -3.1327, F_vars[i]: 0.0418, Q0_vars[i]: 119.3153\n",
      "f_train: -3.1327086993634605, F_train: 0.04177803600331891, Q0_train: 119.31529623836626\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.976566907570657, Lost1: 0.7910738527493777, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -3.0228, F_vars[i]: 0.0464, Q0_vars[i]: 132.5378\n",
      "f_train: -3.0227665842332607, F_train: 0.04640788779854098, Q0_train: 132.5378454851228\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 9.38116241213828, Lost1: 0.0, Left0: 0.0, Left1: 39.27908180898612\n",
      "f_vars[i]: -3.1076, F_vars[i]: 0.0428, Q0_vars[i]: 122.2197\n",
      "f_train: -3.1075960754692447, F_train: 0.042795009453844096, Q0_train: 122.21970487323665\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.09945989234017816, Lost1: 0.0, Left0: 0.0, Left1: 3.451446426671339\n",
      "f_vars[i]: -3.0884, F_vars[i]: 0.0436, Q0_vars[i]: 124.4908\n",
      "f_train: -3.0883536441122574, F_train: 0.04359022016675438, Q0_train: 124.49077385731421\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.369103159156566, Lost1: 0.0, Left0: 0.0, Left1: 3.213638594387703\n",
      "f_vars[i]: -3.0112, F_vars[i]: 0.0469, Q0_vars[i]: 134.0027\n",
      "f_train: -3.0112365019475225, F_train: 0.04692081924253025, Q0_train: 134.00274362405617\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.15998729428861225, Left1: 4.88594292891878\n",
      "f_vars[i]: -3.0435, F_vars[i]: 0.0455, Q0_vars[i]: 129.9476\n",
      "f_train: -3.0434540917540165, F_train: 0.045500921825091904, Q0_train: 129.94761089890153\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.08783956930950772, Left1: 3.592869006297419\n",
      "f_vars[i]: -3.1369, F_vars[i]: 0.0416, Q0_vars[i]: 118.8375\n",
      "f_train: -3.1368958771544464, F_train: 0.04161073349743482, Q0_train: 118.83749139255215\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=2 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 481 nonzeros\n",
      "Model fingerprint: 0x7ea5e4ab\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 7e+02]\n",
      "  GenCon const rng [2e+02, 5e+02]\n",
      "Presolve removed 40 rows and 75 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 253 rows, 189 columns, 695 nonzeros\n",
      "Presolved model has 40 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 149 continuous, 40 integer (40 binary)\n",
      "Found heuristic solution: objective 2825528.9575\n",
      "\n",
      "Root relaxation: objective 5.728064e+06, 92 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5728064.04    0   23 2825528.96 5728064.04   103%     -    0s\n",
      "     0     2 5728064.04    0   23 2825528.96 5728064.04   103%     -    0s\n",
      "H   27    38                    2825529.3844 5706589.58   102%   7.4    0s\n",
      "H   93    88                    2825529.3916 5699099.84   102%   6.3    0s\n",
      "H  500   272                    3071095.1705 5699099.84  85.6%   4.6    0s\n",
      "* 1064   334              52    3071097.9609 5699099.84  85.6%   3.5    0s\n",
      "H 1068   334                    5626241.9655 5699099.84  1.29%   3.4    0s\n",
      "* 1304   282              60    5627144.6918 5698173.89  1.26%   3.7    0s\n",
      "H 1505   334                    5642290.3956 5698173.89  0.99%   3.6    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 12\n",
      "\n",
      "Explored 1755 nodes (6819 simplex iterations) in 0.10 seconds (0.09 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 7: 5.64229e+06 5.62714e+06 5.62624e+06 ... 2.82553e+06\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 5.642290395571e+06, best bound 5.698173885108e+06, gap 0.9904%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 13.20140764322943, Left0: 0.7798062819827543, Left1: 0.0\n",
      "f_vars[i]: -2.5700, F_vars[i]: 0.0711, Q0_vars[i]: 203.0414\n",
      "f_train: -2.5699956518995037, F_train: 0.07109459123296208, Q0_train: 203.04143098618974\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1.618165074968772, Left1: 20.45223425713516\n",
      "f_vars[i]: -2.6813, F_vars[i]: 0.0641, Q0_vars[i]: 183.0205\n",
      "f_train: -2.6813258284941868, F_train: 0.06408431053778382, Q0_train: 183.02053489158044\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 4.286241618634506, Lost1: 0.0, Left0: 0.0, Left1: 10.528803509954344\n",
      "f_vars[i]: -2.6278, F_vars[i]: 0.0674, Q0_vars[i]: 192.4012\n",
      "f_train: -2.6278256285726638, F_train: 0.06736893868960053, Q0_train: 192.40121475254267\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.53178230429188, Left1: 5.669813326788244\n",
      "f_vars[i]: -2.5932, F_vars[i]: 0.0696, Q0_vars[i]: 198.7029\n",
      "f_train: -2.5932289356476357, F_train: 0.06957546789770065, Q0_train: 198.70291562958147\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 4.352570388881503, Lost1: 0.0, Left0: 0.0, Left1: 2.769046219787924\n",
      "f_vars[i]: -2.6490, F_vars[i]: 0.0661, Q0_vars[i]: 188.6387\n",
      "f_train: -2.648986532732923, F_train: 0.06605150148119555, Q0_train: 188.6387015797406\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.628580933296831, Left0: 6.742381294904192, Left1: 0.0\n",
      "f_vars[i]: -2.6218, F_vars[i]: 0.0677, Q0_vars[i]: 193.4857\n",
      "f_train: -2.6217973695204613, F_train: 0.06774868563954373, Q0_train: 193.48574682160614\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.8587166754312818, Left0: 3.929746068043528, Left1: 0.0\n",
      "f_vars[i]: -2.6753, F_vars[i]: 0.0644, Q0_vars[i]: 184.0639\n",
      "f_train: -2.675250585903553, F_train: 0.0644496548866195, Q0_train: 184.06393408839472\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.11619770638913, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -2.6539, F_vars[i]: 0.0657, Q0_vars[i]: 187.7702\n",
      "f_train: -2.653927033635424, F_train: 0.06574738102945303, Q0_train: 187.77015376698745\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.4815979240230774, Left0: 6.923569012996779, Left1: 0.0\n",
      "f_vars[i]: -2.6720, F_vars[i]: 0.0646, Q0_vars[i]: 184.6227\n",
      "f_train: -2.6720102403379657, F_train: 0.06464531039267007, Q0_train: 184.62271321968845\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 2.4484127249855305, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -2.5757, F_vars[i]: 0.0707, Q0_vars[i]: 201.9636\n",
      "f_train: -2.5757242884746963, F_train: 0.07071719951219417, Q0_train: 201.963625295234\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 14.333669769032227, Lost1: 0.0, Left0: 0.0, Left1: 34.77532943540024\n",
      "f_vars[i]: -2.6535, F_vars[i]: 0.0658, Q0_vars[i]: 187.8414\n",
      "f_train: -2.653521203078032, F_train: 0.06577231342821113, Q0_train: 187.84135904201568\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 6.5269472909446336, Left1: 6.517909870179437\n",
      "f_vars[i]: -2.6349, F_vars[i]: 0.0669, Q0_vars[i]: 191.1344\n",
      "f_train: -2.634907252801563, F_train: 0.06692535851991094, Q0_train: 191.1343792472122\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.01846292584730236, Left1: 4.177866941413242\n",
      "f_vars[i]: -2.5722, F_vars[i]: 0.0709, Q0_vars[i]: 202.6278\n",
      "f_train: -2.5721908373372537, F_train: 0.07094975727987492, Q0_train: 202.62779483496914\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 2.3400814284586318, Left1: 0.9122229907690667\n",
      "f_vars[i]: -2.6008, F_vars[i]: 0.0691, Q0_vars[i]: 197.3007\n",
      "f_train: -2.600838369150716, F_train: 0.06908448381689353, Q0_train: 197.30069770231532\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 5.037922318277452, Left0: 1.3974253246130388, Left1: 0.0\n",
      "f_vars[i]: -2.6810, F_vars[i]: 0.0641, Q0_vars[i]: 183.0807\n",
      "f_train: -2.680974605614112, F_train: 0.06410537923765247, Q0_train: 183.08070569917862\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=3 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 481 nonzeros\n",
      "Model fingerprint: 0xdd918f7c\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 7e+02]\n",
      "  GenCon const rng [2e+02, 4e+02]\n",
      "Presolve removed 40 rows and 75 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 253 rows, 189 columns, 697 nonzeros\n",
      "Presolved model has 40 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 149 continuous, 40 integer (40 binary)\n",
      "Found heuristic solution: objective 3351016.1488\n",
      "\n",
      "Root relaxation: objective 5.742847e+06, 94 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5742846.62    0   22 3351016.15 5742846.62  71.4%     -    0s\n",
      "     0     2 5742846.62    0   22 3351016.15 5742846.62  71.4%     -    0s\n",
      "H   36    36                    3351016.1496 5730675.08  71.0%   6.3    0s\n",
      "H  647   284                    3435714.2872 5729891.15  66.8%   4.4    0s\n",
      "H  680   284                    4475031.3373 5729891.15  28.0%   4.3    0s\n",
      "H 1362   442                    4518431.7376 5729891.15  26.8%   3.7    0s\n",
      "H 1498   508                    4535308.2494 5729891.15  26.3%   3.5    0s\n",
      "* 1500   508              60    4535317.2273 5729891.15  26.3%   3.5    0s\n",
      "* 1572   508              54    5359551.0643 5729891.15  6.91%   3.5    0s\n",
      "H 1623   508                    5679558.6645 5729891.15  0.89%   3.5    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 4\n",
      "\n",
      "Explored 1755 nodes (6049 simplex iterations) in 0.08 seconds (0.08 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 9: 5.67956e+06 5.35955e+06 4.53532e+06 ... 3.35102e+06\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 5.679558664474e+06, best bound 5.729891149691e+06, gap 0.8862%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 1.1958040643948493, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -2.2561, F_vars[i]: 0.0948, Q0_vars[i]: 270.8197\n",
      "f_train: -2.2560717279911007, F_train: 0.09482701534934596, Q0_train: 270.81965813109287\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1.431397799885263, Left1: 4.310187678785724\n",
      "f_vars[i]: -2.3754, F_vars[i]: 0.0851, Q0_vars[i]: 242.9509\n",
      "f_train: -2.3753882364934142, F_train: 0.08506882287021005, Q0_train: 242.9509084774087\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 3.64381103253686, Lost1: 0.0, Left0: 0.0, Left1: 2.6968837550348894\n",
      "f_vars[i]: -2.3153, F_vars[i]: 0.0899, Q0_vars[i]: 256.6434\n",
      "f_train: -2.315305997931798, F_train: 0.08986323320525975, Q0_train: 256.64342598515594\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.728058967454899, Left1: 4.189151796559372\n",
      "f_vars[i]: -2.2834, F_vars[i]: 0.0925, Q0_vars[i]: 264.1991\n",
      "f_train: -2.283379639910593, F_train: 0.09250883812071413, Q0_train: 264.1990979222485\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 3.006197384558135, Lost1: 0.4218450711678656, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -2.3366, F_vars[i]: 0.0881, Q0_vars[i]: 251.7014\n",
      "f_train: -2.3366498256071564, F_train: 0.0881327816747145, Q0_train: 251.70137133766752\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.909979843894575, Left1: 0.5736349408189199\n",
      "f_vars[i]: -2.3144, F_vars[i]: 0.0899, Q0_vars[i]: 256.8637\n",
      "f_train: -2.314363281480574, F_train: 0.0899403657575134, Q0_train: 256.86371143182066\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 3.761308651396007, Left1: 5.3434949105468945\n",
      "f_vars[i]: -2.3687, F_vars[i]: 0.0856, Q0_vars[i]: 244.4389\n",
      "f_train: -2.3687127384860553, F_train: 0.08558983221501314, Q0_train: 244.43887656459208\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.9196377356537937, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -2.3451, F_vars[i]: 0.0875, Q0_vars[i]: 249.7701\n",
      "f_train: -2.3450935124333814, F_train: 0.08745655716079777, Q0_train: 249.77011903573523\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.7199725986885142, Left0: 7.980128383589772, Left1: 0.0\n",
      "f_vars[i]: -2.3624, F_vars[i]: 0.0861, Q0_vars[i]: 245.8645\n",
      "f_train: -2.3623514411624402, F_train: 0.08608900838072084, Q0_train: 245.8644905422768\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.36430866325230227, Lost1: 0.0, Left0: 0.0, Left1: 5.801330937720763\n",
      "f_vars[i]: -2.2613, F_vars[i]: 0.0944, Q0_vars[i]: 269.5363\n",
      "f_train: -2.261318128391081, F_train: 0.0943776475964367, Q0_train: 269.5362936724554\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 14.772332274357126, Lost1: 0.0, Left0: 0.0, Left1: 18.860269197287664\n",
      "f_vars[i]: -2.3457, F_vars[i]: 0.0874, Q0_vars[i]: 249.6419\n",
      "f_train: -2.3456559989846726, F_train: 0.08741167670169031, Q0_train: 249.64194342515137\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.7897008764588236, Left0: 6.381744234645225, Left1: 0.0\n",
      "f_vars[i]: -2.3248, F_vars[i]: 0.0891, Q0_vars[i]: 254.4427\n",
      "f_train: -2.3247643448710282, F_train: 0.08909265051114205, Q0_train: 254.4426929871398\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.6856096040344255, Lost1: 0.0, Left0: 0.0, Left1: 4.239923441951817\n",
      "f_vars[i]: -2.2627, F_vars[i]: 0.0943, Q0_vars[i]: 269.2045\n",
      "f_train: -2.262677997637745, F_train: 0.09426148297569223, Q0_train: 269.2045352304012\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.12015940854229257, Lost1: 2.9139941452320386, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -2.2931, F_vars[i]: 0.0917, Q0_vars[i]: 261.8846\n",
      "f_train: -2.2930712971661897, F_train: 0.09169842115256525, Q0_train: 261.88460088309614\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.8472561784640887, Left1: 1.9620849608455728\n",
      "f_vars[i]: -2.3758, F_vars[i]: 0.0850, Q0_vars[i]: 242.8489\n",
      "f_train: -2.375847119424198, F_train: 0.08503311383947906, Q0_train: 242.8489258571698\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=4 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 481 nonzeros\n",
      "Model fingerprint: 0x0754032b\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 7e+02]\n",
      "  GenCon const rng [3e+02, 4e+02]\n",
      "Presolve removed 34 rows and 67 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 259 rows, 197 columns, 721 nonzeros\n",
      "Presolved model has 43 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 154 continuous, 43 integer (43 binary)\n",
      "\n",
      "Root relaxation: objective 5.746592e+06, 85 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5746592.37    0   22          - 5746592.37      -     -    0s\n",
      "H    0     0                    -5630506.045 5746592.37   202%     -    0s\n",
      "     0     2 5746592.37    0   22 -5630506.0 5746592.37   202%     -    0s\n",
      "H   31    36                    -5630504.938 5739912.06   202%   5.8    0s\n",
      "H   36    36                    -5630504.116 5739912.06   202%   5.6    0s\n",
      "H  115   102                    -5630503.962 5737653.40   202%   6.0    0s\n",
      "H  120   102                    -5630502.033 5737399.76   202%   5.9    0s\n",
      "H  204   132                    -5630501.956 5737399.46   202%   5.4    0s\n",
      "H  513   278                    4813373.9407 5737399.46  19.2%   4.1    0s\n",
      "H  860   436                    5691067.2257 5737399.46  0.81%   3.6    0s\n",
      "*  865   436              40    5691070.5699 5737399.46  0.81%   3.5    0s\n",
      "\n",
      "Explored 999 nodes (3468 simplex iterations) in 0.15 seconds (0.06 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 9: 5.69107e+06 5.69107e+06 4.81337e+06 ... -5.63051e+06\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 5.691070569907e+06, best bound 5.737399460279e+06, gap 0.8141%\n",
      "Model status: 2\n",
      "Lost0: 1.3855557682454462, Lost1: 0.0, Left0: 0.0, Left1: 2.2126446777500064\n",
      "f_vars[i]: -1.9895, F_vars[i]: 0.1203, Q0_vars[i]: 343.6098\n",
      "f_train: -1.9894567112632358, F_train: 0.12031435164006375, Q0_train: 343.60979789765037\n",
      "f_train, F_train, Q0_train 不相等\n",
      "Lost0: 0.5217501836498286, Lost1: 0.0, Left0: 0.0, Left1: 6.04354101356995\n",
      "f_vars[i]: -2.1435, F_vars[i]: 0.1049, Q0_vars[i]: 299.7155\n",
      "f_train: -2.1434503637801674, F_train: 0.10494484987145868, Q0_train: 299.7155215747632\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.6750456509457194, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -2.0569, F_vars[i]: 0.1134, Q0_vars[i]: 323.7465\n",
      "f_train: -2.056877707963954, F_train: 0.11335926971211252, Q0_train: 323.746545816349\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.898041297304544, Left1: 1.1010661369381998\n",
      "f_vars[i]: -2.0326, F_vars[i]: 0.1158, Q0_vars[i]: 330.7742\n",
      "f_train: -2.0326236638870707, F_train: 0.11581997297868585, Q0_train: 330.7741509240326\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.676130683177234, Lost1: 0.13317096534160555, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -2.0800, F_vars[i]: 0.1111, Q0_vars[i]: 317.1594\n",
      "f_train: -2.080032215868704, F_train: 0.11105278631890517, Q0_train: 317.15938242485913\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.9028323978921549, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -2.0738, F_vars[i]: 0.1117, Q0_vars[i]: 318.9163\n",
      "f_train: -2.073815767232625, F_train: 0.11166795996119062, Q0_train: 318.91627749195834\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.647766541657802, Left1: 2.093698907299995\n",
      "f_vars[i]: -2.1343, F_vars[i]: 0.1058, Q0_vars[i]: 302.1808\n",
      "f_train: -2.134293715119294, F_train: 0.10580806350061986, Q0_train: 302.1808023714043\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.757715585105975, Left0: 0.10015068278267823, Left1: 0.0\n",
      "f_vars[i]: -2.1013, F_vars[i]: 0.1090, Q0_vars[i]: 311.2155\n",
      "f_train: -2.1012897180716363, F_train: 0.10897153061159238, Q0_train: 311.2154543463327\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.32904644903231883, Left0: 9.087062169073626, Left1: 0.0\n",
      "f_vars[i]: -2.1166, F_vars[i]: 0.1075, Q0_vars[i]: 307.0007\n",
      "f_train: -2.1165801353761386, F_train: 0.10749573352402023, Q0_train: 307.00067587571715\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.41793099518768234, Left1: 6.160133894498188\n",
      "f_vars[i]: -1.9933, F_vars[i]: 0.1199, Q0_vars[i]: 342.4530\n",
      "f_train: -1.9932892126353612, F_train: 0.11990931414589724, Q0_train: 342.45303771389536\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 9.437099257341968, Lost1: 0.0, Left0: 0.0, Left1: 10.323558210192402\n",
      "f_vars[i]: -2.1053, F_vars[i]: 0.1086, Q0_vars[i]: 310.1059\n",
      "f_train: -2.105297331773845, F_train: 0.10858301376272066, Q0_train: 310.10587602836097\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.312595683400559, Left1: 0.6228965557853599\n",
      "f_vars[i]: -2.0752, F_vars[i]: 0.1115, Q0_vars[i]: 318.5149\n",
      "f_train: -2.07523323420536, F_train: 0.11152742713064209, Q0_train: 318.51492506105944\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 5.577226217829605, Lost1: 0.0, Left0: 0.0, Left1: 4.8029212853940635\n",
      "f_vars[i]: -2.0120, F_vars[i]: 0.1180, Q0_vars[i]: 336.8604\n",
      "f_train: -2.01197781106356, F_train: 0.11795105357666266, Q0_train: 336.860375581296\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 6.690499842162183, Lost1: 0.0, Left0: 0.0, Left1: 5.4222798228076385\n",
      "f_vars[i]: -2.0502, F_vars[i]: 0.1140, Q0_vars[i]: 325.6721\n",
      "f_train: -2.0501868021580414, F_train: 0.11403350732195079, Q0_train: 325.67212365218865\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.8781099423284786, Lost1: 0.0, Left0: 0.0, Left1: 1.758415230593073\n",
      "f_vars[i]: -2.1468, F_vars[i]: 0.1046, Q0_vars[i]: 298.8206\n",
      "f_train: -2.146790842786288, F_train: 0.10463148773410116, Q0_train: 298.8205801216578\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=5 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 481 nonzeros\n",
      "Model fingerprint: 0x61de0d97\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 7e+02]\n",
      "  GenCon const rng [2e+02, 4e+02]\n",
      "Presolve removed 34 rows and 67 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 259 rows, 197 columns, 721 nonzeros\n",
      "Presolved model has 43 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 154 continuous, 43 integer (43 binary)\n",
      "\n",
      "Root relaxation: objective 5.746592e+06, 90 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5746592.37    0   22          - 5746592.37      -     -    0s\n",
      "H    0     0                    -5246704.775 5746592.37   210%     -    0s\n",
      "     0     2 5746592.37    0   22 -5246704.8 5746592.37   210%     -    0s\n",
      "H   31    36                    -5246703.524 5739912.06   209%   5.5    0s\n",
      "H   36    36                    -5246702.955 5739912.06   209%   5.2    0s\n",
      "H  115   102                    -5246702.743 5737653.40   209%   5.6    0s\n",
      "H  120   102                    -5246700.923 5737399.76   209%   5.5    0s\n",
      "H  180   130                    -5246700.476 5737399.48   209%   5.2    0s\n",
      "H  394   230                    -5246700.471 5737399.48   209%   4.4    0s\n",
      "H  431   230                    -5246698.309 5737399.48   209%   4.2    0s\n",
      "H  521   260                    3259309.1984 5737399.48  76.0%   3.7    0s\n",
      "H  564   260                    4080228.6694 5737399.48  40.6%   3.5    0s\n",
      "*  758   354              35    4714987.0163 5737399.48  21.7%   3.3    0s\n",
      "H  860   426                    5691734.2423 5737399.48  0.80%   3.2    0s\n",
      "*  870   426              43    5691736.0726 5737399.48  0.80%   3.1    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 1\n",
      "\n",
      "Explored 999 nodes (3036 simplex iterations) in 0.07 seconds (0.05 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 10: 5.69174e+06 5.69173e+06 4.71499e+06 ... -5.2467e+06\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 5.691736072566e+06, best bound 5.737399475602e+06, gap 0.8023%\n",
      "Model status: 2\n",
      "Lost0: 0.9968418206408955, Lost1: 0.0, Left0: 0.0, Left1: 1.8239307099490247\n",
      "f_vars[i]: -1.7788, F_vars[i]: 0.1445, Q0_vars[i]: 412.5559\n",
      "f_train: -1.7787649750283392, F_train: 0.14445570165509825, Q0_train: 412.55589025127614\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.6869118786779609, Lost1: 0.0, Left0: 0.0, Left1: 6.208702660205773\n",
      "f_vars[i]: -1.9374, F_vars[i]: 0.1259, Q0_vars[i]: 359.6675\n",
      "f_train: -1.9373713334955918, F_train: 0.12593692735282694, Q0_train: 359.66750072354887\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.6750456651791978, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.8521, F_vars[i]: 0.1356, Q0_vars[i]: 387.3463\n",
      "f_train: -1.8520821136023595, F_train: 0.13562861831512335, Q0_train: 387.34632646167665\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.09880165191022, Left1: 1.1010661339639807\n",
      "f_vars[i]: -1.8198, F_vars[i]: 0.1395, Q0_vars[i]: 398.2745\n",
      "f_train: -1.819823259087943, F_train: 0.13945508182071095, Q0_train: 398.27445210832536\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.7416398035468319, Lost1: 0.06766180271480948, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.8778, F_vars[i]: 0.1326, Q0_vars[i]: 378.8108\n",
      "f_train: -1.8778162018867368, F_train: 0.13263991052116345, Q0_train: 378.81077548991937\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.9028323671146268, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.8617, F_vars[i]: 0.1345, Q0_vars[i]: 384.1266\n",
      "f_train: -1.8617324192175713, F_train: 0.1345012521497286, Q0_train: 384.1266435646037\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.4928381282714716, Left1: 2.0936989122375556\n",
      "f_vars[i]: -1.9282, F_vars[i]: 0.1270, Q0_vars[i]: 362.5693\n",
      "f_train: -1.9281727143514873, F_train: 0.12695297097861472, Q0_train: 362.5692538407213\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.757715636853675, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.8953, F_vars[i]: 0.1306, Q0_vars[i]: 373.1153\n",
      "f_train: -1.8952622524616944, F_train: 0.1306456342001206, Q0_train: 373.1152547620545\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.32904646225716583, Left0: 8.977528978011437, Left1: 0.0\n",
      "f_vars[i]: -1.9140, F_vars[i]: 0.1285, Q0_vars[i]: 367.0764\n",
      "f_train: -1.914009059990591, F_train: 0.12853112467986308, Q0_train: 367.07635600222943\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.7490246072343778, Left1: 6.16013386022297\n",
      "f_vars[i]: -1.7840, F_vars[i]: 0.1438, Q0_vars[i]: 410.7207\n",
      "f_train: -1.7839740516428044, F_train: 0.14381311254722437, Q0_train: 410.7206984351882\n",
      "f_train, F_train, Q0_train 不相等\n",
      "Lost0: 9.549320230828584, Lost1: 0.0, Left0: 0.0, Left1: 10.435779188539328\n",
      "f_vars[i]: -1.8980, F_vars[i]: 0.1303, Q0_vars[i]: 372.2343\n",
      "f_train: -1.8979808663489401, F_train: 0.13033717115999882, Q0_train: 372.2343048052927\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.2768302027797, Left1: 0.6228965748201682\n",
      "f_vars[i]: -1.8683, F_vars[i]: 0.1337, Q0_vars[i]: 381.9327\n",
      "f_train: -1.8683475679466313, F_train: 0.13373303849534524, Q0_train: 381.9326763867347\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 5.1917574803499065, Lost1: 0.0, Left0: 0.0, Left1: 4.417452570105468\n",
      "f_vars[i]: -1.7960, F_vars[i]: 0.1423, Q0_vars[i]: 406.5267\n",
      "f_train: -1.7959517005791716, F_train: 0.14234457658395883, Q0_train: 406.5266572533623\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 6.556982334151142, Lost1: 0.0, Left0: 0.0, Left1: 5.288762318558668\n",
      "f_vars[i]: -1.8357, F_vars[i]: 0.1376, Q0_vars[i]: 392.8498\n",
      "f_train: -1.8357421092047406, F_train: 0.13755564446935747, Q0_train: 392.8497851793928\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.0596257312824946, Lost1: 0.0, Left0: 0.0, Left1: 1.9399310439265491\n",
      "f_vars[i]: -1.9396, F_vars[i]: 0.1257, Q0_vars[i]: 358.9575\n",
      "f_train: -1.9396318643751256, F_train: 0.1256883056430334, Q0_train: 358.95745363198745\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=6 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 481 nonzeros\n",
      "Model fingerprint: 0x89c22019\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 7e+02]\n",
      "  GenCon const rng [2e+02, 5e+02]\n",
      "Presolve removed 30 rows and 60 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 263 rows, 204 columns, 739 nonzeros\n",
      "Presolved model has 45 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 159 continuous, 45 integer (45 binary)\n",
      "\n",
      "Root relaxation: objective 5.750950e+06, 91 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5750949.74    0   21          - 5750949.74      -     -    0s\n",
      "H    0     0                    -4862366.353 5750949.74   218%     -    0s\n",
      "     0     2 5750949.74    0   21 -4862366.4 5750949.74   218%     -    0s\n",
      "H  128   106                    -4862365.093 5747231.01   218%   4.9    0s\n",
      "H  275   194                    -4862363.086 5747231.01   218%   4.4    0s\n",
      "H  394   256                    -4862361.516 5747231.01   218%   3.9    0s\n",
      "H  529   292                    3981827.5379 5747231.01  44.3%   3.4    0s\n",
      "*  697   370              35    5709881.0621 5747231.01  0.65%   3.0    0s\n",
      "\n",
      "Explored 831 nodes (2538 simplex iterations) in 0.05 seconds (0.05 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 6: 5.70988e+06 3.98183e+06 -4.86236e+06 ... -4.86237e+06\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 5.709881062092e+06, best bound 5.747231005321e+06, gap 0.6541%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 1.4138131175723458, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.6016, F_vars[i]: 0.1678, Q0_vars[i]: 479.1131\n",
      "f_train: -1.6015823791458685, F_train: 0.16776057173390888, Q0_train: 479.11305145983636\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.930338641751511, Left1: 0.058895364098049185\n",
      "f_vars[i]: -1.7460, F_vars[i]: 0.1486, Q0_vars[i]: 424.2643\n",
      "f_train: -1.7459766329596234, F_train: 0.14855538111880867, Q0_train: 424.2643025293473\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.6128817267182285, Lost1: 0.0, Left0: 0.0, Left1: 2.4516868507958804\n",
      "f_vars[i]: -1.6766, F_vars[i]: 0.1575, Q0_vars[i]: 449.9494\n",
      "f_train: -1.676579246482576, F_train: 0.15754896453837214, Q0_train: 449.94937948855204\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 3.513638577781876, Left1: 1.457831729549838\n",
      "f_vars[i]: -1.6317, F_vars[i]: 0.1636, Q0_vars[i]: 467.2150\n",
      "f_train: -1.631722850764439, F_train: 0.1635944846130221, Q0_train: 467.2149833231733\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.1575749163181046, Lost1: 0.0, Left0: 0.0, Left1: 1.7760770883831185\n",
      "f_vars[i]: -1.7040, F_vars[i]: 0.1539, Q0_vars[i]: 439.6449\n",
      "f_train: -1.7040208108769925, F_train: 0.153940853362887, Q0_train: 439.6448535953346\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.261566923088111, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.6688, F_vars[i]: 0.1586, Q0_vars[i]: 452.9148\n",
      "f_train: -1.668776936601993, F_train: 0.158587313076752, Q0_train: 452.9148339547607\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.7314382286054695, Left0: 9.866458751243778, Left1: 0.0\n",
      "f_vars[i]: -1.7381, F_vars[i]: 0.1496, Q0_vars[i]: 427.1188\n",
      "f_train: -1.7380966116525656, F_train: 0.14955486163171444, Q0_train: 427.11875249612774\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.6839538859136667, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.7104, F_vars[i]: 0.1531, Q0_vars[i]: 437.2632\n",
      "f_train: -1.710437891829019, F_train: 0.15310692780976914, Q0_train: 437.26321759877663\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 8.276545471907639, Left1: 0.04360835065492097\n",
      "f_vars[i]: -1.7339, F_vars[i]: 0.1501, Q0_vars[i]: 428.6507\n",
      "f_train: -1.7338853854361764, F_train: 0.15009127077688883, Q0_train: 428.6507013904311\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1.579029571128558, Left1: 1.9789342940205756\n",
      "f_vars[i]: -1.6090, F_vars[i]: 0.1667, Q0_vars[i]: 476.1588\n",
      "f_train: -1.609009733463564, F_train: 0.16672614445626757, Q0_train: 476.158795853876\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.214750427982665, Lost1: 0.0, Left0: 0.0, Left1: 2.1479644373965527\n",
      "f_vars[i]: -1.7099, F_vars[i]: 0.1532, Q0_vars[i]: 437.4571\n",
      "f_train: -1.7099144775411446, F_train: 0.15317480874975015, Q0_train: 437.4570810552141\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 3.2361229620590786, Left1: 0.28198961370080156\n",
      "f_vars[i]: -1.6858, F_vars[i]: 0.1563, Q0_vars[i]: 446.4766\n",
      "f_train: -1.685769566785063, F_train: 0.15633299374997228, Q0_train: 446.47664767263797\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 4.586949007719224, Lost1: 0.0, Left0: 0.0, Left1: 4.12647149818531\n",
      "f_vars[i]: -1.6044, F_vars[i]: 0.1674, Q0_vars[i]: 477.9739\n",
      "f_train: -1.6044420716432288, F_train: 0.16736168940527046, Q0_train: 477.97387002004916\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 4.572963513199795, Lost1: 0.0, Left0: 0.0, Left1: 4.84499832653222\n",
      "f_vars[i]: -1.6416, F_vars[i]: 0.1622, Q0_vars[i]: 463.3693\n",
      "f_train: -1.6415967539125451, F_train: 0.1622479090939527, Q0_train: 463.36925307026405\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.943387959698384, Left1: 1.6494118456268723\n",
      "f_vars[i]: -1.7455, F_vars[i]: 0.1486, Q0_vars[i]: 424.4280\n",
      "f_train: -1.7455235657518298, F_train: 0.14861269721102383, Q0_train: 424.4279934822043\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=7 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 481 nonzeros\n",
      "Model fingerprint: 0x73811a2d\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 7e+02]\n",
      "  GenCon const rng [1e+02, 6e+02]\n",
      "Presolve removed 30 rows and 60 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 263 rows, 204 columns, 721 nonzeros\n",
      "Presolved model has 45 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 159 continuous, 45 integer (45 binary)\n",
      "Found heuristic solution: objective 4918661.4738\n",
      "\n",
      "Root relaxation: objective 5.753830e+06, 70 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5753829.74    0   22 4918661.47 5753829.74  17.0%     -    0s\n",
      "     0     2 5753829.74    0   22 4918661.47 5753829.74  17.0%     -    0s\n",
      "H   33    32                    4918661.4793 5753829.74  17.0%  30.1    0s\n",
      "H  101    76                    4958902.3234 5753829.74  16.0%  19.2    0s\n",
      "H  567   227                    4958905.8974 5753829.74  16.0%  12.8    0s\n",
      "H  617   227                    4958909.2928 5753829.74  16.0%  12.7    0s\n",
      "H 1003   351                    4958910.0525 5753829.74  16.0%  10.9    0s\n",
      "* 1028   351              55    5081034.0267 5753829.74  13.2%  10.8    0s\n",
      "H 1256   430                    5687929.6438 5753829.74  1.16%  10.4    0s\n",
      "H 1455   473                    5699185.4012 5753829.74  0.96%   9.8    0s\n",
      "* 1478   473              80    5719657.7073 5749256.60  0.52%   9.9    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 3\n",
      "\n",
      "Explored 1755 nodes (17703 simplex iterations) in 0.10 seconds (0.14 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 10: 5.71966e+06 5.69919e+06 5.68793e+06 ... 4.91866e+06\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 5.719657707256e+06, best bound 5.727668203958e+06, gap 0.1401%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.045373686077786, Left1: 0.0\n",
      "f_vars[i]: -1.4211, F_vars[i]: 0.1945, Q0_vars[i]: 555.4669\n",
      "f_train: -1.4210582701389431, F_train: 0.19449573382726434, Q0_train: 555.4668988473975\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.718781584521387, Left1: 0.0\n",
      "f_vars[i]: -1.5883, F_vars[i]: 0.1696, Q0_vars[i]: 484.4443\n",
      "f_train: -1.5882709074070345, F_train: 0.16962730723376063, Q0_train: 484.44432407269426\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.2957829060032964e-06, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.5133, F_vars[i]: 0.1805, Q0_vars[i]: 515.3691\n",
      "f_train: -1.5132641379174967, F_train: 0.18045555179360512, Q0_train: 515.3690714039639\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 10.27817017325661, Left1: 1.6426136255631718e-06\n",
      "f_vars[i]: -1.4513, F_vars[i]: 0.1898, Q0_vars[i]: 542.0779\n",
      "f_train: -1.4512607668328459, F_train: 0.18980760860680523, Q0_train: 542.0779245682525\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.5057090119054806, Lost1: 0.0, Left0: 0.0, Left1: 0.5057108999973394\n",
      "f_vars[i]: -1.5476, F_vars[i]: 0.1754, Q0_vars[i]: 501.0054\n",
      "f_train: -1.5476486583283509, F_train: 0.17542613444577956, Q0_train: 501.0053894751506\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.4516931013767715, Left1: 0.0\n",
      "f_vars[i]: -1.4935, F_vars[i]: 0.1834, Q0_vars[i]: 523.7883\n",
      "f_train: -1.4934562382123686, F_train: 0.1834035315992718, Q0_train: 523.7883059460065\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 12.64387896311247, Left1: 0.0\n",
      "f_vars[i]: -1.5795, F_vars[i]: 0.1709, Q0_vars[i]: 487.9963\n",
      "f_train: -1.579466659890652, F_train: 0.1708710292501781, Q0_train: 487.99631155279604\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.0401456620456884e-06, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.5489, F_vars[i]: 0.1752, Q0_vars[i]: 500.4752\n",
      "f_train: -1.5489325520564359, F_train: 0.17524049428472, Q0_train: 500.47521350400626\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.142460619977706, Left1: 4.3227112769272935e-06\n",
      "f_vars[i]: -1.5802, F_vars[i]: 0.1708, Q0_vars[i]: 487.6879\n",
      "f_train: -1.5802290855829053, F_train: 0.1707630403642668, Q0_train: 487.6879024664537\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 10.080083985765611, Left1: 0.0\n",
      "f_vars[i]: -1.4314, F_vars[i]: 0.1929, Q0_vars[i]: 550.8529\n",
      "f_train: -1.4314030932157198, F_train: 0.1928801601937866, Q0_train: 550.8529278445965\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.8195977593177735, Lost1: 0.0, Left0: 0.0, Left1: 1.8195997475568078\n",
      "f_vars[i]: -1.5464, F_vars[i]: 0.1756, Q0_vars[i]: 501.5301\n",
      "f_train: -1.5463791696448124, F_train: 0.1756098439478095, Q0_train: 501.5300516123263\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.079495140266663, Left1: 0.0\n",
      "f_vars[i]: -1.5203, F_vars[i]: 0.1794, Q0_vars[i]: 512.4215\n",
      "f_train: -1.5202585425241595, F_train: 0.17942345086167255, Q0_train: 512.4214596868491\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 2.031690666415829, Left1: 0.0\n",
      "f_vars[i]: -1.4161, F_vars[i]: 0.1953, Q0_vars[i]: 557.7042\n",
      "f_train: -1.4160656688069428, F_train: 0.1952791036320588, Q0_train: 557.7041509842815\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.4597, F_vars[i]: 0.1885, Q0_vars[i]: 538.3831\n",
      "f_train: -1.4596956400767285, F_train: 0.1885138806844177, Q0_train: 538.3831235417214\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 8.656556301763146, Left1: 0.0\n",
      "f_vars[i]: -1.5861, F_vars[i]: 0.1699, Q0_vars[i]: 485.3120\n",
      "f_train: -1.5861155080491283, F_train: 0.16993111982742046, Q0_train: 485.3119926632089\n",
      "f_train, F_train, Q0_train 都相等\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R(T)</th>\n",
       "      <th>R</th>\n",
       "      <th>average_profits</th>\n",
       "      <th>average_losses</th>\n",
       "      <th>average_lefts</th>\n",
       "      <th>average_operation_profits</th>\n",
       "      <th>alpha_values</th>\n",
       "      <th>F_vars</th>\n",
       "      <th>f_vars</th>\n",
       "      <th>Q0_vars</th>\n",
       "      <th>Q1_vars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]</td>\n",
       "      <td>381310.531607</td>\n",
       "      <td>0.155021</td>\n",
       "      <td>5.230233</td>\n",
       "      <td>383495.637367</td>\n",
       "      <td>[-0.0029411303302361246, 0.0, 0.01855775453414...</td>\n",
       "      <td>[0.19449571510635813, 0.16962708883849945, 0.1...</td>\n",
       "      <td>[-1.4210582701389431, -1.5882709074070345, -1....</td>\n",
       "      <td>[555.4668453817327, 484.4437003503325, 515.369...</td>\n",
       "      <td>[132.0706924296501, 112.51550325638364, 127.19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]</td>\n",
       "      <td>380658.754663</td>\n",
       "      <td>1.149059</td>\n",
       "      <td>3.877559</td>\n",
       "      <td>382899.214102</td>\n",
       "      <td>[-0.004801392626435972, -2.5586293848821637, 0...</td>\n",
       "      <td>[0.16776057173390893, 0.14855538111880867, 0.1...</td>\n",
       "      <td>[-1.6015823791458685, -1.7459766329596234, -1....</td>\n",
       "      <td>[479.1130514598365, 424.2643025293473, 449.949...</td>\n",
       "      <td>[207.0106732339741, 172.75379644146693, 193.45...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]</td>\n",
       "      <td>379449.089207</td>\n",
       "      <td>2.034359</td>\n",
       "      <td>4.245825</td>\n",
       "      <td>382368.034523</td>\n",
       "      <td>[-0.00970372751963152, 0.0, 0.0146592427080991...</td>\n",
       "      <td>[0.14445600745047515, 0.12593692735282694, 0.1...</td>\n",
       "      <td>[-1.778764975028339, -1.937371333495592, -1.85...</td>\n",
       "      <td>[412.556763582564, 359.66750072354887, 387.346...</td>\n",
       "      <td>[275.80786311812693, 242.8134936646951, 254.54...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]</td>\n",
       "      <td>379404.723053</td>\n",
       "      <td>2.064279</td>\n",
       "      <td>4.266980</td>\n",
       "      <td>382350.082454</td>\n",
       "      <td>[-0.011261536701351417, -2.734196246044146, 0....</td>\n",
       "      <td>[-1, 0.10494484987145875, 0.11335926971211249,...</td>\n",
       "      <td>[-1, -2.143450363780167, -2.056877707963954, -...</td>\n",
       "      <td>[-1, 299.71552157476344, 323.74654581634894, 3...</td>\n",
       "      <td>[344.75461050864754, 302.7654728618728, 318.14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]</td>\n",
       "      <td>378637.264325</td>\n",
       "      <td>2.370225</td>\n",
       "      <td>5.267789</td>\n",
       "      <td>382166.514857</td>\n",
       "      <td>[-0.005305759314962911, 0.0, 0.011876807058378...</td>\n",
       "      <td>[0.09482701534934591, 0.08506882287021005, 0.0...</td>\n",
       "      <td>[-2.256071727991101, -2.3753882364934142, -2.3...</td>\n",
       "      <td>[270.81965813109275, 242.9509084774087, 256.64...</td>\n",
       "      <td>[415.52207561588875, 358.3184828080911, 384.97...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>376392.102662</td>\n",
       "      <td>3.828411</td>\n",
       "      <td>6.506134</td>\n",
       "      <td>381291.603090</td>\n",
       "      <td>[-0.002116512989443514, -3.9224777868970846, 0...</td>\n",
       "      <td>[0.04674859818505727, 0.04154596528141269, 0.0...</td>\n",
       "      <td>[-3.015094399361634, -3.1385207696433084, -3.0...</td>\n",
       "      <td>[133.5108917215579, 118.65251766901721, 125.09...</td>\n",
       "      <td>[545.9304352503533, 496.5482255565382, 522.308...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>376152.715194</td>\n",
       "      <td>3.449688</td>\n",
       "      <td>8.240773</td>\n",
       "      <td>381518.837063</td>\n",
       "      <td>[-0.0036988938027179567, 0.0, 0.01161472109888...</td>\n",
       "      <td>[0.0710945912329621, 0.06408431053778382, 0.06...</td>\n",
       "      <td>[-2.5699956518995033, -2.6813258284941868, -2....</td>\n",
       "      <td>[203.0414309861898, 183.02053489158044, 192.40...</td>\n",
       "      <td>[471.2946991819626, 434.3909029722712, 456.409...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>368633.107902</td>\n",
       "      <td>7.010124</td>\n",
       "      <td>16.358481</td>\n",
       "      <td>379382.575099</td>\n",
       "      <td>[-0.01965229958295822, -2.539393477141857, -0....</td>\n",
       "      <td>[0.022738898856961204, 0.023682943918313947, 0...</td>\n",
       "      <td>[-3.7606768002086604, -3.7190322630392907, -3....</td>\n",
       "      <td>[64.94078498656665, 67.63691498532296, 69.1736...</td>\n",
       "      <td>[602.88453792509, 552.0890579016283, 603.08537...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R(T)                                              R  average_profits  \\\n",
       "7     9  [7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]    381310.531607   \n",
       "6     8  [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]    380658.754663   \n",
       "5     7  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]    379449.089207   \n",
       "4     6  [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]    379404.723053   \n",
       "3     5  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]    378637.264325   \n",
       "1     3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]    376392.102662   \n",
       "2     4  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]    376152.715194   \n",
       "0     2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]    368633.107902   \n",
       "\n",
       "   average_losses  average_lefts  average_operation_profits  \\\n",
       "7        0.155021       5.230233              383495.637367   \n",
       "6        1.149059       3.877559              382899.214102   \n",
       "5        2.034359       4.245825              382368.034523   \n",
       "4        2.064279       4.266980              382350.082454   \n",
       "3        2.370225       5.267789              382166.514857   \n",
       "1        3.828411       6.506134              381291.603090   \n",
       "2        3.449688       8.240773              381518.837063   \n",
       "0        7.010124      16.358481              379382.575099   \n",
       "\n",
       "                                        alpha_values  \\\n",
       "7  [-0.0029411303302361246, 0.0, 0.01855775453414...   \n",
       "6  [-0.004801392626435972, -2.5586293848821637, 0...   \n",
       "5  [-0.00970372751963152, 0.0, 0.0146592427080991...   \n",
       "4  [-0.011261536701351417, -2.734196246044146, 0....   \n",
       "3  [-0.005305759314962911, 0.0, 0.011876807058378...   \n",
       "1  [-0.002116512989443514, -3.9224777868970846, 0...   \n",
       "2  [-0.0036988938027179567, 0.0, 0.01161472109888...   \n",
       "0  [-0.01965229958295822, -2.539393477141857, -0....   \n",
       "\n",
       "                                              F_vars  \\\n",
       "7  [0.19449571510635813, 0.16962708883849945, 0.1...   \n",
       "6  [0.16776057173390893, 0.14855538111880867, 0.1...   \n",
       "5  [0.14445600745047515, 0.12593692735282694, 0.1...   \n",
       "4  [-1, 0.10494484987145875, 0.11335926971211249,...   \n",
       "3  [0.09482701534934591, 0.08506882287021005, 0.0...   \n",
       "1  [0.04674859818505727, 0.04154596528141269, 0.0...   \n",
       "2  [0.0710945912329621, 0.06408431053778382, 0.06...   \n",
       "0  [0.022738898856961204, 0.023682943918313947, 0...   \n",
       "\n",
       "                                              f_vars  \\\n",
       "7  [-1.4210582701389431, -1.5882709074070345, -1....   \n",
       "6  [-1.6015823791458685, -1.7459766329596234, -1....   \n",
       "5  [-1.778764975028339, -1.937371333495592, -1.85...   \n",
       "4  [-1, -2.143450363780167, -2.056877707963954, -...   \n",
       "3  [-2.256071727991101, -2.3753882364934142, -2.3...   \n",
       "1  [-3.015094399361634, -3.1385207696433084, -3.0...   \n",
       "2  [-2.5699956518995033, -2.6813258284941868, -2....   \n",
       "0  [-3.7606768002086604, -3.7190322630392907, -3....   \n",
       "\n",
       "                                             Q0_vars  \\\n",
       "7  [555.4668453817327, 484.4437003503325, 515.369...   \n",
       "6  [479.1130514598365, 424.2643025293473, 449.949...   \n",
       "5  [412.556763582564, 359.66750072354887, 387.346...   \n",
       "4  [-1, 299.71552157476344, 323.74654581634894, 3...   \n",
       "3  [270.81965813109275, 242.9509084774087, 256.64...   \n",
       "1  [133.5108917215579, 118.65251766901721, 125.09...   \n",
       "2  [203.0414309861898, 183.02053489158044, 192.40...   \n",
       "0  [64.94078498656665, 67.63691498532296, 69.1736...   \n",
       "\n",
       "                                             Q1_vars  \n",
       "7  [132.0706924296501, 112.51550325638364, 127.19...  \n",
       "6  [207.0106732339741, 172.75379644146693, 193.45...  \n",
       "5  [275.80786311812693, 242.8134936646951, 254.54...  \n",
       "4  [344.75461050864754, 302.7654728618728, 318.14...  \n",
       "3  [415.52207561588875, 358.3184828080911, 384.97...  \n",
       "1  [545.9304352503533, 496.5482255565382, 522.308...  \n",
       "2  [471.2946991819626, 434.3909029722712, 456.409...  \n",
       "0  [602.88453792509, 552.0890579016283, 603.08537...  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_2, stimulation_results_df_2 = None, None\n",
    "results_df_2, stimulation_results_df_2 = grid_flexible_F_fixed_R(\n",
    "    assigned_Ts=ASSIGNED_TS,\n",
    "    salvage_value=salvage_value,\n",
    "    cost=cost,\n",
    "    price=price,\n",
    "    Q_star=Q_star,\n",
    "    demand_df_train=demand_df_test,\n",
    "    Qk_hat_df_train=Qk_hat_df_test,\n",
    "    training_df=testing_df,\n",
    ")\n",
    "\n",
    "results_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_vars 中有 -1 的個數： 0\n"
     ]
    }
   ],
   "source": [
    "num_neg_ones = results_df_2.iloc[0][\"F_vars\"].count(-1)\n",
    "print(\"F_vars 中有 -1 的個數：\", num_neg_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2113.3908546916105)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_star * 0.74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "      <th>sum_first_8</th>\n",
       "      <th>sum</th>\n",
       "      <th>Lost_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.625929</td>\n",
       "      <td>67.884966</td>\n",
       "      <td>68.750730</td>\n",
       "      <td>68.558033</td>\n",
       "      <td>74.175914</td>\n",
       "      <td>68.558033</td>\n",
       "      <td>65.559446</td>\n",
       "      <td>71.308420</td>\n",
       "      <td>68.558033</td>\n",
       "      <td>68.558033</td>\n",
       "      <td>550.421472</td>\n",
       "      <td>687.537538</td>\n",
       "      <td>-5.045374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60.770111</td>\n",
       "      <td>61.058111</td>\n",
       "      <td>59.574148</td>\n",
       "      <td>60.117141</td>\n",
       "      <td>58.717761</td>\n",
       "      <td>60.117141</td>\n",
       "      <td>57.979551</td>\n",
       "      <td>58.390955</td>\n",
       "      <td>60.117144</td>\n",
       "      <td>60.117141</td>\n",
       "      <td>476.724919</td>\n",
       "      <td>596.959204</td>\n",
       "      <td>-7.718782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.073532</td>\n",
       "      <td>64.930685</td>\n",
       "      <td>65.683239</td>\n",
       "      <td>63.599781</td>\n",
       "      <td>63.459309</td>\n",
       "      <td>63.599781</td>\n",
       "      <td>64.215938</td>\n",
       "      <td>63.806809</td>\n",
       "      <td>63.599781</td>\n",
       "      <td>63.599781</td>\n",
       "      <td>515.369074</td>\n",
       "      <td>642.568635</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63.121389</td>\n",
       "      <td>66.381203</td>\n",
       "      <td>61.668540</td>\n",
       "      <td>67.299906</td>\n",
       "      <td>67.404706</td>\n",
       "      <td>67.299906</td>\n",
       "      <td>70.525694</td>\n",
       "      <td>68.097560</td>\n",
       "      <td>67.299908</td>\n",
       "      <td>67.299906</td>\n",
       "      <td>531.798904</td>\n",
       "      <td>666.398718</td>\n",
       "      <td>-10.278170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64.915095</td>\n",
       "      <td>62.604395</td>\n",
       "      <td>65.471782</td>\n",
       "      <td>61.716297</td>\n",
       "      <td>63.127936</td>\n",
       "      <td>61.716297</td>\n",
       "      <td>61.250627</td>\n",
       "      <td>60.709187</td>\n",
       "      <td>61.716291</td>\n",
       "      <td>61.716297</td>\n",
       "      <td>501.511615</td>\n",
       "      <td>624.944204</td>\n",
       "      <td>0.505709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   demand_t1  demand_t2  demand_t3  demand_t4  demand_t5  demand_t6  \\\n",
       "0  65.625929  67.884966  68.750730  68.558033  74.175914  68.558033   \n",
       "1  60.770111  61.058111  59.574148  60.117141  58.717761  60.117141   \n",
       "2  66.073532  64.930685  65.683239  63.599781  63.459309  63.599781   \n",
       "3  63.121389  66.381203  61.668540  67.299906  67.404706  67.299906   \n",
       "4  64.915095  62.604395  65.471782  61.716297  63.127936  61.716297   \n",
       "\n",
       "   demand_t7  demand_t8  demand_t9  demand_t10  sum_first_8         sum  \\\n",
       "0  65.559446  71.308420  68.558033   68.558033   550.421472  687.537538   \n",
       "1  57.979551  58.390955  60.117144   60.117141   476.724919  596.959204   \n",
       "2  64.215938  63.806809  63.599781   63.599781   515.369074  642.568635   \n",
       "3  70.525694  68.097560  67.299908   67.299906   531.798904  666.398718   \n",
       "4  61.250627  60.709187  61.716291   61.716297   501.511615  624.944204   \n",
       "\n",
       "      Lost_0  \n",
       "0  -5.045374  \n",
       "1  -7.718782  \n",
       "2   0.000002  \n",
       "3 -10.278170  \n",
       "4   0.505709  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df_test_analysis = demand_df_test.copy()\n",
    "demand_df_test_analysis[\"sum_first_8\"] = demand_df_test_analysis.iloc[:, :8].sum(axis=1)\n",
    "demand_df_test_analysis[\"sum\"] = demand_df_test_analysis.iloc[:, :10].sum(axis=1)\n",
    "\n",
    "demand_df_test_analysis[\"Lost_0\"] = (\n",
    "    demand_df_test_analysis[\"sum_first_8\"] - results_df_2.iloc[0][\"Q0_vars\"]\n",
    ")\n",
    "demand_df_test_analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "      <th>sum_first_8</th>\n",
       "      <th>sum</th>\n",
       "      <th>Lost_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.073532</td>\n",
       "      <td>64.930685</td>\n",
       "      <td>65.683239</td>\n",
       "      <td>63.599781</td>\n",
       "      <td>63.459309</td>\n",
       "      <td>63.599781</td>\n",
       "      <td>64.215938</td>\n",
       "      <td>63.806809</td>\n",
       "      <td>63.599781</td>\n",
       "      <td>63.599781</td>\n",
       "      <td>515.369074</td>\n",
       "      <td>642.568635</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64.915095</td>\n",
       "      <td>62.604395</td>\n",
       "      <td>65.471782</td>\n",
       "      <td>61.716297</td>\n",
       "      <td>63.127936</td>\n",
       "      <td>61.716297</td>\n",
       "      <td>61.250627</td>\n",
       "      <td>60.709187</td>\n",
       "      <td>61.716291</td>\n",
       "      <td>61.716297</td>\n",
       "      <td>501.511615</td>\n",
       "      <td>624.944204</td>\n",
       "      <td>0.505709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>62.564427</td>\n",
       "      <td>62.207089</td>\n",
       "      <td>62.998637</td>\n",
       "      <td>61.999965</td>\n",
       "      <td>61.345170</td>\n",
       "      <td>61.999965</td>\n",
       "      <td>64.147963</td>\n",
       "      <td>63.211996</td>\n",
       "      <td>61.999964</td>\n",
       "      <td>61.999965</td>\n",
       "      <td>500.475214</td>\n",
       "      <td>624.475143</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>65.746933</td>\n",
       "      <td>65.853934</td>\n",
       "      <td>70.574162</td>\n",
       "      <td>62.239247</td>\n",
       "      <td>55.130102</td>\n",
       "      <td>62.239247</td>\n",
       "      <td>57.888206</td>\n",
       "      <td>63.679955</td>\n",
       "      <td>62.239243</td>\n",
       "      <td>62.239247</td>\n",
       "      <td>503.351787</td>\n",
       "      <td>627.830276</td>\n",
       "      <td>1.819598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>62.577572</td>\n",
       "      <td>67.210049</td>\n",
       "      <td>65.172995</td>\n",
       "      <td>67.044144</td>\n",
       "      <td>70.357863</td>\n",
       "      <td>67.044144</td>\n",
       "      <td>68.535449</td>\n",
       "      <td>70.440907</td>\n",
       "      <td>67.044145</td>\n",
       "      <td>67.044144</td>\n",
       "      <td>538.383124</td>\n",
       "      <td>672.471413</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    demand_t1  demand_t2  demand_t3  demand_t4  demand_t5  demand_t6  \\\n",
       "2   66.073532  64.930685  65.683239  63.599781  63.459309  63.599781   \n",
       "4   64.915095  62.604395  65.471782  61.716297  63.127936  61.716297   \n",
       "7   62.564427  62.207089  62.998637  61.999965  61.345170  61.999965   \n",
       "10  65.746933  65.853934  70.574162  62.239247  55.130102  62.239247   \n",
       "13  62.577572  67.210049  65.172995  67.044144  70.357863  67.044144   \n",
       "\n",
       "    demand_t7  demand_t8  demand_t9  demand_t10  sum_first_8         sum  \\\n",
       "2   64.215938  63.806809  63.599781   63.599781   515.369074  642.568635   \n",
       "4   61.250627  60.709187  61.716291   61.716297   501.511615  624.944204   \n",
       "7   64.147963  63.211996  61.999964   61.999965   500.475214  624.475143   \n",
       "10  57.888206  63.679955  62.239243   62.239247   503.351787  627.830276   \n",
       "13  68.535449  70.440907  67.044145   67.044144   538.383124  672.471413   \n",
       "\n",
       "      Lost_0  \n",
       "2   0.000002  \n",
       "4   0.505709  \n",
       "7   0.000001  \n",
       "10  1.819598  \n",
       "13  0.000000  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df_test_analysis[demand_df_test_analysis[\"Lost_0\"] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R(T)                                                                         9\n",
       "R                                [7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
       "average_profits                                                  381310.531607\n",
       "average_losses                                                        0.155021\n",
       "average_lefts                                                         5.230233\n",
       "average_operation_profits                                        383495.637367\n",
       "alpha_values                 [-0.0029411303302361246, 0.0, 0.01855775453414...\n",
       "F_vars                       [0.19449571510635813, 0.16962708883849945, 0.1...\n",
       "f_vars                       [-1.4210582701389431, -1.5882709074070345, -1....\n",
       "Q0_vars                      [555.4668453817327, 484.4437003503325, 515.369...\n",
       "Q1_vars                      [132.0706924296501, 112.51550325638364, 127.19...\n",
       "Name: 7, dtype: object"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demand_df_test_analysis.head()\n",
    "results_df_2.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00294113,  0.        ,  0.01855775, -2.64702674])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_values = results_df_2.iloc[0][\"alpha_values\"]\n",
    "alpha_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++++++++++++++++++++++ THis is R=0 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x1b182bdd\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [3e+02, 3e+03]\n",
      "Presolve removed 62 rows and 97 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 231 rows, 167 columns, 612 nonzeros\n",
      "Presolved model has 41 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 126 continuous, 41 integer (41 binary)\n",
      "\n",
      "Root relaxation: objective 2.526280e+07, 96 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5263e+07    0   24          - 2.5263e+07      -     -    0s\n",
      "H    0     0                    1.837560e+07 2.5263e+07  37.5%     -    0s\n",
      "     0     2 2.5263e+07    0   23 1.8376e+07 2.5263e+07  37.5%     -    0s\n",
      "H   47    42                    2.521248e+07 2.5247e+07  0.14%   3.1    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 6\n",
      "\n",
      "Explored 55 nodes (258 simplex iterations) in 0.02 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 2.52125e+07 1.83756e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.521248454498e+07, best bound 2.524682906173e+07, gap 0.1362%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.060053955115222, Left1: 36.98013902744424\n",
      "f_train: -2.1879092390044566, F_train: 0.10084150994459902, Q0_train: 287.9966552570387\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.787564348438821, Left1: 17.65883923238772\n",
      "f_train: -2.1935481437537554, F_train: 0.10033136594714728, Q0_train: 286.53971788029503\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 23.950137039603305, Left0: 9.872340148496908, Left1: 0.0\n",
      "f_train: -2.177579615911198, F_train: 0.10178199208539633, Q0_train: 290.68260979131145\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 6.515511457487264, Left1: 1.1929361545426218\n",
      "f_train: -2.1832470233647334, F_train: 0.1012650320831993, Q0_train: 289.2062063576837\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 18.52839886017364, Left0: 12.738649214080937, Left1: 0.0\n",
      "f_train: -2.2091865780015167, F_train: 0.09892855934560975, Q0_train: 282.53339539030793\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 27.037615877432472, Left0: 3.2888684533512365, Left1: 0.0\n",
      "f_train: -2.159526722746368, F_train: 0.10344433666010124, Q0_train: 295.43015549607844\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 10.330585983085257, Left0: 10.800221369836542, Left1: 0.0\n",
      "f_train: -2.2227643965641244, F_train: 0.09772478339015149, Q0_train: 279.0954912073848\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.807816447849632, Left1: 5.711934684325456\n",
      "f_train: -2.2109205403091607, F_train: 0.09877409845606026, Q0_train: 282.09226534790065\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 18.63196479163662\n",
      "f_train: -2.1590302726288435, F_train: 0.10349038829938181, Q0_train: 295.56167591945564\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 9.624653434906463\n",
      "f_train: -2.174174930531133, F_train: 0.10209367894210351, Q0_train: 291.5727667541392\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1.0722277325696912, Left1: 35.7239876263352\n",
      "f_train: -2.178542605490295, F_train: 0.10169398700437146, Q0_train: 290.4312731245488\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 15.167211664113097, Left1: 24.802197373810486\n",
      "f_train: -2.2421444031504554, F_train: 0.09602922985746526, Q0_train: 274.2531029241157\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.8846871863621004, Lost1: 8.3115379161577, Left0: 0.0, Left1: 0.0\n",
      "f_train: -2.165624568849525, F_train: 0.10288016641264773, Q0_train: 293.8189227373523\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1.0085534925042383, Left1: 24.290380924166584\n",
      "f_train: -2.183203589269767, F_train: 0.10126898510711792, Q0_train: 289.2174959314647\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 6.286913241360878, Left0: 0.0, Left1: 0.0\n",
      "f_train: -2.1499682164789147, F_train: 0.10433419320622409, Q0_train: 297.9715266941372\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=1 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xe813c422\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [5e+02, 2e+03]\n",
      "Presolve removed 55 rows and 83 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 238 rows, 181 columns, 635 nonzeros\n",
      "Presolved model has 47 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 134 continuous, 47 integer (47 binary)\n",
      "\n",
      "Root relaxation: objective 2.539216e+07, 96 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5392e+07    0   27          - 2.5392e+07      -     -    0s\n",
      "H    0     0                    2.021465e+07 2.5392e+07  25.6%     -    0s\n",
      "     0     2 2.5392e+07    0   25 2.0215e+07 2.5392e+07  25.6%     -    0s\n",
      "H    9     8                    2.496805e+07 2.5390e+07  1.69%   2.1    0s\n",
      "H   69    48                    2.535098e+07 2.5388e+07  0.15%   5.0    0s\n",
      "H   78    48                    2.536595e+07 2.5388e+07  0.09%   5.1    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 7\n",
      "\n",
      "Explored 93 nodes (565 simplex iterations) in 0.03 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 4: 2.53659e+07 2.5351e+07 2.49681e+07 2.02146e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.536594985536e+07, best bound 2.538816320492e+07, gap 0.0876%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1.6509233943988875, Left1: 1.332026656104972\n",
      "f_train: -1.399599587920067, F_train: 0.19787965847949895, Q0_train: 565.1311629190166\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 3.5445045182577815, Left1: 4.179683795646724\n",
      "f_train: -1.4042791069146987, F_train: 0.19713795973656073, Q0_train: 563.0129205673113\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.4943610967070526, Left0: 7.606436190936964, Left1: 0.0\n",
      "f_train: -1.3865350410105632, F_train: 0.19996149399796434, Q0_train: 571.076746899688\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.628808079755117, Left1: 3.807774725673653\n",
      "f_train: -1.3890585587017643, F_train: 0.19955809512199388, Q0_train: 569.9246665006762\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.724340443913093, Left1: 6.702636206277816\n",
      "f_train: -1.4308699410270553, F_train: 0.19296317353322526, Q0_train: 551.0900084289033\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.845951177695952, Left0: 3.3958092645252993, Left1: 0.0\n",
      "f_train: -1.3448412741277287, F_train: 0.20671504011846142, Q0_train: 590.3644260994131\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.936046206859146, Left1: 0.8369143515958513\n",
      "f_train: -1.4455070180978027, F_train: 0.19069400356661037, Q0_train: 544.6094097056807\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 8.565508626546034, Left0: 4.967379547359613, Left1: 0.0\n",
      "f_train: -1.430970975329678, F_train: 0.19294744011231044, Q0_train: 551.0450748236676\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 7.223925849980674\n",
      "f_train: -1.345282438128392, F_train: 0.20664270567113363, Q0_train: 590.1578437217621\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.2752086234244143, Lost1: 2.146915156855357, Left0: 0.0, Left1: 0.0\n",
      "f_train: -1.363643764037441, F_train: 0.20364873333268418, Q0_train: 581.6072575605747\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.40495027274846507, Lost1: 0.19055914424596293, Left0: 0.0, Left1: 0.0\n",
      "f_train: -1.379825222153968, F_train: 0.2010370713053023, Q0_train: 574.1485242575825\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 10.690312559156837, Left1: 4.161348693613036\n",
      "f_train: -1.4911217770574734, F_train: 0.18375341452047714, Q0_train: 524.7875483323418\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.6376606011212971, Left0: 0.0, Left1: 0.0\n",
      "f_train: -1.3441723976322357, F_train: 0.20682474663361253, Q0_train: 590.6777406207921\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 3.1138721000688747\n",
      "f_train: -1.3803212737835224, F_train: 0.20095740672951254, Q0_train: 573.9210075198569\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1.0910902037981007, Left1: 6.785318866206467\n",
      "f_train: -1.3264902597002663, F_train: 0.20974051003249516, Q0_train: 599.0049672446341\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=2 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xc51f1d70\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [8e+02, 2e+03]\n",
      "Presolve removed 55 rows and 83 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 238 rows, 181 columns, 635 nonzeros\n",
      "Presolved model has 47 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 134 continuous, 47 integer (47 binary)\n",
      "\n",
      "Root relaxation: objective 2.539194e+07, 97 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5392e+07    0   27          - 2.5392e+07      -     -    0s\n",
      "H    0     0                    2.192218e+07 2.5392e+07  15.8%     -    0s\n",
      "     0     2 2.5392e+07    0   25 2.1922e+07 2.5392e+07  15.8%     -    0s\n",
      "H    9     8                    2.491100e+07 2.5390e+07  1.92%   1.7    0s\n",
      "H   29    26                    2.491100e+07 2.5389e+07  1.92%   6.4    0s\n",
      "H   30    26                    2.491100e+07 2.5389e+07  1.92%   6.3    0s\n",
      "H  144   100                    2.521362e+07 2.5388e+07  0.69%   6.4    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 7\n",
      "\n",
      "Explored 173 nodes (1294 simplex iterations) in 0.03 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 5: 2.52136e+07 2.4911e+07 2.4911e+07 ... 2.19222e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.521361505711e+07, best bound 2.538784799529e+07, gap 0.6910%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.986591430260887, Left1: 1.6894784176856774\n",
      "f_train: -0.8476911853568848, F_train: 0.2999174082545109, Q0_train: 856.5441996863425\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 18.204039374747026, Left1: 4.821362397714438\n",
      "f_train: -0.8382319449278091, F_train: 0.30190728744437584, Q0_train: 862.2271624995881\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.8577910975809573, Left0: 7.592916616946465, Left1: 0.0\n",
      "f_train: -0.8538482942034122, F_train: 0.2986262135902069, Q0_train: 852.8566334766579\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 12.014630966228651, Left1: 3.8131883063683745\n",
      "f_train: -0.838921284046026, F_train: 0.30176202267215335, Q0_train: 861.8122959575288\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 45.71257714245439, Left1: 6.4102002592935605\n",
      "f_train: -0.8458489750068168, F_train: 0.3003043540714707, Q0_train: 857.6492912415101\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 8.702107413295266, Lost1: 0.0, Left0: 0.0, Left1: 3.9300240147216465\n",
      "f_train: -0.8177087193907926, F_train: 0.3062502515136345, Q0_train: 874.6303794539468\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 57.35193698082935, Left1: 1.389254652016234\n",
      "f_train: -0.8314504970664722, F_train: 0.30333845757963135, Q0_train: 866.3144893581782\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 8.244358266112158, Left0: 39.426399749246, Left1: 0.0\n",
      "f_train: -0.839613378815391, F_train: 0.3016162171349419, Q0_train: 861.3958850265747\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 12.665166813674261, Lost1: 0.0, Left0: 0.0, Left1: 19.474710993618224\n",
      "f_train: -0.8206629650754492, F_train: 0.3056229489323628, Q0_train: 872.838844942617\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.1637467407099393, Left0: 8.29925951450744, Left1: 0.0\n",
      "f_train: -0.8096636359912373, F_train: 0.30796217746086874, Q0_train: 879.5195262658308\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.26522495544134017, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_train: -0.8335609881340829, F_train: 0.30289264486465384, Q0_train: 865.0412778517746\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 72.67706537401318, Left1: 3.6910013991255255\n",
      "f_train: -0.8723752701545531, F_train: 0.29476029816972044, Q0_train: 841.8158357811614\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.4351419070092106, Left0: 0.0, Left1: 0.0\n",
      "f_train: -0.7932331719027953, F_train: 0.3114748666589204, Q0_train: 889.5515333287177\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 15.618625076689796, Left1: 2.413551467104867\n",
      "f_train: -0.8173575307492139, F_train: 0.3063248704924017, Q0_train: 874.8434863016672\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 21.04630347741471, Lost1: 0.0, Left0: 0.0, Left1: 28.243486925168895\n",
      "f_train: -0.8078356498616128, F_train: 0.3083518972602533, Q0_train: 880.6325401305762\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=3 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xc90c97b0\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 2e+03]\n",
      "Presolve removed 52 rows and 65 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 241 rows, 199 columns, 647 nonzeros\n",
      "Presolved model has 62 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 137 continuous, 62 integer (62 binary)\n",
      "\n",
      "Root relaxation: objective 2.539194e+07, 104 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5392e+07    0   27          - 2.5392e+07      -     -    0s\n",
      "H    0     0                    2.361692e+07 2.5392e+07  7.52%     -    0s\n",
      "     0     2 2.5392e+07    0   24 2.3617e+07 2.5392e+07  7.52%     -    0s\n",
      "H    9     8                    2.489699e+07 2.5390e+07  1.98%   1.8    0s\n",
      "H   36    38                    2.489699e+07 2.5389e+07  1.97%   8.0    0s\n",
      "H   74    68                    2.535666e+07 2.5388e+07  0.12%   6.6    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 5\n",
      "\n",
      "Explored 93 nodes (755 simplex iterations) in 0.04 seconds (0.03 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 4: 2.53567e+07 2.4897e+07 2.4897e+07 2.36169e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.535666184250e+07, best bound 2.538784802657e+07, gap 0.1230%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1.7423521889034261, Left1: 1.689478064302905\n",
      "f_train: -0.4237795124487773, F_train: 0.39561270066634363, Q0_train: 1129.8435994433787\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.7965952452939622, Left1: 4.821362451091578\n",
      "f_train: -0.43302550969091613, F_train: 0.3934040996881462, Q0_train: 1123.5359817285334\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.8577912144478432, Left0: 17.204999793589177, Left1: 0.0\n",
      "f_train: -0.40144683628825706, F_train: 0.4009647716100944, Q0_train: 1145.128758613897\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 8.150148062594791, Left1: 3.8131884187810208\n",
      "f_train: -0.40812177321406473, F_train: 0.39936257009327103, Q0_train: 1140.552977488184\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 11.54146729874531, Left1: 6.410200437849134\n",
      "f_train: -0.4750170240611684, F_train: 0.3834294707900621, Q0_train: 1095.049104036434\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.7720833550229145, Left0: 9.528169538898698, Left1: 0.0\n",
      "f_train: -0.33976398603849756, F_train: 0.4158668088165124, Q0_train: 1187.687987192705\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 1.3892544946293128\n",
      "f_train: -0.5013269285821393, F_train: 0.37722888636428364, Q0_train: 1077.3406467132131\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 8.244358316867874, Left0: 0.45178284005530245, Left1: 0.0\n",
      "f_train: -0.47625330971500124, F_train: 0.3831372410287377, Q0_train: 1094.2145152458236\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.441684055039726, Left1: 6.8095440614731615\n",
      "f_train: -0.3399746115021567, F_train: 0.41581564424744166, Q0_train: 1187.54186458141\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.1637465616656755, Left0: 4.018326786193496, Left1: 0.0\n",
      "f_train: -0.37176487236986544, F_train: 0.40811463511679075, Q0_train: 1165.5482939481474\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.26522452100582955, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_train: -0.3940074549680126, F_train: 0.40275296088390306, Q0_train: 1150.2357084216333\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 8.45930608160535, Left1: 3.691001444577809\n",
      "f_train: -0.5685722821935666, F_train: 0.3615663285075837, Q0_train: 1032.6094216653375\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.43514184545324497, Left0: 0.0, Left1: 0.0\n",
      "f_train: -0.3428815861511143, F_train: 0.4151096755943247, Q0_train: 1185.5256649933067\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 2.831490205266965, Left1: 2.413551206114107\n",
      "f_train: -0.39760024397686555, F_train: 0.40188904336105635, Q0_train: 1147.7684173513737\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.666494391596925, Left1: 7.197183336380476\n",
      "f_train: -0.31157801870617674, F_train: 0.4227296092081473, Q0_train: 1207.2876893349417\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=4 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x64029659\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 1e+03]\n",
      "Presolve removed 56 rows and 73 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 237 rows, 191 columns, 639 nonzeros\n",
      "Presolved model has 58 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 133 continuous, 58 integer (58 binary)\n",
      "\n",
      "Root relaxation: objective 2.540358e+07, 95 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5404e+07    0   25          - 2.5404e+07      -     -    0s\n",
      "H    0     0                    2.483526e+07 2.5404e+07  2.29%     -    0s\n",
      "     0     2 2.5404e+07    0   22 2.4835e+07 2.5404e+07  2.29%     -    0s\n",
      "H   33    32                    2.483526e+07 2.5401e+07  2.28%  13.0    0s\n",
      "H   69    55                    2.532089e+07 2.5401e+07  0.32%   8.8    0s\n",
      "H   70    55                    2.535289e+07 2.5401e+07  0.19%   8.6    0s\n",
      "H   86    55                    2.535765e+07 2.5401e+07  0.17%   8.0    0s\n",
      "H   88    55                    2.536047e+07 2.5401e+07  0.16%   7.9    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 9\n",
      "\n",
      "Explored 93 nodes (808 simplex iterations) in 0.04 seconds (0.03 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 6: 2.53605e+07 2.53576e+07 2.53529e+07 ... 2.48353e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.536046510641e+07, best bound 2.540086163672e+07, gap 0.1593%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.044270626615343645, Left0: 1.5551930550016095, Left1: 0.0\n",
      "f_train: -0.02994513100064644, F_train: 0.4925142766189395, Q0_train: 1406.5880648804334\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1.314470559241954, Left1: 3.9735896354927718\n",
      "f_train: -0.037670637383447225, F_train: 0.49058345419470406, Q0_train: 1401.0737642677136\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 12.256071376458749, Left1: 0.2542948950626851\n",
      "f_train: -0.0053505744110315945, F_train: 0.4986623595884768, Q0_train: 1424.1465815313868\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.55430382009463, Left1: 1.4142064545967514\n",
      "f_train: -0.008048488865982417, F_train: 0.4979878886452341, Q0_train: 1422.2203373108403\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 11.458920189726769, Left1: 2.2199238035420876\n",
      "f_train: -0.09073967297565577, F_train: 0.4773306339963847, Q0_train: 1363.2245899352806\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 10.310771817111522, Left1: 1.208751934558677\n",
      "f_train: 0.08147580098721852, F_train: 0.5203576897778212, Q0_train: 1486.1070037093261\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 1.0641162352530955\n",
      "f_train: -0.1171738815569503, F_train: 0.4707399995834241, Q0_train: 1344.4021757528933\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.022285338199907, Lost1: 5.775496615093516, Left0: 0.0, Left1: 0.0\n",
      "f_train: -0.09000525564589079, F_train: 0.4775138639539651, Q0_train: 1363.7478825253563\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 11.176598692590892, Left1: 7.57986390964993\n",
      "f_train: 0.08017279604745342, F_train: 0.5200324699736046, Q0_train: 1485.1781975471697\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 5.026929325021456, Left0: 11.264008407266308, Left1: 0.0\n",
      "f_train: 0.045957364730821126, F_train: 0.5114873194096753, Q0_train: 1460.7738150420735\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 2.601641160733152\n",
      "f_train: 0.01078481022265354, F_train: 0.5026961764225452, Q0_train: 1435.6668945133072\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 3.9287458972503373\n",
      "f_train: -0.21237281761989601, F_train: 0.4471054514154814, Q0_train: 1276.903475816544\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.7437060145430223, Left0: 9.369774183822505, Left1: 0.0\n",
      "f_train: 0.08643926956538461, F_train: 0.5215963721792425, Q0_train: 1489.6445983836927\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 8.59984712088383, Left1: 0.6543544472428948\n",
      "f_train: 0.01223718867184953, F_train: 0.5030592589913642, Q0_train: 1436.7038342166045\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 14.131323021803258, Left1: 2.0456162854748072\n",
      "f_train: 0.11878988395799528, F_train: 0.5296625983560724, Q0_train: 1512.6812046458365\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=5 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xf0ec38b8\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 2e+03]\n",
      "Presolve removed 56 rows and 73 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 237 rows, 191 columns, 639 nonzeros\n",
      "Presolved model has 58 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 133 continuous, 58 integer (58 binary)\n",
      "\n",
      "Root relaxation: objective 2.540358e+07, 95 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5404e+07    0   25          - 2.5404e+07      -     -    0s\n",
      "H    0     0                    1.898036e+07 2.5404e+07  33.8%     -    0s\n",
      "     0     2 2.5404e+07    0   22 1.8980e+07 2.5404e+07  33.8%     -    0s\n",
      "H    9     8                    2.174246e+07 2.5402e+07  16.8%   1.8    0s\n",
      "H   70    68                    2.535152e+07 2.5401e+07  0.19%   2.8    0s\n",
      "H   86    68                    2.536316e+07 2.5401e+07  0.15%   2.7    0s\n",
      "H   92    68                    2.536430e+07 2.5401e+07  0.14%   2.6    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 4\n",
      "\n",
      "Explored 93 nodes (333 simplex iterations) in 0.03 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 5: 2.53643e+07 2.53632e+07 2.53515e+07 ... 1.89804e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.536429829810e+07, best bound 2.540086183113e+07, gap 0.1442%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.044270701084769826, Left0: 2.5483635889604557, Left1: 0.0\n",
      "f_train: 0.36704078496510384, F_train: 0.5907437346959709, Q0_train: 1687.1248734767996\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1.92551611844965, Left1: 3.973589645122729\n",
      "f_train: 0.3573112491020951, F_train: 0.5883894078177072, Q0_train: 1680.4010722693984\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 13.33222912878955, Left1: 0.25429486149232616\n",
      "f_train: 0.39718890918400174, F_train: 0.5980120783616643, Q0_train: 1707.882780276573\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 10.002617754750418, Left1: 1.414206508322195\n",
      "f_train: 0.39339019976672907, F_train: 0.5970985537816518, Q0_train: 1705.2738147455805\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 12.329472571243969, Left1: 2.2199238678497295\n",
      "f_train: 0.29297998391379076, F_train: 0.5727255253037942, Q0_train: 1635.6660640884961\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 8.169172297504705, Left1: 1.2087519381427683\n",
      "f_train: 0.5016247220997063, F_train: 0.62284107089077, Q0_train: 1778.7927339822734\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 1.0641161758576345\n",
      "f_train: 0.2603084147870809, F_train: 0.5647121054770834, Q0_train: 1612.7802692552866\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.4229605964503662, Lost1: 6.3748213641806615, Left0: 0.0, Left1: 0.0\n",
      "f_train: 0.29365880430351243, F_train: 0.5728916319121468, Q0_train: 1636.1404535303827\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.199138997555687, Left1: 7.579863854253517\n",
      "f_train: 0.5001406477588226, F_train: 0.6224923833779578, Q0_train: 1777.7969056029185\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 5.026929269582297, Left0: 9.631074763593206, Left1: 0.0\n",
      "f_train: 0.45811526227258614, F_train: 0.6125669688385352, Q0_train: 1749.450580850704\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 2.6016412696092175\n",
      "f_train: 0.4161286176776411, F_train: 0.602556491954094, Q0_train: 1720.861323690326\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 3.9287458978493532\n",
      "f_train: 0.14584683730322645, F_train: 0.5363972141822371, Q0_train: 1531.9148201821579\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.7437060246500096, Left0: 6.028233533303869, Left1: 0.0\n",
      "f_train: 0.5068218475528581, F_train: 0.6240611463342195, Q0_train: 1782.2771884204085\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.8719701406432705, Left1: 0.654354382480733\n",
      "f_train: 0.41733748815867333, F_train: 0.6028459589526035, Q0_train: 1721.6880222138193\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 10.37050197328958, Left1: 2.045616279306614\n",
      "f_train: 0.546701721532505, F_train: 0.6333700271927953, Q0_train: 1808.8627339257166\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=6 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xe84dbc9b\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [8e+02, 2e+03]\n",
      "Presolve removed 53 rows and 91 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 240 rows, 173 columns, 650 nonzeros\n",
      "Presolved model has 37 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 136 continuous, 37 integer (37 binary)\n",
      "\n",
      "Root relaxation: objective 2.540900e+07, 89 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5409e+07    0   20          - 2.5409e+07      -     -    0s\n",
      "H    0     0                    1.223711e+07 2.5409e+07   108%     -    0s\n",
      "     0     2 2.5409e+07    0   20 1.2237e+07 2.5409e+07   108%     -    0s\n",
      "H   55    56                    2.173796e+07 2.5407e+07  16.9%   4.9    0s\n",
      "H   72    72                    2.509978e+07 2.5407e+07  1.22%   4.5    0s\n",
      "H  479   222                    2.535130e+07 2.5407e+07  0.22%   5.5    0s\n",
      "H  489   222                    2.536761e+07 2.5407e+07  0.16%   5.5    0s\n",
      "\n",
      "Explored 567 nodes (2996 simplex iterations) in 0.11 seconds (0.05 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 5: 2.53676e+07 2.53513e+07 2.50998e+07 ... 1.22371e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Warning: max constraint violation (1.5285e-06) exceeds tolerance\n",
      "Best objective 2.536761404879e+07, best bound 2.540694491852e+07, gap 0.1550%\n",
      "Model status: 2\n",
      "Lost0: 1.0975872678472456, Lost1: 0.0, Left0: 0.0, Left1: 3.852612831301883\n",
      "f_train: 0.7876779796516375, F_train: 0.6873325304605233, Q0_train: 1962.9760594693416\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 8.15747127220095, Left1: 1.7603474818016593\n",
      "f_train: 0.7806481020348484, F_train: 0.6858197779532377, Q0_train: 1958.655738774329\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 3.604562260927062, Left1: 1.3033977922208153\n",
      "f_train: 0.8192335291181516, F_train: 0.6940736153959218, Q0_train: 1982.2281503520044\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.19354760015891, Left1: 0.9206417650101353\n",
      "f_train: 0.8212304346376293, F_train: 0.6944974647894093, Q0_train: 1983.4386360708734\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 14.447266869500027, Left1: 2.951072865084143\n",
      "f_train: 0.7045531965858594, F_train: 0.6691965002472907, Q0_train: 1911.1807616408867\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.28398810024060595, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_train: 0.95280108101753, F_train: 0.7216781489921037, Q0_train: 2061.0648650144344\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 14.54661797299525, Left1: 0.3803585621859611\n",
      "f_train: 0.6736173991749497, F_train: 0.6623126815727037, Q0_train: 1891.5210326784172\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.7670031726120214, Left0: 5.501912956215163, Left1: 0.0\n",
      "f_train: 0.7079541475178357, F_train: 0.6699489437051135, Q0_train: 1913.3296901847182\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 3.1662774761463197, Lost1: 0.0, Left0: 0.0, Left1: 9.887902856052829\n",
      "f_train: 0.9498728654500632, F_train: 0.7210896095191404, Q0_train: 2059.3840353660753\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.5674106742207528, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_train: 0.906905557421009, F_train: 0.7123665269530813, Q0_train: 2034.4714908798198\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.4955650748287326, Lost1: 0.0, Left0: 0.0, Left1: 3.3151568033743617\n",
      "f_train: 0.849252917530388, F_train: 0.7004104013977106, Q0_train: 2000.325590330813\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 8.395986537704061, Left1: 2.0935091230876424\n",
      "f_train: 0.5266720719304177, F_train: 0.6287065916862393, Q0_train: 1795.544271829771\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.3319747420901535, Lost1: 0.0, Left0: 0.0, Left1: 1.664436137260124\n",
      "f_train: 0.9690194845258606, F_train: 0.7249240171240106, Q0_train: 2070.334848832687\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.6519827042103543, Left0: 7.9716679073427485, Left1: 0.0\n",
      "f_train: 0.8574615973856385, F_train: 0.7021300366069886, Q0_train: 2005.2367542831018\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.2894128340340103, Left0: 0.0, Left1: 0.0\n",
      "f_train: 1.0080353553656085, F_train: 0.7326354891463832, Q0_train: 2092.358300789839\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=7 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xd3f70659\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [5e+02, 2e+03]\n",
      "Presolve removed 53 rows and 90 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 240 rows, 174 columns, 639 nonzeros\n",
      "Presolved model has 38 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 136 continuous, 38 integer (38 binary)\n",
      "Found heuristic solution: objective 2.524514e+07\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.02 seconds (0.00 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.52451e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.524514127959e+07, best bound 2.542797509868e+07, gap 0.7242%\n",
      "Model status: 2\n",
      "Lost0: 10.014793751860907, Lost1: 0.0, Left0: 0.0, Left1: 10.014794055471384\n",
      "f_train: 1.2735057752192374, F_train: 0.7813422881235575, Q0_train: 2231.4616839245186\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.19434734856668, Lost1: 0.0, Left0: 0.0, Left1: 2.194347591066048\n",
      "f_train: 1.2639080959099358, F_train: 0.7796981310568509, Q0_train: 2226.7660805347155\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 8.019705899363451, Lost1: 0.0, Left0: 0.0, Left1: 8.019706174674411\n",
      "f_train: 1.3229970866771303, F_train: 0.7896799114746096, Q0_train: 2255.2733824920547\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.2548893336885874e-06, Lost1: 0.0, Left0: 0.0, Left1: 1.4747593013453297e-06\n",
      "f_train: 1.3288332138194239, F_train: 0.7906475691772322, Q0_train: 2258.036948626101\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.8983678273798432e-06, Lost1: 0.0, Left0: 0.0, Left1: 2.1154513092369598e-06\n",
      "f_train: 1.1405956301493223, F_train: 0.7577889806308682, Q0_train: 2164.19500196129\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 8.02143225400214, Lost1: 0.0, Left0: 0.0, Left1: 8.021432500755328\n",
      "f_train: 1.5434645320255003, F_train: 0.8239678019434487, Q0_train: 2353.197320523828\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 7.374830386837213, Lost1: 0.0, Left0: 0.0, Left1: 7.374830675329463\n",
      "f_train: 1.0935527217199956, F_train: 0.7490501317430419, Q0_train: 2139.23742990715\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 19.10624018125054, Lost1: 0.0, Left0: 0.0, Left1: 19.10624044143026\n",
      "f_train: 1.1471477127000993, F_train: 0.7589895494625019, Q0_train: 2167.6237468115637\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.9516384752103686, Lost1: 0.0, Left0: 0.0, Left1: 0.951638760791705\n",
      "f_train: 1.5382495004756453, F_train: 0.8232101100001037, Q0_train: 2351.0334026539103\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 5.00089999272268, Lost1: 0.0, Left0: 0.0, Left1: 5.00090021878683\n",
      "f_train: 1.471321922405397, F_train: 0.81325822857909, Q0_train: 2322.6114902456056\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 9.03290474494483, Lost1: 0.0, Left0: 0.0, Left1: 9.032904927264866\n",
      "f_train: 1.374695036554698, F_train: 0.7981376483438661, Q0_train: 2279.428117290534\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 40.103057717502644, Lost1: 0.0, Left0: 0.0, Left1: 40.10305796655007\n",
      "f_train: 0.8507980533747093, F_train: 0.7007345255812077, Q0_train: 2001.2512674729578\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.40013623403623, Lost1: 0.0, Left0: 0.0, Left1: 2.400136497735579\n",
      "f_train: 1.573781215115587, F_train: 0.8283219824623304, Q0_train: 2365.6325709133966\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.0887470125453547e-06, Lost1: 0.0, Left0: 0.0, Left1: 1.3741884004048188e-06\n",
      "f_train: 1.3907129803011866, F_train: 0.8007060420010472, Q0_train: 2286.763279001797\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.0509214115930603, Lost1: 0.0, Left0: 0.0, Left1: 2.0509216658473064\n",
      "f_train: 1.6337391391027172, F_train: 0.8366812196993645, Q0_train: 2389.5059973038633\n",
      "f_train, F_train, Q0_train 都相等\n",
      "alphas: [-1.65736165e-03  0.00000000e+00  1.07394290e-02 -2.18359061e+00]\n",
      "==================================================\n",
      "X_train: [18.626271399098204, 0.0, 279.54363806240866, 1]\n",
      "f_train: 0.7876779796516375, demand_trian: 2800.5637571324673, F_train: 0.6873325304605233, Q0_train: 1962.9760594693416\n",
      "X_test: [15.747241523289969, 1.0, 68.5580334239261, 1]\n",
      "f_test: -1.4734153519782758, demand_test: 687.5375378113828, F_test: 0.18642405224547978 ,Q0_test: 532.4147123110107\n",
      "==================================================\n",
      "X_train: [17.506621909633513, 0.0, 278.7162624424789, 1]\n",
      "f_train: 0.7806481020348484, demand_trian: 2786.392968239322, F_train: 0.6858197779532377, Q0_train: 1958.655738774329\n",
      "X_test: [19.340630286841073, 1.0, 60.117140841850016, 1]\n",
      "f_test: -1.5700212634668402, demand_test: 596.9592036067162, F_test: 0.1722133604796949 ,Q0_test: 491.8299203966173\n",
      "==================================================\n",
      "X_train: [19.78041817361612, 0.0, 282.6600409928567, 1]\n",
      "f_train: 0.8192335291181516, demand_trian: 2828.613174489932, F_train: 0.6940736153959218, Q0_train: 1982.2281503520044\n",
      "X_test: [15.812464673381875, 1.0, 63.599780644783635, 1]\n",
      "f_test: -1.5267722541127557, demand_test: 642.5686349943295, F_test: 0.17846643447126123 ,Q0_test: 509.6882844337609\n",
      "==================================================\n",
      "X_train: [18.21995099614819, 0.0, 282.6051635000845, 1]\n",
      "f_train: 0.8212304346376293, demand_trian: 2823.2472727362383, F_train: 0.6944974647894093, Q0_train: 1983.4386360708734\n",
      "X_test: [18.07779782141922, 1.0, 67.29990562424058, 1]\n",
      "f_test: -1.4907895008161036, demand_test: 666.3987180210572, F_test: 0.18380325723873123 ,Q0_test: 524.929895825492\n",
      "==================================================\n",
      "X_train: [17.1192752427909, 0.0, 271.5709217716987, 1]\n",
      "f_train: 0.7045531965858594, demand_trian: 2707.336846903293, F_train: 0.6691965002472907, Q0_train: 1911.1807616408867\n",
      "X_test: [15.619099914247208, 1.0, 61.716296772614406, 1]\n",
      "f_test: -1.546679320132477, demand_test: 624.9442037060373, F_test: 0.17556639508432115 ,Q0_test: 501.40596454375464\n",
      "==================================================\n",
      "X_train: [18.031966070639623, 0.0, 294.82732979255314, 1]\n",
      "f_train: 0.95280108101753, demand_trian: 2950.873416421069, F_train: 0.7216781489921037, Q0_train: 2061.0648650144344\n",
      "X_test: [19.240041146611173, 1.0, 65.21036606204129, 1]\n",
      "f_test: -1.5151562201461959, demand_test: 648.7569594501776, F_test: 0.18017589836989012 ,Q0_test: 514.5703997983389\n",
      "==================================================\n",
      "X_train: [15.095965991546668, 0.0, 268.37809350239485, 1]\n",
      "f_train: 0.6736173991749497, demand_trian: 2683.3684520769825, F_train: 0.6623126815727037, Q0_train: 1891.5210326784172\n",
      "X_test: [19.036594793625053, 1.0, 60.54337988339254, 1]\n",
      "f_test: -1.56493980276741, demand_test: 596.4391801420729, F_test: 0.17293895980157142 ,Q0_test: 493.90218387097445\n",
      "==================================================\n",
      "X_train: [16.507874083372748, 0.0, 271.79324626328133, 1]\n",
      "f_train: 0.7079541475178357, demand_trian: 2730.31648136185, F_train: 0.6699489437051135, Q0_train: 1913.3296901847182\n",
      "X_test: [17.845503693072967, 1.0, 61.999965248964, 1]\n",
      "f_test: -1.5473228389085545, demand_test: 624.4751430283195, F_test: 0.17547326979748037 ,Q0_test: 501.14000490922786\n",
      "==================================================\n",
      "X_train: [18.300867687463427, 0.0, 294.5961677507836, 1]\n",
      "f_train: 0.9498728654500632, demand_trian: 2941.1774097840153, F_train: 0.7210896095191404, Q0_train: 2059.3840353660753\n",
      "X_test: [17.03591648613, 1.0, 60.18521794460614, 1]\n",
      "f_test: -1.5654704099835426, demand_test: 598.9158704090889, F_test: 0.17286307965061656 ,Q0_test: 493.68547519924385\n",
      "==================================================\n",
      "X_train: [16.45038803605222, 0.0, 290.3096994523043, 1]\n",
      "f_train: 0.906905557421009, demand_trian: 2908.2317958047756, F_train: 0.7123665269530813, Q0_train: 2034.4714908798198\n",
      "X_test: [15.34583497727569, 1.0, 67.93697703357421, 1]\n",
      "f_test: -1.4794198671842063, demand_test: 676.6456769913636, F_test: 0.18551506091867626 ,Q0_test: 529.8186934501181\n",
      "==================================================\n",
      "X_train: [18.090077144994208, 0.0, 285.1944291770183, 1]\n",
      "f_train: 0.849252917530388, demand_trian: 2858.8498840533343, F_train: 0.7004104013977106, Q0_train: 2000.325590330813\n",
      "X_test: [18.487143865722818, 1.0, 62.2392468806038, 1]\n",
      "f_test: -1.5458165206257077, demand_test: 627.8302761482197, F_test: 0.1756913140915549 ,Q0_test: 501.76272493222075\n",
      "==================================================\n",
      "X_train: [17.14384350472883, 0.0, 255.01134436561506, 1]\n",
      "f_train: 0.5266720719304177, demand_trian: 2551.3770149272727, F_train: 0.6287065916862393, Q0_train: 1795.544271829771\n",
      "X_test: [17.267713413390343, 1.0, 63.45351680696903, 1]\n",
      "f_test: -1.5307549176718909, demand_test: 634.2489939429554, F_test: 0.17788325917061631 ,Q0_test: 508.02277450529465\n",
      "==================================================\n",
      "X_train: [15.677370321112251, 0.0, 295.9741306872337, 1]\n",
      "f_train: 0.9690194845258606, demand_trian: 2959.9809823803407, F_train: 0.7249240171240106, Q0_train: 2070.334848832687\n",
      "X_test: [18.61027799735174, 1.0, 69.28081293465591, 1]\n",
      "f_test: -1.470398199583554, demand_test: 694.2340499677117, F_test: 0.18688209713804182 ,Q0_test: 533.7228581042253\n",
      "==================================================\n",
      "X_train: [16.491411629780153, 0.0, 285.71206497745555, 1]\n",
      "f_train: 0.8574615973856385, demand_trian: 2858.187406007267, F_train: 0.7021300366069886, Q0_train: 2005.2367542831018\n",
      "X_test: [19.331911629643145, 1.0, 67.04414401923533, 1]\n",
      "f_test: -1.495614754551213, demand_test: 672.4714130735691, F_test: 0.18308047867458993 ,Q0_test: 522.8656882478929\n",
      "==================================================\n",
      "X_train: [17.849824553506323, 0.0, 299.94235032839333, 1]\n",
      "f_train: 1.0080353553656085, demand_trian: 2991.4416354874847, F_train: 0.7326354891463832, Q0_train: 2092.358300789839\n",
      "X_test: [19.87760752501443, 1.0, 60.318389295313075, 1]\n",
      "f_test: -1.568749935467537, demand_test: 597.2903829924923, F_test: 0.17239467134315287 ,Q0_test: 492.34773218133125\n"
     ]
    }
   ],
   "source": [
    "# 線性模型預測公式\n",
    "def compute_f_F_Q(X_data, alphas, Q_star):\n",
    "    f = sum(X_data[j] * alphas[j] for j in range(len(alphas)))\n",
    "    big_f = 1 / (1 + np.exp(-f))\n",
    "    q0 = big_f * Q_star\n",
    "    # print(f\"f_vars[i]: {f:.4f}, F_vars[i]: {big_f:.4f}, Q0_vars[i]: {q0:.4f}\")\n",
    "    return f, big_f, q0\n",
    "\n",
    "\n",
    "results_df_2, stimulation_results_df_2 = grid_flexible_F_fixed_R(\n",
    "    assigned_Ts=ASSIGNED_TS,\n",
    "    salvage_value=salvage_value,\n",
    "    cost=cost,\n",
    "    price=price,\n",
    "    Q_star=Q_star,\n",
    "    demand_df_train=demand_df_train,\n",
    "    Qk_hat_df_train=Qk_hat_df_train,\n",
    "    training_df=training_df,\n",
    ")\n",
    "\n",
    "alphas = np.array(results_df_2.iloc[0][\"alpha_values\"])\n",
    "print(f\"alphas: {alphas}\")\n",
    "\n",
    "train_result_list = []\n",
    "test_result_list = []\n",
    "\n",
    "for i in range(len(training_df)):\n",
    "    # 計算訓練與測試的 f_vars, F_vars, Q0_vars\n",
    "    X_train = training_df.iloc[i, :].values.flatten().tolist()\n",
    "    X_test = testing_df.iloc[i, :].values.flatten().tolist()\n",
    "\n",
    "    # 加入 bias 特徵\n",
    "    X_train.append(1)\n",
    "    X_test.append(1)\n",
    "    f_train, F_train, Q0_train = compute_f_F_Q(X_train, alphas, Q_star)\n",
    "    f_test, F_test, Q0_test = compute_f_F_Q(X_test, alphas, Q_star)\n",
    "\n",
    "    demand_train = sum(demand_df_train.iloc[i, :].values.flatten().tolist())\n",
    "    demand_test = sum(demand_df_test.iloc[i, :].values.flatten().tolist())\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"X_train: {X_train}\")\n",
    "    print(\n",
    "        f\"f_train: {f_train}, demand_trian: {demand_train}, F_train: {F_train}, Q0_train: {Q0_train}\"\n",
    "    )\n",
    "    print(f\"X_test: {X_test}\")\n",
    "    print(\n",
    "        f\"f_test: {f_test}, demand_test: {demand_test}, F_test: {F_test} ,Q0_test: {Q0_test}\"\n",
    "    )\n",
    "\n",
    "    # 計算結果\n",
    "    train_result_list.append((f_train, F_train, Q0_train))\n",
    "    test_result_list.append((f_test, F_test, Q0_test))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "BmCtfhVmxlqf",
    "HTASer1nQ6iQ",
    "aRmALsClGzQB",
    "zg9HWiZOypqj",
    "FTJPzWLlAz8L",
    "yXuk_hytiwhv",
    "lQUlr1TGYuqf",
    "uleVduhQ5KpR",
    "igerpH_M5KpT",
    "6EOHpsM05KpT"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
