{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpAJ7uLZxpkB"
   },
   "source": [
    "# Week HW 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmCtfhVmxlqf"
   },
   "source": [
    "# Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1433,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9zBt0n0EZLVO",
    "outputId": "6e9e44a1-d4ec-4ca4-f089-7102126a2f8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter WLSAccessID\n",
      "Set parameter WLSSecret\n",
      "Set parameter LicenseID to value 2563044\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n"
     ]
    }
   ],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import gurobipy_pandas as gppd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gurobipy import min_, max_\n",
    "from scipy.stats import multivariate_normal, norm\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "params = {\n",
    "    \"WLSACCESSID\": \"73a6e3bf-2a9d-41e8-85eb-dd9b9eda802b\",\n",
    "    \"WLSSECRET\": \"c394298a-96ea-4c8c-9d5e-ef2bd5032427\",\n",
    "    \"LICENSEID\": 2563044,\n",
    "}\n",
    "\n",
    "env = gp.Env(params=params)\n",
    "model = gp.Model(env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTASer1nQ6iQ"
   },
   "source": [
    "# Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1434,
   "metadata": {
    "id": "2lZY1EXmRAie"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "#####################\n",
    "\n",
    "salvage_value = 0\n",
    "cost = 400\n",
    "price = 1000\n",
    "holding_cost = 0\n",
    "\n",
    "model_prefix = f\"med_with_holding_cost_{holding_cost}\"\n",
    "\n",
    "#####################\n",
    "\n",
    "CHUNK_SIZE = 30\n",
    "data_size = CHUNK_SIZE * 3\n",
    "train_size = 0.5\n",
    "testing_size = 0.5\n",
    "\n",
    "T = 10\n",
    "service_level = 0.95  # 服務水準\n",
    "M = 5000000\n",
    "LASSO_BETA = 100\n",
    "LASSO_ALPHA = 0.1\n",
    "LASSO_BETA_SECOND_TRAIN = 0.9\n",
    "\n",
    "\n",
    "ASSIGNED_FS = np.arange(0.1, 1.0, 0.1)\n",
    "ASSIGNED_TS = list(range(2, T))  # 2 到 T-1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Gurobi Model Constants\n",
    "THREADS = 12\n",
    "TIME_LIMIT = 20000\n",
    "MIPGAP = 0.01\n",
    "CURRENT_TIMESTAMP = int(datetime.now().strftime(\"%Y%m%d%H%M\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRmALsClGzQB"
   },
   "source": [
    "# Utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models' Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1435,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_parameters(\n",
    "    name: str,\n",
    "    alpha_values=None,\n",
    "    beta_values=None,\n",
    "    f_values=None,\n",
    "    tau_values=None,\n",
    "    data_size=data_size,\n",
    "    current_timestamp=CURRENT_TIMESTAMP,\n",
    "):\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "    params = {}\n",
    "    if alpha_values is not None:\n",
    "        params[\"alpha\"] = alpha_values\n",
    "    if beta_values is not None:\n",
    "        params[\"beta\"] = beta_values\n",
    "    if f_values is not None:\n",
    "        params[\"f_values\"] = f_values\n",
    "    if tau_values is not None:\n",
    "        params[\"tau_values\"] = tau_values\n",
    "\n",
    "    # 如果有參數才進行保存\n",
    "    if params:\n",
    "        with open(f\"models/{name}_{data_size}_{current_timestamp}.pkl\", \"wb\") as f:\n",
    "            pickle.dump(params, f)\n",
    "        print(\n",
    "            f\"Model parameters saved as models/{name}_{data_size}_{current_timestamp}.pkl\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"No parameters provided to save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1436,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_model_parameters(name: str, data_size: int):\n",
    "    # 構建檔案的路徑\n",
    "    file_path = f\"models/{name}_{data_size}_{CURRENT_TIMESTAMP}.pkl\"\n",
    "\n",
    "    # 檢查檔案是否存在\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "        print(f\"Model parameters file '{file_path}' has been deleted.\")\n",
    "    else:\n",
    "        print(f\"File '{file_path}' does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1437,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_models(model_prefix):\n",
    "    file_paths = sorted(glob.glob(f\"models/{model_prefix}_*.pkl\"))\n",
    "\n",
    "    # 逐一讀取並打印每個檔案的內容\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            params = pickle.load(f)\n",
    "            print(f\"Contents of {file_path}:\")\n",
    "            print(params)\n",
    "            print()  # 空行分隔每個檔案的內容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1438,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_models(\"linear_constraint_med_with_holding_cost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1439,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_models(\"med_with_holding_cost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1440,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_strategies_profits_scatter(save_type, dfs: dict):\n",
    "    names = list(dfs.keys())\n",
    "    df_list = [dfs[name] for name in names]\n",
    "\n",
    "    if len(df_list) <= 1:\n",
    "        print(\"No dataframes to plot.\")\n",
    "        return\n",
    "\n",
    "    pairs = list(itertools.combinations(range(len(df_list)), 2))\n",
    "    num_pairs = len(pairs)\n",
    "    grid_size = math.ceil(math.sqrt(num_pairs))\n",
    "    fig, axes = plt.subplots(grid_size, grid_size, figsize=(15, 15))\n",
    "    fig.suptitle(\"Scatter Plots of Profits (Matrix View)\")\n",
    "\n",
    "    for idx, (i, j) in enumerate(pairs):\n",
    "        row, col = divmod(idx, grid_size)\n",
    "        df_i, df_j = df_list[i], df_list[j]\n",
    "\n",
    "        if df_i is None or df_j is None or df_i.empty or df_j.empty:\n",
    "            continue\n",
    "        if len(df_i) != len(df_j):\n",
    "            continue\n",
    "\n",
    "        ax = axes[row, col]\n",
    "        ax.scatter(df_i[\"profits\"], df_j[\"profits\"], alpha=0.6)\n",
    "        ax.plot(\n",
    "            [\n",
    "                min(df_i[\"profits\"].min(), df_j[\"profits\"].min()),\n",
    "                max(df_i[\"profits\"].max(), df_j[\"profits\"].max()),\n",
    "            ],\n",
    "            [\n",
    "                min(df_i[\"profits\"].min(), df_j[\"profits\"].min()),\n",
    "                max(df_i[\"profits\"].max(), df_j[\"profits\"].max()),\n",
    "            ],\n",
    "            \"k--\",\n",
    "            linewidth=1,\n",
    "        )\n",
    "        ax.set_xlabel(names[i])\n",
    "        ax.set_ylabel(names[j])\n",
    "        ax.set_title(f\"{names[i]} vs {names[j]}\")\n",
    "\n",
    "    # Remove empty subplots\n",
    "    for idx in range(num_pairs, grid_size * grid_size):\n",
    "        row, col = divmod(idx, grid_size)\n",
    "        fig.delaxes(axes[row, col])\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "    os.makedirs(\"plots\", exist_ok=True)\n",
    "    save_path = f\"plots/plot_strategies_profits_scatter_{save_type}.png\"\n",
    "    plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "    print(f\"Plot saved as {save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1441,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_relative_profit_deviation(save_type, baseline_profit, max_profits):\n",
    "    \"\"\"\n",
    "    繪製多個策略相對於基準的平均利潤偏差。\n",
    "\n",
    "    :param baseline_profit: 基準利潤值\n",
    "    :param max_profits: 各策略的最大利潤列表，包含 None 值或 -1 表示無效數據\n",
    "    \"\"\"\n",
    "    print(f\"Baseline is: {baseline_profit}\")\n",
    "    for i, profit in enumerate(max_profits):\n",
    "        print(f\"S{i+1}'s profit: {profit}\")\n",
    "\n",
    "    # 計算相對值\n",
    "    ratios = {}\n",
    "    for idx, max_profit in enumerate(max_profits, start=1):\n",
    "        if max_profit is not None and max_profit != -1:\n",
    "            if baseline_profit != 0:\n",
    "                ratio = (max_profit - baseline_profit) / abs(baseline_profit)\n",
    "                ratios[f\"S{idx}\"] = ratio\n",
    "            else:\n",
    "                # 基準利潤為零時，直接記錄增量\n",
    "                ratio = max_profit\n",
    "                ratios[f\"S{idx}\"] = ratio\n",
    "\n",
    "    # 設置 y 軸範圍\n",
    "    if ratios:\n",
    "        y_min = min(ratios.values()) - 0.1\n",
    "        y_max = max(ratios.values()) + 0.1\n",
    "    else:\n",
    "        y_min, y_max = -0.1, 0.1\n",
    "\n",
    "    # 創建圖表顯示結果\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    if ratios:\n",
    "        bars = plt.bar(\n",
    "            ratios.keys(), ratios.values(), color=plt.cm.tab10(range(len(ratios)))\n",
    "        )\n",
    "\n",
    "        # 在每個柱狀圖上標出數值\n",
    "        for bar in bars:\n",
    "            yval = bar.get_height()\n",
    "            plt.text(\n",
    "                bar.get_x() + bar.get_width() / 2,\n",
    "                yval,\n",
    "                f\"{yval:.4f}\",\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "            )\n",
    "\n",
    "    # 添加基準線，表示基準值（No Opt）\n",
    "    plt.axhline(y=0, color=\"gray\", linestyle=\"--\", label=\"Baseline (No Opt)\")\n",
    "\n",
    "    # 設置圖表標題和軸標籤\n",
    "    plt.title(\"Relative Avg Profit Deviation from Baseline (1)\")\n",
    "    plt.xlabel(\"Strategies\")\n",
    "    plt.ylabel(\"Deviation from Baseline (1)\")\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.legend()\n",
    "\n",
    "    name = \"plot_relative_profit_deviation\"\n",
    "\n",
    "    os.makedirs(\"plots\", exist_ok=True)\n",
    "    save_path = f\"plots/{name}_{save_type}_{data_size}_{CURRENT_TIMESTAMP}.png\"\n",
    "\n",
    "    plt.savefig(save_path, format=\"png\", bbox_inches=\"tight\")\n",
    "    print(f\"Plot saved as {save_path}\")\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1442,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_relative_profit_comparison(\n",
    "    save_type,\n",
    "    train_baseline_profit,\n",
    "    test_baseline_profit,\n",
    "    test_max_profits,\n",
    "    train_max_profits,\n",
    "):\n",
    "\n",
    "    # Calculate relative deviations from baseline for test and train data\n",
    "    test_ratios, train_ratios = {}, {}\n",
    "    for idx, (test_profit, train_profit) in enumerate(\n",
    "        zip(test_max_profits, train_max_profits), start=1\n",
    "    ):\n",
    "        if test_profit is not None and test_profit != -1:\n",
    "            if test_baseline_profit != 0:\n",
    "                test_ratio = (test_profit - test_baseline_profit) / abs(\n",
    "                    test_baseline_profit\n",
    "                )  # Relative deviation\n",
    "            else:\n",
    "                test_ratio = test_profit  # Use profit directly if baseline is zero\n",
    "            test_ratios[f\"S{idx}\"] = test_ratio\n",
    "\n",
    "        if train_profit is not None and train_profit != -1:\n",
    "            if train_baseline_profit != 0:\n",
    "                train_ratio = (train_profit - train_baseline_profit) / abs(\n",
    "                    train_baseline_profit\n",
    "                )  # Relative deviation\n",
    "            else:\n",
    "                train_ratio = train_profit  # Use profit directly if baseline is zero\n",
    "            train_ratios[f\"S{idx}\"] = train_ratio\n",
    "\n",
    "    # Define the fixed range of the y-axis\n",
    "    max_value = max(\n",
    "        max(test_ratios.values(), default=0), max(train_ratios.values(), default=0)\n",
    "    )\n",
    "    y_max = min(max_value + 0.1, 1.0)  # Limit max y to 1.0\n",
    "    y_min = -y_max  # Keep symmetric scaling\n",
    "\n",
    "    # Ensure y-axis tick marks are at intervals of 0.05\n",
    "    y_ticks = np.arange(y_min, y_max + 0.05, 0.05)  # Generate ticks\n",
    "\n",
    "    # Create bar plot for relative profit deviation comparison\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    bar_width = 0.35\n",
    "    indices = np.arange(len(train_ratios))\n",
    "\n",
    "    # Plot bars for train and test ratios, with train on the left for each pair\n",
    "    train_bars = plt.bar(\n",
    "        indices - bar_width / 2,\n",
    "        train_ratios.values(),\n",
    "        bar_width,\n",
    "        label=\"Train Data\",\n",
    "        color=\"salmon\",\n",
    "    )\n",
    "    test_bars = plt.bar(\n",
    "        indices + bar_width / 2,\n",
    "        test_ratios.values(),\n",
    "        bar_width,\n",
    "        label=\"Test Data\",\n",
    "        color=\"skyblue\",\n",
    "    )\n",
    "\n",
    "    # Add baseline line\n",
    "    plt.axhline(y=0, color=\"gray\", linestyle=\"--\", label=\"Baseline (No Opt)\")\n",
    "\n",
    "    # Add labels for each bar\n",
    "    for bar in train_bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            yval,\n",
    "            f\"{yval:.2f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "        )\n",
    "    for bar in test_bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            yval,\n",
    "            f\"{yval:.2f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "        )\n",
    "\n",
    "    # Set plot labels and title\n",
    "    plt.xlabel(\"Strategies\")\n",
    "    plt.ylabel(\"Deviation from Baseline\")\n",
    "    plt.title(\"Relative Profit Deviation Comparison between Train and Test Data\")\n",
    "    plt.xticks(indices, train_ratios.keys())\n",
    "\n",
    "    # Set fixed y-axis range and ticks\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.yticks(y_ticks)  # Apply fixed 0.05 intervals\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    name = \"plot_relative_profit_comparison\"\n",
    "\n",
    "    os.makedirs(\"plots\", exist_ok=True)\n",
    "    save_path = f\"plots/{name}_{save_type}.png\"\n",
    "\n",
    "    plt.savefig(save_path, format=\"png\", bbox_inches=\"tight\")\n",
    "    print(f\"Plot saved as {save_path}\")\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1443,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_Q0_Q1_distribution(save_type, stimulation_results_dfs):\n",
    "\n",
    "    for idx, df in enumerate(stimulation_results_dfs, start=1):\n",
    "        if df is None or len(df) == 0:\n",
    "            continue\n",
    "\n",
    "        df[\"Q0\"] = pd.to_numeric(df[\"Q0\"], errors=\"coerce\")\n",
    "        df[\"Q1\"] = pd.to_numeric(df[\"Q1\"], errors=\"coerce\")\n",
    "        df.dropna(subset=[\"Q0\", \"Q1\"], inplace=True)\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(df[\"Q0\"], bins=20, alpha=0.6, label=\"Q0\", edgecolor=\"black\")\n",
    "        plt.hist(df[\"Q1\"], bins=20, alpha=0.6, label=\"Q1\", edgecolor=\"black\")\n",
    "        plt.title(f\"Histogram of Q0 and Q1 for stimulation_results_df_{idx}\")\n",
    "        plt.xlabel(\"Value\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        name = \"plot_Q0_Q1_distribution\"\n",
    "\n",
    "        os.makedirs(\"plots\", exist_ok=True)\n",
    "        save_path = (\n",
    "            f\"plots/{name}_{save_type}_{data_size}_S{idx}_{CURRENT_TIMESTAMP}.png\"\n",
    "        )\n",
    "\n",
    "        plt.savefig(save_path, format=\"png\", bbox_inches=\"tight\")\n",
    "        print(f\"Plot saved as {save_path}\")\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1444,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_profits_deviation_box_plot(\n",
    "    save_type, stimulation_results_dfs, baseline_avg_profits\n",
    "):\n",
    "\n",
    "    for idx, df in enumerate(stimulation_results_dfs, start=1):\n",
    "        if df is not None and \"profits\" in df.columns:\n",
    "            df[\"profits\"] = pd.to_numeric(df[\"profits\"], errors=\"coerce\")\n",
    "            df.dropna(subset=[\"profits\"], inplace=True)\n",
    "\n",
    "            # Calculate deviation\n",
    "            df[\"Deviation\"] = df[\"profits\"] - baseline_avg_profits\n",
    "\n",
    "            # Plot deviation as a boxplot\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.boxplot(y=df[\"Deviation\"])\n",
    "            plt.axhline(0, color=\"red\", linestyle=\"--\", label=\"Baseline\")\n",
    "            plt.title(\n",
    "                f\"Boxplot of Deviation of Profits from Baseline for stimulation_results_df_{idx}\"\n",
    "            )\n",
    "            plt.ylabel(\"Deviation\")\n",
    "            plt.legend()\n",
    "            plt.grid(True, axis=\"y\")\n",
    "\n",
    "            name = \"plot_profits_deviation_box_plot\"\n",
    "\n",
    "            os.makedirs(\"plots\", exist_ok=True)\n",
    "            save_path = (\n",
    "                f\"plots/{name}_{save_type}_{data_size}_S{idx}_{CURRENT_TIMESTAMP}.png\"\n",
    "            )\n",
    "\n",
    "            plt.savefig(save_path, format=\"png\", bbox_inches=\"tight\")\n",
    "            print(f\"Plot saved as {save_path}\")\n",
    "\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"Skipping stimulation_results_df_{idx}: Missing 'profits' column.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1445,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 線性模型預測公式\n",
    "def compute_f_F_Q(X_data, alphas, Q_star):\n",
    "    f = sum(X_data[j] * alphas[j] for j in range(len(alphas)))\n",
    "    big_f = 1 / (1 + np.exp(-f))\n",
    "    q0 = big_f * Q_star\n",
    "    print(f\"f_vars[i]: {f:.4f}, F_vars[i]: {big_f:.4f}, Q0_vars[i]: {q0:.4f}\")\n",
    "    return f, big_f, q0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1446,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def truncate_to_2(x):\n",
    "    return math.floor(x * 100) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1447,
   "metadata": {
    "id": "96OwNkWqLEx1"
   },
   "outputs": [],
   "source": [
    "# Function to replace negative values with 0\n",
    "def replace_negative_with_zero(df):\n",
    "    return df.applymap(lambda x: max(x, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1448,
   "metadata": {
    "id": "ruyH6M8Jc5yW"
   },
   "outputs": [],
   "source": [
    "def check_values(\n",
    "    Q1_vars,\n",
    "    Q_hat_adjusteds,\n",
    "    Q0_vars,\n",
    "    Sold_0s,\n",
    "    total_demand_up_to_k_minus_1_vars,\n",
    "    Sold_1s,\n",
    "    total_demand_from_k_to_T_vars,\n",
    "    Q1_plus_lefts,\n",
    "    Left_0s,\n",
    "    Lost_0s,\n",
    "    Left_1s,\n",
    "    Lost_1s,\n",
    "):\n",
    "\n",
    "    # 用於存儲每個條件的統計結果\n",
    "    results = {\n",
    "        \"Condition\": [],\n",
    "        \"Average_Error_Percentage\": [],\n",
    "        \"Max_Error_Percentage\": [],\n",
    "        \"Min_Error_Percentage\": [],\n",
    "        \"Max_Error\": [],\n",
    "        \"Min_Error\": [],\n",
    "    }\n",
    "\n",
    "    # 定義存儲每個條件下的誤差和誤差百分比\n",
    "    conditions_errors = {\n",
    "        \"Q1_vars\": [],\n",
    "        \"Sold_0s\": [],\n",
    "        \"Sold_1s\": [],\n",
    "        \"Left_0s\": [],\n",
    "        \"Left_1s\": [],\n",
    "        \"Lost_0s\": [],\n",
    "        \"Lost_1s\": [],\n",
    "    }\n",
    "\n",
    "    # 存儲每個條件下的誤差百分比\n",
    "    conditions_error_percentage = {\n",
    "        \"Q1_vars\": [],\n",
    "        \"Sold_0s\": [],\n",
    "        \"Sold_1s\": [],\n",
    "        \"Left_0s\": [],\n",
    "        \"Left_1s\": [],\n",
    "        \"Lost_0s\": [],\n",
    "        \"Lost_1s\": [],\n",
    "    }\n",
    "\n",
    "    # 遍歷每一個變量集合\n",
    "    for i in range(len(Q1_vars)):\n",
    "        # 提取變量的值\n",
    "        Q1 = Q1_vars[i].X\n",
    "        Q_hat_adjusted = Q_hat_adjusteds[i].X\n",
    "        Q0 = Q0_vars[i].X\n",
    "        Sold_0 = Sold_0s[i].X\n",
    "        total_demand_up_to_k_minus_1 = total_demand_up_to_k_minus_1_vars[i].X\n",
    "        Sold_1 = Sold_1s[i].X\n",
    "        total_demand_from_k_to_T = total_demand_from_k_to_T_vars[i].X\n",
    "        Q1_plus_left = Q1_plus_lefts[i].X\n",
    "        Left_0 = Left_0s[i].X\n",
    "        Lost_0 = Lost_0s[i].X\n",
    "        Left_1 = Left_1s[i].X\n",
    "        Lost_1 = Lost_1s[i].X\n",
    "\n",
    "        # 計算理論值\n",
    "        theoretical_sold_0 = min(total_demand_up_to_k_minus_1, Q0)\n",
    "        theoretical_left_0 = max(Q0 - theoretical_sold_0, 0)\n",
    "        theoretical_Q1_plus_left = Q1 + theoretical_left_0  # Q1_plus_left 的理論值\n",
    "        theoretical_sold_1 = min(total_demand_from_k_to_T, theoretical_Q1_plus_left)\n",
    "        theoretical_left_1 = max(theoretical_Q1_plus_left - theoretical_sold_1, 0)\n",
    "        theoretical_lost_0 = max(total_demand_up_to_k_minus_1 - Q0, 0)\n",
    "        theoretical_lost_1 = max(total_demand_from_k_to_T - theoretical_Q1_plus_left, 0)\n",
    "\n",
    "        # 檢查條件 2：Sold_0 一定等於理論值\n",
    "        if not (Sold_0 == theoretical_sold_0):\n",
    "            error = abs(Sold_0 - theoretical_sold_0)\n",
    "            conditions_errors[\"Sold_0s\"].append(error)\n",
    "            # 計算誤差百分比\n",
    "            conditions_error_percentage[\"Sold_0s\"].append(\n",
    "                (error / theoretical_sold_0) * 100 if theoretical_sold_0 != 0 else 0\n",
    "            )\n",
    "\n",
    "        # 檢查條件 3：Sold_1 一定等於理論值\n",
    "        if not (Sold_1 == theoretical_sold_1):\n",
    "            error = abs(Sold_1 - theoretical_sold_1)\n",
    "            conditions_errors[\"Sold_1s\"].append(error)\n",
    "            # 計算誤差百分比\n",
    "            conditions_error_percentage[\"Sold_1s\"].append(\n",
    "                (error / theoretical_sold_1) * 100 if theoretical_sold_1 != 0 else 0\n",
    "            )\n",
    "\n",
    "        # 檢查條件 4：Left_0 一定等於理論值\n",
    "        if not (Left_0 == theoretical_left_0):\n",
    "            error = abs(Left_0 - theoretical_left_0)\n",
    "            conditions_errors[\"Left_0s\"].append(error)\n",
    "            # 計算誤差百分比\n",
    "            conditions_error_percentage[\"Left_0s\"].append(\n",
    "                (error / theoretical_left_0) * 100 if theoretical_left_0 != 0 else 0\n",
    "            )\n",
    "\n",
    "        # 檢查條件 5：Left_1 一定等於理論值\n",
    "        if not (Left_1 == theoretical_left_1):\n",
    "            error = abs(Left_1 - theoretical_left_1)\n",
    "            conditions_errors[\"Left_1s\"].append(error)\n",
    "            # 計算誤差百分比\n",
    "            conditions_error_percentage[\"Left_1s\"].append(\n",
    "                (error / theoretical_left_1) * 100 if theoretical_left_1 != 0 else 0\n",
    "            )\n",
    "\n",
    "        # 檢查條件 6：Lost_0 一定等於理論值\n",
    "        if not (Lost_0 == theoretical_lost_0):\n",
    "            error = abs(Lost_0 - theoretical_lost_0)\n",
    "            conditions_errors[\"Lost_0s\"].append(error)\n",
    "            # 計算誤差百分比\n",
    "            conditions_error_percentage[\"Lost_0s\"].append(\n",
    "                (error / theoretical_lost_0) * 100 if theoretical_lost_0 != 0 else 0\n",
    "            )\n",
    "\n",
    "        # 檢查條件 7：Lost_1 一定等於理論值\n",
    "        if not (Lost_1 == theoretical_lost_1):\n",
    "            error = abs(Lost_1 - theoretical_lost_1)\n",
    "            conditions_errors[\"Lost_1s\"].append(error)\n",
    "            # 計算誤差百分比\n",
    "            conditions_error_percentage[\"Lost_1s\"].append(\n",
    "                (error / theoretical_lost_1) * 100 if theoretical_lost_1 != 0 else 0\n",
    "            )\n",
    "\n",
    "    # 計算每個條件的統計結果\n",
    "    for condition, errors in conditions_errors.items():\n",
    "        error_percentages = conditions_error_percentage[condition]\n",
    "        if errors:\n",
    "            # 統計數據，並將所有數值四捨五入至小數點后三位\n",
    "            avg_error_percentage = (\n",
    "                round(sum(error_percentages) / len(error_percentages), 3)\n",
    "                if error_percentages\n",
    "                else 0.0\n",
    "            )\n",
    "            max_error_percentage = (\n",
    "                round(max(error_percentages), 3) if error_percentages else 0.0\n",
    "            )\n",
    "            min_error_percentage = (\n",
    "                round(min(error_percentages), 3) if error_percentages else 0.0\n",
    "            )\n",
    "            max_error = round(max(errors), 3) if errors else 0.0\n",
    "            min_error = round(min(errors), 3) if errors else 0.0\n",
    "\n",
    "            # 存儲結果\n",
    "            results[\"Condition\"].append(condition)\n",
    "            results[\"Average_Error_Percentage\"].append(avg_error_percentage)\n",
    "            results[\"Max_Error_Percentage\"].append(max_error_percentage)\n",
    "            results[\"Min_Error_Percentage\"].append(min_error_percentage)\n",
    "            results[\"Max_Error\"].append(max_error)\n",
    "            results[\"Min_Error\"].append(min_error)\n",
    "\n",
    "    # 轉換為 DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1449,
   "metadata": {
    "id": "eNMFp-eLU956"
   },
   "outputs": [],
   "source": [
    "# Calculate service level\n",
    "def calculate_service_level(*, salvage_value, cost, price):\n",
    "\n",
    "    cu = price - cost\n",
    "    co = cost - salvage_value\n",
    "    service_lv = cu / (co + cu)\n",
    "\n",
    "    return service_lv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 1450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_service_level(salvage_value=salvage_value, cost=cost, price=price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1451,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_s3_related_strtegies_result(\n",
    "    *,\n",
    "    all_Rs,\n",
    "    losses,\n",
    "    lefts,\n",
    "    profits,\n",
    "    operation_profits,\n",
    "    alpha_values,\n",
    "    beta_values,\n",
    "    F_vars,\n",
    "    Q0_vars,\n",
    "    Q1_vars,\n",
    "    f_values,\n",
    "    tau_values,\n",
    "    holding_costs_0s,\n",
    "    holding_costs_1s,\n",
    "    all_left0s,\n",
    "    all_left1s,\n",
    "    all_lost0s,\n",
    "    all_lost1s,\n",
    "    gamma_values=None\n",
    "):\n",
    "\n",
    "    results_dict = {\n",
    "        \"average_profits\": [sum(profits) / len(profits) if profits else 0],\n",
    "        \"average_losses\": [sum(losses) / len(losses) if losses else 0],\n",
    "        \"average_lefts\": [sum(lefts) / len(lefts) if lefts else 0],\n",
    "        \"average_operation_profits\": [\n",
    "            sum(operation_profits) / len(operation_profits) if operation_profits else 0\n",
    "        ],\n",
    "        \"alpha_values\": [alpha_values],\n",
    "        \"beta_values\": [beta_values],\n",
    "        \"tau_values\": [tau_values],\n",
    "        \"gamma_values\": [gamma_values],\n",
    "    }\n",
    "    stimulations_result = {\n",
    "        \"R(T)\": all_Rs,\n",
    "        # \"R\": [x - 2 for x in all_Rs],\n",
    "        \"F\": F_vars,\n",
    "        \"f_values\": f_values,\n",
    "        \"profits\": profits,\n",
    "        \"losses\": losses,\n",
    "        \"lefts\": lefts,\n",
    "        \"operation_profits\": operation_profits,\n",
    "        \"Q0\": Q0_vars,\n",
    "        \"Q1\": Q1_vars,\n",
    "        \"hc0\": holding_costs_0s,\n",
    "        \"hc1\": holding_costs_1s,\n",
    "        \"Left0s\": all_left0s,\n",
    "        \"Left1s\": all_left1s,\n",
    "        \"lost0s\": all_lost0s,\n",
    "        \"lost1s\": all_lost1s,\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(results_dict).sort_values(\n",
    "        by=\"average_profits\", ascending=False\n",
    "    ), pd.DataFrame(stimulations_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zg9HWiZOypqj"
   },
   "source": [
    "# Generate Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LS641siV6sA_"
   },
   "source": [
    "## Data1: Training data for LR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qIeKRFI5LRNJ"
   },
   "source": [
    "### Making full data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1452,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lf_ktM4A9qZV",
    "outputId": "2c0e47cb-7ee1-4e26-add4-5c6afe560c3e"
   },
   "outputs": [],
   "source": [
    "# np.random.seed(0)\n",
    "\n",
    "# # full_df = pd.DataFrame(\n",
    "# #     {\n",
    "# #         \"X1\": np.zeros(data_size),\n",
    "# #         \"X2\": np.zeros(data_size),\n",
    "# #         \"X3\": np.zeros(data_size),\n",
    "# #         \"X4\": np.random.uniform(5, 15, data_size),\n",
    "# #     }\n",
    "# # )\n",
    "\n",
    "# full_df = pd.DataFrame(\n",
    "#     {\n",
    "#         \"X1\": np.zeros(data_size),\n",
    "#         \"X2\": np.zeros(data_size),\n",
    "#         \"X3\": np.zeros(data_size),  # 將作為轉折時間\n",
    "#         # \"X4\": np.random.uniform(5, 15, data_size),\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# for i in range(0, data_size, CHUNK_SIZE):\n",
    "#     half_chunk = CHUNK_SIZE // 2\n",
    "#     # 訓練 (前 half_chunk)\n",
    "#     full_df.loc[i : i + half_chunk - 1, \"X1\"] = np.random.uniform(\n",
    "#         15, 20, size=half_chunk\n",
    "#     )\n",
    "#     full_df.loc[i : i + half_chunk - 1, \"X2\"] = 0\n",
    "#     full_df.loc[i : i + half_chunk - 1, \"X3\"] = np.random.uniform(\n",
    "#         250, 300, size=half_chunk\n",
    "#     )\n",
    "\n",
    "#     # 測試 (後 half_chunk)\n",
    "#     full_df.loc[i + half_chunk : i + CHUNK_SIZE - 1, \"X1\"] = np.random.uniform(\n",
    "#         15, 20, size=half_chunk\n",
    "#     )\n",
    "#     full_df.loc[i + half_chunk : i + CHUNK_SIZE - 1, \"X2\"] = 1\n",
    "#     full_df.loc[i + half_chunk : i + CHUNK_SIZE - 1, \"X3\"] = np.random.uniform(\n",
    "#         60, 70, size=half_chunk\n",
    "#     )\n",
    "\n",
    "\n",
    "# # # 初始化 X3\n",
    "# # X3_values = np.zeros(data_size)\n",
    "\n",
    "# # # 對每個 chunk 設定對應的 X3 範圍\n",
    "# # for i in range(0, data_size, CHUNK_SIZE):\n",
    "# #     half_chunk = CHUNK_SIZE // 2\n",
    "# #     # 訓練資料 X3：200~250\n",
    "# #     X3_values[i : i + half_chunk] = np.random.uniform(\n",
    "# #         250, 300, size=min(half_chunk, data_size - i)\n",
    "# #     )\n",
    "# #     # 測試資料 X3：40~90\n",
    "# #     X3_values[i + half_chunk : i + CHUNK_SIZE] = np.random.uniform(\n",
    "# #         50, 100, size=min(half_chunk, data_size - i - half_chunk)\n",
    "# #     )\n",
    "\n",
    "# # # 填入 full_df\n",
    "# # full_df[\"X3\"] = X3_values\n",
    "# full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.097627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.430379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.205527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.089766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.847310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.291788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.875174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.783546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.927326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.766883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.583450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.057790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.136089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.851193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.142072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.174259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.040437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.665240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.556314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.740024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.957237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.598317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.922959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.561058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.236549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.279842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.286707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.889338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.043697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.829324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       X1   X2        X3\n",
       "0   250.0  0.0  7.097627\n",
       "1   250.0  0.0  7.430379\n",
       "2   250.0  0.0  7.205527\n",
       "3   250.0  0.0  7.089766\n",
       "4   250.0  0.0  6.847310\n",
       "5   250.0  0.0  7.291788\n",
       "6   250.0  0.0  6.875174\n",
       "7   250.0  0.0  7.783546\n",
       "8   250.0  0.0  7.927326\n",
       "9   250.0  0.0  6.766883\n",
       "10  250.0  0.0  7.583450\n",
       "11  250.0  0.0  7.057790\n",
       "12  250.0  0.0  7.136089\n",
       "13  250.0  0.0  7.851193\n",
       "14  250.0  0.0  6.142072\n",
       "15  100.0  1.0  2.174259\n",
       "16  100.0  1.0  2.040437\n",
       "17  100.0  1.0  3.665240\n",
       "18  100.0  1.0  3.556314\n",
       "19  100.0  1.0  3.740024\n",
       "20  100.0  1.0  3.957237\n",
       "21  100.0  1.0  3.598317\n",
       "22  100.0  1.0  2.922959\n",
       "23  100.0  1.0  3.561058\n",
       "24  100.0  1.0  2.236549\n",
       "25  100.0  1.0  3.279842\n",
       "26  100.0  1.0  2.286707\n",
       "27  100.0  1.0  3.889338\n",
       "28  100.0  1.0  3.043697\n",
       "29  100.0  1.0  2.829324"
      ]
     },
     "execution_count": 1453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# 初始化 full_df，包含 X1, X2, X3, X4\n",
    "# 其他變數 (例如 X4) 用 uniform 隨機數\n",
    "full_df = pd.DataFrame(\n",
    "    {\n",
    "        \"X1\": np.zeros(data_size),\n",
    "        \"X2\": np.zeros(data_size),\n",
    "        \"X3\": np.zeros(data_size),  # 將作為轉折時間\n",
    "        # \"X4\": np.random.uniform(5, 15, data_size),\n",
    "    }\n",
    ")\n",
    "\n",
    "# # 根據 chunk，對第一半 (訓練) 設定 X1=1，對第二半 (測試) 設定 X2=1，\n",
    "# # 並設定 X3 為轉折時間:\n",
    "# #  訓練：X3 ~ Uniform(7, 9)\n",
    "# #  測試：X3 ~ Uniform(2, 4)\n",
    "# for i in range(0, data_size, CHUNK_SIZE):\n",
    "#     half_chunk = CHUNK_SIZE // 2\n",
    "#     # 訓練 (前 half_chunk)\n",
    "#     full_df.loc[i : i + half_chunk - 1, \"X1\"] = 1\n",
    "#     full_df.loc[i : i + half_chunk - 1, \"X2\"] = 0\n",
    "#     full_df.loc[i : i + half_chunk - 1, \"X3\"] = np.random.uniform(7, 9, size=half_chunk)\n",
    "\n",
    "#     # 測試 (後 half_chunk)\n",
    "#     full_df.loc[i + half_chunk : i + CHUNK_SIZE - 1, \"X1\"] = 0\n",
    "#     full_df.loc[i + half_chunk : i + CHUNK_SIZE - 1, \"X2\"] = 1\n",
    "#     full_df.loc[i + half_chunk : i + CHUNK_SIZE - 1, \"X3\"] = np.random.uniform(\n",
    "#         2, 4, size=half_chunk\n",
    "#     )\n",
    "\n",
    "for i in range(0, data_size, CHUNK_SIZE):\n",
    "    half_chunk = CHUNK_SIZE // 2\n",
    "    # 訓練部分（前 half_chunk）\n",
    "    full_df.loc[i : i + half_chunk - 1, \"X1\"] = 250\n",
    "    full_df.loc[i : i + half_chunk - 1, \"X2\"] = 0\n",
    "    full_df.loc[i : i + half_chunk - 1, \"X3\"] = np.random.uniform(6, 8, size=half_chunk)\n",
    "\n",
    "    # 測試部分（後 half_chunk）\n",
    "    full_df.loc[i + half_chunk : i + CHUNK_SIZE - 1, \"X1\"] = 100\n",
    "    full_df.loc[i + half_chunk : i + CHUNK_SIZE - 1, \"X2\"] = 1\n",
    "    full_df.loc[i + half_chunk : i + CHUNK_SIZE - 1, \"X3\"] = np.random.uniform(\n",
    "        2, 4, size=half_chunk\n",
    "    )\n",
    "\n",
    "# 顯示 full_df（部分）\n",
    "full_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1454,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QK33A94iyiRx",
    "outputId": "2ba8de7b-27cf-4945-f51d-2a536cafd7d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 1454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_num = full_df.shape[1]\n",
    "features_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBjAqX8vLWW1"
   },
   "source": [
    "### Split training and testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1455,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# def train_data_split_and_normalized(data, train_size=0.5):\n",
    "#     folds = []\n",
    "#     scalers = []\n",
    "\n",
    "#     # 計算訓練集的大小\n",
    "#     train_len = int(len(data) * train_size)\n",
    "\n",
    "#     # 將資料切分為前半部分為訓練集，後半部分為測試集\n",
    "#     train_data = data.iloc[:train_len].reset_index(drop=True)\n",
    "#     test_data = data.iloc[train_len:].reset_index(drop=True)\n",
    "\n",
    "#     # # 標準化處理\n",
    "#     # scaler = StandardScaler()\n",
    "#     # train_data_normalized = scaler.fit_transform(train_data)\n",
    "#     # test_data_normalized = scaler.transform(test_data)\n",
    "\n",
    "#     # # 將標準化資料轉回 DataFrame\n",
    "#     # train_data_normalized = pd.DataFrame(train_data_normalized, columns=data.columns)\n",
    "#     # test_data_normalized = pd.DataFrame(test_data_normalized, columns=data.columns)\n",
    "\n",
    "#     # # 將資料加入 folds 與 scaler\n",
    "#     # folds.append((train_data_normalized, test_data_normalized))\n",
    "#     # scalers.append(scaler)\n",
    "\n",
    "#     # 將資料加入 folds 與 scaler\n",
    "#     folds.append((train_data, test_data))\n",
    "#     scalers.append(None)\n",
    "\n",
    "#     return folds, scalers\n",
    "\n",
    "\n",
    "# training_data_folds, scalers = train_data_split_and_normalized(full_df, train_size)\n",
    "\n",
    "# for i, (train, test) in enumerate(training_data_folds):\n",
    "#     print(f\"Fold {i + 1}:\")\n",
    "#     print(f\"Train size: {train.shape}, Test size: {test.shape}\")\n",
    "#     print(\"Train (normalized):\")\n",
    "#     print(train.head())\n",
    "#     print(\"Test (normalized):\")\n",
    "#     print(test.head())\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Train size: (15, 3), Test size: (15, 3)\n",
      "Train (normalized):\n",
      "(15, 3)\n",
      "      X1   X2        X3\n",
      "0  250.0  0.0  7.097627\n",
      "1  250.0  0.0  7.430379\n",
      "2  250.0  0.0  7.205527\n",
      "3  250.0  0.0  7.089766\n",
      "4  250.0  0.0  6.847310\n",
      "Test (normalized):\n",
      "(15, 3)\n",
      "      X1   X2        X3\n",
      "0  100.0  1.0  2.174259\n",
      "1  100.0  1.0  2.040437\n",
      "2  100.0  1.0  3.665240\n",
      "3  100.0  1.0  3.556314\n",
      "4  100.0  1.0  3.740024\n",
      "\n",
      "Fold 2:\n",
      "Train size: (15, 3), Test size: (15, 3)\n",
      "Train (normalized):\n",
      "(15, 3)\n",
      "      X1   X2        X3\n",
      "0  250.0  0.0  6.529111\n",
      "1  250.0  0.0  7.548467\n",
      "2  250.0  0.0  6.912301\n",
      "3  250.0  0.0  7.136868\n",
      "4  250.0  0.0  6.037580\n",
      "Test (normalized):\n",
      "(15, 3)\n",
      "      X1   X2        X3\n",
      "0  100.0  1.0  3.341276\n",
      "1  100.0  1.0  2.420765\n",
      "2  100.0  1.0  2.257853\n",
      "3  100.0  1.0  2.630857\n",
      "4  100.0  1.0  2.727422\n",
      "\n",
      "Fold 3:\n",
      "Train size: (15, 3), Test size: (15, 3)\n",
      "Train (normalized):\n",
      "(15, 3)\n",
      "      X1   X2        X3\n",
      "0  250.0  0.0  6.317939\n",
      "1  250.0  0.0  6.220750\n",
      "2  250.0  0.0  7.312659\n",
      "3  250.0  0.0  6.276366\n",
      "4  250.0  0.0  6.393165\n",
      "Test (normalized):\n",
      "(15, 3)\n",
      "      X1   X2        X3\n",
      "0  100.0  1.0  2.078376\n",
      "1  100.0  1.0  2.565614\n",
      "2  100.0  1.0  2.240393\n",
      "3  100.0  1.0  2.592280\n",
      "4  100.0  1.0  2.237455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def train_data_split_and_normalized_k_fold(data, train_size=0.5, chunk_size=CHUNK_SIZE):\n",
    "\n",
    "    folds = []\n",
    "    scalers = []\n",
    "    train_chunk = int(train_size * chunk_size)\n",
    "    n = len(data)\n",
    "\n",
    "    # 依序將資料切分成 chunk_size 大小的子集\n",
    "    for start in range(0, n, chunk_size):\n",
    "        if start + chunk_size > n:\n",
    "            break  # 若剩餘資料不足一個完整的 chunk，則跳過\n",
    "        chunk = data.iloc[start : start + chunk_size].reset_index(drop=True)\n",
    "        train_data = chunk.iloc[:train_chunk].reset_index(drop=True)\n",
    "        test_data = chunk.iloc[train_chunk:].reset_index(drop=True)\n",
    "\n",
    "        # # 建立並使用 StandardScaler 分別標準化當前的訓練與測試資料\n",
    "        # scaler = StandardScaler()\n",
    "        # train_data_normalized = scaler.fit_transform(train_data)\n",
    "        # test_data_normalized = scaler.transform(test_data)\n",
    "\n",
    "        # # 轉回 DataFrame 格式\n",
    "        # train_data_normalized = pd.DataFrame(\n",
    "        #     train_data_normalized, columns=data.columns\n",
    "        # )\n",
    "        # test_data_normalized = pd.DataFrame(test_data_normalized, columns=data.columns)\n",
    "\n",
    "        # folds.append((train_data_normalized, test_data_normalized))\n",
    "        # scalers.append(scaler)\n",
    "\n",
    "        folds.append((train_data, test_data))\n",
    "        scalers.append(None)\n",
    "\n",
    "    return folds, scalers\n",
    "\n",
    "\n",
    "training_data_folds, scalers = train_data_split_and_normalized_k_fold(full_df)\n",
    "\n",
    "for i, (train, test) in enumerate(training_data_folds):\n",
    "    print(f\"Fold {i + 1}:\")\n",
    "    print(f\"Train size: {train.shape}, Test size: {test.shape}\")\n",
    "    print(\"Train (normalized):\")\n",
    "    print(train.shape)\n",
    "    print(train.head())\n",
    "    print(\"Test (normalized):\")\n",
    "    print(test.shape)\n",
    "    print(test.head())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8_ZeISZmXmZ"
   },
   "source": [
    "## Data2: demand_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8sxaCcInWRTC"
   },
   "source": [
    "### mu of each time(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1457,
   "metadata": {
    "id": "54SdjO8-NCOc"
   },
   "outputs": [],
   "source": [
    "# # 設定 b0, b1, b2\n",
    "# b0 = 0\n",
    "# b1 = 0\n",
    "# b2 = 0\n",
    "# b3 = 1\n",
    "# # b4 = 0\n",
    "# bt = 0\n",
    "\n",
    "\n",
    "# def cal_mu_matrix_with_random_noise(data_size, T, training_df, sigma_t):\n",
    "#     np.random.seed(0)\n",
    "\n",
    "#     # 初始化 mu_matrix\n",
    "#     mu_matrix = np.zeros((data_size, T))\n",
    "\n",
    "#     # 生成每個 t 的隨機數\n",
    "#     random_noises = np.random.normal(0, sigma_t, T)\n",
    "\n",
    "#     # 計算 mu_matrix\n",
    "#     for t in range(1, T + 1):\n",
    "#         mu_matrix[:, t - 1] = (\n",
    "#             b0 * random_noises[t - 1]\n",
    "#             + b1 * training_df[\"X1\"]\n",
    "#             + b2 * training_df[\"X2\"]\n",
    "#             + b3 * training_df[\"X3\"]\n",
    "#             # + b4 * training_df[\"X4\"]\n",
    "#             + bt * t\n",
    "#         )\n",
    "\n",
    "#     return mu_matrix\n",
    "\n",
    "\n",
    "# mu_matrix = cal_mu_matrix_with_random_noise(data_size, T, full_df, sigma_t=1)\n",
    "\n",
    "# print(f\"mu_matrix shape: {mu_matrix.shape}\")\n",
    "# print(f\"mu_matrix[:3]: \\n{mu_matrix[:3]}\")\n",
    "# print(\n",
    "#     f\"mu_matrix[CHUNK_SIZE : CHUNK_SIZE + 3]: \\n{mu_matrix[CHUNK_SIZE : CHUNK_SIZE + 3]}\"\n",
    "# )\n",
    "\n",
    "\n",
    "# mu_df = pd.DataFrame(mu_matrix, columns=[f\"t{t}\" for t in range(1, T + 1)])\n",
    "# mu_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>t4</th>\n",
       "      <th>t5</th>\n",
       "      <th>t6</th>\n",
       "      <th>t7</th>\n",
       "      <th>t8</th>\n",
       "      <th>t9</th>\n",
       "      <th>t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>215.946658</td>\n",
       "      <td>216.138206</td>\n",
       "      <td>216.651531</td>\n",
       "      <td>217.994763</td>\n",
       "      <td>221.300885</td>\n",
       "      <td>228.343740</td>\n",
       "      <td>239.615131</td>\n",
       "      <td>286.149744</td>\n",
       "      <td>294.085892</td>\n",
       "      <td>297.976079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211.441354</td>\n",
       "      <td>211.579007</td>\n",
       "      <td>211.949381</td>\n",
       "      <td>212.928863</td>\n",
       "      <td>215.405157</td>\n",
       "      <td>221.012875</td>\n",
       "      <td>231.062686</td>\n",
       "      <td>290.445722</td>\n",
       "      <td>299.898413</td>\n",
       "      <td>304.955967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201.521430</td>\n",
       "      <td>201.693532</td>\n",
       "      <td>202.155411</td>\n",
       "      <td>203.368635</td>\n",
       "      <td>206.383485</td>\n",
       "      <td>212.945396</td>\n",
       "      <td>223.860642</td>\n",
       "      <td>276.182137</td>\n",
       "      <td>284.616328</td>\n",
       "      <td>288.861408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200.517409</td>\n",
       "      <td>200.710456</td>\n",
       "      <td>201.227739</td>\n",
       "      <td>202.580936</td>\n",
       "      <td>205.909141</td>\n",
       "      <td>212.987482</td>\n",
       "      <td>224.283041</td>\n",
       "      <td>292.304795</td>\n",
       "      <td>300.204667</td>\n",
       "      <td>304.069897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>215.707102</td>\n",
       "      <td>215.952552</td>\n",
       "      <td>216.607700</td>\n",
       "      <td>218.304163</td>\n",
       "      <td>222.372590</td>\n",
       "      <td>230.563012</td>\n",
       "      <td>284.305173</td>\n",
       "      <td>295.400342</td>\n",
       "      <td>302.196239</td>\n",
       "      <td>305.350973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>219.664768</td>\n",
       "      <td>219.822744</td>\n",
       "      <td>220.247157</td>\n",
       "      <td>221.365066</td>\n",
       "      <td>224.162634</td>\n",
       "      <td>230.349881</td>\n",
       "      <td>240.950674</td>\n",
       "      <td>289.483467</td>\n",
       "      <td>298.313381</td>\n",
       "      <td>302.858645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>209.369609</td>\n",
       "      <td>209.608384</td>\n",
       "      <td>210.246031</td>\n",
       "      <td>211.899313</td>\n",
       "      <td>215.876794</td>\n",
       "      <td>223.938525</td>\n",
       "      <td>282.168880</td>\n",
       "      <td>293.354719</td>\n",
       "      <td>300.275223</td>\n",
       "      <td>303.505845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>202.422037</td>\n",
       "      <td>202.518905</td>\n",
       "      <td>202.780332</td>\n",
       "      <td>203.477299</td>\n",
       "      <td>205.276480</td>\n",
       "      <td>209.558780</td>\n",
       "      <td>218.043296</td>\n",
       "      <td>280.493581</td>\n",
       "      <td>291.370366</td>\n",
       "      <td>297.884290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>202.916049</td>\n",
       "      <td>202.999991</td>\n",
       "      <td>203.226752</td>\n",
       "      <td>203.832857</td>\n",
       "      <td>205.408025</td>\n",
       "      <td>209.219411</td>\n",
       "      <td>217.040447</td>\n",
       "      <td>284.801410</td>\n",
       "      <td>296.148638</td>\n",
       "      <td>303.304317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>210.592953</td>\n",
       "      <td>210.858721</td>\n",
       "      <td>211.567036</td>\n",
       "      <td>213.393977</td>\n",
       "      <td>217.733486</td>\n",
       "      <td>226.294654</td>\n",
       "      <td>276.194076</td>\n",
       "      <td>287.011421</td>\n",
       "      <td>293.452452</td>\n",
       "      <td>296.396323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>205.360170</td>\n",
       "      <td>205.478387</td>\n",
       "      <td>205.796922</td>\n",
       "      <td>206.642554</td>\n",
       "      <td>208.801671</td>\n",
       "      <td>213.806483</td>\n",
       "      <td>223.198068</td>\n",
       "      <td>285.617543</td>\n",
       "      <td>295.724523</td>\n",
       "      <td>301.388706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>209.239712</td>\n",
       "      <td>209.438977</td>\n",
       "      <td>209.972677</td>\n",
       "      <td>211.367124</td>\n",
       "      <td>214.786388</td>\n",
       "      <td>222.009609</td>\n",
       "      <td>233.400835</td>\n",
       "      <td>287.345973</td>\n",
       "      <td>295.098417</td>\n",
       "      <td>298.863380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>200.483731</td>\n",
       "      <td>200.668109</td>\n",
       "      <td>201.162483</td>\n",
       "      <td>202.457942</td>\n",
       "      <td>205.657712</td>\n",
       "      <td>212.527752</td>\n",
       "      <td>223.677303</td>\n",
       "      <td>287.526565</td>\n",
       "      <td>295.640317</td>\n",
       "      <td>299.654376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>212.294768</td>\n",
       "      <td>212.385325</td>\n",
       "      <td>212.629833</td>\n",
       "      <td>213.282515</td>\n",
       "      <td>214.972898</td>\n",
       "      <td>219.028557</td>\n",
       "      <td>227.201044</td>\n",
       "      <td>279.195339</td>\n",
       "      <td>290.303325</td>\n",
       "      <td>297.116541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>219.165541</td>\n",
       "      <td>219.657029</td>\n",
       "      <td>220.945201</td>\n",
       "      <td>224.128681</td>\n",
       "      <td>230.971968</td>\n",
       "      <td>242.102041</td>\n",
       "      <td>288.747783</td>\n",
       "      <td>296.889168</td>\n",
       "      <td>300.922758</td>\n",
       "      <td>302.602645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>68.994462</td>\n",
       "      <td>80.017421</td>\n",
       "      <td>133.513325</td>\n",
       "      <td>141.803320</td>\n",
       "      <td>145.943194</td>\n",
       "      <td>147.673786</td>\n",
       "      <td>148.342800</td>\n",
       "      <td>148.593542</td>\n",
       "      <td>148.686424</td>\n",
       "      <td>148.720681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>77.005910</td>\n",
       "      <td>88.447233</td>\n",
       "      <td>127.356227</td>\n",
       "      <td>135.028793</td>\n",
       "      <td>138.740186</td>\n",
       "      <td>140.268783</td>\n",
       "      <td>140.856154</td>\n",
       "      <td>141.075790</td>\n",
       "      <td>141.157079</td>\n",
       "      <td>141.187050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>66.588130</td>\n",
       "      <td>71.288329</td>\n",
       "      <td>80.313513</td>\n",
       "      <td>132.558616</td>\n",
       "      <td>142.994105</td>\n",
       "      <td>148.998520</td>\n",
       "      <td>151.692869</td>\n",
       "      <td>152.765983</td>\n",
       "      <td>153.172861</td>\n",
       "      <td>153.324236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>57.807825</td>\n",
       "      <td>62.916465</td>\n",
       "      <td>72.427695</td>\n",
       "      <td>123.035381</td>\n",
       "      <td>133.029770</td>\n",
       "      <td>138.583452</td>\n",
       "      <td>141.030641</td>\n",
       "      <td>141.997725</td>\n",
       "      <td>142.363281</td>\n",
       "      <td>142.499126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>59.341193</td>\n",
       "      <td>63.774059</td>\n",
       "      <td>72.458509</td>\n",
       "      <td>125.505731</td>\n",
       "      <td>136.225312</td>\n",
       "      <td>142.549593</td>\n",
       "      <td>145.425712</td>\n",
       "      <td>146.577917</td>\n",
       "      <td>147.015787</td>\n",
       "      <td>147.178833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>63.873715</td>\n",
       "      <td>67.592256</td>\n",
       "      <td>75.275525</td>\n",
       "      <td>124.306490</td>\n",
       "      <td>135.741172</td>\n",
       "      <td>143.032748</td>\n",
       "      <td>146.495484</td>\n",
       "      <td>147.909717</td>\n",
       "      <td>148.451307</td>\n",
       "      <td>148.653562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>73.229817</td>\n",
       "      <td>78.178324</td>\n",
       "      <td>87.503917</td>\n",
       "      <td>121.995492</td>\n",
       "      <td>132.163436</td>\n",
       "      <td>137.888673</td>\n",
       "      <td>140.428751</td>\n",
       "      <td>141.435482</td>\n",
       "      <td>141.816459</td>\n",
       "      <td>141.958095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>60.554135</td>\n",
       "      <td>68.395306</td>\n",
       "      <td>119.188730</td>\n",
       "      <td>130.522874</td>\n",
       "      <td>137.658771</td>\n",
       "      <td>141.022977</td>\n",
       "      <td>142.392450</td>\n",
       "      <td>142.916207</td>\n",
       "      <td>143.111705</td>\n",
       "      <td>143.184013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>66.646520</td>\n",
       "      <td>71.736908</td>\n",
       "      <td>81.227297</td>\n",
       "      <td>125.466173</td>\n",
       "      <td>135.480367</td>\n",
       "      <td>141.053282</td>\n",
       "      <td>143.510814</td>\n",
       "      <td>144.482301</td>\n",
       "      <td>144.849568</td>\n",
       "      <td>144.986055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>70.578079</td>\n",
       "      <td>81.383066</td>\n",
       "      <td>128.993639</td>\n",
       "      <td>137.570580</td>\n",
       "      <td>141.921939</td>\n",
       "      <td>143.754645</td>\n",
       "      <td>144.465319</td>\n",
       "      <td>144.731991</td>\n",
       "      <td>144.830817</td>\n",
       "      <td>144.867271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>57.819704</td>\n",
       "      <td>64.058247</td>\n",
       "      <td>74.704017</td>\n",
       "      <td>125.839593</td>\n",
       "      <td>134.614962</td>\n",
       "      <td>139.117787</td>\n",
       "      <td>141.024656</td>\n",
       "      <td>141.765752</td>\n",
       "      <td>142.044079</td>\n",
       "      <td>142.147258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>73.947131</td>\n",
       "      <td>84.567109</td>\n",
       "      <td>126.320083</td>\n",
       "      <td>135.126807</td>\n",
       "      <td>139.653985</td>\n",
       "      <td>141.572859</td>\n",
       "      <td>142.318892</td>\n",
       "      <td>142.599113</td>\n",
       "      <td>142.703000</td>\n",
       "      <td>142.741327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>56.565805</td>\n",
       "      <td>60.497647</td>\n",
       "      <td>68.493972</td>\n",
       "      <td>123.756371</td>\n",
       "      <td>134.987130</td>\n",
       "      <td>141.971262</td>\n",
       "      <td>145.241024</td>\n",
       "      <td>146.567884</td>\n",
       "      <td>147.074707</td>\n",
       "      <td>147.263795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>72.154407</td>\n",
       "      <td>79.441732</td>\n",
       "      <td>90.873743</td>\n",
       "      <td>128.061079</td>\n",
       "      <td>135.748642</td>\n",
       "      <td>139.470053</td>\n",
       "      <td>141.003301</td>\n",
       "      <td>141.592541</td>\n",
       "      <td>141.812887</td>\n",
       "      <td>141.894440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>73.674840</td>\n",
       "      <td>81.948301</td>\n",
       "      <td>119.050256</td>\n",
       "      <td>130.085328</td>\n",
       "      <td>136.801225</td>\n",
       "      <td>139.907755</td>\n",
       "      <td>141.161619</td>\n",
       "      <td>141.639536</td>\n",
       "      <td>141.817695</td>\n",
       "      <td>141.883558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            t1          t2          t3          t4          t5          t6  \\\n",
       "0   215.946658  216.138206  216.651531  217.994763  221.300885  228.343740   \n",
       "1   211.441354  211.579007  211.949381  212.928863  215.405157  221.012875   \n",
       "2   201.521430  201.693532  202.155411  203.368635  206.383485  212.945396   \n",
       "3   200.517409  200.710456  201.227739  202.580936  205.909141  212.987482   \n",
       "4   215.707102  215.952552  216.607700  218.304163  222.372590  230.563012   \n",
       "5   219.664768  219.822744  220.247157  221.365066  224.162634  230.349881   \n",
       "6   209.369609  209.608384  210.246031  211.899313  215.876794  223.938525   \n",
       "7   202.422037  202.518905  202.780332  203.477299  205.276480  209.558780   \n",
       "8   202.916049  202.999991  203.226752  203.832857  205.408025  209.219411   \n",
       "9   210.592953  210.858721  211.567036  213.393977  217.733486  226.294654   \n",
       "10  205.360170  205.478387  205.796922  206.642554  208.801671  213.806483   \n",
       "11  209.239712  209.438977  209.972677  211.367124  214.786388  222.009609   \n",
       "12  200.483731  200.668109  201.162483  202.457942  205.657712  212.527752   \n",
       "13  212.294768  212.385325  212.629833  213.282515  214.972898  219.028557   \n",
       "14  219.165541  219.657029  220.945201  224.128681  230.971968  242.102041   \n",
       "15   68.994462   80.017421  133.513325  141.803320  145.943194  147.673786   \n",
       "16   77.005910   88.447233  127.356227  135.028793  138.740186  140.268783   \n",
       "17   66.588130   71.288329   80.313513  132.558616  142.994105  148.998520   \n",
       "18   57.807825   62.916465   72.427695  123.035381  133.029770  138.583452   \n",
       "19   59.341193   63.774059   72.458509  125.505731  136.225312  142.549593   \n",
       "20   63.873715   67.592256   75.275525  124.306490  135.741172  143.032748   \n",
       "21   73.229817   78.178324   87.503917  121.995492  132.163436  137.888673   \n",
       "22   60.554135   68.395306  119.188730  130.522874  137.658771  141.022977   \n",
       "23   66.646520   71.736908   81.227297  125.466173  135.480367  141.053282   \n",
       "24   70.578079   81.383066  128.993639  137.570580  141.921939  143.754645   \n",
       "25   57.819704   64.058247   74.704017  125.839593  134.614962  139.117787   \n",
       "26   73.947131   84.567109  126.320083  135.126807  139.653985  141.572859   \n",
       "27   56.565805   60.497647   68.493972  123.756371  134.987130  141.971262   \n",
       "28   72.154407   79.441732   90.873743  128.061079  135.748642  139.470053   \n",
       "29   73.674840   81.948301  119.050256  130.085328  136.801225  139.907755   \n",
       "\n",
       "            t7          t8          t9         t10  \n",
       "0   239.615131  286.149744  294.085892  297.976079  \n",
       "1   231.062686  290.445722  299.898413  304.955967  \n",
       "2   223.860642  276.182137  284.616328  288.861408  \n",
       "3   224.283041  292.304795  300.204667  304.069897  \n",
       "4   284.305173  295.400342  302.196239  305.350973  \n",
       "5   240.950674  289.483467  298.313381  302.858645  \n",
       "6   282.168880  293.354719  300.275223  303.505845  \n",
       "7   218.043296  280.493581  291.370366  297.884290  \n",
       "8   217.040447  284.801410  296.148638  303.304317  \n",
       "9   276.194076  287.011421  293.452452  296.396323  \n",
       "10  223.198068  285.617543  295.724523  301.388706  \n",
       "11  233.400835  287.345973  295.098417  298.863380  \n",
       "12  223.677303  287.526565  295.640317  299.654376  \n",
       "13  227.201044  279.195339  290.303325  297.116541  \n",
       "14  288.747783  296.889168  300.922758  302.602645  \n",
       "15  148.342800  148.593542  148.686424  148.720681  \n",
       "16  140.856154  141.075790  141.157079  141.187050  \n",
       "17  151.692869  152.765983  153.172861  153.324236  \n",
       "18  141.030641  141.997725  142.363281  142.499126  \n",
       "19  145.425712  146.577917  147.015787  147.178833  \n",
       "20  146.495484  147.909717  148.451307  148.653562  \n",
       "21  140.428751  141.435482  141.816459  141.958095  \n",
       "22  142.392450  142.916207  143.111705  143.184013  \n",
       "23  143.510814  144.482301  144.849568  144.986055  \n",
       "24  144.465319  144.731991  144.830817  144.867271  \n",
       "25  141.024656  141.765752  142.044079  142.147258  \n",
       "26  142.318892  142.599113  142.703000  142.741327  \n",
       "27  145.241024  146.567884  147.074707  147.263795  \n",
       "28  141.003301  141.592541  141.812887  141.894440  \n",
       "29  141.161619  141.639536  141.817695  141.883558  "
      ]
     },
     "execution_count": 1458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cal_mu_matrix_with_turning_point(\n",
    "    data_size, T, training_df, sigma_t, delta=50, gamma=1.0\n",
    "):\n",
    "    np.random.seed(0)\n",
    "    mu_matrix = np.zeros((data_size, T))\n",
    "    random_noises = np.random.normal(0, sigma_t, T)\n",
    "\n",
    "    # 用 X1, X2 區分高低 baseline，X3 作為轉折點\n",
    "    for i in range(data_size):\n",
    "        # 根據 X1 / X2 決定 baseline range\n",
    "        if training_df.loc[i, \"X2\"] == 1:  # Test\n",
    "\n",
    "            # 低 baseline\n",
    "            baseline1 = np.random.uniform(50, 70)\n",
    "            baseline2 = np.random.uniform(90, 110)\n",
    "            # baseline1 = np.random.uniform(100, 120)\n",
    "            # baseline2 = np.random.uniform(160, 180)\n",
    "\n",
    "        else:\n",
    "            # 高 baseline\n",
    "            baseline1 = np.random.uniform(200, 220)\n",
    "            baseline2 = np.random.uniform(240, 260)\n",
    "\n",
    "        # 將 X3 視為轉折點\n",
    "        t_switch = training_df.loc[i, \"X3\"]\n",
    "\n",
    "        # 對於每一個時間點，生成一個平滑轉折項\n",
    "        for t in range(1, T + 1):\n",
    "            # 基本線性部分：當 t < t_switch 則為 baseline1，之後用 baseline2\n",
    "            if t < t_switch:\n",
    "                mu_base = baseline1\n",
    "            else:\n",
    "                mu_base = baseline2\n",
    "            # 加上轉折項（使轉折更平滑或更明顯）\n",
    "            turning_term = delta / (1 + np.exp(-gamma * (t - t_switch)))\n",
    "            mu_matrix[i, t - 1] = mu_base + turning_term\n",
    "    return mu_matrix\n",
    "\n",
    "\n",
    "mu_matrix = cal_mu_matrix_with_turning_point(\n",
    "    data_size, T, full_df, 1, delta=50, gamma=1.0\n",
    ")\n",
    "mu_df = pd.DataFrame(mu_matrix, columns=[f\"t{t}\" for t in range(1, T + 1)])\n",
    "mu_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前 25 筆資料的 row 總和平均： 1931.8924355396284\n",
      "後 25 筆資料的 row 總和平均： 1694.6565567311484\n"
     ]
    }
   ],
   "source": [
    "# 每一筆 row 的總和\n",
    "row_sums = mu_df.sum(axis=1)\n",
    "\n",
    "# 前 25 筆 row 的總和平均\n",
    "first_25_avg = row_sums.head(25).mean()\n",
    "\n",
    "# 後 25 筆（第 6 到第 30 筆）的 row 總和平均\n",
    "last_25_avg = row_sums.iloc[5:30].mean()\n",
    "\n",
    "print(\"前 25 筆資料的 row 總和平均：\", first_25_avg)\n",
    "print(\"後 25 筆資料的 row 總和平均：\", last_25_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices: [0, 1, 2]\n",
      "Test indices: [15, 16, 17]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 現在我們從 full_df 中取出第一個 chunk（共 CHUNK_SIZE 筆），並分別選出前 3 筆訓練與後 3 筆測試觀測\n",
    "chunk_indices = range(0, CHUNK_SIZE)\n",
    "train_indices = [i for i in chunk_indices if full_df.loc[i, \"X2\"] == 0][:3]\n",
    "test_indices = [i for i in chunk_indices if full_df.loc[i, \"X2\"] == 1][:3]\n",
    "\n",
    "print(\"Train indices:\", train_indices)\n",
    "print(\"Test indices:\", test_indices)\n",
    "\n",
    "# 繪圖：X軸為 t=1..T, Y軸為 mu\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 畫出訓練資料趨勢\n",
    "plt.subplot(1, 2, 1)\n",
    "for i in train_indices:\n",
    "    plt.plot(range(1, T + 1), mu_matrix[i, :], marker=\"o\", label=f\"Train {i}\")\n",
    "plt.title(\"Train Demand Trend\")\n",
    "plt.xlabel(\"Time Period\")\n",
    "plt.ylabel(\"Demand Mean (mu)\")\n",
    "plt.legend()\n",
    "\n",
    "# 畫出測試資料趨勢\n",
    "plt.subplot(1, 2, 2)\n",
    "for i in test_indices:\n",
    "    plt.plot(range(1, T + 1), mu_matrix[i, :], marker=\"o\", label=f\"Test {i}\")\n",
    "plt.title(\"Test Demand Trend\")\n",
    "plt.xlabel(\"Time Period\")\n",
    "plt.ylabel(\"Demand Mean (mu)\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLArWn7yNAR0"
   },
   "source": [
    "### sigma matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1461,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MV_pdKuXNCRO",
    "outputId": "f8f01814-2bfe-4428-d764-0ddcd4d5795d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (90, 3)\n",
      "coefficients.shape: (3, 10)\n",
      "coefficients: [[ 0.43037873  0.20552675  0.08976637 -0.1526904   0.29178823 -0.12482558\n",
      "   0.783546    0.92732552 -0.23311696  0.58345008]\n",
      " [ 0.05778984  0.13608912  0.85119328 -0.85792788 -0.8257414  -0.95956321\n",
      "   0.66523969  0.5563135   0.7400243   0.95723668]\n",
      " [ 0.59831713 -0.07704128  0.56105835 -0.76345115  0.27984204 -0.71329343\n",
      "   0.88933783  0.04369664 -0.17067612 -0.47088878]]\n"
     ]
    }
   ],
   "source": [
    "X = full_df.values\n",
    "feature_num = X.shape[1]\n",
    "print(f\"X.shape: {X.shape}\")\n",
    "\n",
    "# 生成輸入特徵矩陣 X (shape: feature_num * data_size)\n",
    "np.random.seed(0)\n",
    "\n",
    "# 隨機生成常數項 c 和係數向量 coefficients\n",
    "c = np.random.uniform(0, 1)\n",
    "coefficients = np.random.uniform(-1, 1, (feature_num, T))  # shape: (feature_num, T)\n",
    "\n",
    "print(f\"coefficients.shape: {coefficients.shape}\")\n",
    "print(f\"coefficients: {coefficients}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1462,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YirRAft9lcD4",
    "outputId": "d4233ae9-50b8-456b-c963-bd23826b8882"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value range: (np.float64(2.1799654523117813e-26), np.float64(1.0))\n",
      "New Value range: (np.float64(6.539896356935343e-26), np.float64(3.0))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((90, 10),\n",
       " array([[3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 6.08149613e-19,\n",
       "         3.00000000e+00, 9.20458963e-16, 3.00000000e+00, 3.00000000e+00,\n",
       "         7.56855515e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 4.71717948e-19,\n",
       "         3.00000000e+00, 7.25980243e-16, 3.00000000e+00, 3.00000000e+00,\n",
       "         7.15069397e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 5.60060460e-19,\n",
       "         3.00000000e+00, 8.52274144e-16, 3.00000000e+00, 3.00000000e+00,\n",
       "         7.43044890e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 6.11810223e-19,\n",
       "         3.00000000e+00, 9.25634421e-16, 3.00000000e+00, 3.00000000e+00,\n",
       "         7.57871612e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 7.36217830e-19,\n",
       "         3.00000000e+00, 1.10039246e-15, 3.00000000e+00, 3.00000000e+00,\n",
       "         7.89891484e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 5.24365165e-19,\n",
       "         3.00000000e+00, 8.01414666e-16, 3.00000000e+00, 3.00000000e+00,\n",
       "         7.32185346e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 7.20721366e-19,\n",
       "         3.00000000e+00, 1.07873721e-15, 3.00000000e+00, 3.00000000e+00,\n",
       "         7.86143790e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 3.60234527e-19,\n",
       "         3.00000000e+00, 5.64314043e-16, 3.00000000e+00, 3.00000000e+00,\n",
       "         6.73240336e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 3.22785057e-19,\n",
       "         3.00000000e+00, 5.09308501e-16, 3.00000000e+00, 3.00000000e+00,\n",
       "         6.56920264e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 7.82839575e-19,\n",
       "         3.00000000e+00, 1.16536535e-15, 3.00000000e+00, 3.00000000e+00,\n",
       "         8.00809001e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 4.19691009e-19,\n",
       "         3.00000000e+00, 6.50888282e-16, 3.00000000e+00, 3.00000000e+00,\n",
       "         6.96629687e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 6.26929853e-19,\n",
       "         3.00000000e+00, 9.46989503e-16, 3.00000000e+00, 3.00000000e+00,\n",
       "         7.62019102e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 5.90551579e-19,\n",
       "         3.00000000e+00, 8.95549634e-16, 3.00000000e+00, 3.00000000e+00,\n",
       "         7.51903361e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 3.42102327e-19,\n",
       "         3.00000000e+00, 5.37731064e-16, 3.00000000e+00, 3.00000000e+00,\n",
       "         6.65511956e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 1.26135322e-18,\n",
       "         3.00000000e+00, 1.81976644e-15, 3.00000000e+00, 3.00000000e+00,\n",
       "         8.90927248e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99997241e+00, 9.78840247e-08,\n",
       "         3.00000000e+00, 1.59988300e-06, 3.00000000e+00, 3.00000000e+00,\n",
       "         5.64353568e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99997025e+00, 1.08413190e-07,\n",
       "         3.00000000e+00, 1.76012470e-06, 3.00000000e+00, 3.00000000e+00,\n",
       "         5.77391840e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99998805e+00, 3.13587129e-08,\n",
       "         3.00000000e+00, 5.52348462e-07, 3.00000000e+00, 3.00000000e+00,\n",
       "         4.37556605e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99998729e+00, 3.40779987e-08,\n",
       "         3.00000000e+00, 5.96975121e-07, 3.00000000e+00, 3.00000000e+00,\n",
       "         4.45767350e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99998854e+00, 2.96184584e-08,\n",
       "         3.00000000e+00, 5.23656409e-07, 3.00000000e+00, 3.00000000e+00,\n",
       "         4.32007148e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99998985e+00, 2.50924427e-08,\n",
       "         3.00000000e+00, 4.48495935e-07, 3.00000000e+00, 3.00000000e+00,\n",
       "         4.16284602e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99998759e+00, 3.30025311e-08,\n",
       "         3.00000000e+00, 5.79354489e-07, 3.00000000e+00, 3.00000000e+00,\n",
       "         4.42583065e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99998187e+00, 5.52676309e-08,\n",
       "         3.00000000e+00, 9.37899804e-07, 3.00000000e+00, 3.00000000e+00,\n",
       "         4.96655048e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99998733e+00, 3.39547757e-08,\n",
       "         3.00000000e+00, 5.94958092e-07, 3.00000000e+00, 3.00000000e+00,\n",
       "         4.45406500e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99997335e+00, 9.33380448e-08,\n",
       "         3.00000000e+00, 1.53035433e-06, 3.00000000e+00, 3.00000000e+00,\n",
       "         5.58385447e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99998516e+00, 4.20863907e-08,\n",
       "         3.00000000e+00, 7.27112107e-07, 3.00000000e+00, 3.00000000e+00,\n",
       "         4.67305984e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99997409e+00, 8.98314219e-08,\n",
       "         3.00000000e+00, 1.47657046e-06, 3.00000000e+00, 3.00000000e+00,\n",
       "         5.53625665e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99998946e+00, 2.64274745e-08,\n",
       "         3.00000000e+00, 4.70751999e-07, 3.00000000e+00, 3.00000000e+00,\n",
       "         4.21136866e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99998306e+00, 5.04009437e-08,\n",
       "         3.00000000e+00, 8.60506859e-07, 3.00000000e+00, 3.00000000e+00,\n",
       "         4.86525170e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99998089e+00, 5.93631123e-08,\n",
       "         3.00000000e+00, 1.00268053e-06, 3.00000000e+00, 3.00000000e+00,\n",
       "         5.04655969e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 9.38661528e-19,\n",
       "         3.00000000e+00, 1.38076226e-15, 3.00000000e+00, 3.00000000e+00,\n",
       "         8.33975844e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 4.31050963e-19,\n",
       "         3.00000000e+00, 6.67334184e-16, 3.00000000e+00, 3.00000000e+00,\n",
       "         7.00801503e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 7.00579980e-19,\n",
       "         3.00000000e+00, 1.05054513e-15, 3.00000000e+00, 3.00000000e+00,\n",
       "         7.81178090e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 5.90200567e-19,\n",
       "         3.00000000e+00, 8.95052298e-16, 3.00000000e+00, 3.00000000e+00,\n",
       "         7.51803425e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 1.36610013e-18,\n",
       "         3.00000000e+00, 1.96058321e-15, 3.00000000e+00, 3.00000000e+00,\n",
       "         9.06958913e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 5.47485768e-19,\n",
       "         3.00000000e+00, 8.34382448e-16, 3.00000000e+00, 3.00000000e+00,\n",
       "         7.39282284e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 5.52136424e-19,\n",
       "         3.00000000e+00, 8.41002672e-16, 3.00000000e+00, 3.00000000e+00,\n",
       "         7.40681600e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 5.48072506e-19,\n",
       "         3.00000000e+00, 8.35217875e-16, 3.00000000e+00, 3.00000000e+00,\n",
       "         7.39459333e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 3.32750985e-19,\n",
       "         3.00000000e+00, 5.23985466e-16, 3.00000000e+00, 3.00000000e+00,\n",
       "         6.61401169e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 4.96375425e-19,\n",
       "         3.00000000e+00, 7.61375506e-16, 3.00000000e+00, 3.00000000e+00,\n",
       "         7.23261036e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 8.11977058e-19,\n",
       "         3.00000000e+00, 1.20584193e-15, 3.00000000e+00, 3.00000000e+00,\n",
       "         8.07378244e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 7.21332670e-19,\n",
       "         3.00000000e+00, 1.07959204e-15, 3.00000000e+00, 3.00000000e+00,\n",
       "         7.86292808e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 4.84535573e-19,\n",
       "         3.00000000e+00, 7.44394440e-16, 3.00000000e+00, 3.00000000e+00,\n",
       "         7.19368050e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 1.28234680e-18,\n",
       "         3.00000000e+00, 1.84804884e-15, 3.00000000e+00, 3.00000000e+00,\n",
       "         8.94221037e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 5.07916923e-19,\n",
       "         3.00000000e+00, 7.77903063e-16, 3.00000000e+00, 3.00000000e+00,\n",
       "         7.26987132e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99998566e+00, 4.01580453e-08,\n",
       "         3.00000000e+00, 6.95937897e-07, 3.00000000e+00, 3.00000000e+00,\n",
       "         4.62431756e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99997597e+00, 8.10922726e-08,\n",
       "         3.00000000e+00, 1.34191689e-06, 3.00000000e+00, 3.00000000e+00,\n",
       "         5.41102201e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99997367e+00, 9.18322393e-08,\n",
       "         3.00000000e+00, 1.50727515e-06, 3.00000000e+00, 3.00000000e+00,\n",
       "         5.56358822e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99997864e+00, 6.90750104e-08,\n",
       "         3.00000000e+00, 1.15516388e-06, 3.00000000e+00, 3.00000000e+00,\n",
       "         5.22043311e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99997977e+00, 6.41658081e-08,\n",
       "         3.00000000e+00, 1.07827569e-06, 3.00000000e+00, 3.00000000e+00,\n",
       "         5.13509867e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99998395e+00, 4.68141985e-08,\n",
       "         3.00000000e+00, 8.03155500e-07, 3.00000000e+00, 3.00000000e+00,\n",
       "         4.78561527e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99998140e+00, 5.72323696e-08,\n",
       "         3.00000000e+00, 9.69015252e-07, 3.00000000e+00, 3.00000000e+00,\n",
       "         5.00548812e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99998996e+00, 2.47214435e-08,\n",
       "         3.00000000e+00, 4.42297423e-07, 3.00000000e+00, 3.00000000e+00,\n",
       "         4.14900655e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99997286e+00, 9.56799559e-08,\n",
       "         3.00000000e+00, 1.56619990e-06, 3.00000000e+00, 3.00000000e+00,\n",
       "         5.61487496e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99997593e+00, 8.12789359e-08,\n",
       "         3.00000000e+00, 1.34480264e-06, 3.00000000e+00, 3.00000000e+00,\n",
       "         5.41380404e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99997461e+00, 8.74019344e-08,\n",
       "         3.00000000e+00, 1.43922681e-06, 3.00000000e+00, 3.00000000e+00,\n",
       "         5.50242651e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99998538e+00, 4.12474256e-08,\n",
       "         3.00000000e+00, 7.13560938e-07, 3.00000000e+00, 3.00000000e+00,\n",
       "         4.65207127e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99997710e+00, 7.59495848e-08,\n",
       "         3.00000000e+00, 1.26223714e-06, 3.00000000e+00, 3.00000000e+00,\n",
       "         5.33234385e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99998197e+00, 5.48614167e-08,\n",
       "         3.00000000e+00, 9.31457626e-07, 3.00000000e+00, 3.00000000e+00,\n",
       "         4.95836633e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99997687e+00, 7.69847456e-08,\n",
       "         3.00000000e+00, 1.27830347e-06, 3.00000000e+00, 3.00000000e+00,\n",
       "         5.34850627e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 1.10287370e-18,\n",
       "         3.00000000e+00, 1.60522406e-15, 3.00000000e+00, 3.00000000e+00,\n",
       "         8.64582270e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 1.18781821e-18,\n",
       "         3.00000000e+00, 1.72045285e-15, 3.00000000e+00, 3.00000000e+00,\n",
       "         8.79043415e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 5.16076168e-19,\n",
       "         3.00000000e+00, 7.89572283e-16, 3.00000000e+00, 3.00000000e+00,\n",
       "         7.29581815e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 1.13843940e-18,\n",
       "         3.00000000e+00, 1.65353809e-15, 3.00000000e+00, 3.00000000e+00,\n",
       "         8.70738785e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 1.04131901e-18,\n",
       "         3.00000000e+00, 1.52136119e-15, 3.00000000e+00, 3.00000000e+00,\n",
       "         8.53552677e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 8.00629438e-19,\n",
       "         3.00000000e+00, 1.19008983e-15, 3.00000000e+00, 3.00000000e+00,\n",
       "         8.04841953e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 4.01348079e-19,\n",
       "         3.00000000e+00, 6.24270895e-16, 3.00000000e+00, 3.00000000e+00,\n",
       "         6.89704477e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 1.21213842e-18,\n",
       "         3.00000000e+00, 1.75334232e-15, 3.00000000e+00, 3.00000000e+00,\n",
       "         8.83035454e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 3.91093054e-19,\n",
       "         3.00000000e+00, 6.09355207e-16, 3.00000000e+00, 3.00000000e+00,\n",
       "         6.85725031e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 1.21399596e-18,\n",
       "         3.00000000e+00, 1.75585259e-15, 3.00000000e+00, 3.00000000e+00,\n",
       "         8.83337796e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 3.16539275e-19,\n",
       "         3.00000000e+00, 5.00095117e-16, 3.00000000e+00, 3.00000000e+00,\n",
       "         6.54056974e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 6.87334401e-19,\n",
       "         3.00000000e+00, 1.03197622e-15, 3.00000000e+00, 3.00000000e+00,\n",
       "         7.77851749e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 3.16393527e-19,\n",
       "         3.00000000e+00, 4.99879976e-16, 3.00000000e+00, 3.00000000e+00,\n",
       "         6.53989636e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 5.58282726e-19,\n",
       "         3.00000000e+00, 8.49746340e-16, 3.00000000e+00, 3.00000000e+00,\n",
       "         7.42516963e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 4.54692910e-19,\n",
       "         3.00000000e+00, 7.01470500e-16, 3.00000000e+00, 3.00000000e+00,\n",
       "         7.09217189e-26, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99997088e+00, 1.05318106e-07,\n",
       "         3.00000000e+00, 1.71313185e-06, 3.00000000e+00, 3.00000000e+00,\n",
       "         5.73665165e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99997785e+00, 7.26027422e-08,\n",
       "         3.00000000e+00, 1.21019251e-06, 3.00000000e+00, 3.00000000e+00,\n",
       "         5.27888950e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99997341e+00, 9.30645074e-08,\n",
       "         3.00000000e+00, 1.52616371e-06, 3.00000000e+00, 3.00000000e+00,\n",
       "         5.58019197e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99997818e+00, 7.11396001e-08,\n",
       "         3.00000000e+00, 1.18739097e-06, 3.00000000e+00, 3.00000000e+00,\n",
       "         5.25491813e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99997337e+00, 9.32734647e-08,\n",
       "         3.00000000e+00, 1.52936503e-06, 3.00000000e+00, 3.00000000e+00,\n",
       "         5.58299054e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99997870e+00, 6.88060755e-08,\n",
       "         3.00000000e+00, 1.15096134e-06, 3.00000000e+00, 3.00000000e+00,\n",
       "         5.21588237e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99998088e+00, 5.93992844e-08,\n",
       "         3.00000000e+00, 1.00325135e-06, 3.00000000e+00, 3.00000000e+00,\n",
       "         5.04724698e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99997169e+00, 1.01379847e-07,\n",
       "         3.00000000e+00, 1.65320532e-06, 3.00000000e+00, 3.00000000e+00,\n",
       "         5.68798271e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99998601e+00, 3.88412969e-08,\n",
       "         3.00000000e+00, 6.74594643e-07, 3.00000000e+00, 3.00000000e+00,\n",
       "         4.58997985e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99998389e+00, 4.70719009e-08,\n",
       "         3.00000000e+00, 8.07285491e-07, 3.00000000e+00, 3.00000000e+00,\n",
       "         4.79149211e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99997741e+00, 7.45595004e-08,\n",
       "         3.00000000e+00, 1.24063950e-06, 3.00000000e+00, 3.00000000e+00,\n",
       "         5.31036859e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99998308e+00, 5.02933392e-08,\n",
       "         3.00000000e+00, 8.58790280e-07, 3.00000000e+00, 3.00000000e+00,\n",
       "         4.86292763e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99997262e+00, 9.68713010e-08,\n",
       "         3.00000000e+00, 1.58441257e-06, 3.00000000e+00, 3.00000000e+00,\n",
       "         5.63042957e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99998406e+00, 4.64050029e-08,\n",
       "         3.00000000e+00, 7.96594578e-07, 3.00000000e+00, 3.00000000e+00,\n",
       "         4.77623184e-10, 3.00000000e+00],\n",
       "        [3.00000000e+00, 3.00000000e+00, 2.99998927e+00, 2.70551347e-08,\n",
       "         3.00000000e+00, 4.81189869e-07, 3.00000000e+00, 3.00000000e+00,\n",
       "         4.23352596e-10, 3.00000000e+00]]))"
      ]
     },
     "execution_count": 1462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 進行矩陣運算\n",
    "# X.T 的形狀為 (data_size, feature_num)，X.T @ coefficients 的形狀為 (feature_num, T)\n",
    "linear_combination = c + X @ coefficients\n",
    "\n",
    "# 使用 sigmoid 函數將值映射到 [0, 1] 之間\n",
    "sigma_matrix = 1 / (1 + np.exp(-linear_combination))  # shape: (data_size, T)\n",
    "# print(f\"sigma_matrix.shape: {sigma_matrix.shape}\")\n",
    "# print(f\"sigma_matrix: {sigma_matrix}\")\n",
    "\n",
    "# 計算每個元素的最小值和最大值\n",
    "min_value = np.min(sigma_matrix)\n",
    "max_value = np.max(sigma_matrix)\n",
    "print(f\"Value range: {(min_value, max_value)}\")\n",
    "\n",
    "# 再將值縮放到 [2, 10] 的範圍\n",
    "# shape: (data_size, T)\n",
    "# sigma_matrix = 0 + sigma_matrix * 300\n",
    "\n",
    "# sigma_matrix = 0 + sigma_matrix * 200\n",
    "# sigma_matrix = 100 + sigma_matrix * 100\n",
    "# sigma_matrix = 0 + sigma_matrix * 10\n",
    "sigma_matrix = 0 + sigma_matrix * 3\n",
    "# sigma_matrix = 50 + sigma_matrix * 50\n",
    "# sigma_matrix = 0 + sigma_matrix * 2\n",
    "# sigma_matrix = 10 + sigma_matrix * 5\n",
    "# sigma_matrix = 0 + sigma_matrix * 1\n",
    "\n",
    "\n",
    "# sigma_matrix = 0 + sigma_matrix * 80\n",
    "# sigma_matrix = 40 + sigma_matrix * 40\n",
    "# sigma_matrix = 0 + sigma_matrix * 40\n",
    "# sigma_matrix = 20 + sigma_matrix * 20\n",
    "# sigma_matrix = 0 + sigma_matrix * 5\n",
    "\n",
    "# sigma_matrix = 0 + sigma_matrix * 8\n",
    "# sigma_matrix = 4 + sigma_matrix * 4\n",
    "# sigma_matrix = 0 + sigma_matrix * 4\n",
    "# sigma_matrix = 2 + sigma_matrix * 2\n",
    "# sigma_matrix = 0 + sigma_matrix * 0.3\n",
    "\n",
    "# 計算每個元素的最小值和最大值\n",
    "min_value = np.min(sigma_matrix)\n",
    "max_value = np.max(sigma_matrix)\n",
    "print(f\"New Value range: {(min_value, max_value)}\")\n",
    "\n",
    "# 輸出 sigma_matrix 的形狀和內容\n",
    "sigma_matrix_shape = sigma_matrix.shape\n",
    "sigma_matrix_content = sigma_matrix\n",
    "\n",
    "sigma_matrix_shape, sigma_matrix_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNQRS392qk1H"
   },
   "source": [
    "### corr matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1463,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6t2w0Y7EYxB0",
    "outputId": "72618685-7498-42d7-e92c-67457a485da5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr_matrix shape: (10, 10)\n",
      "corr_matrix: \n",
      "[[ 1.          0.35424279  0.5557836   0.58741064 -0.38777369 -0.16148427\n",
      "  -0.0990728  -0.27594366 -0.48889127 -0.02092469]\n",
      " [ 0.35424279  1.          0.64567134  0.34424882 -0.53396229 -0.11871438\n",
      "  -0.3666009   0.07223015  0.10995817 -0.04912633]\n",
      " [ 0.5557836   0.64567134  1.          0.259728   -0.42849166 -0.23652044\n",
      "  -0.55154321  0.01056255 -0.4142461  -0.12870872]\n",
      " [ 0.58741064  0.34424882  0.259728    1.         -0.43371556 -0.07896157\n",
      "   0.16623268 -0.63102156  0.08913915  0.24417687]\n",
      " [-0.38777369 -0.53396229 -0.42849166 -0.43371556  1.          0.37139904\n",
      "   0.30031034  0.29401969 -0.15371929 -0.10854857]\n",
      " [-0.16148427 -0.11871438 -0.23652044 -0.07896157  0.37139904  1.\n",
      "   0.65829169  0.52050763 -0.34173775  0.14741869]\n",
      " [-0.0990728  -0.3666009  -0.55154321  0.16623268  0.30031034  0.65829169\n",
      "   1.          0.03894138 -0.00977194  0.48587032]\n",
      " [-0.27594366  0.07223015  0.01056255 -0.63102156  0.29401969  0.52050763\n",
      "   0.03894138  1.         -0.20365855  0.13048727]\n",
      " [-0.48889127  0.10995817 -0.4142461   0.08913915 -0.15371929 -0.34173775\n",
      "  -0.00977194 -0.20365855  1.          0.35511152]\n",
      " [-0.02092469 -0.04912633 -0.12870872  0.24417687 -0.10854857  0.14741869\n",
      "   0.48587032  0.13048727  0.35511152  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Generate correlation matrix\n",
    "np.random.seed(0)\n",
    "\n",
    "A = np.random.uniform(-1, 1, (T, T))\n",
    "corr_matrix = np.dot(A, A.T)\n",
    "\n",
    "D = np.diag(1 / np.sqrt(np.diag(corr_matrix)))\n",
    "corr_matrix = D @ corr_matrix @ D\n",
    "\n",
    "print(f\"corr_matrix shape: {corr_matrix.shape}\")\n",
    "print(f\"corr_matrix: \\n{corr_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxpp4zz0qxAA"
   },
   "source": [
    "### cov matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1464,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ft_GZABHZ754",
    "outputId": "a7b0c34d-fecb-4cda-c58a-ded5cb35b8a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cov_matrices shape: (90, 10, 10)\n",
      "cov_matrices: \n",
      "[[ 9.00000000e+00  3.18818512e+00  5.00205241e+00  1.07170067e-18\n",
      "  -3.48996324e+00 -4.45918936e-16 -8.91655219e-01 -2.48349295e+00\n",
      "  -1.11006017e-25 -1.88322255e-01]\n",
      " [ 3.18818512e+00  9.00000000e+00  5.81104207e+00  6.28064362e-19\n",
      "  -4.80566058e+00 -3.27815136e-16 -3.29940812e+00  6.50071334e-01\n",
      "   2.49667332e-26 -4.42136970e-01]\n",
      " [ 5.00205241e+00  5.81104207e+00  9.00000000e+00  4.73860448e-19\n",
      "  -3.85642497e+00 -6.53122065e-16 -4.96388886e+00  9.50629143e-02\n",
      "  -9.40573334e-26 -1.15837848e+00]\n",
      " [ 1.07170067e-18  6.28064362e-19  4.73860448e-19  3.69845952e-37\n",
      "  -7.91291843e-19 -4.42008538e-35  3.03283011e-19 -1.15126655e-18\n",
      "   4.10290917e-45  4.45488207e-19]\n",
      " [-3.48996324e+00 -4.80566058e+00 -3.85642497e+00 -7.91291843e-19\n",
      "   9.00000000e+00  1.02557273e-15  2.70279307e+00  2.64617719e+00\n",
      "  -3.49029871e-26 -9.76937126e-01]\n",
      " [-4.45918936e-16 -3.27815136e-16 -6.53122065e-16 -4.42008538e-35\n",
      "   1.02557273e-15  8.47244703e-31  1.81779147e-15  1.43731773e-15\n",
      "  -2.38073120e-41  4.07078564e-16]\n",
      " [-8.91655219e-01 -3.29940812e+00 -4.96388886e+00  3.03283011e-19\n",
      "   2.70279307e+00  1.81779147e-15  9.00000000e+00  3.50472395e-01\n",
      "  -2.21878502e-27  4.37283284e+00]\n",
      " [-2.48349295e+00  6.50071334e-01  9.50629143e-02 -1.15126655e-18\n",
      "   2.64617719e+00  1.43731773e-15  3.50472395e-01  9.00000000e+00\n",
      "  -4.62420292e-26  1.17438539e+00]\n",
      " [-1.11006017e-25  2.49667332e-26 -9.40573334e-26  4.10290917e-45\n",
      "  -3.49029871e-26 -2.38073120e-41 -2.21878502e-27 -4.62420292e-26\n",
      "   5.72830271e-51  8.06304336e-26]\n",
      " [-1.88322255e-01 -4.42136970e-01 -1.15837848e+00  4.45488207e-19\n",
      "  -9.76937126e-01  4.07078564e-16  4.37283284e+00  1.17438539e+00\n",
      "   8.06304336e-26  9.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Generate covariance matrices\n",
    "cov_matrices = []\n",
    "for i in range(data_size):\n",
    "    cov_matrix = np.zeros((T, T))  # 每一個模擬都會有 T*T 的共變異矩陣\n",
    "    for j in range(T):\n",
    "        for k in range(T):\n",
    "            cov_matrix[j, k] = (\n",
    "                corr_matrix[j, k] * sigma_matrix[i, j] * sigma_matrix[i, k]\n",
    "            )\n",
    "    cov_matrices.append(cov_matrix)\n",
    "\n",
    "print(f\"cov_matrices shape: {np.array(cov_matrices).shape}\")\n",
    "print(f\"cov_matrices: \\n{cov_matrices[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1465,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "36jbx5j7Tt0D",
    "outputId": "62658998-8158-425b-c756-8448e4c96db5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All covariance matrices are positive definite: False\n"
     ]
    }
   ],
   "source": [
    "def is_positive_definite(matrix):\n",
    "    return np.all(np.linalg.eigvals(matrix) > 0)\n",
    "\n",
    "\n",
    "positive_definite_check = all(is_positive_definite(cov) for cov in cov_matrices)\n",
    "print(\"All covariance matrices are positive definite:\", positive_definite_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDjqi0k25thw"
   },
   "source": [
    "### MVN stimulation for demand_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1466,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kz-UdBRYc2Hb",
    "outputId": "4e19fe37-abd4-4435-d5b9-9e964c44ceb0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>216.269540</td>\n",
       "      <td>211.134274</td>\n",
       "      <td>215.128316</td>\n",
       "      <td>217.994763</td>\n",
       "      <td>229.527662</td>\n",
       "      <td>228.343740</td>\n",
       "      <td>242.806583</td>\n",
       "      <td>289.728142</td>\n",
       "      <td>294.085892</td>\n",
       "      <td>302.742662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>213.412362</td>\n",
       "      <td>212.203824</td>\n",
       "      <td>210.885199</td>\n",
       "      <td>212.928863</td>\n",
       "      <td>214.608230</td>\n",
       "      <td>221.012875</td>\n",
       "      <td>232.696730</td>\n",
       "      <td>291.971737</td>\n",
       "      <td>299.898413</td>\n",
       "      <td>310.098635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>204.681787</td>\n",
       "      <td>207.336518</td>\n",
       "      <td>210.952538</td>\n",
       "      <td>203.368635</td>\n",
       "      <td>201.143341</td>\n",
       "      <td>212.945396</td>\n",
       "      <td>217.246014</td>\n",
       "      <td>274.878251</td>\n",
       "      <td>284.616328</td>\n",
       "      <td>292.693517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>198.383496</td>\n",
       "      <td>200.987261</td>\n",
       "      <td>197.538109</td>\n",
       "      <td>202.580936</td>\n",
       "      <td>202.908901</td>\n",
       "      <td>212.987482</td>\n",
       "      <td>223.541107</td>\n",
       "      <td>289.059699</td>\n",
       "      <td>300.204667</td>\n",
       "      <td>305.030320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>219.811740</td>\n",
       "      <td>215.888884</td>\n",
       "      <td>220.591784</td>\n",
       "      <td>218.304163</td>\n",
       "      <td>224.051815</td>\n",
       "      <td>230.563012</td>\n",
       "      <td>282.302153</td>\n",
       "      <td>291.526875</td>\n",
       "      <td>302.196239</td>\n",
       "      <td>297.751466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>62.698196</td>\n",
       "      <td>78.611085</td>\n",
       "      <td>139.791254</td>\n",
       "      <td>143.076516</td>\n",
       "      <td>142.163674</td>\n",
       "      <td>150.919528</td>\n",
       "      <td>145.896928</td>\n",
       "      <td>149.493779</td>\n",
       "      <td>152.352166</td>\n",
       "      <td>146.679443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>64.781553</td>\n",
       "      <td>72.263140</td>\n",
       "      <td>83.800937</td>\n",
       "      <td>130.848821</td>\n",
       "      <td>141.944226</td>\n",
       "      <td>142.279298</td>\n",
       "      <td>146.301937</td>\n",
       "      <td>144.274959</td>\n",
       "      <td>144.628356</td>\n",
       "      <td>146.560884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>75.532997</td>\n",
       "      <td>88.519768</td>\n",
       "      <td>134.606680</td>\n",
       "      <td>145.260208</td>\n",
       "      <td>152.214092</td>\n",
       "      <td>151.198150</td>\n",
       "      <td>151.674544</td>\n",
       "      <td>151.286388</td>\n",
       "      <td>152.224362</td>\n",
       "      <td>152.695641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>61.766267</td>\n",
       "      <td>71.418492</td>\n",
       "      <td>79.609229</td>\n",
       "      <td>136.806694</td>\n",
       "      <td>149.697938</td>\n",
       "      <td>149.059237</td>\n",
       "      <td>151.665693</td>\n",
       "      <td>152.244795</td>\n",
       "      <td>151.654347</td>\n",
       "      <td>150.452055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>68.819794</td>\n",
       "      <td>74.071775</td>\n",
       "      <td>80.358485</td>\n",
       "      <td>123.003555</td>\n",
       "      <td>129.832291</td>\n",
       "      <td>140.982057</td>\n",
       "      <td>145.590577</td>\n",
       "      <td>148.889060</td>\n",
       "      <td>145.948128</td>\n",
       "      <td>145.404458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "0   216.269540  211.134274  215.128316  217.994763  229.527662  228.343740   \n",
       "1   213.412362  212.203824  210.885199  212.928863  214.608230  221.012875   \n",
       "2   204.681787  207.336518  210.952538  203.368635  201.143341  212.945396   \n",
       "3   198.383496  200.987261  197.538109  202.580936  202.908901  212.987482   \n",
       "4   219.811740  215.888884  220.591784  218.304163  224.051815  230.563012   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "85   62.698196   78.611085  139.791254  143.076516  142.163674  150.919528   \n",
       "86   64.781553   72.263140   83.800937  130.848821  141.944226  142.279298   \n",
       "87   75.532997   88.519768  134.606680  145.260208  152.214092  151.198150   \n",
       "88   61.766267   71.418492   79.609229  136.806694  149.697938  149.059237   \n",
       "89   68.819794   74.071775   80.358485  123.003555  129.832291  140.982057   \n",
       "\n",
       "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "0   242.806583  289.728142  294.085892  302.742662  \n",
       "1   232.696730  291.971737  299.898413  310.098635  \n",
       "2   217.246014  274.878251  284.616328  292.693517  \n",
       "3   223.541107  289.059699  300.204667  305.030320  \n",
       "4   282.302153  291.526875  302.196239  297.751466  \n",
       "..         ...         ...         ...         ...  \n",
       "85  145.896928  149.493779  152.352166  146.679443  \n",
       "86  146.301937  144.274959  144.628356  146.560884  \n",
       "87  151.674544  151.286388  152.224362  152.695641  \n",
       "88  151.665693  152.244795  151.654347  150.452055  \n",
       "89  145.590577  148.889060  145.948128  145.404458  \n",
       "\n",
       "[90 rows x 10 columns]"
      ]
     },
     "execution_count": 1466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simulate_demand_data(data_size, T, cov_matrices, mu_matrix):\n",
    "    np.random.seed(0)\n",
    "\n",
    "    simulated_data = np.array(\n",
    "        [\n",
    "            np.random.multivariate_normal(mu_matrix[i], cov_matrices[i])\n",
    "            for i in range(data_size)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    demand_df = pd.DataFrame(\n",
    "        simulated_data, columns=[f\"demand_t{t}\" for t in range(1, T + 1)]\n",
    "    )\n",
    "    return demand_df\n",
    "\n",
    "\n",
    "demand_df = simulate_demand_data(data_size, T, cov_matrices, mu_matrix)\n",
    "demand_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9SB3AS8eLXlJ"
   },
   "source": [
    "### Replace negative values to 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1467,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jj5Gvln1Lb2X",
    "outputId": "09dc87db-1439-4d01-a41e-7bd0e7a0f1ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_65248/2799096767.py:3: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df.applymap(lambda x: max(x, 0))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>216.269540</td>\n",
       "      <td>211.134274</td>\n",
       "      <td>215.128316</td>\n",
       "      <td>217.994763</td>\n",
       "      <td>229.527662</td>\n",
       "      <td>228.343740</td>\n",
       "      <td>242.806583</td>\n",
       "      <td>289.728142</td>\n",
       "      <td>294.085892</td>\n",
       "      <td>302.742662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>213.412362</td>\n",
       "      <td>212.203824</td>\n",
       "      <td>210.885199</td>\n",
       "      <td>212.928863</td>\n",
       "      <td>214.608230</td>\n",
       "      <td>221.012875</td>\n",
       "      <td>232.696730</td>\n",
       "      <td>291.971737</td>\n",
       "      <td>299.898413</td>\n",
       "      <td>310.098635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>204.681787</td>\n",
       "      <td>207.336518</td>\n",
       "      <td>210.952538</td>\n",
       "      <td>203.368635</td>\n",
       "      <td>201.143341</td>\n",
       "      <td>212.945396</td>\n",
       "      <td>217.246014</td>\n",
       "      <td>274.878251</td>\n",
       "      <td>284.616328</td>\n",
       "      <td>292.693517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>198.383496</td>\n",
       "      <td>200.987261</td>\n",
       "      <td>197.538109</td>\n",
       "      <td>202.580936</td>\n",
       "      <td>202.908901</td>\n",
       "      <td>212.987482</td>\n",
       "      <td>223.541107</td>\n",
       "      <td>289.059699</td>\n",
       "      <td>300.204667</td>\n",
       "      <td>305.030320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>219.811740</td>\n",
       "      <td>215.888884</td>\n",
       "      <td>220.591784</td>\n",
       "      <td>218.304163</td>\n",
       "      <td>224.051815</td>\n",
       "      <td>230.563012</td>\n",
       "      <td>282.302153</td>\n",
       "      <td>291.526875</td>\n",
       "      <td>302.196239</td>\n",
       "      <td>297.751466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>62.698196</td>\n",
       "      <td>78.611085</td>\n",
       "      <td>139.791254</td>\n",
       "      <td>143.076516</td>\n",
       "      <td>142.163674</td>\n",
       "      <td>150.919528</td>\n",
       "      <td>145.896928</td>\n",
       "      <td>149.493779</td>\n",
       "      <td>152.352166</td>\n",
       "      <td>146.679443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>64.781553</td>\n",
       "      <td>72.263140</td>\n",
       "      <td>83.800937</td>\n",
       "      <td>130.848821</td>\n",
       "      <td>141.944226</td>\n",
       "      <td>142.279298</td>\n",
       "      <td>146.301937</td>\n",
       "      <td>144.274959</td>\n",
       "      <td>144.628356</td>\n",
       "      <td>146.560884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>75.532997</td>\n",
       "      <td>88.519768</td>\n",
       "      <td>134.606680</td>\n",
       "      <td>145.260208</td>\n",
       "      <td>152.214092</td>\n",
       "      <td>151.198150</td>\n",
       "      <td>151.674544</td>\n",
       "      <td>151.286388</td>\n",
       "      <td>152.224362</td>\n",
       "      <td>152.695641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>61.766267</td>\n",
       "      <td>71.418492</td>\n",
       "      <td>79.609229</td>\n",
       "      <td>136.806694</td>\n",
       "      <td>149.697938</td>\n",
       "      <td>149.059237</td>\n",
       "      <td>151.665693</td>\n",
       "      <td>152.244795</td>\n",
       "      <td>151.654347</td>\n",
       "      <td>150.452055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>68.819794</td>\n",
       "      <td>74.071775</td>\n",
       "      <td>80.358485</td>\n",
       "      <td>123.003555</td>\n",
       "      <td>129.832291</td>\n",
       "      <td>140.982057</td>\n",
       "      <td>145.590577</td>\n",
       "      <td>148.889060</td>\n",
       "      <td>145.948128</td>\n",
       "      <td>145.404458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "0   216.269540  211.134274  215.128316  217.994763  229.527662  228.343740   \n",
       "1   213.412362  212.203824  210.885199  212.928863  214.608230  221.012875   \n",
       "2   204.681787  207.336518  210.952538  203.368635  201.143341  212.945396   \n",
       "3   198.383496  200.987261  197.538109  202.580936  202.908901  212.987482   \n",
       "4   219.811740  215.888884  220.591784  218.304163  224.051815  230.563012   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "85   62.698196   78.611085  139.791254  143.076516  142.163674  150.919528   \n",
       "86   64.781553   72.263140   83.800937  130.848821  141.944226  142.279298   \n",
       "87   75.532997   88.519768  134.606680  145.260208  152.214092  151.198150   \n",
       "88   61.766267   71.418492   79.609229  136.806694  149.697938  149.059237   \n",
       "89   68.819794   74.071775   80.358485  123.003555  129.832291  140.982057   \n",
       "\n",
       "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "0   242.806583  289.728142  294.085892  302.742662  \n",
       "1   232.696730  291.971737  299.898413  310.098635  \n",
       "2   217.246014  274.878251  284.616328  292.693517  \n",
       "3   223.541107  289.059699  300.204667  305.030320  \n",
       "4   282.302153  291.526875  302.196239  297.751466  \n",
       "..         ...         ...         ...         ...  \n",
       "85  145.896928  149.493779  152.352166  146.679443  \n",
       "86  146.301937  144.274959  144.628356  146.560884  \n",
       "87  151.674544  151.286388  152.224362  152.695641  \n",
       "88  151.665693  152.244795  151.654347  150.452055  \n",
       "89  145.590577  148.889060  145.948128  145.404458  \n",
       "\n",
       "[90 rows x 10 columns]"
      ]
     },
     "execution_count": 1467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df = replace_negative_with_zero(demand_df)\n",
    "demand_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJ_lOKc5Sx_y"
   },
   "source": [
    "### Validate the mean and std of total demand\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ypOKYMaS8cm"
   },
   "source": [
    "檢查生成的需求數據是否符合上述總需求的特性。例如，從生成的需求 demand_df 中計算總需求\n",
    "𝐷\n",
    "D，然後檢查其均值和標準差是否接近理論值（即均值為所有\n",
    "𝜇\n",
    "𝑡\n",
    "μ\n",
    "t\n",
    "​\n",
    "的和，標準差根據共變異數矩陣計算）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1468,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OYoBmwqpUMLF",
    "outputId": "5ed51381-2231-42d6-c082-01af32258d0a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>theoretical_mean</th>\n",
       "      <th>empirical_mean</th>\n",
       "      <th>theoretical_std</th>\n",
       "      <th>empirical_std</th>\n",
       "      <th>std_relative_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2434.202629</td>\n",
       "      <td>2447.761572</td>\n",
       "      <td>7.865978</td>\n",
       "      <td>34.437346</td>\n",
       "      <td>77.158582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2410.679424</td>\n",
       "      <td>2419.716868</td>\n",
       "      <td>7.865978</td>\n",
       "      <td>39.092791</td>\n",
       "      <td>79.878699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2301.588404</td>\n",
       "      <td>2309.862324</td>\n",
       "      <td>7.865978</td>\n",
       "      <td>35.257145</td>\n",
       "      <td>77.689690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2344.795563</td>\n",
       "      <td>2333.221978</td>\n",
       "      <td>7.865978</td>\n",
       "      <td>43.183231</td>\n",
       "      <td>81.784647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2506.759846</td>\n",
       "      <td>2502.988131</td>\n",
       "      <td>7.865978</td>\n",
       "      <td>35.731136</td>\n",
       "      <td>77.985648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1318.547653</td>\n",
       "      <td>1311.682568</td>\n",
       "      <td>7.865969</td>\n",
       "      <td>30.691519</td>\n",
       "      <td>74.370871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1217.007718</td>\n",
       "      <td>1217.684113</td>\n",
       "      <td>7.865971</td>\n",
       "      <td>32.086912</td>\n",
       "      <td>75.485421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1363.009964</td>\n",
       "      <td>1355.212829</td>\n",
       "      <td>7.865967</td>\n",
       "      <td>27.406663</td>\n",
       "      <td>71.299070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1258.880281</td>\n",
       "      <td>1254.374747</td>\n",
       "      <td>7.865972</td>\n",
       "      <td>36.149307</td>\n",
       "      <td>78.240325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1197.969037</td>\n",
       "      <td>1202.900180</td>\n",
       "      <td>7.865974</td>\n",
       "      <td>31.070103</td>\n",
       "      <td>74.683142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    theoretical_mean  empirical_mean  theoretical_std  empirical_std  \\\n",
       "0        2434.202629     2447.761572         7.865978      34.437346   \n",
       "1        2410.679424     2419.716868         7.865978      39.092791   \n",
       "2        2301.588404     2309.862324         7.865978      35.257145   \n",
       "3        2344.795563     2333.221978         7.865978      43.183231   \n",
       "4        2506.759846     2502.988131         7.865978      35.731136   \n",
       "..               ...             ...              ...            ...   \n",
       "85       1318.547653     1311.682568         7.865969      30.691519   \n",
       "86       1217.007718     1217.684113         7.865971      32.086912   \n",
       "87       1363.009964     1355.212829         7.865967      27.406663   \n",
       "88       1258.880281     1254.374747         7.865972      36.149307   \n",
       "89       1197.969037     1202.900180         7.865974      31.070103   \n",
       "\n",
       "    std_relative_error  \n",
       "0            77.158582  \n",
       "1            79.878699  \n",
       "2            77.689690  \n",
       "3            81.784647  \n",
       "4            77.985648  \n",
       "..                 ...  \n",
       "85           74.370871  \n",
       "86           75.485421  \n",
       "87           71.299070  \n",
       "88           78.240325  \n",
       "89           74.683142  \n",
       "\n",
       "[90 rows x 5 columns]"
      ]
     },
     "execution_count": 1468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_theoretical_vs_empirical(demand_df, cov_matrices, mu_matrix):\n",
    "    results = []\n",
    "    for i in range(len(demand_df)):\n",
    "\n",
    "        demand_i = demand_df.iloc[i, :]\n",
    "\n",
    "        # theoretical mean\n",
    "        theoretical_mean = mu_matrix[i].sum()\n",
    "\n",
    "        # theoretical std\n",
    "        variance_sum = np.sum(np.diag(cov_matrices[i]))\n",
    "        covariance_sum = np.sum(cov_matrices[i]) - variance_sum\n",
    "        theoretical_variance = variance_sum + covariance_sum\n",
    "        theoretical_std = np.sqrt(theoretical_variance)\n",
    "\n",
    "        # empirical mean and std\n",
    "        empirical_mean = demand_i.sum()\n",
    "        empirical_std = demand_i.std(ddof=0)  # 指定除以 n 而非 n-1\n",
    "        std_relative_error = abs(theoretical_std - empirical_std) / empirical_std * 100\n",
    "\n",
    "        # save the results\n",
    "        results.append(\n",
    "            {\n",
    "                \"theoretical_mean\": theoretical_mean,\n",
    "                \"empirical_mean\": empirical_mean,\n",
    "                \"theoretical_std\": theoretical_std,\n",
    "                \"empirical_std\": empirical_std,\n",
    "                \"std_relative_error\": std_relative_error,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "results_df = check_theoretical_vs_empirical(demand_df, cov_matrices, mu_matrix)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-QM7SNl1okD"
   },
   "source": [
    "### Validate normal distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1469,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_pKfG7Hq1vHo",
    "outputId": "55ca004b-bca0-468b-f047-ec36a691b1f5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>216.269540</td>\n",
       "      <td>211.134274</td>\n",
       "      <td>215.128316</td>\n",
       "      <td>217.994763</td>\n",
       "      <td>229.527662</td>\n",
       "      <td>228.343740</td>\n",
       "      <td>242.806583</td>\n",
       "      <td>289.728142</td>\n",
       "      <td>294.085892</td>\n",
       "      <td>302.742662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>213.412362</td>\n",
       "      <td>212.203824</td>\n",
       "      <td>210.885199</td>\n",
       "      <td>212.928863</td>\n",
       "      <td>214.608230</td>\n",
       "      <td>221.012875</td>\n",
       "      <td>232.696730</td>\n",
       "      <td>291.971737</td>\n",
       "      <td>299.898413</td>\n",
       "      <td>310.098635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>204.681787</td>\n",
       "      <td>207.336518</td>\n",
       "      <td>210.952538</td>\n",
       "      <td>203.368635</td>\n",
       "      <td>201.143341</td>\n",
       "      <td>212.945396</td>\n",
       "      <td>217.246014</td>\n",
       "      <td>274.878251</td>\n",
       "      <td>284.616328</td>\n",
       "      <td>292.693517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>198.383496</td>\n",
       "      <td>200.987261</td>\n",
       "      <td>197.538109</td>\n",
       "      <td>202.580936</td>\n",
       "      <td>202.908901</td>\n",
       "      <td>212.987482</td>\n",
       "      <td>223.541107</td>\n",
       "      <td>289.059699</td>\n",
       "      <td>300.204667</td>\n",
       "      <td>305.030320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>219.811740</td>\n",
       "      <td>215.888884</td>\n",
       "      <td>220.591784</td>\n",
       "      <td>218.304163</td>\n",
       "      <td>224.051815</td>\n",
       "      <td>230.563012</td>\n",
       "      <td>282.302153</td>\n",
       "      <td>291.526875</td>\n",
       "      <td>302.196239</td>\n",
       "      <td>297.751466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>62.698196</td>\n",
       "      <td>78.611085</td>\n",
       "      <td>139.791254</td>\n",
       "      <td>143.076516</td>\n",
       "      <td>142.163674</td>\n",
       "      <td>150.919528</td>\n",
       "      <td>145.896928</td>\n",
       "      <td>149.493779</td>\n",
       "      <td>152.352166</td>\n",
       "      <td>146.679443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>64.781553</td>\n",
       "      <td>72.263140</td>\n",
       "      <td>83.800937</td>\n",
       "      <td>130.848821</td>\n",
       "      <td>141.944226</td>\n",
       "      <td>142.279298</td>\n",
       "      <td>146.301937</td>\n",
       "      <td>144.274959</td>\n",
       "      <td>144.628356</td>\n",
       "      <td>146.560884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>75.532997</td>\n",
       "      <td>88.519768</td>\n",
       "      <td>134.606680</td>\n",
       "      <td>145.260208</td>\n",
       "      <td>152.214092</td>\n",
       "      <td>151.198150</td>\n",
       "      <td>151.674544</td>\n",
       "      <td>151.286388</td>\n",
       "      <td>152.224362</td>\n",
       "      <td>152.695641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>61.766267</td>\n",
       "      <td>71.418492</td>\n",
       "      <td>79.609229</td>\n",
       "      <td>136.806694</td>\n",
       "      <td>149.697938</td>\n",
       "      <td>149.059237</td>\n",
       "      <td>151.665693</td>\n",
       "      <td>152.244795</td>\n",
       "      <td>151.654347</td>\n",
       "      <td>150.452055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>68.819794</td>\n",
       "      <td>74.071775</td>\n",
       "      <td>80.358485</td>\n",
       "      <td>123.003555</td>\n",
       "      <td>129.832291</td>\n",
       "      <td>140.982057</td>\n",
       "      <td>145.590577</td>\n",
       "      <td>148.889060</td>\n",
       "      <td>145.948128</td>\n",
       "      <td>145.404458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "0   216.269540  211.134274  215.128316  217.994763  229.527662  228.343740   \n",
       "1   213.412362  212.203824  210.885199  212.928863  214.608230  221.012875   \n",
       "2   204.681787  207.336518  210.952538  203.368635  201.143341  212.945396   \n",
       "3   198.383496  200.987261  197.538109  202.580936  202.908901  212.987482   \n",
       "4   219.811740  215.888884  220.591784  218.304163  224.051815  230.563012   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "85   62.698196   78.611085  139.791254  143.076516  142.163674  150.919528   \n",
       "86   64.781553   72.263140   83.800937  130.848821  141.944226  142.279298   \n",
       "87   75.532997   88.519768  134.606680  145.260208  152.214092  151.198150   \n",
       "88   61.766267   71.418492   79.609229  136.806694  149.697938  149.059237   \n",
       "89   68.819794   74.071775   80.358485  123.003555  129.832291  140.982057   \n",
       "\n",
       "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "0   242.806583  289.728142  294.085892  302.742662  \n",
       "1   232.696730  291.971737  299.898413  310.098635  \n",
       "2   217.246014  274.878251  284.616328  292.693517  \n",
       "3   223.541107  289.059699  300.204667  305.030320  \n",
       "4   282.302153  291.526875  302.196239  297.751466  \n",
       "..         ...         ...         ...         ...  \n",
       "85  145.896928  149.493779  152.352166  146.679443  \n",
       "86  146.301937  144.274959  144.628356  146.560884  \n",
       "87  151.674544  151.286388  152.224362  152.695641  \n",
       "88  151.665693  152.244795  151.654347  150.452055  \n",
       "89  145.590577  148.889060  145.948128  145.404458  \n",
       "\n",
       "[90 rows x 10 columns]"
      ]
     },
     "execution_count": 1469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1470,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bVUx-51j2NEz",
    "outputId": "977a455f-19f4-4bb0-9415-4ebf9a65f5b1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x800 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 創建 2x5 的子圖網格\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "fig.suptitle(\"Normal Distributions of Demand Columns\")\n",
    "\n",
    "for idx, column in enumerate(demand_df.columns):\n",
    "    data = demand_df[column].dropna()  # 移除缺失值\n",
    "    mean, std_dev = np.mean(data), np.std(data)\n",
    "\n",
    "    # 產生 x 值範圍\n",
    "    x = np.linspace(mean - 3 * std_dev, mean + 3 * std_dev, 100)\n",
    "    pdf = norm.pdf(x, mean, std_dev)\n",
    "\n",
    "    # 確定當前的軸位置\n",
    "    ax = axes[idx // 5, idx % 5]\n",
    "    ax.hist(data, bins=15, density=True, alpha=0.6, color=\"skyblue\")\n",
    "    ax.plot(\n",
    "        x,\n",
    "        pdf,\n",
    "        \"r-\",\n",
    "        label=f\"Normal Distribution\\nMean={mean:.2f}, StdDev={std_dev:.2f}\",\n",
    "    )\n",
    "    ax.set_xlabel(column)\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.legend()\n",
    "\n",
    "# 移除空白子圖（若有）\n",
    "for idx in range(len(demand_df.columns), 10):\n",
    "    fig.delaxes(axes[idx // 5, idx % 5])\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79eqz9n_cweM"
   },
   "source": [
    "### Validate the covariance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1471,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LRxNQvrdcnxf",
    "outputId": "787e0b16-4a37-4522-d09f-0ea4383dfb1e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>demand_t1</th>\n",
       "      <td>5100.505115</td>\n",
       "      <td>4808.047395</td>\n",
       "      <td>3661.323557</td>\n",
       "      <td>2772.347453</td>\n",
       "      <td>2632.614785</td>\n",
       "      <td>2782.226478</td>\n",
       "      <td>3663.192086</td>\n",
       "      <td>4921.687805</td>\n",
       "      <td>5217.772355</td>\n",
       "      <td>5345.413769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t2</th>\n",
       "      <td>4808.047395</td>\n",
       "      <td>4544.115580</td>\n",
       "      <td>3477.890700</td>\n",
       "      <td>2619.745987</td>\n",
       "      <td>2483.783544</td>\n",
       "      <td>2624.946271</td>\n",
       "      <td>3451.603840</td>\n",
       "      <td>4638.947910</td>\n",
       "      <td>4916.813649</td>\n",
       "      <td>5035.990363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t3</th>\n",
       "      <td>3661.323557</td>\n",
       "      <td>3477.890700</td>\n",
       "      <td>2906.644827</td>\n",
       "      <td>2047.925147</td>\n",
       "      <td>1917.364971</td>\n",
       "      <td>2015.001633</td>\n",
       "      <td>2632.481680</td>\n",
       "      <td>3507.813425</td>\n",
       "      <td>3721.903140</td>\n",
       "      <td>3807.554414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t4</th>\n",
       "      <td>2772.347453</td>\n",
       "      <td>2619.745987</td>\n",
       "      <td>2047.925147</td>\n",
       "      <td>1541.594594</td>\n",
       "      <td>1464.165999</td>\n",
       "      <td>1543.098011</td>\n",
       "      <td>2031.097847</td>\n",
       "      <td>2689.919684</td>\n",
       "      <td>2848.917692</td>\n",
       "      <td>2915.470163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t5</th>\n",
       "      <td>2632.614785</td>\n",
       "      <td>2483.783544</td>\n",
       "      <td>1917.364971</td>\n",
       "      <td>1464.165999</td>\n",
       "      <td>1404.258060</td>\n",
       "      <td>1473.552272</td>\n",
       "      <td>1947.776343</td>\n",
       "      <td>2566.333892</td>\n",
       "      <td>2712.387325</td>\n",
       "      <td>2772.758480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t6</th>\n",
       "      <td>2782.226478</td>\n",
       "      <td>2624.946271</td>\n",
       "      <td>2015.001633</td>\n",
       "      <td>1543.098011</td>\n",
       "      <td>1473.552272</td>\n",
       "      <td>1561.357341</td>\n",
       "      <td>2087.275585</td>\n",
       "      <td>2711.966398</td>\n",
       "      <td>2866.394441</td>\n",
       "      <td>2929.358577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t7</th>\n",
       "      <td>3663.192086</td>\n",
       "      <td>3451.603840</td>\n",
       "      <td>2632.481680</td>\n",
       "      <td>2031.097847</td>\n",
       "      <td>1947.776343</td>\n",
       "      <td>2087.275585</td>\n",
       "      <td>2975.296334</td>\n",
       "      <td>3594.672783</td>\n",
       "      <td>3783.151788</td>\n",
       "      <td>3853.261662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t8</th>\n",
       "      <td>4921.687805</td>\n",
       "      <td>4638.947910</td>\n",
       "      <td>3507.813425</td>\n",
       "      <td>2689.919684</td>\n",
       "      <td>2566.333892</td>\n",
       "      <td>2711.966398</td>\n",
       "      <td>3594.672783</td>\n",
       "      <td>4839.496415</td>\n",
       "      <td>5113.808138</td>\n",
       "      <td>5236.299388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t9</th>\n",
       "      <td>5217.772355</td>\n",
       "      <td>4916.813649</td>\n",
       "      <td>3721.903140</td>\n",
       "      <td>2848.917692</td>\n",
       "      <td>2712.387325</td>\n",
       "      <td>2866.394441</td>\n",
       "      <td>3783.151788</td>\n",
       "      <td>5113.808138</td>\n",
       "      <td>5416.836813</td>\n",
       "      <td>5549.438577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t10</th>\n",
       "      <td>5345.413769</td>\n",
       "      <td>5035.990363</td>\n",
       "      <td>3807.554414</td>\n",
       "      <td>2915.470163</td>\n",
       "      <td>2772.758480</td>\n",
       "      <td>2929.358577</td>\n",
       "      <td>3853.261662</td>\n",
       "      <td>5236.299388</td>\n",
       "      <td>5549.438577</td>\n",
       "      <td>5696.572903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              demand_t1    demand_t2    demand_t3    demand_t4    demand_t5  \\\n",
       "demand_t1   5100.505115  4808.047395  3661.323557  2772.347453  2632.614785   \n",
       "demand_t2   4808.047395  4544.115580  3477.890700  2619.745987  2483.783544   \n",
       "demand_t3   3661.323557  3477.890700  2906.644827  2047.925147  1917.364971   \n",
       "demand_t4   2772.347453  2619.745987  2047.925147  1541.594594  1464.165999   \n",
       "demand_t5   2632.614785  2483.783544  1917.364971  1464.165999  1404.258060   \n",
       "demand_t6   2782.226478  2624.946271  2015.001633  1543.098011  1473.552272   \n",
       "demand_t7   3663.192086  3451.603840  2632.481680  2031.097847  1947.776343   \n",
       "demand_t8   4921.687805  4638.947910  3507.813425  2689.919684  2566.333892   \n",
       "demand_t9   5217.772355  4916.813649  3721.903140  2848.917692  2712.387325   \n",
       "demand_t10  5345.413769  5035.990363  3807.554414  2915.470163  2772.758480   \n",
       "\n",
       "              demand_t6    demand_t7    demand_t8    demand_t9   demand_t10  \n",
       "demand_t1   2782.226478  3663.192086  4921.687805  5217.772355  5345.413769  \n",
       "demand_t2   2624.946271  3451.603840  4638.947910  4916.813649  5035.990363  \n",
       "demand_t3   2015.001633  2632.481680  3507.813425  3721.903140  3807.554414  \n",
       "demand_t4   1543.098011  2031.097847  2689.919684  2848.917692  2915.470163  \n",
       "demand_t5   1473.552272  1947.776343  2566.333892  2712.387325  2772.758480  \n",
       "demand_t6   1561.357341  2087.275585  2711.966398  2866.394441  2929.358577  \n",
       "demand_t7   2087.275585  2975.296334  3594.672783  3783.151788  3853.261662  \n",
       "demand_t8   2711.966398  3594.672783  4839.496415  5113.808138  5236.299388  \n",
       "demand_t9   2866.394441  3783.151788  5113.808138  5416.836813  5549.438577  \n",
       "demand_t10  2929.358577  3853.261662  5236.299388  5549.438577  5696.572903  "
      ]
     },
     "execution_count": 1471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1472,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sfelD3W3dxO8",
    "outputId": "8bbaf932-fa69-4d5d-9a3d-91f3dd739124"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>demand_t1</th>\n",
       "      <td>5091.505115</td>\n",
       "      <td>4804.859210</td>\n",
       "      <td>3656.321521</td>\n",
       "      <td>2772.347453</td>\n",
       "      <td>2636.104748</td>\n",
       "      <td>2782.226479</td>\n",
       "      <td>3664.083741</td>\n",
       "      <td>4924.171298</td>\n",
       "      <td>5217.772355</td>\n",
       "      <td>5345.602092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t2</th>\n",
       "      <td>4804.859210</td>\n",
       "      <td>4535.115580</td>\n",
       "      <td>3472.079677</td>\n",
       "      <td>2619.745987</td>\n",
       "      <td>2488.589204</td>\n",
       "      <td>2624.946271</td>\n",
       "      <td>3454.903248</td>\n",
       "      <td>4638.297838</td>\n",
       "      <td>4916.813649</td>\n",
       "      <td>5036.432500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t3</th>\n",
       "      <td>3656.321521</td>\n",
       "      <td>3472.079677</td>\n",
       "      <td>2897.644886</td>\n",
       "      <td>2047.925147</td>\n",
       "      <td>1921.221383</td>\n",
       "      <td>2015.001633</td>\n",
       "      <td>2637.445552</td>\n",
       "      <td>3507.718362</td>\n",
       "      <td>3721.903140</td>\n",
       "      <td>3808.712789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t4</th>\n",
       "      <td>2772.347453</td>\n",
       "      <td>2619.745987</td>\n",
       "      <td>2047.925147</td>\n",
       "      <td>1541.594594</td>\n",
       "      <td>1464.165999</td>\n",
       "      <td>1543.098011</td>\n",
       "      <td>2031.097847</td>\n",
       "      <td>2689.919684</td>\n",
       "      <td>2848.917692</td>\n",
       "      <td>2915.470163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t5</th>\n",
       "      <td>2636.104748</td>\n",
       "      <td>2488.589204</td>\n",
       "      <td>1921.221383</td>\n",
       "      <td>1464.165999</td>\n",
       "      <td>1395.258060</td>\n",
       "      <td>1473.552272</td>\n",
       "      <td>1945.073550</td>\n",
       "      <td>2563.687715</td>\n",
       "      <td>2712.387325</td>\n",
       "      <td>2773.735417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t6</th>\n",
       "      <td>2782.226479</td>\n",
       "      <td>2624.946271</td>\n",
       "      <td>2015.001633</td>\n",
       "      <td>1543.098011</td>\n",
       "      <td>1473.552272</td>\n",
       "      <td>1561.357341</td>\n",
       "      <td>2087.275584</td>\n",
       "      <td>2711.966398</td>\n",
       "      <td>2866.394441</td>\n",
       "      <td>2929.358577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t7</th>\n",
       "      <td>3664.083741</td>\n",
       "      <td>3454.903248</td>\n",
       "      <td>2637.445552</td>\n",
       "      <td>2031.097847</td>\n",
       "      <td>1945.073550</td>\n",
       "      <td>2087.275584</td>\n",
       "      <td>2966.296334</td>\n",
       "      <td>3594.322311</td>\n",
       "      <td>3783.151788</td>\n",
       "      <td>3848.888829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t8</th>\n",
       "      <td>4924.171298</td>\n",
       "      <td>4638.297838</td>\n",
       "      <td>3507.718362</td>\n",
       "      <td>2689.919684</td>\n",
       "      <td>2563.687715</td>\n",
       "      <td>2711.966398</td>\n",
       "      <td>3594.322311</td>\n",
       "      <td>4830.496415</td>\n",
       "      <td>5113.808138</td>\n",
       "      <td>5235.125003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t9</th>\n",
       "      <td>5217.772355</td>\n",
       "      <td>4916.813649</td>\n",
       "      <td>3721.903140</td>\n",
       "      <td>2848.917692</td>\n",
       "      <td>2712.387325</td>\n",
       "      <td>2866.394441</td>\n",
       "      <td>3783.151788</td>\n",
       "      <td>5113.808138</td>\n",
       "      <td>5416.836813</td>\n",
       "      <td>5549.438577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t10</th>\n",
       "      <td>5345.602092</td>\n",
       "      <td>5036.432500</td>\n",
       "      <td>3808.712789</td>\n",
       "      <td>2915.470163</td>\n",
       "      <td>2773.735417</td>\n",
       "      <td>2929.358577</td>\n",
       "      <td>3848.888829</td>\n",
       "      <td>5235.125003</td>\n",
       "      <td>5549.438577</td>\n",
       "      <td>5687.572903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              demand_t1    demand_t2    demand_t3    demand_t4    demand_t5  \\\n",
       "demand_t1   5091.505115  4804.859210  3656.321521  2772.347453  2636.104748   \n",
       "demand_t2   4804.859210  4535.115580  3472.079677  2619.745987  2488.589204   \n",
       "demand_t3   3656.321521  3472.079677  2897.644886  2047.925147  1921.221383   \n",
       "demand_t4   2772.347453  2619.745987  2047.925147  1541.594594  1464.165999   \n",
       "demand_t5   2636.104748  2488.589204  1921.221383  1464.165999  1395.258060   \n",
       "demand_t6   2782.226479  2624.946271  2015.001633  1543.098011  1473.552272   \n",
       "demand_t7   3664.083741  3454.903248  2637.445552  2031.097847  1945.073550   \n",
       "demand_t8   4924.171298  4638.297838  3507.718362  2689.919684  2563.687715   \n",
       "demand_t9   5217.772355  4916.813649  3721.903140  2848.917692  2712.387325   \n",
       "demand_t10  5345.602092  5036.432500  3808.712789  2915.470163  2773.735417   \n",
       "\n",
       "              demand_t6    demand_t7    demand_t8    demand_t9   demand_t10  \n",
       "demand_t1   2782.226479  3664.083741  4924.171298  5217.772355  5345.602092  \n",
       "demand_t2   2624.946271  3454.903248  4638.297838  4916.813649  5036.432500  \n",
       "demand_t3   2015.001633  2637.445552  3507.718362  3721.903140  3808.712789  \n",
       "demand_t4   1543.098011  2031.097847  2689.919684  2848.917692  2915.470163  \n",
       "demand_t5   1473.552272  1945.073550  2563.687715  2712.387325  2773.735417  \n",
       "demand_t6   1561.357341  2087.275584  2711.966398  2866.394441  2929.358577  \n",
       "demand_t7   2087.275584  2966.296334  3594.322311  3783.151788  3848.888829  \n",
       "demand_t8   2711.966398  3594.322311  4830.496415  5113.808138  5235.125003  \n",
       "demand_t9   2866.394441  3783.151788  5113.808138  5416.836813  5549.438577  \n",
       "demand_t10  2929.358577  3848.888829  5235.125003  5549.438577  5687.572903  "
      ]
     },
     "execution_count": 1472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empirical_covariance = demand_df.cov()\n",
    "covariance_diff = np.abs(empirical_covariance - np.array(cov_matrices).mean(axis=0))\n",
    "covariance_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zoLCr9riPt8d"
   },
   "source": [
    "### Validate the corr matrix of damand_df is close to original setting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>216.269540</td>\n",
       "      <td>211.134274</td>\n",
       "      <td>215.128316</td>\n",
       "      <td>217.994763</td>\n",
       "      <td>229.527662</td>\n",
       "      <td>228.343740</td>\n",
       "      <td>242.806583</td>\n",
       "      <td>289.728142</td>\n",
       "      <td>294.085892</td>\n",
       "      <td>302.742662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>213.412362</td>\n",
       "      <td>212.203824</td>\n",
       "      <td>210.885199</td>\n",
       "      <td>212.928863</td>\n",
       "      <td>214.608230</td>\n",
       "      <td>221.012875</td>\n",
       "      <td>232.696730</td>\n",
       "      <td>291.971737</td>\n",
       "      <td>299.898413</td>\n",
       "      <td>310.098635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>204.681787</td>\n",
       "      <td>207.336518</td>\n",
       "      <td>210.952538</td>\n",
       "      <td>203.368635</td>\n",
       "      <td>201.143341</td>\n",
       "      <td>212.945396</td>\n",
       "      <td>217.246014</td>\n",
       "      <td>274.878251</td>\n",
       "      <td>284.616328</td>\n",
       "      <td>292.693517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>198.383496</td>\n",
       "      <td>200.987261</td>\n",
       "      <td>197.538109</td>\n",
       "      <td>202.580936</td>\n",
       "      <td>202.908901</td>\n",
       "      <td>212.987482</td>\n",
       "      <td>223.541107</td>\n",
       "      <td>289.059699</td>\n",
       "      <td>300.204667</td>\n",
       "      <td>305.030320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>219.811740</td>\n",
       "      <td>215.888884</td>\n",
       "      <td>220.591784</td>\n",
       "      <td>218.304163</td>\n",
       "      <td>224.051815</td>\n",
       "      <td>230.563012</td>\n",
       "      <td>282.302153</td>\n",
       "      <td>291.526875</td>\n",
       "      <td>302.196239</td>\n",
       "      <td>297.751466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>62.698196</td>\n",
       "      <td>78.611085</td>\n",
       "      <td>139.791254</td>\n",
       "      <td>143.076516</td>\n",
       "      <td>142.163674</td>\n",
       "      <td>150.919528</td>\n",
       "      <td>145.896928</td>\n",
       "      <td>149.493779</td>\n",
       "      <td>152.352166</td>\n",
       "      <td>146.679443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>64.781553</td>\n",
       "      <td>72.263140</td>\n",
       "      <td>83.800937</td>\n",
       "      <td>130.848821</td>\n",
       "      <td>141.944226</td>\n",
       "      <td>142.279298</td>\n",
       "      <td>146.301937</td>\n",
       "      <td>144.274959</td>\n",
       "      <td>144.628356</td>\n",
       "      <td>146.560884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>75.532997</td>\n",
       "      <td>88.519768</td>\n",
       "      <td>134.606680</td>\n",
       "      <td>145.260208</td>\n",
       "      <td>152.214092</td>\n",
       "      <td>151.198150</td>\n",
       "      <td>151.674544</td>\n",
       "      <td>151.286388</td>\n",
       "      <td>152.224362</td>\n",
       "      <td>152.695641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>61.766267</td>\n",
       "      <td>71.418492</td>\n",
       "      <td>79.609229</td>\n",
       "      <td>136.806694</td>\n",
       "      <td>149.697938</td>\n",
       "      <td>149.059237</td>\n",
       "      <td>151.665693</td>\n",
       "      <td>152.244795</td>\n",
       "      <td>151.654347</td>\n",
       "      <td>150.452055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>68.819794</td>\n",
       "      <td>74.071775</td>\n",
       "      <td>80.358485</td>\n",
       "      <td>123.003555</td>\n",
       "      <td>129.832291</td>\n",
       "      <td>140.982057</td>\n",
       "      <td>145.590577</td>\n",
       "      <td>148.889060</td>\n",
       "      <td>145.948128</td>\n",
       "      <td>145.404458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "0   216.269540  211.134274  215.128316  217.994763  229.527662  228.343740   \n",
       "1   213.412362  212.203824  210.885199  212.928863  214.608230  221.012875   \n",
       "2   204.681787  207.336518  210.952538  203.368635  201.143341  212.945396   \n",
       "3   198.383496  200.987261  197.538109  202.580936  202.908901  212.987482   \n",
       "4   219.811740  215.888884  220.591784  218.304163  224.051815  230.563012   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "85   62.698196   78.611085  139.791254  143.076516  142.163674  150.919528   \n",
       "86   64.781553   72.263140   83.800937  130.848821  141.944226  142.279298   \n",
       "87   75.532997   88.519768  134.606680  145.260208  152.214092  151.198150   \n",
       "88   61.766267   71.418492   79.609229  136.806694  149.697938  149.059237   \n",
       "89   68.819794   74.071775   80.358485  123.003555  129.832291  140.982057   \n",
       "\n",
       "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "0   242.806583  289.728142  294.085892  302.742662  \n",
       "1   232.696730  291.971737  299.898413  310.098635  \n",
       "2   217.246014  274.878251  284.616328  292.693517  \n",
       "3   223.541107  289.059699  300.204667  305.030320  \n",
       "4   282.302153  291.526875  302.196239  297.751466  \n",
       "..         ...         ...         ...         ...  \n",
       "85  145.896928  149.493779  152.352166  146.679443  \n",
       "86  146.301937  144.274959  144.628356  146.560884  \n",
       "87  151.674544  151.286388  152.224362  152.695641  \n",
       "88  151.665693  152.244795  151.654347  150.452055  \n",
       "89  145.590577  148.889060  145.948128  145.404458  \n",
       "\n",
       "[90 rows x 10 columns]"
      ]
     },
     "execution_count": 1473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1474,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YLqFAdfQPz6O",
    "outputId": "aaa6eb63-394c-40f8-8d58-665e9fb63026"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Matrix from demand_df:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>demand_t1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998706</td>\n",
       "      <td>0.950902</td>\n",
       "      <td>0.988681</td>\n",
       "      <td>0.983688</td>\n",
       "      <td>0.985904</td>\n",
       "      <td>0.940347</td>\n",
       "      <td>0.990621</td>\n",
       "      <td>0.992672</td>\n",
       "      <td>0.991672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t2</th>\n",
       "      <td>0.998706</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956963</td>\n",
       "      <td>0.989804</td>\n",
       "      <td>0.983254</td>\n",
       "      <td>0.985473</td>\n",
       "      <td>0.938709</td>\n",
       "      <td>0.989224</td>\n",
       "      <td>0.991029</td>\n",
       "      <td>0.989814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t3</th>\n",
       "      <td>0.950902</td>\n",
       "      <td>0.956963</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967460</td>\n",
       "      <td>0.949042</td>\n",
       "      <td>0.945863</td>\n",
       "      <td>0.895167</td>\n",
       "      <td>0.935277</td>\n",
       "      <td>0.937986</td>\n",
       "      <td>0.935714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t4</th>\n",
       "      <td>0.988681</td>\n",
       "      <td>0.989804</td>\n",
       "      <td>0.967460</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995134</td>\n",
       "      <td>0.994620</td>\n",
       "      <td>0.948376</td>\n",
       "      <td>0.984814</td>\n",
       "      <td>0.985875</td>\n",
       "      <td>0.983822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t5</th>\n",
       "      <td>0.983688</td>\n",
       "      <td>0.983254</td>\n",
       "      <td>0.949042</td>\n",
       "      <td>0.995134</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995155</td>\n",
       "      <td>0.952907</td>\n",
       "      <td>0.984441</td>\n",
       "      <td>0.983457</td>\n",
       "      <td>0.980351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t6</th>\n",
       "      <td>0.985904</td>\n",
       "      <td>0.985473</td>\n",
       "      <td>0.945863</td>\n",
       "      <td>0.994620</td>\n",
       "      <td>0.995155</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968419</td>\n",
       "      <td>0.986582</td>\n",
       "      <td>0.985625</td>\n",
       "      <td>0.982233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t7</th>\n",
       "      <td>0.940347</td>\n",
       "      <td>0.938709</td>\n",
       "      <td>0.895167</td>\n",
       "      <td>0.948376</td>\n",
       "      <td>0.952907</td>\n",
       "      <td>0.968419</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947314</td>\n",
       "      <td>0.942358</td>\n",
       "      <td>0.935958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t8</th>\n",
       "      <td>0.990621</td>\n",
       "      <td>0.989224</td>\n",
       "      <td>0.935277</td>\n",
       "      <td>0.984814</td>\n",
       "      <td>0.984441</td>\n",
       "      <td>0.986582</td>\n",
       "      <td>0.947314</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998784</td>\n",
       "      <td>0.997281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t9</th>\n",
       "      <td>0.992672</td>\n",
       "      <td>0.991029</td>\n",
       "      <td>0.937986</td>\n",
       "      <td>0.985875</td>\n",
       "      <td>0.983457</td>\n",
       "      <td>0.985625</td>\n",
       "      <td>0.942358</td>\n",
       "      <td>0.998784</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t10</th>\n",
       "      <td>0.991672</td>\n",
       "      <td>0.989814</td>\n",
       "      <td>0.935714</td>\n",
       "      <td>0.983822</td>\n",
       "      <td>0.980351</td>\n",
       "      <td>0.982233</td>\n",
       "      <td>0.935958</td>\n",
       "      <td>0.997281</td>\n",
       "      <td>0.999009</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            demand_t1  demand_t2  demand_t3  demand_t4  demand_t5  demand_t6  \\\n",
       "demand_t1    1.000000   0.998706   0.950902   0.988681   0.983688   0.985904   \n",
       "demand_t2    0.998706   1.000000   0.956963   0.989804   0.983254   0.985473   \n",
       "demand_t3    0.950902   0.956963   1.000000   0.967460   0.949042   0.945863   \n",
       "demand_t4    0.988681   0.989804   0.967460   1.000000   0.995134   0.994620   \n",
       "demand_t5    0.983688   0.983254   0.949042   0.995134   1.000000   0.995155   \n",
       "demand_t6    0.985904   0.985473   0.945863   0.994620   0.995155   1.000000   \n",
       "demand_t7    0.940347   0.938709   0.895167   0.948376   0.952907   0.968419   \n",
       "demand_t8    0.990621   0.989224   0.935277   0.984814   0.984441   0.986582   \n",
       "demand_t9    0.992672   0.991029   0.937986   0.985875   0.983457   0.985625   \n",
       "demand_t10   0.991672   0.989814   0.935714   0.983822   0.980351   0.982233   \n",
       "\n",
       "            demand_t7  demand_t8  demand_t9  demand_t10  \n",
       "demand_t1    0.940347   0.990621   0.992672    0.991672  \n",
       "demand_t2    0.938709   0.989224   0.991029    0.989814  \n",
       "demand_t3    0.895167   0.935277   0.937986    0.935714  \n",
       "demand_t4    0.948376   0.984814   0.985875    0.983822  \n",
       "demand_t5    0.952907   0.984441   0.983457    0.980351  \n",
       "demand_t6    0.968419   0.986582   0.985625    0.982233  \n",
       "demand_t7    1.000000   0.947314   0.942358    0.935958  \n",
       "demand_t8    0.947314   1.000000   0.998784    0.997281  \n",
       "demand_t9    0.942358   0.998784   1.000000    0.999009  \n",
       "demand_t10   0.935958   0.997281   0.999009    1.000000  "
      ]
     },
     "execution_count": 1474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_matrix = demand_df.corr()\n",
    "print(\"Correlation Matrix from demand_df:\")\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1475,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bsBxErYBQDXT",
    "outputId": "0b94e967-9e3d-4114-f049-cada8da8e427"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original corr_matrix shape: (10, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.354243</td>\n",
       "      <td>0.555784</td>\n",
       "      <td>0.587411</td>\n",
       "      <td>-0.387774</td>\n",
       "      <td>-0.161484</td>\n",
       "      <td>-0.099073</td>\n",
       "      <td>-0.275944</td>\n",
       "      <td>-0.488891</td>\n",
       "      <td>-0.020925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.354243</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.645671</td>\n",
       "      <td>0.344249</td>\n",
       "      <td>-0.533962</td>\n",
       "      <td>-0.118714</td>\n",
       "      <td>-0.366601</td>\n",
       "      <td>0.072230</td>\n",
       "      <td>0.109958</td>\n",
       "      <td>-0.049126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.555784</td>\n",
       "      <td>0.645671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.259728</td>\n",
       "      <td>-0.428492</td>\n",
       "      <td>-0.236520</td>\n",
       "      <td>-0.551543</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>-0.414246</td>\n",
       "      <td>-0.128709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.587411</td>\n",
       "      <td>0.344249</td>\n",
       "      <td>0.259728</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.433716</td>\n",
       "      <td>-0.078962</td>\n",
       "      <td>0.166233</td>\n",
       "      <td>-0.631022</td>\n",
       "      <td>0.089139</td>\n",
       "      <td>0.244177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.387774</td>\n",
       "      <td>-0.533962</td>\n",
       "      <td>-0.428492</td>\n",
       "      <td>-0.433716</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.371399</td>\n",
       "      <td>0.300310</td>\n",
       "      <td>0.294020</td>\n",
       "      <td>-0.153719</td>\n",
       "      <td>-0.108549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.161484</td>\n",
       "      <td>-0.118714</td>\n",
       "      <td>-0.236520</td>\n",
       "      <td>-0.078962</td>\n",
       "      <td>0.371399</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.658292</td>\n",
       "      <td>0.520508</td>\n",
       "      <td>-0.341738</td>\n",
       "      <td>0.147419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.099073</td>\n",
       "      <td>-0.366601</td>\n",
       "      <td>-0.551543</td>\n",
       "      <td>0.166233</td>\n",
       "      <td>0.300310</td>\n",
       "      <td>0.658292</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.038941</td>\n",
       "      <td>-0.009772</td>\n",
       "      <td>0.485870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.275944</td>\n",
       "      <td>0.072230</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>-0.631022</td>\n",
       "      <td>0.294020</td>\n",
       "      <td>0.520508</td>\n",
       "      <td>0.038941</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.203659</td>\n",
       "      <td>0.130487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.488891</td>\n",
       "      <td>0.109958</td>\n",
       "      <td>-0.414246</td>\n",
       "      <td>0.089139</td>\n",
       "      <td>-0.153719</td>\n",
       "      <td>-0.341738</td>\n",
       "      <td>-0.009772</td>\n",
       "      <td>-0.203659</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.355112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.020925</td>\n",
       "      <td>-0.049126</td>\n",
       "      <td>-0.128709</td>\n",
       "      <td>0.244177</td>\n",
       "      <td>-0.108549</td>\n",
       "      <td>0.147419</td>\n",
       "      <td>0.485870</td>\n",
       "      <td>0.130487</td>\n",
       "      <td>0.355112</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.000000  0.354243  0.555784  0.587411 -0.387774 -0.161484 -0.099073   \n",
       "1  0.354243  1.000000  0.645671  0.344249 -0.533962 -0.118714 -0.366601   \n",
       "2  0.555784  0.645671  1.000000  0.259728 -0.428492 -0.236520 -0.551543   \n",
       "3  0.587411  0.344249  0.259728  1.000000 -0.433716 -0.078962  0.166233   \n",
       "4 -0.387774 -0.533962 -0.428492 -0.433716  1.000000  0.371399  0.300310   \n",
       "5 -0.161484 -0.118714 -0.236520 -0.078962  0.371399  1.000000  0.658292   \n",
       "6 -0.099073 -0.366601 -0.551543  0.166233  0.300310  0.658292  1.000000   \n",
       "7 -0.275944  0.072230  0.010563 -0.631022  0.294020  0.520508  0.038941   \n",
       "8 -0.488891  0.109958 -0.414246  0.089139 -0.153719 -0.341738 -0.009772   \n",
       "9 -0.020925 -0.049126 -0.128709  0.244177 -0.108549  0.147419  0.485870   \n",
       "\n",
       "          7         8         9  \n",
       "0 -0.275944 -0.488891 -0.020925  \n",
       "1  0.072230  0.109958 -0.049126  \n",
       "2  0.010563 -0.414246 -0.128709  \n",
       "3 -0.631022  0.089139  0.244177  \n",
       "4  0.294020 -0.153719 -0.108549  \n",
       "5  0.520508 -0.341738  0.147419  \n",
       "6  0.038941 -0.009772  0.485870  \n",
       "7  1.000000 -0.203659  0.130487  \n",
       "8 -0.203659  1.000000  0.355112  \n",
       "9  0.130487  0.355112  1.000000  "
      ]
     },
     "execution_count": 1475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Original corr_matrix shape: {corr_matrix.shape}\")\n",
    "corr_matrix_df = pd.DataFrame(corr_matrix)\n",
    "corr_matrix_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hne073eTB2gq"
   },
   "source": [
    "### Split test and train demand_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Train Data:\n",
      "(15, 10)\n",
      "Test Data:\n",
      "(15, 10)\n",
      "========================================\n",
      "Fold 2:\n",
      "Train Data:\n",
      "(15, 10)\n",
      "Test Data:\n",
      "(15, 10)\n",
      "========================================\n",
      "Fold 3:\n",
      "Train Data:\n",
      "(15, 10)\n",
      "Test Data:\n",
      "(15, 10)\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "def demand_data_split_data_k_fold(data):\n",
    "    folds = []\n",
    "    chunk_size = CHUNK_SIZE  # 每組 60 筆資料\n",
    "    train_chunk = int(train_size * chunk_size)\n",
    "\n",
    "    n = len(data)\n",
    "    # 依序切分每一個 chunk\n",
    "    for start in range(0, n, chunk_size):\n",
    "        # 若剩餘資料不足 60 筆，這裡直接跳過\n",
    "        if start + chunk_size > n:\n",
    "            break\n",
    "        chunk = data.iloc[start : start + chunk_size].reset_index(drop=True)\n",
    "        train_data = chunk.iloc[:train_chunk].reset_index(drop=True)\n",
    "        test_data = chunk.iloc[train_chunk:].reset_index(drop=True)\n",
    "        folds.append((train_data, test_data))\n",
    "\n",
    "    return folds\n",
    "\n",
    "\n",
    "# 使用函數切分資料\n",
    "demand_folds = demand_data_split_data_k_fold(demand_df)\n",
    "\n",
    "# 印出結果，每個 fold 的訓練與測試資料\n",
    "for i, (train_data, test_data) in enumerate(demand_folds, 1):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(\"Train Data:\")\n",
    "    print(train_data.shape)\n",
    "    print(\"Test Data:\")\n",
    "    print(test_data.shape)\n",
    "    print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJ2ej5ZlAg1e"
   },
   "source": [
    "### Define the Q star(Q optimal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1477,
   "metadata": {
    "id": "JZM_eOn8ldpT"
   },
   "outputs": [],
   "source": [
    "def calculate_Q_star(demand_df, service_level=0.95):\n",
    "\n",
    "    # 計算每一行的總和\n",
    "    demand_sum = demand_df.sum(axis=1)\n",
    "\n",
    "    # 計算總和的均值和標準差\n",
    "    mean_sum = demand_sum.mean()\n",
    "    std_sum = demand_sum.std()\n",
    "\n",
    "    # 計算總和的95%百分位數值\n",
    "    Q_star = norm.ppf(service_level, loc=mean_sum, scale=std_sum)\n",
    "\n",
    "    # 打印結果\n",
    "    print(f\"mean of sum: {mean_sum}\")\n",
    "    print(f\"std of sum: {std_sum}\")\n",
    "    print(f\"{service_level*100} percentile of sum: {Q_star}\")\n",
    "\n",
    "    return Q_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "  0   216.269540  211.134274  215.128316  217.994763  229.527662  228.343740   \n",
       "  1   213.412362  212.203824  210.885199  212.928863  214.608230  221.012875   \n",
       "  2   204.681787  207.336518  210.952538  203.368635  201.143341  212.945396   \n",
       "  3   198.383496  200.987261  197.538109  202.580936  202.908901  212.987482   \n",
       "  4   219.811740  215.888884  220.591784  218.304163  224.051815  230.563012   \n",
       "  5   220.360046  221.653541  221.084469  221.365066  219.588375  230.349881   \n",
       "  6   206.804647  210.281255  211.971112  211.899313  212.103444  223.938525   \n",
       "  7   197.500672  202.217054  202.132739  203.477299  205.711701  209.558780   \n",
       "  8   204.862165  204.349647  204.410897  203.832857  198.517193  209.219411   \n",
       "  9   214.729484  211.058905  213.111249  213.393977  216.269393  226.294654   \n",
       "  10  203.536333  198.875464  199.443303  206.642554  213.162637  213.806483   \n",
       "  11  211.399931  203.772432  204.362386  211.367124  219.630126  222.009609   \n",
       "  12  200.333009  200.122945  201.407273  202.457942  209.620603  212.527752   \n",
       "  13  215.485256  214.091043  212.898490  213.282515  211.999879  219.028557   \n",
       "  14  223.772374  219.297995  227.067323  224.128681  227.334861  242.102041   \n",
       "  \n",
       "       demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "  0   242.806583  289.728142  294.085892  302.742662  \n",
       "  1   232.696730  291.971737  299.898413  310.098635  \n",
       "  2   217.246014  274.878251  284.616328  292.693517  \n",
       "  3   223.541107  289.059699  300.204667  305.030320  \n",
       "  4   282.302153  291.526875  302.196239  297.751466  \n",
       "  5   239.096051  287.137346  298.313381  302.956429  \n",
       "  6   279.861703  289.879410  300.275223  301.905500  \n",
       "  7   218.989494  282.840421  291.370366  300.913051  \n",
       "  8   213.080292  285.593964  296.148638  306.810950  \n",
       "  9   277.908923  287.515460  293.452452  298.903205  \n",
       "  10  226.483521  286.300518  295.724523  295.565024  \n",
       "  11  239.661313  287.100126  295.098417  300.312782  \n",
       "  12  224.286097  289.751327  295.640317  296.230690  \n",
       "  13  226.998326  277.137760  290.303325  296.421243  \n",
       "  14  285.157984  297.060136  300.922758  304.073340  ,\n",
       "      demand_t1  demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "  0   70.227917  81.121645  131.788409  141.803321  143.426979  147.673785   \n",
       "  1   79.608727  91.639215  128.702757  135.028793  134.579449  140.268787   \n",
       "  2   63.419471  70.874302   77.661979  132.558616  142.859878  148.998521   \n",
       "  3   52.116936  63.450198   73.716363  123.035381  131.841477  138.583452   \n",
       "  4   60.415934  67.035420   74.759950  125.505731  131.973688  142.549592   \n",
       "  5   63.891435  69.705305   78.722662  124.306490  138.151168  143.032748   \n",
       "  6   70.216180  78.598394   84.946904  121.995492  133.578784  137.888674   \n",
       "  7   63.185446  71.742871  120.581034  130.522874  136.377091  141.022977   \n",
       "  8   70.992077  75.616666   82.533829  125.466173  133.000874  141.053282   \n",
       "  9   70.526757  84.725666  130.149324  137.570580  142.534312  143.754643   \n",
       "  10  55.599240  61.360904   73.969731  125.839593  135.145787  139.117788   \n",
       "  11  76.219043  89.003219  127.269401  135.126808  137.205275  141.572859   \n",
       "  12  52.094021  62.108609   68.768801  123.756371  140.592759  141.971262   \n",
       "  13  76.509810  77.459588   92.319729  128.061079  135.441582  139.470053   \n",
       "  14  71.680424  85.624544  120.815521  130.085328  134.069275  139.907755   \n",
       "  \n",
       "       demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "  0   150.205352  144.538643  148.686424  152.970565  \n",
       "  1   145.314588  142.865421  141.157079  144.668688  \n",
       "  2   155.162599  155.783147  153.172861  154.443828  \n",
       "  3   136.399301  138.619786  142.363281  140.167618  \n",
       "  4   141.600813  144.825519  147.015787  148.199725  \n",
       "  5   145.171105  149.727225  148.451307  149.989241  \n",
       "  6   143.451611  143.435230  141.816459  143.709674  \n",
       "  7   141.719665  141.606493  143.111705  139.494170  \n",
       "  8   140.385933  143.311775  144.849568  141.009104  \n",
       "  9   141.951848  142.737482  144.830817  144.223385  \n",
       "  10  140.487488  143.253560  142.044079  141.546400  \n",
       "  11  140.719360  140.781289  142.703000  138.273542  \n",
       "  12  141.598922  153.777150  147.074707  142.399240  \n",
       "  13  144.019581  140.131849  141.812887  142.555552  \n",
       "  14  138.392343  148.279216  141.817695  142.604815  ),\n",
       " (     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "  0   222.161187  222.674769  225.353917  223.221310  222.893692  238.065400   \n",
       "  1   220.530094  219.738950  218.759769  220.933432  220.124623  228.300609   \n",
       "  2   213.362537  218.822792  216.870371  217.362713  219.563800  229.111736   \n",
       "  3   199.797687  207.323601  203.789124  207.736732  210.971595  217.800933   \n",
       "  4   201.639849  204.461900  204.373246  211.688475  219.980465  230.453114   \n",
       "  5   203.068617  210.253707  211.044927  208.252652  210.515431  217.622674   \n",
       "  6   200.028086  200.649557  201.110990  203.196222  208.172300  212.642934   \n",
       "  7   209.370477  211.540854  211.088956  213.227575  217.505323  222.607287   \n",
       "  8   212.532495  213.315555  214.680239  211.469208  208.301130  217.041472   \n",
       "  9   207.618493  211.794800  208.888392  213.191496  215.856144  221.701392   \n",
       "  10  207.056248  210.847827  208.026988  209.464407  214.390723  222.751866   \n",
       "  11  206.903862  203.906252  207.385176  205.308491  204.528274  217.356427   \n",
       "  12  206.768808  202.093273  201.684832  207.410315  211.014986  215.716571   \n",
       "  13  211.774461  215.380556  214.549172  217.086505  225.127256  235.226440   \n",
       "  14  216.725708  216.467046  218.712706  218.300728  222.101593  227.007575   \n",
       "  \n",
       "       demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "  0   280.312076  287.113818  295.476806  301.581639  \n",
       "  1   239.480837  278.599581  292.608620  299.370778  \n",
       "  2   264.688890  278.406242  285.268849  285.786165  \n",
       "  3   231.228251  281.000002  285.687011  285.367038  \n",
       "  4   279.671471  284.587074  289.916916  290.508358  \n",
       "  5   225.661659  285.838794  290.975307  292.078159  \n",
       "  6   225.213431  291.325190  296.608369  302.124771  \n",
       "  7   231.530616  282.838947  288.006589  291.168008  \n",
       "  8   222.363761  259.051539  279.508591  284.723369  \n",
       "  9   231.422106  289.526303  300.437872  305.779847  \n",
       "  10  280.193543  295.421032  298.712701  297.452760  \n",
       "  11  277.360165  290.208239  298.996474  304.379612  \n",
       "  12  228.428223  270.682926  285.297802  290.140345  \n",
       "  13  272.923294  287.175093  287.743459  285.591008  \n",
       "  14  233.518253  273.349587  282.149117  284.578008  ,\n",
       "      demand_t1  demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "  0   72.009341  74.997743   87.005613  128.348847  132.655500  142.127494   \n",
       "  1   75.795766  83.482632  141.773017  150.698577  153.139419  157.886776   \n",
       "  2   69.530409  78.997508  139.540892  144.071128  143.380065  150.365428   \n",
       "  3   68.809892  78.215789  128.691086  141.307123  149.945005  149.781344   \n",
       "  4   64.970365  70.317737  144.067324  148.114171  154.964918  157.228781   \n",
       "  5   61.214051  71.651536   83.195967  142.057095  151.063978  154.218832   \n",
       "  6   68.135098  77.074529  116.844346  133.674097  137.638788  143.839906   \n",
       "  7   67.593216  71.811630   78.765094  123.220756  134.731523  142.090958   \n",
       "  8   82.760314  98.611711  142.416633  144.507976  144.328414  150.527009   \n",
       "  9   78.667055  87.035540  135.495516  145.326754  154.982092  152.497608   \n",
       "  10  73.323629  85.298402  134.014373  142.154358  144.857784  148.793222   \n",
       "  11  66.698211  76.821448   83.183982  136.220205  146.781319  149.712745   \n",
       "  12  65.400532  74.729399  133.985731  142.957392  152.664942  150.652859   \n",
       "  13  61.466612  68.275961  126.848571  133.236399  138.154667  143.807840   \n",
       "  14  70.101169  80.342774  125.119997  136.763122  140.617546  144.351719   \n",
       "  \n",
       "       demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "  0   143.667318  146.757340  145.226417  146.246406  \n",
       "  1   157.120115  160.255430  159.174422  154.083678  \n",
       "  2   143.087074  150.143303  151.464211  150.393109  \n",
       "  3   152.159759  146.176481  151.359503  156.142474  \n",
       "  4   154.225794  161.729377  158.960790  160.413033  \n",
       "  5   157.783124  159.201692  156.785961  157.766049  \n",
       "  6   148.444796  141.058813  145.839363  148.821352  \n",
       "  7   142.116537  141.833349  147.603113  144.935219  \n",
       "  8   149.120515  152.715787  151.569603  151.212534  \n",
       "  9   152.332204  154.227160  153.781491  150.241387  \n",
       "  10  151.988611  153.420355  149.963613  149.547872  \n",
       "  11  154.821903  153.684922  152.712027  154.495989  \n",
       "  12  149.533798  153.490008  152.052310  148.127874  \n",
       "  13  141.438731  141.799862  145.915902  141.017522  \n",
       "  14  146.299292  144.897715  145.727324  147.517382  ),\n",
       " (     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "  0   216.647776  217.707632  217.106637  216.842714  219.597076  233.419212   \n",
       "  1   206.392192  207.466613  209.843167  207.604607  213.000352  224.961254   \n",
       "  2   208.757150  211.215125  210.251555  213.156271  218.505110  222.001409   \n",
       "  3   211.765499  214.318603  215.414811  216.141472  219.949536  233.053752   \n",
       "  4   212.809346  217.810872  213.306858  217.226836  220.572888  233.189850   \n",
       "  5   215.874024  216.634876  219.161295  220.970899  229.078910  234.109029   \n",
       "  6   208.663645  212.202013  212.214505  209.993864  212.365034  216.827046   \n",
       "  7   214.795873  214.957004  218.508049  221.137495  226.253158  238.703949   \n",
       "  8   204.887138  207.948928  204.303492  203.239600  207.493960  209.886562   \n",
       "  9   213.251598  213.261233  212.440552  219.307496  221.331998  236.889734   \n",
       "  10  208.525023  203.488282  205.712190  203.930813  203.325865  209.200737   \n",
       "  11  205.089368  202.923453  206.838589  205.766863  206.676825  217.322137   \n",
       "  12  200.903965  205.939596  203.960886  203.417689  204.627082  208.684890   \n",
       "  13  213.954358  215.974160  219.545605  218.086512  222.010790  227.634165   \n",
       "  14  208.134237  213.335557  212.206389  209.640137  210.502901  217.426165   \n",
       "  \n",
       "       demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "  0   281.223054  286.606612  295.373362  295.021682  \n",
       "  1   275.069930  290.849170  293.042855  290.427386  \n",
       "  2   233.240220  284.029835  294.011162  298.315636  \n",
       "  3   285.949828  296.587134  299.984362  300.882037  \n",
       "  4   283.261878  291.515898  295.193378  301.422180  \n",
       "  5   272.091637  289.444930  292.637615  290.154113  \n",
       "  6   222.394845  288.244280  297.610300  300.054982  \n",
       "  7   283.869552  292.548952  301.227187  296.088081  \n",
       "  8   219.793122  286.423417  297.882888  307.923009  \n",
       "  9   296.471696  298.622569  307.131742  309.556117  \n",
       "  10  211.768872  282.906452  294.373221  295.898815  \n",
       "  11  276.893707  286.436047  296.672410  301.681387  \n",
       "  12  216.679969  282.292518  293.965063  298.664190  \n",
       "  13  232.487659  282.208998  294.230272  299.601931  \n",
       "  14  223.577690  277.934792  282.421103  285.004960  ,\n",
       "      demand_t1  demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "  0   76.726007  85.292909  133.499628  142.686827  151.989907  148.099649   \n",
       "  1   73.215452  84.322469  140.436462  147.706836  153.427440  155.765750   \n",
       "  2   81.614354  93.288630  142.735808  149.774088  154.774819  155.977932   \n",
       "  3   53.997127  65.378692  122.601776  137.369862  143.971341  145.596807   \n",
       "  4   79.623523  88.635007  129.643968  136.108997  141.327015  142.297723   \n",
       "  5   66.573648  73.473881  116.509127  130.907484  138.170199  139.414829   \n",
       "  6   61.543065  69.925424  118.981441  128.541003  130.878560  138.357764   \n",
       "  7   77.934606  89.308782  127.931099  137.811266  140.377104  143.458587   \n",
       "  8   61.555771  65.481206   76.431186  141.016287  148.612409  155.152840   \n",
       "  9   71.879524  75.816228   88.691319  125.840719  138.654339  137.945803   \n",
       "  10  62.698196  78.611085  139.791254  143.076516  142.163674  150.919528   \n",
       "  11  64.781553  72.263140   83.800937  130.848821  141.944226  142.279298   \n",
       "  12  75.532997  88.519768  134.606680  145.260208  152.214092  151.198150   \n",
       "  13  61.766267  71.418492   79.609229  136.806694  149.697938  149.059237   \n",
       "  14  68.819794  74.071775   80.358485  123.003555  129.832291  140.982057   \n",
       "  \n",
       "       demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "  0   147.917016  153.114936  149.021591  145.097141  \n",
       "  1   155.706461  157.681604  157.247505  159.518788  \n",
       "  2   156.344506  152.764874  157.058150  156.135556  \n",
       "  3   148.718305  148.766359  147.117258  151.321785  \n",
       "  4   143.193646  140.258585  143.374846  140.789340  \n",
       "  5   143.089660  141.209537  141.000788  144.971862  \n",
       "  6   139.188552  143.200519  140.266246  142.386797  \n",
       "  7   144.180047  142.103770  144.426712  143.175555  \n",
       "  8   160.099228  158.393803  158.380157  160.635284  \n",
       "  9   139.968061  144.014399  140.495582  140.628759  \n",
       "  10  145.896928  149.493779  152.352166  146.679443  \n",
       "  11  146.301937  144.274959  144.628356  146.560884  \n",
       "  12  151.674544  151.286388  152.224362  152.695641  \n",
       "  13  151.665693  152.244795  151.654347  150.452055  \n",
       "  14  145.590577  148.889060  145.948128  145.404458  )]"
      ]
     },
     "execution_count": 1478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1479,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AxUzUg3JmmDz",
    "outputId": "90d6c954-d522-46e7-bccd-09ce837a852f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of sum: 2400.9164885329315\n",
      "std of sum: 75.12106255060029\n",
      "95.0 percentile of sum: 2524.479640729735\n",
      "Q_star: 2524.479640729735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# demand_df_train_1 = demand_folds[0][0]\n",
    "# Q_star = calculate_Q_star(demand_df_train_1, service_level=0.95)\n",
    "# print(f\"Q_star: {Q_star}\\n\")\n",
    "\n",
    "# demand_df_train_2 = demand_folds[1][0]\n",
    "# Q_star = calculate_Q_star(demand_df_train_2, service_level=0.95)\n",
    "# print(f\"Q_star: {Q_star}\\n\")\n",
    "\n",
    "demand_df_train_1 = demand_folds[0][0]\n",
    "Q_star = calculate_Q_star(demand_df_train_1, service_level=0.95)\n",
    "print(f\"Q_star: {Q_star}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pl8jIyaJmbAj"
   },
   "source": [
    "## Data3: Qk hat df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFQx0fsxhSfc"
   },
   "source": [
    "### Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1480,
   "metadata": {
    "id": "kY0mTXa7hdfH"
   },
   "outputs": [],
   "source": [
    "# 計算條件分佈的函數\n",
    "def calculate_conditional_distribution(mu, covariance_matrix, x_observed, k):\n",
    "    mu_1 = mu[:k]\n",
    "    mu_2 = mu[k:]\n",
    "    Sigma_11 = covariance_matrix[:k, :k]\n",
    "    Sigma_22 = covariance_matrix[k:, k:]\n",
    "    Sigma_12 = covariance_matrix[k:, :k]\n",
    "    Sigma_21 = covariance_matrix[:k, k:]\n",
    "\n",
    "    # Compute conditional mean and covariance\n",
    "    Sigma_11_inv = np.linalg.pinv(Sigma_11)\n",
    "    mu_cond = mu_2 + np.dot(Sigma_12, np.dot(Sigma_11_inv, (x_observed - mu_1)))\n",
    "    sigma_cond = Sigma_22 - np.dot(Sigma_12, np.dot(Sigma_11_inv, Sigma_21))\n",
    "\n",
    "    return mu_cond, sigma_cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1481,
   "metadata": {
    "id": "uSbq87Meihmj"
   },
   "outputs": [],
   "source": [
    "def cal_Var_Y(sigma_cond):\n",
    "\n",
    "    # Extract the variances (diagonal elements)\n",
    "    variances = np.diag(sigma_cond)\n",
    "\n",
    "    # Calculate the sum of covariances (off-diagonal elements)\n",
    "    covariances_sum = np.sum(sigma_cond) - np.sum(variances)\n",
    "\n",
    "    # Total variance for the sum of mu_cond\n",
    "    total_variance = np.sum(variances) + covariances_sum\n",
    "\n",
    "    return total_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1482,
   "metadata": {
    "id": "FySGAFQrrKX0"
   },
   "outputs": [],
   "source": [
    "def cal_Qk_hat(mu_cond, sigma_cond, service_level, x_observed):\n",
    "    # predict_quantity = mu_cond + norm.ppf(service_level) * np.sqrt(np.diag(sigma_cond))\n",
    "    # Qk_hat = x_observed.sum() + predict_quantity.sum()\n",
    "\n",
    "    mean_Y = np.sum(mu_cond)\n",
    "    var_Y = cal_Var_Y(sigma_cond)\n",
    "\n",
    "    sd_Y = np.sqrt(var_Y)\n",
    "    if sd_Y < 0 or np.isnan(sd_Y):  # scale must be positive\n",
    "        sd_Y = 1e-6\n",
    "\n",
    "    percentile_95_Y = norm.ppf(service_level, loc=mean_Y, scale=sd_Y)\n",
    "\n",
    "    # print(f\"        mean_Y: {mean_Y}\")\n",
    "    # print(f\"        sd_Y: {sd_Y}\")\n",
    "    # print(f\"    percentile_95_Y: {percentile_95_Y}\")\n",
    "\n",
    "    Qk_hat = x_observed.sum() + percentile_95_Y\n",
    "    return Qk_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1483,
   "metadata": {
    "id": "rZp0UnPjm0Zb"
   },
   "outputs": [],
   "source": [
    "def cal_mu_and_cov_matrix(demand_df_train):\n",
    "\n",
    "    mu_matrix = demand_df_train.mean().values\n",
    "    covariance_matrix = demand_df_train.cov().values\n",
    "\n",
    "    # print(f\"mu_matrix: {mu_matrix}\")\n",
    "    # print(f\"covariance_matrix: \\n{covariance_matrix}\\n\")\n",
    "\n",
    "    return mu_matrix, covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1484,
   "metadata": {
    "id": "aaJEWprdphY9"
   },
   "outputs": [],
   "source": [
    "def make_Qk_hat_df(demand_df, T, service_level, mu_matrix, covariance_matrix):\n",
    "    results_df = pd.DataFrame(index=demand_df.index)\n",
    "\n",
    "    for index, row_data in demand_df.iterrows():\n",
    "        for k in range(2, T):\n",
    "            # print(f\"Now processing index: {index}, t={k}\")\n",
    "\n",
    "            x_observed = row_data[\n",
    "                : k - 1\n",
    "            ].values  # 取出前 k 個觀測值 -> Qk_hat_2(t=2): 則 observerd: T=1\n",
    "\n",
    "            mu_cond, sigma_cond = calculate_conditional_distribution(\n",
    "                mu_matrix, covariance_matrix, x_observed, len(x_observed)\n",
    "            )\n",
    "\n",
    "            Qk_hat = cal_Qk_hat(mu_cond, sigma_cond, service_level, x_observed)\n",
    "\n",
    "            results_df.loc[index, f\"Qk_hat_k{k}\"] = Qk_hat\n",
    "\n",
    "            # print(f\"    x_observed: {x_observed}\")\n",
    "            # print(f\"    mu_cond: {mu_cond}\")\n",
    "            # print(f\"    sigma_cond: \\n{sigma_cond}\")\n",
    "            # print(f\"    Qk_hat: {Qk_hat}\")\n",
    "            # print(\"\\n\")\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKbvvh-lkIlB"
   },
   "source": [
    "公式連結：https://jujueffectivelife.notion.site/Qk-eab4d89ec36345efbf3a0d4a4f488474?pvs=4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ixG_NmrKPrC"
   },
   "source": [
    "### Validate the consistency of condMVN in Python and R\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJwMUzx5hoWN"
   },
   "source": [
    "#### Given mu and sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1485,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eI8aDJT_FHnD",
    "outputId": "fa4f1da8-e77d-4e55-fa91-384b463f751c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigma_11: \n",
      "[[5 1]\n",
      " [1 8]]\n",
      "\n",
      "Sigma_22: \n",
      "[[10  1]\n",
      " [ 1  7]]\n",
      "\n",
      "Sigma_12: \n",
      "[[0 1]\n",
      " [2 0]]\n",
      "\n",
      "Sigma_21: \n",
      "[[0 2]\n",
      " [1 0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "# Define the mean vector and the covariance matrix\n",
    "mu = np.array([10, 20, 30, 40])\n",
    "covariance_matrix = np.array([[5, 1, 0, 2], [1, 8, 1, 0], [0, 1, 10, 1], [2, 0, 1, 7]])\n",
    "\n",
    "# Mean and covariance partitioning\n",
    "mu_1 = mu[:2]\n",
    "mu_2 = mu[2:]\n",
    "Sigma_11 = covariance_matrix[:2, :2]\n",
    "Sigma_22 = covariance_matrix[2:, 2:]\n",
    "Sigma_12 = covariance_matrix[2:, :2]\n",
    "Sigma_21 = covariance_matrix[:2, 2:]\n",
    "\n",
    "print(f\"Sigma_11: \\n{Sigma_11}\\n\")\n",
    "print(f\"Sigma_22: \\n{Sigma_22}\\n\")\n",
    "print(f\"Sigma_12: \\n{Sigma_12}\\n\")\n",
    "print(f\"Sigma_21: \\n{Sigma_21}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1486,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H7bmBDjVhH9J",
    "outputId": "8825f168-b07c-46c2-f8fb-e20f26e8b4be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu_cond: [31.38461538 37.84615385]\n",
      "sigma_cond: \n",
      "[[9.87179487 1.05128205]\n",
      " [1.05128205 6.17948718]]\n"
     ]
    }
   ],
   "source": [
    "# Observed values of X1 and X2\n",
    "x_observed = np.array([6, 30])\n",
    "\n",
    "mu_cond, sigma_cond = calculate_conditional_distribution(\n",
    "    mu, covariance_matrix, x_observed, len(x_observed)\n",
    ")\n",
    "print(f\"mu_cond: {mu_cond}\")\n",
    "print(f\"sigma_cond: \\n{sigma_cond}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1487,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K3-lRrG4q4lq",
    "outputId": "6b7a3ed8-4681-46fc-db04-d1e90ca512d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional density at X3 = 30, X4 = 40: 0.012061749355189695\n",
      "Conditional cumulative probability up to X3 = 30, X4 = 40: 0.2790601403798458\n",
      "Qk_hat of x_observed: 112.23905144741786\n"
     ]
    }
   ],
   "source": [
    "# Define the conditional distribution\n",
    "conditional_dist = multivariate_normal(mean=mu_cond, cov=sigma_cond)\n",
    "\n",
    "# Values at which to evaluate the PDF and CDF\n",
    "x3, x4 = 30, 40  # These can be any values of interest\n",
    "\n",
    "# Calculate the PDF\n",
    "pdf_value = conditional_dist.pdf([x3, x4])\n",
    "print(f\"Conditional density at X3 = {x3}, X4 = {x4}: {pdf_value}\")\n",
    "\n",
    "# Calculate the CDF\n",
    "cdf_value = conditional_dist.cdf([x3, x4])\n",
    "print(f\"Conditional cumulative probability up to X3 = {x3}, X4 = {x4}: {cdf_value}\")\n",
    "\n",
    "# Qk hat\n",
    "Qk_hat = cal_Qk_hat(mu_cond, sigma_cond, service_level, x_observed)\n",
    "print(f\"Qk_hat of x_observed: {Qk_hat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75v9w7MUqe4f"
   },
   "source": [
    "```\n",
    "R 中運行的結果\n",
    "```\n",
    "\n",
    "![image.png](data:image/png;base64,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)\n",
    "![image.png](data:image/png;base64,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)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1488,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_b25RnwonwV2",
    "outputId": "94fc223a-b8c1-4c38-cb37-f2d9faa004ca"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "mean_Y = np.sum(mu_cond)\n",
    "var_Y = cal_Var_Y(sigma_cond)\n",
    "\n",
    "percentile_95_Y = norm.ppf(service_level, loc=mean_Y, scale=np.sqrt(var_Y))\n",
    "\n",
    "# Generate normal distribution data\n",
    "x_values = np.linspace(mean_Y - 4 * np.sqrt(var_Y), mean_Y + 4 * np.sqrt(var_Y), 1000)\n",
    "y_values = norm.pdf(x_values, loc=mean_Y, scale=np.sqrt(var_Y))\n",
    "\n",
    "# Create dataframe\n",
    "data = pd.DataFrame({\"x\": x_values, \"y\": y_values})\n",
    "\n",
    "# Plot distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data[\"x\"], data[\"y\"], color=\"blue\")\n",
    "plt.axvline(x=percentile_95_Y, color=\"red\", linestyle=\"dashed\")\n",
    "plt.fill_between(\n",
    "    data[\"x\"], data[\"y\"], where=(data[\"x\"] <= percentile_95_Y), color=\"red\", alpha=0.3\n",
    ")\n",
    "plt.title(\"Distribution of X3 + X4\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.annotate(\n",
    "    \"95th Percentile\",\n",
    "    xy=(percentile_95_Y, max(y_values)),\n",
    "    xytext=(percentile_95_Y, max(y_values) * 1.1),\n",
    "    arrowprops=dict(facecolor=\"red\", shrink=0.05),\n",
    "    color=\"red\",\n",
    "    ha=\"center\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9unedSCMe4Lt"
   },
   "source": [
    "```\n",
    "以下為 R 程式結果\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fcBXYzDZZJg0"
   },
   "source": [
    "![image.png](data:image/png;base64,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)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbc-cfXeKUWl"
   },
   "source": [
    "P(X3,X4∣X1=10,X2=20) 的 R 計算如下\n",
    "\n",
    "```\n",
    "install.packages(\"condMVNorm\")\n",
    "install.packages(\"mvtnorm\")\n",
    "library(condMVNorm)\n",
    "library(mvtnorm)\n",
    "library(ggplot2)\n",
    "\n",
    "# Define the mean vector and covariance matrix\n",
    "mu <- c(10, 20, 30, 40)\n",
    "sigma <- matrix(c(\n",
    "    5, 1, 0, 2,\n",
    "    1, 8, 1, 0,\n",
    "    0, 1, 10, 1,\n",
    "    2, 0, 1, 7\n",
    "), nrow = 4, byrow = TRUE)\n",
    "\n",
    "# Observed values of X1 and X2\n",
    "x_observed <- c(6, 30)\n",
    "\n",
    "# Compute the conditional mean and covariance using condMVNorm\n",
    "conditional_results <- condMVN(mean = mu, sigma = sigma, dependent.ind = c(3, 4), given.ind = c(1, 2), X.given = x_observed)\n",
    "\n",
    "# Print the conditional mean and covariance\n",
    "print(conditional_results$condMean)\n",
    "print(conditional_results$condVar)\n",
    "\n",
    "# Extract the conditional mean and covariance\n",
    "mu_cond <- conditional_results$condMean\n",
    "Sigma_cond <- conditional_results$condVar\n",
    "\n",
    "# Print the conditional mean and covariance\n",
    "print(mu_cond)\n",
    "print(Sigma_cond)\n",
    "\n",
    "# Values at which to evaluate the PDF and CDF\n",
    "x_values <- c(30, 40)\n",
    "\n",
    "# Calculate the PDF\n",
    "pdf_value <- dmvnorm(x_values, mean = mu_cond, sigma = Sigma_cond)\n",
    "cat(\"Conditional density at X3 =\", x_values[1], \", X4 =\", x_values[2], \": \", pdf_value, \"\\n\")\n",
    "\n",
    "# Calculate the CDF\n",
    "cdf_value <- pmvnorm(upper = x_values, mean = mu_cond, sigma = Sigma_cond)\n",
    "cat(\"Conditional cumulative probability up to X3 =\", x_values[1], \", X4 =\", x_values[2], \": \", cdf_value, \"\\n\")\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gsOfLgI-tdM"
   },
   "source": [
    "#### Conditional mean and variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1489,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "77QPjnQS-zHN",
    "outputId": "7531e890-df7f-4c69-ad05-c1ca3455641a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "公式計算的Y的均值: 5\n",
      "公式計算的Y的方差: 3.0\n",
      "模擬計算的Y的均值: 5.01077089723792\n",
      "模擬計算的Y的方差: 2.9701945334779807\n"
     ]
    }
   ],
   "source": [
    "def cal_Var_Y(sigma_cond):\n",
    "    variances = np.diag(sigma_cond)\n",
    "    covariances_sum = np.sum(sigma_cond) - np.sum(variances)\n",
    "    total_variance = np.sum(variances) + covariances_sum\n",
    "\n",
    "    return total_variance\n",
    "\n",
    "\n",
    "def simulate_Y(mu_cond, sigma_cond, num_samples=10000):\n",
    "    samples = np.random.multivariate_normal(mu_cond, sigma_cond, num_samples)\n",
    "\n",
    "    Y = samples[:, 0] + samples[:, 1]\n",
    "\n",
    "    mean_Y = np.mean(Y)\n",
    "    var_Y = np.var(Y)\n",
    "\n",
    "    return mean_Y, var_Y\n",
    "\n",
    "\n",
    "mu_cond = [2, 3]\n",
    "sigma_cond = [[1, 0.5], [0.5, 1]]\n",
    "\n",
    "mean_Y_formula = np.sum(mu_cond)\n",
    "var_Y_formula = cal_Var_Y(sigma_cond)\n",
    "\n",
    "mean_Y_simulated, var_Y_simulated = simulate_Y(mu_cond, sigma_cond)\n",
    "\n",
    "print(f\"公式計算的Y的均值: {mean_Y_formula}\")\n",
    "print(f\"公式計算的Y的方差: {var_Y_formula}\")\n",
    "print(f\"模擬計算的Y的均值: {mean_Y_simulated}\")\n",
    "print(f\"模擬計算的Y的方差: {var_Y_simulated}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Teqw8lLAkV9"
   },
   "source": [
    "### Calculate Qk hat for 2~T-1 of demand_df_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1490,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_df_train = demand_folds[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1491,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZO2S6yw1pl0Q",
    "outputId": "6ab08c48-dc46-4e6f-8102-41f13107803f"
   },
   "outputs": [],
   "source": [
    "_, _ = cal_mu_and_cov_matrix(demand_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1492,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ZFqe6xB10hB",
    "outputId": "e49ad786-9c88-42d3-a91a-c742572252a7"
   },
   "outputs": [],
   "source": [
    "mu_matrix, covariance_matrix = cal_mu_and_cov_matrix(demand_df)\n",
    "Qk_hat_df = make_Qk_hat_df(demand_df, T, service_level, mu_matrix, covariance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1493,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u63PjHtxm9Di",
    "outputId": "d8b1fb44-98b2-4c85-c9b6-115c73b0d241"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Qk_hat_k2</th>\n",
       "      <th>Qk_hat_k3</th>\n",
       "      <th>Qk_hat_k4</th>\n",
       "      <th>Qk_hat_k5</th>\n",
       "      <th>Qk_hat_k6</th>\n",
       "      <th>Qk_hat_k7</th>\n",
       "      <th>Qk_hat_k8</th>\n",
       "      <th>Qk_hat_k9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2543.187282</td>\n",
       "      <td>2520.705176</td>\n",
       "      <td>2528.829590</td>\n",
       "      <td>2526.149161</td>\n",
       "      <td>2542.158236</td>\n",
       "      <td>2515.075421</td>\n",
       "      <td>2502.250564</td>\n",
       "      <td>2458.130618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2520.273230</td>\n",
       "      <td>2511.301893</td>\n",
       "      <td>2507.827690</td>\n",
       "      <td>2479.318113</td>\n",
       "      <td>2474.161385</td>\n",
       "      <td>2452.049828</td>\n",
       "      <td>2442.544347</td>\n",
       "      <td>2429.494767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2450.255595</td>\n",
       "      <td>2453.357978</td>\n",
       "      <td>2448.529785</td>\n",
       "      <td>2371.869213</td>\n",
       "      <td>2362.748709</td>\n",
       "      <td>2363.529295</td>\n",
       "      <td>2338.448340</td>\n",
       "      <td>2316.483020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2399.744435</td>\n",
       "      <td>2401.367154</td>\n",
       "      <td>2387.885637</td>\n",
       "      <td>2344.721035</td>\n",
       "      <td>2336.819482</td>\n",
       "      <td>2329.809214</td>\n",
       "      <td>2314.584298</td>\n",
       "      <td>2336.624213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2571.595090</td>\n",
       "      <td>2554.195423</td>\n",
       "      <td>2562.026131</td>\n",
       "      <td>2541.792726</td>\n",
       "      <td>2546.556232</td>\n",
       "      <td>2542.224658</td>\n",
       "      <td>2559.948890</td>\n",
       "      <td>2514.056082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1311.572811</td>\n",
       "      <td>1333.047755</td>\n",
       "      <td>1349.106955</td>\n",
       "      <td>1350.022211</td>\n",
       "      <td>1338.130099</td>\n",
       "      <td>1346.136222</td>\n",
       "      <td>1330.017408</td>\n",
       "      <td>1320.957869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1328.280961</td>\n",
       "      <td>1319.912066</td>\n",
       "      <td>1293.870823</td>\n",
       "      <td>1286.077090</td>\n",
       "      <td>1287.722012</td>\n",
       "      <td>1262.202019</td>\n",
       "      <td>1270.667264</td>\n",
       "      <td>1225.693075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1414.505598</td>\n",
       "      <td>1428.116645</td>\n",
       "      <td>1433.896935</td>\n",
       "      <td>1421.801612</td>\n",
       "      <td>1426.459046</td>\n",
       "      <td>1403.479862</td>\n",
       "      <td>1406.882661</td>\n",
       "      <td>1362.185374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1304.098906</td>\n",
       "      <td>1302.902952</td>\n",
       "      <td>1269.765826</td>\n",
       "      <td>1320.890245</td>\n",
       "      <td>1322.800522</td>\n",
       "      <td>1292.081682</td>\n",
       "      <td>1298.679291</td>\n",
       "      <td>1264.775512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1360.666924</td>\n",
       "      <td>1345.123965</td>\n",
       "      <td>1317.086871</td>\n",
       "      <td>1244.502691</td>\n",
       "      <td>1238.541439</td>\n",
       "      <td>1257.167126</td>\n",
       "      <td>1242.717186</td>\n",
       "      <td>1219.324403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Qk_hat_k2    Qk_hat_k3    Qk_hat_k4    Qk_hat_k5    Qk_hat_k6  \\\n",
       "0   2543.187282  2520.705176  2528.829590  2526.149161  2542.158236   \n",
       "1   2520.273230  2511.301893  2507.827690  2479.318113  2474.161385   \n",
       "2   2450.255595  2453.357978  2448.529785  2371.869213  2362.748709   \n",
       "3   2399.744435  2401.367154  2387.885637  2344.721035  2336.819482   \n",
       "4   2571.595090  2554.195423  2562.026131  2541.792726  2546.556232   \n",
       "..          ...          ...          ...          ...          ...   \n",
       "85  1311.572811  1333.047755  1349.106955  1350.022211  1338.130099   \n",
       "86  1328.280961  1319.912066  1293.870823  1286.077090  1287.722012   \n",
       "87  1414.505598  1428.116645  1433.896935  1421.801612  1426.459046   \n",
       "88  1304.098906  1302.902952  1269.765826  1320.890245  1322.800522   \n",
       "89  1360.666924  1345.123965  1317.086871  1244.502691  1238.541439   \n",
       "\n",
       "      Qk_hat_k7    Qk_hat_k8    Qk_hat_k9  \n",
       "0   2515.075421  2502.250564  2458.130618  \n",
       "1   2452.049828  2442.544347  2429.494767  \n",
       "2   2363.529295  2338.448340  2316.483020  \n",
       "3   2329.809214  2314.584298  2336.624213  \n",
       "4   2542.224658  2559.948890  2514.056082  \n",
       "..          ...          ...          ...  \n",
       "85  1346.136222  1330.017408  1320.957869  \n",
       "86  1262.202019  1270.667264  1225.693075  \n",
       "87  1403.479862  1406.882661  1362.185374  \n",
       "88  1292.081682  1298.679291  1264.775512  \n",
       "89  1257.167126  1242.717186  1219.324403  \n",
       "\n",
       "[90 rows x 8 columns]"
      ]
     },
     "execution_count": 1493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qk_hat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5PqgJQzymc9c"
   },
   "source": [
    "### Plot the distribuction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1494,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H5rCKosmEf1a",
    "outputId": "8c1b9eb9-a602-473a-cb5a-9034f367148b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_star is: 2524.479640729735\n",
      "Early bias: -602.9057344111947\n",
      "Mid bias: -636.3266223153399\n",
      "Late bias: -660.7051518982014\n"
     ]
    }
   ],
   "source": [
    "# 將 T 個時期分成三份\n",
    "early_values = Qk_hat_df.iloc[:, : T // 3].mean(axis=1)\n",
    "mid_values = Qk_hat_df.iloc[:, T // 3 : 2 * T // 3].mean(axis=1)\n",
    "late_values = Qk_hat_df.iloc[:, 2 * T // 3 :].mean(axis=1)\n",
    "\n",
    "# 計算與 Q_star 的差距\n",
    "early_diff = early_values - Q_star\n",
    "mid_diff = mid_values - Q_star\n",
    "late_diff = late_values - Q_star\n",
    "\n",
    "# 繪製直方圖\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# 早期\n",
    "plt.hist(early_diff, bins=10, alpha=0.5, label=\"Early\", color=\"blue\", edgecolor=\"black\")\n",
    "# 中期\n",
    "plt.hist(mid_diff, bins=10, alpha=0.5, label=\"Mid\", color=\"green\", edgecolor=\"black\")\n",
    "# 晚期\n",
    "plt.hist(late_diff, bins=10, alpha=0.5, label=\"Late\", color=\"red\", edgecolor=\"black\")\n",
    "\n",
    "plt.axvline(0, color=\"grey\", linestyle=\"--\")\n",
    "\n",
    "plt.xlabel(\"Difference from Q star\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of Differences from Q star at Different Times\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 計算偏差\n",
    "early_bias = np.mean(early_diff)\n",
    "mid_bias = np.mean(mid_diff)\n",
    "late_bias = np.mean(late_diff)\n",
    "\n",
    "print(f\"Q_star is: {Q_star}\")\n",
    "print(f\"Early bias: {early_bias}\")\n",
    "print(f\"Mid bias: {mid_bias}\")\n",
    "print(f\"Late bias: {late_bias}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1495,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EdNJAb6XEzwb",
    "outputId": "e157524f-5345-410d-e5a8-1bec824f9606"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 繪製直方圖\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 18))\n",
    "\n",
    "# 早期\n",
    "axes[0].hist(early_diff, bins=10, alpha=0.5, color=\"blue\", edgecolor=\"black\")\n",
    "axes[0].axvline(0, color=\"grey\", linestyle=\"--\")\n",
    "axes[0].set_title(\"Early\")\n",
    "axes[0].set_xlabel(\"Difference from Q star\")\n",
    "axes[0].set_ylabel(\"Frequency\")\n",
    "\n",
    "# 中期\n",
    "axes[1].hist(mid_diff, bins=10, alpha=0.5, color=\"green\", edgecolor=\"black\")\n",
    "axes[1].axvline(0, color=\"grey\", linestyle=\"--\")\n",
    "axes[1].set_title(\"Mid\")\n",
    "axes[1].set_xlabel(\"Difference from Q star\")\n",
    "axes[1].set_ylabel(\"Frequency\")\n",
    "\n",
    "# 晚期\n",
    "axes[2].hist(late_diff, bins=10, alpha=0.5, color=\"red\", edgecolor=\"black\")\n",
    "axes[2].axvline(0, color=\"grey\", linestyle=\"--\")\n",
    "axes[2].set_title(\"Late\")\n",
    "axes[2].set_xlabel(\"Difference from Q star\")\n",
    "axes[2].set_ylabel(\"Frequency\")\n",
    "\n",
    "fig.suptitle(\"Histogram of Differences from Q star at Different Times\")\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDilezxfOmIe"
   },
   "source": [
    "# Strategies utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the r and R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1496,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gurobipy as gp\n",
    "# from gurobipy import GRB\n",
    "\n",
    "# # 初始化模型\n",
    "# # model = gp.Model(\"Test_r_R_relationship\")\n",
    "# model = gp.Model(env=env)\n",
    "\n",
    "# # 設定參數\n",
    "# K = 4  # 候選數量\n",
    "# i = 0  # 單個 i 的例子\n",
    "\n",
    "# # 定義變數\n",
    "# r_vars = model.addVars(K, lb=0.0, ub=1.0, name=\"r_vars\")  # r_{i,k}\n",
    "# R_vars = model.addVars(K, vtype=GRB.BINARY, name=\"R_vars\")  # R_{i,k}\n",
    "# max_r_helper = model.addVar(lb=0.0, ub=1.0, name=\"max_r_helper\")  # 最大值輔助變數\n",
    "\n",
    "# # 假設 exp_tau_vars 是已知的輸入數值\n",
    "# exp_tau_vars = [0.1, 0.3, 0.5, 0.2]  # 例子數值\n",
    "\n",
    "# # 限制式 1: 定義 r_vars 與 exp_tau_vars 的關係\n",
    "# for k in range(K):\n",
    "#     model.addConstr(\n",
    "#         r_vars[k] * sum(exp_tau_vars) == exp_tau_vars[k],\n",
    "#         name=f\"softmax_relation_{k}\",\n",
    "#     )\n",
    "\n",
    "# # 限制式 2: 確保 r_vars 的加總為 1\n",
    "# model.addConstr(gp.quicksum(r_vars[k] for k in range(K)) == 1, name=\"sum_r_constraint\")\n",
    "\n",
    "# # 限制式 3: 找出 r_vars 中的最大值\n",
    "# model.addGenConstrMax(\n",
    "#     max_r_helper, [r_vars[k] for k in range(K)], name=\"max_r_constraint\"\n",
    "# )\n",
    "\n",
    "# # 限制式 4: 確保 R_vars 對應到最大值\n",
    "# for k in range(K):\n",
    "#     model.addGenConstrIndicator(\n",
    "#         R_vars[k], 1, r_vars[k] == max_r_helper, name=f\"indicator_R_{k}\"\n",
    "#     )\n",
    "\n",
    "# # 限制式 5: 確保僅有一個 R_vars[k] 為 1\n",
    "# model.addConstr(\n",
    "#     gp.quicksum(R_vars[k] for k in range(K)) == 1, name=\"unique_R_constraint\"\n",
    "# )\n",
    "\n",
    "# # 設定目標函數（範例：最大化 max_r_helper）\n",
    "# model.setObjective(max_r_helper, GRB.MAXIMIZE)\n",
    "\n",
    "# # 求解模型\n",
    "# model.optimize()\n",
    "\n",
    "# # 輸出結果\n",
    "# if model.Status == GRB.OPTIMAL:\n",
    "#     print(\"Optimal solution found!\")\n",
    "#     print(f\"max_r_helper: {max_r_helper.X}\")\n",
    "#     print(\"r_vars:\")\n",
    "#     for k in range(K):\n",
    "#         print(f\"  r_vars[{k}]: {r_vars[k].X}\")\n",
    "#     print(\"R_vars:\")\n",
    "#     for k in range(K):\n",
    "#         print(f\"  R_vars[{k}]: {R_vars[k].X}\")\n",
    "# else:\n",
    "#     print(\"No optimal solution found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "檢驗結果：目前的寫法可以成功讓 r 與 R 的關係實現\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8oJyOCv3Oqap"
   },
   "source": [
    "## S0 - One-time Procurement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1497,
   "metadata": {
    "id": "iMoKgd_XO05c"
   },
   "outputs": [],
   "source": [
    "def one_time_procurement(Q_star, demand_df, cost, price, salvage_value):\n",
    "\n",
    "    all_losses = []\n",
    "    all_lefts = []\n",
    "    all_operation_profits = []\n",
    "    all_profits = []\n",
    "\n",
    "    for i, row in demand_df.iterrows():\n",
    "        inventory = Q_star\n",
    "        losses = []\n",
    "        lefts = []\n",
    "        daily_operation_profits = []\n",
    "        daily_profits = []\n",
    "        total_sold = 0  # 追蹤總售出量\n",
    "        total_lost = 0  # 追蹤總丟失量\n",
    "\n",
    "        # print(\"=\" * 50)\n",
    "        # print(\n",
    "        #     f\"Processing row {i+1}/{len(demand_df)} with initial inventory Q_star={Q_star}\"\n",
    "        # )\n",
    "        # print(\"=\" * 50)\n",
    "\n",
    "        for day, demand in enumerate(row):\n",
    "            sales = min(inventory, demand)\n",
    "            loss = max(demand - inventory, 0)\n",
    "            left = max(inventory - sales, 0)\n",
    "            total_sold += sales\n",
    "            total_lost += loss\n",
    "\n",
    "            inventory -= sales\n",
    "\n",
    "            # print(\"-\" * 50)\n",
    "            # print(f\"Day {day+1}\")\n",
    "            # print(f\"Demand      : {demand}\")\n",
    "            # print(f\"Sales       : {sales}\")\n",
    "            # print(f\"Loss        : {loss}\")\n",
    "            # print(f\"Left        : {left}\")\n",
    "            # print(f\"Inventory   : {inventory}\")\n",
    "            # print(\"-\" * 50)\n",
    "\n",
    "            if day == len(row) - 1:\n",
    "                left_penalty_cost = (cost - salvage_value) * left\n",
    "                lefts.append(left)\n",
    "                # print(f\"End of period: Left Penalty Cost = {left_penalty_cost}\")\n",
    "                # print(\"-\" * 50)\n",
    "            else:\n",
    "                left_penalty_cost = 0\n",
    "\n",
    "        operation_profit = (price - cost) * total_sold\n",
    "        profit = operation_profit - left_penalty_cost - (price - cost) * total_lost\n",
    "\n",
    "        # print(\"=\" * 50)\n",
    "        # print(f\"Row {i+1} Summary\")\n",
    "        # print(f\"Total Sold         : {total_sold}\")\n",
    "        # print(f\"Total Lost         : {total_lost}\")\n",
    "        # print(f\"Operation Profit   : {operation_profit}\")\n",
    "        # print(f\"Profit             : {profit}\")\n",
    "        # print(\"=\" * 50)\n",
    "\n",
    "        all_losses.append(total_lost)\n",
    "        all_lefts.append(sum(lefts))\n",
    "        all_operation_profits.append(operation_profit)\n",
    "        all_profits.append(profit)\n",
    "\n",
    "    avg_losses = np.mean(all_losses)\n",
    "    avg_lefts = np.mean(all_lefts)\n",
    "    avg_operation_profits = np.mean(all_operation_profits)\n",
    "    avg_profits = np.mean(all_profits)\n",
    "\n",
    "    # print(\"=\" * 50)\n",
    "    # print(\"Overall Summary\")\n",
    "    # print(f\"Average Losses           : {avg_losses}\")\n",
    "    # print(f\"Average Lefts            : {avg_lefts}\")\n",
    "    # print(f\"Average Operation Profits: {avg_operation_profits}\")\n",
    "    # print(f\"Average Profits          : {avg_profits}\")\n",
    "    # print(\"=\" * 50)\n",
    "\n",
    "    stimulation_df = pd.DataFrame(\n",
    "        {\n",
    "            \"losses\": all_losses,\n",
    "            \"lefts\": all_lefts,\n",
    "            \"operation_profits\": all_operation_profits,\n",
    "            \"profits\": all_profits,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return avg_losses, avg_lefts, avg_profits, avg_operation_profits, stimulation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gmHkLPVROtLN"
   },
   "source": [
    "## S1 - Grid for Fixed F & Fixed Rk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1498,
   "metadata": {
    "id": "iCm5WosfO_l-"
   },
   "outputs": [],
   "source": [
    "def cal_fixed_F_fixed_R(\n",
    "    Q_star, assigned_F, assigned_R, demand_df, cost, price, salvage_value, Qk_hat_df\n",
    "):\n",
    "    all_losses = []\n",
    "    all_lefts = []\n",
    "    all_left0s = []\n",
    "    all_left1s = []\n",
    "    all_operation_profits = []\n",
    "    all_profits = []\n",
    "    all_q0s = []\n",
    "    all_q1s = []\n",
    "\n",
    "    Q0 = assigned_F * Q_star  # 期初庫存\n",
    "\n",
    "    # print(f\"\\n\")\n",
    "    # print(f\"====\" * 10)\n",
    "    # print(f\"\\n\")\n",
    "\n",
    "    for i, row in demand_df.iterrows():\n",
    "\n",
    "        # 第一階段計算\n",
    "        total_sold_0 = min(Q0, row[: assigned_R + 1].sum())  # 第一階段售出量\n",
    "        left_0 = max(Q0 - total_sold_0, 0)  # 第一階段剩餘\n",
    "        lost_0 = max((row[: assigned_R + 1].sum() - Q0), 0)\n",
    "\n",
    "        # 第二階段開始補貨，根據指定的 R\n",
    "        Qk_hat = Qk_hat_df.iloc[i, assigned_R]\n",
    "        Q1 = max((Qk_hat - Q0), 0)  # 二次訂貨量\n",
    "        total_sold_1 = min(Q1 + left_0, row[assigned_R + 1 :].sum())  # 第二階段售出量\n",
    "        left_1 = max((Q1 + left_0) - total_sold_1, 0)  # 第二階段剩餘\n",
    "        lost_1 = max(row[assigned_R + 1 :].sum() - (Q1 + left_0), 0)\n",
    "\n",
    "        # 統計\n",
    "        total_sold = total_sold_0 + total_sold_1\n",
    "        total_lost = lost_0 + lost_1\n",
    "        total_left = left_0 + left_1\n",
    "\n",
    "        # 計算運營利潤和總利潤\n",
    "        operation_profit = (price - cost) * total_sold\n",
    "\n",
    "        # left_penalty_cost = (cost - salvage_value) * left_1\n",
    "        left_penalty_cost = (cost - salvage_value) * total_left\n",
    "        lost_penalty_cost = (price - cost) * total_lost\n",
    "\n",
    "        profit = operation_profit - left_penalty_cost - lost_penalty_cost\n",
    "\n",
    "        all_losses.append(total_lost)\n",
    "        all_lefts.append(total_left)\n",
    "        all_operation_profits.append(operation_profit)\n",
    "        all_profits.append(profit)\n",
    "        all_q0s.append(Q0)\n",
    "        all_q1s.append(Q1)\n",
    "        all_left0s.append(left_0)\n",
    "        all_left1s.append(left_1)\n",
    "\n",
    "        # print(f\"這是第 {i+1} 筆模擬資料\\n\")\n",
    "        # print(f\"F: {assigned_F}, R: {assigned_R+2}\")\n",
    "        # print(f\"Q_star 為 {Q_star}\")\n",
    "        # print(f\"期初庫存 Q0: {Q0}\")\n",
    "        # print(f\"重新估計量 Qk_hat: {Qk_hat}\")\n",
    "        # print(f\"訂貨量 Q1 為 {Q1}\\n\")\n",
    "\n",
    "        # print(\n",
    "        #     f\"第一階段：期初庫存 Q0: {Q0}，需求量為 {row[:assigned_R + 1].sum()}，Sold_0 為 {total_sold_0}，Left_0 為 {left_0}，Lost_0 為 {lost_0}\"\n",
    "        # )\n",
    "        # print(\n",
    "        #     f\"第二階段：期初庫存 Q1+left_0 為 {Q1+left_0}，需求量為 {row[assigned_R + 1:].sum()}，Sold_1 為 {total_sold_1}，Left_1 為 {left_1}，Lost_1 為 {lost_1}\\n\"\n",
    "        # )\n",
    "        # print(\n",
    "        #     f\"統計結果：Sold 為 {total_sold}, Lost 為 {total_lost} Left_Penalty_Cost 為 {left_penalty_cost}，Lost_Penalty_Cost 為 {lost_penalty_cost}，Profit 為 {profit}\"\n",
    "        # )\n",
    "        # print(\"----\" * 10)\n",
    "\n",
    "    result_df = {\n",
    "        \"R(T)\": assigned_R + 2,\n",
    "        \"F\": assigned_F,\n",
    "        \"Q0\": all_q0s,\n",
    "        \"Q1\": all_q1s,\n",
    "        \"average_profits\": np.mean(all_profits),\n",
    "        \"average_losses\": np.mean(all_losses),\n",
    "        \"average_lefts\": np.mean(all_lefts),\n",
    "        \"average_operation_profits\": np.mean(all_operation_profits),\n",
    "    }\n",
    "\n",
    "    stimulation_result = {\n",
    "        \"R(T)\": assigned_R + 2,\n",
    "        \"F\": assigned_F,\n",
    "        \"profits\": all_profits,\n",
    "        \"losses\": all_losses,\n",
    "        \"lefts\": all_lefts,\n",
    "        \"Left0s\": all_left0s,\n",
    "        \"Left1s\": all_left1s,\n",
    "        \"operation_profits\": all_operation_profits,\n",
    "        \"Q0\": all_q0s,\n",
    "        \"Q1\": all_q1s,\n",
    "    }\n",
    "\n",
    "    return result_df, stimulation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1499,
   "metadata": {
    "id": "4OJpJmXYZ3nm"
   },
   "outputs": [],
   "source": [
    "def grid_fixed_F_fixed_R(\n",
    "    assigned_Ts,\n",
    "    assigned_Fs,\n",
    "    cost,\n",
    "    price,\n",
    "    salvage_value,\n",
    "    Qk_hat_df,\n",
    "    demand_df_train,\n",
    "    Q_star,\n",
    "):\n",
    "\n",
    "    results_list = []\n",
    "    max_profit = None\n",
    "    max_profit_stimulation_result = {}\n",
    "\n",
    "    for assigned_T in assigned_Ts:\n",
    "        for assigned_F in assigned_Fs:\n",
    "            assigned_R = assigned_T - 2\n",
    "            mean_result, stimulation_result = cal_fixed_F_fixed_R(\n",
    "                Q_star,\n",
    "                assigned_F,\n",
    "                assigned_R,\n",
    "                demand_df_train,\n",
    "                cost,\n",
    "                price,\n",
    "                salvage_value,\n",
    "                Qk_hat_df,\n",
    "            )\n",
    "            results_list.append(mean_result)\n",
    "\n",
    "            if max_profit is None or max_profit < mean_result[\"average_profits\"]:\n",
    "                # print(\n",
    "                #     f\"max_profit is changed from {max_profit} to {mean_result['average_profits']}\"\n",
    "                # )\n",
    "                max_profit = mean_result[\"average_profits\"]\n",
    "                max_profit_stimulation_result = stimulation_result\n",
    "\n",
    "    results_df_1 = pd.DataFrame(results_list).sort_values(\n",
    "        by=\"average_profits\", ascending=False\n",
    "    )\n",
    "\n",
    "    return results_df_1, pd.DataFrame(max_profit_stimulation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S8 - Grid for Fixed F & Fixed Rk(with holding cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1500,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_fixed_F_fixed_R_with_holding_cost(\n",
    "    Q_star,\n",
    "    assigned_F,\n",
    "    assigned_R,\n",
    "    demand_df,\n",
    "    cost,\n",
    "    price,\n",
    "    salvage_value,\n",
    "    Qk_hat_df,\n",
    "    holding_cost,\n",
    "):\n",
    "    all_losses = []\n",
    "    all_lefts = []\n",
    "    all_operation_profits = []\n",
    "    all_profits = []\n",
    "    all_q0s = []\n",
    "    all_q1s = []\n",
    "    all_holding_costs_0 = []\n",
    "    all_holding_costs_1 = []\n",
    "    all_left0s = []\n",
    "    all_left1s = []\n",
    "    all_lost0s = []\n",
    "    all_lost1s = []\n",
    "\n",
    "    Q0 = assigned_F * Q_star  # 期初庫存\n",
    "\n",
    "    # print(f\"\\n\")\n",
    "    # print(f\"====\" * 10)\n",
    "    # print(f\"\\n\")\n",
    "\n",
    "    for i, row in demand_df.iterrows():\n",
    "\n",
    "        # 第一階段計算\n",
    "        total_sold_0 = min(Q0, row[: assigned_R + 1].sum())  # 第一階段售出量\n",
    "        left_0 = max(Q0 - total_sold_0, 0)  # 第一階段剩餘\n",
    "        lost_0 = max(row[: assigned_R + 1].sum() - Q0, 0)\n",
    "\n",
    "        # 第二階段開始補貨，根據指定的 R\n",
    "        Qk_hat = Qk_hat_df.iloc[i, assigned_R]\n",
    "        Q1 = max((Qk_hat - Q0), 0)  # 二次訂貨量\n",
    "        total_sold_1 = min(Q1 + left_0, row[assigned_R + 1 :].sum())  # 第二階段售出量\n",
    "        left_1 = max((Q1 + left_0) - total_sold_1, 0)  # 第二階段剩餘\n",
    "        lost_1 = max(row[assigned_R + 1 :].sum() - (Q1 + left_0), 0)\n",
    "\n",
    "        # 統計\n",
    "        total_sold = total_sold_0 + total_sold_1\n",
    "        total_lost = lost_0 + lost_1\n",
    "\n",
    "        # 計算 holding_cost\n",
    "        \"\"\"\n",
    "        今天 T = 10, 假設 R = 5 (此時 assigned_R=3), 此時:\n",
    "        第一階段是 T=1~4 -> 高為 R-1 = (assigned_R+2) - 1\n",
    "        第二階段是 T=5~10 -> 高為 T - R = T - (assigned_R+2)\n",
    "        \"\"\"\n",
    "\n",
    "        first_holding_cost = (Q0 + left_0 + Q1) * ((assigned_R + 2) - 1) / 2\n",
    "        # T = 1 ~ R+1, R+1 才是代表 R(T)\n",
    "        second_holding_cost = (Q1 + left_0 + left_1) * (T - (assigned_R + 2)) / 2\n",
    "        # T = R+1 ~ T\n",
    "        holding_penalty = holding_cost * (first_holding_cost + second_holding_cost)\n",
    "\n",
    "        # 計算運營利潤和總利潤\n",
    "        operation_profit = (price - cost) * total_sold\n",
    "        left_penalty_cost = (cost - salvage_value) * left_1\n",
    "        lost_penalty_cost = (price - cost) * total_lost\n",
    "        profit = (\n",
    "            operation_profit - left_penalty_cost - lost_penalty_cost - holding_penalty\n",
    "        )\n",
    "\n",
    "        all_losses.append(total_lost)\n",
    "        all_lefts.append(left_1)\n",
    "        all_operation_profits.append(operation_profit)\n",
    "        all_profits.append(profit)\n",
    "        all_q0s.append(Q0)\n",
    "        all_q1s.append(Q1)\n",
    "        all_holding_costs_0.append(first_holding_cost)\n",
    "        all_holding_costs_1.append(second_holding_cost)\n",
    "        all_left0s.append(left_0)\n",
    "        all_left1s.append(left_1)\n",
    "        all_lost0s.append(lost_0)\n",
    "        all_lost1s.append(lost_1)\n",
    "\n",
    "        # print(f\"這是第 {i+1} 筆模擬資料\\n\")\n",
    "        # print(f\"F: {assigned_F}, R: {assigned_R+2}\")\n",
    "        # print(f\"Q_star 為 {Q_star}\")\n",
    "        # print(f\"期初庫存 Q0: {Q0}\")\n",
    "        # print(f\"重新估計量 Qk_hat: {Qk_hat}\")\n",
    "        # print(f\"訂貨量 Q1 為 {Q1}\\n\")\n",
    "\n",
    "        # print(\n",
    "        #     f\"第一階段：期初庫存 Q0: {Q0}，需求量為 {row[:assigned_R + 1].sum()}，Sold_0 為 {total_sold_0}，Left_0 為 {left_0}，Lost_0 為 {lost_0}, first_holding_cost 為 {first_holding_cost}\"\n",
    "        # )\n",
    "        # print(\n",
    "        #     f\"第二階段：期初庫存 Q1+left_0 為 {Q1+left_0}，需求量為 {row[assigned_R + 1:].sum()}，Sold_1 為 {total_sold_1}，Left_1 為 {left_1}，Lost_1 為 {lost_1}, second_holding_cost 為 {second_holding_cost}\\n\"\n",
    "        # )\n",
    "        # print(\n",
    "        #     f\"統計結果：Sold 為 {total_sold}, Lost 為 {total_lost} Left_Penalty_Cost 為 {left_penalty_cost}，Lost_Penalty_Cost 為 {lost_penalty_cost}，holding_penalty 為 {holding_penalty}，Profit 為 {profit}\"\n",
    "        # )\n",
    "        # print(\"----\" * 10)\n",
    "\n",
    "    result_df = {\n",
    "        \"R(T)\": assigned_R + 2,\n",
    "        \"F\": assigned_F,\n",
    "        \"Q0\": all_q0s,\n",
    "        \"Q1\": all_q1s,\n",
    "        \"average_profits\": np.mean(all_profits),\n",
    "        \"average_losses\": np.mean(all_losses),\n",
    "        \"average_lefts\": np.mean(all_lefts),\n",
    "        \"average_operation_profits\": np.mean(all_operation_profits),\n",
    "    }\n",
    "\n",
    "    stimulation_result = {\n",
    "        \"R(T)\": assigned_R + 2,\n",
    "        \"F\": assigned_F,\n",
    "        \"profits\": all_profits,\n",
    "        \"losses\": all_losses,\n",
    "        \"lefts\": all_lefts,\n",
    "        \"operation_profits\": all_operation_profits,\n",
    "        \"Q0\": all_q0s,\n",
    "        \"Q1\": all_q1s,\n",
    "        \"hc0\": all_holding_costs_0,\n",
    "        \"hc1\": all_holding_costs_1,\n",
    "        \"Left0s\": all_left0s,\n",
    "        \"Left1s\": all_left1s,\n",
    "        \"lost0s\": all_lost0s,\n",
    "        \"lost1s\": all_lost1s,\n",
    "    }\n",
    "\n",
    "    return result_df, stimulation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1501,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_fixed_F_fixed_R_with_holding_cost(\n",
    "    assigned_Ts,\n",
    "    assigned_Fs,\n",
    "    cost,\n",
    "    price,\n",
    "    salvage_value,\n",
    "    holding_cost,\n",
    "    Qk_hat_df,\n",
    "    demand_df_train,\n",
    "    Q_star,\n",
    "):\n",
    "\n",
    "    results_list = []\n",
    "    max_profit = None\n",
    "    max_profit_stimulation_result = {}\n",
    "\n",
    "    for assigned_T in assigned_Ts:\n",
    "        for assigned_F in assigned_Fs:\n",
    "            assigned_R = assigned_T - 2\n",
    "            mean_result, stimulation_result = cal_fixed_F_fixed_R_with_holding_cost(\n",
    "                Q_star,\n",
    "                assigned_F,\n",
    "                assigned_R,\n",
    "                demand_df_train,\n",
    "                cost,\n",
    "                price,\n",
    "                salvage_value,\n",
    "                Qk_hat_df,\n",
    "                holding_cost,\n",
    "            )\n",
    "            results_list.append(mean_result)\n",
    "\n",
    "            if max_profit is None or max_profit < mean_result[\"average_profits\"]:\n",
    "                # print(\n",
    "                #     f\"max_profit is changed from {max_profit} to {mean_result['average_profits']}\"\n",
    "                # )\n",
    "                max_profit = mean_result[\"average_profits\"]\n",
    "                max_profit_stimulation_result = stimulation_result\n",
    "\n",
    "    results_df_1 = pd.DataFrame(results_list).sort_values(\n",
    "        by=\"average_profits\", ascending=False\n",
    "    )\n",
    "\n",
    "    return results_df_1, pd.DataFrame(max_profit_stimulation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S2 - Grid for Fixed Rk & Flexible F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1502,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cal_flexible_F_fixed_R(\n",
    "#     assigned_R,\n",
    "#     salvage_value,\n",
    "#     cost,\n",
    "#     price,\n",
    "#     Q_star,\n",
    "#     demand_df_train,\n",
    "#     Qk_hat_df,\n",
    "#     training_df,\n",
    "# ):\n",
    "#     # print(\n",
    "#     #     f\"+++++++++++++++++++++++++++++++++++++++ THis is R={assigned_R} +++++++++++++++++++++++++++++++++++++++++++++++++\"\n",
    "#     # )\n",
    "#     with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "#         model.setParam(\"OutputFlag\", True)\n",
    "#         model.setParam(\"Threads\", THREADS)\n",
    "#         model.setParam(\"MIPGap\", MIPGAP)\n",
    "#         model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "\n",
    "#         # ======================= Decision Variables =======================\n",
    "#         alphas = model.addVars(\n",
    "#             features_num + 1, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"alphas\"\n",
    "#         )\n",
    "#         Sold_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_0\")\n",
    "#         Sold_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_1\")\n",
    "#         Lost_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_0\")\n",
    "#         Lost_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_1\")\n",
    "#         Left_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_1\")\n",
    "\n",
    "#         f_vars = model.addVars(\n",
    "#             len(demand_df_train), lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"f_var\"\n",
    "#         )\n",
    "#         F_vars = model.addVars(len(demand_df_train), lb=0, ub=1, name=\"Fraction\")\n",
    "\n",
    "#         Q0_vars = model.addVars(\n",
    "#             len(demand_df_train), lb=0.0, ub=(Q_star + 1), name=\"Q0_var\"\n",
    "#         )\n",
    "#         Q1_vars = model.addVars(len(Qk_hat_df), lb=0.0, name=\"Q1_var\")\n",
    "\n",
    "#         profits_vars = model.addVars(\n",
    "#             len(demand_df_train), lb=-GRB.INFINITY, name=\"profits_vars\"\n",
    "#         )\n",
    "\n",
    "#         # ======================= Model Constraints =======================\n",
    "#         for i, row in demand_df_train.iterrows():\n",
    "#             demand_row = demand_df_train.iloc[i]\n",
    "#             Qk_hat_df_row = Qk_hat_df.iloc[i].tolist()\n",
    "#             X_data = training_df.iloc[i].tolist()\n",
    "#             X_data.append(1)\n",
    "\n",
    "#             model.addConstr(F_vars[i] >= 0, name=f\"Fraction_lower_bound_{i}\")\n",
    "#             model.addConstr(F_vars[i] <= 1, name=f\"Fraction_upper_bound_{i}\")\n",
    "\n",
    "#             # Calculate F using logistic regression\n",
    "#             model.addConstr(\n",
    "#                 f_vars[i]\n",
    "#                 == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "#             )\n",
    "#             model.addGenConstrLogistic(xvar=f_vars[i], yvar=F_vars[i])\n",
    "\n",
    "#             # Calculate initial order quantity\n",
    "#             model.addConstr(Q0_vars[i] == F_vars[i] * Q_star)\n",
    "\n",
    "#             # Define demand variables for before and after reorder point\n",
    "#             total_demand_before_R = demand_row[: assigned_R + 1].sum()\n",
    "#             total_demand_after_R = demand_row[assigned_R + 1 :].sum()\n",
    "\n",
    "#             # Calculate first period sales and lost sales\n",
    "#             model.addGenConstrMin(\n",
    "#                 Sold_0s[i],\n",
    "#                 [total_demand_before_R, Q0_vars[i]],\n",
    "#                 name=f\"min_sales_constr_{i}\",\n",
    "#             )\n",
    "\n",
    "#             # Calculate lost sales\n",
    "#             Lost_0_expr = total_demand_before_R - Q0_vars[i]\n",
    "#             Lost_0_var = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_expr_{i}\")\n",
    "#             model.addConstr(Lost_0_var == Lost_0_expr)\n",
    "#             model.addGenConstrMax(\n",
    "#                 Lost_0s[i], [Lost_0_var, 0], name=f\"max_lost_constr_{i}\"\n",
    "#             )\n",
    "\n",
    "#             # Calculate inventory left after first period\n",
    "#             left_0 = Q0_vars[i] - Sold_0s[i]\n",
    "\n",
    "#             # Calculate Q1 based on reorder point estimate\n",
    "#             Q_hat = Qk_hat_df_row[assigned_R]\n",
    "#             Q_hat_adjusted = Q_hat - Q0_vars[i]\n",
    "#             Q_hat_adjusted_var = model.addVar(\n",
    "#                 lb=-GRB.INFINITY, name=f\"Q_hat_adjusted_{i}\"\n",
    "#             )\n",
    "#             model.addConstr(Q_hat_adjusted_var == Q_hat_adjusted)\n",
    "\n",
    "#             model.addGenConstrMax(\n",
    "#                 Q1_vars[i], [Q_hat_adjusted_var, 0], name=f\"max_Q1_constr_{i}\"\n",
    "#             )\n",
    "\n",
    "#             # Calculate second period sales and lost sales\n",
    "#             total_stock_second_period = Q1_vars[i] + left_0\n",
    "#             total_stock_second_period_var = model.addVar(\n",
    "#                 lb=0, name=f\"total_stock_second_period_{i}\"\n",
    "#             )\n",
    "#             model.addConstr(total_stock_second_period_var == total_stock_second_period)\n",
    "\n",
    "#             model.addGenConstrMin(\n",
    "#                 Sold_1s[i],\n",
    "#                 [total_demand_after_R, total_stock_second_period_var],\n",
    "#                 name=f\"min_sales2_constr_{i}\",\n",
    "#             )\n",
    "\n",
    "#             # Calculate second period lost sales\n",
    "#             Lost_1_expr = total_demand_after_R - total_stock_second_period_var\n",
    "#             Lost_1_var = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_1_expr_{i}\")\n",
    "#             model.addConstr(Lost_1_var == Lost_1_expr)\n",
    "\n",
    "#             model.addGenConstrMax(\n",
    "#                 Lost_1s[i], [Lost_1_var, 0], name=f\"max_lost2_constr_{i}\"\n",
    "#             )\n",
    "\n",
    "#             model.addConstr(Left_1s[i] == total_stock_second_period_var - Sold_1s[i])\n",
    "\n",
    "#             # # Calculate holding costs directly in profit equation\n",
    "#             # holding_cost_1 = (\n",
    "#             #     (Q0_vars[i] + total_stock_second_period) * (assigned_R + 2 - 1) / 2\n",
    "#             # )\n",
    "#             # holding_cost_2 = (\n",
    "#             #     (total_stock_second_period + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "#             # )\n",
    "\n",
    "#             # Calculate profit\n",
    "#             model.addConstr(\n",
    "#                 profits_vars[i]\n",
    "#                 == (\n",
    "#                     (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue\n",
    "#                     - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "#                     - (cost - salvage_value) * Left_1s[i]  # Salvage cost\n",
    "#                     # - holding_cost * (holding_cost_1 + holding_cost_2)  # Holding cost\n",
    "#                 )\n",
    "#             )\n",
    "\n",
    "#         # Set objective\n",
    "#         model.setObjective(\n",
    "#             gp.quicksum(profits_vars[i] for i in range(len(demand_df_train))),\n",
    "#             GRB.MAXIMIZE,\n",
    "#         )\n",
    "\n",
    "#         model.write(\"s2_model_debug.lp\")\n",
    "#         model.write(\"s2_model.mps\")\n",
    "\n",
    "#         # Solve model\n",
    "#         try:\n",
    "#             model.optimize()\n",
    "\n",
    "#             if model.status == GRB.OPTIMAL or model.status == GRB.TIME_LIMIT:\n",
    "#                 print(f\"Model status: {model.status}\")\n",
    "\n",
    "#                 # Collect results\n",
    "#                 alpha_values = np.array([alpha.X for alpha in alphas.values()])\n",
    "\n",
    "#                 results = {\n",
    "#                     \"losses\": [],\n",
    "#                     \"lefts\": [],\n",
    "#                     \"profits\": [],\n",
    "#                     \"operation_profits\": [],\n",
    "#                     \"Q0s\": [],\n",
    "#                     \"Q1s\": [],\n",
    "#                     \"Fs\": [],\n",
    "#                 }\n",
    "\n",
    "#                 for i in range(len(demand_df_train)):\n",
    "#                     sold0, sold1 = Sold_0s[i].X, Sold_1s[i].X\n",
    "#                     lost0, lost1 = Lost_0s[i].X, Lost_1s[i].X\n",
    "#                     left1 = Left_1s[i].X\n",
    "#                     left0 = Q0_vars[i].X - Sold_0s[i].X\n",
    "\n",
    "#                     # Record results\n",
    "#                     results[\"losses\"].append(lost0 + lost1)\n",
    "#                     results[\"lefts\"].append(left1)\n",
    "#                     # results[\"lefts\"].append(left0)\n",
    "\n",
    "#                     results[\"operation_profits\"].append(\n",
    "#                         (price - cost) * (sold0 + sold1)\n",
    "#                     )\n",
    "#                     results[\"profits\"].append(profits_vars[i].X)\n",
    "#                     results[\"Q0s\"].append(Q0_vars[i].X)\n",
    "#                     results[\"Q1s\"].append(Q1_vars[i].X)\n",
    "#                     results[\"Fs\"].append(F_vars[i].X)\n",
    "\n",
    "#                     # print(f\"\\nObservation {i+1}:\")\n",
    "#                     # print(f\"Reorder day: {assigned_R}\")\n",
    "#                     # print(f\"Profit: {profits_vars[i].X:.2f}\")\n",
    "\n",
    "#                 return (\n",
    "#                     [assigned_R] * len(demand_df_train),  # Fixed R for all observations\n",
    "#                     results[\"losses\"],\n",
    "#                     results[\"lefts\"],\n",
    "#                     results[\"profits\"],\n",
    "#                     results[\"operation_profits\"],\n",
    "#                     alpha_values,\n",
    "#                     results[\"Fs\"],\n",
    "#                     results[\"Q0s\"],\n",
    "#                     results[\"Q1s\"],\n",
    "#                 )\n",
    "\n",
    "#             else:\n",
    "#                 print(\"===================== 找不到最佳解 ==================\")\n",
    "#                 print(f\"Model is feasible. Status: {model.status}\")\n",
    "#                 model.computeIIS()\n",
    "#                 model.write(\"model.ilp\")\n",
    "\n",
    "#                 for constr in model.getConstrs():\n",
    "#                     if constr.IISConstr:\n",
    "#                         print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "#                 for var in model.getVars():\n",
    "#                     if var.IISLB > 0 or var.IISUB > 0:\n",
    "#                         print(\n",
    "#                             f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "#                         )\n",
    "\n",
    "#                 return None\n",
    "\n",
    "#         except gp.GurobiError as e:\n",
    "#             print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "#             return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1503,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def grid_flexible_F_fixed_R(\n",
    "#     assigned_Ts,\n",
    "#     salvage_value,\n",
    "#     cost,\n",
    "#     price,\n",
    "#     Q_star,\n",
    "#     demand_df_train,\n",
    "#     Qk_hat_df_train,\n",
    "#     training_df,\n",
    "# ):\n",
    "#     results_dict = {\n",
    "#         \"R(T)\": [],\n",
    "#         \"R\": [],\n",
    "#         \"average_profits\": [],\n",
    "#         \"average_losses\": [],\n",
    "#         \"average_lefts\": [],\n",
    "#         \"average_operation_profits\": [],\n",
    "#         \"alpha_values\": [],\n",
    "#         \"F_vars\": [],\n",
    "#         \"Q0_vars\": [],\n",
    "#         \"Q1_vars\": [],\n",
    "#     }\n",
    "\n",
    "#     max_profit = None\n",
    "#     max_profit_stimulation_result = {}\n",
    "\n",
    "#     for assigned_T in assigned_Ts:\n",
    "#         assigned_R = assigned_T - 2\n",
    "#         result = cal_flexible_F_fixed_R(\n",
    "#             assigned_R=assigned_R,\n",
    "#             salvage_value=salvage_value,\n",
    "#             cost=cost,\n",
    "#             price=price,\n",
    "#             Q_star=Q_star,\n",
    "#             demand_df_train=demand_df_train,\n",
    "#             Qk_hat_df=Qk_hat_df_train,\n",
    "#             training_df=training_df,\n",
    "#         )\n",
    "\n",
    "#         if result is None:\n",
    "#             print(f\"模型沒有最佳解\")\n",
    "#             continue\n",
    "\n",
    "#         (\n",
    "#             all_Rs,\n",
    "#             losses,\n",
    "#             lefts,\n",
    "#             profits,\n",
    "#             operation_profits,\n",
    "#             alpha_values,\n",
    "#             F_vars,\n",
    "#             Q0_vars,\n",
    "#             Q1_vars,\n",
    "#         ) = result\n",
    "\n",
    "#         # 計算平均值\n",
    "#         average_losses = sum(losses) / len(losses) if losses else 0\n",
    "#         average_lefts = sum(lefts) / len(lefts) if lefts else 0\n",
    "#         average_profits = sum(profits) / len(profits) if profits else 0\n",
    "#         average_operation_profits = (\n",
    "#             sum(operation_profits) / len(operation_profits) if operation_profits else 0\n",
    "#         )\n",
    "\n",
    "#         # 將結果存儲到字典中\n",
    "#         results_dict[\"R(T)\"].append(assigned_T)\n",
    "#         results_dict[\"R\"].append(all_Rs)\n",
    "#         results_dict[\"average_losses\"].append(average_losses)\n",
    "#         results_dict[\"average_lefts\"].append(average_lefts)\n",
    "#         results_dict[\"average_profits\"].append(average_profits)\n",
    "#         results_dict[\"average_operation_profits\"].append(average_operation_profits)\n",
    "#         results_dict[\"alpha_values\"].append(alpha_values)\n",
    "#         results_dict[\"F_vars\"].append(F_vars)\n",
    "#         results_dict[\"Q0_vars\"].append(Q0_vars)\n",
    "#         results_dict[\"Q1_vars\"].append(Q1_vars)\n",
    "\n",
    "#         # print(f\"The average profits is {average_profits}\")\n",
    "\n",
    "#         if max_profit is None or max_profit < average_profits:\n",
    "#             # print(f\"max_profit is changed from {max_profit} to {average_profits}\")\n",
    "#             max_profit = average_profits\n",
    "#             max_profit_stimulation_result = {\n",
    "#                 \"R\": all_Rs,\n",
    "#                 \"F\": F_vars,\n",
    "#                 \"profits\": profits,\n",
    "#                 \"losses\": losses,\n",
    "#                 \"lefts\": lefts,\n",
    "#                 \"operation_profits\": operation_profits,\n",
    "#                 \"Q0\": Q0_vars,\n",
    "#                 \"Q1\": Q1_vars,\n",
    "#             }\n",
    "\n",
    "#     return pd.DataFrame(results_dict).sort_values(\n",
    "#         by=\"average_profits\", ascending=False\n",
    "#     ), pd.DataFrame(max_profit_stimulation_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S17 - Grid for Fixed Rk & Flexible F with lasso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1504,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_flexible_F_fixed_R(\n",
    "    assigned_R,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_train,\n",
    "    Qk_hat_df,\n",
    "    training_df,\n",
    "    lambda_alpha,\n",
    "):\n",
    "    print(\n",
    "        f\"+++++++++++++++++++++++++++++++++++++++ THis is R={assigned_R} +++++++++++++++++++++++++++++++++++++++++++++++++\"\n",
    "    )\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "        model.setParam(\"NonConvex\", 2)\n",
    "        model.setParam(\"IntFeasTol\", 1e-9)\n",
    "        model.setParam(\"NumericFocus\", 3)\n",
    "\n",
    "        # ======================= Decision Variables =======================\n",
    "        alphas = model.addVars(\n",
    "            features_num + 1, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"alphas\"\n",
    "        )\n",
    "        abs_alphas = model.addVars(alphas.keys(), lb=0, name=\"abs_alpha\")\n",
    "\n",
    "        # 進行 L1 正則化處理：alphas\n",
    "        for i in alphas.keys():\n",
    "            model.addConstr(abs_alphas[i] >= alphas[i])\n",
    "            model.addConstr(abs_alphas[i] >= -alphas[i])\n",
    "\n",
    "        Sold_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_0\")\n",
    "        Left_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_0\")\n",
    "        Lost_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_0\")\n",
    "\n",
    "        Sold_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_1\")\n",
    "        Left_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_1\")\n",
    "        Lost_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_1\")\n",
    "\n",
    "        f_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"f_var\"\n",
    "        )\n",
    "        F_vars = model.addVars(len(demand_df_train), lb=0, ub=1, name=\"Fraction\")\n",
    "\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, ub=(Q_star + 1), name=\"Q0_var\"\n",
    "        )\n",
    "        Q1_vars = model.addVars(len(Qk_hat_df), lb=0.0, name=\"Q1_var\")\n",
    "\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, name=\"profits_vars\"\n",
    "        )\n",
    "\n",
    "        # ======================= Model Constraints =======================\n",
    "        for i, row in demand_df_train.iterrows():\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i].tolist()\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            model.addConstr(F_vars[i] >= 0, name=f\"Fraction_lower_bound_{i}\")\n",
    "            model.addConstr(F_vars[i] <= 1, name=f\"Fraction_upper_bound_{i}\")\n",
    "\n",
    "            # Calculate F using logistic regression\n",
    "            model.addConstr(\n",
    "                f_vars[i]\n",
    "                == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            )\n",
    "            model.addGenConstrLogistic(\n",
    "                xvar=f_vars[i], yvar=F_vars[i], options=\"FuncNonlinear=1\"\n",
    "            )\n",
    "\n",
    "            # Calculate initial order quantity\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star)\n",
    "\n",
    "            # Define demand variables for before and after reorder point\n",
    "            total_demand_before_R = demand_row[: assigned_R + 1].sum()\n",
    "            total_demand_after_R = demand_row[assigned_R + 1 :].sum()\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Left_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0s[i],\n",
    "                [total_demand_before_R, Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_before_R - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_before_R - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # Calculate Q1 based on reorder point estimate\n",
    "            Q_hat = Qk_hat_df_row[assigned_R]\n",
    "            Q_hat_adjusted = Q_hat - Q0_vars[i]\n",
    "            Q_hat_adjusted_var = model.addVar(\n",
    "                lb=-GRB.INFINITY, name=f\"Q_hat_adjusted_{i}\"\n",
    "            )\n",
    "            model.addConstr(Q_hat_adjusted_var == Q_hat_adjusted)\n",
    "\n",
    "            model.addGenConstrMax(\n",
    "                Q1_vars[i], [Q_hat_adjusted_var, 0], name=f\"max_Q1_constr_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1s[i],\n",
    "                [total_demand_after_R, Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_after_R - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_after_R - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # # Calculate holding costs directly in profit equation\n",
    "            # holding_cost_1 = (\n",
    "            #     (Q0_vars[i] + total_stock_second_period) * (assigned_R + 2 - 1) / 2\n",
    "            # )\n",
    "            # holding_cost_2 = (\n",
    "            #     (total_stock_second_period + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "            # )\n",
    "\n",
    "            # model.addConstr(\n",
    "            #     profits_vars[i]\n",
    "            #     == (\n",
    "            #         (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "            #         - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "            #         - (cost - salvage_value) * (Left_1s[i])  # left cost\n",
    "            #     ),\n",
    "            #     name=f\"Profit_Constraint_{i}\",\n",
    "            # )\n",
    "\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * (Left_0s[i] + Left_1s[i])  # left cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "        # Set objective\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train)))\n",
    "            - lambda_alpha * gp.quicksum(abs_alphas[i] for i in abs_alphas.keys()),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "\n",
    "        model.write(\"s17_model_debug.lp\")\n",
    "        model.write(\"s17_model.mps\")\n",
    "\n",
    "        # Solve model\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL or model.status == GRB.TIME_LIMIT:\n",
    "                print(f\"Model status: {model.status}\")\n",
    "\n",
    "                # Collect results\n",
    "                alpha_values = np.array([alpha.X for alpha in alphas.values()])\n",
    "\n",
    "                results = {\n",
    "                    \"losses\": [],\n",
    "                    \"lefts\": [],\n",
    "                    \"profits\": [],\n",
    "                    \"operation_profits\": [],\n",
    "                    \"Q0s\": [],\n",
    "                    \"Q1s\": [],\n",
    "                    \"Fs\": [],\n",
    "                    \"fs\": [],\n",
    "                }\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "                    sold0, sold1 = Sold_0s[i].X, Sold_1s[i].X\n",
    "                    lost0, lost1 = Lost_0s[i].X, Lost_1s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    print(\n",
    "                        f\"Lost0: {lost0}, Lost1: {lost1}, Left0: {left0}, Left1: {left1}\"\n",
    "                    )\n",
    "\n",
    "                    # Record results\n",
    "                    results[\"losses\"].append(lost0 + lost1)\n",
    "\n",
    "                    # results[\"lefts\"].append(left1)\n",
    "                    results[\"lefts\"].append(left0 + left1)\n",
    "\n",
    "                    results[\"operation_profits\"].append(\n",
    "                        (price - cost) * (sold0 + sold1)\n",
    "                    )\n",
    "                    results[\"profits\"].append(profits_vars[i].X)\n",
    "                    results[\"Q1s\"].append(Q1_vars[i].X)\n",
    "\n",
    "                    # Check f\n",
    "                    x_data = training_df.iloc[i].tolist()\n",
    "                    x_data.append(1)\n",
    "                    f_train, F_train, Q0_train = compute_f_F_Q(\n",
    "                        x_data, alpha_values, Q_star\n",
    "                    )\n",
    "                    print(\n",
    "                        f\"f_train: {f_train}, F_train: {F_train}, Q0_train: {Q0_train}\"\n",
    "                    )\n",
    "                    if (\n",
    "                        truncate_to_2(f_train) == truncate_to_2(f_vars[i].X)\n",
    "                        and truncate_to_2(F_train) == truncate_to_2(F_vars[i].X)\n",
    "                        and truncate_to_2(Q0_train) == truncate_to_2(Q0_vars[i].X)\n",
    "                    ):\n",
    "                        print(\"f_train, F_train, Q0_train 都相等\")\n",
    "                        results[\"Q0s\"].append(Q0_vars[i].X)\n",
    "                        results[\"Fs\"].append(F_vars[i].X)\n",
    "                        results[\"fs\"].append(f_vars[i].X)\n",
    "                    else:\n",
    "                        print(f\"f_train, F_train, Q0_train 不相等\")\n",
    "                        results[\"Q0s\"].append(-1)\n",
    "                        results[\"Fs\"].append(-1)\n",
    "                        results[\"fs\"].append(-1)\n",
    "                        # results[\"Q0s\"].append(Q0_vars[i].X)\n",
    "                        # results[\"Fs\"].append(F_vars[i].X)\n",
    "                        # results[\"fs\"].append(f_vars[i].X)\n",
    "                return (\n",
    "                    [assigned_R] * len(demand_df_train),  # Fixed R for all observations\n",
    "                    results[\"losses\"],\n",
    "                    results[\"lefts\"],\n",
    "                    results[\"profits\"],\n",
    "                    results[\"operation_profits\"],\n",
    "                    alpha_values,\n",
    "                    results[\"Fs\"],\n",
    "                    results[\"fs\"],\n",
    "                    results[\"Q0s\"],\n",
    "                    results[\"Q1s\"],\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1505,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_flexible_F_fixed_R(\n",
    "    assigned_Ts,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_train,\n",
    "    Qk_hat_df_train,\n",
    "    training_df,\n",
    "):\n",
    "    results_dict = {\n",
    "        \"R(T)\": [],\n",
    "        \"R\": [],\n",
    "        \"average_profits\": [],\n",
    "        \"average_losses\": [],\n",
    "        \"average_lefts\": [],\n",
    "        \"average_operation_profits\": [],\n",
    "        \"alpha_values\": [],\n",
    "        \"F_vars\": [],\n",
    "        \"f_vars\": [],\n",
    "        \"Q0_vars\": [],\n",
    "        \"Q1_vars\": [],\n",
    "    }\n",
    "\n",
    "    max_profit = None\n",
    "    max_profit_stimulation_result = {}\n",
    "\n",
    "    for assigned_T in assigned_Ts:\n",
    "        assigned_R = assigned_T - 2\n",
    "        result = cal_flexible_F_fixed_R(\n",
    "            assigned_R=assigned_R,\n",
    "            salvage_value=salvage_value,\n",
    "            cost=cost,\n",
    "            price=price,\n",
    "            Q_star=Q_star,\n",
    "            demand_df_train=demand_df_train,\n",
    "            Qk_hat_df=Qk_hat_df_train,\n",
    "            training_df=training_df,\n",
    "            lambda_alpha=LASSO_ALPHA,\n",
    "        )\n",
    "\n",
    "        if result is None:\n",
    "            print(f\"模型沒有最佳解\")\n",
    "            continue\n",
    "\n",
    "        (\n",
    "            all_Rs,\n",
    "            losses,\n",
    "            lefts,\n",
    "            profits,\n",
    "            operation_profits,\n",
    "            alpha_values,\n",
    "            F_vars,\n",
    "            f_vars,\n",
    "            Q0_vars,\n",
    "            Q1_vars,\n",
    "        ) = result\n",
    "\n",
    "        # 計算平均值\n",
    "        average_losses = sum(losses) / len(losses) if losses else 0\n",
    "        average_lefts = sum(lefts) / len(lefts) if lefts else 0\n",
    "        average_profits = sum(profits) / len(profits) if profits else 0\n",
    "        average_operation_profits = (\n",
    "            sum(operation_profits) / len(operation_profits) if operation_profits else 0\n",
    "        )\n",
    "\n",
    "        # 將結果存儲到字典中\n",
    "        results_dict[\"R(T)\"].append(assigned_T)\n",
    "        results_dict[\"R\"].append(all_Rs)\n",
    "        results_dict[\"average_losses\"].append(average_losses)\n",
    "        results_dict[\"average_lefts\"].append(average_lefts)\n",
    "        results_dict[\"average_profits\"].append(average_profits)\n",
    "        results_dict[\"average_operation_profits\"].append(average_operation_profits)\n",
    "        results_dict[\"alpha_values\"].append(alpha_values)\n",
    "        results_dict[\"F_vars\"].append(F_vars)\n",
    "        results_dict[\"f_vars\"].append(f_vars)\n",
    "        results_dict[\"Q0_vars\"].append(Q0_vars)\n",
    "        results_dict[\"Q1_vars\"].append(Q1_vars)\n",
    "\n",
    "        # print(f\"The average profits is {average_profits}\")\n",
    "\n",
    "        if max_profit is None or max_profit < average_profits:\n",
    "            # print(f\"max_profit is changed from {max_profit} to {average_profits}\")\n",
    "            max_profit = average_profits\n",
    "            max_profit_stimulation_result = {\n",
    "                \"R\": all_Rs,\n",
    "                \"F\": F_vars,\n",
    "                \"f\": f_vars,\n",
    "                \"profits\": profits,\n",
    "                \"losses\": losses,\n",
    "                \"lefts\": lefts,\n",
    "                \"operation_profits\": operation_profits,\n",
    "                \"Q0\": Q0_vars,\n",
    "                \"Q1\": Q1_vars,\n",
    "            }\n",
    "\n",
    "    return pd.DataFrame(results_dict).sort_values(\n",
    "        by=\"average_profits\", ascending=False\n",
    "    ), pd.DataFrame(max_profit_stimulation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S13 - Grid for Fixed Rk & Optimized F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1506,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_optimized_F_fixed_R(\n",
    "    assigned_R,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_train,\n",
    "    Qk_hat_df,\n",
    "    training_df,\n",
    "):\n",
    "    print(\n",
    "        f\"+++++++++++++++++++++++++++++++++++++++ THis is R={assigned_R} +++++++++++++++++++++++++++++++++++++++++++++++++\"\n",
    "    )\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "\n",
    "        # ======================= Decision Variables =======================\n",
    "        # alphas = model.addVars(\n",
    "        #     features_num + 1, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"alphas\"\n",
    "        # )\n",
    "        Sold_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_0\")\n",
    "        Sold_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_1\")\n",
    "        Lost_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_0\")\n",
    "        Lost_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_1\")\n",
    "        Left_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_1\")\n",
    "\n",
    "        # f_vars = model.addVars(\n",
    "        #     len(demand_df_train), lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"f_var\"\n",
    "        # )\n",
    "        F_vars = model.addVars(len(demand_df_train), lb=0, ub=1, name=\"Fraction\")\n",
    "\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, ub=(Q_star + 1), name=\"Q0_var\"\n",
    "        )\n",
    "        Q1_vars = model.addVars(len(Qk_hat_df), lb=0.0, name=\"Q1_var\")\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, name=\"profits_vars\"\n",
    "        )\n",
    "\n",
    "        # ======================= Model Constraints =======================\n",
    "        for i, row in demand_df_train.iterrows():\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i].tolist()\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            model.addConstr(F_vars[i] >= 0, name=f\"Fraction_lower_bound_{i}\")\n",
    "            model.addConstr(F_vars[i] <= 1, name=f\"Fraction_upper_bound_{i}\")\n",
    "\n",
    "            # Calculate F using logistic regression\n",
    "            # model.addConstr(\n",
    "            #     f_vars[i]\n",
    "            #     == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            # )\n",
    "            # model.addGenConstrLogistic(xvar=f_vars[i], yvar=F_vars[i])\n",
    "\n",
    "            # Calculate initial order quantity\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star)\n",
    "\n",
    "            # Define demand variables for before and after reorder point\n",
    "            total_demand_before_R = demand_row[: assigned_R + 1].sum()\n",
    "            total_demand_after_R = demand_row[assigned_R + 1 :].sum()\n",
    "\n",
    "            # Calculate first period sales and lost sales\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0s[i],\n",
    "                [total_demand_before_R, Q0_vars[i]],\n",
    "                name=f\"min_sales_constr_{i}\",\n",
    "            )\n",
    "\n",
    "            # Calculate lost sales\n",
    "            Lost_0_expr = total_demand_before_R - Q0_vars[i]\n",
    "            Lost_0_var = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_expr_{i}\")\n",
    "            model.addConstr(Lost_0_var == Lost_0_expr)\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_var, 0], name=f\"max_lost_constr_{i}\"\n",
    "            )\n",
    "\n",
    "            # Calculate inventory left after first period\n",
    "            left_0 = Q0_vars[i] - Sold_0s[i]\n",
    "\n",
    "            # Calculate Q1 based on reorder point estimate\n",
    "            Q_hat = Qk_hat_df_row[assigned_R]\n",
    "            Q_hat_adjusted = Q_hat - Q0_vars[i]\n",
    "            Q_hat_adjusted_var = model.addVar(\n",
    "                lb=-GRB.INFINITY, name=f\"Q_hat_adjusted_{i}\"\n",
    "            )\n",
    "            model.addConstr(Q_hat_adjusted_var == Q_hat_adjusted)\n",
    "\n",
    "            model.addGenConstrMax(\n",
    "                Q1_vars[i], [Q_hat_adjusted_var, 0], name=f\"max_Q1_constr_{i}\"\n",
    "            )\n",
    "\n",
    "            # Calculate second period sales and lost sales\n",
    "            total_stock_second_period = Q1_vars[i] + left_0\n",
    "            total_stock_second_period_var = model.addVar(\n",
    "                lb=0, name=f\"total_stock_second_period_{i}\"\n",
    "            )\n",
    "            model.addConstr(total_stock_second_period_var == total_stock_second_period)\n",
    "\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1s[i],\n",
    "                [total_demand_after_R, total_stock_second_period_var],\n",
    "                name=f\"min_sales2_constr_{i}\",\n",
    "            )\n",
    "\n",
    "            # Calculate second period lost sales\n",
    "            Lost_1_expr = total_demand_after_R - total_stock_second_period_var\n",
    "            Lost_1_var = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_1_expr_{i}\")\n",
    "            model.addConstr(Lost_1_var == Lost_1_expr)\n",
    "\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_var, 0], name=f\"max_lost2_constr_{i}\"\n",
    "            )\n",
    "\n",
    "            model.addConstr(Left_1s[i] == total_stock_second_period_var - Sold_1s[i])\n",
    "\n",
    "            # # Calculate holding costs directly in profit equation\n",
    "            # holding_cost_1 = (\n",
    "            #     (Q0_vars[i] + total_stock_second_period) * (assigned_R + 2 - 1) / 2\n",
    "            # )\n",
    "            # holding_cost_2 = (\n",
    "            #     (total_stock_second_period + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "            # )\n",
    "\n",
    "            # Calculate profit\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "                    - (cost - salvage_value) * Left_1s[i]  # Salvage cost\n",
    "                    # - holding_cost * (holding_cost_1 + holding_cost_2)  # Holding cost\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Set objective\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train))),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "\n",
    "        model.write(\"s2_model_debug.lp\")\n",
    "        model.write(\"s2_model.mps\")\n",
    "\n",
    "        # Solve model\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL or model.status == GRB.TIME_LIMIT:\n",
    "                print(f\"Model status: {model.status}\")\n",
    "\n",
    "                # Collect results\n",
    "                # alpha_values = np.array([alpha.X for alpha in alphas.values()])\n",
    "\n",
    "                results = {\n",
    "                    \"losses\": [],\n",
    "                    \"lefts\": [],\n",
    "                    \"profits\": [],\n",
    "                    \"operation_profits\": [],\n",
    "                    \"Q0s\": [],\n",
    "                    \"Q1s\": [],\n",
    "                    \"Fs\": [],\n",
    "                }\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "                    sold0, sold1 = Sold_0s[i].X, Sold_1s[i].X\n",
    "                    lost0, lost1 = Lost_0s[i].X, Lost_1s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "\n",
    "                    # Record results\n",
    "                    results[\"losses\"].append(lost0 + lost1)\n",
    "                    results[\"lefts\"].append(left1)\n",
    "                    results[\"operation_profits\"].append(\n",
    "                        (price - cost) * (sold0 + sold1)\n",
    "                    )\n",
    "                    results[\"profits\"].append(profits_vars[i].X)\n",
    "                    results[\"Q0s\"].append(Q0_vars[i].X)\n",
    "                    results[\"Q1s\"].append(Q1_vars[i].X)\n",
    "                    results[\"Fs\"].append(F_vars[i].X)\n",
    "\n",
    "                    print(f\"\\nObservation {i+1}:\")\n",
    "                    print(f\"Reorder day: {assigned_R}\")\n",
    "                    print(f\"Profit: {profits_vars[i].X:.2f}\")\n",
    "\n",
    "                return (\n",
    "                    [assigned_R] * len(demand_df_train),  # Fixed R for all observations\n",
    "                    results[\"losses\"],\n",
    "                    results[\"lefts\"],\n",
    "                    results[\"profits\"],\n",
    "                    results[\"operation_profits\"],\n",
    "                    None,\n",
    "                    results[\"Fs\"],\n",
    "                    results[\"Q0s\"],\n",
    "                    results[\"Q1s\"],\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1507,
   "metadata": {
    "id": "XHdZiv2bbIfP"
   },
   "outputs": [],
   "source": [
    "def grid_optimized_F_fixed_R(\n",
    "    assigned_Ts,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_train,\n",
    "    Qk_hat_df_train,\n",
    "    training_df,\n",
    "):\n",
    "    results_dict = {\n",
    "        \"R(T)\": [],\n",
    "        \"R\": [],\n",
    "        \"average_profits\": [],\n",
    "        \"average_losses\": [],\n",
    "        \"average_lefts\": [],\n",
    "        \"average_operation_profits\": [],\n",
    "        \"alpha_values\": [],\n",
    "        \"F_vars\": [],\n",
    "        \"Q0_vars\": [],\n",
    "        \"Q1_vars\": [],\n",
    "    }\n",
    "\n",
    "    max_profit = None\n",
    "    max_profit_stimulation_result = {}\n",
    "\n",
    "    for assigned_T in assigned_Ts:\n",
    "        assigned_R = assigned_T - 2\n",
    "        result = cal_optimized_F_fixed_R(\n",
    "            assigned_R=assigned_R,\n",
    "            salvage_value=salvage_value,\n",
    "            cost=cost,\n",
    "            price=price,\n",
    "            Q_star=Q_star,\n",
    "            demand_df_train=demand_df_train,\n",
    "            Qk_hat_df=Qk_hat_df_train,\n",
    "            training_df=training_df,\n",
    "        )\n",
    "\n",
    "        if result is None:\n",
    "            print(f\"模型沒有最佳解\")\n",
    "            results_dict[\"R(T)\"].append(None)\n",
    "            results_dict[\"R\"].append(None)\n",
    "            results_dict[\"average_losses\"].append(None)\n",
    "            results_dict[\"average_lefts\"].append(None)\n",
    "            results_dict[\"average_profits\"].append(None)\n",
    "            results_dict[\"average_operation_profits\"].append(None)\n",
    "            results_dict[\"alpha_values\"].append(None)\n",
    "            results_dict[\"F_vars\"].append(None)\n",
    "            results_dict[\"Q0_vars\"].append(None)\n",
    "            results_dict[\"Q1_vars\"].append(None)\n",
    "\n",
    "            continue\n",
    "\n",
    "        (\n",
    "            all_Rs,\n",
    "            losses,\n",
    "            lefts,\n",
    "            profits,\n",
    "            operation_profits,\n",
    "            alpha_values,\n",
    "            F_vars,\n",
    "            Q0_vars,\n",
    "            Q1_vars,\n",
    "        ) = result\n",
    "\n",
    "        # 計算平均值\n",
    "        average_losses = sum(losses) / len(losses) if losses else 0\n",
    "        average_lefts = sum(lefts) / len(lefts) if lefts else 0\n",
    "        average_profits = sum(profits) / len(profits) if profits else 0\n",
    "        average_operation_profits = (\n",
    "            sum(operation_profits) / len(operation_profits) if operation_profits else 0\n",
    "        )\n",
    "\n",
    "        # 將結果存儲到字典中\n",
    "        results_dict[\"R(T)\"].append(assigned_T)\n",
    "        results_dict[\"R\"].append(all_Rs)\n",
    "        results_dict[\"average_losses\"].append(average_losses)\n",
    "        results_dict[\"average_lefts\"].append(average_lefts)\n",
    "        results_dict[\"average_profits\"].append(average_profits)\n",
    "        results_dict[\"average_operation_profits\"].append(average_operation_profits)\n",
    "        results_dict[\"alpha_values\"].append(alpha_values)\n",
    "        results_dict[\"F_vars\"].append(F_vars)\n",
    "        results_dict[\"Q0_vars\"].append(Q0_vars)\n",
    "        results_dict[\"Q1_vars\"].append(Q1_vars)\n",
    "\n",
    "        print(f\"The average profits is {average_profits}\")\n",
    "\n",
    "        if max_profit is None or max_profit < average_profits:\n",
    "            print(f\"max_profit is changed from {max_profit} to {average_profits}\")\n",
    "            max_profit = average_profits\n",
    "            max_profit_stimulation_result = {\n",
    "                \"R\": all_Rs,\n",
    "                \"F\": F_vars,\n",
    "                \"profits\": profits,\n",
    "                \"losses\": losses,\n",
    "                \"lefts\": lefts,\n",
    "                \"operation_profits\": operation_profits,\n",
    "                \"Q0\": Q0_vars,\n",
    "                \"Q1\": Q1_vars,\n",
    "            }\n",
    "\n",
    "    return pd.DataFrame(results_dict).sort_values(\n",
    "        by=\"average_profits\", ascending=False\n",
    "    ), pd.DataFrame(max_profit_stimulation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HzqGevK3OwNQ"
   },
   "source": [
    "## S3 - Grid for Fixed F & Flexible Rk(with full beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1508,
   "metadata": {
    "id": "JEygghprPvw5"
   },
   "outputs": [],
   "source": [
    "def cal_fixed_F_flexible_R(\n",
    "    assigned_F,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_train,\n",
    "    Qk_hat_df,\n",
    "    training_df,\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        betas = model.addVars(\n",
    "            K, features_num + 1, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"betas\"\n",
    "        )  # Beta coefficients\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "        Sold_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Sold_0\",\n",
    "        )\n",
    "        Left_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Left_0\",\n",
    "        )\n",
    "        Lost_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Lost_0\",\n",
    "        )\n",
    "\n",
    "        Sold_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Sold_1\",\n",
    "        )\n",
    "        Left_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Left_1\",\n",
    "        )\n",
    "        Lost_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Lost_1\",\n",
    "        )\n",
    "\n",
    "        Holding_Cost_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Holding_Cost_0\",\n",
    "        )\n",
    "\n",
    "        Holding_Cost_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Holding_Cost_1\",\n",
    "        )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=-GRB.INFINITY,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"profits_vars\",\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Total_Demand_from_k_to_T\",\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=1,\n",
    "            name=\"Fraction_for_second_order_amount\",\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), vtype=GRB.CONTINUOUS, lb=0, ub=Q_star, name=\"Q0_var\"\n",
    "        )\n",
    "\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        tau_vars = model.addVars(\n",
    "            len(demand_df_train), K, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"tau\"\n",
    "        )  # Tau變量\n",
    "        r_vars = model.addVars(\n",
    "            len(demand_df_train), K, vtype=GRB.CONTINUOUS, lb=0.0, ub=1.0, name=\"r\"\n",
    "        )  # but t-1 is different from others\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=demand_df_train.max().max(),\n",
    "            name=\"Q1_var\",\n",
    "        )  # Every stimulation will have there own Q1 vars.\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=(-demand_df_train.max().max() * 100),\n",
    "            ub=demand_df_train.max().max() * 100,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=(-demand_df_train.max().max() * 100),\n",
    "            ub=demand_df_train.max().max() * 100,\n",
    "            name=f\"Q_hat_adjusted\",\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, row in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            model.addConstr(F_vars[i] == assigned_F)\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "            # 用線性回歸計算確定最佳補貨時間\n",
    "            exp_tau_vars = []\n",
    "            for k in range(K):\n",
    "\n",
    "                # 計算 tau_vars 作為 beta 和特徵的線性組合\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, k]\n",
    "                    == gp.quicksum(\n",
    "                        X_data[j] * betas[k, j] for j in range(features_num + 1)\n",
    "                    ),\n",
    "                    name=f\"tau_computation_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "                # 定義指數變數\n",
    "                exp_tau_var = model.addVar(\n",
    "                    vtype=GRB.CONTINUOUS, name=f\"exp_tau_var_{i}_{k}\"\n",
    "                )\n",
    "                neg_tau_var = model.addVar(\n",
    "                    vtype=GRB.CONTINUOUS, name=f\"neg_tau_var_{i}_{k}\"\n",
    "                )\n",
    "\n",
    "                # 設定約束條件\n",
    "                model.addConstr(\n",
    "                    neg_tau_var == -tau_vars[i, k], name=f\"neg_tau_constr_{i}_{k}\"\n",
    "                )\n",
    "                model.addGenConstrExp(xvar=neg_tau_var, yvar=exp_tau_var)\n",
    "\n",
    "                exp_tau_vars.append(exp_tau_var)\n",
    "\n",
    "                model.addConstr(\n",
    "                    r_vars[i, k] * gp.quicksum(exp_tau_vars) == exp_tau_vars[k],\n",
    "                    name=f\"softmax_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "            ### 找到最大 R 以及 r, R 的相關限制式 -> k: 0~7\n",
    "            max_r_helpers = model.addVar(vtype=GRB.CONTINUOUS, name=\"max_r_helper\")\n",
    "            model.addGenConstrMax(\n",
    "                max_r_helpers,\n",
    "                [r_vars[i, k] for k in range(K)],\n",
    "                name=f\"MaxRConstraint_{i}\",\n",
    "            )\n",
    "\n",
    "            ### 指定讓當 r_vars 中的值等於 max_r 時，R_vars 設為 1 -> k: 0~7\n",
    "            for k in range(K):\n",
    "                model.addConstr(\n",
    "                    r_vars[i, k] - max_r_helpers >= (R_vars[i, k] - 1),\n",
    "                    \"link_r_R_{}\".format(k),\n",
    "                )\n",
    "                model.addGenConstrIndicator(\n",
    "                    R_vars[i, k], 1, r_vars[i, k] == max_r_helpers\n",
    "                )\n",
    "\n",
    "            ## 只會有一個 R 為 1\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"Ensure_only_one_R_true_{i}\",\n",
    "            )  # 0~7\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "\n",
    "            ### 將 Q_hats(重新估計的值) 與原先 Q0 值進行比較。如果發現原先估計的比較少，則補足 Q_hat_adjusted，如果不用補充，則為 0\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            # ### 0~k-1 的需求量\n",
    "            total_demand_up_to_k_minus_1_var = model.addVar(\n",
    "                name=f\"Total_Demand_Up_to_K_Minus_1_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_var\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == total_demand_up_to_k_minus_1_var,\n",
    "                name=f\"Calculate_Total_Demand_Up_to_K_minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            total_demand_from_k_to_T_var = model.addVar(\n",
    "                name=f\"Total_Demand_from_K_to_T_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_var\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i] == total_demand_from_k_to_T_var,\n",
    "                name=f\"Calculate_Total_Demand_from_k_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Sold_0_aux = model.addVar(name=f\"Sold_0_aux_{i}\")\n",
    "            Left_0_aux = model.addVar(name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(name=f\"Lost_0_aux_{i}\")\n",
    "            Sold_1_aux = model.addVar(name=f\"Sold_1_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0_aux,\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "            model.addConstr(Sold_0s[i] == Sold_0_aux, name=f\"Constr_Sold_0_eq_aux_{i}\")\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1_aux,\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "            model.addConstr(Sold_1s[i] == Sold_1_aux, name=f\"Constr_Sold_1_eq_aux_{i}\")\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Holding_Cost_0\n",
    "            assigned_R_var = model.addVar(vtype=GRB.INTEGER, name=f\"assigned_R_{i}\")\n",
    "            model.addConstr(\n",
    "                assigned_R_var == gp.quicksum(k * R_vars[i, k] for k in range(K)),\n",
    "                name=f\"Calc_assigned_R_{i}\",\n",
    "            )\n",
    "\n",
    "            model.addConstr(\n",
    "                Holding_Cost_0s[i]\n",
    "                == ((Q0_vars[i] + Q1_plus_lefts[i]) * (assigned_R_var + 2 - 1) / 2),\n",
    "                name=f\"Constr_Holding_Cost_0_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Holding_Cost_1\n",
    "            model.addConstr(\n",
    "                Holding_Cost_1s[i]\n",
    "                == ((Q1_plus_lefts[i] + Left_1s[i]) * (T - (assigned_R_var + 2)) / 2),\n",
    "                name=f\"Constr_Holding_Cost_1_{i}\",\n",
    "            )\n",
    "\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "                    - holding_cost\n",
    "                    * (Holding_Cost_0s[i] + Holding_Cost_1s[i])  # holding cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train))),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                print(\"===================== 找到最佳解 ==================\")\n",
    "                print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                print(\"Beta values:\")\n",
    "                for key, beta in betas.items():\n",
    "                    print(f\"beta{key}: {beta.X}\")\n",
    "\n",
    "                beta_values = np.array(\n",
    "                    [[betas[i, j].X for j in range(1)] for i in range(K)]\n",
    "                )\n",
    "                tau_values = np.array(\n",
    "                    [\n",
    "                        [tau_vars[i, j].X for j in range(K)]\n",
    "                        for i in range(len(demand_df_train))\n",
    "                    ]\n",
    "                )\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                all_holding_costs_0 = []\n",
    "                all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    print(\"----------------------------------------------\")\n",
    "                    print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "                    all_Q0s.append(Q0_vars[i].X)\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    all_Fs.append(F_vars[i].X)\n",
    "                    all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    for k in range(K):\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        print(f\"第 {k+2} 天補貨策略: R_vars = {R_value}\")\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "                    all_Rs.append(reorder_day)\n",
    "\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "                    # print(f\"第一階段需求量: {demand_row[: (reorder_day-1)].sum()}\")\n",
    "                    # print(f\"第二階段需求量: {demand_row[(reorder_day-1): ].sum()}\\n\")\n",
    "\n",
    "                    # print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "                    # print(f\"F_var（重新訂貨量佔總訂貨量比例）: {F_vars[i].X}\")\n",
    "                    # print(f\"Q0_var（期初庫存量）: {Q0_vars[i].X}\\n\")\n",
    "                    # print(f\"Q1_var（二次訂貨量）: {Q1_vars[i].X}\")\n",
    "                    # print(f\"Holding_Cost_0: {Holding_Cost_0}\")\n",
    "                    # print(f\"Holding_Cost_1: {Holding_Cost_1}\\n\")\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    print(check_results_df)\n",
    "\n",
    "                    # for t in range(2):\n",
    "                    #     if t == 0:\n",
    "                    #         print(\n",
    "                    #             f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                    #         )\n",
    "                    #     else:\n",
    "                    #         print(\n",
    "                    #             f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                    #         )\n",
    "\n",
    "                    # print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                print(\"==========================================\")\n",
    "                print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    beta_values,\n",
    "                    tau_values,\n",
    "                    all_holding_costs_0,\n",
    "                    all_holding_costs_1,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1509,
   "metadata": {
    "id": "18afnulQbj_B"
   },
   "outputs": [],
   "source": [
    "def grid_fixed_F_flexible_R(\n",
    "    assigned_Fs,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_train,\n",
    "    Qk_hat_df_train,\n",
    "    training_df,\n",
    "):\n",
    "    results_dict = {\n",
    "        \"R(T)\": [],\n",
    "        \"average_losses\": [],\n",
    "        \"average_lefts\": [],\n",
    "        \"average_operation_profits\": [],\n",
    "        \"average_profits\": [],\n",
    "        \"beta_values\": [],\n",
    "        \"F_vars\": [],\n",
    "        \"Q0_vars\": [],\n",
    "        \"Q1_vars\": [],\n",
    "        \"tau_values\": [],\n",
    "    }\n",
    "\n",
    "    max_profit = None\n",
    "    max_profit_stimulation_result = {}\n",
    "\n",
    "    for assigned_F in assigned_Fs:\n",
    "        print(\n",
    "            f\"+++++++++++++++++++++++++++++++++++++++ THis is F={assigned_F} +++++++++++++++++++++++++++++++++++++++++++++++++\"\n",
    "        )\n",
    "        result = cal_fixed_F_flexible_R(\n",
    "            assigned_F=assigned_F,\n",
    "            salvage_value=salvage_value,\n",
    "            cost=cost,\n",
    "            price=price,\n",
    "            Q_star=Q_star,\n",
    "            demand_df_train=demand_df_train,\n",
    "            Qk_hat_df=Qk_hat_df_train,\n",
    "            training_df=training_df,\n",
    "        )\n",
    "\n",
    "        if result is None:\n",
    "            print(f\"模型沒有最佳解\")\n",
    "\n",
    "        else:\n",
    "            (\n",
    "                all_Rs,\n",
    "                losses,\n",
    "                lefts,\n",
    "                profits,\n",
    "                operation_profits,\n",
    "                F_vars,\n",
    "                Q0_vars,\n",
    "                Q1_vars,\n",
    "                beta_values,\n",
    "                tau_values,\n",
    "                holding_costs_0s,\n",
    "                holding_costs_1s,\n",
    "                all_left0s,\n",
    "                all_left1s,\n",
    "                all_lost0s,\n",
    "                all_lost1s,\n",
    "            ) = result\n",
    "\n",
    "            # 计算平均值\n",
    "            average_losses = sum(losses) / len(losses) if losses else 0\n",
    "            average_lefts = sum(lefts) / len(lefts) if lefts else 0\n",
    "            average_profits = sum(profits) / len(profits) if profits else 0\n",
    "            average_operation_profits = (\n",
    "                sum(operation_profits) / len(operation_profits)\n",
    "                if operation_profits\n",
    "                else 0\n",
    "            )\n",
    "\n",
    "            # 将结果存储到字典中\n",
    "            results_dict[\"R(T)\"].append(all_Rs)\n",
    "            results_dict[\"average_losses\"].append(average_losses)\n",
    "            results_dict[\"average_lefts\"].append(average_lefts)\n",
    "            results_dict[\"average_profits\"].append(average_profits)\n",
    "            results_dict[\"average_operation_profits\"].append(average_operation_profits)\n",
    "            results_dict[\"beta_values\"].append(beta_values)\n",
    "            results_dict[\"tau_values\"].append(tau_values)\n",
    "            results_dict[\"F_vars\"].append(F_vars)\n",
    "            results_dict[\"Q0_vars\"].append(Q0_vars)\n",
    "            results_dict[\"Q1_vars\"].append(Q1_vars)\n",
    "\n",
    "            if max_profit is None or max_profit < average_profits:\n",
    "                print(f\"max_profit is changed from {max_profit} to {average_profits}\")\n",
    "                max_profit = average_profits\n",
    "                max_profit_stimulation_result = {\n",
    "                    \"R(T)\": all_Rs,\n",
    "                    \"F\": F_vars,\n",
    "                    \"profits\": profits,\n",
    "                    \"losses\": losses,\n",
    "                    \"lefts\": lefts,\n",
    "                    \"operation_profits\": operation_profits,\n",
    "                    \"Q0\": Q0_vars,\n",
    "                    \"Q1\": Q1_vars,\n",
    "                    \"hc0\": holding_costs_0s,\n",
    "                    \"hc1\": holding_costs_1s,\n",
    "                    \"Left0s\": all_left0s,\n",
    "                    \"Left1s\": all_left1s,\n",
    "                    \"lost0s\": all_lost0s,\n",
    "                    \"lost1s\": all_lost1s,\n",
    "                }\n",
    "\n",
    "            print(f\"beta_values: \\n{beta_values}\")\n",
    "\n",
    "    print(max_profit_stimulation_result)\n",
    "\n",
    "    return pd.DataFrame(results_dict).sort_values(\n",
    "        by=\"average_profits\", ascending=False\n",
    "    ), pd.DataFrame(max_profit_stimulation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4Bnp-M_QC6e"
   },
   "source": [
    "## Fully flexible F & Rk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6BPJ4AakQC6e"
   },
   "source": [
    "### S5 - Simple beta with softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1510,
   "metadata": {
    "id": "bdApAjTOQC6e"
   },
   "outputs": [],
   "source": [
    "def __fully_flexible_simple_beta_with_softmax_5(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        alphas = model.addVars(\n",
    "            features_num + 1, name=\"alphas\"\n",
    "        )  # alpha coefficients with intercept\n",
    "        betas = model.addVars(\n",
    "            K, features_num + 1, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"betas\"\n",
    "        )  # Beta coefficients\n",
    "        betas = model.addVars(\n",
    "            K, 1, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"betas_with_ONLY_intercept\"\n",
    "        )  # Beta coefficients with ONLY intercept\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "\n",
    "        #### 1-1. 計算兩階段 Sold, Loss, Left 以及總合的 profit\n",
    "        Sold_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Sold_0\",\n",
    "        )\n",
    "        Left_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Left_0\",\n",
    "        )\n",
    "        Lost_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Lost_0\",\n",
    "        )\n",
    "\n",
    "        Sold_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Sold_1\",\n",
    "        )\n",
    "        Left_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Left_1\",\n",
    "        )\n",
    "        Lost_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Lost_1\",\n",
    "        )\n",
    "\n",
    "        Holding_Cost_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Holding_Cost_0\",\n",
    "        )\n",
    "\n",
    "        Holding_Cost_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Holding_Cost_1\",\n",
    "        )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=-GRB.INFINITY,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"profits_vars\",\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Total_Demand_from_k_to_T\",\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        f_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=-GRB.INFINITY,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"f_var\",\n",
    "        )\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=1,\n",
    "            name=\"Fraction_for_second_order_amount\",\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), vtype=GRB.CONTINUOUS, lb=0, ub=Q_star, name=\"Q0_var\"\n",
    "        )\n",
    "\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        tau_vars = model.addVars(\n",
    "            len(demand_df_train), K, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"tau\"\n",
    "        )  # Tau變量\n",
    "        r_vars = model.addVars(\n",
    "            len(demand_df_train), K, vtype=GRB.CONTINUOUS, lb=0.0, ub=1.0, name=\"r\"\n",
    "        )  # but t-1 is different from others\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=demand_df_train.max().max(),\n",
    "            name=\"Q1_var\",\n",
    "        )  # Every stimulation will have there own Q1 vars.\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=(-demand_df_train.max().max() * 100),\n",
    "            ub=demand_df_train.max().max() * 100,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=(-demand_df_train.max().max() * 100),\n",
    "            ub=demand_df_train.max().max() * 100,\n",
    "            name=f\"Q_hat_adjusted\",\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, row in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            ### 用線性回歸計算F_var\n",
    "            model.addConstr(\n",
    "                f_vars[i]\n",
    "                == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            )\n",
    "            model.addGenConstrLogistic(\n",
    "                xvar=f_vars[i], yvar=F_vars[i], name=f\"logistic_constraint_{i}\"\n",
    "            )\n",
    "\n",
    "            ### Q0_var = F_vars * Q_star\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "            # 用線性回歸計算確定最佳補貨時間\n",
    "\n",
    "            ### 訓練 beta(使用 softmax)\n",
    "            exp_tau_vars = []\n",
    "            for k in range(K):\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, k] == betas[k, 0], name=f\"tau_computation_{i}_{k}\"\n",
    "                )  # 只使用截距項\n",
    "\n",
    "                exp_tau_var = model.addVar(\n",
    "                    vtype=GRB.CONTINUOUS, name=f\"exp_tau_var_{i}_{k}\"\n",
    "                )\n",
    "                neg_tau_var = model.addVar(\n",
    "                    vtype=GRB.CONTINUOUS, name=f\"neg_tau_var_{i}_{k}\"\n",
    "                )\n",
    "\n",
    "                model.addConstr(\n",
    "                    neg_tau_var == -tau_vars[i, k], name=f\"neg_tau_constr_{i}_{k}\"\n",
    "                )\n",
    "                model.addGenConstrExp(xvar=neg_tau_var, yvar=exp_tau_var)\n",
    "\n",
    "                exp_tau_vars.append(exp_tau_var)\n",
    "\n",
    "            for k in range(K):\n",
    "                model.addConstr(\n",
    "                    r_vars[i, k] * gp.quicksum(exp_tau_vars) == exp_tau_vars[k],\n",
    "                    name=f\"softmax_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "            ### 找到最大 R 以及 r, R 的相關限制式 -> k: 0~7\n",
    "            max_r_helpers = model.addVar(vtype=GRB.CONTINUOUS, name=\"max_r_helper\")\n",
    "            model.addGenConstrMax(\n",
    "                max_r_helpers,\n",
    "                [r_vars[i, k] for k in range(K)],\n",
    "                name=f\"MaxRConstraint_{i}\",\n",
    "            )\n",
    "\n",
    "            ### 指定讓當 r_vars 中的值等於 max_r 時，R_vars 設為 1 -> k: 0~7\n",
    "            for k in range(K):\n",
    "                model.addConstr(\n",
    "                    r_vars[i, k] - max_r_helpers >= (R_vars[i, k] - 1),\n",
    "                    \"link_r_R_{}\".format(k),\n",
    "                )\n",
    "                model.addGenConstrIndicator(\n",
    "                    R_vars[i, k], 1, r_vars[i, k] == max_r_helpers\n",
    "                )\n",
    "\n",
    "            ## 只會有一個 R 為 1\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"Ensure_only_one_R_true_{i}\",\n",
    "            )  # 0~7\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "\n",
    "            ### 將 Q_hats(重新估計的值) 與原先 Q0 值進行比較。如果發現原先估計的比較少，則補足 Q_hat_adjusted，如果不用補充，則為 0\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            \"\"\"\n",
    "            計算每一個時間點 k 為界線。Rk = 1 時，代表選到該 k 的 timeline，其他非k則是 R=0。\n",
    "            因此意義上可以理解為，model 2 挑到一個最好的 timeline k 並且將其 R 設為 1, 因此只會計算到該時間線的數值。\n",
    "            \"\"\"\n",
    "            # ### 0~k-1 的需求量\n",
    "            total_demand_up_to_k_minus_1_var = model.addVar(\n",
    "                name=f\"Total_Demand_Up_to_K_Minus_1_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_var\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == total_demand_up_to_k_minus_1_var,\n",
    "                name=f\"Calculate_Total_Demand_Up_to_K_minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            total_demand_from_k_to_T_var = model.addVar(\n",
    "                name=f\"Total_Demand_from_K_to_T_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_var\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i] == total_demand_from_k_to_T_var,\n",
    "                name=f\"Calculate_Total_Demand_from_k_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Sold_0_aux = model.addVar(name=f\"Sold_0_aux_{i}\")\n",
    "            Left_0_aux = model.addVar(name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(name=f\"Lost_0_aux_{i}\")\n",
    "            Sold_1_aux = model.addVar(name=f\"Sold_1_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0_aux,\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "            model.addConstr(Sold_0s[i] == Sold_0_aux, name=f\"Constr_Sold_0_eq_aux_{i}\")\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1_aux,\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "            model.addConstr(Sold_1s[i] == Sold_1_aux, name=f\"Constr_Sold_1_eq_aux_{i}\")\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            assigned_R_var = model.addVar(vtype=GRB.INTEGER, name=f\"assigned_R_{i}\")\n",
    "            model.addConstr(\n",
    "                assigned_R_var == gp.quicksum(k * R_vars[i, k] for k in range(K)),\n",
    "                name=f\"Calc_assigned_R_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Holding_Cost_0\n",
    "            model.addConstr(\n",
    "                Holding_Cost_0s[i]\n",
    "                == ((Q0_vars[i] + Q1_plus_lefts[i]) * (assigned_R_var + 2 - 1) / 2),\n",
    "                name=f\"Constr_Holding_Cost_0_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Holding_Cost_1\n",
    "            model.addConstr(\n",
    "                Holding_Cost_1s[i]\n",
    "                == ((Q1_plus_lefts[i] + Left_1s[i]) * (T - (assigned_R_var + 2)) / 2),\n",
    "                name=f\"Constr_Holding_Cost_1_{i}\",\n",
    "            )\n",
    "\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "                    - holding_cost\n",
    "                    * (Holding_Cost_0s[i] + Holding_Cost_1s[i])  # holding cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train))),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                print(\"===================== 找到最佳解 ==================\")\n",
    "                print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                print(\"Alphas values:\")\n",
    "                for key, alpha in alphas.items():\n",
    "                    print(f\"alpha[{key}]: {alpha.X}\")\n",
    "\n",
    "                print(\"Beta values:\")\n",
    "                for key, beta in betas.items():\n",
    "                    print(f\"beta{key}: {beta.X}\")\n",
    "\n",
    "                alpha_values = np.array([alpha.X for _, alpha in alphas.items()])\n",
    "                beta_values = np.array(\n",
    "                    [[betas[i, j].X for j in range(1)] for i in range(K)]\n",
    "                )\n",
    "                f_values = np.array([f.X for _, f in f_vars.items()])\n",
    "                tau_values = np.array(\n",
    "                    [\n",
    "                        [tau_vars[i, j].X for j in range(K)]\n",
    "                        for i in range(len(demand_df_train))\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                print(f\"------------\")\n",
    "                print(f\"f_values:\\n{f_values}\")\n",
    "                print(f\"tau_values:\\n{tau_values}\")\n",
    "\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                all_holding_costs_0 = []\n",
    "                all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    print(\"----------------------------------------------\")\n",
    "                    print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "                    all_Q0s.append(Q0_vars[i].X)\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    all_Fs.append(F_vars[i].X)\n",
    "                    all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    for k in range(K):\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        print(f\"第 {k+2} 天補貨策略: R_vars = {R_value}\")\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "                    all_Rs.append(reorder_day)\n",
    "\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "                    # print(f\"第一階段需求量: {demand_row[: (reorder_day-1)].sum()}\")\n",
    "                    # print(f\"第二階段需求量: {demand_row[(reorder_day-1): ].sum()}\\n\")\n",
    "\n",
    "                    # print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "                    # print(f\"F_var（重新訂貨量佔總訂貨量比例）: {F_vars[i].X}\")\n",
    "                    # print(f\"Q0_var（期初庫存量）: {Q0_vars[i].X}\\n\")\n",
    "                    # print(f\"Q1_var（二次訂貨量）: {Q1_vars[i].X}\")\n",
    "                    # print(f\"Holding_Cost_0: {Holding_Cost_0}\")\n",
    "                    # print(f\"Holding_Cost_1: {Holding_Cost_1}\\n\")\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    print(check_results_df)\n",
    "\n",
    "                    # for t in range(2):\n",
    "                    #     if t == 0:\n",
    "                    #         print(\n",
    "                    #             f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                    #         )\n",
    "                    #     else:\n",
    "                    #         print(\n",
    "                    #             f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                    #         )\n",
    "\n",
    "                    # print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                print(\"==========================================\")\n",
    "                print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    alpha_values,\n",
    "                    beta_values,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    f_values,\n",
    "                    tau_values,\n",
    "                    all_holding_costs_0,\n",
    "                    all_holding_costs_1,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1511,
   "metadata": {
    "id": "rjpIHSWueRBJ"
   },
   "outputs": [],
   "source": [
    "def fully_flexible_simple_beta_with_softmax_5(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    result = __fully_flexible_simple_beta_with_softmax_5(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "\n",
    "    if result is None:\n",
    "        print(f\"找不到最佳解\")\n",
    "        return None, None\n",
    "    else:\n",
    "        (\n",
    "            all_Rs,\n",
    "            all_losses,\n",
    "            all_lefts,\n",
    "            all_profits,\n",
    "            all_operation_profits,\n",
    "            alpha_values,\n",
    "            beta_values,\n",
    "            all_Fs,\n",
    "            all_Q0s,\n",
    "            all_Q1s,\n",
    "            f_values,\n",
    "            tau_values,\n",
    "            holding_costs_0s,\n",
    "            holding_costs_1s,\n",
    "            all_left0s,\n",
    "            all_left1s,\n",
    "            all_lost0s,\n",
    "            all_lost1s,\n",
    "        ) = result\n",
    "        return make_s3_related_strtegies_result(\n",
    "            all_Rs=all_Rs,\n",
    "            losses=all_losses,\n",
    "            lefts=all_lefts,\n",
    "            profits=all_profits,\n",
    "            operation_profits=all_operation_profits,\n",
    "            alpha_values=alpha_values,\n",
    "            beta_values=beta_values,\n",
    "            F_vars=all_Fs,\n",
    "            Q0_vars=all_Q0s,\n",
    "            Q1_vars=all_Q1s,\n",
    "            f_values=f_values,\n",
    "            tau_values=tau_values,\n",
    "            holding_costs_0s=holding_costs_0s,\n",
    "            holding_costs_1s=holding_costs_1s,\n",
    "            all_left0s=all_left0s,\n",
    "            all_left1s=all_left1s,\n",
    "            all_lost0s=all_lost0s,\n",
    "            all_lost1s=all_lost1s,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8HSaPvrQC6f"
   },
   "source": [
    "### S6 - Simple beta and softmax with T is 1 - sum(T-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1512,
   "metadata": {
    "id": "FJ6F57YQQC6f"
   },
   "outputs": [],
   "source": [
    "def __fully_flexible_simple_beta_with_softmax_6(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        alphas = model.addVars(features_num + 1, lb=-GRB.INFINITY, name=\"alphas\")\n",
    "        betas = model.addVars(\n",
    "            K, 1, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"betas_with_ONLY_intercept\"\n",
    "        )\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "\n",
    "        #### 1-1. 計算兩階段 Sold, Loss, Left 以及總合的 profit\n",
    "        Sold_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_0\")\n",
    "        Left_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_0\")\n",
    "        Lost_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_0\")\n",
    "\n",
    "        Sold_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_1\")\n",
    "        Left_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_1\")\n",
    "        Lost_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_1\")\n",
    "        Holding_Cost_0s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_0\"\n",
    "        )\n",
    "\n",
    "        Holding_Cost_1s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_1\"\n",
    "        )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, name=\"profits_vars\"\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, name=\"Total_Demand_from_k_to_T\"\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        f_vars = model.addVars(len(demand_df_train), lb=-GRB.INFINITY, name=\"f_var\")\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=1, name=\"Fraction_for_second_order_amount\"\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=(Q_star + 1), name=\"Q0_var\"\n",
    "        )\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        r_vars = model.addVars(len(demand_df_train), K, lb=0.0, ub=1.0, name=\"r\")\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(len(Qk_hat_df), lb=0.0, name=\"Q1_var\")\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            # lb=0.0,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df), lb=-GRB.INFINITY, name=f\"Q_hat_adjusted\"\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, row in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            ### 用線性回歸計算F_var\n",
    "            model.addConstr(\n",
    "                f_vars[i]\n",
    "                == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            )\n",
    "            model.addGenConstrLogistic(\n",
    "                xvar=f_vars[i], yvar=F_vars[i], name=f\"logistic_constraint_{i}\"\n",
    "            )\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "            # 用線性回歸計算確定最佳補貨時間\n",
    "            exp_tau_vars = []\n",
    "            for p in range(K - 1):  # 一直到前一個\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, p] == betas[p, 0], name=f\"tau_computation_{i}_{p}\"\n",
    "                )  # 只使用截距項\n",
    "\n",
    "                # 定義指數變數\n",
    "                exp_tau_var = model.addVar(lb=0, name=f\"exp_tau_var_{i}_{p}\")\n",
    "                neg_tau_var = model.addVar(\n",
    "                    lb=-GRB.INFINITY, ub=0, name=f\"neg_tau_var_{i}_{p}\"\n",
    "                )\n",
    "                model.addConstr(\n",
    "                    neg_tau_var == -tau_vars[i, p], name=f\"neg_tau_constr_{i}_{p}\"\n",
    "                )\n",
    "                model.addGenConstrExp(xvar=neg_tau_var, yvar=exp_tau_var)\n",
    "                exp_tau_vars.append(exp_tau_var)\n",
    "\n",
    "            sum_exp_tau_vars = model.addVar(lb=0, name=f\"sum_exp_tau_vars_{i}\")\n",
    "            model.addConstr(\n",
    "                sum_exp_tau_vars == gp.quicksum(exp_tau_vars),\n",
    "                name=f\"sum_exp_tau_vars_computation_{i}\",\n",
    "            )\n",
    "\n",
    "            # 將 r_vars 的最後一個變量設為 1，其他變量根據 softmax 計算\n",
    "            for p in range(K):\n",
    "                if p == K - 1:  # 最後一個是特別處理\n",
    "                    r_sum_without_last = gp.quicksum(r_vars[i, p] for p in range(K - 1))\n",
    "                    model.addConstr(\n",
    "                        r_vars[i, p] == 1 - r_sum_without_last,\n",
    "                        name=f\"r_var_fixed_{i}_{p}\",\n",
    "                    )\n",
    "                else:\n",
    "                    model.addConstr(\n",
    "                        r_vars[i, p] * (sum_exp_tau_vars + 1) == exp_tau_vars[p],\n",
    "                        name=f\"softmax_{i}_{p}\",\n",
    "                    )\n",
    "\n",
    "            ### 找到最大 R 以及 r, R 的相關限制式 -> k: 0~7\n",
    "            max_r_helpers = model.addVar(lb=0.0, ub=1.0, name=\"max_r_helper\")\n",
    "            model.addGenConstrMax(\n",
    "                max_r_helpers,\n",
    "                [r_vars[i, k] for k in range(K)],\n",
    "                name=f\"MaxRConstraint_{i}\",\n",
    "            )\n",
    "\n",
    "            ### 指定讓當 r_vars 中的值等於 max_r 時，R_vars 設為 1 -> k: 0~7\n",
    "            eps = 1e-10\n",
    "            for k in range(K):\n",
    "                model.addGenConstrIndicator(\n",
    "                    R_vars[i, k], 1, r_vars[i, k] >= max_r_helpers - eps\n",
    "                )\n",
    "\n",
    "            ## 只會有一個 R 為 1\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"Ensure_only_one_R_true_{i}\",\n",
    "            )\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            \"\"\"\n",
    "            計算每一個時間點 k 為界線。Rk = 1 時，代表選到該 k 的 timeline，其他非k則是 R=0。\n",
    "            因此意義上可以理解為，model 2 挑到一個最好的 timeline k 並且將其 R 設為 1, 因此只會計算到該時間線的數值。\n",
    "            \"\"\"\n",
    "            # ### 0~k-1 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Left_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0s[i],\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1s[i],\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # assigned_R_var = model.addVar(vtype=GRB.INTEGER, name=f\"assigned_R_{i}\")\n",
    "            # model.addConstr(\n",
    "            #     assigned_R_var == gp.quicksum(k * R_vars[i, k] for k in range(K)),\n",
    "            #     name=f\"Calc_assigned_R_{i}\",\n",
    "            # )\n",
    "\n",
    "            # # 計算 Holding_Cost_0\n",
    "            # model.addConstr(\n",
    "            #     Holding_Cost_0s[i]\n",
    "            #     == ((Q0_vars[i] + Q1_plus_lefts[i]) * (assigned_R_var + 2 - 1) / 2),\n",
    "            #     name=f\"Constr_Holding_Cost_0_{i}\",\n",
    "            # )\n",
    "\n",
    "            # # 計算 Holding_Cost_1\n",
    "            # model.addConstr(\n",
    "            #     Holding_Cost_1s[i]\n",
    "            #     == ((Q1_plus_lefts[i] + Left_1s[i]) * (T - (assigned_R_var + 2)) / 2),\n",
    "            #     name=f\"Constr_Holding_Cost_1_{i}\",\n",
    "            # )\n",
    "\n",
    "            # model.addConstr(\n",
    "            #     profits_vars[i]\n",
    "            #     == (\n",
    "            #         (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "            #         - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "            #         - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "            #         # - holding_cost\n",
    "            #         # * (Holding_Cost_0s[i] + Holding_Cost_1s[i])  # holding cost\n",
    "            #     ),\n",
    "            #     name=f\"Profit_Constraint_{i}\",\n",
    "            # )\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train))),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "\n",
    "        model.write(\"s6_model_debug.lp\")\n",
    "        model.write(\"s6_model.mps\")\n",
    "\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                print(\"===================== 找到最佳解 ==================\")\n",
    "                print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                print(\"Alphas values:\")\n",
    "                for key, alpha in alphas.items():\n",
    "                    print(f\"alpha[{key}]: {alpha.X}\")\n",
    "\n",
    "                print(\"Beta values:\")\n",
    "                for key, beta in betas.items():\n",
    "                    print(f\"beta{key}: {beta.X}\")\n",
    "\n",
    "                alpha_values = np.array([alpha.X for _, alpha in alphas.items()])\n",
    "                beta_values = np.array(\n",
    "                    [[betas[k, j].X for j in range(features_num + 1)] for k in range(K)]\n",
    "                )\n",
    "                print(f\"beta_values:\\n{beta_values}\")\n",
    "\n",
    "                f_values = np.array([f.X for _, f in f_vars.items()])\n",
    "                tau_values = np.array(\n",
    "                    [\n",
    "                        [tau_vars[i, j].X for j in range(K)]\n",
    "                        for i in range(len(demand_df_train))\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                print(f\"------------\")\n",
    "                print(f\"f_values:\\n{f_values}\")\n",
    "                print(f\"tau_values:\\n{tau_values}\")\n",
    "\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                all_rs = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                all_holding_costs_0 = []\n",
    "                all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    print(\"----------------------------------------------\")\n",
    "                    print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "                    all_Q0s.append(Q0_vars[i].X)\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    all_Fs.append(F_vars[i].X)\n",
    "                    all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    rs = []\n",
    "                    for k in range(K):\n",
    "                        rs.append(r_vars[i, k].X)\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        print(\n",
    "                            f\"第 {k+2} 天補貨策略: R_vars = {R_value}, r_vars = {rs[k]}\"\n",
    "                        )\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "\n",
    "                    all_Rs.append(reorder_day)\n",
    "                    all_rs.append(rs)\n",
    "\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    print(check_results_df)\n",
    "\n",
    "                    for t in range(2):\n",
    "                        if t == 0:\n",
    "                            print(\n",
    "                                f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                            )\n",
    "                        else:\n",
    "                            print(\n",
    "                                f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                            )\n",
    "\n",
    "                    print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                print(\"==========================================\")\n",
    "                print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    alpha_values,\n",
    "                    beta_values,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    f_values,\n",
    "                    tau_values,\n",
    "                    all_holding_costs_0,\n",
    "                    all_holding_costs_1,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1513,
   "metadata": {
    "id": "iAQkhleJepdr"
   },
   "outputs": [],
   "source": [
    "def fully_flexible_simple_beta_with_softmax_6(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    result = __fully_flexible_simple_beta_with_softmax_6(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "\n",
    "    if result is None:\n",
    "        print(f\"找不到最佳解\")\n",
    "        return None, None\n",
    "    else:\n",
    "        (\n",
    "            all_Rs,\n",
    "            all_losses,\n",
    "            all_lefts,\n",
    "            all_profits,\n",
    "            all_operation_profits,\n",
    "            alpha_values,\n",
    "            beta_values,\n",
    "            all_Fs,\n",
    "            all_Q0s,\n",
    "            all_Q1s,\n",
    "            f_values,\n",
    "            tau_values,\n",
    "            holding_costs_0s,\n",
    "            holding_costs_1s,\n",
    "            all_left0s,\n",
    "            all_left1s,\n",
    "            all_lost0s,\n",
    "            all_lost1s,\n",
    "        ) = result\n",
    "        return make_s3_related_strtegies_result(\n",
    "            all_Rs=all_Rs,\n",
    "            losses=all_losses,\n",
    "            lefts=all_lefts,\n",
    "            profits=all_profits,\n",
    "            operation_profits=all_operation_profits,\n",
    "            alpha_values=alpha_values,\n",
    "            beta_values=beta_values,\n",
    "            F_vars=all_Fs,\n",
    "            Q0_vars=all_Q0s,\n",
    "            Q1_vars=all_Q1s,\n",
    "            f_values=f_values,\n",
    "            tau_values=tau_values,\n",
    "            holding_costs_0s=holding_costs_0s,\n",
    "            holding_costs_1s=holding_costs_1s,\n",
    "            all_left0s=all_left0s,\n",
    "            all_left1s=all_left1s,\n",
    "            all_lost0s=all_lost0s,\n",
    "            all_lost1s=all_lost1s,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMeeInmeQC6g"
   },
   "source": [
    "### S7 - Simple beat and softmax with T is 1 - sum(T-1) & tau with f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1514,
   "metadata": {
    "id": "fCSTKTWSQC6g"
   },
   "outputs": [],
   "source": [
    "def __fully_flexible_simple_beta_with_softmax_7(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        alphas = model.addVars(\n",
    "            features_num + 1, name=\"alphas\"\n",
    "        )  # alpha coefficients with intercept\n",
    "        betas = model.addVars(\n",
    "            K, 1, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"betas_with_ONLY_intercept\"\n",
    "        )  # Beta coefficients with ONLY intercept\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "        Sold_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Sold_0\",\n",
    "        )\n",
    "        Left_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Left_0\",\n",
    "        )\n",
    "        Lost_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Lost_0\",\n",
    "        )\n",
    "\n",
    "        Sold_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Sold_1\",\n",
    "        )\n",
    "        Left_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Left_1\",\n",
    "        )\n",
    "        Lost_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Lost_1\",\n",
    "        )\n",
    "\n",
    "        Holding_Cost_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Holding_Cost_0\",\n",
    "        )\n",
    "\n",
    "        Holding_Cost_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Holding_Cost_1\",\n",
    "        )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=-GRB.INFINITY,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"profits_vars\",\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Total_Demand_from_k_to_T\",\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        f_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=-GRB.INFINITY,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"f_var\",\n",
    "        )\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=1,\n",
    "            name=\"Fraction_for_second_order_amount\",\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), vtype=GRB.CONTINUOUS, lb=0, ub=Q_star, name=\"Q0_var\"\n",
    "        )\n",
    "\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        tau_vars = model.addVars(\n",
    "            len(demand_df_train), K, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"tau\"\n",
    "        )  # Tau變量\n",
    "        r_vars = model.addVars(\n",
    "            len(demand_df_train), K, vtype=GRB.CONTINUOUS, lb=0.0, ub=1.0, name=\"r\"\n",
    "        )  # but t-1 is different from others\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=demand_df_train.max().max(),\n",
    "            name=\"Q1_var\",\n",
    "        )  # Every stimulation will have there own Q1 vars.\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=(-demand_df_train.max().max() * 100),\n",
    "            ub=demand_df_train.max().max() * 100,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=(-demand_df_train.max().max() * 100),\n",
    "            ub=demand_df_train.max().max() * 100,\n",
    "            name=f\"Q_hat_adjusted\",\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, row in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            ### 用線性回歸計算F_var\n",
    "            model.addConstr(\n",
    "                f_vars[i]\n",
    "                == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            )\n",
    "            model.addGenConstrLogistic(\n",
    "                xvar=f_vars[i], yvar=F_vars[i], name=f\"logistic_constraint_{i}\"\n",
    "            )\n",
    "\n",
    "            ### Q0_var = F_vars * Q_star\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "            # 用線性回歸計算確定最佳補貨時間\n",
    "            exp_tau_vars = []\n",
    "            for p in range(K - 1):  # 一直到前一個\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, p] == betas[p, 0] + f_vars[i],\n",
    "                    name=f\"tau_computation_{i}_{p}\",\n",
    "                )  # 只使用截距項\n",
    "                exp_tau_var = model.addVar(\n",
    "                    vtype=GRB.CONTINUOUS, name=f\"exp_tau_var_{i}_{p}\"\n",
    "                )\n",
    "\n",
    "                neg_tau_var = model.addVar(\n",
    "                    vtype=GRB.CONTINUOUS, name=f\"neg_tau_var_{i}_{p}\"\n",
    "                )\n",
    "                model.addConstr(\n",
    "                    neg_tau_var == -tau_vars[i, p], name=f\"neg_tau_constr_{i}_{p}\"\n",
    "                )\n",
    "                model.addGenConstrExp(xvar=neg_tau_var, yvar=exp_tau_var)\n",
    "\n",
    "                exp_tau_vars.append(exp_tau_var)\n",
    "\n",
    "            sum_exp_tau_vars = model.addVar(\n",
    "                vtype=GRB.CONTINUOUS, name=f\"sum_exp_tau_vars_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                sum_exp_tau_vars == gp.quicksum(exp_tau_vars),\n",
    "                name=f\"sum_exp_tau_vars_computation_{i}\",\n",
    "            )\n",
    "\n",
    "            # 將 r_vars 的最後一個變量設為 1，其他變量根據 softmax 計算\n",
    "            for p in range(K):\n",
    "                if p == K - 1:  # 最後一個是特別處理\n",
    "                    r_sum_without_last = gp.quicksum(r_vars[i, p] for p in range(K - 1))\n",
    "                    model.addConstr(\n",
    "                        r_vars[i, p] == 1 - r_sum_without_last,\n",
    "                        name=f\"r_var_fixed_{i}_{p}\",\n",
    "                    )\n",
    "                else:\n",
    "                    model.addConstr(\n",
    "                        r_vars[i, p] * (sum_exp_tau_vars + 1) == exp_tau_vars[p],\n",
    "                        name=f\"softmax_{i}_{p}\",\n",
    "                    )\n",
    "\n",
    "            ### 找到最大 R 以及 r, R 的相關限制式 -> k: 0~7\n",
    "            max_r_helpers = model.addVar(vtype=GRB.CONTINUOUS, name=\"max_r_helper\")\n",
    "            model.addGenConstrMax(\n",
    "                max_r_helpers,\n",
    "                [r_vars[i, k] for k in range(K)],\n",
    "                name=f\"MaxRConstraint_{i}\",\n",
    "            )\n",
    "\n",
    "            ### 指定讓當 r_vars 中的值等於 max_r 時，R_vars 設為 1 -> k: 0~7\n",
    "            for k in range(K):\n",
    "                model.addConstr(\n",
    "                    r_vars[i, k] - max_r_helpers >= (R_vars[i, k] - 1),\n",
    "                    \"link_r_R_{}\".format(k),\n",
    "                )\n",
    "                model.addGenConstrIndicator(\n",
    "                    R_vars[i, k], 1, r_vars[i, k] == max_r_helpers\n",
    "                )\n",
    "\n",
    "            ## 只會有一個 R 為 1\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"Ensure_only_one_R_true_{i}\",\n",
    "            )  # 0~7\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "\n",
    "            ### 將 Q_hats(重新估計的值) 與原先 Q0 值進行比較。如果發現原先估計的比較少，則補足 Q_hat_adjusted，如果不用補充，則為 0\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            # ### 0~k-1 的需求量\n",
    "            total_demand_up_to_k_minus_1_var = model.addVar(\n",
    "                name=f\"Total_Demand_Up_to_K_Minus_1_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_var\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == total_demand_up_to_k_minus_1_var,\n",
    "                name=f\"Calculate_Total_Demand_Up_to_K_minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            total_demand_from_k_to_T_var = model.addVar(\n",
    "                name=f\"Total_Demand_from_K_to_T_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_var\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i] == total_demand_from_k_to_T_var,\n",
    "                name=f\"Calculate_Total_Demand_from_k_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Sold_0_aux = model.addVar(name=f\"Sold_0_aux_{i}\")\n",
    "            Left_0_aux = model.addVar(name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(name=f\"Lost_0_aux_{i}\")\n",
    "            Sold_1_aux = model.addVar(name=f\"Sold_1_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0_aux,\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "            model.addConstr(Sold_0s[i] == Sold_0_aux, name=f\"Constr_Sold_0_eq_aux_{i}\")\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1_aux,\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "            model.addConstr(Sold_1s[i] == Sold_1_aux, name=f\"Constr_Sold_1_eq_aux_{i}\")\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            assigned_R_var = model.addVar(vtype=GRB.INTEGER, name=f\"assigned_R_{i}\")\n",
    "            model.addConstr(\n",
    "                assigned_R_var == gp.quicksum(k * R_vars[i, k] for k in range(K)),\n",
    "                name=f\"Calc_assigned_R_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Holding_Cost_0\n",
    "            model.addConstr(\n",
    "                Holding_Cost_0s[i]\n",
    "                == ((Q0_vars[i] + Q1_plus_lefts[i]) * (assigned_R_var + 2 - 1) / 2),\n",
    "                name=f\"Constr_Holding_Cost_0_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Holding_Cost_1\n",
    "            model.addConstr(\n",
    "                Holding_Cost_1s[i]\n",
    "                == ((Q1_plus_lefts[i] + Left_1s[i]) * (T - (assigned_R_var + 2)) / 2),\n",
    "                name=f\"Constr_Holding_Cost_1_{i}\",\n",
    "            )\n",
    "\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "                    - holding_cost\n",
    "                    * (Holding_Cost_0s[i] + Holding_Cost_1s[i])  # holding cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train))),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                print(\"===================== 找到最佳解 ==================\")\n",
    "                print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                print(\"Alphas values:\")\n",
    "                for key, alpha in alphas.items():\n",
    "                    print(f\"alpha[{key}]: {alpha.X}\")\n",
    "\n",
    "                print(\"Beta values:\")\n",
    "                for key, beta in betas.items():\n",
    "                    print(f\"beta{key}: {beta.X}\")\n",
    "\n",
    "                alpha_values = np.array([alpha.X for _, alpha in alphas.items()])\n",
    "                beta_values = np.array(\n",
    "                    [[betas[i, j].X for j in range(1)] for i in range(K)]\n",
    "                )\n",
    "                f_values = np.array([f.X for _, f in f_vars.items()])\n",
    "                tau_values = np.array(\n",
    "                    [\n",
    "                        [tau_vars[i, j].X for j in range(K)]\n",
    "                        for i in range(len(demand_df_train))\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                print(f\"------------\")\n",
    "                print(f\"f_values:\\n{f_values}\")\n",
    "                print(f\"tau_values:\\n{tau_values}\")\n",
    "\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                all_holding_costs_0 = []\n",
    "                all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    print(\"----------------------------------------------\")\n",
    "                    print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "                    all_Q0s.append(Q0_vars[i].X)\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    all_Fs.append(F_vars[i].X)\n",
    "                    all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    for k in range(K):\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        print(f\"第 {k+2} 天補貨策略: R_vars = {R_value}\")\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "                    all_Rs.append(reorder_day)\n",
    "\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "                    # print(f\"第一階段需求量: {demand_row[: (reorder_day-1)].sum()}\")\n",
    "                    # print(f\"第二階段需求量: {demand_row[(reorder_day-1): ].sum()}\\n\")\n",
    "\n",
    "                    # print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "                    # print(f\"F_var（重新訂貨量佔總訂貨量比例）: {F_vars[i].X}\")\n",
    "                    # print(f\"Q0_var（期初庫存量）: {Q0_vars[i].X}\\n\")\n",
    "                    # print(f\"Q1_var（二次訂貨量）: {Q1_vars[i].X}\")\n",
    "                    # print(f\"Holding_Cost_0: {Holding_Cost_0}\")\n",
    "                    # print(f\"Holding_Cost_1: {Holding_Cost_1}\\n\")\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    print(check_results_df)\n",
    "\n",
    "                    # for t in range(2):\n",
    "                    #     if t == 0:\n",
    "                    #         print(\n",
    "                    #             f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                    #         )\n",
    "                    #     else:\n",
    "                    #         print(\n",
    "                    #             f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                    #         )\n",
    "\n",
    "                    # print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                print(\"==========================================\")\n",
    "                print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    alpha_values,\n",
    "                    beta_values,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    f_values,\n",
    "                    tau_values,\n",
    "                    all_holding_costs_0,\n",
    "                    all_holding_costs_1,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1515,
   "metadata": {
    "id": "m0dwZyvzcL4m"
   },
   "outputs": [],
   "source": [
    "def fully_flexible_simple_beta_with_softmax_7(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "    result = __fully_flexible_simple_beta_with_softmax_7(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "\n",
    "    if result is None:\n",
    "        print(f\"找不到最佳解\")\n",
    "        return None, None\n",
    "    else:\n",
    "        (\n",
    "            all_Rs,\n",
    "            all_losses,\n",
    "            all_lefts,\n",
    "            all_profits,\n",
    "            all_operation_profits,\n",
    "            alpha_values,\n",
    "            beta_values,\n",
    "            all_Fs,\n",
    "            all_Q0s,\n",
    "            all_Q1s,\n",
    "            f_values,\n",
    "            tau_values,\n",
    "            holding_costs_0s,\n",
    "            holding_costs_1s,\n",
    "            all_left0s,\n",
    "            all_left1s,\n",
    "            all_lost0s,\n",
    "            all_lost1s,\n",
    "        ) = result\n",
    "        return make_s3_related_strtegies_result(\n",
    "            all_Rs=all_Rs,\n",
    "            losses=all_losses,\n",
    "            lefts=all_lefts,\n",
    "            profits=all_profits,\n",
    "            operation_profits=all_operation_profits,\n",
    "            alpha_values=alpha_values,\n",
    "            beta_values=beta_values,\n",
    "            F_vars=all_Fs,\n",
    "            Q0_vars=all_Q0s,\n",
    "            Q1_vars=all_Q1s,\n",
    "            f_values=f_values,\n",
    "            tau_values=tau_values,\n",
    "            holding_costs_0s=holding_costs_0s,\n",
    "            holding_costs_1s=holding_costs_1s,\n",
    "            all_left0s=all_left0s,\n",
    "            all_left1s=all_left1s,\n",
    "            all_lost0s=all_lost0s,\n",
    "            all_lost1s=all_lost1s,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgQovzuG41d_"
   },
   "source": [
    "### S4 - Beta with softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1516,
   "metadata": {
    "id": "tVy2xESR44dH"
   },
   "outputs": [],
   "source": [
    "def __fully_flexible_beta_with_softmax_4(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "        model.setParam(\"IntFeasTol\", 1e-9)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        alphas = model.addVars(features_num + 1, lb=-GRB.INFINITY, name=\"alphas\")\n",
    "        betas = model.addVars(K, features_num + 1, lb=-GRB.INFINITY, name=\"betas\")\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "        Sold_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_0\")\n",
    "        Left_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_0\")\n",
    "        Lost_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_0\")\n",
    "\n",
    "        Sold_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_1\")\n",
    "        Left_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_1\")\n",
    "        Lost_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_1\")\n",
    "\n",
    "        Holding_Cost_0s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_0\"\n",
    "        )\n",
    "\n",
    "        Holding_Cost_1s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_1\"\n",
    "        )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, name=\"profits_vars\"\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, name=\"Total_Demand_from_k_to_T\"\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        f_vars = model.addVars(len(demand_df_train), lb=-GRB.INFINITY, name=\"f_var\")\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=1, name=\"Fraction_for_second_order_amount\"\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=(Q_star + 1), name=\"Q0_var\"\n",
    "        )\n",
    "\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        # tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        r_vars = model.addVars(len(demand_df_train), K, lb=0.0, ub=1.0, name=\"r\")\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(len(Qk_hat_df), lb=0.0, name=\"Q1_var\")\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            lb=0.0,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df), lb=-GRB.INFINITY, name=f\"Q_hat_adjusted\"\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, _ in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            ### 用線性回歸計算F_var\n",
    "            model.addConstr(\n",
    "                f_vars[i]\n",
    "                == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            )\n",
    "            model.addGenConstrLogistic(\n",
    "                xvar=f_vars[i], yvar=F_vars[i], name=f\"logistic_constraint_{i}\"\n",
    "            )\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "            # 用線性回歸計算確定最佳補貨時間\n",
    "            exp_tau_vars = []\n",
    "            for k in range(K):\n",
    "\n",
    "                # 計算 tau_vars 作為 beta 和特徵的線性組合\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, k]\n",
    "                    == gp.quicksum(\n",
    "                        X_data[j] * betas[k, j] for j in range(features_num + 1)\n",
    "                    ),\n",
    "                    name=f\"tau_computation_{i}_{k}\",\n",
    "                )\n",
    "                # model.addConstr(tau_vars[i, k] >= -5, name=f\"tau_lb_{i}_{k}\")\n",
    "\n",
    "                exp_tau_var = model.addVar(lb=1e-6, name=f\"exp_tau_var_{i}_{k}\")\n",
    "                exp_tau_var = model.addVar(\n",
    "                    lb=-GRB.INFINITY, name=f\"exp_tau_var_{i}_{k}\"\n",
    "                )\n",
    "                model.addGenConstrExp(xvar=tau_vars[i, k], yvar=exp_tau_var)\n",
    "                exp_tau_vars.append(exp_tau_var)\n",
    "\n",
    "            ### 找到最大 R 以及 r, R 的相關限制式 -> k: 0~7\n",
    "            for k in range(K):\n",
    "                model.addConstr(\n",
    "                    r_vars[i, k] * gp.quicksum(exp_tau_vars) == exp_tau_vars[k],\n",
    "                    name=f\"softmax_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "            model.addConstr(\n",
    "                gp.quicksum(r_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"sum_r_{i}\",\n",
    "            )\n",
    "\n",
    "            max_r_helpers = model.addVar(lb=0.0, ub=1.0, name=\"max_r_helper\")\n",
    "            model.addGenConstrMax(\n",
    "                max_r_helpers,\n",
    "                [r_vars[i, k] for k in range(K)],\n",
    "                name=f\"MaxRConstraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # 確保 R_vars 的邏輯行為\n",
    "            for k in range(K):\n",
    "                model.addGenConstrIndicator(\n",
    "                    R_vars[i, k], True, r_vars[i, k] == max_r_helpers\n",
    "                )\n",
    "\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"Ensure_only_one_R_true_{i}\",\n",
    "            )\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            # ### 0~k-1 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Left_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0s[i],\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1s[i],\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train))),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "        model.write(\"s4_model_debug.lp\")\n",
    "        model.write(\"s4_model.mps\")\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                print(\"===================== 找到最佳解 ==================\")\n",
    "                print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                print(\"Alphas values:\")\n",
    "                for key, alpha in alphas.items():\n",
    "                    print(f\"alpha[{key}]: {alpha.X}\")\n",
    "\n",
    "                alpha_values = np.array([alpha.X for _, alpha in alphas.items()])\n",
    "                beta_values = np.array(\n",
    "                    [[betas[k, j].X for j in range(features_num + 1)] for k in range(K)]\n",
    "                )\n",
    "                print(f\"beta_values:\\n{beta_values}\")\n",
    "\n",
    "                f_values = np.array([f.X for _, f in f_vars.items()])\n",
    "                tau_values = np.array(\n",
    "                    [\n",
    "                        [tau_vars[i, j].X for j in range(K)]\n",
    "                        for i in range(len(demand_df_train))\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                print(f\"------------\")\n",
    "                print(f\"f_values:\\n{f_values}\")\n",
    "                print(f\"tau_values:\\n{tau_values}\")\n",
    "\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                all_rs = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                all_holding_costs_0 = []\n",
    "                all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    print(\"----------------------------------------------\")\n",
    "                    print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "                    all_Q0s.append(Q0_vars[i].X)\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    all_Fs.append(F_vars[i].X)\n",
    "                    all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    rs = []\n",
    "                    for k in range(K):\n",
    "                        rs.append(r_vars[i, k].X)\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        print(\n",
    "                            f\"第 {k+2} 天補貨策略: R_vars = {R_value}, r_vars = {rs[k]}\"\n",
    "                        )\n",
    "                        # print(\n",
    "                        #     f\"第 {k+2} 天補貨策略: R_vars = {R_value}, tau_vars = {tau_vars[i, k].X}\"\n",
    "                        # )\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "\n",
    "                    all_Rs.append(reorder_day)\n",
    "                    all_rs.append(rs)\n",
    "\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    print(check_results_df)\n",
    "\n",
    "                    for t in range(2):\n",
    "                        if t == 0:\n",
    "                            print(\n",
    "                                f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                            )\n",
    "                        else:\n",
    "                            print(\n",
    "                                f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                            )\n",
    "\n",
    "                    print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                print(\"==========================================\")\n",
    "                print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    alpha_values,\n",
    "                    beta_values,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    f_values,\n",
    "                    tau_values,\n",
    "                    all_holding_costs_0,\n",
    "                    all_holding_costs_1,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1517,
   "metadata": {
    "id": "tSxMyuGNeyyb"
   },
   "outputs": [],
   "source": [
    "def fully_flexible_beta_with_softmax_4(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    result = __fully_flexible_beta_with_softmax_4(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "    if result is None:\n",
    "        print(f\"找不到最佳解\")\n",
    "        return None, None\n",
    "    else:\n",
    "        (\n",
    "            all_Rs,\n",
    "            all_losses,\n",
    "            all_lefts,\n",
    "            all_profits,\n",
    "            all_operation_profits,\n",
    "            alpha_values,\n",
    "            beta_values,\n",
    "            all_Fs,\n",
    "            all_Q0s,\n",
    "            all_Q1s,\n",
    "            f_values,\n",
    "            tau_values,\n",
    "            holding_costs_0s,\n",
    "            holding_costs_1s,\n",
    "            all_left0s,\n",
    "            all_left1s,\n",
    "            all_lost0s,\n",
    "            all_lost1s,\n",
    "        ) = result\n",
    "\n",
    "        print(f\"all_Rs: {all_Rs}\")\n",
    "\n",
    "        return make_s3_related_strtegies_result(\n",
    "            all_Rs=all_Rs,\n",
    "            losses=all_losses,\n",
    "            lefts=all_lefts,\n",
    "            profits=all_profits,\n",
    "            operation_profits=all_operation_profits,\n",
    "            alpha_values=alpha_values,\n",
    "            beta_values=beta_values,\n",
    "            F_vars=all_Fs,\n",
    "            Q0_vars=all_Q0s,\n",
    "            Q1_vars=all_Q1s,\n",
    "            f_values=f_values,\n",
    "            tau_values=tau_values,\n",
    "            holding_costs_0s=holding_costs_0s,\n",
    "            holding_costs_1s=holding_costs_1s,\n",
    "            all_left0s=all_left0s,\n",
    "            all_left1s=all_left1s,\n",
    "            all_lost0s=all_lost0s,\n",
    "            all_lost1s=all_lost1s,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S9 - Without beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1518,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __fully_flexible_beta_with_softmax_9(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "        model.setParam(\"IntFeasTol\", 1e-9)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        alphas = model.addVars(features_num + 1, lb=-GRB.INFINITY, name=\"alphas\")\n",
    "        # betas = model.addVars(K, features_num + 1, lb=-GRB.INFINITY, name=\"betas\")\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "        Sold_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_0\")\n",
    "        Left_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_0\")\n",
    "        Lost_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_0\")\n",
    "\n",
    "        Sold_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_1\")\n",
    "        Left_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_1\")\n",
    "        Lost_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_1\")\n",
    "\n",
    "        Holding_Cost_0s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_0\"\n",
    "        )\n",
    "\n",
    "        Holding_Cost_1s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_1\"\n",
    "        )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, name=\"profits_vars\"\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, name=\"Total_Demand_from_k_to_T\"\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        f_vars = model.addVars(len(demand_df_train), lb=-GRB.INFINITY, name=\"f_var\")\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=1, name=\"Fraction_for_second_order_amount\"\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=(Q_star + 1), name=\"Q0_var\"\n",
    "        )\n",
    "\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        # tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        # r_vars = model.addVars(len(demand_df_train), K, lb=0.0, ub=1.0, name=\"r\")\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(len(Qk_hat_df), lb=0.0, name=\"Q1_var\")\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            lb=0.0,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df), lb=-GRB.INFINITY, name=f\"Q_hat_adjusted\"\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, _ in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            ### 用線性回歸計算F_var\n",
    "            model.addConstr(\n",
    "                f_vars[i]\n",
    "                == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            )\n",
    "            model.addGenConstrLogistic(\n",
    "                xvar=f_vars[i], yvar=F_vars[i], name=f\"logistic_constraint_{i}\"\n",
    "            )\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"Ensure_only_one_R_true_{i}\",\n",
    "            )\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            # ### 0~k-1 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Left_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0s[i],\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1s[i],\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train))),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "        model.write(\"s4_model_debug.lp\")\n",
    "        model.write(\"s4_model.mps\")\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                print(\"===================== 找到最佳解 ==================\")\n",
    "                print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                print(\"Alphas values:\")\n",
    "                for key, alpha in alphas.items():\n",
    "                    print(f\"alpha[{key}]: {alpha.X}\")\n",
    "\n",
    "                # print(\"Beta values:\")\n",
    "                # for key, beta in betas.items():\n",
    "                #     print(f\"beta{key}: {beta.X}\")\n",
    "\n",
    "                alpha_values = np.array([alpha.X for _, alpha in alphas.items()])\n",
    "                # beta_values = np.array(\n",
    "                #     [[betas[k, j].X for j in range(features_num + 1)] for k in range(K)]\n",
    "                # )\n",
    "                # print(f\"beta_values:\\n{beta_values}\")\n",
    "\n",
    "                f_values = np.array([f.X for _, f in f_vars.items()])\n",
    "                # tau_values = np.array(\n",
    "                #     [\n",
    "                #         [tau_vars[i, j].X for j in range(K)]\n",
    "                #         for i in range(len(demand_df_train))\n",
    "                #     ]\n",
    "                # )\n",
    "\n",
    "                print(f\"------------\")\n",
    "                print(f\"f_values:\\n{f_values}\")\n",
    "                # print(f\"tau_values:\\n{tau_values}\")\n",
    "\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                # all_rs = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                all_holding_costs_0 = []\n",
    "                all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    # print(\"----------------------------------------------\")\n",
    "                    # print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "                    all_Q0s.append(Q0_vars[i].X)\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    all_Fs.append(F_vars[i].X)\n",
    "                    all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    rs = []\n",
    "                    for k in range(K):\n",
    "                        # rs.append(r_vars[i, k].X)\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        # print(\n",
    "                        #     f\"第 {k+2} 天補貨策略: R_vars = {R_value}, r_vars = {rs[k]}\"\n",
    "                        # )\n",
    "                        # print(f\"第 {k+2} 天補貨策略: R_vars = {R_value}\")\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    # print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "\n",
    "                    all_Rs.append(reorder_day)\n",
    "                    # all_rs.append(rs)\n",
    "\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    print(check_results_df)\n",
    "\n",
    "                #     for t in range(2):\n",
    "                #         if t == 0:\n",
    "                #             print(\n",
    "                #                 f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                #             )\n",
    "                #         else:\n",
    "                #             print(\n",
    "                #                 f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                #             )\n",
    "\n",
    "                #     print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                # print(\"==========================================\")\n",
    "                # print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    alpha_values,\n",
    "                    None,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    f_values,\n",
    "                    None,\n",
    "                    all_holding_costs_0,\n",
    "                    all_holding_costs_1,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1519,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_flexible_beta_with_softmax_9(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    result = __fully_flexible_beta_with_softmax_9(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "    if result is None:\n",
    "        print(f\"找不到最佳解\")\n",
    "        return None, None\n",
    "    else:\n",
    "        (\n",
    "            all_Rs,\n",
    "            all_losses,\n",
    "            all_lefts,\n",
    "            all_profits,\n",
    "            all_operation_profits,\n",
    "            alpha_values,\n",
    "            beta_values,\n",
    "            all_Fs,\n",
    "            all_Q0s,\n",
    "            all_Q1s,\n",
    "            f_values,\n",
    "            tau_values,\n",
    "            holding_costs_0s,\n",
    "            holding_costs_1s,\n",
    "            all_left0s,\n",
    "            all_left1s,\n",
    "            all_lost0s,\n",
    "            all_lost1s,\n",
    "        ) = result\n",
    "\n",
    "        print(f\"all_Rs: {all_Rs}\")\n",
    "\n",
    "        return make_s3_related_strtegies_result(\n",
    "            all_Rs=all_Rs,\n",
    "            losses=all_losses,\n",
    "            lefts=all_lefts,\n",
    "            profits=all_profits,\n",
    "            operation_profits=all_operation_profits,\n",
    "            alpha_values=alpha_values,\n",
    "            beta_values=beta_values,\n",
    "            F_vars=all_Fs,\n",
    "            Q0_vars=all_Q0s,\n",
    "            Q1_vars=all_Q1s,\n",
    "            f_values=f_values,\n",
    "            tau_values=tau_values,\n",
    "            holding_costs_0s=holding_costs_0s,\n",
    "            holding_costs_1s=holding_costs_1s,\n",
    "            all_left0s=all_left0s,\n",
    "            all_left1s=all_left1s,\n",
    "            all_lost0s=all_lost0s,\n",
    "            all_lost1s=all_lost1s,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S11 - Beta(Beta+Gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1520,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __fully_flexible_beta_with_softmax_11(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "        model.setParam(\"IntFeasTol\", 1e-9)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        alphas = model.addVars(features_num + 1, lb=-GRB.INFINITY, name=\"alphas\")\n",
    "        betas = model.addVars(K, lb=-GRB.INFINITY, name=\"betas\")  # for intercept\n",
    "        gammas = model.addVars(\n",
    "            features_num, lb=-GRB.INFINITY, name=\"gammas\"\n",
    "        )  # for features coefficients\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "        Sold_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_0\")\n",
    "        Left_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_0\")\n",
    "        Lost_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_0\")\n",
    "\n",
    "        Sold_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_1\")\n",
    "        Left_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_1\")\n",
    "        Lost_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_1\")\n",
    "\n",
    "        # Holding_Cost_0s = model.addVars(\n",
    "        #     len(demand_df_train), lb=0.0, name=\"Holding_Cost_0\"\n",
    "        # )\n",
    "\n",
    "        # Holding_Cost_1s = model.addVars(\n",
    "        #     len(demand_df_train), lb=0.0, name=\"Holding_Cost_1\"\n",
    "        # )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, name=\"profits_vars\"\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, name=\"Total_Demand_from_k_to_T\"\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        f_vars = model.addVars(len(demand_df_train), lb=-GRB.INFINITY, name=\"f_var\")\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=1, name=\"Fraction_for_second_order_amount\"\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=(Q_star + 1), name=\"Q0_var\"\n",
    "        )\n",
    "\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        r_vars = model.addVars(len(demand_df_train), K, lb=0.0, ub=1.0, name=\"r\")\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(len(Qk_hat_df), lb=0.0, name=\"Q1_var\")\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            lb=0.0,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df), lb=-GRB.INFINITY, name=f\"Q_hat_adjusted\"\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, _ in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            ### 用線性回歸計算F_var\n",
    "            model.addConstr(\n",
    "                f_vars[i]\n",
    "                == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            )\n",
    "            model.addGenConstrLogistic(\n",
    "                xvar=f_vars[i], yvar=F_vars[i], name=f\"logistic_constraint_{i}\"\n",
    "            )\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "            # 用線性回歸計算確定最佳補貨時間\n",
    "            exp_tau_vars = []\n",
    "            for k in range(K):\n",
    "\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, k]\n",
    "                    == gp.quicksum(\n",
    "                        X_data[j] * gammas[j]\n",
    "                        for j in range(features_num)  # features coefficient\n",
    "                    )\n",
    "                    + betas[k],  # intercept\n",
    "                    name=f\"tau_computation_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "                exp_tau_var = model.addVar(lb=0, name=f\"exp_tau_var_{i}_{k}\")\n",
    "                # neg_tau_var = model.addVar(\n",
    "                #     lb=-GRB.INFINITY, ub=0, name=f\"neg_tau_var_{i}_{k}\"\n",
    "                # )\n",
    "\n",
    "                # model.addConstr(\n",
    "                #     neg_tau_var == -tau_vars[i, k], name=f\"neg_tau_constr_{i}_{k}\"\n",
    "                # )\n",
    "                # model.addGenConstrExp(xvar=neg_tau_var, yvar=exp_tau_var)\n",
    "                model.addGenConstrExp(xvar=tau_vars[i, k], yvar=exp_tau_var)\n",
    "\n",
    "                exp_tau_vars.append(exp_tau_var)\n",
    "\n",
    "            ### 找到最大 R 以及 r, R 的相關限制式 -> k: 0~7\n",
    "            for k in range(K):\n",
    "                model.addConstr(\n",
    "                    r_vars[i, k] * gp.quicksum(exp_tau_vars) == exp_tau_vars[k],\n",
    "                    name=f\"softmax_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "            model.addConstr(\n",
    "                gp.quicksum(r_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"sum_r_{i}\",\n",
    "            )\n",
    "\n",
    "            max_r_helpers = model.addVar(lb=0.0, ub=1.0, name=\"max_r_helper\")\n",
    "            model.addGenConstrMax(\n",
    "                max_r_helpers,\n",
    "                [r_vars[i, k] for k in range(K)],\n",
    "                name=f\"MaxRConstraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # 確保 R_vars 的邏輯行為\n",
    "            # for k in range(K):\n",
    "            #     model.addGenConstrIndicator(\n",
    "            #         R_vars[i, k], 1, r_vars[i, k] == max_r_helpers\n",
    "            #     )\n",
    "\n",
    "            epsilon = 1e-3  # 可調整的小正數\n",
    "            for k in range(K):\n",
    "                for k2 in range(K):\n",
    "                    if k != k2:\n",
    "                        model.addGenConstrIndicator(\n",
    "                            R_vars[i, k],\n",
    "                            True,\n",
    "                            r_vars[i, k] >= r_vars[i, k2] + epsilon,\n",
    "                            name=f\"tau_diff_{i}_{k}_{k2}\",\n",
    "                        )\n",
    "\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"Ensure_only_one_R_true_{i}\",\n",
    "            )\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            # ### 0~k-1 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Left_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0s[i],\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1s[i],\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train))),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "        model.write(\"s4_model_debug.lp\")\n",
    "        model.write(\"s4_model.mps\")\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                print(\"===================== 找到最佳解 ==================\")\n",
    "                print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                print(\"Alphas values:\")\n",
    "                for key, alpha in alphas.items():\n",
    "                    print(f\"alpha[{key}]: {alpha.X}\")\n",
    "\n",
    "                # print(\"Beta values:\")\n",
    "                # for key, beta in betas.items():\n",
    "                #     print(f\"beta{key}: {beta.X}\")\n",
    "\n",
    "                alpha_values = np.array([alpha.X for _, alpha in alphas.items()])\n",
    "                beta_values = np.array([betas[k].X for k in range(K)])\n",
    "                print(f\"beta_values:\\n{beta_values}\")\n",
    "\n",
    "                gamma_values = np.array([gammas[j].X for j in range(features_num)])\n",
    "                print(f\"gamma_values:\\n{gamma_values}\")\n",
    "\n",
    "                f_values = np.array([f.X for _, f in f_vars.items()])\n",
    "                tau_values = np.array(\n",
    "                    [\n",
    "                        [tau_vars[i, j].X for j in range(K)]\n",
    "                        for i in range(len(demand_df_train))\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                print(f\"------------\")\n",
    "                print(f\"f_values:\\n{f_values}\")\n",
    "                print(f\"tau_values:\\n{tau_values}\")\n",
    "\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                all_rs = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                # all_holding_costs_0 = []\n",
    "                # all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    print(\"----------------------------------------------\")\n",
    "                    print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    # Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    # Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "                    all_Q0s.append(Q0_vars[i].X)\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    all_Fs.append(F_vars[i].X)\n",
    "                    # all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    # all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    rs = []\n",
    "                    for k in range(K):\n",
    "                        rs.append(r_vars[i, k].X)\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        print(\n",
    "                            f\"第 {k+2} 天補貨策略: R_vars = {R_value}, r_vars = {rs[k]}\"\n",
    "                        )\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "\n",
    "                    all_Rs.append(reorder_day)\n",
    "                    all_rs.append(rs)\n",
    "\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    print(check_results_df)\n",
    "\n",
    "                    # for t in range(2):\n",
    "                    #     if t == 0:\n",
    "                    #         print(\n",
    "                    #             f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                    #         )\n",
    "                    #     else:\n",
    "                    #         print(\n",
    "                    #             f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                    #         )\n",
    "\n",
    "                    # print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                print(\"==========================================\")\n",
    "                print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    alpha_values,\n",
    "                    beta_values,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    f_values,\n",
    "                    tau_values,\n",
    "                    None,\n",
    "                    None,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                    gamma_values,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1521,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_flexible_beta_with_softmax_11(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    result = __fully_flexible_beta_with_softmax_11(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "    if result is None:\n",
    "        print(f\"找不到最佳解\")\n",
    "        return None, None\n",
    "    else:\n",
    "        (\n",
    "            all_Rs,\n",
    "            all_losses,\n",
    "            all_lefts,\n",
    "            all_profits,\n",
    "            all_operation_profits,\n",
    "            alpha_values,\n",
    "            beta_values,\n",
    "            all_Fs,\n",
    "            all_Q0s,\n",
    "            all_Q1s,\n",
    "            f_values,\n",
    "            tau_values,\n",
    "            holding_costs_0s,\n",
    "            holding_costs_1s,\n",
    "            all_left0s,\n",
    "            all_left1s,\n",
    "            all_lost0s,\n",
    "            all_lost1s,\n",
    "            gamma_values,\n",
    "        ) = result\n",
    "\n",
    "        print(f\"all_Rs: {all_Rs}\")\n",
    "\n",
    "        return make_s3_related_strtegies_result(\n",
    "            all_Rs=all_Rs,\n",
    "            losses=all_losses,\n",
    "            lefts=all_lefts,\n",
    "            profits=all_profits,\n",
    "            operation_profits=all_operation_profits,\n",
    "            alpha_values=alpha_values,\n",
    "            beta_values=beta_values,\n",
    "            F_vars=all_Fs,\n",
    "            Q0_vars=all_Q0s,\n",
    "            Q1_vars=all_Q1s,\n",
    "            f_values=f_values,\n",
    "            tau_values=tau_values,\n",
    "            holding_costs_0s=holding_costs_0s,\n",
    "            holding_costs_1s=holding_costs_1s,\n",
    "            all_left0s=all_left0s,\n",
    "            all_left1s=all_left1s,\n",
    "            all_lost0s=all_lost0s,\n",
    "            all_lost1s=all_lost1s,\n",
    "            gamma_values=gamma_values,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S12 - Beta without r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1522,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __fully_flexible_beta_with_softmax_12(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "        model.setParam(\"IntFeasTol\", 1e-9)\n",
    "        model.setParam(\"NumericFocus\", 3)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        alphas = model.addVars(features_num + 1, lb=-GRB.INFINITY, name=\"alphas\")\n",
    "        betas = model.addVars(K, features_num + 1, lb=-GRB.INFINITY, name=\"betas\")\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "        Sold_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_0\")\n",
    "        Left_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_0\")\n",
    "        Lost_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_0\")\n",
    "\n",
    "        Sold_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_1\")\n",
    "        Left_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_1\")\n",
    "        Lost_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_1\")\n",
    "\n",
    "        Holding_Cost_0s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_0\"\n",
    "        )\n",
    "\n",
    "        Holding_Cost_1s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_1\"\n",
    "        )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, name=\"profits_vars\"\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, name=\"Total_Demand_from_k_to_T\"\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        f_vars = model.addVars(len(demand_df_train), lb=-GRB.INFINITY, name=\"f_var\")\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=1, name=\"Fraction_for_second_order_amount\"\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=(Q_star + 1), name=\"Q0_var\"\n",
    "        )\n",
    "\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        # tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        r_vars = model.addVars(len(demand_df_train), K, lb=0.0, ub=1.0, name=\"r\")\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(len(Qk_hat_df), lb=0.0, name=\"Q1_var\")\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            lb=0.0,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df), lb=-GRB.INFINITY, name=f\"Q_hat_adjusted\"\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, _ in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            ### 用線性回歸計算F_var\n",
    "            model.addConstr(\n",
    "                f_vars[i]\n",
    "                == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            )\n",
    "            model.addGenConstrLogistic(\n",
    "                xvar=f_vars[i],\n",
    "                yvar=F_vars[i],\n",
    "                options=\"FuncNonlinear=1\",\n",
    "                name=f\"logistic_constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model(Alternative Model) ===================\n",
    "\n",
    "            # Step 1: 利用線性回歸計算 tau\n",
    "            for k in range(K):\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, k]\n",
    "                    == gp.quicksum(\n",
    "                        X_data[j] * betas[k, j] for j in range(features_num + 1)\n",
    "                    ),\n",
    "                    name=f\"tau_computation_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "            delta = 1e-3\n",
    "            tau_star = model.addVar(lb=-GRB.INFINITY, name=f\"tau_star_{i}\")\n",
    "\n",
    "            for k in range(K):\n",
    "                # 如果候選 k 被選中 (R_vars[i,k] == 1)，則強制 tau_vars[i,k] 等於 tau_star\n",
    "                model.addGenConstrIndicator(\n",
    "                    R_vars[i, k],\n",
    "                    True,\n",
    "                    tau_vars[i, k] == tau_star,\n",
    "                    name=f\"tau_star_eq_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "                # 如果候選 k 未被選中 (R_vars[i,k] == 0)，則必須有 tau_vars[i,k] <= tau_star - delta\n",
    "                # 利用 Big-M 技巧：當 R_vars[i,k]==0 時，約束變為 tau_vars[i,k] <= tau_star - delta\n",
    "                # 當 R_vars[i,k]==1 時，由於前面的 indicator 約束已強制 tau_vars[i,k] == tau_star，\n",
    "                # 此約束則不會影響模型（因為 tau_star <= tau_star - delta + M 已經成立）\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, k] <= tau_star - delta + M * R_vars[i, k],\n",
    "                    name=f\"tau_gap_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "            # Step 3: 保證只有一個候選被選中 (即 R_vars 為 1 的只有一個)\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"one_R_{i}\",\n",
    "            )\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            # ### 0~k-1 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Left_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0s[i],\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1s[i],\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # model.addConstr(\n",
    "            #     profits_vars[i]\n",
    "            #     == (\n",
    "            #         (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "            #         - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "            #         - (cost - salvage_value) * (Left_1s[i])  # left cost\n",
    "            #     ),\n",
    "            #     name=f\"Profit_Constraint_{i}\",\n",
    "            # )\n",
    "\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * (Left_0s[i] + Left_1s[i])  # left cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train))),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "        model.write(\"s4_model_debug.lp\")\n",
    "        model.write(\"s4_model.mps\")\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                # print(\"===================== 找到最佳解 ==================\")\n",
    "                # print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                # print(\"Alphas values:\")\n",
    "                # for key, alpha in alphas.items():\n",
    "                #     print(f\"alpha[{key}]: {alpha.X}\")\n",
    "\n",
    "                alpha_values = np.array([alpha.X for _, alpha in alphas.items()])\n",
    "                beta_values = np.array(\n",
    "                    [[betas[k, j].X for j in range(features_num + 1)] for k in range(K)]\n",
    "                )\n",
    "                # print(f\"beta_values:\\n{beta_values}\")\n",
    "\n",
    "                f_values = np.array([f.X for _, f in f_vars.items()])\n",
    "                tau_values = np.array(\n",
    "                    [\n",
    "                        [tau_vars[i, j].X for j in range(K)]\n",
    "                        for i in range(len(demand_df_train))\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                # print(f\"------------\")\n",
    "                # print(f\"f_values:\\n{f_values}\")\n",
    "                # print(f\"tau_values:\\n{tau_values}\")\n",
    "\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                all_rs = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                all_holding_costs_0 = []\n",
    "                all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    # print(\"----------------------------------------------\")\n",
    "                    # print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    # all_Fs.append(F_vars[i].X)\n",
    "                    all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    # Check f\n",
    "                    x_data = training_df.iloc[i].tolist()\n",
    "                    x_data.append(1)\n",
    "                    f_train, F_train, Q0_train = compute_f_F_Q(\n",
    "                        x_data, alpha_values, Q_star\n",
    "                    )\n",
    "                    if (\n",
    "                        truncate_to_2(f_train) == truncate_to_2(f_vars[i].X)\n",
    "                        and truncate_to_2(F_train) == truncate_to_2(F_vars[i].X)\n",
    "                        and truncate_to_2(Q0_train) == truncate_to_2(Q0_vars[i].X)\n",
    "                    ):\n",
    "                        print(\"f_train, F_train, Q0_train 都相等\")\n",
    "                        all_Q0s.append(Q0_vars[i].X)\n",
    "                        all_Fs.append(F_vars[i].X)\n",
    "                    else:\n",
    "                        print(f\"f_train, F_train, Q0_train 不相等\")\n",
    "                        all_Q0s.append(-1)\n",
    "                        all_Fs.append(-1)\n",
    "                        # results[\"Q0s\"].append(Q0_vars[i].X)\n",
    "                        # results[\"Fs\"].append(F_vars[i].X)\n",
    "                        # results[\"fs\"].append(f_vars[i].X)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    rs = []\n",
    "                    for k in range(K):\n",
    "                        rs.append(r_vars[i, k].X)\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        print(\n",
    "                            f\"第 {k+2} 天補貨策略: R_vars = {R_value}, tau_vars = {tau_vars[i, k].X}\"\n",
    "                        )\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "\n",
    "                    all_Rs.append(reorder_day)\n",
    "                    all_rs.append(rs)\n",
    "\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    # print(check_results_df)\n",
    "\n",
    "                    # for t in range(2):\n",
    "                    #     if t == 0:\n",
    "                    #         print(\n",
    "                    #             f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                    #         )\n",
    "                    #     else:\n",
    "                    #         print(\n",
    "                    #             f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                    #         )\n",
    "\n",
    "                    # print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                # print(\"==========================================\")\n",
    "                # print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    alpha_values,\n",
    "                    beta_values,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    f_values,\n",
    "                    tau_values,\n",
    "                    all_holding_costs_0,\n",
    "                    all_holding_costs_1,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1523,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_flexible_beta_with_softmax_12(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    result = __fully_flexible_beta_with_softmax_12(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "    if result is None:\n",
    "        print(f\"找不到最佳解\")\n",
    "        return None, None\n",
    "    else:\n",
    "        (\n",
    "            all_Rs,\n",
    "            all_losses,\n",
    "            all_lefts,\n",
    "            all_profits,\n",
    "            all_operation_profits,\n",
    "            alpha_values,\n",
    "            beta_values,\n",
    "            all_Fs,\n",
    "            all_Q0s,\n",
    "            all_Q1s,\n",
    "            f_values,\n",
    "            tau_values,\n",
    "            holding_costs_0s,\n",
    "            holding_costs_1s,\n",
    "            all_left0s,\n",
    "            all_left1s,\n",
    "            all_lost0s,\n",
    "            all_lost1s,\n",
    "        ) = result\n",
    "\n",
    "        print(f\"all_Rs: {all_Rs}\")\n",
    "\n",
    "        return make_s3_related_strtegies_result(\n",
    "            all_Rs=all_Rs,\n",
    "            losses=all_losses,\n",
    "            lefts=all_lefts,\n",
    "            profits=all_profits,\n",
    "            operation_profits=all_operation_profits,\n",
    "            alpha_values=alpha_values,\n",
    "            beta_values=beta_values,\n",
    "            F_vars=all_Fs,\n",
    "            Q0_vars=all_Q0s,\n",
    "            Q1_vars=all_Q1s,\n",
    "            f_values=f_values,\n",
    "            tau_values=tau_values,\n",
    "            holding_costs_0s=holding_costs_0s,\n",
    "            holding_costs_1s=holding_costs_1s,\n",
    "            all_left0s=all_left0s,\n",
    "            all_left1s=all_left1s,\n",
    "            all_lost0s=all_lost0s,\n",
    "            all_lost1s=all_lost1s,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S14 - Optimized F & Rk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1524,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __cal_optimized_F_R(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "        model.setParam(\"IntFeasTol\", 1e-9)\n",
    "        model.setParam(\"NumericFocus\", 3)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "        Sold_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_0\")\n",
    "        Left_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_0\")\n",
    "        Lost_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_0\")\n",
    "\n",
    "        Sold_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_1\")\n",
    "        Left_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_1\")\n",
    "        Lost_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_1\")\n",
    "\n",
    "        Holding_Cost_0s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_0\"\n",
    "        )\n",
    "\n",
    "        Holding_Cost_1s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_1\"\n",
    "        )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, name=\"profits_vars\"\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, name=\"Total_Demand_from_k_to_T\"\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=1, name=\"Fraction_for_second_order_amount\"\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=(Q_star + 1), name=\"Q0_var\"\n",
    "        )\n",
    "\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(len(Qk_hat_df), lb=0.0, name=\"Q1_var\")\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            lb=0.0,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df), lb=-GRB.INFINITY, name=f\"Q_hat_adjusted\"\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, _ in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            model.addConstr(F_vars[i] >= 0, name=f\"Fraction_lower_bound_{i}\")\n",
    "            model.addConstr(F_vars[i] <= 1, name=f\"Fraction_upper_bound_{i}\")\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"Ensure_only_one_R_true_{i}\",\n",
    "            )\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            # ### 0~k-1 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Left_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0s[i],\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1s[i],\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # model.addConstr(\n",
    "            #     profits_vars[i]\n",
    "            #     == (\n",
    "            #         (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "            #         - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "            #         - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "            #     ),\n",
    "            #     name=f\"Profit_Constraint_{i}\",\n",
    "            # )\n",
    "\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * (Left_0s[i] + Left_1s[i])  # left cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train))),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "        model.write(\"s4_model_debug.lp\")\n",
    "        model.write(\"s4_model.mps\")\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                # print(\"===================== 找到最佳解 ==================\")\n",
    "                # print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                # all_rs = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                all_holding_costs_0 = []\n",
    "                all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    # print(\"----------------------------------------------\")\n",
    "                    # print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "                    all_Q0s.append(Q0_vars[i].X)\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    all_Fs.append(F_vars[i].X)\n",
    "                    all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    rs = []\n",
    "                    for k in range(K):\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        print(f\"第 {k+2} 天補貨策略: R_vars = {R_value}\")\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    # print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "\n",
    "                    all_Rs.append(reorder_day)\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    # print(check_results_df)\n",
    "\n",
    "                #     for t in range(2):\n",
    "                #         if t == 0:\n",
    "                #             print(\n",
    "                #                 f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                #             )\n",
    "                #         else:\n",
    "                #             print(\n",
    "                #                 f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                #             )\n",
    "\n",
    "                #     print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                # print(\"==========================================\")\n",
    "                # print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    all_holding_costs_0,\n",
    "                    all_holding_costs_1,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1525,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_optimized_F_R(\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df,\n",
    "    Qk_hat_df,\n",
    "    training_df,\n",
    "):\n",
    "    results_dict = {\n",
    "        \"R(T)\": [],\n",
    "        \"average_profits\": [],\n",
    "        \"average_losses\": [],\n",
    "        \"average_lefts\": [],\n",
    "        \"average_operation_profits\": [],\n",
    "        \"alpha_values\": [],\n",
    "        \"F_vars\": [],\n",
    "        \"Q0_vars\": [],\n",
    "        \"Q1_vars\": [],\n",
    "    }\n",
    "\n",
    "    max_profit = None\n",
    "    max_profit_stimulation_result = {}\n",
    "\n",
    "    (\n",
    "        all_Rs,\n",
    "        losses,\n",
    "        lefts,\n",
    "        profits,\n",
    "        operation_profits,\n",
    "        F_vars,\n",
    "        Q0_vars,\n",
    "        Q1_vars,\n",
    "        all_holding_costs_0,\n",
    "        all_holding_costs_1,\n",
    "        all_left0s,\n",
    "        all_left1s,\n",
    "        all_lost0s,\n",
    "        all_lost1s,\n",
    "    ) = __cal_optimized_F_R(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df,\n",
    "        Qk_hat_df=Qk_hat_df,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "\n",
    "    # 計算平均值\n",
    "    average_losses = sum(losses) / len(losses) if losses else 0\n",
    "    average_lefts = sum(lefts) / len(lefts) if lefts else 0\n",
    "    average_profits = sum(profits) / len(profits) if profits else 0\n",
    "    average_operation_profits = (\n",
    "        sum(operation_profits) / len(operation_profits) if operation_profits else 0\n",
    "    )\n",
    "\n",
    "    # 將結果存儲到字典中\n",
    "    results_dict[\"R(T)\"].append(all_Rs)\n",
    "    results_dict[\"average_losses\"].append(average_losses)\n",
    "    results_dict[\"average_lefts\"].append(average_lefts)\n",
    "    results_dict[\"average_profits\"].append(average_profits)\n",
    "    results_dict[\"average_operation_profits\"].append(average_operation_profits)\n",
    "    results_dict[\"alpha_values\"].append(None)\n",
    "    results_dict[\"F_vars\"].append(F_vars)\n",
    "    results_dict[\"Q0_vars\"].append(Q0_vars)\n",
    "    results_dict[\"Q1_vars\"].append(Q1_vars)\n",
    "\n",
    "    # print(f\"The average profits is {average_profits}\")\n",
    "\n",
    "    if max_profit is None or max_profit < average_profits:\n",
    "        # print(f\"max_profit is changed from {max_profit} to {average_profits}\")\n",
    "        max_profit = average_profits\n",
    "        max_profit_stimulation_result = {\n",
    "            \"R\": all_Rs,\n",
    "            \"F\": F_vars,\n",
    "            \"profits\": profits,\n",
    "            \"losses\": losses,\n",
    "            \"lefts\": lefts,\n",
    "            \"operation_profits\": operation_profits,\n",
    "            \"Q0\": Q0_vars,\n",
    "            \"Q1\": Q1_vars,\n",
    "        }\n",
    "\n",
    "    return pd.DataFrame(results_dict).sort_values(\n",
    "        by=\"average_profits\", ascending=False\n",
    "    ), pd.DataFrame(max_profit_stimulation_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S15 - Beta with Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1526,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __fully_flexible_beta_with_lasso_15(\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_train,\n",
    "    Qk_hat_df,\n",
    "    training_df,\n",
    "    lambda_beta,\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "        model.setParam(\"IntFeasTol\", 1e-9)\n",
    "        model.setParam(\"NumericFocus\", 3)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        alphas = model.addVars(features_num + 1, lb=-GRB.INFINITY, name=\"alphas\")\n",
    "        betas = model.addVars(K, features_num + 1, lb=-GRB.INFINITY, name=\"betas\")\n",
    "        abs_betas = model.addVars(betas.keys(), lb=0, name=\"abs_beta\")\n",
    "\n",
    "        # 進行 lasso 處理\n",
    "        for k, j in betas.keys():\n",
    "            model.addConstr(abs_betas[k, j] >= betas[k, j])\n",
    "            model.addConstr(abs_betas[k, j] >= -betas[k, j])\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "        Sold_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_0\")\n",
    "        Left_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_0\")\n",
    "        Lost_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_0\")\n",
    "\n",
    "        Sold_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_1\")\n",
    "        Left_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_1\")\n",
    "        Lost_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_1\")\n",
    "\n",
    "        Holding_Cost_0s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_0\"\n",
    "        )\n",
    "\n",
    "        Holding_Cost_1s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_1\"\n",
    "        )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, name=\"profits_vars\"\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, name=\"Total_Demand_from_k_to_T\"\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        f_vars = model.addVars(len(demand_df_train), lb=-GRB.INFINITY, name=\"f_var\")\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=1, name=\"Fraction_for_second_order_amount\"\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=(Q_star + 1), name=\"Q0_var\"\n",
    "        )\n",
    "\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        # tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        r_vars = model.addVars(len(demand_df_train), K, lb=0.0, ub=1.0, name=\"r\")\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(len(Qk_hat_df), lb=0.0, name=\"Q1_var\")\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            lb=0.0,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df), lb=-GRB.INFINITY, name=f\"Q_hat_adjusted\"\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, _ in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            ### 用線性回歸計算F_var\n",
    "            model.addConstr(\n",
    "                f_vars[i]\n",
    "                == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            )\n",
    "            model.addGenConstrLogistic(\n",
    "                xvar=f_vars[i],\n",
    "                yvar=F_vars[i],\n",
    "                options=\"FuncNonlinear=1\",\n",
    "                name=f\"logistic_constraint_{i}\",\n",
    "            )\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model(Alternative Model) ===================\n",
    "\n",
    "            # Step 1: 利用線性回歸計算 tau\n",
    "            for k in range(K):\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, k]\n",
    "                    == gp.quicksum(\n",
    "                        X_data[j] * betas[k, j] for j in range(features_num + 1)\n",
    "                    ),\n",
    "                    name=f\"tau_computation_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "            delta = 1e-3\n",
    "            tau_star = model.addVar(lb=-GRB.INFINITY, name=f\"tau_star_{i}\")\n",
    "\n",
    "            for k in range(K):\n",
    "                # 如果候選 k 被選中 (R_vars[i,k] == 1)，則強制 tau_vars[i,k] 等於 tau_star\n",
    "                model.addGenConstrIndicator(\n",
    "                    R_vars[i, k],\n",
    "                    True,\n",
    "                    tau_vars[i, k] == tau_star,\n",
    "                    name=f\"tau_star_eq_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, k] <= tau_star - delta + M * R_vars[i, k],\n",
    "                    name=f\"tau_gap_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "            # Step 3: 保證只有一個候選被選中 (即 R_vars 為 1 的只有一個)\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"one_R_{i}\",\n",
    "            )\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            # ### 0~k-1 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Left_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0s[i],\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1s[i],\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train)))\n",
    "            - lambda_beta * gp.quicksum(abs_betas[k, j] for k, j in abs_betas.keys()),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "        model.write(\"s4_model_debug.lp\")\n",
    "        model.write(\"s4_model.mps\")\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                # print(\"===================== 找到最佳解 ==================\")\n",
    "                # print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                # print(\"Alphas values:\")\n",
    "                # for key, alpha in alphas.items():\n",
    "                #     print(f\"alpha[{key}]: {alpha.X}\")\n",
    "\n",
    "                alpha_values = np.array([alpha.X for _, alpha in alphas.items()])\n",
    "                beta_values = np.array(\n",
    "                    [[betas[k, j].X for j in range(features_num + 1)] for k in range(K)]\n",
    "                )\n",
    "                # print(f\"beta_values:\\n{beta_values}\")\n",
    "\n",
    "                f_values = np.array([f.X for _, f in f_vars.items()])\n",
    "                tau_values = np.array(\n",
    "                    [\n",
    "                        [tau_vars[i, j].X for j in range(K)]\n",
    "                        for i in range(len(demand_df_train))\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                # print(f\"------------\")\n",
    "                # print(f\"f_values:\\n{f_values}\")\n",
    "                # print(f\"tau_values:\\n{tau_values}\")\n",
    "\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                all_rs = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                all_holding_costs_0 = []\n",
    "                all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    # print(\"----------------------------------------------\")\n",
    "                    # print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "                    all_Q0s.append(Q0_vars[i].X)\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    all_Fs.append(F_vars[i].X)\n",
    "                    all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    rs = []\n",
    "                    for k in range(K):\n",
    "                        rs.append(r_vars[i, k].X)\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        # print(\n",
    "                        #     f\"第 {k+2} 天補貨策略: R_vars = {R_value}, tau_vars = {tau_vars[i, k].X}\"\n",
    "                        # )\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    # print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "\n",
    "                    all_Rs.append(reorder_day)\n",
    "                    all_rs.append(rs)\n",
    "\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    # print(check_results_df)\n",
    "\n",
    "                #     for t in range(2):\n",
    "                #         if t == 0:\n",
    "                #             print(\n",
    "                #                 f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                #             )\n",
    "                #         else:\n",
    "                #             print(\n",
    "                #                 f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                #             )\n",
    "\n",
    "                #     print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                # print(\"==========================================\")\n",
    "                # print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    alpha_values,\n",
    "                    beta_values,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    f_values,\n",
    "                    tau_values,\n",
    "                    all_holding_costs_0,\n",
    "                    all_holding_costs_1,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1527,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_flexible_beta_with_lasso_15(\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_train,\n",
    "    Qk_hat_df,\n",
    "    training_df,\n",
    "    lambda_beta,\n",
    "):\n",
    "\n",
    "    result = __fully_flexible_beta_with_lasso_15(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df,\n",
    "        training_df=training_df,\n",
    "        lambda_beta=lambda_beta,\n",
    "    )\n",
    "    if result is None:\n",
    "        print(f\"找不到最佳解\")\n",
    "        return None, None\n",
    "    else:\n",
    "        (\n",
    "            all_Rs,\n",
    "            all_losses,\n",
    "            all_lefts,\n",
    "            all_profits,\n",
    "            all_operation_profits,\n",
    "            alpha_values,\n",
    "            beta_values,\n",
    "            all_Fs,\n",
    "            all_Q0s,\n",
    "            all_Q1s,\n",
    "            f_values,\n",
    "            tau_values,\n",
    "            holding_costs_0s,\n",
    "            holding_costs_1s,\n",
    "            all_left0s,\n",
    "            all_left1s,\n",
    "            all_lost0s,\n",
    "            all_lost1s,\n",
    "        ) = result\n",
    "\n",
    "        # print(f\"all_Rs: {all_Rs}\")\n",
    "\n",
    "        return make_s3_related_strtegies_result(\n",
    "            all_Rs=all_Rs,\n",
    "            losses=all_losses,\n",
    "            lefts=all_lefts,\n",
    "            profits=all_profits,\n",
    "            operation_profits=all_operation_profits,\n",
    "            alpha_values=alpha_values,\n",
    "            beta_values=beta_values,\n",
    "            F_vars=all_Fs,\n",
    "            Q0_vars=all_Q0s,\n",
    "            Q1_vars=all_Q1s,\n",
    "            f_values=f_values,\n",
    "            tau_values=tau_values,\n",
    "            holding_costs_0s=holding_costs_0s,\n",
    "            holding_costs_1s=holding_costs_1s,\n",
    "            all_left0s=all_left0s,\n",
    "            all_left1s=all_left1s,\n",
    "            all_lost0s=all_lost0s,\n",
    "            all_lost1s=all_lost1s,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S16 - Beta with second Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1528,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __fully_flexible_beta_with_second_training_16(\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_train,\n",
    "    Qk_hat_df,\n",
    "    training_df,\n",
    "    lambda_beta,\n",
    "    last_beta_total,\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "        model.setParam(\"IntFeasTol\", 1e-9)\n",
    "        model.setParam(\"NumericFocus\", 3)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        alphas = model.addVars(features_num + 1, lb=-GRB.INFINITY, name=\"alphas\")\n",
    "        betas = model.addVars(K, features_num + 1, lb=-GRB.INFINITY, name=\"betas\")\n",
    "        abs_betas = model.addVars(betas.keys(), lb=0, name=\"abs_beta\")\n",
    "\n",
    "        # 進行絕對值處理\n",
    "        for k, j in betas.keys():\n",
    "            model.addConstr(abs_betas[k, j] >= betas[k, j])\n",
    "            model.addConstr(abs_betas[k, j] >= -betas[k, j])\n",
    "\n",
    "        # 設定 beta 的上限\n",
    "        model.addConstr(\n",
    "            gp.quicksum(abs_betas[k, j] for k, j in abs_betas.keys())\n",
    "            <= lambda_beta * last_beta_total,\n",
    "            name=\"beta_limit\",\n",
    "        )\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "        Sold_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_0\")\n",
    "        Left_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_0\")\n",
    "        Lost_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_0\")\n",
    "\n",
    "        Sold_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_1\")\n",
    "        Left_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_1\")\n",
    "        Lost_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_1\")\n",
    "\n",
    "        Holding_Cost_0s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_0\"\n",
    "        )\n",
    "\n",
    "        Holding_Cost_1s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_1\"\n",
    "        )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, name=\"profits_vars\"\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, name=\"Total_Demand_from_k_to_T\"\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        f_vars = model.addVars(len(demand_df_train), lb=-GRB.INFINITY, name=\"f_var\")\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=1, name=\"Fraction_for_second_order_amount\"\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=(Q_star + 1), name=\"Q0_var\"\n",
    "        )\n",
    "\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        # tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        r_vars = model.addVars(len(demand_df_train), K, lb=0.0, ub=1.0, name=\"r\")\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(len(Qk_hat_df), lb=0.0, name=\"Q1_var\")\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            lb=0.0,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df), lb=-GRB.INFINITY, name=f\"Q_hat_adjusted\"\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, _ in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            ### 用線性回歸計算F_var\n",
    "            model.addConstr(\n",
    "                f_vars[i]\n",
    "                == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            )\n",
    "            model.addGenConstrLogistic(\n",
    "                xvar=f_vars[i],\n",
    "                yvar=F_vars[i],\n",
    "                options=\"FuncNonlinear=1\",\n",
    "                name=f\"logistic_constraint_{i}\",\n",
    "            )\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model(Alternative Model) ===================\n",
    "\n",
    "            # Step 1: 利用線性回歸計算 tau\n",
    "            for k in range(K):\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, k]\n",
    "                    == gp.quicksum(\n",
    "                        X_data[j] * betas[k, j] for j in range(features_num + 1)\n",
    "                    ),\n",
    "                    name=f\"tau_computation_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "            delta = 1e-3\n",
    "            tau_star = model.addVar(lb=-GRB.INFINITY, name=f\"tau_star_{i}\")\n",
    "\n",
    "            for k in range(K):\n",
    "                # 如果候選 k 被選中 (R_vars[i,k] == 1)，則強制 tau_vars[i,k] 等於 tau_star\n",
    "                model.addGenConstrIndicator(\n",
    "                    R_vars[i, k],\n",
    "                    True,\n",
    "                    tau_vars[i, k] == tau_star,\n",
    "                    name=f\"tau_star_eq_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, k] <= tau_star - delta + M * R_vars[i, k],\n",
    "                    name=f\"tau_gap_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "            # Step 3: 保證只有一個候選被選中 (即 R_vars 為 1 的只有一個)\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"one_R_{i}\",\n",
    "            )\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            # ### 0~k-1 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Left_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0s[i],\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1s[i],\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train)))\n",
    "            - lambda_beta * gp.quicksum(abs_betas[k, j] for k, j in abs_betas.keys()),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "        model.write(\"s4_model_debug.lp\")\n",
    "        model.write(\"s4_model.mps\")\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                # print(\"===================== 找到最佳解 ==================\")\n",
    "                # print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                # print(\"Alphas values:\")\n",
    "                # for key, alpha in alphas.items():\n",
    "                #     print(f\"alpha[{key}]: {alpha.X}\")\n",
    "\n",
    "                alpha_values = np.array([alpha.X for _, alpha in alphas.items()])\n",
    "                beta_values = np.array(\n",
    "                    [[betas[k, j].X for j in range(features_num + 1)] for k in range(K)]\n",
    "                )\n",
    "                # print(f\"beta_values:\\n{beta_values}\")\n",
    "\n",
    "                f_values = np.array([f.X for _, f in f_vars.items()])\n",
    "                tau_values = np.array(\n",
    "                    [\n",
    "                        [tau_vars[i, j].X for j in range(K)]\n",
    "                        for i in range(len(demand_df_train))\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                # print(f\"------------\")\n",
    "                # print(f\"f_values:\\n{f_values}\")\n",
    "                # print(f\"tau_values:\\n{tau_values}\")\n",
    "\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                all_rs = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                all_holding_costs_0 = []\n",
    "                all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    # print(\"----------------------------------------------\")\n",
    "                    # print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "                    all_Q0s.append(Q0_vars[i].X)\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    all_Fs.append(F_vars[i].X)\n",
    "                    all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    rs = []\n",
    "                    for k in range(K):\n",
    "                        rs.append(r_vars[i, k].X)\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        # print(\n",
    "                        #     f\"第 {k+2} 天補貨策略: R_vars = {R_value}, tau_vars = {tau_vars[i, k].X}\"\n",
    "                        # )\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    # print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "\n",
    "                    all_Rs.append(reorder_day)\n",
    "                    all_rs.append(rs)\n",
    "\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    # print(check_results_df)\n",
    "\n",
    "                #     for t in range(2):\n",
    "                #         if t == 0:\n",
    "                #             print(\n",
    "                #                 f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                #             )\n",
    "                #         else:\n",
    "                #             print(\n",
    "                #                 f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                #             )\n",
    "\n",
    "                #     print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                # print(\"==========================================\")\n",
    "                # print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    alpha_values,\n",
    "                    beta_values,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    f_values,\n",
    "                    tau_values,\n",
    "                    all_holding_costs_0,\n",
    "                    all_holding_costs_1,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1529,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_flexible_beta_with_second_training_16(\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_train,\n",
    "    Qk_hat_df,\n",
    "    training_df,\n",
    "    lambda_beta,\n",
    "    last_beta_total,\n",
    "):\n",
    "\n",
    "    result = __fully_flexible_beta_with_second_training_16(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df,\n",
    "        training_df=training_df,\n",
    "        lambda_beta=lambda_beta,\n",
    "        last_beta_total=last_beta_total,\n",
    "    )\n",
    "    if result is None:\n",
    "        print(f\"找不到最佳解\")\n",
    "        return None, None\n",
    "    else:\n",
    "        (\n",
    "            all_Rs,\n",
    "            all_losses,\n",
    "            all_lefts,\n",
    "            all_profits,\n",
    "            all_operation_profits,\n",
    "            alpha_values,\n",
    "            beta_values,\n",
    "            all_Fs,\n",
    "            all_Q0s,\n",
    "            all_Q1s,\n",
    "            f_values,\n",
    "            tau_values,\n",
    "            holding_costs_0s,\n",
    "            holding_costs_1s,\n",
    "            all_left0s,\n",
    "            all_left1s,\n",
    "            all_lost0s,\n",
    "            all_lost1s,\n",
    "        ) = result\n",
    "\n",
    "        # print(f\"all_Rs: {all_Rs}\")\n",
    "\n",
    "        return make_s3_related_strtegies_result(\n",
    "            all_Rs=all_Rs,\n",
    "            losses=all_losses,\n",
    "            lefts=all_lefts,\n",
    "            profits=all_profits,\n",
    "            operation_profits=all_operation_profits,\n",
    "            alpha_values=alpha_values,\n",
    "            beta_values=beta_values,\n",
    "            F_vars=all_Fs,\n",
    "            Q0_vars=all_Q0s,\n",
    "            Q1_vars=all_Q1s,\n",
    "            f_values=f_values,\n",
    "            tau_values=tau_values,\n",
    "            holding_costs_0s=holding_costs_0s,\n",
    "            holding_costs_1s=holding_costs_1s,\n",
    "            all_left0s=all_left0s,\n",
    "            all_left1s=all_left1s,\n",
    "            all_lost0s=all_lost0s,\n",
    "            all_lost1s=all_lost1s,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S1 - Grid for Fixed F & Fixed Rk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1530,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_fixed_F_fixed_R(\n",
    "    assigned_T,\n",
    "    assigned_F,\n",
    "    cost,\n",
    "    price,\n",
    "    salvage_value,\n",
    "    Qk_hat_df_test,\n",
    "    demand_df_test,\n",
    "    Q_star,\n",
    "):\n",
    "    assigned_R = assigned_T - 2\n",
    "    result, stimulation_result = cal_fixed_F_fixed_R(\n",
    "        Q_star,\n",
    "        assigned_F,\n",
    "        assigned_R,\n",
    "        demand_df_test,\n",
    "        cost,\n",
    "        price,\n",
    "        salvage_value,\n",
    "        Qk_hat_df_test,\n",
    "    )\n",
    "\n",
    "    results_df_1 = pd.DataFrame([result]).sort_values(\n",
    "        by=\"average_profits\", ascending=False\n",
    "    )\n",
    "\n",
    "    return results_df_1, pd.DataFrame(stimulation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S8 - Grid for Fixed F & Fixed Rk(with holding cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1531,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_fixed_F_fixed_R_with_holding_cost(\n",
    "    assigned_T,\n",
    "    assigned_F,\n",
    "    cost,\n",
    "    price,\n",
    "    salvage_value,\n",
    "    Qk_hat_df_test,\n",
    "    demand_df_test,\n",
    "    Q_star,\n",
    "    holding_cost,\n",
    "):\n",
    "\n",
    "    assigned_R = assigned_T - 2\n",
    "    result, stimulation_result = cal_fixed_F_fixed_R_with_holding_cost(\n",
    "        Q_star,\n",
    "        assigned_F,\n",
    "        assigned_R,\n",
    "        demand_df_test,\n",
    "        cost,\n",
    "        price,\n",
    "        salvage_value,\n",
    "        Qk_hat_df_test,\n",
    "        holding_cost,\n",
    "    )\n",
    "\n",
    "    results_df_1 = pd.DataFrame([result]).sort_values(\n",
    "        by=\"average_profits\", ascending=False\n",
    "    )\n",
    "\n",
    "    return results_df_1, pd.DataFrame(stimulation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S2 - Grid for Fixed Rk & Flexible F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1532,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_flexible_F_fixed_R(\n",
    "    assigned_R,\n",
    "    alphas,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_test,\n",
    "    Qk_hat_df_test,\n",
    "    testing_df,\n",
    "):\n",
    "\n",
    "    # ======================= Global Variables =======================\n",
    "\n",
    "    # Category 1 - Some variables that is important to future work\n",
    "    K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "    n = len(demand_df_test)\n",
    "\n",
    "    # Initialize lists or numpy arrays to replace Gurobi variables\n",
    "    Sold_0s = np.zeros(n)\n",
    "    Left_0s = np.zeros(n)\n",
    "    Lost_0s = np.zeros(n)\n",
    "    Sold_1s = np.zeros(n)\n",
    "    Left_1s = np.zeros(n)\n",
    "    Lost_1s = np.zeros(n)\n",
    "    all_holding_costs_0 = np.zeros(n)\n",
    "    all_holding_costs_1 = np.zeros(n)\n",
    "    profits_vars = np.zeros(n)\n",
    "\n",
    "    # 1-2. Arrays for demand calculation up to certain periods\n",
    "    total_demand_up_to_k_minus_1_vars = np.zeros(n)\n",
    "    total_demand_from_k_to_T_vars = np.zeros(n)\n",
    "    Q1_plus_lefts = np.zeros(n)\n",
    "\n",
    "    # 2. Variables for Model 2: Optimal Fraction Model\n",
    "    f_vars = np.zeros(n)\n",
    "    F_vars = np.zeros(n)  # Assuming values will be between 0 and 1\n",
    "    Q0_vars = np.zeros(n)  # Replace Q_star with a specific value as needed\n",
    "\n",
    "    # 3. Variables for Model 3: Optimal Order Time Model (2D array for binary values)\n",
    "    R_vars = np.zeros((n, K), dtype=int)  # Use dtype=int to represent binary 0/1 values\n",
    "\n",
    "    # 4. Variables for Model 4: Re-estimate order-up-to-level\n",
    "    Q1_vars = np.zeros(n)\n",
    "    Q_hats = np.zeros(n)\n",
    "    Q_hat_adjusteds = np.zeros(n)\n",
    "\n",
    "    # ======================= Start Stimulation! =======================\n",
    "\n",
    "    for i, row in demand_df_test.iterrows():\n",
    "\n",
    "        ### Data for this stimulation\n",
    "        demand_row = demand_df_test.iloc[i]\n",
    "        Qk_hat_df_test_row = Qk_hat_df_test.iloc[i]\n",
    "        X_data = testing_df.iloc[i].tolist()\n",
    "        X_data.append(1)\n",
    "\n",
    "        # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "        ### 用線性回歸計算F_var\n",
    "        f_vars[i] = sum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "        F_vars[i] = 1 / (1 + np.exp(-(f_vars[i])))\n",
    "        print(f\"f_vars[i]: {f_vars[i]}, F_vars[i]: {F_vars[i]}\")\n",
    "        Q0_vars[i] = F_vars[i] * Q_star\n",
    "\n",
    "        # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "        # Ensure only one `R` is set to 1 in each row by setting `assigned_R` to 1 and all others to 0\n",
    "        R_vars[i, assigned_R] = 1\n",
    "\n",
    "        # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "        Q_hats[i] = sum(\n",
    "            R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
    "        )\n",
    "        Q_hat_adjusteds[i] = Q_hats[i] - Q0_vars[i]\n",
    "        Q1_vars[i] = max(Q_hat_adjusteds[i], 0)\n",
    "\n",
    "        # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "        # Calculate the demand up to k-1\n",
    "        total_demand_up_to_k_minus_1 = sum(\n",
    "            R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_up_to_k_minus_1_vars[i] = total_demand_up_to_k_minus_1\n",
    "\n",
    "        # Calculate the demand from k to T\n",
    "        total_demand_from_k_to_T = sum(\n",
    "            R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars[i] = total_demand_from_k_to_T\n",
    "\n",
    "        Sold_0s[i] = min(total_demand_up_to_k_minus_1_vars[i], Q0_vars[i])\n",
    "        Left_0s[i] = max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "        Lost_0s[i] = max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "        Q1_plus_lefts[i] = Q1_vars[i] + Left_0s[i]\n",
    "\n",
    "        Sold_1s[i] = min(total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i])\n",
    "        Left_1s[i] = max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "        Lost_1s[i] = max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "\n",
    "        # all_holding_costs_0[i] = (\n",
    "        #     (Q0_vars[i] + Left_0s[i] + Q1_vars[i]) * ((assigned_R + 2) - 1) / 2\n",
    "        # )\n",
    "        # all_holding_costs_1[i] = (\n",
    "        #     (Q1_vars[i] + Left_0s[i] + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "        # )\n",
    "\n",
    "        # profits_vars[i] = (\n",
    "        #     (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue from sales\n",
    "        #     - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "        #     - (cost - salvage_value) * Left_1s[i]\n",
    "        # )\n",
    "\n",
    "        profits_vars[i] = (\n",
    "            (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue from sales\n",
    "            - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "            - (cost - salvage_value) * (Left_0s[i] + Left_1s[i])  # 加上 Left_0s[i]\n",
    "        )\n",
    "\n",
    "    # Calculate the average profit\n",
    "    print(f\"assigned_R: {assigned_R}\")\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"average_profits\": [np.mean(profits_vars)],\n",
    "            \"average_loss_penalty\": [\n",
    "                np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))\n",
    "            ],\n",
    "            \"average_left_penalty\": [\n",
    "                np.mean((cost - salvage_value) * (Left_0s[i] + Left_1s[i]))\n",
    "            ],\n",
    "            \"average_loss\": [np.mean((Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"average_left\": [np.mean((Left_0s[i] + Left_1s[i]))],\n",
    "            \"alpha_values\": [alphas],\n",
    "            \"R(T)\": assigned_R + 2,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    stimulation_result = pd.DataFrame(\n",
    "        {\n",
    "            \"F\": F_vars,\n",
    "            \"R(T)\": assigned_R + 2,\n",
    "            \"Sold_0\": Sold_0s,\n",
    "            \"Left_0\": Left_0s,\n",
    "            \"Lost_0\": Lost_0s,\n",
    "            \"Sold_1\": Sold_1s,\n",
    "            \"Left_1\": Left_1s,\n",
    "            \"Lost_1\": Lost_1s,\n",
    "            \"profits\": profits_vars,\n",
    "            \"Q0\": Q0_vars,\n",
    "            \"Q1\": Q1_vars,\n",
    "            \"hc0\": all_holding_costs_0,\n",
    "            \"hc1\": all_holding_costs_1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return results_df, stimulation_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3 - Grid for Fixed F & Flexible Rk(原s6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1533,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_fixed_F_flexible_R(\n",
    "    assigned_F,\n",
    "    betas,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_test,\n",
    "    Qk_hat_df_test,\n",
    "    testing_df,\n",
    "):\n",
    "\n",
    "    # ======================= Global Variables =======================\n",
    "\n",
    "    # Category 1 - Some variables that is important to future work\n",
    "    K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "    n = len(demand_df_test)\n",
    "\n",
    "    # Initialize lists or numpy arrays to replace Gurobi variables\n",
    "    Sold_0s = np.zeros(n)\n",
    "    Left_0s = np.zeros(n)\n",
    "    Lost_0s = np.zeros(n)\n",
    "    Sold_1s = np.zeros(n)\n",
    "    Left_1s = np.zeros(n)\n",
    "    Lost_1s = np.zeros(n)\n",
    "    all_holding_costs_0 = np.zeros(n)\n",
    "    all_holding_costs_1 = np.zeros(n)\n",
    "    profits_vars = np.zeros(n)\n",
    "\n",
    "    # 1-2. Arrays for demand calculation up to certain periods\n",
    "    total_demand_up_to_k_minus_1_vars = np.zeros(n)\n",
    "    total_demand_from_k_to_T_vars = np.zeros(n)\n",
    "    Q1_plus_lefts = np.zeros(n)\n",
    "\n",
    "    # 2. Variables for Model 2: Optimal Fraction Model\n",
    "    f_vars = np.zeros(n)\n",
    "    F_vars = np.zeros(n)  # Assuming values will be between 0 and 1\n",
    "    Q0_vars = np.zeros(n)  # Replace Q_star with a specific value as needed\n",
    "\n",
    "    # 3. Variables for Model 3: Optimal Order Time Model (2D array for binary values)\n",
    "    tau_vars = np.zeros((n, K))\n",
    "    exp_tau_vars = np.zeros((n, K))\n",
    "    r_vars = np.zeros((n, K))\n",
    "    max_r_index = np.zeros(n, dtype=int)\n",
    "    R_vars = np.zeros(\n",
    "        (n, K), dtype=int\n",
    "    )  # Binary array to select one optimal replenishment time\n",
    "\n",
    "    # 4. Variables for Model 4: Re-estimate order-up-to-level\n",
    "    Q1_vars = np.zeros(n)\n",
    "    Q_hats = np.zeros(n)\n",
    "    Q_hat_adjusteds = np.zeros(n)\n",
    "\n",
    "    # ======================= Start Stimulation! =======================\n",
    "\n",
    "    for i, row in demand_df_test.iterrows():\n",
    "\n",
    "        ### Data for this stimulation\n",
    "        demand_row = demand_df_test.iloc[i]\n",
    "        Qk_hat_df_test_row = Qk_hat_df_test.iloc[i]\n",
    "        X_data = testing_df.iloc[i].tolist()\n",
    "        X_data.append(1)\n",
    "\n",
    "        # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "        F_vars[i] = assigned_F\n",
    "        Q0_vars[i] = F_vars[i] * Q_star\n",
    "\n",
    "        # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "        for k in range(K):\n",
    "            tau_vars[i, k] = betas[k, 0]\n",
    "            exp_tau_vars[i, k] = np.exp(-tau_vars[i, k])  # Calculate exp(-tau_vars)\n",
    "\n",
    "        sum_exp_tau_vars = np.sum(\n",
    "            exp_tau_vars[i]\n",
    "        )  # Sum of all exp_tau_vars for normalization\n",
    "\n",
    "        for k in range(K):\n",
    "            r_vars[i, k] = exp_tau_vars[i, k] / sum_exp_tau_vars\n",
    "\n",
    "        max_r_index[i] = np.argmax(\n",
    "            r_vars[i]\n",
    "        )  # Find index of the maximum value in r_vars\n",
    "        R_vars[i, max_r_index[i]] = (\n",
    "            1  # Set only this R_vars element to 1, ensuring only one is set\n",
    "        )\n",
    "\n",
    "        # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "        Q_hats[i] = sum(\n",
    "            R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
    "        )\n",
    "        Q_hat_adjusteds[i] = Q_hats[i] - Q0_vars[i]\n",
    "        Q1_vars[i] = max(Q_hat_adjusteds[i], 0)\n",
    "\n",
    "        # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "        # Calculate the demand up to k-1\n",
    "        total_demand_up_to_k_minus_1 = sum(\n",
    "            R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_up_to_k_minus_1_vars[i] = total_demand_up_to_k_minus_1\n",
    "\n",
    "        # Calculate the demand from k to T\n",
    "        total_demand_from_k_to_T = sum(\n",
    "            R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars[i] = total_demand_from_k_to_T\n",
    "\n",
    "        Sold_0s[i] = min(total_demand_up_to_k_minus_1_vars[i], Q0_vars[i])\n",
    "        Left_0s[i] = max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "        Lost_0s[i] = max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "        Q1_plus_lefts[i] = Q1_vars[i] + Left_0s[i]\n",
    "\n",
    "        Sold_1s[i] = min(total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i])\n",
    "        Left_1s[i] = max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "        Lost_1s[i] = max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "\n",
    "        assigned_R = max_r_index[i]\n",
    "\n",
    "        all_holding_costs_0[i] = (\n",
    "            (Q0_vars[i] + Left_0s[i] + Q1_vars[i]) * ((assigned_R + 2) - 1) / 2\n",
    "        )\n",
    "        all_holding_costs_1[i] = (\n",
    "            (Q1_vars[i] + Left_0s[i] + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "        )\n",
    "\n",
    "        profits_vars[i] = (\n",
    "            (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue from sales\n",
    "            - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "            - (cost - salvage_value) * Left_1s[i]\n",
    "            - holding_cost * (all_holding_costs_0[i] + all_holding_costs_1[i])\n",
    "        )\n",
    "\n",
    "    # Calculate the average profit\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"average_profits\": [np.mean(profits_vars)],\n",
    "            \"average_loss\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"average_left\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"beta_balues\": [betas],\n",
    "            \"F\": [assigned_F],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    stimulation_result = pd.DataFrame(\n",
    "        {\n",
    "            \"F\": F_vars,\n",
    "            \"R(T)\": [x + 2 for x in max_r_index],\n",
    "            \"Sold_0\": Sold_0s,\n",
    "            \"Left_0\": Left_0s,\n",
    "            \"Lost_0\": Lost_0s,\n",
    "            \"Sold_1\": Sold_1s,\n",
    "            \"Left_1\": Left_1s,\n",
    "            \"Lost_1\": Lost_1s,\n",
    "            \"profits\": profits_vars,\n",
    "            \"Q0\": Q0_vars,\n",
    "            \"Q1\": Q1_vars,\n",
    "            \"hc0\": all_holding_costs_0,\n",
    "            \"hc1\": all_holding_costs_1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return results_df, stimulation_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully flexible F & Rk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S5 - Simple beta with softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1534,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_fully_flexible_simple_beta_with_softmax_5(\n",
    "    alphas,\n",
    "    betas,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_test,\n",
    "    Qk_hat_df_test,\n",
    "    testing_df,\n",
    "):\n",
    "\n",
    "    # ======================= Global Variables =======================\n",
    "\n",
    "    # Category 1 - Some variables that is important to future work\n",
    "    K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "    n = len(demand_df_test)\n",
    "\n",
    "    # Initialize lists or numpy arrays to replace Gurobi variables\n",
    "    Sold_0s = np.zeros(n)\n",
    "    Left_0s = np.zeros(n)\n",
    "    Lost_0s = np.zeros(n)\n",
    "    Sold_1s = np.zeros(n)\n",
    "    Left_1s = np.zeros(n)\n",
    "    Lost_1s = np.zeros(n)\n",
    "    all_holding_costs_0 = np.zeros(n)\n",
    "    all_holding_costs_1 = np.zeros(n)\n",
    "    profits_vars = np.zeros(n)\n",
    "\n",
    "    # 1-2. Arrays for demand calculation up to certain periods\n",
    "    total_demand_up_to_k_minus_1_vars = np.zeros(n)\n",
    "    total_demand_from_k_to_T_vars = np.zeros(n)\n",
    "    Q1_plus_lefts = np.zeros(n)\n",
    "\n",
    "    # 2. Variables for Model 2: Optimal Fraction Model\n",
    "    f_vars = np.zeros(n)\n",
    "    F_vars = np.zeros(n)  # Assuming values will be between 0 and 1\n",
    "    Q0_vars = np.zeros(n)  # Replace Q_star with a specific value as needed\n",
    "\n",
    "    # 3. Variables for Model 3: Optimal Order Time Model (2D array for binary values)\n",
    "    tau_vars = np.zeros((n, K))\n",
    "    exp_tau_vars = np.zeros((n, K))\n",
    "    r_vars = np.zeros((n, K))\n",
    "    max_r_index = np.zeros(n, dtype=int)\n",
    "    R_vars = np.zeros(\n",
    "        (n, K), dtype=int\n",
    "    )  # Binary array to select one optimal replenishment time\n",
    "\n",
    "    # 4. Variables for Model 4: Re-estimate order-up-to-level\n",
    "    Q1_vars = np.zeros(n)\n",
    "    Q_hats = np.zeros(n)\n",
    "    Q_hat_adjusteds = np.zeros(n)\n",
    "\n",
    "    # ======================= Start Stimulation! =======================\n",
    "\n",
    "    for i, row in demand_df_test.iterrows():\n",
    "\n",
    "        ### Data for this stimulation\n",
    "        demand_row = demand_df_test.iloc[i]\n",
    "        Qk_hat_df_test_row = Qk_hat_df_test.iloc[i]\n",
    "        X_data = testing_df.iloc[i].tolist()\n",
    "        X_data.append(1)\n",
    "\n",
    "        # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "        ### 用線性回歸計算F_var\n",
    "        f_vars[i] = sum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "        F_vars[i] = 1 / (1 + np.exp(-(f_vars[i])))\n",
    "        Q0_vars[i] = F_vars[i] * Q_star\n",
    "\n",
    "        # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "        for k in range(K):\n",
    "            tau_vars[i, k] = betas[k, 0]\n",
    "            exp_tau_vars[i, k] = np.exp(-tau_vars[i, k])  # Calculate exp(-tau_vars)\n",
    "\n",
    "        sum_exp_tau_vars = np.sum(\n",
    "            exp_tau_vars[i]\n",
    "        )  # Sum of all exp_tau_vars for normalization\n",
    "\n",
    "        for k in range(K):\n",
    "            r_vars[i, k] = exp_tau_vars[i, k] / sum_exp_tau_vars\n",
    "\n",
    "        max_r_index[i] = np.argmax(\n",
    "            r_vars[i]\n",
    "        )  # Find index of the maximum value in r_vars\n",
    "        R_vars[i, max_r_index[i]] = (\n",
    "            1  # Set only this R_vars element to 1, ensuring only one is set\n",
    "        )\n",
    "\n",
    "        # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "        Q_hats[i] = sum(\n",
    "            R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
    "        )\n",
    "        Q_hat_adjusteds[i] = Q_hats[i] - Q0_vars[i]\n",
    "        Q1_vars[i] = max(Q_hat_adjusteds[i], 0)\n",
    "\n",
    "        # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "        # Calculate the demand up to k-1\n",
    "        total_demand_up_to_k_minus_1 = sum(\n",
    "            R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_up_to_k_minus_1_vars[i] = total_demand_up_to_k_minus_1\n",
    "\n",
    "        # Calculate the demand from k to T\n",
    "        total_demand_from_k_to_T = sum(\n",
    "            R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars[i] = total_demand_from_k_to_T\n",
    "\n",
    "        Sold_0s[i] = min(total_demand_up_to_k_minus_1_vars[i], Q0_vars[i])\n",
    "        Left_0s[i] = max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "        Lost_0s[i] = max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "        Q1_plus_lefts[i] = Q1_vars[i] + Left_0s[i]\n",
    "\n",
    "        Sold_1s[i] = min(total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i])\n",
    "        Left_1s[i] = max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "        Lost_1s[i] = max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "\n",
    "        assigned_R = max_r_index[i]\n",
    "\n",
    "        all_holding_costs_0[i] = (\n",
    "            (Q0_vars[i] + Left_0s[i] + Q1_vars[i]) * ((assigned_R + 2) - 1) / 2\n",
    "        )\n",
    "        all_holding_costs_1[i] = (\n",
    "            (Q1_vars[i] + Left_0s[i] + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "        )\n",
    "\n",
    "        profits_vars[i] = (\n",
    "            (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue from sales\n",
    "            - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "            - (cost - salvage_value) * Left_1s[i]\n",
    "            - holding_cost * (all_holding_costs_0[i] + all_holding_costs_1[i])\n",
    "        )\n",
    "\n",
    "    # Calculate the average profit\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"average_profits\": [np.mean(profits_vars)],\n",
    "            \"average_loss\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"average_left\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"alpha_values\": [alphas],\n",
    "            \"beta_balues\": [betas],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    stimulation_result = pd.DataFrame(\n",
    "        {\n",
    "            \"F\": F_vars,\n",
    "            \"R(T)\": [x + 2 for x in max_r_index],\n",
    "            \"Sold_0\": Sold_0s,\n",
    "            \"Left_0\": Left_0s,\n",
    "            \"Lost_0\": Lost_0s,\n",
    "            \"Sold_1\": Sold_1s,\n",
    "            \"Left_1\": Left_1s,\n",
    "            \"Lost_1\": Lost_1s,\n",
    "            \"profits\": profits_vars,\n",
    "            \"Q0\": Q0_vars,\n",
    "            \"Q1\": Q1_vars,\n",
    "            \"hc0\": all_holding_costs_0,\n",
    "            \"hc1\": all_holding_costs_1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return results_df, stimulation_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S6 - Simple beta and softmax with T is 1 - sum(T-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1535,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_fully_flexible_simple_beta_with_softmax_6(\n",
    "    alphas,\n",
    "    betas,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_test,\n",
    "    Qk_hat_df_test,\n",
    "    testing_df,\n",
    "):\n",
    "\n",
    "    # ======================= Global Variables =======================\n",
    "\n",
    "    # Category 1 - Some variables that is important to future work\n",
    "    K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "    n = len(demand_df_test)\n",
    "\n",
    "    # Initialize lists or numpy arrays to replace Gurobi variables\n",
    "    Sold_0s = np.zeros(n)\n",
    "    Left_0s = np.zeros(n)\n",
    "    Lost_0s = np.zeros(n)\n",
    "    Sold_1s = np.zeros(n)\n",
    "    Left_1s = np.zeros(n)\n",
    "    Lost_1s = np.zeros(n)\n",
    "    all_holding_costs_0 = np.zeros(n)\n",
    "    all_holding_costs_1 = np.zeros(n)\n",
    "    profits_vars = np.zeros(n)\n",
    "\n",
    "    # 1-2. Arrays for demand calculation up to certain periods\n",
    "    total_demand_up_to_k_minus_1_vars = np.zeros(n)\n",
    "    total_demand_from_k_to_T_vars = np.zeros(n)\n",
    "    Q1_plus_lefts = np.zeros(n)\n",
    "\n",
    "    # 2. Variables for Model 2: Optimal Fraction Model\n",
    "    f_vars = np.zeros(n)\n",
    "    F_vars = np.zeros(n)  # Assuming values will be between 0 and 1\n",
    "    Q0_vars = np.zeros(n)  # Replace Q_star with a specific value as needed\n",
    "\n",
    "    # 3. Variables for Model 3: Optimal Order Time Model (2D array for binary values)\n",
    "    tau_vars = np.zeros((n, K - 1))\n",
    "    exp_tau_vars = np.zeros((n, K - 1))\n",
    "    r_vars = np.zeros((n, K))\n",
    "    max_r_index = np.zeros(n, dtype=int)\n",
    "    R_vars = np.zeros(\n",
    "        (n, K), dtype=int\n",
    "    )  # Binary array to select one optimal replenishment time\n",
    "\n",
    "    # 4. Variables for Model 4: Re-estimate order-up-to-level\n",
    "    Q1_vars = np.zeros(n)\n",
    "    Q_hats = np.zeros(n)\n",
    "    Q_hat_adjusteds = np.zeros(n)\n",
    "\n",
    "    # ======================= Start Stimulation! =======================\n",
    "\n",
    "    for i, row in demand_df_test.iterrows():\n",
    "\n",
    "        ### Data for this stimulation\n",
    "        demand_row = demand_df_test.iloc[i]\n",
    "        Qk_hat_df_test_row = Qk_hat_df_test.iloc[i]\n",
    "        X_data = testing_df.iloc[i].tolist()\n",
    "        X_data.append(1)\n",
    "\n",
    "        # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "        ### 用線性回歸計算F_var\n",
    "        f_vars[i] = sum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "        F_vars[i] = 1 / (1 + np.exp(-(f_vars[i])))\n",
    "        Q0_vars[i] = F_vars[i] * Q_star\n",
    "\n",
    "        # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "        # Step 1: Calculate tau_vars based on betas\n",
    "        for p in range(K - 1):\n",
    "            tau_vars[i, p] = betas[p, 0]  # Only intercept term is used\n",
    "            exp_tau_vars[i, p] = np.exp(-tau_vars[i, p])  # Calculate exp(-tau_vars)\n",
    "\n",
    "        # Step 2: Calculate softmax-normalized r_vars\n",
    "        sum_exp_tau_vars = (\n",
    "            np.sum(exp_tau_vars[i]) + 1\n",
    "        )  # Adding 1 as in the softmax denominator for the last element\n",
    "\n",
    "        for p in range(K):\n",
    "            if p == K - 1:\n",
    "                # Set the last r_vars element to ensure the sum of all r_vars elements is 1\n",
    "                r_vars[i, p] = 1 - np.sum(r_vars[i, : K - 1])\n",
    "            else:\n",
    "                r_vars[i, p] = exp_tau_vars[i, p] / sum_exp_tau_vars\n",
    "\n",
    "        # Step 3: Find the maximum r_vars element and set corresponding R_vars to 1\n",
    "        max_r_index[i] = np.argmax(\n",
    "            r_vars[i]\n",
    "        )  # Find index of the maximum value in r_vars\n",
    "        R_vars[i, max_r_index[i]] = (\n",
    "            1  # Set only this R_vars element to 1, ensuring only one is set\n",
    "        )\n",
    "\n",
    "        # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "        Q_hats[i] = sum(\n",
    "            R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
    "        )\n",
    "        Q_hat_adjusteds[i] = Q_hats[i] - Q0_vars[i]\n",
    "        Q1_vars[i] = max(Q_hat_adjusteds[i], 0)\n",
    "\n",
    "        # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "        # Calculate the demand up to k-1\n",
    "        total_demand_up_to_k_minus_1 = sum(\n",
    "            R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_up_to_k_minus_1_vars[i] = total_demand_up_to_k_minus_1\n",
    "\n",
    "        # Calculate the demand from k to T\n",
    "        total_demand_from_k_to_T = sum(\n",
    "            R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars[i] = total_demand_from_k_to_T\n",
    "\n",
    "        Sold_0s[i] = min(total_demand_up_to_k_minus_1_vars[i], Q0_vars[i])\n",
    "        Left_0s[i] = max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "        Lost_0s[i] = max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "        Q1_plus_lefts[i] = Q1_vars[i] + Left_0s[i]\n",
    "\n",
    "        Sold_1s[i] = min(total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i])\n",
    "        Left_1s[i] = max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "        Lost_1s[i] = max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "\n",
    "        assigned_R = max_r_index[i]\n",
    "\n",
    "        # all_holding_costs_0[i] = (\n",
    "        #     (Q0_vars[i] + Left_0s[i] + Q1_vars[i]) * ((assigned_R + 2) - 1) / 2\n",
    "        # )\n",
    "        # all_holding_costs_1[i] = (\n",
    "        #     (Q1_vars[i] + Left_0s[i] + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "        # )\n",
    "\n",
    "        profits_vars[i] = (\n",
    "            (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue from sales\n",
    "            - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "            - (cost - salvage_value) * Left_1s[i]\n",
    "            # - holding_cost * (all_holding_costs_0[i] + all_holding_costs_1[i])\n",
    "        )\n",
    "\n",
    "    # Calculate the average profit\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"average_profits\": [np.mean(profits_vars)],\n",
    "            \"average_loss\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"average_left\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"alpha_values\": [alphas],\n",
    "            \"beta_balues\": [betas],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    stimulation_result = pd.DataFrame(\n",
    "        {\n",
    "            \"F\": F_vars,\n",
    "            \"R(T)\": [x + 2 for x in max_r_index],\n",
    "            \"Sold_0\": Sold_0s,\n",
    "            \"Left_0\": Left_0s,\n",
    "            \"Lost_0\": Lost_0s,\n",
    "            \"Sold_1\": Sold_1s,\n",
    "            \"Left_1\": Left_1s,\n",
    "            \"Lost_1\": Lost_1s,\n",
    "            \"profits\": profits_vars,\n",
    "            \"Q0\": Q0_vars,\n",
    "            \"Q1\": Q1_vars,\n",
    "            \"hc0\": all_holding_costs_0,\n",
    "            \"hc1\": all_holding_costs_1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return results_df, stimulation_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S7 - Simple beat and softmax with T is 1 - sum(T-1) & tau with f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1536,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_fully_flexible_simple_beta_with_softmax_7(\n",
    "    alphas,\n",
    "    betas,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_test,\n",
    "    Qk_hat_df_test,\n",
    "    testing_df,\n",
    "):\n",
    "\n",
    "    # ======================= Global Variables =======================\n",
    "\n",
    "    # Category 1 - Some variables that is important to future work\n",
    "    K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "    n = len(demand_df_test)\n",
    "\n",
    "    # Initialize lists or numpy arrays to replace Gurobi variables\n",
    "    Sold_0s = np.zeros(n)\n",
    "    Left_0s = np.zeros(n)\n",
    "    Lost_0s = np.zeros(n)\n",
    "    Sold_1s = np.zeros(n)\n",
    "    Left_1s = np.zeros(n)\n",
    "    Lost_1s = np.zeros(n)\n",
    "    all_holding_costs_0 = np.zeros(n)\n",
    "    all_holding_costs_1 = np.zeros(n)\n",
    "    profits_vars = np.zeros(n)\n",
    "\n",
    "    # 1-2. Arrays for demand calculation up to certain periods\n",
    "    total_demand_up_to_k_minus_1_vars = np.zeros(n)\n",
    "    total_demand_from_k_to_T_vars = np.zeros(n)\n",
    "    Q1_plus_lefts = np.zeros(n)\n",
    "\n",
    "    # 2. Variables for Model 2: Optimal Fraction Model\n",
    "    f_vars = np.zeros(n)\n",
    "    F_vars = np.zeros(n)  # Assuming values will be between 0 and 1\n",
    "    Q0_vars = np.zeros(n)  # Replace Q_star with a specific value as needed\n",
    "\n",
    "    # 3. Variables for Model 3: Optimal Order Time Model (2D array for binary values)\n",
    "    tau_vars = np.zeros((n, K - 1))\n",
    "    exp_tau_vars = np.zeros((n, K - 1))\n",
    "    r_vars = np.zeros((n, K))\n",
    "    max_r_index = np.zeros(n, dtype=int)\n",
    "    R_vars = np.zeros(\n",
    "        (n, K), dtype=int\n",
    "    )  # Binary array to select one optimal replenishment time\n",
    "\n",
    "    # 4. Variables for Model 4: Re-estimate order-up-to-level\n",
    "    Q1_vars = np.zeros(n)\n",
    "    Q_hats = np.zeros(n)\n",
    "    Q_hat_adjusteds = np.zeros(n)\n",
    "\n",
    "    # ======================= Start Stimulation! =======================\n",
    "\n",
    "    for i, row in demand_df_test.iterrows():\n",
    "\n",
    "        ### Data for this stimulation\n",
    "        demand_row = demand_df_test.iloc[i]\n",
    "        Qk_hat_df_test_row = Qk_hat_df_test.iloc[i]\n",
    "        X_data = testing_df.iloc[i].tolist()\n",
    "        X_data.append(1)\n",
    "\n",
    "        # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "        ### 用線性回歸計算F_var\n",
    "        f_vars[i] = sum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "        F_vars[i] = 1 / (1 + np.exp(-(f_vars[i])))\n",
    "        Q0_vars[i] = F_vars[i] * Q_star\n",
    "\n",
    "        # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "        # Step 1: Calculate tau_vars based on betas and f_vars\n",
    "        for p in range(K - 1):\n",
    "            tau_vars[i, p] = betas[p, 0] + f_vars[i]\n",
    "            exp_tau_vars[i, p] = np.exp(-tau_vars[i, p])  # Calculate exp(-tau_vars)\n",
    "\n",
    "        # Step 2: Calculate the sum of exp_tau_vars for softmax normalization\n",
    "        sum_exp_tau_vars = np.sum(exp_tau_vars[i]) + 1  # Adding 1 for the last r_var\n",
    "\n",
    "        # Step 3: Calculate r_vars with softmax normalization\n",
    "        for p in range(K):\n",
    "            if p == K - 1:\n",
    "                # Last r_var element ensures all r_vars sum to 1\n",
    "                r_vars[i, p] = 1 - np.sum(r_vars[i, : K - 1])\n",
    "            else:\n",
    "                r_vars[i, p] = exp_tau_vars[i, p] / sum_exp_tau_vars\n",
    "\n",
    "        # Step 4: Find the index of the maximum r_vars and set corresponding R_vars to 1\n",
    "        max_r_index[i] = np.argmax(\n",
    "            r_vars[i]\n",
    "        )  # Find index of the maximum value in r_vars\n",
    "        R_vars[i, max_r_index[i]] = (\n",
    "            1  # Set only this R_vars element to 1, ensuring only one is set\n",
    "        )\n",
    "\n",
    "        # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "        Q_hats[i] = sum(\n",
    "            R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
    "        )\n",
    "        Q_hat_adjusteds[i] = Q_hats[i] - Q0_vars[i]\n",
    "        Q1_vars[i] = max(Q_hat_adjusteds[i], 0)\n",
    "\n",
    "        # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "        # Calculate the demand up to k-1\n",
    "        total_demand_up_to_k_minus_1 = sum(\n",
    "            R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_up_to_k_minus_1_vars[i] = total_demand_up_to_k_minus_1\n",
    "\n",
    "        # Calculate the demand from k to T\n",
    "        total_demand_from_k_to_T = sum(\n",
    "            R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars[i] = total_demand_from_k_to_T\n",
    "\n",
    "        Sold_0s[i] = min(total_demand_up_to_k_minus_1_vars[i], Q0_vars[i])\n",
    "        Left_0s[i] = max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "        Lost_0s[i] = max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "        Q1_plus_lefts[i] = Q1_vars[i] + Left_0s[i]\n",
    "\n",
    "        Sold_1s[i] = min(total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i])\n",
    "        Left_1s[i] = max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "        Lost_1s[i] = max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "\n",
    "        assigned_R = max_r_index[i]\n",
    "\n",
    "        all_holding_costs_0[i] = (\n",
    "            (Q0_vars[i] + Left_0s[i] + Q1_vars[i]) * ((assigned_R + 2) - 1) / 2\n",
    "        )\n",
    "        all_holding_costs_1[i] = (\n",
    "            (Q1_vars[i] + Left_0s[i] + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "        )\n",
    "\n",
    "        profits_vars[i] = (\n",
    "            (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue from sales\n",
    "            - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "            - (cost - salvage_value) * Left_1s[i]\n",
    "            - holding_cost * (all_holding_costs_0[i] + all_holding_costs_1[i])\n",
    "        )\n",
    "\n",
    "    # Calculate the average profit\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"average_profits\": [np.mean(profits_vars)],\n",
    "            \"average_loss\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"average_left\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"alpha_values\": [alphas],\n",
    "            \"beta_balues\": [betas],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    stimulation_result = pd.DataFrame(\n",
    "        {\n",
    "            \"F\": F_vars,\n",
    "            \"R(T)\": [x + 2 for x in max_r_index],\n",
    "            \"Sold_0\": Sold_0s,\n",
    "            \"Left_0\": Left_0s,\n",
    "            \"Lost_0\": Lost_0s,\n",
    "            \"Sold_1\": Sold_1s,\n",
    "            \"Left_1\": Left_1s,\n",
    "            \"Lost_1\": Lost_1s,\n",
    "            \"profits\": profits_vars,\n",
    "            \"Q0\": Q0_vars,\n",
    "            \"Q1\": Q1_vars,\n",
    "            \"hc0\": all_holding_costs_0,\n",
    "            \"hc1\": all_holding_costs_1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return results_df, stimulation_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S4 - Beta with softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1537,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_fully_flexible_beta_with_softmax_4(\n",
    "    alphas,\n",
    "    betas,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_test,\n",
    "    Qk_hat_df_test,\n",
    "    testing_df,\n",
    "):\n",
    "\n",
    "    # ======================= Global Variables =======================\n",
    "\n",
    "    # Category 1 - Some variables that is important to future work\n",
    "    K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "    n = len(demand_df_test)\n",
    "\n",
    "    # Initialize lists or numpy arrays to replace Gurobi variables\n",
    "    Sold_0s = np.zeros(n)\n",
    "    Left_0s = np.zeros(n)\n",
    "    Lost_0s = np.zeros(n)\n",
    "    Sold_1s = np.zeros(n)\n",
    "    Left_1s = np.zeros(n)\n",
    "    Lost_1s = np.zeros(n)\n",
    "    all_holding_costs_0 = np.zeros(n)\n",
    "    all_holding_costs_1 = np.zeros(n)\n",
    "    profits_vars = np.zeros(n)\n",
    "\n",
    "    # 1-2. Arrays for demand calculation up to certain periods\n",
    "    total_demand_up_to_k_minus_1_vars = np.zeros(n)\n",
    "    total_demand_from_k_to_T_vars = np.zeros(n)\n",
    "    Q1_plus_lefts = np.zeros(n)\n",
    "\n",
    "    # 2. Variables for Model 2: Optimal Fraction Model\n",
    "    f_vars = np.zeros(n)\n",
    "    F_vars = np.zeros(n)  # Assuming values will be between 0 and 1\n",
    "    Q0_vars = np.zeros(n)  # Replace Q_star with a specific value as needed\n",
    "\n",
    "    # 3. Variables for Model 3: Optimal Order Time Model (2D array for binary values)\n",
    "    tau_vars = np.zeros((n, K))\n",
    "    exp_tau_vars = np.zeros((n, K))\n",
    "    r_vars = np.zeros((n, K))\n",
    "    max_r_index = np.zeros(n, dtype=int)\n",
    "    R_vars = np.zeros(\n",
    "        (n, K), dtype=int\n",
    "    )  # Binary array to select one optimal replenishment time\n",
    "\n",
    "    # 4. Variables for Model 4: Re-estimate order-up-to-level\n",
    "    Q1_vars = np.zeros(n)\n",
    "    Q_hats = np.zeros(n)\n",
    "    Q_hat_adjusteds = np.zeros(n)\n",
    "\n",
    "    # ======================= Start Stimulation! =======================\n",
    "\n",
    "    for i, row in demand_df_test.iterrows():\n",
    "\n",
    "        ### Data for this stimulation\n",
    "        demand_row = demand_df_test.iloc[i]\n",
    "        Qk_hat_df_test_row = Qk_hat_df_test.iloc[i]\n",
    "        X_data = testing_df.iloc[i].tolist()\n",
    "        X_data.append(1)\n",
    "\n",
    "        # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "        ### 用線性回歸計算F_var\n",
    "        f_vars[i] = sum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "        F_vars[i] = 1 / (1 + np.exp(-(f_vars[i])))\n",
    "        Q0_vars[i] = F_vars[i] * Q_star\n",
    "\n",
    "        # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "        # Step 1: Calculate tau_vars as a linear combination of X_data and betas\n",
    "        for k in range(K):\n",
    "            tau_vars[i, k] = sum(\n",
    "                X_data[j] * betas[k, j] for j in range(features_num + 1)\n",
    "            )\n",
    "\n",
    "        # Step 2: Calculate the exponentials of tau_vars\n",
    "        exp_tau_vars[i] = np.exp(tau_vars[i])\n",
    "\n",
    "        # Step 3: Softmax normalization\n",
    "        sum_exp_tau = np.sum(exp_tau_vars[i])  # Sum of exponentials for normalization\n",
    "        r_vars[i] = exp_tau_vars[i] / sum_exp_tau  # Normalize to get softmax\n",
    "\n",
    "        max_r_index[i] = np.argmax(r_vars[i])\n",
    "        R_vars[i, max_r_index[i]] = 1\n",
    "\n",
    "        # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "        Q_hats[i] = sum(\n",
    "            R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
    "        )\n",
    "        Q_hat_adjusteds[i] = Q_hats[i] - Q0_vars[i]\n",
    "        Q1_vars[i] = max(Q_hat_adjusteds[i], 0)\n",
    "\n",
    "        # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "        # Calculate the demand up to k-1\n",
    "        total_demand_up_to_k_minus_1 = sum(\n",
    "            R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_up_to_k_minus_1_vars[i] = total_demand_up_to_k_minus_1\n",
    "\n",
    "        # Calculate the demand from k to T\n",
    "        total_demand_from_k_to_T = sum(\n",
    "            R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars[i] = total_demand_from_k_to_T\n",
    "\n",
    "        Sold_0s[i] = min(total_demand_up_to_k_minus_1_vars[i], Q0_vars[i])\n",
    "        Left_0s[i] = max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "        Lost_0s[i] = max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "        Q1_plus_lefts[i] = Q1_vars[i] + Left_0s[i]\n",
    "\n",
    "        Sold_1s[i] = min(total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i])\n",
    "        Left_1s[i] = max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "        Lost_1s[i] = max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "\n",
    "        # assigned_R = max_r_index[i]\n",
    "\n",
    "        # all_holding_costs_0[i] = (\n",
    "        #     (Q0_vars[i] + Left_0s[i] + Q1_vars[i]) * ((assigned_R + 2) - 1) / 2\n",
    "        # )\n",
    "        # all_holding_costs_1[i] = (\n",
    "        #     (Q1_vars[i] + Left_0s[i] + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "        # )\n",
    "\n",
    "        profits_vars[i] = (\n",
    "            (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue from sales\n",
    "            - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "            - (cost - salvage_value) * Left_1s[i]\n",
    "            # - holding_cost * (all_holding_costs_0[i] + all_holding_costs_1[i])\n",
    "        )\n",
    "\n",
    "    # Calculate the average profit\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"average_profits\": [np.mean(profits_vars)],\n",
    "            \"average_loss\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"average_left\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"alpha_values\": [alphas],\n",
    "            \"beta_balues\": [betas],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    stimulation_result = pd.DataFrame(\n",
    "        {\n",
    "            \"F\": F_vars,\n",
    "            \"R(T)\": [x + 2 for x in max_r_index],\n",
    "            \"Sold_0\": Sold_0s,\n",
    "            \"Left_0\": Left_0s,\n",
    "            \"Lost_0\": Lost_0s,\n",
    "            \"Sold_1\": Sold_1s,\n",
    "            \"Left_1\": Left_1s,\n",
    "            \"Lost_1\": Lost_1s,\n",
    "            \"profits\": profits_vars,\n",
    "            \"Q0\": Q0_vars,\n",
    "            \"Q1\": Q1_vars,\n",
    "            \"hc0\": all_holding_costs_0,\n",
    "            \"hc1\": all_holding_costs_1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return results_df, stimulation_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S12 - Beta without r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1538,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_fully_flexible_beta_with_softmax_12(\n",
    "    alphas,\n",
    "    betas,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_test,\n",
    "    Qk_hat_df_test,\n",
    "    testing_df,\n",
    "):\n",
    "\n",
    "    # ======================= Global Variables =======================\n",
    "\n",
    "    # Category 1 - Some variables that is important to future work\n",
    "    K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "    n = len(demand_df_test)\n",
    "\n",
    "    # Initialize lists or numpy arrays to replace Gurobi variables\n",
    "    Sold_0s = np.zeros(n)\n",
    "    Left_0s = np.zeros(n)\n",
    "    Lost_0s = np.zeros(n)\n",
    "    Sold_1s = np.zeros(n)\n",
    "    Left_1s = np.zeros(n)\n",
    "    Lost_1s = np.zeros(n)\n",
    "    all_holding_costs_0 = np.zeros(n)\n",
    "    all_holding_costs_1 = np.zeros(n)\n",
    "    profits_vars = np.zeros(n)\n",
    "\n",
    "    # 1-2. Arrays for demand calculation up to certain periods\n",
    "    total_demand_up_to_k_minus_1_vars = np.zeros(n)\n",
    "    total_demand_from_k_to_T_vars = np.zeros(n)\n",
    "    Q1_plus_lefts = np.zeros(n)\n",
    "\n",
    "    # 2. Variables for Model 2: Optimal Fraction Model\n",
    "    f_vars = np.zeros(n)\n",
    "    F_vars = np.zeros(n)  # Assuming values will be between 0 and 1\n",
    "    Q0_vars = np.zeros(n)  # Replace Q_star with a specific value as needed\n",
    "\n",
    "    # 3. Variables for Model 3: Optimal Order Time Model (2D array for binary values)\n",
    "    tau_vars = np.zeros((n, K))\n",
    "    exp_tau_vars = np.zeros((n, K))\n",
    "    r_vars = np.zeros((n, K))\n",
    "    max_r_index = np.zeros(n, dtype=int)\n",
    "    R_vars = np.zeros(\n",
    "        (n, K), dtype=int\n",
    "    )  # Binary array to select one optimal replenishment time\n",
    "\n",
    "    # 4. Variables for Model 4: Re-estimate order-up-to-level\n",
    "    Q1_vars = np.zeros(n)\n",
    "    Q_hats = np.zeros(n)\n",
    "    Q_hat_adjusteds = np.zeros(n)\n",
    "\n",
    "    # ======================= Start Stimulation! =======================\n",
    "\n",
    "    for i, row in demand_df_test.iterrows():\n",
    "\n",
    "        ### Data for this stimulation\n",
    "        demand_row = demand_df_test.iloc[i]\n",
    "        Qk_hat_df_test_row = Qk_hat_df_test.iloc[i]\n",
    "        X_data = testing_df.iloc[i].tolist()\n",
    "        X_data.append(1)\n",
    "\n",
    "        # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "        ### 用線性回歸計算F_var\n",
    "        f_vars[i] = sum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "        F_vars[i] = 1 / (1 + np.exp(-(f_vars[i])))\n",
    "        Q0_vars[i] = F_vars[i] * Q_star\n",
    "\n",
    "        # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "        # Step 1: Calculate tau_vars as a linear combination of X_data and betas\n",
    "        for k in range(K):\n",
    "            tau_vars[i, k] = sum(\n",
    "                X_data[j] * betas[k, j] for j in range(features_num + 1)\n",
    "            )\n",
    "\n",
    "        max_r_index[i] = np.argmax(tau_vars[i])\n",
    "        R_vars[i, max_r_index[i]] = 1\n",
    "\n",
    "        print(f\"tau: {tau_vars[i]}\")\n",
    "        print(f\"R: {R_vars[i]}\")\n",
    "        print(f\"max_r_index: {max_r_index[i]}\")\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "        # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "        Q_hats[i] = sum(\n",
    "            R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
    "        )\n",
    "        Q_hat_adjusteds[i] = Q_hats[i] - Q0_vars[i]\n",
    "        Q1_vars[i] = max(Q_hat_adjusteds[i], 0)\n",
    "\n",
    "        # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "        # Calculate the demand up to k-1\n",
    "        total_demand_up_to_k_minus_1 = sum(\n",
    "            R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_up_to_k_minus_1_vars[i] = total_demand_up_to_k_minus_1\n",
    "\n",
    "        # Calculate the demand from k to T\n",
    "        total_demand_from_k_to_T = sum(\n",
    "            R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars[i] = total_demand_from_k_to_T\n",
    "\n",
    "        Sold_0s[i] = min(total_demand_up_to_k_minus_1_vars[i], Q0_vars[i])\n",
    "        Left_0s[i] = max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "        Lost_0s[i] = max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "        Q1_plus_lefts[i] = Q1_vars[i] + Left_0s[i]\n",
    "\n",
    "        Sold_1s[i] = min(total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i])\n",
    "        Left_1s[i] = max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "        Lost_1s[i] = max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "\n",
    "        # assigned_R = max_r_index[i]\n",
    "\n",
    "        # all_holding_costs_0[i] = (\n",
    "        #     (Q0_vars[i] + Left_0s[i] + Q1_vars[i]) * ((assigned_R + 2) - 1) / 2\n",
    "        # )\n",
    "        # all_holding_costs_1[i] = (\n",
    "        #     (Q1_vars[i] + Left_0s[i] + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "        # )\n",
    "\n",
    "        # profits_vars[i] = (\n",
    "        #     (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue from sales\n",
    "        #     - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "        #     - (cost - salvage_value) * (Left_1s[i])\n",
    "        # )\n",
    "\n",
    "        profits_vars[i] = (\n",
    "            (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue from sales\n",
    "            - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "            - (cost - salvage_value) * (Left_0s[i] + Left_1s[i])\n",
    "        )\n",
    "\n",
    "    # Calculate the average profit\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"average_profits\": [np.mean(profits_vars)],\n",
    "            \"average_loss\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"average_left\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"alpha_values\": [alphas],\n",
    "            \"beta_balues\": [betas],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    stimulation_result = pd.DataFrame(\n",
    "        {\n",
    "            \"F\": F_vars,\n",
    "            \"R(T)\": [x + 2 for x in max_r_index],\n",
    "            \"Sold_0\": Sold_0s,\n",
    "            \"Left_0\": Left_0s,\n",
    "            \"Lost_0\": Lost_0s,\n",
    "            \"Sold_1\": Sold_1s,\n",
    "            \"Left_1\": Left_1s,\n",
    "            \"Lost_1\": Lost_1s,\n",
    "            \"profits\": profits_vars,\n",
    "            \"Q0\": Q0_vars,\n",
    "            \"Q1\": Q1_vars,\n",
    "            \"hc0\": all_holding_costs_0,\n",
    "            \"hc1\": all_holding_costs_1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return results_df, stimulation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S15 - Beta with Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1539,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_fully_flexible_beta_with_lasso_15(\n",
    "    alphas,\n",
    "    betas,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_test,\n",
    "    Qk_hat_df_test,\n",
    "    testing_df,\n",
    "):\n",
    "\n",
    "    # ======================= Global Variables =======================\n",
    "\n",
    "    # Category 1 - Some variables that is important to future work\n",
    "    K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "    n = len(demand_df_test)\n",
    "\n",
    "    # Initialize lists or numpy arrays to replace Gurobi variables\n",
    "    Sold_0s = np.zeros(n)\n",
    "    Left_0s = np.zeros(n)\n",
    "    Lost_0s = np.zeros(n)\n",
    "    Sold_1s = np.zeros(n)\n",
    "    Left_1s = np.zeros(n)\n",
    "    Lost_1s = np.zeros(n)\n",
    "    all_holding_costs_0 = np.zeros(n)\n",
    "    all_holding_costs_1 = np.zeros(n)\n",
    "    profits_vars = np.zeros(n)\n",
    "\n",
    "    # 1-2. Arrays for demand calculation up to certain periods\n",
    "    total_demand_up_to_k_minus_1_vars = np.zeros(n)\n",
    "    total_demand_from_k_to_T_vars = np.zeros(n)\n",
    "    Q1_plus_lefts = np.zeros(n)\n",
    "\n",
    "    # 2. Variables for Model 2: Optimal Fraction Model\n",
    "    f_vars = np.zeros(n)\n",
    "    F_vars = np.zeros(n)  # Assuming values will be between 0 and 1\n",
    "    Q0_vars = np.zeros(n)  # Replace Q_star with a specific value as needed\n",
    "\n",
    "    # 3. Variables for Model 3: Optimal Order Time Model (2D array for binary values)\n",
    "    tau_vars = np.zeros((n, K))\n",
    "    exp_tau_vars = np.zeros((n, K))\n",
    "    r_vars = np.zeros((n, K))\n",
    "    max_r_index = np.zeros(n, dtype=int)\n",
    "    R_vars = np.zeros(\n",
    "        (n, K), dtype=int\n",
    "    )  # Binary array to select one optimal replenishment time\n",
    "\n",
    "    # 4. Variables for Model 4: Re-estimate order-up-to-level\n",
    "    Q1_vars = np.zeros(n)\n",
    "    Q_hats = np.zeros(n)\n",
    "    Q_hat_adjusteds = np.zeros(n)\n",
    "\n",
    "    # ======================= Start Stimulation! =======================\n",
    "\n",
    "    for i, row in demand_df_test.iterrows():\n",
    "\n",
    "        ### Data for this stimulation\n",
    "        demand_row = demand_df_test.iloc[i]\n",
    "        Qk_hat_df_test_row = Qk_hat_df_test.iloc[i]\n",
    "        X_data = testing_df.iloc[i].tolist()\n",
    "        X_data.append(1)\n",
    "\n",
    "        # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "        ### 用線性回歸計算F_var\n",
    "        f_vars[i] = sum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "        F_vars[i] = 1 / (1 + np.exp(-(f_vars[i])))\n",
    "        Q0_vars[i] = F_vars[i] * Q_star\n",
    "\n",
    "        # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "        # Step 1: Calculate tau_vars as a linear combination of X_data and betas\n",
    "        for k in range(K):\n",
    "            tau_vars[i, k] = sum(\n",
    "                X_data[j] * betas[k, j] for j in range(features_num + 1)\n",
    "            )\n",
    "\n",
    "        max_r_index[i] = np.argmax(tau_vars[i])\n",
    "        R_vars[i, max_r_index[i]] = 1\n",
    "\n",
    "        print(f\"tau: {tau_vars[i]}\")\n",
    "        print(f\"R: {R_vars[i]}\")\n",
    "        print(f\"max_r_index: {max_r_index[i]}\")\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "        # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "        Q_hats[i] = sum(\n",
    "            R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
    "        )\n",
    "        Q_hat_adjusteds[i] = Q_hats[i] - Q0_vars[i]\n",
    "        Q1_vars[i] = max(Q_hat_adjusteds[i], 0)\n",
    "\n",
    "        # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "        # Calculate the demand up to k-1\n",
    "        total_demand_up_to_k_minus_1 = sum(\n",
    "            R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_up_to_k_minus_1_vars[i] = total_demand_up_to_k_minus_1\n",
    "\n",
    "        # Calculate the demand from k to T\n",
    "        total_demand_from_k_to_T = sum(\n",
    "            R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars[i] = total_demand_from_k_to_T\n",
    "\n",
    "        Sold_0s[i] = min(total_demand_up_to_k_minus_1_vars[i], Q0_vars[i])\n",
    "        Left_0s[i] = max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "        Lost_0s[i] = max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "        Q1_plus_lefts[i] = Q1_vars[i] + Left_0s[i]\n",
    "\n",
    "        Sold_1s[i] = min(total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i])\n",
    "        Left_1s[i] = max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "        Lost_1s[i] = max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "\n",
    "        # assigned_R = max_r_index[i]\n",
    "\n",
    "        # all_holding_costs_0[i] = (\n",
    "        #     (Q0_vars[i] + Left_0s[i] + Q1_vars[i]) * ((assigned_R + 2) - 1) / 2\n",
    "        # )\n",
    "        # all_holding_costs_1[i] = (\n",
    "        #     (Q1_vars[i] + Left_0s[i] + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "        # )\n",
    "\n",
    "        profits_vars[i] = (\n",
    "            (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue from sales\n",
    "            - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "            - (cost - salvage_value) * Left_1s[i]\n",
    "            # - holding_cost * (all_holding_costs_0[i] + all_holding_costs_1[i])\n",
    "        )\n",
    "\n",
    "    # Calculate the average profit\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"average_profits\": [np.mean(profits_vars)],\n",
    "            \"average_loss\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"average_left\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"alpha_values\": [alphas],\n",
    "            \"beta_balues\": [betas],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    stimulation_result = pd.DataFrame(\n",
    "        {\n",
    "            \"F\": F_vars,\n",
    "            \"R(T)\": [x + 2 for x in max_r_index],\n",
    "            \"Sold_0\": Sold_0s,\n",
    "            \"Left_0\": Left_0s,\n",
    "            \"Lost_0\": Lost_0s,\n",
    "            \"Sold_1\": Sold_1s,\n",
    "            \"Left_1\": Left_1s,\n",
    "            \"Lost_1\": Lost_1s,\n",
    "            \"profits\": profits_vars,\n",
    "            \"Q0\": Q0_vars,\n",
    "            \"Q1\": Q1_vars,\n",
    "            \"hc0\": all_holding_costs_0,\n",
    "            \"hc1\": all_holding_costs_1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return results_df, stimulation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S16 - Beta with second Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1540,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_fully_flexible_beta_with_second_training_16(\n",
    "    alphas,\n",
    "    betas,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_test,\n",
    "    Qk_hat_df_test,\n",
    "    testing_df,\n",
    "):\n",
    "\n",
    "    # ======================= Global Variables =======================\n",
    "\n",
    "    # Category 1 - Some variables that is important to future work\n",
    "    K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "    n = len(demand_df_test)\n",
    "\n",
    "    # Initialize lists or numpy arrays to replace Gurobi variables\n",
    "    Sold_0s = np.zeros(n)\n",
    "    Left_0s = np.zeros(n)\n",
    "    Lost_0s = np.zeros(n)\n",
    "    Sold_1s = np.zeros(n)\n",
    "    Left_1s = np.zeros(n)\n",
    "    Lost_1s = np.zeros(n)\n",
    "    all_holding_costs_0 = np.zeros(n)\n",
    "    all_holding_costs_1 = np.zeros(n)\n",
    "    profits_vars = np.zeros(n)\n",
    "\n",
    "    # 1-2. Arrays for demand calculation up to certain periods\n",
    "    total_demand_up_to_k_minus_1_vars = np.zeros(n)\n",
    "    total_demand_from_k_to_T_vars = np.zeros(n)\n",
    "    Q1_plus_lefts = np.zeros(n)\n",
    "\n",
    "    # 2. Variables for Model 2: Optimal Fraction Model\n",
    "    f_vars = np.zeros(n)\n",
    "    F_vars = np.zeros(n)  # Assuming values will be between 0 and 1\n",
    "    Q0_vars = np.zeros(n)  # Replace Q_star with a specific value as needed\n",
    "\n",
    "    # 3. Variables for Model 3: Optimal Order Time Model (2D array for binary values)\n",
    "    tau_vars = np.zeros((n, K))\n",
    "    exp_tau_vars = np.zeros((n, K))\n",
    "    r_vars = np.zeros((n, K))\n",
    "    max_r_index = np.zeros(n, dtype=int)\n",
    "    R_vars = np.zeros(\n",
    "        (n, K), dtype=int\n",
    "    )  # Binary array to select one optimal replenishment time\n",
    "\n",
    "    # 4. Variables for Model 4: Re-estimate order-up-to-level\n",
    "    Q1_vars = np.zeros(n)\n",
    "    Q_hats = np.zeros(n)\n",
    "    Q_hat_adjusteds = np.zeros(n)\n",
    "\n",
    "    # ======================= Start Stimulation! =======================\n",
    "\n",
    "    for i, row in demand_df_test.iterrows():\n",
    "\n",
    "        ### Data for this stimulation\n",
    "        demand_row = demand_df_test.iloc[i]\n",
    "        Qk_hat_df_test_row = Qk_hat_df_test.iloc[i]\n",
    "        X_data = testing_df.iloc[i].tolist()\n",
    "        X_data.append(1)\n",
    "\n",
    "        # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "        ### 用線性回歸計算F_var\n",
    "        f_vars[i] = sum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "        F_vars[i] = 1 / (1 + np.exp(-(f_vars[i])))\n",
    "        Q0_vars[i] = F_vars[i] * Q_star\n",
    "\n",
    "        # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "        # Step 1: Calculate tau_vars as a linear combination of X_data and betas\n",
    "        for k in range(K):\n",
    "            tau_vars[i, k] = sum(\n",
    "                X_data[j] * betas[k, j] for j in range(features_num + 1)\n",
    "            )\n",
    "\n",
    "        max_r_index[i] = np.argmax(tau_vars[i])\n",
    "        R_vars[i, max_r_index[i]] = 1\n",
    "\n",
    "        print(f\"tau: {tau_vars[i]}\")\n",
    "        print(f\"R: {R_vars[i]}\")\n",
    "        print(f\"max_r_index: {max_r_index[i]}\")\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "        # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "        Q_hats[i] = sum(\n",
    "            R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
    "        )\n",
    "        Q_hat_adjusteds[i] = Q_hats[i] - Q0_vars[i]\n",
    "        Q1_vars[i] = max(Q_hat_adjusteds[i], 0)\n",
    "\n",
    "        # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "        # Calculate the demand up to k-1\n",
    "        total_demand_up_to_k_minus_1 = sum(\n",
    "            R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_up_to_k_minus_1_vars[i] = total_demand_up_to_k_minus_1\n",
    "\n",
    "        # Calculate the demand from k to T\n",
    "        total_demand_from_k_to_T = sum(\n",
    "            R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars[i] = total_demand_from_k_to_T\n",
    "\n",
    "        Sold_0s[i] = min(total_demand_up_to_k_minus_1_vars[i], Q0_vars[i])\n",
    "        Left_0s[i] = max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "        Lost_0s[i] = max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "        Q1_plus_lefts[i] = Q1_vars[i] + Left_0s[i]\n",
    "\n",
    "        Sold_1s[i] = min(total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i])\n",
    "        Left_1s[i] = max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "        Lost_1s[i] = max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "\n",
    "        # assigned_R = max_r_index[i]\n",
    "\n",
    "        # all_holding_costs_0[i] = (\n",
    "        #     (Q0_vars[i] + Left_0s[i] + Q1_vars[i]) * ((assigned_R + 2) - 1) / 2\n",
    "        # )\n",
    "        # all_holding_costs_1[i] = (\n",
    "        #     (Q1_vars[i] + Left_0s[i] + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "        # )\n",
    "\n",
    "        profits_vars[i] = (\n",
    "            (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue from sales\n",
    "            - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "            - (cost - salvage_value) * Left_1s[i]\n",
    "            # - holding_cost * (all_holding_costs_0[i] + all_holding_costs_1[i])\n",
    "        )\n",
    "\n",
    "    # Calculate the average profit\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"average_profits\": [np.mean(profits_vars)],\n",
    "            \"average_loss\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"average_left\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"alpha_values\": [alphas],\n",
    "            \"beta_balues\": [betas],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    stimulation_result = pd.DataFrame(\n",
    "        {\n",
    "            \"F\": F_vars,\n",
    "            \"R(T)\": [x + 2 for x in max_r_index],\n",
    "            \"Sold_0\": Sold_0s,\n",
    "            \"Left_0\": Left_0s,\n",
    "            \"Lost_0\": Lost_0s,\n",
    "            \"Sold_1\": Sold_1s,\n",
    "            \"Left_1\": Left_1s,\n",
    "            \"Lost_1\": Lost_1s,\n",
    "            \"profits\": profits_vars,\n",
    "            \"Q0\": Q0_vars,\n",
    "            \"Q1\": Q1_vars,\n",
    "            \"hc0\": all_holding_costs_0,\n",
    "            \"hc1\": all_holding_costs_1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return results_df, stimulation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting reasonable parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202504100239"
      ]
     },
     "execution_count": 1541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CURRENT_TIMESTAMP = int(datetime.now().strftime(\"%Y%m%d%H%M\"))\n",
    "CURRENT_TIMESTAMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service_lv: 0.6\n"
     ]
    }
   ],
   "source": [
    "status = \"train\"\n",
    "\n",
    "service_lv = calculate_service_level(\n",
    "    salvage_value=salvage_value, cost=cost, price=price\n",
    ")\n",
    "print(f\"service_lv: {service_lv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1543,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_df, testing_df = training_data_folds[0]\n",
    "# demand_df_train, demand_df_test = demand_folds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1544,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>216.269540</td>\n",
       "      <td>211.134274</td>\n",
       "      <td>215.128316</td>\n",
       "      <td>217.994763</td>\n",
       "      <td>229.527662</td>\n",
       "      <td>228.343740</td>\n",
       "      <td>242.806583</td>\n",
       "      <td>289.728142</td>\n",
       "      <td>294.085892</td>\n",
       "      <td>302.742662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>213.412362</td>\n",
       "      <td>212.203824</td>\n",
       "      <td>210.885199</td>\n",
       "      <td>212.928863</td>\n",
       "      <td>214.608230</td>\n",
       "      <td>221.012875</td>\n",
       "      <td>232.696730</td>\n",
       "      <td>291.971737</td>\n",
       "      <td>299.898413</td>\n",
       "      <td>310.098635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>204.681787</td>\n",
       "      <td>207.336518</td>\n",
       "      <td>210.952538</td>\n",
       "      <td>203.368635</td>\n",
       "      <td>201.143341</td>\n",
       "      <td>212.945396</td>\n",
       "      <td>217.246014</td>\n",
       "      <td>274.878251</td>\n",
       "      <td>284.616328</td>\n",
       "      <td>292.693517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>198.383496</td>\n",
       "      <td>200.987261</td>\n",
       "      <td>197.538109</td>\n",
       "      <td>202.580936</td>\n",
       "      <td>202.908901</td>\n",
       "      <td>212.987482</td>\n",
       "      <td>223.541107</td>\n",
       "      <td>289.059699</td>\n",
       "      <td>300.204667</td>\n",
       "      <td>305.030320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>219.811740</td>\n",
       "      <td>215.888884</td>\n",
       "      <td>220.591784</td>\n",
       "      <td>218.304163</td>\n",
       "      <td>224.051815</td>\n",
       "      <td>230.563012</td>\n",
       "      <td>282.302153</td>\n",
       "      <td>291.526875</td>\n",
       "      <td>302.196239</td>\n",
       "      <td>297.751466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>220.360046</td>\n",
       "      <td>221.653541</td>\n",
       "      <td>221.084469</td>\n",
       "      <td>221.365066</td>\n",
       "      <td>219.588375</td>\n",
       "      <td>230.349881</td>\n",
       "      <td>239.096051</td>\n",
       "      <td>287.137346</td>\n",
       "      <td>298.313381</td>\n",
       "      <td>302.956429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>206.804647</td>\n",
       "      <td>210.281255</td>\n",
       "      <td>211.971112</td>\n",
       "      <td>211.899313</td>\n",
       "      <td>212.103444</td>\n",
       "      <td>223.938525</td>\n",
       "      <td>279.861703</td>\n",
       "      <td>289.879410</td>\n",
       "      <td>300.275223</td>\n",
       "      <td>301.905500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>197.500672</td>\n",
       "      <td>202.217054</td>\n",
       "      <td>202.132739</td>\n",
       "      <td>203.477299</td>\n",
       "      <td>205.711701</td>\n",
       "      <td>209.558780</td>\n",
       "      <td>218.989494</td>\n",
       "      <td>282.840421</td>\n",
       "      <td>291.370366</td>\n",
       "      <td>300.913051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>204.862165</td>\n",
       "      <td>204.349647</td>\n",
       "      <td>204.410897</td>\n",
       "      <td>203.832857</td>\n",
       "      <td>198.517193</td>\n",
       "      <td>209.219411</td>\n",
       "      <td>213.080292</td>\n",
       "      <td>285.593964</td>\n",
       "      <td>296.148638</td>\n",
       "      <td>306.810950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>214.729484</td>\n",
       "      <td>211.058905</td>\n",
       "      <td>213.111249</td>\n",
       "      <td>213.393977</td>\n",
       "      <td>216.269393</td>\n",
       "      <td>226.294654</td>\n",
       "      <td>277.908923</td>\n",
       "      <td>287.515460</td>\n",
       "      <td>293.452452</td>\n",
       "      <td>298.903205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>203.536333</td>\n",
       "      <td>198.875464</td>\n",
       "      <td>199.443303</td>\n",
       "      <td>206.642554</td>\n",
       "      <td>213.162637</td>\n",
       "      <td>213.806483</td>\n",
       "      <td>226.483521</td>\n",
       "      <td>286.300518</td>\n",
       "      <td>295.724523</td>\n",
       "      <td>295.565024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>211.399931</td>\n",
       "      <td>203.772432</td>\n",
       "      <td>204.362386</td>\n",
       "      <td>211.367124</td>\n",
       "      <td>219.630126</td>\n",
       "      <td>222.009609</td>\n",
       "      <td>239.661313</td>\n",
       "      <td>287.100126</td>\n",
       "      <td>295.098417</td>\n",
       "      <td>300.312782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>200.333009</td>\n",
       "      <td>200.122945</td>\n",
       "      <td>201.407273</td>\n",
       "      <td>202.457942</td>\n",
       "      <td>209.620603</td>\n",
       "      <td>212.527752</td>\n",
       "      <td>224.286097</td>\n",
       "      <td>289.751327</td>\n",
       "      <td>295.640317</td>\n",
       "      <td>296.230690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>215.485256</td>\n",
       "      <td>214.091043</td>\n",
       "      <td>212.898490</td>\n",
       "      <td>213.282515</td>\n",
       "      <td>211.999879</td>\n",
       "      <td>219.028557</td>\n",
       "      <td>226.998326</td>\n",
       "      <td>277.137760</td>\n",
       "      <td>290.303325</td>\n",
       "      <td>296.421243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>223.772374</td>\n",
       "      <td>219.297995</td>\n",
       "      <td>227.067323</td>\n",
       "      <td>224.128681</td>\n",
       "      <td>227.334861</td>\n",
       "      <td>242.102041</td>\n",
       "      <td>285.157984</td>\n",
       "      <td>297.060136</td>\n",
       "      <td>300.922758</td>\n",
       "      <td>304.073340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "0   216.269540  211.134274  215.128316  217.994763  229.527662  228.343740   \n",
       "1   213.412362  212.203824  210.885199  212.928863  214.608230  221.012875   \n",
       "2   204.681787  207.336518  210.952538  203.368635  201.143341  212.945396   \n",
       "3   198.383496  200.987261  197.538109  202.580936  202.908901  212.987482   \n",
       "4   219.811740  215.888884  220.591784  218.304163  224.051815  230.563012   \n",
       "5   220.360046  221.653541  221.084469  221.365066  219.588375  230.349881   \n",
       "6   206.804647  210.281255  211.971112  211.899313  212.103444  223.938525   \n",
       "7   197.500672  202.217054  202.132739  203.477299  205.711701  209.558780   \n",
       "8   204.862165  204.349647  204.410897  203.832857  198.517193  209.219411   \n",
       "9   214.729484  211.058905  213.111249  213.393977  216.269393  226.294654   \n",
       "10  203.536333  198.875464  199.443303  206.642554  213.162637  213.806483   \n",
       "11  211.399931  203.772432  204.362386  211.367124  219.630126  222.009609   \n",
       "12  200.333009  200.122945  201.407273  202.457942  209.620603  212.527752   \n",
       "13  215.485256  214.091043  212.898490  213.282515  211.999879  219.028557   \n",
       "14  223.772374  219.297995  227.067323  224.128681  227.334861  242.102041   \n",
       "\n",
       "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "0   242.806583  289.728142  294.085892  302.742662  \n",
       "1   232.696730  291.971737  299.898413  310.098635  \n",
       "2   217.246014  274.878251  284.616328  292.693517  \n",
       "3   223.541107  289.059699  300.204667  305.030320  \n",
       "4   282.302153  291.526875  302.196239  297.751466  \n",
       "5   239.096051  287.137346  298.313381  302.956429  \n",
       "6   279.861703  289.879410  300.275223  301.905500  \n",
       "7   218.989494  282.840421  291.370366  300.913051  \n",
       "8   213.080292  285.593964  296.148638  306.810950  \n",
       "9   277.908923  287.515460  293.452452  298.903205  \n",
       "10  226.483521  286.300518  295.724523  295.565024  \n",
       "11  239.661313  287.100126  295.098417  300.312782  \n",
       "12  224.286097  289.751327  295.640317  296.230690  \n",
       "13  226.998326  277.137760  290.303325  296.421243  \n",
       "14  285.157984  297.060136  300.922758  304.073340  "
      ]
     },
     "execution_count": 1545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1546,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of sum: 2400.9164885329315\n",
      "std of sum: 75.12106255060029\n",
      "60.0 percentile of sum: 2419.9481921146094\n",
      "Q_star: 2419.9481921146094\n"
     ]
    }
   ],
   "source": [
    "Q_star = calculate_Q_star(demand_df_train, service_level=service_lv)\n",
    "print(f\"Q_star: {Q_star}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Qk_hat_k2</th>\n",
       "      <th>Qk_hat_k3</th>\n",
       "      <th>Qk_hat_k4</th>\n",
       "      <th>Qk_hat_k5</th>\n",
       "      <th>Qk_hat_k6</th>\n",
       "      <th>Qk_hat_k7</th>\n",
       "      <th>Qk_hat_k8</th>\n",
       "      <th>Qk_hat_k9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2458.583412</td>\n",
       "      <td>2455.127529</td>\n",
       "      <td>2461.950525</td>\n",
       "      <td>2482.863039</td>\n",
       "      <td>2480.539995</td>\n",
       "      <td>2459.764438</td>\n",
       "      <td>2447.809327</td>\n",
       "      <td>2445.699514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2436.068219</td>\n",
       "      <td>2437.098258</td>\n",
       "      <td>2418.778558</td>\n",
       "      <td>2408.028856</td>\n",
       "      <td>2406.875716</td>\n",
       "      <td>2407.005056</td>\n",
       "      <td>2403.973757</td>\n",
       "      <td>2418.945451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2367.269363</td>\n",
       "      <td>2370.754663</td>\n",
       "      <td>2390.149866</td>\n",
       "      <td>2340.792223</td>\n",
       "      <td>2340.242203</td>\n",
       "      <td>2339.011774</td>\n",
       "      <td>2324.092475</td>\n",
       "      <td>2309.377098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2317.637438</td>\n",
       "      <td>2318.968804</td>\n",
       "      <td>2303.363276</td>\n",
       "      <td>2314.175369</td>\n",
       "      <td>2314.498138</td>\n",
       "      <td>2345.706294</td>\n",
       "      <td>2333.648470</td>\n",
       "      <td>2331.705702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2486.496732</td>\n",
       "      <td>2485.889477</td>\n",
       "      <td>2494.683738</td>\n",
       "      <td>2481.821622</td>\n",
       "      <td>2480.263389</td>\n",
       "      <td>2476.806795</td>\n",
       "      <td>2496.571658</td>\n",
       "      <td>2502.186607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2490.817504</td>\n",
       "      <td>2497.606366</td>\n",
       "      <td>2479.602398</td>\n",
       "      <td>2492.472025</td>\n",
       "      <td>2492.585365</td>\n",
       "      <td>2484.213426</td>\n",
       "      <td>2468.648776</td>\n",
       "      <td>2465.074351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2383.997966</td>\n",
       "      <td>2389.322236</td>\n",
       "      <td>2396.626866</td>\n",
       "      <td>2424.886721</td>\n",
       "      <td>2425.925849</td>\n",
       "      <td>2431.351426</td>\n",
       "      <td>2453.290156</td>\n",
       "      <td>2448.327829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2310.680594</td>\n",
       "      <td>2314.641888</td>\n",
       "      <td>2320.281017</td>\n",
       "      <td>2341.631584</td>\n",
       "      <td>2341.018751</td>\n",
       "      <td>2318.051686</td>\n",
       "      <td>2319.043404</td>\n",
       "      <td>2314.737600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2368.690777</td>\n",
       "      <td>2367.855120</td>\n",
       "      <td>2364.779953</td>\n",
       "      <td>2329.465171</td>\n",
       "      <td>2332.871559</td>\n",
       "      <td>2314.104146</td>\n",
       "      <td>2313.442861</td>\n",
       "      <td>2326.203378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2446.447432</td>\n",
       "      <td>2444.507916</td>\n",
       "      <td>2442.564335</td>\n",
       "      <td>2425.244408</td>\n",
       "      <td>2425.243311</td>\n",
       "      <td>2444.768775</td>\n",
       "      <td>2463.706582</td>\n",
       "      <td>2455.400745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2358.242936</td>\n",
       "      <td>2351.231112</td>\n",
       "      <td>2349.279695</td>\n",
       "      <td>2366.318142</td>\n",
       "      <td>2367.872760</td>\n",
       "      <td>2348.133081</td>\n",
       "      <td>2348.885066</td>\n",
       "      <td>2343.121437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2420.209822</td>\n",
       "      <td>2411.696088</td>\n",
       "      <td>2401.463827</td>\n",
       "      <td>2402.567443</td>\n",
       "      <td>2402.685945</td>\n",
       "      <td>2410.516214</td>\n",
       "      <td>2404.421689</td>\n",
       "      <td>2392.942656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2333.000032</td>\n",
       "      <td>2331.084478</td>\n",
       "      <td>2338.831266</td>\n",
       "      <td>2329.336051</td>\n",
       "      <td>2326.674514</td>\n",
       "      <td>2335.240391</td>\n",
       "      <td>2327.950832</td>\n",
       "      <td>2337.040239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2452.403079</td>\n",
       "      <td>2453.862014</td>\n",
       "      <td>2434.447894</td>\n",
       "      <td>2408.006603</td>\n",
       "      <td>2407.757018</td>\n",
       "      <td>2391.919063</td>\n",
       "      <td>2393.922340</td>\n",
       "      <td>2378.866163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2517.707399</td>\n",
       "      <td>2517.647489</td>\n",
       "      <td>2540.245604</td>\n",
       "      <td>2553.153278</td>\n",
       "      <td>2555.484620</td>\n",
       "      <td>2568.320171</td>\n",
       "      <td>2550.343858</td>\n",
       "      <td>2552.172538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Qk_hat_k2    Qk_hat_k3    Qk_hat_k4    Qk_hat_k5    Qk_hat_k6  \\\n",
       "0   2458.583412  2455.127529  2461.950525  2482.863039  2480.539995   \n",
       "1   2436.068219  2437.098258  2418.778558  2408.028856  2406.875716   \n",
       "2   2367.269363  2370.754663  2390.149866  2340.792223  2340.242203   \n",
       "3   2317.637438  2318.968804  2303.363276  2314.175369  2314.498138   \n",
       "4   2486.496732  2485.889477  2494.683738  2481.821622  2480.263389   \n",
       "5   2490.817504  2497.606366  2479.602398  2492.472025  2492.585365   \n",
       "6   2383.997966  2389.322236  2396.626866  2424.886721  2425.925849   \n",
       "7   2310.680594  2314.641888  2320.281017  2341.631584  2341.018751   \n",
       "8   2368.690777  2367.855120  2364.779953  2329.465171  2332.871559   \n",
       "9   2446.447432  2444.507916  2442.564335  2425.244408  2425.243311   \n",
       "10  2358.242936  2351.231112  2349.279695  2366.318142  2367.872760   \n",
       "11  2420.209822  2411.696088  2401.463827  2402.567443  2402.685945   \n",
       "12  2333.000032  2331.084478  2338.831266  2329.336051  2326.674514   \n",
       "13  2452.403079  2453.862014  2434.447894  2408.006603  2407.757018   \n",
       "14  2517.707399  2517.647489  2540.245604  2553.153278  2555.484620   \n",
       "\n",
       "      Qk_hat_k7    Qk_hat_k8    Qk_hat_k9  \n",
       "0   2459.764438  2447.809327  2445.699514  \n",
       "1   2407.005056  2403.973757  2418.945451  \n",
       "2   2339.011774  2324.092475  2309.377098  \n",
       "3   2345.706294  2333.648470  2331.705702  \n",
       "4   2476.806795  2496.571658  2502.186607  \n",
       "5   2484.213426  2468.648776  2465.074351  \n",
       "6   2431.351426  2453.290156  2448.327829  \n",
       "7   2318.051686  2319.043404  2314.737600  \n",
       "8   2314.104146  2313.442861  2326.203378  \n",
       "9   2444.768775  2463.706582  2455.400745  \n",
       "10  2348.133081  2348.885066  2343.121437  \n",
       "11  2410.516214  2404.421689  2392.942656  \n",
       "12  2335.240391  2327.950832  2337.040239  \n",
       "13  2391.919063  2393.922340  2378.866163  \n",
       "14  2568.320171  2550.343858  2552.172538  "
      ]
     },
     "execution_count": 1547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_matrix, covariance_matrix = cal_mu_and_cov_matrix(demand_df_train)\n",
    "Qk_hat_df_train = make_Qk_hat_df(\n",
    "    demand_df_train, T, service_lv, mu_matrix, covariance_matrix\n",
    ")\n",
    "Qk_hat_df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-folds training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 1548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data_folds), len(demand_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Testing Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1549,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for single fold training.\n",
    "def perform_fold_training(\n",
    "    training_df, demand_df_train, Qk_hat_df_train, Q_star\n",
    ") -> dict[str, float]:\n",
    "\n",
    "    # 1. Baseline model\n",
    "    (\n",
    "        baseline_avg_losses,\n",
    "        baseline_avg_lefts,\n",
    "        baseline_avg_profits,\n",
    "        baseline_avg_operation_profits,\n",
    "        baseline_stimulation_df,\n",
    "    ) = one_time_procurement(\n",
    "        Q_star=Q_star,\n",
    "        demand_df=demand_df_train,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        salvage_value=salvage_value,\n",
    "    )\n",
    "\n",
    "    # 2. S1 - Grid F & Grid R\n",
    "\n",
    "    results_df_1, stimulation_results_df_1 = None, None\n",
    "\n",
    "    results_df_1, stimulation_results_df_1 = grid_fixed_F_fixed_R(\n",
    "        assigned_Ts=ASSIGNED_TS,\n",
    "        assigned_Fs=ASSIGNED_FS,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        salvage_value=salvage_value,\n",
    "        Qk_hat_df=Qk_hat_df_train,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Q_star=Q_star,\n",
    "    )\n",
    "\n",
    "    S1_profit_training = results_df_1.iloc[0][\"average_profits\"]\n",
    "\n",
    "    # 3. S2 - Grid R & Flexible F\n",
    "\n",
    "    results_df_2, stimulation_results_df_2 = None, None\n",
    "    results_df_2, stimulation_results_df_2 = grid_flexible_F_fixed_R(\n",
    "        assigned_Ts=ASSIGNED_TS,\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df_train=Qk_hat_df_train,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "\n",
    "    S2_profit_training = results_df_2.iloc[0][\"average_profits\"]\n",
    "\n",
    "    # 5. S14 - Optimized F & Rk\n",
    "    results_df_14, stimulation_results_df_14 = None, None\n",
    "    results_df_14, stimulation_results_df_14 = cal_optimized_F_R(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df_train,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "    S14_profit_training = results_df_14.iloc[0][\"average_profits\"]\n",
    "\n",
    "    # 4. S12 - Beta without r\n",
    "\n",
    "    results_df_12, stimulation_results_df_12 = None, None\n",
    "    results_df_12, stimulation_results_df_12 = fully_flexible_beta_with_softmax_12(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df_train,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "    if results_df_12 is not None:\n",
    "        S12_profit_training = results_df_12.iloc[0][\"average_profits\"]\n",
    "    else:\n",
    "        S12_profit_training = None\n",
    "\n",
    "    # # 6. S15 - Beta with Lasso\n",
    "    # results_df_15, stimulation_results_df_15 = None, None\n",
    "    # results_df_15, stimulation_results_df_15 = fully_flexible_beta_with_lasso_15(\n",
    "    #     salvage_value=salvage_value,\n",
    "    #     cost=cost,\n",
    "    #     price=price,\n",
    "    #     Q_star=Q_star,\n",
    "    #     demand_df_train=demand_df_train,\n",
    "    #     Qk_hat_df=Qk_hat_df_train,\n",
    "    #     training_df=training_df,\n",
    "    #     lambda_beta=LASSO_BETA,\n",
    "    # )\n",
    "    # if results_df_15 is not None:\n",
    "    #     S15_profit_training = results_df_15.iloc[0][\"average_profits\"]\n",
    "    # else:\n",
    "    #     S15_profit_training = None\n",
    "\n",
    "    # # 7. S16 - Beta with Second Training\n",
    "    # results_df_16, stimulation_results_df_16 = None, None\n",
    "    # if results_df_12 is not None:\n",
    "    #     last_beta_total = np.sum(np.abs(results_df_12.iloc[0][\"beta_values\"]))\n",
    "    #     results_df_16, stimulation_results_df_16 = (\n",
    "    #         fully_flexible_beta_with_second_training_16(\n",
    "    #             salvage_value=salvage_value,\n",
    "    #             cost=cost,\n",
    "    #             price=price,\n",
    "    #             Q_star=Q_star,\n",
    "    #             demand_df_train=demand_df_train,\n",
    "    #             Qk_hat_df=Qk_hat_df_train,\n",
    "    #             training_df=training_df,\n",
    "    #             lambda_beta=LASSO_BETA_SECOND_TRAIN,\n",
    "    #             last_beta_total=last_beta_total,\n",
    "    #         )\n",
    "    #     )\n",
    "    # if results_df_16 is not None:\n",
    "    #     S16_profit_training = results_df_16.iloc[0][\"average_profits\"]\n",
    "    # else:\n",
    "    #     S16_profit_training = None\n",
    "\n",
    "    # print(f\"baseline_profit: {baseline_avg_profits}\")\n",
    "    # print(f\"S1_profit_training: {S1_profit_training}\")\n",
    "    # print(f\"S2_profit_training: {S2_profit_training}\")\n",
    "    # print(f\"S12_profit_training: {S12_profit_training}\")\n",
    "    # print(f\"S14_profit_training: {S14_profit_training}\")\n",
    "    # print(f\"S15_profit_training: {S15_profit_training}\")\n",
    "    # print(f\"S16_profit_training: {S16_profit_training}\")\n",
    "\n",
    "    # 整理利潤結果\n",
    "    training_profits = {\n",
    "        \"baseline\": baseline_avg_profits,\n",
    "        \"S1\": S1_profit_training,\n",
    "        \"S2\": S2_profit_training,\n",
    "        \"S12\": S12_profit_training,\n",
    "        # \"S15\": S15_profit_training,\n",
    "        # \"S16\": S16_profit_training,\n",
    "        # \"S12\": None,\n",
    "        \"S15\": None,\n",
    "        \"S16\": None,\n",
    "        \"S14\": S14_profit_training,\n",
    "    }\n",
    "\n",
    "    training_results = {\n",
    "        \"S1\": results_df_1,\n",
    "        \"S2\": results_df_2,\n",
    "        \"S12\": results_df_12,\n",
    "        # \"S15\": results_df_15,\n",
    "        # \"S16\": results_df_16,\n",
    "        # \"S12\": None,\n",
    "        \"S15\": None,\n",
    "        \"S16\": None,\n",
    "        \"S14\": results_df_14,\n",
    "    }\n",
    "\n",
    "    training_stimulation_results = {\n",
    "        \"baseline\": baseline_stimulation_df,\n",
    "        \"S1\": stimulation_results_df_1,\n",
    "        \"S2\": stimulation_results_df_2,\n",
    "        \"S12\": stimulation_results_df_12,\n",
    "        # \"S15\": stimulation_results_df_15,\n",
    "        # \"S16\": stimulation_results_df_16,\n",
    "        # \"S12\": None,\n",
    "        \"S15\": None,\n",
    "        \"S16\": None,\n",
    "        \"S14\": stimulation_results_df_14,\n",
    "    }\n",
    "\n",
    "    return training_profits, training_results, training_stimulation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1550,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for single fold testing.\n",
    "\n",
    "\n",
    "def perform_fold_testing(\n",
    "    results_df_1,\n",
    "    results_df_2,\n",
    "    results_df_12,\n",
    "    results_df_15,\n",
    "    results_df_16,\n",
    "    demand_df_test,\n",
    "    Qk_hat_df_test,\n",
    "    Q_star,\n",
    "    testing_df,\n",
    ") -> dict[str, float]:\n",
    "\n",
    "    # 1. Baseline model\n",
    "\n",
    "    (\n",
    "        test_baseline_avg_loss,\n",
    "        test_baseline_avg_lefts,\n",
    "        test_baseline_avg_profits,\n",
    "        test_baseline_avg_operation_profits,\n",
    "        test_stimulation_df_baseline,\n",
    "    ) = one_time_procurement(\n",
    "        Q_star=Q_star,\n",
    "        demand_df=demand_df_test,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        salvage_value=salvage_value,\n",
    "    )\n",
    "\n",
    "    print(f\"baseline_profit: {test_baseline_avg_profits}\")\n",
    "\n",
    "    # 2. S1 - Grid F & Grid R\n",
    "    if results_df_1 is not None:\n",
    "        assigned_T = results_df_1.iloc[0][\"R(T)\"]\n",
    "        assigned_F = results_df_1.iloc[0][\"F\"]\n",
    "\n",
    "        test_results_df_1, test_stimulation_results_df_1 = cal_test_fixed_F_fixed_R(\n",
    "            assigned_T=int(assigned_T),\n",
    "            assigned_F=assigned_F,\n",
    "            salvage_value=salvage_value,\n",
    "            cost=cost,\n",
    "            price=price,\n",
    "            Q_star=Q_star,\n",
    "            demand_df_test=demand_df_test,\n",
    "            Qk_hat_df_test=Qk_hat_df_test,\n",
    "        )\n",
    "\n",
    "    S1_profit_testing = test_results_df_1.iloc[0][\"average_profits\"]\n",
    "\n",
    "    # 3. S2 - Grid R & Flexible F\n",
    "\n",
    "    if results_df_2 is not None and len(results_df_2) > 0:\n",
    "        assigned_R = results_df_2.iloc[0][\"R\"]\n",
    "        alphas = results_df_2.iloc[0][\"alpha_values\"]\n",
    "\n",
    "        test_results_df_2, test_stimulation_results_df_2 = cal_test_flexible_F_fixed_R(\n",
    "            assigned_R=assigned_R[0],\n",
    "            alphas=alphas,\n",
    "            salvage_value=salvage_value,\n",
    "            cost=cost,\n",
    "            price=price,\n",
    "            Q_star=Q_star,\n",
    "            demand_df_test=demand_df_test,\n",
    "            Qk_hat_df_test=Qk_hat_df_test,\n",
    "            testing_df=testing_df,\n",
    "        )\n",
    "\n",
    "    S2_profit_testing = test_results_df_2.iloc[0][\"average_profits\"]\n",
    "\n",
    "    # 5. S14 - Optimized F & Rk\n",
    "    test_results_df_14, test_stimulation_results_df_14 = cal_optimized_F_R(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df=demand_df_test,\n",
    "        Qk_hat_df=Qk_hat_df_test,\n",
    "        training_df=testing_df,\n",
    "    )\n",
    "\n",
    "    S14_profit_testing = test_results_df_14.iloc[0][\"average_profits\"]\n",
    "\n",
    "    # 4. S12 - Beta without r\n",
    "    test_results_df_12, test_stimulation_results_df_12 = None, None\n",
    "    if results_df_12 is not None:\n",
    "        alphas = results_df_12.iloc[0][\"alpha_values\"]\n",
    "        betas = results_df_12.iloc[0][\"beta_values\"]\n",
    "\n",
    "        test_results_df_12, test_stimulation_results_df_12 = (\n",
    "            cal_test_fully_flexible_beta_with_softmax_12(\n",
    "                alphas=alphas,\n",
    "                betas=betas,\n",
    "                salvage_value=salvage_value,\n",
    "                cost=cost,\n",
    "                price=price,\n",
    "                Q_star=Q_star,\n",
    "                demand_df_test=demand_df_test,\n",
    "                Qk_hat_df_test=Qk_hat_df_test,\n",
    "                testing_df=testing_df,\n",
    "            )\n",
    "        )\n",
    "        S12_profit_testing = test_results_df_12.iloc[0][\"average_profits\"]\n",
    "    else:\n",
    "        S12_profit_testing = None\n",
    "\n",
    "    # # 6. S15 - Beta with Lasso\n",
    "    # test_results_df_15, test_stimulation_results_df_15 = None, None\n",
    "    # if results_df_15 is not None:\n",
    "    #     alphas = results_df_15.iloc[0][\"alpha_values\"]\n",
    "    #     betas = results_df_15.iloc[0][\"beta_values\"]\n",
    "\n",
    "    #     test_results_df_15, test_stimulation_results_df_15 = (\n",
    "    #         cal_test_fully_flexible_beta_with_lasso_15(\n",
    "    #             alphas=alphas,\n",
    "    #             betas=betas,\n",
    "    #             salvage_value=salvage_value,\n",
    "    #             cost=cost,\n",
    "    #             price=price,\n",
    "    #             Q_star=Q_star,\n",
    "    #             demand_df_test=demand_df_test,\n",
    "    #             Qk_hat_df_test=Qk_hat_df_test,\n",
    "    #             testing_df=testing_df,\n",
    "    #         )\n",
    "    #     )\n",
    "    #     S15_profit_testing = test_results_df_15.iloc[0][\"average_profits\"]\n",
    "    # else:\n",
    "    #     S15_profit_testing = None\n",
    "\n",
    "    # # 7. S16 - Beta with Second Training\n",
    "    # test_results_df_16, test_stimulation_results_df_16 = None, None\n",
    "    # if results_df_16 is not None:\n",
    "    #     alphas = results_df_16.iloc[0][\"alpha_values\"]\n",
    "    #     betas = results_df_16.iloc[0][\"beta_values\"]\n",
    "\n",
    "    #     test_results_df_16, test_stimulation_results_df_16 = (\n",
    "    #         cal_test_fully_flexible_beta_with_second_training_16(\n",
    "    #             alphas=alphas,\n",
    "    #             betas=betas,\n",
    "    #             salvage_value=salvage_value,\n",
    "    #             cost=cost,\n",
    "    #             price=price,\n",
    "    #             Q_star=Q_star,\n",
    "    #             demand_df_test=demand_df_test,\n",
    "    #             Qk_hat_df_test=Qk_hat_df_test,\n",
    "    #             testing_df=testing_df,\n",
    "    #         )\n",
    "    #     )\n",
    "    #     S16_profit_testing = test_results_df_16.iloc[0][\"average_profits\"]\n",
    "    # else:\n",
    "    #     S16_profit_testing = None\n",
    "\n",
    "    # print(f\"baseline_profit: {test_baseline_avg_profits}\")\n",
    "    # print(f\"S1_profit_testing: {S1_profit_testing}\")\n",
    "    # print(f\"S2_profit_testing: {S2_profit_testing}\")\n",
    "    # print(f\"S12_profit_testing: {S12_profit_testing}\")\n",
    "    # print(f\"S14_profit_testing: {S14_profit_testing}\")\n",
    "    # print(f\"S15_profit_testing: {S15_profit_testing}\")\n",
    "    # print(f\"S16_profit_testing: {S16_profit_testing}\")\n",
    "\n",
    "    # 整理利潤結果\n",
    "    testing_profits = {\n",
    "        \"baseline\": test_baseline_avg_profits,\n",
    "        \"S1\": S1_profit_testing,\n",
    "        \"S2\": S2_profit_testing,\n",
    "        \"S12\": S12_profit_testing,\n",
    "        # \"S15\": S15_profit_testing,\n",
    "        # \"S16\": S16_profit_testing,\n",
    "        # \"S12\": None,\n",
    "        \"S15\": None,\n",
    "        \"S16\": None,\n",
    "        \"S14\": S14_profit_testing,\n",
    "    }\n",
    "\n",
    "    testing_stimulation_results = {\n",
    "        \"baseline\": test_stimulation_df_baseline,\n",
    "        \"S1\": test_stimulation_results_df_1,\n",
    "        \"S2\": test_stimulation_results_df_2,\n",
    "        \"S12\": test_stimulation_results_df_12,\n",
    "        # \"S15\": test_stimulation_results_df_15,\n",
    "        # \"S16\": test_stimulation_results_df_16,\n",
    "        # \"S12\": None,\n",
    "        \"S15\": None,\n",
    "        \"S16\": None,\n",
    "        \"S14\": test_stimulation_results_df_14,\n",
    "    }\n",
    "\n",
    "    return testing_profits, testing_stimulation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Processing Fold 1 =====\n",
      "training_df: \n",
      "       X1   X2        X3\n",
      "0   250.0  0.0  7.097627\n",
      "1   250.0  0.0  7.430379\n",
      "2   250.0  0.0  7.205527\n",
      "3   250.0  0.0  7.089766\n",
      "4   250.0  0.0  6.847310\n",
      "5   250.0  0.0  7.291788\n",
      "6   250.0  0.0  6.875174\n",
      "7   250.0  0.0  7.783546\n",
      "8   250.0  0.0  7.927326\n",
      "9   250.0  0.0  6.766883\n",
      "10  250.0  0.0  7.583450\n",
      "11  250.0  0.0  7.057790\n",
      "12  250.0  0.0  7.136089\n",
      "13  250.0  0.0  7.851193\n",
      "14  250.0  0.0  6.142072\n",
      "demand_df_train: \n",
      "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
      "0   216.269540  211.134274  215.128316  217.994763  229.527662  228.343740   \n",
      "1   213.412362  212.203824  210.885199  212.928863  214.608230  221.012875   \n",
      "2   204.681787  207.336518  210.952538  203.368635  201.143341  212.945396   \n",
      "3   198.383496  200.987261  197.538109  202.580936  202.908901  212.987482   \n",
      "4   219.811740  215.888884  220.591784  218.304163  224.051815  230.563012   \n",
      "5   220.360046  221.653541  221.084469  221.365066  219.588375  230.349881   \n",
      "6   206.804647  210.281255  211.971112  211.899313  212.103444  223.938525   \n",
      "7   197.500672  202.217054  202.132739  203.477299  205.711701  209.558780   \n",
      "8   204.862165  204.349647  204.410897  203.832857  198.517193  209.219411   \n",
      "9   214.729484  211.058905  213.111249  213.393977  216.269393  226.294654   \n",
      "10  203.536333  198.875464  199.443303  206.642554  213.162637  213.806483   \n",
      "11  211.399931  203.772432  204.362386  211.367124  219.630126  222.009609   \n",
      "12  200.333009  200.122945  201.407273  202.457942  209.620603  212.527752   \n",
      "13  215.485256  214.091043  212.898490  213.282515  211.999879  219.028557   \n",
      "14  223.772374  219.297995  227.067323  224.128681  227.334861  242.102041   \n",
      "\n",
      "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
      "0   242.806583  289.728142  294.085892  302.742662  \n",
      "1   232.696730  291.971737  299.898413  310.098635  \n",
      "2   217.246014  274.878251  284.616328  292.693517  \n",
      "3   223.541107  289.059699  300.204667  305.030320  \n",
      "4   282.302153  291.526875  302.196239  297.751466  \n",
      "5   239.096051  287.137346  298.313381  302.956429  \n",
      "6   279.861703  289.879410  300.275223  301.905500  \n",
      "7   218.989494  282.840421  291.370366  300.913051  \n",
      "8   213.080292  285.593964  296.148638  306.810950  \n",
      "9   277.908923  287.515460  293.452452  298.903205  \n",
      "10  226.483521  286.300518  295.724523  295.565024  \n",
      "11  239.661313  287.100126  295.098417  300.312782  \n",
      "12  224.286097  289.751327  295.640317  296.230690  \n",
      "13  226.998326  277.137760  290.303325  296.421243  \n",
      "14  285.157984  297.060136  300.922758  304.073340  \n",
      "testing_df: \n",
      "       X1   X2        X3\n",
      "0   100.0  1.0  2.174259\n",
      "1   100.0  1.0  2.040437\n",
      "2   100.0  1.0  3.665240\n",
      "3   100.0  1.0  3.556314\n",
      "4   100.0  1.0  3.740024\n",
      "5   100.0  1.0  3.957237\n",
      "6   100.0  1.0  3.598317\n",
      "7   100.0  1.0  2.922959\n",
      "8   100.0  1.0  3.561058\n",
      "9   100.0  1.0  2.236549\n",
      "10  100.0  1.0  3.279842\n",
      "11  100.0  1.0  2.286707\n",
      "12  100.0  1.0  3.889338\n",
      "13  100.0  1.0  3.043697\n",
      "14  100.0  1.0  2.829324\n",
      "demand_df_test: \n",
      "    demand_t1  demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
      "0   70.227917  81.121645  131.788409  141.803321  143.426979  147.673785   \n",
      "1   79.608727  91.639215  128.702757  135.028793  134.579449  140.268787   \n",
      "2   63.419471  70.874302   77.661979  132.558616  142.859878  148.998521   \n",
      "3   52.116936  63.450198   73.716363  123.035381  131.841477  138.583452   \n",
      "4   60.415934  67.035420   74.759950  125.505731  131.973688  142.549592   \n",
      "5   63.891435  69.705305   78.722662  124.306490  138.151168  143.032748   \n",
      "6   70.216180  78.598394   84.946904  121.995492  133.578784  137.888674   \n",
      "7   63.185446  71.742871  120.581034  130.522874  136.377091  141.022977   \n",
      "8   70.992077  75.616666   82.533829  125.466173  133.000874  141.053282   \n",
      "9   70.526757  84.725666  130.149324  137.570580  142.534312  143.754643   \n",
      "10  55.599240  61.360904   73.969731  125.839593  135.145787  139.117788   \n",
      "11  76.219043  89.003219  127.269401  135.126808  137.205275  141.572859   \n",
      "12  52.094021  62.108609   68.768801  123.756371  140.592759  141.971262   \n",
      "13  76.509810  77.459588   92.319729  128.061079  135.441582  139.470053   \n",
      "14  71.680424  85.624544  120.815521  130.085328  134.069275  139.907755   \n",
      "\n",
      "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
      "0   150.205352  144.538643  148.686424  152.970565  \n",
      "1   145.314588  142.865421  141.157079  144.668688  \n",
      "2   155.162599  155.783147  153.172861  154.443828  \n",
      "3   136.399301  138.619786  142.363281  140.167618  \n",
      "4   141.600813  144.825519  147.015787  148.199725  \n",
      "5   145.171105  149.727225  148.451307  149.989241  \n",
      "6   143.451611  143.435230  141.816459  143.709674  \n",
      "7   141.719665  141.606493  143.111705  139.494170  \n",
      "8   140.385933  143.311775  144.849568  141.009104  \n",
      "9   141.951848  142.737482  144.830817  144.223385  \n",
      "10  140.487488  143.253560  142.044079  141.546400  \n",
      "11  140.719360  140.781289  142.703000  138.273542  \n",
      "12  141.598922  153.777150  147.074707  142.399240  \n",
      "13  144.019581  140.131849  141.812887  142.555552  \n",
      "14  138.392343  148.279216  141.817695  142.604815  \n",
      "===== Processing Fold 2 =====\n",
      "training_df: \n",
      "       X1   X2        X3\n",
      "0   250.0  0.0  6.529111\n",
      "1   250.0  0.0  7.548467\n",
      "2   250.0  0.0  6.912301\n",
      "3   250.0  0.0  7.136868\n",
      "4   250.0  0.0  6.037580\n",
      "5   250.0  0.0  7.235271\n",
      "6   250.0  0.0  7.224191\n",
      "7   250.0  0.0  7.233868\n",
      "8   250.0  0.0  7.887496\n",
      "9   250.0  0.0  7.363641\n",
      "10  250.0  0.0  6.719016\n",
      "11  250.0  0.0  6.874064\n",
      "12  250.0  0.0  7.395262\n",
      "13  250.0  0.0  6.120451\n",
      "14  250.0  0.0  7.333533\n",
      "demand_df_train: \n",
      "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
      "0   222.161187  222.674769  225.353917  223.221310  222.893692  238.065400   \n",
      "1   220.530094  219.738950  218.759769  220.933432  220.124623  228.300609   \n",
      "2   213.362537  218.822792  216.870371  217.362713  219.563800  229.111736   \n",
      "3   199.797687  207.323601  203.789124  207.736732  210.971595  217.800933   \n",
      "4   201.639849  204.461900  204.373246  211.688475  219.980465  230.453114   \n",
      "5   203.068617  210.253707  211.044927  208.252652  210.515431  217.622674   \n",
      "6   200.028086  200.649557  201.110990  203.196222  208.172300  212.642934   \n",
      "7   209.370477  211.540854  211.088956  213.227575  217.505323  222.607287   \n",
      "8   212.532495  213.315555  214.680239  211.469208  208.301130  217.041472   \n",
      "9   207.618493  211.794800  208.888392  213.191496  215.856144  221.701392   \n",
      "10  207.056248  210.847827  208.026988  209.464407  214.390723  222.751866   \n",
      "11  206.903862  203.906252  207.385176  205.308491  204.528274  217.356427   \n",
      "12  206.768808  202.093273  201.684832  207.410315  211.014986  215.716571   \n",
      "13  211.774461  215.380556  214.549172  217.086505  225.127256  235.226440   \n",
      "14  216.725708  216.467046  218.712706  218.300728  222.101593  227.007575   \n",
      "\n",
      "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
      "0   280.312076  287.113818  295.476806  301.581639  \n",
      "1   239.480837  278.599581  292.608620  299.370778  \n",
      "2   264.688890  278.406242  285.268849  285.786165  \n",
      "3   231.228251  281.000002  285.687011  285.367038  \n",
      "4   279.671471  284.587074  289.916916  290.508358  \n",
      "5   225.661659  285.838794  290.975307  292.078159  \n",
      "6   225.213431  291.325190  296.608369  302.124771  \n",
      "7   231.530616  282.838947  288.006589  291.168008  \n",
      "8   222.363761  259.051539  279.508591  284.723369  \n",
      "9   231.422106  289.526303  300.437872  305.779847  \n",
      "10  280.193543  295.421032  298.712701  297.452760  \n",
      "11  277.360165  290.208239  298.996474  304.379612  \n",
      "12  228.428223  270.682926  285.297802  290.140345  \n",
      "13  272.923294  287.175093  287.743459  285.591008  \n",
      "14  233.518253  273.349587  282.149117  284.578008  \n",
      "testing_df: \n",
      "       X1   X2        X3\n",
      "0   100.0  1.0  3.341276\n",
      "1   100.0  1.0  2.420765\n",
      "2   100.0  1.0  2.257853\n",
      "3   100.0  1.0  2.630857\n",
      "4   100.0  1.0  2.727422\n",
      "5   100.0  1.0  3.140394\n",
      "6   100.0  1.0  2.877203\n",
      "7   100.0  1.0  3.976748\n",
      "8   100.0  1.0  2.204090\n",
      "9   100.0  1.0  2.417754\n",
      "10  100.0  1.0  2.322619\n",
      "11  100.0  1.0  3.306217\n",
      "12  100.0  1.0  2.506583\n",
      "13  100.0  1.0  2.932622\n",
      "14  100.0  1.0  2.488851\n",
      "demand_df_test: \n",
      "    demand_t1  demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
      "0   72.009341  74.997743   87.005613  128.348847  132.655500  142.127494   \n",
      "1   75.795766  83.482632  141.773017  150.698577  153.139419  157.886776   \n",
      "2   69.530409  78.997508  139.540892  144.071128  143.380065  150.365428   \n",
      "3   68.809892  78.215789  128.691086  141.307123  149.945005  149.781344   \n",
      "4   64.970365  70.317737  144.067324  148.114171  154.964918  157.228781   \n",
      "5   61.214051  71.651536   83.195967  142.057095  151.063978  154.218832   \n",
      "6   68.135098  77.074529  116.844346  133.674097  137.638788  143.839906   \n",
      "7   67.593216  71.811630   78.765094  123.220756  134.731523  142.090958   \n",
      "8   82.760314  98.611711  142.416633  144.507976  144.328414  150.527009   \n",
      "9   78.667055  87.035540  135.495516  145.326754  154.982092  152.497608   \n",
      "10  73.323629  85.298402  134.014373  142.154358  144.857784  148.793222   \n",
      "11  66.698211  76.821448   83.183982  136.220205  146.781319  149.712745   \n",
      "12  65.400532  74.729399  133.985731  142.957392  152.664942  150.652859   \n",
      "13  61.466612  68.275961  126.848571  133.236399  138.154667  143.807840   \n",
      "14  70.101169  80.342774  125.119997  136.763122  140.617546  144.351719   \n",
      "\n",
      "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
      "0   143.667318  146.757340  145.226417  146.246406  \n",
      "1   157.120115  160.255430  159.174422  154.083678  \n",
      "2   143.087074  150.143303  151.464211  150.393109  \n",
      "3   152.159759  146.176481  151.359503  156.142474  \n",
      "4   154.225794  161.729377  158.960790  160.413033  \n",
      "5   157.783124  159.201692  156.785961  157.766049  \n",
      "6   148.444796  141.058813  145.839363  148.821352  \n",
      "7   142.116537  141.833349  147.603113  144.935219  \n",
      "8   149.120515  152.715787  151.569603  151.212534  \n",
      "9   152.332204  154.227160  153.781491  150.241387  \n",
      "10  151.988611  153.420355  149.963613  149.547872  \n",
      "11  154.821903  153.684922  152.712027  154.495989  \n",
      "12  149.533798  153.490008  152.052310  148.127874  \n",
      "13  141.438731  141.799862  145.915902  141.017522  \n",
      "14  146.299292  144.897715  145.727324  147.517382  \n",
      "===== Processing Fold 3 =====\n",
      "training_df: \n",
      "       X1   X2        X3\n",
      "0   250.0  0.0  6.317939\n",
      "1   250.0  0.0  6.220750\n",
      "2   250.0  0.0  7.312659\n",
      "3   250.0  0.0  6.276366\n",
      "4   250.0  0.0  6.393165\n",
      "5   250.0  0.0  6.737450\n",
      "6   250.0  0.0  7.641986\n",
      "7   250.0  0.0  6.194203\n",
      "8   250.0  0.0  7.675890\n",
      "9   250.0  0.0  6.192197\n",
      "10  250.0  0.0  7.952919\n",
      "11  250.0  0.0  6.937302\n",
      "12  250.0  0.0  7.953522\n",
      "13  250.0  0.0  7.209691\n",
      "14  250.0  0.0  7.478527\n",
      "demand_df_train: \n",
      "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
      "0   216.647776  217.707632  217.106637  216.842714  219.597076  233.419212   \n",
      "1   206.392192  207.466613  209.843167  207.604607  213.000352  224.961254   \n",
      "2   208.757150  211.215125  210.251555  213.156271  218.505110  222.001409   \n",
      "3   211.765499  214.318603  215.414811  216.141472  219.949536  233.053752   \n",
      "4   212.809346  217.810872  213.306858  217.226836  220.572888  233.189850   \n",
      "5   215.874024  216.634876  219.161295  220.970899  229.078910  234.109029   \n",
      "6   208.663645  212.202013  212.214505  209.993864  212.365034  216.827046   \n",
      "7   214.795873  214.957004  218.508049  221.137495  226.253158  238.703949   \n",
      "8   204.887138  207.948928  204.303492  203.239600  207.493960  209.886562   \n",
      "9   213.251598  213.261233  212.440552  219.307496  221.331998  236.889734   \n",
      "10  208.525023  203.488282  205.712190  203.930813  203.325865  209.200737   \n",
      "11  205.089368  202.923453  206.838589  205.766863  206.676825  217.322137   \n",
      "12  200.903965  205.939596  203.960886  203.417689  204.627082  208.684890   \n",
      "13  213.954358  215.974160  219.545605  218.086512  222.010790  227.634165   \n",
      "14  208.134237  213.335557  212.206389  209.640137  210.502901  217.426165   \n",
      "\n",
      "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
      "0   281.223054  286.606612  295.373362  295.021682  \n",
      "1   275.069930  290.849170  293.042855  290.427386  \n",
      "2   233.240220  284.029835  294.011162  298.315636  \n",
      "3   285.949828  296.587134  299.984362  300.882037  \n",
      "4   283.261878  291.515898  295.193378  301.422180  \n",
      "5   272.091637  289.444930  292.637615  290.154113  \n",
      "6   222.394845  288.244280  297.610300  300.054982  \n",
      "7   283.869552  292.548952  301.227187  296.088081  \n",
      "8   219.793122  286.423417  297.882888  307.923009  \n",
      "9   296.471696  298.622569  307.131742  309.556117  \n",
      "10  211.768872  282.906452  294.373221  295.898815  \n",
      "11  276.893707  286.436047  296.672410  301.681387  \n",
      "12  216.679969  282.292518  293.965063  298.664190  \n",
      "13  232.487659  282.208998  294.230272  299.601931  \n",
      "14  223.577690  277.934792  282.421103  285.004960  \n",
      "testing_df: \n",
      "       X1   X2        X3\n",
      "0   100.0  1.0  2.078376\n",
      "1   100.0  1.0  2.565614\n",
      "2   100.0  1.0  2.240393\n",
      "3   100.0  1.0  2.592280\n",
      "4   100.0  1.0  2.237455\n",
      "5   100.0  1.0  2.635966\n",
      "6   100.0  1.0  2.828526\n",
      "7   100.0  1.0  2.128295\n",
      "8   100.0  1.0  3.384944\n",
      "9   100.0  1.0  3.133203\n",
      "10  100.0  1.0  2.530779\n",
      "11  100.0  1.0  3.046496\n",
      "12  100.0  1.0  2.187881\n",
      "13  100.0  1.0  3.151893\n",
      "14  100.0  1.0  3.858592\n",
      "demand_df_test: \n",
      "    demand_t1  demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
      "0   76.726007  85.292909  133.499628  142.686827  151.989907  148.099649   \n",
      "1   73.215452  84.322469  140.436462  147.706836  153.427440  155.765750   \n",
      "2   81.614354  93.288630  142.735808  149.774088  154.774819  155.977932   \n",
      "3   53.997127  65.378692  122.601776  137.369862  143.971341  145.596807   \n",
      "4   79.623523  88.635007  129.643968  136.108997  141.327015  142.297723   \n",
      "5   66.573648  73.473881  116.509127  130.907484  138.170199  139.414829   \n",
      "6   61.543065  69.925424  118.981441  128.541003  130.878560  138.357764   \n",
      "7   77.934606  89.308782  127.931099  137.811266  140.377104  143.458587   \n",
      "8   61.555771  65.481206   76.431186  141.016287  148.612409  155.152840   \n",
      "9   71.879524  75.816228   88.691319  125.840719  138.654339  137.945803   \n",
      "10  62.698196  78.611085  139.791254  143.076516  142.163674  150.919528   \n",
      "11  64.781553  72.263140   83.800937  130.848821  141.944226  142.279298   \n",
      "12  75.532997  88.519768  134.606680  145.260208  152.214092  151.198150   \n",
      "13  61.766267  71.418492   79.609229  136.806694  149.697938  149.059237   \n",
      "14  68.819794  74.071775   80.358485  123.003555  129.832291  140.982057   \n",
      "\n",
      "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
      "0   147.917016  153.114936  149.021591  145.097141  \n",
      "1   155.706461  157.681604  157.247505  159.518788  \n",
      "2   156.344506  152.764874  157.058150  156.135556  \n",
      "3   148.718305  148.766359  147.117258  151.321785  \n",
      "4   143.193646  140.258585  143.374846  140.789340  \n",
      "5   143.089660  141.209537  141.000788  144.971862  \n",
      "6   139.188552  143.200519  140.266246  142.386797  \n",
      "7   144.180047  142.103770  144.426712  143.175555  \n",
      "8   160.099228  158.393803  158.380157  160.635284  \n",
      "9   139.968061  144.014399  140.495582  140.628759  \n",
      "10  145.896928  149.493779  152.352166  146.679443  \n",
      "11  146.301937  144.274959  144.628356  146.560884  \n",
      "12  151.674544  151.286388  152.224362  152.695641  \n",
      "13  151.665693  152.244795  151.654347  150.452055  \n",
      "14  145.590577  148.889060  145.948128  145.404458  \n"
     ]
    }
   ],
   "source": [
    "for fold_idx in range(len(training_data_folds)):\n",
    "    print(f\"===== Processing Fold {fold_idx + 1} =====\")\n",
    "    # 取出該 fold 的訓練資料與需求資料\n",
    "    training_df, testing_df = training_data_folds[fold_idx]\n",
    "    demand_df_train, demand_df_test = demand_folds[fold_idx]\n",
    "\n",
    "    print(f\"training_df: \\n{training_df}\")\n",
    "    print(f\"demand_df_train: \\n{demand_df_train}\")\n",
    "    print(f\"testing_df: \\n{testing_df}\")\n",
    "    print(f\"demand_df_test: \\n{demand_df_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Processing Fold 1 =====\n",
      "mean of sum: 2400.9164885329315\n",
      "std of sum: 75.12106255060029\n",
      "60.0 percentile of sum: 2419.9481921146094\n",
      "Fold 1 Q_star: 2419.9481921146094\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=0 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x91d6a2b8\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [2e+02, 2e+03]\n",
      "Presolve removed 67 rows and 104 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 226 rows, 160 columns, 596 nonzeros\n",
      "Presolved model has 38 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 122 continuous, 38 integer (38 binary)\n",
      "\n",
      "Root relaxation: objective 2.135785e+07, 90 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1358e+07    0   23          - 2.1358e+07      -     -    0s\n",
      "H    0     0                    1.533045e+07 2.1358e+07  39.3%     -    0s\n",
      "     0     2 2.1358e+07    0   22 1.5330e+07 2.1358e+07  39.3%     -    0s\n",
      "H   65    50                    2.126659e+07 2.1331e+07  0.30%   3.0    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 5\n",
      "\n",
      "Explored 89 nodes (342 simplex iterations) in 0.03 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 2.12666e+07 1.53305e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.126659272098e+07, best bound 2.133056532030e+07, gap 0.3008%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.663467484140016, Left1: 10.821840147252573\n",
      "f_vars[i]: -2.2979, F_vars[i]: 0.0913, Q0_vars[i]: 220.9330\n",
      "f_train: -2.2979053744558717, F_train: 0.09129658563175952, Q0_train: 220.93300734581308\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 6.53818768963235, Left1: 16.3513511661763\n",
      "f_vars[i]: -2.3028, F_vars[i]: 0.0909, Q0_vars[i]: 219.9519\n",
      "f_train: -2.302802118577419, F_train: 0.09089115650280928, Q0_train: 219.95188985817933\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 15.932126022999004, Left1: 57.40703832354666\n",
      "f_vars[i]: -2.2995, F_vars[i]: 0.0912, Q0_vars[i]: 220.6144\n",
      "f_train: -2.299493217279936, F_train: 0.09116494123819016, Q0_train: 220.61443473359287\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 15.584540728472348, Left0: 22.572736275878476, Left1: 0.0\n",
      "f_vars[i]: -2.2978, F_vars[i]: 0.0913, Q0_vars[i]: 220.9562\n",
      "f_train: -2.2977896979651296, F_train: 0.0913061827828712, Q0_train: 220.95623195429522\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 16.49139874122784, Left0: 1.861920096126173, Left1: 0.0\n",
      "f_vars[i]: -2.2942, F_vars[i]: 0.0916, Q0_vars[i]: 221.6737\n",
      "f_train: -2.294221726227416, F_train: 0.09160264712004863, Q0_train: 221.6736602910742\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 28.912919434053038\n",
      "f_vars[i]: -2.3008, F_vars[i]: 0.0911, Q0_vars[i]: 220.3600\n",
      "f_train: -2.300762633286167, F_train: 0.09105981974829769, Q0_train: 220.36004617417518\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 64.92216545802512, Left0: 14.786455321107365, Left1: 0.0\n",
      "f_vars[i]: -2.2946, F_vars[i]: 0.0916, Q0_vars[i]: 221.5911\n",
      "f_train: -2.2946317824410043, F_train: 0.09156853139923699, Q0_train: 221.59110201417337\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.030983430383458, Left0: 21.41419625980229, Left1: 0.0\n",
      "f_vars[i]: -2.3080, F_vars[i]: 0.0905, Q0_vars[i]: 218.9149\n",
      "f_train: -2.307999295986745, F_train: 0.09046262608242056, Q0_train: 218.91486844209354\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 13.631780019361683, Left1: 41.864765588095\n",
      "f_vars[i]: -2.3101, F_vars[i]: 0.0903, Q0_vars[i]: 218.4939\n",
      "f_train: -2.3101151423188377, F_train: 0.0902886868535779, Q0_train: 218.49394451971793\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 6.190269781163465, Left0: 7.182620395043837, Left1: 0.0\n",
      "f_vars[i]: -2.2930, F_vars[i]: 0.0917, Q0_vars[i]: 221.9121\n",
      "f_train: -2.293038176269706, F_train: 0.09170117982340127, Q0_train: 221.9121043284166\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 15.965544107257369, Left1: 18.70257611314446\n",
      "f_vars[i]: -2.3051, F_vars[i]: 0.0907, Q0_vars[i]: 219.5019\n",
      "f_train: -2.3050547025461987, F_train: 0.09070519704264805, Q0_train: 219.50187759875556\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.650799332851767, Left1: 25.495575191333955\n",
      "f_vars[i]: -2.2973, F_vars[i]: 0.0913, Q0_vars[i]: 221.0507\n",
      "f_train: -2.2973191343094213, F_train: 0.09134523265921117, Q0_train: 221.05073063194644\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 20.484689888512612, Left1: 0.6220769243082032\n",
      "f_vars[i]: -2.2985, F_vars[i]: 0.0912, Q0_vars[i]: 220.8194\n",
      "f_train: -2.298471379432482, F_train: 0.09124963986022352, Q0_train: 220.81940101085712\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 3.2314801470246324, Left1: 74.75668494963384\n",
      "f_vars[i]: -2.3090, F_vars[i]: 0.0904, Q0_vars[i]: 218.7167\n",
      "f_train: -2.3089947871338095, F_train: 0.09038075131394877, Q0_train: 218.7167357441504\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 33.210092787400754, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -2.2838, F_vars[i]: 0.0925, Q0_vars[i]: 223.7724\n",
      "f_train: -2.283843515575619, F_train: 0.0924699026770457, Q0_train: 223.77237380833063\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=1 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x9058b5cf\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [4e+02, 2e+03]\n",
      "Presolve removed 62 rows and 96 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 231 rows, 168 columns, 611 nonzeros\n",
      "Presolved model has 41 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 127 continuous, 41 integer (41 binary)\n",
      "\n",
      "Root relaxation: objective 2.136763e+07, 99 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1368e+07    0   24          - 2.1368e+07      -     -    0s\n",
      "H    0     0                    1.659489e+07 2.1368e+07  28.8%     -    0s\n",
      "     0     2 2.1368e+07    0   23 1.6595e+07 2.1368e+07  28.8%     -    0s\n",
      "H   10    14                    2.118776e+07 2.1349e+07  0.76%   3.9    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 5\n",
      "\n",
      "Explored 17 nodes (160 simplex iterations) in 0.02 seconds (0.01 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 2.11878e+07 1.65949e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.118776048617e+07, best bound 2.134620798908e+07, gap 0.7478%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 19.515842809797746, Left1: 7.365957424068711\n",
      "f_vars[i]: -1.4849, F_vars[i]: 0.1847, Q0_vars[i]: 446.9197\n",
      "f_train: -1.484946130317747, F_train: 0.18468149764571257, Q0_train: 446.9196563447606\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 13.579247477075441, Left1: 17.38139039457269\n",
      "f_vars[i]: -1.5063, F_vars[i]: 0.1815, Q0_vars[i]: 439.1954\n",
      "f_train: -1.5062877397063232, F_train: 0.18148960169441375, Q0_train: 439.1954335079971\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 32.38520629049044, Left1: 60.892338377598435\n",
      "f_vars[i]: -1.4919, F_vars[i]: 0.1836, Q0_vars[i]: 444.4035\n",
      "f_train: -1.4918664676848794, F_train: 0.18364174609402062, Q0_train: 444.4035114569953\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 14.253173962472829, Left0: 47.73263375742511, Left1: 0.0\n",
      "f_vars[i]: -1.4844, F_vars[i]: 0.1848, Q0_vars[i]: 447.1034\n",
      "f_train: -1.4844419744093345, F_train: 0.18475742260766762, Q0_train: 447.1033908191801\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 17.09865373606567, Left0: 17.098653736062023, Left1: 0.0\n",
      "f_vars[i]: -1.4689, F_vars[i]: 0.1871, Q0_vars[i]: 452.7993\n",
      "f_train: -1.4688915888376826, F_train: 0.18711114546618518, Q0_train: 452.7992781953885\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.38614513825085756, Left1: 35.70178121762683\n",
      "f_vars[i]: -1.4974, F_vars[i]: 0.1828, Q0_vars[i]: 442.3999\n",
      "f_train: -1.4973989970317536, F_train: 0.18281377465192902, Q0_train: 442.39986346258326\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 59.597895235511714, Left0: 35.05581844075728, Left1: 0.0\n",
      "f_vars[i]: -1.4707, F_vars[i]: 0.1868, Q0_vars[i]: 452.1418\n",
      "f_train: -1.4706787476764014, F_train: 0.18683946958618602, Q0_train: 452.1418366407434\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.06968950008104002, Left0: 31.39202785572445, Left1: 0.0\n",
      "f_vars[i]: -1.5289, F_vars[i]: 0.1781, Q0_vars[i]: 431.1114\n",
      "f_train: -1.528938735437328, F_train: 0.17814901452299386, Q0_train: 431.1113856219183\n",
      "f_train, F_train, Q0_train 不相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 18.641124928682892, Left1: 41.029108518723206\n",
      "f_vars[i]: -1.5382, F_vars[i]: 0.1768, Q0_vars[i]: 427.8538\n",
      "f_train: -1.5381602844553939, F_train: 0.17680287444786352, Q0_train: 427.8537963807736\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 8.129785061455323, Left0: 28.91259719459958, Left1: 0.0\n",
      "f_vars[i]: -1.4637, F_vars[i]: 0.1879, Q0_vars[i]: 454.7010\n",
      "f_train: -1.4637332917606194, F_train: 0.18789699195759696, Q0_train: 454.70098599156006\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 33.26541280633967, Left1: 11.690751835662923\n",
      "f_vars[i]: -1.5161, F_vars[i]: 0.1800, Q0_vars[i]: 435.6772\n",
      "f_train: -1.5161052359820908, F_train: 0.1800357593717036, Q0_train: 435.677210407535\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 32.67904784021583, Left1: 16.981841268348035\n",
      "f_vars[i]: -1.4824, F_vars[i]: 0.1851, Q0_vars[i]: 447.8514\n",
      "f_train: -1.4823911043856395, F_train: 0.1850665287285724, Q0_train: 447.8514116176352\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.2934776588274417, Left0: 45.565531755417425, Left1: 0.0\n",
      "f_vars[i]: -1.4874, F_vars[i]: 0.1843, Q0_vars[i]: 446.0215\n",
      "f_train: -1.4874129647740646, F_train: 0.18431034480233482, Q0_train: 446.0214856924305\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 76.21561964569901\n",
      "f_vars[i]: -1.5333, F_vars[i]: 0.1775, Q0_vars[i]: 429.5763\n",
      "f_train: -1.533277410827154, F_train: 0.17751466743025654, Q0_train: 429.5762985216754\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 33.270002710471545, Left0: 26.613646222006736, Left1: 0.0\n",
      "f_vars[i]: -1.4237, F_vars[i]: 0.1941, Q0_vars[i]: 469.6840\n",
      "f_train: -1.4236599589249812, F_train: 0.1940884586203396, Q0_train: 469.68401454860197\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=2 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x03a68304\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [6e+02, 2e+03]\n",
      "Presolve removed 57 rows and 88 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 236 rows, 176 columns, 628 nonzeros\n",
      "Presolved model has 44 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 132 continuous, 44 integer (44 binary)\n",
      "\n",
      "Root relaxation: objective 2.140193e+07, 96 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1402e+07    0   25          - 2.1402e+07      -     -    0s\n",
      "H    0     0                    1.789470e+07 2.1402e+07  19.6%     -    0s\n",
      "     0     2 2.1402e+07    0   24 1.7895e+07 2.1402e+07  19.6%     -    0s\n",
      "H    9     8                    2.106969e+07 2.1391e+07  1.53%   2.0    0s\n",
      "H   70    33                    2.117278e+07 2.1348e+07  0.83%   6.2    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 8\n",
      "\n",
      "Explored 92 nodes (663 simplex iterations) in 0.03 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 3: 2.11728e+07 2.10697e+07 1.78947e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.117278158633e+07, best bound 2.132636134607e+07, gap 0.7254%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 21.751527114789088, Left1: 14.188952677451994\n",
      "f_vars[i]: -0.9719, F_vars[i]: 0.2745, Q0_vars[i]: 664.2837\n",
      "f_train: -0.9718934656605503, F_train: 0.27450325525687663, Q0_train: 664.2836562884537\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.9383098573396182, Left0: 25.751206423398948, Left1: 0.0\n",
      "f_vars[i]: -0.9761, F_vars[i]: 0.2737, Q0_vars[i]: 662.2526\n",
      "f_train: -0.9761118710813989, F_train: 0.2736639542973079, Q0_train: 662.2525914487053\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 40.65378620576436, Left1: 80.28754172483832\n",
      "f_vars[i]: -0.9733, F_vars[i]: 0.2742, Q0_vars[i]: 663.6246\n",
      "f_train: -0.9732613469731584, F_train: 0.27423092407101596, Q0_train: 663.6246289275738\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 29.858702540690956, Left0: 67.42281671153431, Left1: 0.0\n",
      "f_vars[i]: -0.9718, F_vars[i]: 0.2745, Q0_vars[i]: 664.3317\n",
      "f_train: -0.9717938136625085, F_train: 0.2745231015196267, Q0_train: 664.3316832161161\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 8.304393200793925, Left0: 9.521695852059867, Left1: 0.0\n",
      "f_vars[i]: -0.9687, F_vars[i]: 0.2751, Q0_vars[i]: 665.8141\n",
      "f_train: -0.9687201077578895, F_train: 0.2751356853734965, Q0_train: 665.8141044058068\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 17.697813089594092\n",
      "f_vars[i]: -0.9744, F_vars[i]: 0.2740, Q0_vars[i]: 663.0981\n",
      "f_train: -0.9743549126627427, F_train: 0.27401332726912764, Q0_train: 663.0980559402342\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 52.293265198500535, Left0: 36.58661608490772, Left1: 0.0\n",
      "f_vars[i]: -0.9691, F_vars[i]: 0.2751, Q0_vars[i]: 665.6436\n",
      "f_train: -0.9690733594923723, F_train: 0.2750652398429278, Q0_train: 665.6436298714646\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 58.250687809584356, Left1: 5.5694401536632085\n",
      "f_vars[i]: -0.9806, F_vars[i]: 0.2728, Q0_vars[i]: 660.1012\n",
      "f_train: -0.9805890912122496, F_train: 0.2727749107254751, Q0_train: 660.1011520643375\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 45.60381409907552, Left1: 37.953941117017166\n",
      "f_vars[i]: -0.9824, F_vars[i]: 0.2724, Q0_vars[i]: 659.2265\n",
      "f_train: -0.9824118324900115, F_train: 0.27241348559301903, Q0_train: 659.2265219684656\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 10.073366001509385, Left0: 27.406660928223783, Left1: 0.0\n",
      "f_vars[i]: -0.9677, F_vars[i]: 0.2753, Q0_vars[i]: 666.3063\n",
      "f_train: -0.9677005132204748, F_train: 0.2753390758842611, Q0_train: 666.3062989046249\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 59.46446814713415, Left1: 9.739335080624187\n",
      "f_vars[i]: -0.9781, F_vars[i]: 0.2733, Q0_vars[i]: 661.3196\n",
      "f_train: -0.9780524079338363, F_train: 0.27327839937880277, Q0_train: 661.319568520708\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 44.99232545909591, Left1: 6.749579986707886\n",
      "f_vars[i]: -0.9714, F_vars[i]: 0.2746, Q0_vars[i]: 664.5271\n",
      "f_train: -0.9713884364921233, F_train: 0.27460384388408976, Q0_train: 664.5270755550255\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 62.18546488279338, Left1: 6.4533111548325905\n",
      "f_vars[i]: -0.9724, F_vars[i]: 0.2744, Q0_vars[i]: 664.0487\n",
      "f_train: -0.972381062807204, F_train: 0.2744061603688325, Q0_train: 664.0486916896677\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 17.214765319060902, Left1: 56.80149960724157\n",
      "f_vars[i]: -0.9814, F_vars[i]: 0.2726, Q0_vars[i]: 659.6896\n",
      "f_train: -0.981446678447144, F_train: 0.27260482536428804, Q0_train: 659.6895543020277\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 10.671887366479723, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -0.9598, F_vars[i]: 0.2769, Q0_vars[i]: 670.1377\n",
      "f_train: -0.9597795752355538, F_train: 0.2769223297561902, Q0_train: 670.1376912496581\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=3 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xed0ec375\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [8e+02, 2e+03]\n",
      "Presolve removed 61 rows and 96 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 232 rows, 168 columns, 614 nonzeros\n",
      "Presolved model has 40 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 128 continuous, 40 integer (40 binary)\n",
      "\n",
      "Root relaxation: objective 2.142452e+07, 93 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1425e+07    0   23          - 2.1425e+07      -     -    0s\n",
      "H    0     0                    1.918526e+07 2.1425e+07  11.7%     -    0s\n",
      "     0     2 2.1425e+07    0   22 1.9185e+07 2.1425e+07  11.7%     -    0s\n",
      "H   68    44                    2.113391e+07 2.1404e+07  1.28%   2.9    0s\n",
      "H  157    32                    2.114930e+07 2.1404e+07  1.20%   7.9    0s\n",
      "H  163    32                    2.117465e+07 2.1404e+07  1.08%   7.7    0s\n",
      "H  166    32                    2.118325e+07 2.1404e+07  1.04%   7.6    0s\n",
      "H  204    53                    2.118459e+07 2.1404e+07  1.04%   7.4    0s\n",
      "H  212    53                    2.119481e+07 2.1404e+07  0.99%   7.2    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 5\n",
      "\n",
      "Explored 242 nodes (1684 simplex iterations) in 0.03 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 7: 2.11948e+07 2.11846e+07 2.11833e+07 ... 1.91853e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.119481038256e+07, best bound 2.140385908742e+07, gap 0.9863%\n",
      "Model status: 2\n",
      "Lost0: 0.3663551398182392, Lost1: 0.0, Left0: 0.0, Left1: 35.46782250676506\n",
      "f_vars[i]: -0.5952, F_vars[i]: 0.3554, Q0_vars[i]: 860.1605\n",
      "f_train: -0.5951859296438504, F_train: 0.3554458479057347, Q0_train: 860.1605370341271\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 11.688011751528279, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -0.6146, F_vars[i]: 0.3510, Q0_vars[i]: 849.4302\n",
      "f_train: -0.6145949172150684, F_train: 0.3510117490567857, Q0_train: 849.4302475409555\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 30.334913859455355, Left1: 30.929898312101614\n",
      "f_vars[i]: -0.6015, F_vars[i]: 0.3540, Q0_vars[i]: 856.6744\n",
      "f_train: -0.6014795853612682, F_train: 0.3540052609588503, Q0_train: 856.6743912564303\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 19.04660973403861, Left0: 60.92495367097763, Left1: 0.0\n",
      "f_vars[i]: -0.5947, F_vars[i]: 0.3556, Q0_vars[i]: 860.4148\n",
      "f_train: -0.594727428338622, F_train: 0.35555089939408413, Q0_train: 860.4147561934373\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 6.324137754259823, Lost1: 14.84237077985463, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -0.5806, F_vars[i]: 0.3588, Q0_vars[i]: 868.2724\n",
      "f_train: -0.5805852315252273, F_train: 0.3587979430191213, Q0_train: 868.2724335435632\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 30.57116133247672, Lost1: 0.0, Left0: 0.0, Left1: 61.13860176888693\n",
      "f_vars[i]: -0.6065, F_vars[i]: 0.3529, Q0_vars[i]: 853.8920\n",
      "f_train: -0.606511108119264, F_train: 0.3528554715124298, Q0_train: 853.8919603642526\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 24.03340978335234, Left0: 26.41143717579257, Left1: 0.0\n",
      "f_vars[i]: -0.5822, F_vars[i]: 0.3584, Q0_vars[i]: 867.3678\n",
      "f_train: -0.5822105514838548, F_train: 0.35842410457042917, Q0_train: 867.3677638655078\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 32.78157270366273, Left1: 26.920006779489313\n",
      "f_vars[i]: -0.6352, F_vars[i]: 0.3463, Q0_vars[i]: 838.1093\n",
      "f_train: -0.6351947176618948, F_train: 0.3463335863056882, Q0_train: 838.1093360490192\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 16.065230363974365, Left1: 2.639159488338464\n",
      "f_vars[i]: -0.6436, F_vars[i]: 0.3444, Q0_vars[i]: 833.5208\n",
      "f_train: -0.6435811953178313, F_train: 0.34443745456006863, Q0_train: 833.520795459196\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 27.393293135344038, Left0: 18.592303246066535, Left1: 0.0\n",
      "f_vars[i]: -0.5759, F_vars[i]: 0.3599, Q0_vars[i]: 870.8859\n",
      "f_train: -0.57589405186607, F_train: 0.35987791849555234, Q0_train: 870.8859182452807\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 36.01717106389788, Left1: 26.777781474823314\n",
      "f_vars[i]: -0.6235, F_vars[i]: 0.3490, Q0_vars[i]: 844.5148\n",
      "f_train: -0.6235233752206231, F_train: 0.3489805394726383, Q0_train: 844.5148255799921\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 30.547374016484696, Left1: 7.853195919527934\n",
      "f_vars[i]: -0.5929, F_vars[i]: 0.3560, Q0_vars[i]: 861.4492\n",
      "f_train: -0.5928622779614727, F_train: 0.3559783846624507, Q0_train: 861.4492483957765\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.041904143696229, Left0: 54.59596036143353, Left1: 0.0\n",
      "f_vars[i]: -0.5974, F_vars[i]: 0.3549, Q0_vars[i]: 858.9171\n",
      "f_train: -0.5974293761633312, F_train: 0.3549320319622329, Q0_train: 858.9171290705702\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 19.808326962379, Lost1: 0.0, Left0: 0.0, Left1: 50.16853538949749\n",
      "f_vars[i]: -0.6391, F_vars[i]: 0.3454, Q0_vars[i]: 835.9490\n",
      "f_train: -0.6391404977192208, F_train: 0.34544085689309406, Q0_train: 835.9489771209645\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.9616437921498857, Lost1: 0.0, Left0: 0.0, Left1: 5.197429791510142\n",
      "f_vars[i]: -0.5394, F_vars[i]: 0.3683, Q0_vars[i]: 891.3047\n",
      "f_train: -0.5394496204840337, F_train: 0.36831562385235883, Q0_train: 891.3047280690803\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=4 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x2c81176e\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 1e+03]\n",
      "Presolve removed 54 rows and 74 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 239 rows, 190 columns, 642 nonzeros\n",
      "Presolved model has 55 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 135 continuous, 55 integer (55 binary)\n",
      "\n",
      "Root relaxation: objective 2.141900e+07, 101 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1419e+07    0   23          - 2.1419e+07      -     -    0s\n",
      "H    0     0                    2.046140e+07 2.1419e+07  4.68%     -    0s\n",
      "     0     2 2.1419e+07    0   21 2.0461e+07 2.1419e+07  4.68%     -    0s\n",
      "H   44    32                    2.046140e+07 2.1398e+07  4.58%   4.8    0s\n",
      "H   64    31                    2.106297e+07 2.1398e+07  1.59%   5.0    0s\n",
      "H  154    31                    2.108904e+07 2.1398e+07  1.47%  10.9    0s\n",
      "H  191    31                    2.113847e+07 2.1398e+07  1.23%   9.6    0s\n",
      "H  195    31                    2.114174e+07 2.1398e+07  1.21%   9.4    0s\n",
      "H  218    31                    2.114500e+07 2.1398e+07  1.20%   9.0    0s\n",
      "H  226    31                    2.115502e+07 2.1398e+07  1.15%   8.7    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 5\n",
      "\n",
      "Explored 256 nodes (2139 simplex iterations) in 0.04 seconds (0.03 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 8: 2.1155e+07 2.1145e+07 2.11417e+07 ... 2.04614e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.115501792673e+07, best bound 2.116230185227e+07, gap 0.0344%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.8758122729490543, Left1: 32.77842322855099\n",
      "f_vars[i]: -0.1974, F_vars[i]: 0.4508, Q0_vars[i]: 1090.9304\n",
      "f_train: -0.19740931475492624, F_train: 0.4508073226587679, Q0_train: 1090.9303654601126\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 12.84115183979111, Left0: 16.647407777622902, Left1: 0.0\n",
      "f_vars[i]: -0.2145, F_vars[i]: 0.4466, Q0_vars[i]: 1080.6859\n",
      "f_train: -0.21452302835333908, F_train: 0.44657397531514653, Q0_train: 1080.6858842093231\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 60.123659317366446, Left1: 30.379878788966835\n",
      "f_vars[i]: -0.2030, F_vars[i]: 0.4494, Q0_vars[i]: 1087.6065\n",
      "f_train: -0.2029586934146676, F_train: 0.4494337855286377, Q0_train: 1087.606476765252\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 18.723839757471524, Left0: 88.77388357968368, Left1: 0.0\n",
      "f_vars[i]: -0.1970, F_vars[i]: 0.4509, Q0_vars[i]: 1091.1726\n",
      "f_train: -0.1970050350369149, F_train: 0.4509074162531543, Q0_train: 1091.1725867728903\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 22.724741816714186, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -0.1845, F_vars[i]: 0.4540, Q0_vars[i]: 1098.6484\n",
      "f_train: -0.18453527044828033, F_train: 0.453996655366543, Q0_train: 1098.648385380345\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 19.10099432126617, Lost1: 0.0, Left0: 0.0, Left1: 49.781774566006405\n",
      "f_vars[i]: -0.2074, F_vars[i]: 0.4483, Q0_vars[i]: 1084.9505\n",
      "f_train: -0.20739519681950908, F_train: 0.44833625157738416, Q0_train: 1084.9505014641315\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 22.994282464589105, Left0: 44.72899711939459, Left1: 0.0\n",
      "f_vars[i]: -0.1860, F_vars[i]: 0.4536, Q0_vars[i]: 1097.7888\n",
      "f_train: -0.18596838282344536, F_train: 0.4536414336593712, Q0_train: 1097.7887672522747\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 58.79390886384306, Left1: 26.307174391830472\n",
      "f_vars[i]: -0.2327, F_vars[i]: 0.4421, Q0_vars[i]: 1069.8334\n",
      "f_train: -0.2326867313150655, F_train: 0.44208937018238686, Q0_train: 1069.8333721259535\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 49.44883526729586, Left1: 6.045547169893325\n",
      "f_vars[i]: -0.2401, F_vars[i]: 0.4403, Q0_vars[i]: 1065.4216\n",
      "f_train: -0.24008143833811596, F_train: 0.4402662816321884, Q0_train: 1065.4215922848357\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 27.39439032624, Left0: 32.567136679091135, Left1: 0.0\n",
      "f_vars[i]: -0.1804, F_vars[i]: 0.4550, Q0_vars[i]: 1101.1301\n",
      "f_train: -0.180398861744275, F_train: 0.45502219731561827, Q0_train: 1101.1301437659474\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 54.31915850496341, Left1: 28.332399206763398\n",
      "f_vars[i]: -0.2224, F_vars[i]: 0.4446, Q0_vars[i]: 1075.9794\n",
      "f_train: -0.22239562204849433, F_train: 0.4446291260024235, Q0_train: 1075.9794496310635\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 41.626024617664825, Left1: 7.971697653653791\n",
      "f_vars[i]: -0.1954, F_vars[i]: 0.4513, Q0_vars[i]: 1092.1580\n",
      "f_train: -0.1953604541820207, F_train: 0.45131463067790284, Q0_train: 1092.1580245838636\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 5.703440758648867, Left0: 75.80354539074148, Left1: 0.0\n",
      "f_vars[i]: -0.1994, F_vars[i]: 0.4503, Q0_vars[i]: 1089.7453\n",
      "f_train: -0.19938745509155492, F_train: 0.45031762232742634, Q0_train: 1089.7453160286047\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 30.110623429442057\n",
      "f_vars[i]: -0.2362, F_vars[i]: 0.4412, Q0_vars[i]: 1067.7572\n",
      "f_train: -0.23616589011073302, F_train: 0.44123142205826055, Q0_train: 1067.7571821140457\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.161155499840904, Lost1: 0.0, Left0: 0.0, Left1: 5.728283949883577\n",
      "f_vars[i]: -0.1483, F_vars[i]: 0.4630, Q0_vars[i]: 1120.4401\n",
      "f_train: -0.14826428704579486, F_train: 0.4630016790992556, Q0_train: 1120.440076282272\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=5 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x49e6315e\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 1e+03]\n",
      "Presolve removed 55 rows and 75 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 238 rows, 189 columns, 639 nonzeros\n",
      "Presolved model has 55 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 134 continuous, 55 integer (55 binary)\n",
      "\n",
      "Root relaxation: objective 2.147591e+07, 100 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1476e+07    0   23          - 2.1476e+07      -     -    0s\n",
      "H    0     0                    2.002238e+07 2.1476e+07  7.26%     -    0s\n",
      "     0     2 2.1476e+07    0   21 2.0022e+07 2.1476e+07  7.26%     -    0s\n",
      "H    9    12                    2.008232e+07 2.1467e+07  6.90%   2.9    0s\n",
      "H   64    50                    2.014258e+07 2.1460e+07  6.54%   3.6    0s\n",
      "H  484   126                    2.095657e+07 2.1460e+07  2.40%   4.4    0s\n",
      "H  505   126                    2.106583e+07 2.1460e+07  1.87%   4.3    0s\n",
      "H  540   126                    2.115185e+07 2.1460e+07  1.46%   4.1    0s\n",
      "H  698    40                    2.117027e+07 2.1410e+07  1.13%   4.5    0s\n",
      "H  718    40                    2.117221e+07 2.1410e+07  1.13%   4.5    0s\n",
      "H  730    40                    2.117221e+07 2.1410e+07  1.13%   4.4    0s\n",
      "*  906     5              49    2.117221e+07 2.1212e+07  0.19%   4.0    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 6\n",
      "\n",
      "Explored 911 nodes (3721 simplex iterations) in 0.05 seconds (0.06 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 10: 2.11722e+07 2.11722e+07 2.11722e+07 ... 2.00224e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.117221495039e+07, best bound 2.121175348352e+07, gap 0.1867%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 12.002866466192245\n",
      "f_vars[i]: 0.1797, F_vars[i]: 0.5448, Q0_vars[i]: 1318.3983\n",
      "f_train: 0.17969939959000714, F_train: 0.5448043467097654, Q0_train: 1318.3982938764775\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 12.711812056468943, Left0: 17.49065661735814, Left1: 0.0\n",
      "f_vars[i]: 0.1533, F_vars[i]: 0.5383, Q0_vars[i]: 1302.5428\n",
      "f_train: 0.15330905266140793, F_train: 0.5382523699221797, Q0_train: 1302.5428494945827\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 72.8324452574157, Left1: 29.14944957423222\n",
      "f_vars[i]: 0.1711, F_vars[i]: 0.5427, Q0_vars[i]: 1313.2608\n",
      "f_train: 0.1711419332501286, F_train: 0.542681357611766, Q0_train: 1313.2607702468947\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 103.38617353244133, Left1: 12.484315472907497\n",
      "f_vars[i]: 0.1803, F_vars[i]: 0.5450, Q0_vars[i]: 1318.7724\n",
      "f_train: 0.18032282255154974, F_train: 0.5449589466492153, Q0_train: 1318.7724177204504\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 26.18133633881712, Left0: 1.089861969184259, Left1: 0.0\n",
      "f_vars[i]: 0.1996, F_vars[i]: 0.5497, Q0_vars[i]: 1330.3014\n",
      "f_train: 0.19955192859680626, F_train: 0.5497230897398085, Q0_train: 1330.301397179507\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 25.25053324415503, Lost1: 0.0, Left0: 0.0, Left1: 47.55937418068233\n",
      "f_vars[i]: 0.1643, F_vars[i]: 0.5410, Q0_vars[i]: 1309.1508\n",
      "f_train: 0.16430058561798533, F_train: 0.5409829942804754, Q0_train: 1309.1508189737845\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 17.568704598247223, Left0: 51.978210830248386, Left1: 0.0\n",
      "f_vars[i]: 0.1973, F_vars[i]: 0.5492, Q0_vars[i]: 1328.9775\n",
      "f_train: 0.1973419855268358, F_train: 0.5491760079103172, Q0_train: 1328.9774874952905\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 65.0809556153646, Left1: 3.34010902474256\n",
      "f_vars[i]: 0.1253, F_vars[i]: 0.5313, Q0_vars[i]: 1285.6797\n",
      "f_train: 0.12529956074654713, F_train: 0.5312839710827614, Q0_train: 1285.6796853211988\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 12.72186526857331, Left0: 53.61204850696509, Left1: 0.0\n",
      "f_vars[i]: 0.1139, F_vars[i]: 0.5284, Q0_vars[i]: 1278.8056\n",
      "f_train: 0.11389649018261361, F_train: 0.5284433809238642, Q0_train: 1278.805604301637\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 7.868926141560905, Left0: 39.26241602778433, Left1: 0.0\n",
      "f_vars[i]: 0.2059, F_vars[i]: 0.5513, Q0_vars[i]: 1334.1210\n",
      "f_train: 0.2059305126551081, F_train: 0.5513014594828303, Q0_train: 1334.1209701856208\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 59.76999901817821, Left1: 8.592720468223888\n",
      "f_vars[i]: 0.1412, F_vars[i]: 0.5352, Q0_vars[i]: 1295.2380\n",
      "f_train: 0.14116905290926063, F_train: 0.5352337690475972, Q0_train: 1295.2379917654214\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 47.751116375693115, Left1: 15.80196652654422\n",
      "f_vars[i]: 0.1829, F_vars[i]: 0.5456, Q0_vars[i]: 1320.2941\n",
      "f_train: 0.1828588623808488, F_train: 0.5455877584590954, Q0_train: 1320.29410972295\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 90.09677036931645, Left1: 2.8624357323594722\n",
      "f_vars[i]: 0.1766, F_vars[i]: 0.5440, Q0_vars[i]: 1316.5674\n",
      "f_train: 0.17664899153819025, F_train: 0.5440477653593997, Q0_train: 1316.5674062054725\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 4.338705626697902, Lost1: 0.0, Left0: 0.0, Left1: 18.61137471772554\n",
      "f_vars[i]: 0.1199, F_vars[i]: 0.5299, Q0_vars[i]: 1282.4461\n",
      "f_train: 0.11993449447327098, F_train: 0.5299477341646371, Q0_train: 1282.4460612069472\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 17.40267933051996\n",
      "f_vars[i]: 0.2555, F_vars[i]: 0.5635, Q0_vars[i]: 1363.7033\n",
      "f_train: 0.25548390560043166, F_train: 0.5635258135038607, Q0_train: 1363.7032735985822\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=6 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x9eb8e87b\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [9e+02, 2e+03]\n",
      "Presolve removed 64 rows and 108 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 229 rows, 156 columns, 608 nonzeros\n",
      "Presolved model has 31 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 125 continuous, 31 integer (31 binary)\n",
      "Found heuristic solution: objective -1.48151e+07\n",
      "\n",
      "Root relaxation: objective 2.153709e+07, 86 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1537e+07    0   20 -1.482e+07 2.1537e+07   245%     -    0s\n",
      "     0     2 2.1537e+07    0   20 -1.482e+07 2.1537e+07   245%     -    0s\n",
      "H   52    40                    1.422425e+07 2.1529e+07  51.4%   5.8    0s\n",
      "H   59    40                    1.748548e+07 2.1529e+07  23.1%   5.4    0s\n",
      "H   64    54                    1.969747e+07 2.1529e+07  9.30%   5.3    0s\n",
      "H  479   126                    1.991477e+07 2.1529e+07  8.11%   3.1    0s\n",
      "H  481   126                    1.992211e+07 2.1529e+07  8.07%   3.1    0s\n",
      "*  567   136              27    2.107913e+07 2.1529e+07  2.13%   2.9    0s\n",
      "H  687   162                    2.111278e+07 2.1529e+07  1.97%   2.7    0s\n",
      "H  723   162                    2.111675e+07 2.1529e+07  1.95%   2.7    0s\n",
      "H  747   162                    2.114906e+07 2.1529e+07  1.80%   2.7    0s\n",
      "H  795   162                    2.116948e+07 2.1529e+07  1.70%   2.8    0s\n",
      "H 1024   111                    2.118418e+07 2.1483e+07  1.41%   2.9    0s\n",
      "H 1086   111                    2.118461e+07 2.1483e+07  1.41%   2.9    0s\n",
      "* 1188    14              63    2.118461e+07 2.1458e+07  1.29%   2.8    0s\n",
      "H 1229    14                    2.118463e+07 2.1391e+07  0.97%   2.8    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 3\n",
      "\n",
      "Explored 1294 nodes (3655 simplex iterations) in 0.06 seconds (0.07 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 10: 2.11846e+07 2.11846e+07 2.11846e+07 ... 1.99221e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.118463379359e+07, best bound 2.118502234915e+07, gap 0.0018%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 13.128155861615761, Left1: 0.04775530961205732\n",
      "f_vars[i]: 0.6215, F_vars[i]: 0.6506, Q0_vars[i]: 1574.3331\n",
      "f_train: 0.6215227289120437, F_train: 0.6505647902245623, Q0_train: 1574.3330879573496\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 15.743110954146118, Left0: 30.072519377686262, Left1: 0.0\n",
      "f_vars[i]: 0.5737, F_vars[i]: 0.6396, Q0_vars[i]: 1547.8206\n",
      "f_train: 0.5736674849465537, F_train: 0.6396089967637676, Q0_train: 1547.8206353787184\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 108.10223406838577, Left1: 14.23015100521775\n",
      "f_vars[i]: 0.6060, F_vars[i]: 0.6470, Q0_vars[i]: 1565.7765\n",
      "f_train: 0.6060049473334486, F_train: 0.6470289388310679, Q0_train: 1565.776510770077\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 136.02754787821175, Left1: 0.42649138263175246\n",
      "f_vars[i]: 0.6227, F_vars[i]: 0.6508, Q0_vars[i]: 1574.9549\n",
      "f_train: 0.6226532202238493, F_train: 0.6508217413266777, Q0_train: 1574.9548963123757\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 17.48493212365713, Lost1: 0.0, Left0: 0.0, Left1: 11.068459316503064\n",
      "f_vars[i]: 0.6575, F_vars[i]: 0.6587, Q0_vars[i]: 1594.0287\n",
      "f_train: 0.6575225443567879, F_train: 0.6587036430217252, Q0_train: 1594.028690069731\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 14.589782461321988, Lost1: 0.0, Left0: 0.0, Left1: 21.333973394683625\n",
      "f_vars[i]: 0.5936, F_vars[i]: 0.6442, Q0_vars[i]: 1558.9077\n",
      "f_train: 0.5935991096658071, F_train: 0.6441905218021862, Q0_train: 1558.9076886125672\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 34.98705284427229, Left1: 4.370024669617806\n",
      "f_vars[i]: 0.6535, F_vars[i]: 0.6578, Q0_vars[i]: 1591.8471\n",
      "f_train: 0.6535151182683997, F_train: 0.6578021487869373, Q0_train: 1591.8471207260543\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 79.70426876160138, Left1: 4.331826936646621\n",
      "f_vars[i]: 0.5229, F_vars[i]: 0.6278, Q0_vars[i]: 1519.2920\n",
      "f_train: 0.5228761455010502, F_train: 0.6278200590076849, Q0_train: 1519.2920167689344\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 13.383151173327974, Left0: 69.29667624427259, Left1: 0.0\n",
      "f_vars[i]: 0.5022, F_vars[i]: 0.6230, Q0_vars[i]: 1507.5691\n",
      "f_train: 0.5021982542528163, F_train: 0.6229757898746608, Q0_train: 1507.5691364383563\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 27.5431213240662, Left1: 11.068880293766142\n",
      "f_vars[i]: 0.6691, F_vars[i]: 0.6613, Q0_vars[i]: 1600.3098\n",
      "f_train: 0.669089224290564, F_train: 0.6612991912965428, Q0_train: 1600.3097824249219\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 73.55297656652158, Left1: 9.344705632906539\n",
      "f_vars[i]: 0.5517, F_vars[i]: 0.6345, Q0_vars[i]: 1535.5033\n",
      "f_train: 0.5516532745440974, F_train: 0.6345190782107741, Q0_train: 1535.5032961783913\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 65.27919957021243, Left1: 9.707441652883745\n",
      "f_vars[i]: 0.6273, F_vars[i]: 0.6519, Q0_vars[i]: 1577.4822\n",
      "f_train: 0.627251977681099, F_train: 0.6518660956491471, Q0_train: 1577.4821796669626\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.4271236148599655, Left0: 120.53185964458919, Left1: 0.0\n",
      "f_vars[i]: 0.6160, F_vars[i]: 0.6493, Q0_vars[i]: 1571.2875\n",
      "f_train: 0.615991235828268, F_train: 0.6493062696049027, Q0_train: 1571.2875332590654\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 16.27594635999094\n",
      "f_vars[i]: 0.5131, F_vars[i]: 0.6255, Q0_vars[i]: 1513.7841\n",
      "f_train: 0.5131473398853719, F_train: 0.6255439940961367, Q0_train: 1513.7840576010979\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.5736337765530379, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 0.7589, F_vars[i]: 0.6811, Q0_vars[i]: 1648.2876\n",
      "f_train: 0.7589474484030474, F_train: 0.6811251698371709, Q0_train: 1648.287623351218\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=7 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x3489b3b9\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [6e+02, 2e+03]\n",
      "Presolve removed 53 rows and 92 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 240 rows, 172 columns, 644 nonzeros\n",
      "Presolved model has 36 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 136 continuous, 36 integer (36 binary)\n",
      "\n",
      "Root relaxation: objective 2.159295e+07, 99 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1593e+07    0   23          - 2.1593e+07      -     -    0s\n",
      "H    0     0                    7343464.9868 2.1593e+07   194%     -    0s\n",
      "     0     2 2.1593e+07    0   23 7343464.99 2.1593e+07   194%     -    0s\n",
      "*  556   336              32    2.085998e+07 2.1592e+07  3.51%   2.6    0s\n",
      "* 1053   390              35    2.086459e+07 2.1592e+07  3.48%   3.1    0s\n",
      "H 1114   452                    2.087750e+07 2.1592e+07  3.42%   3.0    0s\n",
      "H 1133   452                    2.091697e+07 2.1592e+07  3.23%   3.0    0s\n",
      "H 1190   452                    2.118536e+07 2.1592e+07  1.92%   2.9    0s\n",
      "H 1331   496                    2.122555e+07 2.1592e+07  1.72%   2.8    0s\n",
      "* 1332   496              63    2.122600e+07 2.1592e+07  1.72%   2.8    0s\n",
      "* 1529   496              29    2.122600e+07 2.1592e+07  1.72%   2.9    0s\n",
      "H 1614   418                    2.123951e+07 2.1591e+07  1.66%   2.9    0s\n",
      "\n",
      "Explored 1923 nodes (6779 simplex iterations) in 0.07 seconds (0.08 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 10: 2.12395e+07 2.1226e+07 2.1226e+07 ... 7.34346e+06\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.123951013612e+07, best bound 2.145131694229e+07, gap 0.9972%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 2.062057959322374, Left0: 11.678243192574564, Left1: 0.0\n",
      "f_vars[i]: 1.2066, F_vars[i]: 0.7697, Q0_vars[i]: 1862.6113\n",
      "f_train: 1.2065647269871629, F_train: 0.7696905527392044, Q0_train: 1862.6112615889322\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.7714169976093217, Left0: 21.57774393495552, Left1: 0.0\n",
      "f_vars[i]: 1.1349, F_vars[i]: 0.7568, Q0_vars[i]: 1831.2976\n",
      "f_train: 1.1349471988601094, F_train: 0.7567507311672709, Q0_train: 1831.2975637696459\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.48522597578892146, Left0: 120.03429094584385, Left1: 0.0\n",
      "f_vars[i]: 1.1833, F_vars[i]: 0.7655, Q0_vars[i]: 1852.5868\n",
      "f_train: 1.1833416678909447, F_train: 0.7655481124911703, Q0_train: 1852.586770799759\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.516276723064152, Left0: 135.3496956744845, Left1: 0.0\n",
      "f_vars[i]: 1.2083, F_vars[i]: 0.7700, Q0_vars[i]: 1863.3367\n",
      "f_train: 1.2082565581557387, F_train: 0.7699903217373469, Q0_train: 1863.3366870340392\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 17.654302223690138, Lost1: 0.0, Left0: 0.0, Left1: 16.852778351511347\n",
      "f_vars[i]: 1.2604, F_vars[i]: 0.7791, Q0_vars[i]: 1885.3861\n",
      "f_train: 1.2604400723315923, F_train: 0.7791018544787249, Q0_train: 1885.3861242189298\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 16.151680106387516, Lost1: 0.0, Left0: 0.0, Left1: 19.321446496492864\n",
      "f_vars[i]: 1.1648, F_vars[i]: 0.7622, Q0_vars[i]: 1844.4831\n",
      "f_train: 1.1647757730280393, F_train: 0.7621994143489048, Q0_train: 1844.4830947844462\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.5923020498643154, Left0: 36.14479233411766, Left1: 0.0\n",
      "f_vars[i]: 1.2544, F_vars[i]: 0.7781, Q0_vars[i]: 1882.8842\n",
      "f_train: 1.2544427786847518, F_train: 0.778067979860797, Q0_train: 1882.884201206402\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 74.35215149116209, Left1: 0.026022853903555188\n",
      "f_vars[i]: 1.0589, F_vars[i]: 0.7425, Q0_vars[i]: 1796.7803\n",
      "f_train: 1.0589356715973457, F_train: 0.7424870982304711, Q0_train: 1796.780311031251\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.6226334071061501, Left0: 58.48854034955286, Left1: 0.0\n",
      "f_vars[i]: 1.0280, F_vars[i]: 0.7365, Q0_vars[i]: 1782.3550\n",
      "f_train: 1.0279902759548856, F_train: 0.7365260834354996, Q0_train: 1782.3549640549913\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 32.278502275694656, Left1: 2.7630438677313123\n",
      "f_vars[i]: 1.2778, F_vars[i]: 0.7821, Q0_vars[i]: 1892.5605\n",
      "f_train: 1.2777501298477802, F_train: 0.7820665553816689, Q0_train: 1892.5605468091696\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 68.24704855909363, Left1: 3.5810763078926584\n",
      "f_vars[i]: 1.1020, F_vars[i]: 0.7506, Q0_vars[i]: 1816.4979\n",
      "f_train: 1.1020019414118407, F_train: 0.7506350211561293, Q0_train: 1816.4978623846866\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.7715909498133442, Left0: 66.97778813409366, Left1: 0.0\n",
      "f_vars[i]: 1.2151, F_vars[i]: 0.7712, Q0_vars[i]: 1866.2808\n",
      "f_train: 1.2151388058312826, F_train: 0.7712069383220902, Q0_train: 1866.2808361387852\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 118.54526160578018, Left1: 4.662283537001144\n",
      "f_vars[i]: 1.1983, F_vars[i]: 0.7682, Q0_vars[i]: 1859.0522\n",
      "f_train: 1.1982865984335274, F_train: 0.7682198386580389, Q0_train: 1859.0522097070982\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.9019027258169672, Lost1: 0.0, Left0: 0.0, Left1: 2.1216720607066013\n",
      "f_vars[i]: 1.0444, F_vars[i]: 0.7397, Q0_vars[i]: 1790.0199\n",
      "f_train: 1.0443760757811396, F_train: 0.7396934898812656, Q0_train: 1790.0199235571147\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 1.255045816476013\n",
      "f_vars[i]: 1.4122, F_vars[i]: 0.8041, Q0_vars[i]: 1945.9214\n",
      "f_train: 1.4122270096953395, F_train: 0.8041169639188107, Q0_train: 1945.9213930840147\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 210 rows, 435 columns and 960 nonzeros\n",
      "Model fingerprint: 0x395c1b6e\n",
      "Model has 105 general constraints\n",
      "Variable types: 315 continuous, 120 integer (120 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Presolve removed 198 rows and 409 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 12 rows, 26 columns, 61 nonzeros\n",
      "Presolved model has 6 SOS constraint(s)\n",
      "Variable types: 12 continuous, 14 integer (14 binary)\n",
      "Found heuristic solution: objective 2.159695e+07\n",
      "\n",
      "Root relaxation: interrupted, 8 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0          -    0      2.1597e+07 2.1599e+07  0.01%     -    0s\n",
      "\n",
      "Explored 1 nodes (8 simplex iterations) in 0.02 seconds (0.00 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.1597e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.159695033977e+07, best bound 2.159907625691e+07, gap 0.0098%\n",
      "\n",
      "model.status is optimal: True\n",
      "model.status is TIME_LIMIT: False\n",
      "\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 1.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 1.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 1.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 667 and 669 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 667 and 669 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 435 rows, 741 columns and 1830 nonzeros\n",
      "Model fingerprint: 0x31d4be36\n",
      "Model has 240 general constraints\n",
      "Variable types: 621 continuous, 120 integer (120 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 5e+06]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e-03, 1e+00]\n",
      "  GenCon coe range [1e+00, 1e+00]\n",
      "Presolve removed 21 rows and 216 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 534 rows, 526 columns, 1910 nonzeros\n",
      "Presolved model has 200 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 326 continuous, 200 integer (200 binary)\n",
      "\n",
      "Root relaxation: objective 2.160426e+07, 217 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1604e+07    0   50          - 2.1604e+07      -     -    0s\n",
      "     0     2 2.1604e+07    0   50          - 2.1604e+07      -     -    0s\n",
      "* 2095  1377             111    1.779032e+07 2.1603e+07  21.4%   3.4    0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_65248/565741137.py:107: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_65248/348315154.py:156: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 5513  2188              83    2.048541e+07 2.1601e+07  5.45%   3.1    0s\n",
      "H 6054  1961                    2.059055e+07 2.1599e+07  4.90%   3.2    0s\n",
      "* 9223  1629              78    2.111777e+07 2.1595e+07  2.26%   4.5    0s\n",
      "H 9488  1562                    2.113203e+07 2.1594e+07  2.19%   4.6    0s\n",
      "H10759  1794                    2.113203e+07 2.1592e+07  2.18%   5.2    0s\n",
      "*19889  3505              98    2.116397e+07 2.1580e+07  1.97%   7.1    1s\n",
      "*19894  3501              98    2.116526e+07 2.1580e+07  1.96%   7.1    1s\n",
      "*19902  3496              96    2.116612e+07 2.1580e+07  1.95%   7.1    1s\n",
      "H20336  3543                    2.117420e+07 2.1580e+07  1.92%   7.1    1s\n",
      "*35193  4583              63    2.118033e+07 2.1553e+07  1.76%   8.9    2s\n",
      "H36149  4588                    2.118461e+07 2.1551e+07  1.73%   9.0    2s\n",
      "H36585  4588                    2.118461e+07 2.1551e+07  1.73%   9.1    2s\n",
      "H37994  4796                    2.118461e+07 2.1547e+07  1.71%   9.3    2s\n",
      "*61253  6510              75    2.118463e+07 2.1496e+07  1.47%  11.1    3s\n",
      "H62713  6705                    2.118464e+07 2.1488e+07  1.43%  11.2    3s\n",
      " 79127  9219 2.1454e+07   72   67 2.1185e+07 2.1465e+07  1.32%  11.6    5s\n",
      "*86069  9993              88    2.119294e+07 2.1460e+07  1.26%  11.6    5s\n",
      "*86388  9980              83    2.119439e+07 2.1460e+07  1.26%  11.6    5s\n",
      "H87913 10222                    2.119761e+07 2.1459e+07  1.23%  11.6    5s\n",
      "H87913 10222                    2.119761e+07 2.1459e+07  1.23%  11.6    5s\n",
      "*107794  9675              51    2.123064e+07 2.1442e+07  1.00%  11.9    6s\n",
      "\n",
      "Cutting planes:\n",
      "  Cover: 3\n",
      "  Implied bound: 1\n",
      "\n",
      "Explored 109014 nodes (1304478 simplex iterations) in 6.53 seconds (11.75 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 10: 2.12306e+07 2.11976e+07 2.11976e+07 ... 2.11846e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.123063547378e+07, best bound 2.144143622722e+07, gap 0.9929%\n",
      "\n",
      "model.status is optimal: True\n",
      "model.status is TIME_LIMIT: False\n",
      "\n",
      "f_vars[i]: -2.2619, F_vars[i]: 0.0943, Q0_vars[i]: 228.2659\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 1.0, tau_vars = 9.598111295744544e-05\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.000904018887042555\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.0009040188870425546\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.000904018887042555\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.0009040188870425535\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.0009040188870425546\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0009040188870425546\n",
      "第 9 天補貨策略: R_vars = -0.0, tau_vars = -0.0009040188870425546\n",
      "*** 於第[2]天進貨 ***\n",
      "\n",
      "f_vars[i]: -2.2883, F_vars[i]: 0.0921, Q0_vars[i]: 222.8763\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 1.0, tau_vars = 5.359880071930988e-05\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.0009464011992806906\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.0009464011992806902\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.0009464011992806906\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.0009464011992806891\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.0009464011992806902\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0009464011992806902\n",
      "第 9 天補貨策略: R_vars = -0.0, tau_vars = -0.0009464011992806902\n",
      "*** 於第[2]天進貨 ***\n",
      "\n",
      "f_vars[i]: -2.2705, F_vars[i]: 0.0936, Q0_vars[i]: 226.5055\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 1.0, tau_vars = 8.223801168767684e-05\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.0009177619883123236\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.0009177619883123232\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.0009177619883123236\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.0009177619883123221\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.0009177619883123232\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0009177619883123234\n",
      "第 9 天補貨策略: R_vars = -0.0, tau_vars = -0.0009177619883123232\n",
      "*** 於第[2]天進貨 ***\n",
      "\n",
      "f_vars[i]: -2.2613, F_vars[i]: 0.0944, Q0_vars[i]: 228.3946\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 1.0, tau_vars = 9.698231641581625e-05\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.0009030176835841837\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.0009030176835841835\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.0009030176835841837\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.0009030176835841826\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.0009030176835841835\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0009030176835841837\n",
      "第 9 天補貨策略: R_vars = -0.0, tau_vars = -0.0009030176835841835\n",
      "*** 於第[2]天進貨 ***\n",
      "\n",
      "f_vars[i]: -2.2421, F_vars[i]: 0.0960, Q0_vars[i]: 232.3969\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 1.0, tau_vars = 0.00012786383452072214\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.0008721361654792783\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.0008721361654792779\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.0008721361654792783\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.000872136165479277\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.0008721361654792779\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0008721361654792779\n",
      "第 9 天補貨策略: R_vars = -0.0, tau_vars = -0.0008721361654792779\n",
      "*** 於第[2]天進貨 ***\n",
      "\n",
      "f_vars[i]: -2.2773, F_vars[i]: 0.0930, Q0_vars[i]: 225.1070\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 1.0, tau_vars = 7.125095902559515e-05\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.0009287490409744053\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.0009287490409744048\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.0009287490409744053\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.0009287490409744038\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.0009287490409744048\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0009287490409744051\n",
      "第 9 天補貨策略: R_vars = -0.0, tau_vars = -0.0009287490409744048\n",
      "*** 於第[2]天進貨 ***\n",
      "\n",
      "f_vars[i]: -2.2443, F_vars[i]: 0.0958, Q0_vars[i]: 231.9337\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 1.0, tau_vars = 0.00012431471493266197\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.0008756852850673385\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.0008756852850673381\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.0008756852850673385\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.0008756852850673372\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.0008756852850673381\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0008756852850673381\n",
      "第 9 天補貨策略: R_vars = -0.0, tau_vars = -0.0008756852850673381\n",
      "*** 於第[2]天進貨 ***\n",
      "\n",
      "f_vars[i]: -2.3162, F_vars[i]: 0.0898, Q0_vars[i]: 217.2814\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 1.0, tau_vars = 8.616177520798864e-06\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.0009913838224792015\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.0009913838224792013\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.0009913838224792015\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.0009913838224792002\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.0009913838224792013\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0009913838224792013\n",
      "第 9 天補貨策略: R_vars = -0.0, tau_vars = -0.0009913838224792013\n",
      "*** 於第[2]天進貨 ***\n",
      "\n",
      "f_vars[i]: -2.3276, F_vars[i]: 0.0889, Q0_vars[i]: 215.0401\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 1.0, tau_vars = -9.696901061369542e-06\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.00100969690106137\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.0010096969010613696\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.00100969690106137\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.0010096969010613686\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.0010096969010613696\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0010096969010613696\n",
      "第 9 天補貨策略: R_vars = -0.0, tau_vars = -0.0010096969010613696\n",
      "*** 於第[2]天進貨 ***\n",
      "\n",
      "f_vars[i]: -2.2357, F_vars[i]: 0.0966, Q0_vars[i]: 233.7383\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 1.0, tau_vars = 0.00013810769914014386\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.0008618923008598566\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.0008618923008598562\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.0008618923008598566\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.0008618923008598553\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.0008618923008598562\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0008618923008598564\n",
      "第 9 天補貨策略: R_vars = -0.0, tau_vars = -0.0008618923008598562\n",
      "*** 於第[2]天進貨 ***\n",
      "\n",
      "f_vars[i]: -2.3004, F_vars[i]: 0.0911, Q0_vars[i]: 220.4356\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 1.0, tau_vars = 3.4102230194546984e-05\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.0009658977698054535\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.0009658977698054531\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.0009658977698054535\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.000965897769805452\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.0009658977698054531\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0009658977698054533\n",
      "第 9 天補貨策略: R_vars = -0.0, tau_vars = -0.0009658977698054531\n",
      "*** 於第[2]天進貨 ***\n",
      "\n",
      "f_vars[i]: -2.2588, F_vars[i]: 0.0946, Q0_vars[i]: 228.9189\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 1.0, tau_vars = 0.00010105514017158213\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.0008989448598284184\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.0008989448598284179\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.0008989448598284184\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.0008989448598284171\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.0008989448598284179\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0008989448598284179\n",
      "第 9 天補貨策略: R_vars = -0.0, tau_vars = -0.0008989448598284179\n",
      "*** 於第[2]天進貨 ***\n",
      "\n",
      "f_vars[i]: -2.2650, F_vars[i]: 0.0941, Q0_vars[i]: 227.6370\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 1.0, tau_vars = 9.108222523703728e-05\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.0009089177747629632\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.0009089177747629627\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.0009089177747629632\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.0009089177747629627\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.0009089177747629627\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0009089177747629627\n",
      "第 9 天補貨策略: R_vars = -0.0, tau_vars = -0.0009089177747629627\n",
      "*** 於第[2]天進貨 ***\n",
      "\n",
      "f_vars[i]: -2.3216, F_vars[i]: 0.0894, Q0_vars[i]: 216.2243\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.0010000000000000005\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.0010000000000000005\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0010000000000000002\n",
      "第 9 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "*** 於第[2]天進貨 ***\n",
      "\n",
      "f_vars[i]: -2.1862, F_vars[i]: 0.1010, Q0_vars[i]: 244.3967\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 1.0, tau_vars = 0.00021768934988349774\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.0007823106501165023\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.0007823106501165023\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.0007823106501165023\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.0007823106501165015\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.0007823106501165023\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0007823106501165023\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.0007823106501165023\n",
      "*** 於第[2]天進貨 ***\n",
      "\n",
      "all_Rs: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "Fold 1 Q_star: 2419.9481921146094\n",
      "baseline_profit: 256634.1257902774\n",
      "f_vars[i]: -0.9093791281713195, F_vars[i]: 0.2871269036277598\n",
      "f_vars[i]: -0.9074098186663238, F_vars[i]: 0.287530160752404\n",
      "f_vars[i]: -0.9313202703201496, F_vars[i]: 0.282656937065356\n",
      "f_vars[i]: -0.9297173224261759, F_vars[i]: 0.2829820671773383\n",
      "f_vars[i]: -0.932420793771935, F_vars[i]: 0.28243384612082845\n",
      "f_vars[i]: -0.9356172715190586, F_vars[i]: 0.2817864828153157\n",
      "f_vars[i]: -0.9303354439742479, F_vars[i]: 0.2828566651526948\n",
      "f_vars[i]: -0.9203969311221779, F_vars[i]: 0.28487702375083074\n",
      "f_vars[i]: -0.9297871472171648, F_vars[i]: 0.2829678997173205\n",
      "f_vars[i]: -0.9102957858597227, F_vars[i]: 0.2869393141255104\n",
      "f_vars[i]: -0.9256487935754886, F_vars[i]: 0.28380831315789046\n",
      "f_vars[i]: -0.9110339023510026, F_vars[i]: 0.286788315447876\n",
      "f_vars[i]: -0.9346180782120939, F_vars[i]: 0.28198874649962635\n",
      "f_vars[i]: -0.9221736993576488, F_vars[i]: 0.2845151951802768\n",
      "f_vars[i]: -0.9190190092657243, F_vars[i]: 0.28515782008204116\n",
      "assigned_R: 0\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 210 rows, 435 columns and 960 nonzeros\n",
      "Model fingerprint: 0xfc0ddda5\n",
      "Model has 105 general constraints\n",
      "Variable types: 315 continuous, 120 integer (120 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Presolve removed 199 rows and 410 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 11 rows, 25 columns, 59 nonzeros\n",
      "Presolved model has 6 SOS constraint(s)\n",
      "Variable types: 11 continuous, 14 integer (14 binary)\n",
      "Found heuristic solution: objective 1.101099e+07\n",
      "\n",
      "Root relaxation: interrupted, 7 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0          -    0      1.1011e+07 1.1013e+07  0.02%     -    0s\n",
      "\n",
      "Explored 1 nodes (7 simplex iterations) in 0.02 seconds (0.01 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 1.1011e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 1.101098585600e+07, best bound 1.101330496244e+07, gap 0.0211%\n",
      "\n",
      "model.status is optimal: True\n",
      "model.status is TIME_LIMIT: False\n",
      "\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 1.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 1.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 1.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 1.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 1.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 1.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 1.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 1.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "tau: [ 0.00012307 -0.00027693 -0.00027693 -0.00027693 -0.00027693 -0.00027693\n",
      " -0.00027693 -0.00027693]\n",
      "R: [1 0 0 0 0 0 0 0]\n",
      "max_r_index: 0\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 0.00014011 -0.00025989 -0.00025989 -0.00025989 -0.00025989 -0.00025989\n",
      " -0.00025989 -0.00025989]\n",
      "R: [1 0 0 0 0 0 0 0]\n",
      "max_r_index: 0\n",
      "\n",
      "\n",
      "\n",
      "tau: [-6.68385508e-05 -4.66838551e-04 -4.66838551e-04 -4.66838551e-04\n",
      " -4.66838551e-04 -4.66838551e-04 -4.66838551e-04 -4.66838551e-04]\n",
      "R: [1 0 0 0 0 0 0 0]\n",
      "max_r_index: 0\n",
      "\n",
      "\n",
      "\n",
      "tau: [-5.29647121e-05 -4.52964712e-04 -4.52964712e-04 -4.52964712e-04\n",
      " -4.52964712e-04 -4.52964712e-04 -4.52964712e-04 -4.52964712e-04]\n",
      "R: [1 0 0 0 0 0 0 0]\n",
      "max_r_index: 0\n",
      "\n",
      "\n",
      "\n",
      "tau: [-7.63638042e-05 -4.76363804e-04 -4.76363804e-04 -4.76363804e-04\n",
      " -4.76363804e-04 -4.76363804e-04 -4.76363804e-04 -4.76363804e-04]\n",
      "R: [1 0 0 0 0 0 0 0]\n",
      "max_r_index: 0\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.00010403 -0.00050403 -0.00050403 -0.00050403 -0.00050403 -0.00050403\n",
      " -0.00050403 -0.00050403]\n",
      "R: [1 0 0 0 0 0 0 0]\n",
      "max_r_index: 0\n",
      "\n",
      "\n",
      "\n",
      "tau: [-5.83146793e-05 -4.58314679e-04 -4.58314679e-04 -4.58314679e-04\n",
      " -4.58314679e-04 -4.58314679e-04 -4.58314679e-04 -4.58314679e-04]\n",
      "R: [1 0 0 0 0 0 0 0]\n",
      "max_r_index: 0\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 2.77051626e-05 -3.72294837e-04 -3.72294837e-04 -3.72294837e-04\n",
      " -3.72294837e-04 -3.72294837e-04 -3.72294837e-04 -3.72294837e-04]\n",
      "R: [1 0 0 0 0 0 0 0]\n",
      "max_r_index: 0\n",
      "\n",
      "\n",
      "\n",
      "tau: [-5.35690598e-05 -4.53569060e-04 -4.53569060e-04 -4.53569060e-04\n",
      " -4.53569060e-04 -4.53569060e-04 -4.53569060e-04 -4.53569060e-04]\n",
      "R: [1 0 0 0 0 0 0 0]\n",
      "max_r_index: 0\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 0.00011513 -0.00028487 -0.00028487 -0.00028487 -0.00028487 -0.00028487\n",
      " -0.00028487 -0.00028487]\n",
      "R: [1 0 0 0 0 0 0 0]\n",
      "max_r_index: 0\n",
      "\n",
      "\n",
      "\n",
      "tau: [-1.77507708e-05 -4.17750771e-04 -4.17750771e-04 -4.17750771e-04\n",
      " -4.17750771e-04 -4.17750771e-04 -4.17750771e-04 -4.17750771e-04]\n",
      "R: [1 0 0 0 0 0 0 0]\n",
      "max_r_index: 0\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 0.00010874 -0.00029126 -0.00029126 -0.00029126 -0.00029126 -0.00029126\n",
      " -0.00029126 -0.00029126]\n",
      "R: [1 0 0 0 0 0 0 0]\n",
      "max_r_index: 0\n",
      "\n",
      "\n",
      "\n",
      "tau: [-9.53817461e-05 -4.95381746e-04 -4.95381746e-04 -4.95381746e-04\n",
      " -4.95381746e-04 -4.95381746e-04 -4.95381746e-04 -4.95381746e-04]\n",
      "R: [1 0 0 0 0 0 0 0]\n",
      "max_r_index: 0\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 1.23268736e-05 -3.87673126e-04 -3.87673126e-04 -3.87673126e-04\n",
      " -3.87673126e-04 -3.87673126e-04 -3.87673126e-04 -3.87673126e-04]\n",
      "R: [1 0 0 0 0 0 0 0]\n",
      "max_r_index: 0\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 3.96313553e-05 -3.60368645e-04 -3.60368645e-04 -3.60368645e-04\n",
      " -3.60368645e-04 -3.60368645e-04 -3.60368645e-04 -3.60368645e-04]\n",
      "R: [1 0 0 0 0 0 0 0]\n",
      "max_r_index: 0\n",
      "\n",
      "\n",
      "\n",
      "===== Processing Fold 2 =====\n",
      "mean of sum: 2397.625210740225\n",
      "std of sum: 56.649967850962106\n",
      "60.0 percentile of sum: 2411.9773159880024\n",
      "Fold 2 Q_star: 2411.9773159880024\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=0 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xb7f24c36\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 2e+03]\n",
      "  GenCon const rng [2e+02, 2e+03]\n",
      "Presolve removed 63 rows and 100 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 230 rows, 164 columns, 606 nonzeros\n",
      "Presolved model has 38 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 126 continuous, 38 integer (38 binary)\n",
      "\n",
      "Root relaxation: objective 2.123795e+07, 95 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1238e+07    0   22          - 2.1238e+07      -     -    0s\n",
      "H    0     0                    1.521891e+07 2.1238e+07  39.5%     -    0s\n",
      "     0     2 2.1238e+07    0   22 1.5219e+07 2.1238e+07  39.5%     -    0s\n",
      "H   61    36                    2.112416e+07 2.1204e+07  0.38%   2.9    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 4\n",
      "\n",
      "Explored 63 nodes (277 simplex iterations) in 0.02 seconds (0.01 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 2.11242e+07 1.52189e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.112415547701e+07, best bound 2.120399975352e+07, gap 0.3780%\n",
      "Model status: 2\n",
      "Lost0: 21.01601264299316, Lost1: 25.454435747298703, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -2.3971, F_vars[i]: 0.0834, Q0_vars[i]: 201.1452\n",
      "f_train: -2.3970973516876235, F_train: 0.08339430590854635, Q0_train: 201.14517413397803\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 14.22594249131305, Left1: 25.915693095731967\n",
      "f_vars[i]: -2.2273, F_vars[i]: 0.0973, Q0_vars[i]: 234.7560\n",
      "f_train: -2.2272578709111075, F_train: 0.09732928842930699, Q0_train: 234.75603587274202\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.1287988046090902, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -2.3333, F_vars[i]: 0.0884, Q0_vars[i]: 213.2337\n",
      "f_train: -2.3332524479518715, F_train: 0.08840619558662922, Q0_train: 213.23373834774833\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 20.821981935769998, Left1: 31.705844629031617\n",
      "f_vars[i]: -2.2958, F_vars[i]: 0.0915, Q0_vars[i]: 220.6197\n",
      "f_train: -2.2958362984250593, F_train: 0.09146838454084634, Q0_train: 220.61966864258903\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 15.08790447397439, Lost1: 30.725997857758557, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -2.4790, F_vars[i]: 0.0773, Q0_vars[i]: 186.5519\n",
      "f_train: -2.4789936303446436, F_train: 0.0773439880428331, Q0_train: 186.55194468736073\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 20.859426221859422, Left1: 23.181250338831887\n",
      "f_vars[i]: -2.2794, F_vars[i]: 0.0928, Q0_vars[i]: 223.9280\n",
      "f_train: -2.279440919120737, F_train: 0.09284002861515128, Q0_train: 223.92804303542192\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 23.52524272653568, Left1: 22.4689947922966\n",
      "f_vars[i]: -2.2813, F_vars[i]: 0.0927, Q0_vars[i]: 223.5533\n",
      "f_train: -2.2812869322055835, F_train: 0.09268467280747739, Q0_train: 223.5533283514055\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 14.510084962508516, Left1: 30.599024073480905\n",
      "f_vars[i]: -2.2797, F_vars[i]: 0.0928, Q0_vars[i]: 223.8806\n",
      "f_train: -2.279674679282734, F_train: 0.09282034303090723, Q0_train: 223.88056185277333\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 34.468848306759256, Left1: 102.046061807137\n",
      "f_vars[i]: -2.1708, F_vars[i]: 0.1024, Q0_vars[i]: 247.0013\n",
      "f_train: -2.1707707722773804, F_train: 0.10240616300357848, Q0_train: 247.00134218200108\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 5.348874171016632, Left0: 20.692325550394422, Left1: 0.0\n",
      "f_vars[i]: -2.2581, F_vars[i]: 0.0947, Q0_vars[i]: 228.3108\n",
      "f_train: -2.258052686165481, F_train: 0.09465711651820452, Q0_train: 228.31081783874254\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 46.215054754691664, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -2.3655, F_vars[i]: 0.0858, Q0_vars[i]: 207.0562\n",
      "f_train: -2.365456502121093, F_train: 0.08584502312451073, Q0_train: 207.05624846678538\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 18.979320262452347, Left0: 5.094747918266928, Left1: 0.0\n",
      "f_vars[i]: -2.3396, F_vars[i]: 0.0879, Q0_vars[i]: 211.9986\n",
      "f_train: -2.339623244751059, F_train: 0.08789411413326449, Q0_train: 211.99860949829443\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 22.633365863177204, Left1: 77.45142147685056\n",
      "f_vars[i]: -2.2528, F_vars[i]: 0.0951, Q0_vars[i]: 229.4022\n",
      "f_train: -2.2527840379214137, F_train: 0.09510958989985796, Q0_train: 229.40217337137904\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 22.83200067165688, Lost1: 8.439584577143513, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -2.4652, F_vars[i]: 0.0783, Q0_vars[i]: 188.9425\n",
      "f_train: -2.4651860659347653, F_train: 0.07833509018972216, Q0_train: 188.94246058348415\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 10.550351632549122, Left1: 52.743944275646754\n",
      "f_vars[i]: -2.2631, F_vars[i]: 0.0942, Q0_vars[i]: 227.2761\n",
      "f_train: -2.263068975752949, F_train: 0.094228108022972, Q0_train: 227.27605907987558\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=1 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x94762113\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 2e+03]\n",
      "  GenCon const rng [4e+02, 2e+03]\n",
      "Presolve removed 64 rows and 101 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 229 rows, 163 columns, 606 nonzeros\n",
      "Presolved model has 38 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 125 continuous, 38 integer (38 binary)\n",
      "Found heuristic solution: objective 2.106431e+07\n",
      "\n",
      "Root relaxation: interrupted, 67 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0          -    0      2.1064e+07 2.1236e+07  0.81%     -    0s\n",
      "\n",
      "Explored 1 nodes (67 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.10643e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.106431371672e+07, best bound 2.123578584244e+07, gap 0.8140%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 44.514862757808146, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.4866, F_vars[i]: 0.1844, Q0_vars[i]: 444.8360\n",
      "f_train: -1.48663110617257, F_train: 0.18442791847110257, Q0_train: 444.8359557871841\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 21.806122220027646\n",
      "f_vars[i]: -1.4993, F_vars[i]: 0.1825, Q0_vars[i]: 440.2690\n",
      "f_train: -1.499269586674682, F_train: 0.1825344876328458, Q0_train: 440.2690435559166\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 10.929578007241336, Left1: 15.356579472123371\n",
      "f_vars[i]: -1.4914, F_vars[i]: 0.1837, Q0_vars[i]: 443.1149\n",
      "f_train: -1.4913820778979563, F_train: 0.18371437570658708, Q0_train: 443.11490682518536\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 34.98740244839411, Left1: 46.592642418966534\n",
      "f_vars[i]: -1.4942, F_vars[i]: 0.1833, Q0_vars[i]: 442.1087\n",
      "f_train: -1.494166373246109, F_train: 0.1832972009460079, Q0_train: 442.1086907658657\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 47.914708341139885, Left0: 40.94942953617479, Left1: 0.0\n",
      "f_vars[i]: -1.4805, F_vars[i]: 0.1853, Q0_vars[i]: 447.0512\n",
      "f_train: -1.4805368546106248, F_train: 0.18534634426994648, Q0_train: 447.0511779804138\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 28.34601136447994, Left1: 38.819279003156225\n",
      "f_vars[i]: -1.4954, F_vars[i]: 0.1831, Q0_vars[i]: 441.6683\n",
      "f_train: -1.4953864233823613, F_train: 0.18311463081593754, Q0_train: 441.66833575355895\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 41.040256914289564, Left1: 10.858303129778285\n",
      "f_vars[i]: -1.4952, F_vars[i]: 0.1831, Q0_vars[i]: 441.7179\n",
      "f_train: -1.4952490536714271, F_train: 0.1831351799749383, Q0_train: 441.71789985893145\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 20.763281043359605, Left1: 30.867349986370982\n",
      "f_vars[i]: -1.4954, F_vars[i]: 0.1831, Q0_vars[i]: 441.6746\n",
      "f_train: -1.4953690282912078, F_train: 0.18311723285172998, Q0_train: 441.6746118048657\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 12.910172241666984, Left1: 98.95858299203701\n",
      "f_vars[i]: -1.5035, F_vars[i]: 0.1819, Q0_vars[i]: 438.7582\n",
      "f_train: -1.5034730327252654, F_train: 0.18190810450338385, Q0_train: 438.7582216565368\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 21.681099009879823, Left1: 1.5531733260775908\n",
      "f_vars[i]: -1.4970, F_vars[i]: 0.1829, Q0_vars[i]: 441.0944\n",
      "f_train: -1.4969780130642405, F_train: 0.18287667506521962, Q0_train: 441.09439188061845\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 41.152808343097604, Left0: 26.07830128869888, Left1: 0.0\n",
      "f_vars[i]: -1.4890, F_vars[i]: 0.1841, Q0_vars[i]: 443.9824\n",
      "f_train: -1.4889856368063692, F_train: 0.18407402659866562, Q0_train: 443.98237661855364\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 40.21163923668655, Left0: 32.47629708709909, Left1: 0.0\n",
      "f_vars[i]: -1.4909, F_vars[i]: 0.1838, Q0_vars[i]: 443.2864\n",
      "f_train: -1.490907999722721, F_train: 0.18378548074389353, Q0_train: 443.286410562221\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 32.09101765664871, Left1: 49.65896317028387\n",
      "f_vars[i]: -1.4974, F_vars[i]: 0.1828, Q0_vars[i]: 440.9531\n",
      "f_train: -1.4973700756624106, F_train: 0.18281809533875762, Q0_train: 440.9530989092153\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 23.94435384795156, Left0: 19.522082402989838, Left1: 0.0\n",
      "f_vars[i]: -1.4816, F_vars[i]: 0.1852, Q0_vars[i]: 446.6771\n",
      "f_train: -1.4815643343978806, F_train: 0.1851912520903676, Q0_train: 446.6770991613824\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 8.036195917201574, Left1: 48.285707151116185\n",
      "f_vars[i]: -1.4966, F_vars[i]: 0.1829, Q0_vars[i]: 441.2289\n",
      "f_train: -1.4966047295505702, F_train: 0.1829324624679526, Q0_train: 441.22894983052834\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=2 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x6fac0d98\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_65248/2788820283.py:74: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_65248/565741137.py:107: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_65248/904923607.py:90: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 2e+03]\n",
      "  GenCon const rng [6e+02, 2e+03]\n",
      "Presolve removed 64 rows and 101 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 229 rows, 163 columns, 605 nonzeros\n",
      "Presolved model has 38 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 125 continuous, 38 integer (38 binary)\n",
      "\n",
      "Root relaxation: objective 2.123924e+07, 101 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1239e+07    0   22          - 2.1239e+07      -     -    0s\n",
      "H    0     0                    1.775421e+07 2.1239e+07  19.6%     -    0s\n",
      "     0     2 2.1239e+07    0   21 1.7754e+07 2.1239e+07  19.6%     -    0s\n",
      "H   63    56                    2.100236e+07 2.1205e+07  0.97%   2.8    0s\n",
      "H   72    56                    2.106389e+07 2.1205e+07  0.67%   2.8    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 3\n",
      "\n",
      "Explored 87 nodes (347 simplex iterations) in 0.03 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 3: 2.10639e+07 2.10024e+07 1.77542e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.106389360823e+07, best bound 2.120533289361e+07, gap 0.6715%\n",
      "Model status: 2\n",
      "Lost0: 23.55760478147738, Lost1: 18.08666997517139, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.0043, F_vars[i]: 0.2681, Q0_vars[i]: 646.6323\n",
      "f_train: -1.0043236774669841, F_train: 0.26809218451443684, Q0_train: 646.6322676424917\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 18.459744751402468\n",
      "f_vars[i]: -0.9783, F_vars[i]: 0.2732, Q0_vars[i]: 659.0288\n",
      "f_train: -0.9782872540609173, F_train: 0.27323176205174005, Q0_train: 659.0288120762285\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 2.2192191609965866, Left1: 14.057630839818785\n",
      "f_vars[i]: -0.9945, F_vars[i]: 0.2700, Q0_vars[i]: 651.2749\n",
      "f_train: -0.9945362420698461, F_train: 0.2700170165868091, Q0_train: 651.2749189381398\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 43.095062040384846, Left1: 44.74535130235063\n",
      "f_vars[i]: -0.9888, F_vars[i]: 0.2711, Q0_vars[i]: 654.0055\n",
      "f_train: -0.9888003395173256, F_train: 0.27114909816964927, Q0_train: 654.005474035798\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 46.85843031125364, Left0: 30.23276570041947, Left1: 0.0\n",
      "f_vars[i]: -1.0169, F_vars[i]: 0.2656, Q0_vars[i]: 640.7078\n",
      "f_train: -1.0168783919347066, F_train: 0.26563589777686464, Q0_train: 640.7077597499053\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 30.83698681098781, Left1: 43.30441068404593\n",
      "f_vars[i]: -0.9863, F_vars[i]: 0.2716, Q0_vars[i]: 655.2042\n",
      "f_train: -0.9862869248771094, F_train: 0.27164610304430487, Q0_train: 655.2042385194028\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 53.280563507692364, Left1: 11.78615993719643\n",
      "f_vars[i]: -0.9866, F_vars[i]: 0.2716, Q0_vars[i]: 655.0692\n",
      "f_train: -0.9865699190199935, F_train: 0.2715901149987785, Q0_train: 655.0691966236267\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 23.186849975858536, Left1: 30.532481747907013\n",
      "f_vars[i]: -0.9863, F_vars[i]: 0.2716, Q0_vars[i]: 655.1871\n",
      "f_train: -0.9863227603526149, F_train: 0.27163901289231795, Q0_train: 655.1871372336434\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 22.656214815217115, Left1: 100.55121044047996\n",
      "f_vars[i]: -0.9696, F_vars[i]: 0.2750, Q0_vars[i]: 663.1845\n",
      "f_train: -0.9696277715290365, F_train: 0.2749547014567791, Q0_train: 663.1845028380045\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.4858257479497752, Left0: 28.46844479803131, Left1: 0.0\n",
      "f_vars[i]: -0.9830, F_vars[i]: 0.2723, Q0_vars[i]: 656.7701\n",
      "f_train: -0.9830081048607942, F_train: 0.2722953178376602, Q0_train: 656.7701298741797\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 44.2123896377052, Left0: 22.999429055337817, Left1: 0.0\n",
      "f_vars[i]: -0.9995, F_vars[i]: 0.2690, Q0_vars[i]: 648.9305\n",
      "f_train: -0.9994731294526159, F_train: 0.2690450230167408, Q0_train: 648.9304924958489\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 36.83790109289703, Left0: 32.61541825339123, Left1: 0.0\n",
      "f_vars[i]: -0.9955, F_vars[i]: 0.2698, Q0_vars[i]: 650.8107\n",
      "f_train: -0.9955128863821067, F_train: 0.26982455559259966, Q0_train: 650.810707385894\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 46.609308529534815, Left1: 46.177988783671935\n",
      "f_vars[i]: -0.9822, F_vars[i]: 0.2725, Q0_vars[i]: 657.1562\n",
      "f_train: -0.9822004201232233, F_train: 0.27245539046585737, Q0_train: 657.1562214223019\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 24.315787480378503, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.0148, F_vars[i]: 0.2660, Q0_vars[i]: 641.7042\n",
      "f_train: -1.0147616897901965, F_train: 0.2660490149885748, Q0_train: 641.7041890933945\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.497203892636117, Left1: 50.45694141982699\n",
      "f_vars[i]: -0.9838, F_vars[i]: 0.2721, Q0_vars[i]: 656.4027\n",
      "f_train: -0.9837771029702422, F_train: 0.272142967102809, Q0_train: 656.4026633576444\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=3 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xba159167\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 2e+03]\n",
      "  GenCon const rng [8e+02, 2e+03]\n",
      "Presolve removed 64 rows and 101 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 229 rows, 163 columns, 606 nonzeros\n",
      "Presolved model has 38 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 125 continuous, 38 integer (38 binary)\n",
      "\n",
      "Root relaxation: objective 2.127817e+07, 99 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1278e+07    0   22          - 2.1278e+07      -     -    0s\n",
      "H    0     0                    1.907321e+07 2.1278e+07  11.6%     -    0s\n",
      "     0     2 2.1278e+07    0   21 1.9073e+07 2.1278e+07  11.6%     -    0s\n",
      "H  505   250                    2.068378e+07 2.1244e+07  2.71%   1.7    0s\n",
      "H  701   298                    2.079363e+07 2.1244e+07  2.17%   1.8    0s\n",
      "*  707   298              34    2.079363e+07 2.1244e+07  2.17%   1.8    0s\n",
      "H  726   298                    2.092245e+07 2.1244e+07  1.54%   1.8    0s\n",
      "H  860   334                    2.092537e+07 2.1244e+07  1.52%   2.1    0s\n",
      "H  902   334                    2.099954e+07 2.1244e+07  1.16%   2.1    0s\n",
      "H  916   334                    2.100307e+07 2.1244e+07  1.15%   2.1    0s\n",
      "H 1005   336                    2.106675e+07 2.1244e+07  0.84%   2.3    0s\n",
      "H 1154   336                    2.106702e+07 2.1187e+07  0.57%   2.4    0s\n",
      "* 1167   336              49    2.106702e+07 2.1187e+07  0.57%   2.4    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 4\n",
      "\n",
      "Explored 1205 nodes (3094 simplex iterations) in 0.06 seconds (0.05 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 10: 2.1067e+07 2.1067e+07 2.10668e+07 ... 2.06838e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.106702250378e+07, best bound 2.118743054157e+07, gap 0.5715%\n",
      "Model status: 2\n",
      "Lost0: 33.38643035321843, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -0.5903, F_vars[i]: 0.3566, Q0_vars[i]: 860.0248\n",
      "f_train: -0.5903079661534063, F_train: 0.35656419568984876, Q0_train: 860.0247516974223\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 16.628622748597763, Lost1: 0.0, Left0: 0.0, Left1: 34.85787670297577\n",
      "f_vars[i]: -0.5843, F_vars[i]: 0.3579, Q0_vars[i]: 863.3327\n",
      "f_train: -0.5843351945319173, F_train: 0.35793567669085025, Q0_train: 863.3327327611464\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 5.150370382198687, Lost1: 0.0, Left0: 0.0, Left1: 12.719426600016803\n",
      "f_vars[i]: -0.5881, F_vars[i]: 0.3571, Q0_vars[i]: 861.2676\n",
      "f_train: -0.588062722424056, F_train: 0.35707947908918064, Q0_train: 861.2676035679159\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 43.348806532601074, Left1: 42.38913772246178\n",
      "f_vars[i]: -0.5867, F_vars[i]: 0.3574, Q0_vars[i]: 861.9963\n",
      "f_train: -0.5867469028333614, F_train: 0.35738161346873326, Q0_train: 861.996344837777\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 5.870130941289972, Left0: 36.26811525992111, Left1: 0.0\n",
      "f_vars[i]: -0.5932, F_vars[i]: 0.3559, Q0_vars[i]: 858.4317\n",
      "f_train: -0.5931880254119003, F_train: 0.35590370803106686, Q0_train: 858.4316704469503\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 29.69485412262895, Left1: 32.0325928480097\n",
      "f_vars[i]: -0.5862, F_vars[i]: 0.3575, Q0_vars[i]: 862.3158\n",
      "f_train: -0.5861703239614484, F_train: 0.3575140414560323, Q0_train: 862.3157581391442\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 57.29390203985576, Left1: 6.050439541572125\n",
      "f_vars[i]: -0.5862, F_vars[i]: 0.3575, Q0_vars[i]: 862.2798\n",
      "f_train: -0.586235242992734, F_train: 0.3574991298384473, Q0_train: 862.2797916557845\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 17.083309922145357, Left1: 33.681225010743674\n",
      "f_vars[i]: -0.5862, F_vars[i]: 0.3575, Q0_vars[i]: 862.3112\n",
      "f_train: -0.586178544641678, F_train: 0.35751215318647867, Q0_train: 862.3112036758143\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 12.435818133547079, Left1: 77.20125059728593\n",
      "f_vars[i]: -0.5823, F_vars[i]: 0.3584, Q0_vars[i]: 864.4342\n",
      "f_train: -0.5823487038870022, F_train: 0.35839233618109556, Q0_train: 864.4341850927487\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 21.238942854874757, Left1: 0.963914971357589\n",
      "f_vars[i]: -0.5854, F_vars[i]: 0.3577, Q0_vars[i]: 862.7325\n",
      "f_train: -0.58541816062319, F_train: 0.3576868301937714, Q0_train: 862.7325206550291\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 65.79100197697221, Left0: 25.244154305420466, Left1: 0.0\n",
      "f_vars[i]: -0.5892, F_vars[i]: 0.3568, Q0_vars[i]: 860.6406\n",
      "f_train: -0.5891952474409684, F_train: 0.3568195232072504, Q0_train: 860.6405958775425\n",
      "f_train, F_train, Q0_train 不相等\n",
      "Lost0: 0.0, Lost1: 52.56830471045615, Left0: 37.63905509813489, Left1: 0.0\n",
      "f_vars[i]: -0.5883, F_vars[i]: 0.3570, Q0_vars[i]: 861.1435\n",
      "f_train: -0.5882867652329158, F_train: 0.3570280463941641, Q0_train: 861.1435490742358\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 44.87763456598236, Left1: 47.665113731664405\n",
      "f_vars[i]: -0.5852, F_vars[i]: 0.3577, Q0_vars[i]: 862.8352\n",
      "f_train: -0.5852328772451915, F_train: 0.35772939960927985, Q0_train: 862.8351971195904\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.08856201837863864, Lost1: 13.0044951393661, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -0.5927, F_vars[i]: 0.3560, Q0_vars[i]: 858.7002\n",
      "f_train: -0.5927024526316955, F_train: 0.3560150267051943, Q0_train: 858.7001685637915\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 7.571419864539962, Lost1: 0.0, Left0: 0.0, Left1: 66.1473951536284\n",
      "f_vars[i]: -0.5856, F_vars[i]: 0.3576, Q0_vars[i]: 862.6348\n",
      "f_train: -0.5855945692647861, F_train: 0.357646301861927, Q0_train: 862.6347672379655\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=4 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x0f17848d\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 2e+03]\n",
      "  GenCon const rng [1e+03, 1e+03]\n",
      "Presolve removed 59 rows and 85 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 234 rows, 179 columns, 630 nonzeros\n",
      "Presolved model has 49 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 130 continuous, 49 integer (49 binary)\n",
      "\n",
      "Root relaxation: objective 2.128408e+07, 95 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1284e+07    0   20          - 2.1284e+07      -     -    0s\n",
      "H    0     0                    2.037197e+07 2.1284e+07  4.48%     -    0s\n",
      "     0     2 2.1284e+07    0   20 2.0372e+07 2.1284e+07  4.48%     -    0s\n",
      "H   86    51                    2.095854e+07 2.1250e+07  1.39%   5.2    0s\n",
      "H  222    35                    2.097953e+07 2.1237e+07  1.23%  10.2    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 4\n",
      "\n",
      "Explored 277 nodes (2492 simplex iterations) in 0.04 seconds (0.04 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 3: 2.09795e+07 2.09585e+07 2.0372e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.097953001908e+07, best bound 2.116656515717e+07, gap 0.8915%\n",
      "Model status: 2\n",
      "Lost0: 55.192825583820536, Lost1: 0.0, Left0: 0.0, Left1: 15.127785644210352\n",
      "f_vars[i]: -0.2414, F_vars[i]: 0.4399, Q0_vars[i]: 1061.1120\n",
      "f_train: -0.24142786627033358, F_train: 0.4399345055955985, Q0_train: 1061.1120480169805\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.5839554176754596, Left1: 5.2393975365337155\n",
      "f_vars[i]: -0.1751, F_vars[i]: 0.4563, Q0_vars[i]: 1100.6708\n",
      "f_train: -0.17510413124656304, F_train: 0.456335478369479, Q0_train: 1100.6708223077171\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 10.031837626240645, Lost1: 0.0, Left0: 0.0, Left1: 17.415513484888187\n",
      "f_vars[i]: -0.2165, F_vars[i]: 0.4461, Q0_vars[i]: 1075.9504\n",
      "f_train: -0.2164958983990939, F_train: 0.44608644059138025, Q0_train: 1075.9503756762388\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 55.04645239380534, Left1: 26.862298854243363\n",
      "f_vars[i]: -0.2019, F_vars[i]: 0.4497, Q0_vars[i]: 1084.6652\n",
      "f_train: -0.20188457966754725, F_train: 0.44969958192969123, Q0_train: 1084.6651906237034\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 12.782145776692573, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -0.2734, F_vars[i]: 0.4321, Q0_vars[i]: 1042.1439\n",
      "f_train: -0.2734090467370141, F_train: 0.4320703712188404, Q0_train: 1042.1439342903584\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 45.352692186088916, Left1: 30.571812412529198\n",
      "f_vars[i]: -0.1955, F_vars[i]: 0.4513, Q0_vars[i]: 1088.4880\n",
      "f_train: -0.1954820471843906, F_train: 0.45128452081325227, Q0_train: 1088.48802725808\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 74.90032536040303, Left1: 13.98977270579644\n",
      "f_vars[i]: -0.1962, F_vars[i]: 0.4511, Q0_vars[i]: 1088.0575\n",
      "f_train: -0.19620293070411177, F_train: 0.45110601700904623, Q0_train: 1088.0574801315174\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 25.700320098941347, Left1: 38.447093566911235\n",
      "f_vars[i]: -0.1956, F_vars[i]: 0.4513, Q0_vars[i]: 1088.4335\n",
      "f_train: -0.19557333247902597, F_train: 0.45126191622820255, Q0_train: 1088.4335055117028\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 53.58420706140555, Left1: 63.52167511087464\n",
      "f_vars[i]: -0.1530, F_vars[i]: 0.4618, Q0_vars[i]: 1113.8828\n",
      "f_train: -0.15304544768891226, F_train: 0.4618131462628553, Q0_train: 1113.8828330110564\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 11.442965235278734, Left0: 36.12927412448721, Left1: 0.0\n",
      "f_vars[i]: -0.1871, F_vars[i]: 0.4534, Q0_vars[i]: 1093.4786\n",
      "f_train: -0.18712976367136186, F_train: 0.45335359991964325, Q0_train: 1093.4785991276797\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 46.05851485618109, Left0: 18.674299747922532, Left1: 0.0\n",
      "f_vars[i]: -0.2291, F_vars[i]: 0.4430, Q0_vars[i]: 1068.4605\n",
      "f_train: -0.2290718503841398, F_train: 0.44298115311681574, Q0_train: 1068.4604927279674\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 58.16779941399318, Left0: 46.43580385265568, Left1: 0.0\n",
      "f_vars[i]: -0.2190, F_vars[i]: 0.4455, Q0_vars[i]: 1074.4679\n",
      "f_train: -0.21898374773110868, F_train: 0.44547179237915174, Q0_train: 1074.467858131031\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 65.73633709238015, Left1: 47.57483186109266\n",
      "f_vars[i]: -0.1851, F_vars[i]: 0.4539, Q0_vars[i]: 1094.7086\n",
      "f_train: -0.1850723125506017, F_train: 0.4538635346793519, Q0_train: 1094.7085502007308\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 38.58154010007081, Lost1: 0.0, Left0: 0.0, Left1: 49.14581739466668\n",
      "f_vars[i]: -0.2680, F_vars[i]: 0.4334, Q0_vars[i]: 1045.3364\n",
      "f_train: -0.26801707757261584, F_train: 0.43339396421313053, Q0_train: 1045.336410568187\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 70.929625350798\n",
      "f_vars[i]: -0.1891, F_vars[i]: 0.4529, Q0_vars[i]: 1092.3078\n",
      "f_train: -0.18908866663008872, F_train: 0.45286818104148857, Q0_train: 1092.3077798048184\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=5 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x510efbbe\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 1e+03]\n",
      "Presolve removed 53 rows and 71 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 240 rows, 193 columns, 643 nonzeros\n",
      "Presolved model has 57 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 136 continuous, 57 integer (57 binary)\n",
      "\n",
      "Root relaxation: objective 2.142248e+07, 111 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1422e+07    0   24          - 2.1422e+07      -     -    0s\n",
      "H    0     0                    1.969298e+07 2.1422e+07  8.78%     -    0s\n",
      "     0     2 2.1422e+07    0   23 1.9693e+07 2.1422e+07  8.78%     -    0s\n",
      "H   66    44                    2.007505e+07 2.1408e+07  6.64%   4.2    0s\n",
      "H  473   126                    2.096827e+07 2.1408e+07  2.10%   3.6    0s\n",
      "*  808    89              25    2.096827e+07 2.1406e+07  2.09%   3.8    0s\n",
      "*  877   120              29    2.099636e+07 2.1406e+07  1.95%   3.5    0s\n",
      "H  993   148                    2.105531e+07 2.1406e+07  1.67%   3.3    0s\n",
      "H 1090   148                    2.107874e+07 2.1406e+07  1.55%   3.2    0s\n",
      "H 1261   131                    2.108804e+07 2.1313e+07  1.07%   3.1    0s\n",
      "H 1291   131                    2.110659e+07 2.1313e+07  0.98%   3.1    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 7\n",
      "\n",
      "Explored 1369 nodes (4224 simplex iterations) in 0.07 seconds (0.07 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 9: 2.11066e+07 2.1088e+07 2.10787e+07 ... 1.9693e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.110659418827e+07, best bound 2.131277446765e+07, gap 0.9769%\n",
      "Model status: 2\n",
      "Lost0: 40.87411773956205, Lost1: 0.0, Left0: 0.0, Left1: 34.297367898836\n",
      "f_vars[i]: 0.1788, F_vars[i]: 0.5446, Q0_vars[i]: 1313.4962\n",
      "f_train: 0.1787639405843251, F_train: 0.544572350119665, Q0_train: 1313.4961554029082\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 21.69035982968444, Lost1: 0.0, Left0: 0.0, Left1: 12.636045068893615\n",
      "f_vars[i]: 0.1674, F_vars[i]: 0.5418, Q0_vars[i]: 1306.6971\n",
      "f_train: 0.16740378986189666, F_train: 0.5417534845733553, Q0_train: 1306.6971156483892\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 4.152858160788014, Lost1: 0.0, Left0: 0.0, Left1: 20.575525361929486\n",
      "f_vars[i]: 0.1745, F_vars[i]: 0.5435, Q0_vars[i]: 1310.9411\n",
      "f_train: 0.1744935099048328, F_train: 0.5435130264653757, Q0_train: 1310.941090778473\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 62.023586945637135, Left1: 25.826397687126473\n",
      "f_vars[i]: 0.1720, F_vars[i]: 0.5429, Q0_vars[i]: 1309.4433\n",
      "f_train: 0.1719908344601474, F_train: 0.5428920288266452, Q0_train: 1309.443258560573\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 44.17515822539485, Left1: 9.474101490976182\n",
      "f_vars[i]: 0.1842, F_vars[i]: 0.5459, Q0_vars[i]: 1316.7722\n",
      "f_train: 0.18424178392732232, F_train: 0.5459305931292847, Q0_train: 1316.7722067317104\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.4804512219875505, Left0: 48.02881281845589, Left1: 0.0\n",
      "f_vars[i]: 0.1709, F_vars[i]: 0.5426, Q0_vars[i]: 1308.7868\n",
      "f_train: 0.17089418732488226, F_train: 0.5426198717989374, Q0_train: 1308.7868219833551\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 13.402931753854318, Left0: 83.06064708190729, Left1: 0.0\n",
      "f_vars[i]: 0.1710, F_vars[i]: 0.5427, Q0_vars[i]: 1308.8607\n",
      "f_train: 0.17101766266043766, F_train: 0.5426505161843193, Q0_train: 1308.8607355457584\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.28887963635270353, Left0: 23.455709505577715, Left1: 0.0\n",
      "f_vars[i]: 0.1709, F_vars[i]: 0.5426, Q0_vars[i]: 1308.7962\n",
      "f_train: 0.17090982297485624, F_train: 0.5426237523074143, Q0_train: 1308.7961816817758\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 27.094266401915775, Left1: 50.262629962561505\n",
      "f_vars[i]: 0.1636, F_vars[i]: 0.5408, Q0_vars[i]: 1304.4344\n",
      "f_train: 0.16362550491061256, F_train: 0.5408153533413909, Q0_train: 1304.434364397471\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 32.049867191435055, Left0: 28.879672579572116, Left1: 0.0\n",
      "f_vars[i]: 0.1695, F_vars[i]: 0.5423, Q0_vars[i]: 1307.9304\n",
      "f_train: 0.16946358032498315, F_train: 0.5422647970908571, Q0_train: 1307.9303898419842\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 13.00985787758168, Left0: 39.69195353258965, Left1: 0.0\n",
      "f_vars[i]: 0.1766, F_vars[i]: 0.5440, Q0_vars[i]: 1312.2300\n",
      "f_train: 0.17664756093915623, F_train: 0.5440474104852752, Q0_train: 1312.230012912497\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 12.527341562659103, Left0: 65.80761115825794, Left1: 0.0\n",
      "f_vars[i]: 0.1749, F_vars[i]: 0.5436, Q0_vars[i]: 1311.1961\n",
      "f_train: 0.1749196370428212, F_train: 0.5436187494658684, Q0_train: 1311.1960922574397\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 63.03062189318803, Left1: 31.828608629824657\n",
      "f_vars[i]: 0.1691, F_vars[i]: 0.5422, Q0_vars[i]: 1307.7194\n",
      "f_train: 0.1691111732292807, F_train: 0.5421773235243713, Q0_train: 1307.719405583872\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.9244057052493417, Lost1: 0.0, Left0: 0.0, Left1: 36.92014275428541\n",
      "f_vars[i]: 0.1833, F_vars[i]: 0.5457, Q0_vars[i]: 1316.2200\n",
      "f_train: 0.18331822945053816, F_train: 0.5457016431628684, Q0_train: 1316.2199846062178\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 11.184092639332562, Lost1: 0.0, Left0: 0.0, Left1: 15.2574190003254\n",
      "f_vars[i]: 0.1698, F_vars[i]: 0.5423, Q0_vars[i]: 1308.1313\n",
      "f_train: 0.1697991077625403, F_train: 0.5423480784114046, Q0_train: 1308.1312624979905\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=6 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x05d97e8c\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [8e+02, 2e+03]\n",
      "Presolve removed 66 rows and 111 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 227 rows, 153 columns, 599 nonzeros\n",
      "Presolved model has 30 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 123 continuous, 30 integer (30 binary)\n",
      "Found heuristic solution: objective -1.52039e+07\n",
      "\n",
      "Root relaxation: objective 2.143663e+07, 85 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1437e+07    0   21 -1.520e+07 2.1437e+07   241%     -    0s\n",
      "H    0     0                    1.373977e+07 2.1437e+07  56.0%     -    0s\n",
      "     0     2 2.1437e+07    0   21 1.3740e+07 2.1437e+07  56.0%     -    0s\n",
      "H  508   258                    1.733346e+07 2.1422e+07  23.6%   3.1    0s\n",
      "H  511   258                    1.789491e+07 2.1422e+07  19.7%   3.0    0s\n",
      "H  513   258                    1.789491e+07 2.1422e+07  19.7%   3.0    0s\n",
      "H  521   258                    2.082415e+07 2.1422e+07  2.87%   3.0    0s\n",
      "*  634   236              31    2.082415e+07 2.1420e+07  2.86%   3.4    0s\n",
      "H 1016   502                    2.093468e+07 2.1420e+07  2.32%   2.7    0s\n",
      "* 1025   502              44    2.093469e+07 2.1420e+07  2.32%   2.7    0s\n",
      "H 1119   502                    2.096315e+07 2.1420e+07  2.18%   2.5    0s\n",
      "H 1152   502                    2.098951e+07 2.1420e+07  2.05%   2.5    0s\n",
      "H 1255   522                    2.100050e+07 2.1404e+07  1.92%   2.4    0s\n",
      "H 1318   522                    2.107317e+07 2.1404e+07  1.57%   2.3    0s\n",
      "H 1472   335                    2.109085e+07 2.1359e+07  1.27%   2.4    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 5\n",
      "\n",
      "Explored 1755 nodes (4227 simplex iterations) in 0.07 seconds (0.08 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 10: 2.10908e+07 2.10732e+07 2.10005e+07 ... 1.78949e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.109084508471e+07, best bound 2.113315065764e+07, gap 0.2006%\n",
      "Model status: 2\n",
      "Lost0: 44.3205891455998, Lost1: 0.0, Left0: 0.0, Left1: 29.453360686429324\n",
      "f_vars[i]: 0.6604, F_vars[i]: 0.6594, Q0_vars[i]: 1590.3618\n",
      "f_train: 0.6604441992747916, F_train: 0.6593601645966934, Q0_train: 1590.36176007334\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 9.461352919032208, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 0.6020, F_vars[i]: 0.6461, Q0_vars[i]: 1558.4070\n",
      "f_train: 0.6019914278198295, F_train: 0.6461117812595336, Q0_train: 1558.4069599905972\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.3661831710825822, Lost1: 0.0, Left0: 0.0, Left1: 29.01981311642612\n",
      "f_vars[i]: 0.6385, F_vars[i]: 0.6544, Q0_vars[i]: 1578.4167\n",
      "f_train: 0.638471030553553, F_train: 0.6544077532421029, Q0_train: 1578.4166562266262\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 92.73040445765525, Left1: 18.394278153789287\n",
      "f_vars[i]: 0.6256, F_vars[i]: 0.6515, Q0_vars[i]: 1571.3783\n",
      "f_train: 0.6255937088200197, F_train: 0.651489678895768, Q0_train: 1571.3783270969002\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 53.29336040752541, Left1: 18.961548283028378\n",
      "f_vars[i]: 0.6886, F_vars[i]: 0.6657, Q0_vars[i]: 1605.5619\n",
      "f_train: 0.6886300158909515, F_train: 0.6656620977033743, Q0_train: 1605.561879773528\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.963252883856285, Left0: 81.86583978802491, Left1: 0.0\n",
      "f_vars[i]: 0.6200, F_vars[i]: 0.6502, Q0_vars[i]: 1568.2855\n",
      "f_train: 0.6199509963304894, F_train: 0.6502074033722182, Q0_train: 1568.285507621251\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 21.53037602532845, Left0: 117.62048234009194, Left1: 0.0\n",
      "f_vars[i]: 0.6206, F_vars[i]: 0.6504, Q0_vars[i]: 1568.6340\n",
      "f_train: 0.6205863290603004, F_train: 0.650351888216584, Q0_train: 1568.6340017883656\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 51.45855274948872, Left1: 1.2523576054430805\n",
      "f_vars[i]: 0.6200, F_vars[i]: 0.6502, Q0_vars[i]: 1568.3296\n",
      "f_train: 0.6200314483506087, F_train: 0.6502257009764013, Q0_train: 1568.329641027478\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 47.951222087513315, Left1: 36.698408833216945\n",
      "f_vars[i]: 0.5826, F_vars[i]: 0.6417, Q0_vars[i]: 1547.6551\n",
      "f_train: 0.5825505566425566, F_train: 0.6416540779820397, Q0_train: 1547.6550808038764\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 28.89830015090513, Left0: 53.770132144867716, Left1: 0.0\n",
      "f_vars[i]: 0.6126, F_vars[i]: 0.6485, Q0_vars[i]: 1564.2430\n",
      "f_train: 0.6125899193474285, F_train: 0.6485313710876948, Q0_train: 1564.242955770117\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 31.72058697931273, Left1: 1.7653627991323901\n",
      "f_vars[i]: 0.6496, F_vars[i]: 0.6569, Q0_vars[i]: 1584.4522\n",
      "f_train: 0.6495545325147589, F_train: 0.656910070573696, Q0_train: 1584.4521888678325\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.2643981406702096, Left0: 56.863645115658244, Left1: 0.0\n",
      "f_vars[i]: 0.6407, F_vars[i]: 0.6549, Q0_vars[i]: 1579.6123\n",
      "f_train: 0.6406636345793444, F_train: 0.6549034606993136, Q0_train: 1579.6122913687846\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 90.12876944595564, Left1: 20.75969910389938\n",
      "f_vars[i]: 0.6108, F_vars[i]: 0.6481, Q0_vars[i]: 1563.2458\n",
      "f_train: 0.6107766360620639, F_train: 0.6481179429041074, Q0_train: 1563.2457763695143\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 10.941274380428188, Left1: 8.22943788621501\n",
      "f_vars[i]: 0.6839, F_vars[i]: 0.6646, Q0_vars[i]: 1603.0090\n",
      "f_train: 0.6838779382049495, F_train: 0.6646036627225236, Q0_train: 1603.0089586092681\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 12.358265076008532, Left1: 18.804355761897227\n",
      "f_vars[i]: 0.6143, F_vars[i]: 0.6489, Q0_vars[i]: 1565.1919\n",
      "f_train: 0.6143163496654416, F_train: 0.6489247899252585, Q0_train: 1565.1918730820032\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=7 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xb6a829c1\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [6e+02, 2e+03]\n",
      "Presolve removed 63 rows and 106 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 230 rows, 158 columns, 615 nonzeros\n",
      "Presolved model has 32 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 126 continuous, 32 integer (32 binary)\n",
      "\n",
      "Root relaxation: objective 2.155258e+07, 82 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1553e+07    0   20          - 2.1553e+07      -     -    0s\n",
      "H    0     0                    6986760.3419 2.1553e+07   208%     -    0s\n",
      "     0     2 2.1553e+07    0   20 6986760.34 2.1553e+07   208%     -    0s\n",
      "H   34    28                    1.985783e+07 2.1550e+07  8.52%   2.7    0s\n",
      "H   63    48                    2.040639e+07 2.1550e+07  5.60%  16.6    0s\n",
      "H  795   112                    2.115079e+07 2.1550e+07  1.89%   3.3    0s\n",
      "*  960   141              40    2.115079e+07 2.1550e+07  1.89%   3.2    0s\n",
      "* 1028   147              54    2.115079e+07 2.1503e+07  1.67%   3.2    0s\n",
      "H 1054   147                    2.118595e+07 2.1503e+07  1.50%   3.1    0s\n",
      "H 1141   147                    2.118727e+07 2.1503e+07  1.49%   3.1    0s\n",
      "H 1145   147                    2.118727e+07 2.1503e+07  1.49%   3.1    0s\n",
      "* 1147   147              50    2.118727e+07 2.1503e+07  1.49%   3.1    0s\n",
      "H 1418    55                    2.118891e+07 2.1369e+07  0.85%   3.0    0s\n",
      "H 1445    55                    2.118916e+07 2.1369e+07  0.85%   3.0    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 2\n",
      "\n",
      "Explored 1511 nodes (4493 simplex iterations) in 0.07 seconds (0.07 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 10: 2.11892e+07 2.11889e+07 2.11873e+07 ... 2.04064e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.118916165691e+07, best bound 2.136896503994e+07, gap 0.8486%\n",
      "Model status: 2\n",
      "Lost0: 51.586467197993784, Lost1: 0.0, Left0: 0.0, Left1: 52.39671962502765\n",
      "f_vars[i]: 1.2390, F_vars[i]: 0.7754, Q0_vars[i]: 1870.2097\n",
      "f_train: 1.238968686470734, F_train: 0.7753844482065478, Q0_train: 1870.2097002440676\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 16.506197149189973, Lost1: 0.0, Left0: 0.0, Left1: 19.147062573526465\n",
      "f_vars[i]: 1.1456, F_vars[i]: 0.7587, Q0_vars[i]: 1829.9617\n",
      "f_train: 1.1455530303904617, F_train: 0.7586977226722731, Q0_train: 1829.961696777279\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.8734230879904885, Lost1: 0.0, Left0: 0.0, Left1: 4.937441745967655\n",
      "f_vars[i]: 1.2039, F_vars[i]: 0.7692, Q0_vars[i]: 1855.3157\n",
      "f_train: 1.2038525076965834, F_train: 0.7692094141079088, Q0_train: 1855.3156580726977\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 86.80692454149721, Left1: 8.380041691152996\n",
      "f_vars[i]: 1.1833, F_vars[i]: 0.7655, Q0_vars[i]: 1846.4548\n",
      "f_train: 1.183272757098759, F_train: 0.7655357438664365, Q0_train: 1846.4548487838465\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 2.290407914528714, Left0: 52.04149700766609, Left1: 0.0\n",
      "f_vars[i]: 1.2840, F_vars[i]: 0.7831, Q0_vars[i]: 1888.8971\n",
      "f_train: 1.2840135403898598, F_train: 0.7831321952700632, Q0_train: 1888.8970904112791\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 70.2829708698847, Left1: 0.11378193361053945\n",
      "f_vars[i]: 1.1743, F_vars[i]: 0.7639, Q0_vars[i]: 1842.5414\n",
      "f_train: 1.1742549179756308, F_train: 0.7639132508305365, Q0_train: 1842.541432385907\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.8305542395754628, Left0: 100.64428173899546, Left1: 0.0\n",
      "f_vars[i]: 1.1753, F_vars[i]: 0.7641, Q0_vars[i]: 1842.9830\n",
      "f_train: 1.1752702680147693, F_train: 0.7640963199312838, Q0_train: 1842.9829909041678\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 42.887324883360066, Left1: 4.663291405934729\n",
      "f_vars[i]: 1.1744, F_vars[i]: 0.7639, Q0_vars[i]: 1842.5974\n",
      "f_train: 1.1743834914898605, F_train: 0.7639364382507702, Q0_train: 1842.597359917527\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.253871680678003, Left0: 57.37690210079796, Left1: 0.0\n",
      "f_vars[i]: 1.1145, F_vars[i]: 0.7530, Q0_vars[i]: 1816.1323\n",
      "f_train: 1.1144838151831677, F_train: 0.7529640878496434, Q0_train: 1816.1322996469373\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 5.65193510503002, Left0: 37.40908129059255, Left1: 0.0\n",
      "f_vars[i]: 1.1625, F_vars[i]: 0.7618, Q0_vars[i]: 1837.4082\n",
      "f_train: 1.1624908934697977, F_train: 0.7617850285009642, Q0_train: 1837.4082084035995\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.6989076494627398, Left0: 14.711341800020863, Left1: 0.0\n",
      "f_vars[i]: 1.2216, F_vars[i]: 0.7723, Q0_vars[i]: 1862.8640\n",
      "f_train: 1.2215654848848558, F_train: 0.7723389283444979, Q0_train: 1862.863975421412\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 43.857769568144555, Left1: 4.220689439009902\n",
      "f_vars[i]: 1.2074, F_vars[i]: 0.7698, Q0_vars[i]: 1856.8147\n",
      "f_train: 1.2073565937902833, F_train: 0.7698308946177527, Q0_train: 1856.8146549647697\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 92.33891768574716, Left1: 1.673426759186441\n",
      "f_vars[i]: 1.1596, F_vars[i]: 0.7613, Q0_vars[i]: 1836.1389\n",
      "f_train: 1.1595930146601976, F_train: 0.7612587556202213, Q0_train: 1836.1388501532278\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 6.53661384824903, Left1: 1.3648966978119006\n",
      "f_vars[i]: 1.2764, F_vars[i]: 0.7818, Q0_vars[i]: 1885.7794\n",
      "f_train: 1.2764190595169667, F_train: 0.7818396046313025, Q0_train: 1885.77939111173\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 12.431783443546465, Left1: 2.3650218994199577\n",
      "f_vars[i]: 1.1652, F_vars[i]: 0.7623, Q0_vars[i]: 1838.6150\n",
      "f_train: 1.165249969161501, F_train: 0.7622853524071667, Q0_train: 1838.6149783160063\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 210 rows, 435 columns and 960 nonzeros\n",
      "Model fingerprint: 0xbb1b56b9\n",
      "Model has 105 general constraints\n",
      "Variable types: 315 continuous, 120 integer (120 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Presolve removed 198 rows and 409 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 12 rows, 26 columns, 61 nonzeros\n",
      "Presolved model has 6 SOS constraint(s)\n",
      "Variable types: 12 continuous, 14 integer (14 binary)\n",
      "Found heuristic solution: objective 2.155333e+07\n",
      "Found heuristic solution: objective 2.155973e+07\n",
      "\n",
      "Root relaxation: interrupted, 8 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0          -    0      2.1560e+07 2.1560e+07  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (8 simplex iterations) in 0.02 seconds (0.01 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 2.15597e+07 2.15533e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.155972754779e+07, best bound 2.156011314578e+07, gap 0.0018%\n",
      "\n",
      "model.status is optimal: True\n",
      "model.status is TIME_LIMIT: False\n",
      "\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 1.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 1.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 1.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 1.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 1.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 667 and 669 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 667 and 669 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 435 rows, 741 columns and 1830 nonzeros\n",
      "Model fingerprint: 0x80c176b2\n",
      "Model has 240 general constraints\n",
      "Variable types: 621 continuous, 120 integer (120 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 5e+06]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e-03, 1e+00]\n",
      "  GenCon coe range [1e+00, 1e+00]\n",
      "Presolve removed 20 rows and 213 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 535 rows, 529 columns, 1913 nonzeros\n",
      "Presolved model has 202 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 327 continuous, 202 integer (202 binary)\n",
      "\n",
      "Root relaxation: objective 2.157366e+07, 225 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1574e+07    0   50          - 2.1574e+07      -     -    0s\n",
      "     0     2 2.1574e+07    0   50          - 2.1574e+07      -     -    0s\n",
      "* 2081  1156             109    1.667114e+07 2.1572e+07  29.4%   2.8    0s\n",
      "* 2121  1105             110    1.994587e+07 2.1572e+07  8.15%   2.7    0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_65248/565741137.py:107: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_65248/348315154.py:156: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H 2799  1424                    1.996168e+07 2.1570e+07  8.06%   2.7    0s\n",
      "H 4767  1497                    2.094624e+07 2.1567e+07  2.97%   3.2    0s\n",
      "H 4868  1432                    2.095520e+07 2.1567e+07  2.92%   3.2    0s\n",
      "H 6192  1292                    2.095920e+07 2.1556e+07  2.85%   3.8    0s\n",
      "*10554  2205              64    2.096442e+07 2.1550e+07  2.79%   4.9    0s\n",
      "*10723  2005              76    2.114468e+07 2.1550e+07  1.92%   4.9    0s\n",
      "*10797  1996              78    2.115169e+07 2.1550e+07  1.88%   4.9    0s\n",
      "*11310  2019              74    2.117931e+07 2.1549e+07  1.75%   5.0    0s\n",
      "H11645  2098                    2.118195e+07 2.1549e+07  1.73%   5.1    0s\n",
      "H11720  2098                    2.118195e+07 2.1548e+07  1.73%   5.1    0s\n",
      "*36730  4042              64    2.118546e+07 2.1468e+07  1.33%   9.1    2s\n",
      "H37627  3867                    2.119838e+07 2.1463e+07  1.25%   9.2    2s\n",
      "H38012  3867                    2.119845e+07 2.1463e+07  1.25%   9.3    2s\n",
      "H38238  3867                    2.119846e+07 2.1462e+07  1.24%   9.3    2s\n",
      "H39806  3695                    2.119882e+07 2.1454e+07  1.21%   9.5    2s\n",
      "\n",
      "Cutting planes:\n",
      "  Cover: 2\n",
      "\n",
      "Explored 44192 nodes (452674 simplex iterations) in 2.55 seconds (4.48 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 10: 2.11988e+07 2.11985e+07 2.11984e+07 ... 2.11447e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.119881840730e+07, best bound 2.140210091562e+07, gap 0.9589%\n",
      "\n",
      "model.status is optimal: True\n",
      "model.status is TIME_LIMIT: False\n",
      "\n",
      "f_vars[i]: 1.2775, F_vars[i]: 0.7820, Q0_vars[i]: 1886.2207\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -6.529111224209254\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -6.529111224209254\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.8828775610992122\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.0995, F_vars[i]: 0.7502, Q0_vars[i]: 1809.3757\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -7.548467378868433\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -7.548467378868433\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -1.0207166397750336\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.2106, F_vars[i]: 0.7704, Q0_vars[i]: 1858.1891\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -6.912300664433097\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -6.912300664433097\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.9346930910858027\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.1714, F_vars[i]: 0.7634, Q0_vars[i]: 1841.2807\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -7.136867897737297\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -7.136867897737297\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.9650594555776898\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.3633, F_vars[i]: 0.7963, Q0_vars[i]: 1920.6580\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -6.037579600872711\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -6.037579600872711\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.8164118162355901\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.1542, F_vars[i]: 0.7603, Q0_vars[i]: 1833.7603\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -7.235270994151755\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -7.235270994151755\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.9783656901911963\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.1561, F_vars[i]: 0.7606, Q0_vars[i]: 1834.6104\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -7.224191445444843\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -7.224191445444843\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.9768674947087594\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.1544, F_vars[i]: 0.7603, Q0_vars[i]: 1833.8680\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -7.233867993749514\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -7.233867993749514\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.978175974082707\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.0403, F_vars[i]: 0.7389, Q0_vars[i]: 1782.2178\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -7.887496157029249\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -7.887496157029249\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -1.0665606896811244\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.1318, F_vars[i]: 0.7562, Q0_vars[i]: 1823.8482\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -7.363640598206967\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -7.363640598206967\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.9957240471031301\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.2443, F_vars[i]: 0.7763, Q0_vars[i]: 1872.4581\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -6.719015801147572\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -6.719015801147572\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.9085567820484901\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.2173, F_vars[i]: 0.7716, Q0_vars[i]: 1861.0327\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -6.874063907598683\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -6.874063907598683\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.9295226515789462\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.1262, F_vars[i]: 0.7551, Q0_vars[i]: 1821.3889\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -7.39526239185453\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -7.39526239185453\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -1.0\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.3489, F_vars[i]: 0.7939, Q0_vars[i]: 1914.9717\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -6.12045094325854\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -6.12045094325854\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.8276178205657552\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 1.1370, F_vars[i]: 0.7571, Q0_vars[i]: 1826.1832\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -7.333533430891335\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -250.0\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -7.333533430891335\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.9916529045634425\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "all_Rs: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "Fold 2 Q_star: 2411.9773159880024\n",
      "baseline_profit: 339886.65508754214\n",
      "f_vars[i]: 0.4287227369182537, F_vars[i]: 0.6055686285930436\n",
      "f_vars[i]: 0.5130800077613793, F_vars[i]: 0.6255282221732547\n",
      "f_vars[i]: 0.528009608675353, F_vars[i]: 0.6290187652718507\n",
      "f_vars[i]: 0.49382683244578773, F_vars[i]: 0.6210075210077397\n",
      "f_vars[i]: 0.4849774544878477, F_vars[i]: 0.6189225372878906\n",
      "f_vars[i]: 0.44713194774477777, F_vars[i]: 0.6099571128455701\n",
      "f_vars[i]: 0.47125120617936433, F_vars[i]: 0.6156798573272262\n",
      "f_vars[i]: 0.3704869302935378, F_vars[i]: 0.591576632716597\n",
      "f_vars[i]: 0.5329365455939885, F_vars[i]: 0.6301677537903126\n",
      "f_vars[i]: 0.5133559971874495, F_vars[i]: 0.6255928684320048\n",
      "f_vars[i]: 0.5220742940162637, F_vars[i]: 0.6276326775647836\n",
      "f_vars[i]: 0.4319356156757588, F_vars[i]: 0.6063357807370082\n",
      "f_vars[i]: 0.5052154822135707, F_vars[i]: 0.6236842037993622\n",
      "f_vars[i]: 0.46617255210157915, F_vars[i]: 0.6144774516637309\n",
      "f_vars[i]: 0.5068404769466737, F_vars[i]: 0.6240655169444413\n",
      "assigned_R: 7\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 210 rows, 435 columns and 960 nonzeros\n",
      "Model fingerprint: 0xd283ba3a\n",
      "Model has 105 general constraints\n",
      "Variable types: 315 continuous, 120 integer (120 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Presolve removed 199 rows and 410 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 11 rows, 25 columns, 59 nonzeros\n",
      "Presolved model has 6 SOS constraint(s)\n",
      "Variable types: 11 continuous, 14 integer (14 binary)\n",
      "Found heuristic solution: objective 1.173064e+07\n",
      "\n",
      "Root relaxation: interrupted, 7 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0          -    0      1.1731e+07 1.1735e+07  0.04%     -    0s\n",
      "\n",
      "Explored 1 nodes (7 simplex iterations) in 0.02 seconds (0.01 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 1.17306e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 1.173064356555e+07, best bound 1.173498006774e+07, gap 0.0370%\n",
      "\n",
      "model.status is optimal: True\n",
      "model.status is TIME_LIMIT: False\n",
      "\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 1.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 1.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 1.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 1.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 1.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 1.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 1.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "tau: [-100.         -100.           -3.34127574 -100.         -100.\n",
      "   -3.34127574   -0.45181301    0.        ]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-100.         -100.           -2.42076512 -100.         -100.\n",
      "   -2.42076512   -0.32733999    0.        ]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-100.         -100.           -2.2578526  -100.         -100.\n",
      "   -2.2578526    -0.30531068    0.        ]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-100.         -100.           -2.6308567  -100.         -100.\n",
      "   -2.6308567    -0.35574893    0.        ]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-100.         -100.           -2.72742154 -100.         -100.\n",
      "   -2.72742154   -0.3688066     0.        ]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-100.         -100.           -3.14039354 -100.         -100.\n",
      "   -3.14039354   -0.42464937    0.        ]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-100.         -100.           -2.87720303 -100.         -100.\n",
      "   -2.87720303   -0.3890603     0.        ]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-100.         -100.           -3.97674768 -100.         -100.\n",
      "   -3.97674768   -0.53774261    0.        ]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-100.         -100.           -2.20408962 -100.         -100.\n",
      "   -2.20408962   -0.29804076    0.        ]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-100.         -100.           -2.41775351 -100.         -100.\n",
      "   -2.41775351   -0.32693276    0.        ]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-100.         -100.           -2.32261904 -100.         -100.\n",
      "   -2.32261904   -0.31406851    0.        ]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-100.         -100.           -3.30621665 -100.         -100.\n",
      "   -3.30621665   -0.44707226    0.        ]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-100.         -100.           -2.50658321 -100.         -100.\n",
      "   -2.50658321   -0.33894446    0.        ]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-100.         -100.           -2.93262155 -100.         -100.\n",
      "   -2.93262155   -0.39655409    0.        ]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "tau: [-100.         -100.           -2.48885118 -100.         -100.\n",
      "   -2.48885118   -0.3365467     0.        ]\n",
      "R: [0 0 0 0 0 0 0 1]\n",
      "max_r_index: 7\n",
      "\n",
      "\n",
      "\n",
      "===== Processing Fold 3 =====\n",
      "mean of sum: 2421.9595370061525\n",
      "std of sum: 71.01185031754258\n",
      "60.0 percentile of sum: 2439.950183572415\n",
      "Fold 3 Q_star: 2439.950183572415\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=0 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x3149f492\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [2e+02, 2e+03]\n",
      "Presolve removed 63 rows and 99 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 230 rows, 165 columns, 607 nonzeros\n",
      "Presolved model has 39 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 126 continuous, 39 integer (39 binary)\n",
      "\n",
      "Root relaxation: objective 2.145746e+07, 88 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1457e+07    0   23          - 2.1457e+07      -     -    0s\n",
      "H    0     0                    1.535866e+07 2.1457e+07  39.7%     -    0s\n",
      "     0     2 2.1457e+07    0   22 1.5359e+07 2.1457e+07  39.7%     -    0s\n",
      "H   66    52                    2.138878e+07 2.1423e+07  0.16%   2.8    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 5\n",
      "\n",
      "Explored 89 nodes (324 simplex iterations) in 0.03 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 2.13888e+07 1.53587e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.138877740288e+07, best bound 2.142169189787e+07, gap 0.1539%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.942744256666603, Left1: 34.40033169493654\n",
      "f_vars[i]: -2.3237, F_vars[i]: 0.0892, Q0_vars[i]: 217.5924\n",
      "f_train: -2.32370051981091, F_train: 0.08917902314184205, Q0_train: 217.59237388574616\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 30.13939082157094, Left0: 11.599672299804748, Left1: 0.0\n",
      "f_vars[i]: -2.3217, F_vars[i]: 0.0893, Q0_vars[i]: 217.9922\n",
      "f_train: -2.321684659874063, F_train: 0.08934289929277733, Q0_train: 217.99222353030385\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.780135226845218, Left1: 23.958598818924656\n",
      "f_vars[i]: -2.3443, F_vars[i]: 0.0875, Q0_vars[i]: 213.5378\n",
      "f_train: -2.3443326756445684, F_train: 0.08751729701505546, Q0_train: 213.53784491764614\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 39.812219486902734, Left0: 5.997831937831509, Left1: 0.0\n",
      "f_vars[i]: -2.3228, F_vars[i]: 0.0892, Q0_vars[i]: 217.7633\n",
      "f_train: -2.322838220808601, F_train: 0.08924908916495145, Q0_train: 217.76333149169412\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 19.30870245813685, Left0: 4.473992631227483, Left1: 0.0\n",
      "f_vars[i]: -2.3253, F_vars[i]: 0.0891, Q0_vars[i]: 217.2833\n",
      "f_train: -2.3252608235922048, F_train: 0.0890523669249368, Q0_train: 217.2833390260576\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 24.325608015315538\n",
      "f_vars[i]: -2.3324, F_vars[i]: 0.0885, Q0_vars[i]: 215.8740\n",
      "f_train: -2.3324018828229, F_train: 0.0884747670917031, Q0_train: 215.87402420692763\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 3.54694125445274, Left1: 35.72797391986842\n",
      "f_vars[i]: -2.3512, F_vars[i]: 0.0870, Q0_vars[i]: 212.2106\n",
      "f_train: -2.3511634739571767, F_train: 0.08697333775573979, Q0_train: 212.21061142302295\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 16.792373578614843, Left0: 3.305603056156021, Left1: 0.0\n",
      "f_vars[i]: -2.3211, F_vars[i]: 0.0894, Q0_vars[i]: 218.1016\n",
      "f_train: -2.321134015560789, F_train: 0.08938771025647861, Q0_train: 218.10156004941283\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.186755455772054, Left1: 20.32889123741552\n",
      "f_vars[i]: -2.3519, F_vars[i]: 0.0869, Q0_vars[i]: 212.0744\n",
      "f_train: -2.3518666862196067, F_train: 0.08691751260633504, Q0_train: 212.07440083948487\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 55.85462099144115, Left0: 4.858136765004755, Left1: 0.0\n",
      "f_vars[i]: -2.3211, F_vars[i]: 0.0894, Q0_vars[i]: 218.1098\n",
      "f_train: -2.3210924132475093, F_train: 0.08939109664059755, Q0_train: 218.10982265796548\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 2.438752957684239, Left1: 95.47284252627833\n",
      "f_vars[i]: -2.3576, F_vars[i]: 0.0865, Q0_vars[i]: 210.9644\n",
      "f_train: -2.3576127331522723, F_train: 0.08646257099327641, Q0_train: 210.96436596718775\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 33.71646139994209, Left0: 9.968603967671758, Left1: 0.0\n",
      "f_vars[i]: -2.3365, F_vars[i]: 0.0881, Q0_vars[i]: 215.0597\n",
      "f_train: -2.33654714866461, F_train: 0.08814103369666983, Q0_train: 215.05973134845195\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 10.057436261563694, Left1: 2.260117205147708\n",
      "f_vars[i]: -2.3576, F_vars[i]: 0.0865, Q0_vars[i]: 210.9620\n",
      "f_train: -2.3576252454900497, F_train: 0.08646158268893359, Q0_train: 210.96195455382505\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 55.270566432113355\n",
      "f_vars[i]: -2.3422, F_vars[i]: 0.0877, Q0_vars[i]: 213.9544\n",
      "f_train: -2.342196944309139, F_train: 0.08768800260878261, Q0_train: 213.95435806239752\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.733439586055052, Left1: 69.63978634475234\n",
      "f_vars[i]: -2.3478, F_vars[i]: 0.0872, Q0_vars[i]: 212.8684\n",
      "f_train: -2.347773054814954, F_train: 0.08724294475041541, Q0_train: 212.86843905917414\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=1 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xe4020d76\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [4e+02, 2e+03]\n",
      "Presolve removed 65 rows and 103 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 228 rows, 161 columns, 600 nonzeros\n",
      "Presolved model has 37 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 124 continuous, 37 integer (37 binary)\n",
      "\n",
      "Root relaxation: objective 2.145249e+07, 89 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1452e+07    0   22          - 2.1452e+07      -     -    0s\n",
      "H    0     0                    1.662303e+07 2.1452e+07  29.1%     -    0s\n",
      "     0     2 2.1452e+07    0   21 1.6623e+07 2.1452e+07  29.1%     -    0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_65248/2788820283.py:74: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_65248/565741137.py:107: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_65248/904923607.py:90: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H   55    34                    2.107288e+07 2.1419e+07  1.64%   2.7    0s\n",
      "H   76    46                    2.118501e+07 2.1419e+07  1.11%   3.5    0s\n",
      "H  207    84                    2.127503e+07 2.1416e+07  0.66%   4.1    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 4\n",
      "\n",
      "Explored 255 nodes (1129 simplex iterations) in 0.03 seconds (0.03 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 4: 2.1275e+07 2.1185e+07 2.10729e+07 1.6623e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.127503444278e+07, best bound 2.141562619115e+07, gap 0.6608%\n",
      "Model status: 2\n",
      "Lost0: 5.276280313727568, Lost1: 0.0, Left0: 0.0, Left1: 39.6577813528088\n",
      "f_vars[i]: -1.5447, F_vars[i]: 0.1759, Q0_vars[i]: 429.0791\n",
      "f_train: -1.5446819173954325, F_train: 0.1758556921965728, Q0_train: 429.0791284572819\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 31.259601900358575, Left0: 13.235715275585097, Left1: 0.0\n",
      "f_vars[i]: -1.5503, F_vars[i]: 0.1750, Q0_vars[i]: 427.0945\n",
      "f_train: -1.5503043732435076, F_train: 0.17504231155918487, Q0_train: 427.094520221773\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 29.837185837151083, Left1: 24.761905991686035\n",
      "f_vars[i]: -1.4871, F_vars[i]: 0.1844, Q0_vars[i]: 449.8095\n",
      "f_train: -1.4871365576683204, F_train: 0.18435190348421004, Q0_train: 449.8094607482224\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 38.566178894592895, Left0: 2.145208786973943, Left1: 0.0\n",
      "f_vars[i]: -1.5471, F_vars[i]: 0.1755, Q0_vars[i]: 428.2293\n",
      "f_train: -1.547086964482138, F_train: 0.17550739928829032, Q0_train: 428.2293111117811\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 15.001412972206992, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.5403, F_vars[i]: 0.1765, Q0_vars[i]: 430.6202\n",
      "f_train: -1.5403300579435133, F_train: 0.1764872991896379, Q0_train: 430.62021805595674\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.219949228534593, Left1: 23.862424122477933\n",
      "f_vars[i]: -1.5204, F_vars[i]: 0.1794, Q0_vars[i]: 437.7288\n",
      "f_train: -1.5204128556125482, F_train: 0.17940073236524137, Q0_train: 437.72884986759635\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 35.975739347290755, Left1: 37.82163447040216\n",
      "f_vars[i]: -1.4681, F_vars[i]: 0.1872, Q0_vars[i]: 456.8414\n",
      "f_train: -1.4680847072804344, F_train: 0.187233903592073, Q0_train: 456.84139744045837\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 3.1992054222660045, Lost1: 14.89591518118398, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.5518, F_vars[i]: 0.1748, Q0_vars[i]: 426.5537\n",
      "f_train: -1.551840181006133, F_train: 0.17482064774752323, Q0_train: 426.55367156381783\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 44.73403342417873, Left1: 21.436829194529537\n",
      "f_vars[i]: -1.4661, F_vars[i]: 0.1875, Q0_vars[i]: 457.5701\n",
      "f_train: -1.4661233706691612, F_train: 0.18753255774772273, Q0_train: 457.5700987023606\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 57.50821958039751, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.5520, F_vars[i]: 0.1748, Q0_vars[i]: 426.5128\n",
      "f_train: -1.5519562144493877, F_train: 0.1748039095815223, Q0_train: 426.5128312726112\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 51.54462260968103, Left1: 87.22883264854977\n",
      "f_vars[i]: -1.4501, F_vars[i]: 0.1900, Q0_vars[i]: 463.5579\n",
      "f_train: -1.45009701160058, F_train: 0.18998663628479265, Q0_train: 463.5579280793855\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 38.879467024925134, Left0: 33.884361312419514, Left1: 0.0\n",
      "f_vars[i]: -1.5089, F_vars[i]: 0.1811, Q0_vars[i]: 441.8972\n",
      "f_train: -1.5088512516798862, F_train: 0.18110909999378746, Q0_train: 441.8971817764766\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 56.72747123555155, Left1: 5.309550922806011\n",
      "f_vars[i]: -1.4501, F_vars[i]: 0.1900, Q0_vars[i]: 463.5710\n",
      "f_train: -1.4500621133095715, F_train: 0.18999200690072654, Q0_train: 463.57103211471923\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 17.699586499821862, Left1: 56.113439841190484\n",
      "f_vars[i]: -1.4931, F_vars[i]: 0.1835, Q0_vars[i]: 447.6281\n",
      "f_train: -1.4930933480768758, F_train: 0.1834578866929348, Q0_train: 447.6281043142336\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 31.87082715205679, Left1: 73.67751618630064\n",
      "f_vars[i]: -1.4775, F_vars[i]: 0.1858, Q0_vars[i]: 453.3406\n",
      "f_train: -1.477540960458137, F_train: 0.18579913003466939, Q0_train: 453.34062143568656\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=2 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xf14f3675\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [6e+02, 2e+03]\n",
      "Presolve removed 65 rows and 103 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 228 rows, 161 columns, 600 nonzeros\n",
      "Presolved model has 37 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 124 continuous, 37 integer (37 binary)\n",
      "\n",
      "Root relaxation: objective 2.145367e+07, 91 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1454e+07    0   22          - 2.1454e+07      -     -    0s\n",
      "H    0     0                    1.789670e+07 2.1454e+07  19.9%     -    0s\n",
      "     0     2 2.1454e+07    0   21 1.7897e+07 2.1454e+07  19.9%     -    0s\n",
      "H   56    34                    2.089105e+07 2.1421e+07  2.54%   3.0    0s\n",
      "H   57    34                    2.120533e+07 2.1421e+07  1.02%   3.0    0s\n",
      "H   98    38                    2.121863e+07 2.1421e+07  0.95%   4.9    0s\n",
      "H  105    38                    2.124360e+07 2.1421e+07  0.83%   5.2    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 4\n",
      "\n",
      "Explored 111 nodes (695 simplex iterations) in 0.03 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 5: 2.12436e+07 2.12186e+07 2.12053e+07 ... 1.78967e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.124360253818e+07, best bound 2.142076136030e+07, gap 0.8339%\n",
      "Model status: 2\n",
      "Lost0: 9.39960964493747, Lost1: 0.0, Left0: 0.0, Left1: 42.41257068406867\n",
      "f_vars[i]: -1.0297, F_vars[i]: 0.2631, Q0_vars[i]: 642.0624\n",
      "f_train: -1.0296822289509007, F_train: 0.2631457153504923, Q0_train: 642.0624364757282\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 29.818136485067498, Left0: 15.95655847507237, Left1: 0.0\n",
      "f_vars[i]: -1.0348, F_vars[i]: 0.2622, Q0_vars[i]: 639.6585\n",
      "f_train: -1.03476947148563, F_train: 0.26216048803948605, Q0_train: 639.6585309173779\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 36.773954866769145, Left1: 24.1804424244267\n",
      "f_vars[i]: -0.9776, F_vars[i]: 0.2734, Q0_vars[i]: 666.9978\n",
      "f_train: -0.9776147321860696, F_train: 0.2733653292322143, Q0_train: 666.997785242475\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.465475838164366, Lost1: 37.25400034956741, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.0319, F_vars[i]: 0.2627, Q0_vars[i]: 641.0334\n",
      "f_train: -1.0318583345830514, F_train: 0.2627239858984992, Q0_train: 641.0334376219197\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 17.32854987015139, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.0257, F_vars[i]: 0.2639, Q0_vars[i]: 643.9271\n",
      "f_train: -1.025744632088038, F_train: 0.2639099273153003, Q0_train: 643.9270755995497\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.8350030580183324, Left1: 24.756151872247983\n",
      "f_vars[i]: -1.0077, F_vars[i]: 0.2674, Q0_vars[i]: 652.5052\n",
      "f_train: -1.0077233898393179, F_train: 0.2674256233230849, Q0_train: 652.5051987191284\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 42.30494315020405, Left1: 38.464802348741614\n",
      "f_vars[i]: -0.9604, F_vars[i]: 0.2768, Q0_vars[i]: 675.3851\n",
      "f_train: -0.9603764672218845, F_train: 0.27680282619752744, Q0_train: 675.3851065940204\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 9.258026889663313, Lost1: 7.38213495610108, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.0362, F_vars[i]: 0.2619, Q0_vars[i]: 639.0029\n",
      "f_train: -1.0361590825001605, F_train: 0.2618917811444134, Q0_train: 639.0028994794183\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 59.11268830949484, Left1: 19.319834330839058\n",
      "f_vars[i]: -0.9586, F_vars[i]: 0.2772, Q0_vars[i]: 676.2522\n",
      "f_train: -0.9586018343384255, F_train: 0.27715821824542847, Q0_train: 676.2522454865366\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 59.327205819866776, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.0363, F_vars[i]: 0.2619, Q0_vars[i]: 638.9534\n",
      "f_train: -1.0362640704776431, F_train: 0.26187148700576957, Q0_train: 638.9533827921088\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 65.63792250765846, Left1: 85.69613599996092\n",
      "f_vars[i]: -0.9441, F_vars[i]: 0.2801, Q0_vars[i]: 683.3634\n",
      "f_train: -0.9441010578568386, F_train: 0.28007269284367425, Q0_train: 683.3634183175436\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 37.66255081484519, Left0: 42.6664020221142, Left1: 0.0\n",
      "f_vars[i]: -0.9973, F_vars[i]: 0.2695, Q0_vars[i]: 657.5178\n",
      "f_train: -0.9972623591286782, F_train: 0.2694800145878977, Q0_train: 657.5178110628381\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 72.5745057232723, Left1: 5.551228736449048\n",
      "f_vars[i]: -0.9441, F_vars[i]: 0.2801, Q0_vars[i]: 683.3790\n",
      "f_train: -0.944069481607028, F_train: 0.2800790596696447, Q0_train: 683.378953055739\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 14.91463910141465, Left1: 58.463952009389914\n",
      "f_vars[i]: -0.9830, F_vars[i]: 0.2723, Q0_vars[i]: 664.3888\n",
      "f_train: -0.9830044832762885, F_train: 0.27229603545731407, Q0_train: 664.3887617001143\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 37.53780524946092, Left1: 74.2366098646578\n",
      "f_vars[i]: -0.9689, F_vars[i]: 0.2751, Q0_vars[i]: 671.2140\n",
      "f_train: -0.9689325599124562, F_train: 0.27509331678132887, Q0_train: 671.2139887801479\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=3 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x48fd12ac\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [8e+02, 2e+03]\n",
      "Presolve removed 69 rows and 108 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 224 rows, 156 columns, 589 nonzeros\n",
      "Presolved model has 36 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 120 continuous, 36 integer (36 binary)\n",
      "\n",
      "Root relaxation: objective 2.156037e+07, 90 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1560e+07    0   22          - 2.1560e+07      -     -    0s\n",
      "H    0     0                    1.929042e+07 2.1560e+07  11.8%     -    0s\n",
      "     0     2 2.1560e+07    0   21 1.9290e+07 2.1560e+07  11.8%     -    0s\n",
      "H   64    50                    2.138913e+07 2.1536e+07  0.69%   2.7    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 4\n",
      "\n",
      "Explored 87 nodes (325 simplex iterations) in 0.02 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 2.13891e+07 1.92904e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.138912793496e+07, best bound 2.153626626820e+07, gap 0.6879%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 19.96925689541854, Left0: 8.860548283794463, Left1: 0.0\n",
      "f_vars[i]: -0.5775, F_vars[i]: 0.3595, Q0_vars[i]: 877.1653\n",
      "f_train: -0.5775292177713176, F_train: 0.35950131856149947, Q0_train: 877.1653082186559\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 40.3132492362638, Left0: 46.9083289808495, Left1: 0.0\n",
      "f_vars[i]: -0.5757, F_vars[i]: 0.3599, Q0_vars[i]: 878.2149\n",
      "f_train: -0.5756615031858249, F_train: 0.35993149150429105, Q0_train: 878.2149087693881\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 23.07454264966865, Left1: 55.63024619922476\n",
      "f_vars[i]: -0.5966, F_vars[i]: 0.3551, Q0_vars[i]: 866.4546\n",
      "f_train: -0.5966451184727075, F_train: 0.355111612326802, Q0_train: 866.4546436854768\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 34.85851986290061, Left0: 19.973830201554463, Left1: 0.0\n",
      "f_vars[i]: -0.5767, F_vars[i]: 0.3597, Q0_vars[i]: 877.6142\n",
      "f_train: -0.5767302890391027, F_train: 0.3596853006295742, Q0_train: 877.6142152994289\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 8.364370059295652, Left0: 15.199369346910657, Left1: 0.0\n",
      "f_vars[i]: -0.5790, F_vars[i]: 0.3592, Q0_vars[i]: 876.3533\n",
      "f_train: -0.5789748549789706, F_train: 0.3591685136178581, Q0_train: 876.3532807353243\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 28.808026756610616\n",
      "f_vars[i]: -0.5856, F_vars[i]: 0.3576, Q0_vars[i]: 872.6411\n",
      "f_train: -0.58559111845901, F_train: 0.3576470946346468, Q0_train: 872.6410942079473\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 19.847543599214994, Left1: 8.343415849739358\n",
      "f_vars[i]: -0.6030, F_vars[i]: 0.3537, Q0_vars[i]: 862.9216\n",
      "f_train: -0.6029739220794557, F_train: 0.35366360236685673, Q0_train: 862.9215715178937\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.103287352601239, Left1: 10.03251624022164\n",
      "f_vars[i]: -0.5752, F_vars[i]: 0.3600, Q0_vars[i]: 878.5017\n",
      "f_train: -0.5751513256697576, F_train: 0.36004903501226654, Q0_train: 878.5017090732506\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 7.453617130940984, Left0: 42.17906396040846, Left1: 0.0\n",
      "f_vars[i]: -0.6036, F_vars[i]: 0.3535, Q0_vars[i]: 862.5582\n",
      "f_train: -0.6036254553408845, F_train: 0.3535146854105718, Q0_train: 862.5582215630692\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 20.262499848900354, Left1: 0.3339373402283172\n",
      "f_vars[i]: -0.5751, F_vars[i]: 0.3601, Q0_vars[i]: 878.5234\n",
      "f_train: -0.5751127807064484, F_train: 0.36005791634884343, Q0_train: 878.5233790920618\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 37.93553245142103, Left1: 47.68684095931985\n",
      "f_vars[i]: -0.6089, F_vars[i]: 0.3523, Q0_vars[i]: 859.5918\n",
      "f_train: -0.6089492258414533, F_train: 0.35229893095542497, Q0_train: 859.5918412570547\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 25.398860530621732, Left0: 49.87116086517715, Left1: 0.0\n",
      "f_vars[i]: -0.5894, F_vars[i]: 0.3568, Q0_vars[i]: 870.4894\n",
      "f_train: -0.589431749115828, F_train: 0.35676524806448506, Q0_train: 870.4894325071984\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 45.36325026982757, Left1: 25.278930225381828\n",
      "f_vars[i]: -0.6090, F_vars[i]: 0.3523, Q0_vars[i]: 859.5854\n",
      "f_train: -0.6089608186487401, F_train: 0.35229628566224663, Q0_train: 859.5853868734786\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 37.32163303968764\n",
      "f_vars[i]: -0.5947, F_vars[i]: 0.3556, Q0_vars[i]: 867.5606\n",
      "f_train: -0.5946663418260948, F_train: 0.3555648965424874, Q0_train: 867.5606345907489\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 21.358053228748098, Left1: 38.82356117777044\n",
      "f_vars[i]: -0.5998, F_vars[i]: 0.3544, Q0_vars[i]: 864.6744\n",
      "f_train: -0.5998326645113498, F_train: 0.35438197842991737, Q0_train: 864.6743733248325\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=4 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xad440d6c\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 1e+03]\n",
      "Presolve removed 59 rows and 81 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 234 rows, 183 columns, 625 nonzeros\n",
      "Presolved model has 53 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 130 continuous, 53 integer (53 binary)\n",
      "\n",
      "Root relaxation: objective 2.156336e+07, 102 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1563e+07    0   23          - 2.1563e+07      -     -    0s\n",
      "H    0     0                    2.058791e+07 2.1563e+07  4.74%     -    0s\n",
      "     0     2 2.1563e+07    0   22 2.0588e+07 2.1563e+07  4.74%     -    0s\n",
      "H   34    26                    2.058791e+07 2.1544e+07  4.64%   4.4    0s\n",
      "H   64    48                    2.133264e+07 2.1539e+07  0.97%   3.9    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 7\n",
      "\n",
      "Explored 87 nodes (403 simplex iterations) in 0.03 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 3: 2.13326e+07 2.05879e+07 2.05879e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.133264062299e+07, best bound 2.153935694645e+07, gap 0.9690%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 20.93177558043567, Left0: 24.629889803438367, Left1: 0.0\n",
      "f_vars[i]: -0.1766, F_vars[i]: 0.4560, Q0_vars[i]: 1112.5321\n",
      "f_train: -0.17659723117709067, F_train: 0.45596507433440175, Q0_train: 1112.5320668248335\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 35.744820611710566, Left0: 70.73247482415609, Left1: 0.0\n",
      "f_vars[i]: -0.1725, F_vars[i]: 0.4570, Q0_vars[i]: 1115.0394\n",
      "f_train: -0.17245536914923051, F_train: 0.4569926944166363, Q0_train: 1115.0394086331244\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 25.04042586168281, Left1: 58.900710818974176\n",
      "f_vars[i]: -0.2190, F_vars[i]: 0.4455, Q0_vars[i]: 1086.9259\n",
      "f_train: -0.21898883846999193, F_train: 0.4454705348312034, Q0_train: 1086.9259132374966\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 35.689126453713016, Left0: 36.014198544150766, Left1: 0.0\n",
      "f_vars[i]: -0.1748, F_vars[i]: 0.4564, Q0_vars[i]: 1113.6045\n",
      "f_train: -0.1748255190511427, F_train: 0.4564046010594461, Q0_train: 1113.6044901382902\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 9.274567123335146, Left0: 28.86488422172689, Left1: 0.0\n",
      "f_vars[i]: -0.1798, F_vars[i]: 0.4552, Q0_vars[i]: 1110.5920\n",
      "f_train: -0.1798030903072533, F_train: 0.4551699388822131, Q0_train: 1110.5919759323008\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 34.51583235980638\n",
      "f_vars[i]: -0.1945, F_vars[i]: 0.4515, Q0_vars[i]: 1101.7200\n",
      "f_train: -0.19447538054214666, F_train: 0.4515338106588232, Q0_train: 1101.7200042061477\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 23.03281012190133, Left1: 6.9228683679016285\n",
      "f_vars[i]: -0.2330, F_vars[i]: 0.4420, Q0_vars[i]: 1078.4733\n",
      "f_train: -0.23302365489439705, F_train: 0.4420062708304744, Q0_train: 1078.4732816529745\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 20.07245466297565, Left1: 10.072256205063468\n",
      "f_vars[i]: -0.1713, F_vars[i]: 0.4573, Q0_vars[i]: 1115.7245\n",
      "f_train: -0.17132399452824712, F_train: 0.4572734590806502, Q0_train: 1115.7244604266257\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 2.0996114127169676, Left0: 49.73066190998025, Left1: 0.0\n",
      "f_vars[i]: -0.2345, F_vars[i]: 0.4416, Q0_vars[i]: 1077.6039\n",
      "f_train: -0.23446850139094452, F_train: 0.44164994853796197, Q0_train: 1077.6038730099478\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.098385348809188, Left0: 36.18291215693734, Left1: 0.0\n",
      "f_vars[i]: -0.1712, F_vars[i]: 0.4573, Q0_vars[i]: 1115.7762\n",
      "f_train: -0.17123851684277228, F_train: 0.4572946725350684, Q0_train: 1115.7762201986275\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 45.52183478983411, Left1: 45.83627627412943\n",
      "f_vars[i]: -0.2463, F_vars[i]: 0.4387, Q0_vars[i]: 1070.5054\n",
      "f_train: -0.24627454662538292, F_train: 0.43874067155239715, Q0_train: 1070.505382094956\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 27.569813064115806, Left0: 69.28046490099793, Left1: 0.0\n",
      "f_vars[i]: -0.2030, F_vars[i]: 0.4494, Q0_vars[i]: 1096.5757\n",
      "f_train: -0.20299240043590797, F_train: 0.4494254449744442, Q0_train: 1096.5756969675094\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 51.63934284190876, Left1: 23.18328581901187\n",
      "f_vars[i]: -0.2463, F_vars[i]: 0.4387, Q0_vars[i]: 1070.4899\n",
      "f_train: -0.24630025494755944, F_train: 0.4387343409575806, Q0_train: 1070.4899357589713\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 35.67269860664419\n",
      "f_vars[i]: -0.2146, F_vars[i]: 0.4466, Q0_vars[i]: 1089.5714\n",
      "f_train: -0.21460068413534047, F_train: 0.44655478310529484, Q0_train: 1089.571425012904\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 28.847324287148037, Left1: 34.57010825180896\n",
      "f_vars[i]: -0.2261, F_vars[i]: 0.4437, Q0_vars[i]: 1082.6670\n",
      "f_train: -0.22605757156339726, F_train: 0.44372505024360476, Q0_train: 1082.6670177975625\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=5 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x823ede9c\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 1e+03]\n",
      "Presolve removed 57 rows and 79 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 236 rows, 185 columns, 633 nonzeros\n",
      "Presolved model has 53 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 132 continuous, 53 integer (53 binary)\n",
      "\n",
      "Root relaxation: objective 2.169825e+07, 99 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1698e+07    0   22          - 2.1698e+07      -     -    0s\n",
      "H    0     0                    2.019005e+07 2.1698e+07  7.47%     -    0s\n",
      "     0     2 2.1698e+07    0   21 2.0190e+07 2.1698e+07  7.47%     -    0s\n",
      "H   31    28                    2.129104e+07 2.1689e+07  1.87%   2.9    0s\n",
      "H   55    22                    2.138490e+07 2.1687e+07  1.41%  14.0    0s\n",
      "H  184    68                    2.142368e+07 2.1687e+07  1.23%   9.4    0s\n",
      "H  249    67                    2.145444e+07 2.1687e+07  1.08%   7.8    0s\n",
      "H  387    69                    2.149693e+07 2.1687e+07  0.88%   5.7    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 3\n",
      "\n",
      "Explored 454 nodes (2434 simplex iterations) in 0.04 seconds (0.04 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 6: 2.14969e+07 2.14544e+07 2.14237e+07 ... 2.019e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Warning: max constraint violation (5.8792e-06) exceeds tolerance\n",
      "Best objective 2.149693038764e+07, best bound 2.168712791072e+07, gap 0.8848%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.466824952796969, Left1: 3.188438344676797\n",
      "f_vars[i]: 0.1789, F_vars[i]: 0.5446, Q0_vars[i]: 1328.7879\n",
      "f_train: 0.1788605581090434, F_train: 0.544596312448138, Q0_train: 1328.7878725306946\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 63.89319703224908, Left1: 20.051998198768615\n",
      "f_vars[i]: 0.1861, F_vars[i]: 0.5464, Q0_vars[i]: 1333.1614\n",
      "f_train: 0.18609025091048736, F_train: 0.5463887712829674, Q0_train: 1333.1613827937824\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 19.945826147479693\n",
      "f_vars[i]: 0.1049, F_vars[i]: 0.5262, Q0_vars[i]: 1283.8830\n",
      "f_train: 0.10486526419881426, F_train: 0.5261923179741835, Q0_train: 1283.8830428355036\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 11.125712641672635, Left0: 20.015351890681814, Left1: 0.0\n",
      "f_vars[i]: 0.1820, F_vars[i]: 0.5454, Q0_vars[i]: 1330.6590\n",
      "f_train: 0.1819531126936813, F_train: 0.5453631941487493, Q0_train: 1330.6590256768795\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 10.484122011407862, Left1: 4.038582673085557\n",
      "f_vars[i]: 0.1733, F_vars[i]: 0.5432, Q0_vars[i]: 1325.4008\n",
      "f_train: 0.17326467477930468, F_train: 0.5432081280754585, Q0_train: 1325.400771815743\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 25.950158228570587, Lost1: 0.0, Left0: 0.0, Left1: 26.301576169995343\n",
      "f_vars[i]: 0.1477, F_vars[i]: 0.5368, Q0_vars[i]: 1309.8789\n",
      "f_train: 0.14765393488058598, F_train: 0.5368465649334768, Q0_train: 1309.8788746596572\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 3.2943662157824747, Lost1: 13.956432116423457, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 0.0804, F_vars[i]: 0.5201, Q0_vars[i]: 1268.9717\n",
      "f_train: 0.08036724601506229, F_train: 0.5200810042435543, Q0_train: 1268.9717417765862\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 11.677328396322537\n",
      "f_vars[i]: 0.1881, F_vars[i]: 0.5469, Q0_vars[i]: 1334.3555\n",
      "f_train: 0.18806508515123238, F_train: 0.5468781851672745, Q0_train: 1334.3555282906404\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 12.624467048278234, Left0: 29.676074826617764, Left1: 0.0\n",
      "f_vars[i]: 0.0778, F_vars[i]: 0.5195, Q0_vars[i]: 1267.4358\n",
      "f_train: 0.07784524111846824, F_train: 0.5194514884618635, Q0_train: 1267.435754629488\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.14212207762921025, Left0: 17.96312776588877, Left1: 0.0\n",
      "f_vars[i]: 0.1882, F_vars[i]: 0.5469, Q0_vars[i]: 1334.4457\n",
      "f_train: 0.18821428795016792, F_train: 0.5469151577256044, Q0_train: 1334.4457394911246\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 20.696863690404598, Left1: 16.115566661028197\n",
      "f_vars[i]: 0.0572, F_vars[i]: 0.5143, Q0_vars[i]: 1254.8798\n",
      "f_train: 0.05723758213060015, F_train: 0.5143054901792068, Q0_train: 1254.8797751750565\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 14.609873500394542, Left0: 56.23766637435233, Left1: 0.0\n",
      "f_vars[i]: 0.1328, F_vars[i]: 0.5331, Q0_vars[i]: 1300.8549\n",
      "f_train: 0.13278732730131482, F_train: 0.5331481391571047, Q0_train: 1300.854900007669\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 27.31831655322867, Left1: 6.208203740174213\n",
      "f_vars[i]: 0.0572, F_vars[i]: 0.5143, Q0_vars[i]: 1254.8524\n",
      "f_train: 0.05719270780341912, F_train: 0.5142942807736162, Q0_train: 1254.852424783828\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 28.664065418571198, Lost1: 0.0, Left0: 0.0, Left1: 28.11683675827704\n",
      "f_vars[i]: 0.1125, F_vars[i]: 0.5281, Q0_vars[i]: 1288.5415\n",
      "f_train: 0.11252486454075161, F_train: 0.528101570912419, Q0_train: 1288.5415248926377\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.129588199378418, Left1: 26.13651216175333\n",
      "f_vars[i]: 0.0925, F_vars[i]: 0.5231, Q0_vars[i]: 1276.3750\n",
      "f_train: 0.09252666662676423, F_train: 0.5231151779015962, Q0_train: 1276.3749743505161\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=6 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xab689e2b\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [8e+02, 2e+03]\n",
      "Presolve removed 60 rows and 102 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 233 rows, 162 columns, 624 nonzeros\n",
      "Presolved model has 33 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 129 continuous, 33 integer (33 binary)\n",
      "Found heuristic solution: objective 2.065836e+07\n",
      "\n",
      "Root relaxation: objective 2.171196e+07, 87 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1712e+07    0   20 2.0658e+07 2.1712e+07  5.10%     -    0s\n",
      "H    0     0                    2.079021e+07 2.1712e+07  4.43%     -    0s\n",
      "     0     2 2.1712e+07    0   20 2.0790e+07 2.1712e+07  4.43%     -    0s\n",
      "H  227    73                    2.136391e+07 2.1702e+07  1.58%   3.7    0s\n",
      "*  423   109              22    2.136392e+07 2.1702e+07  1.58%   3.2    0s\n",
      "H  512   131                    2.146875e+07 2.1702e+07  1.09%   3.1    0s\n",
      "H  548   131                    2.146883e+07 2.1702e+07  1.09%   3.0    0s\n",
      "H  565   127                    2.146883e+07 2.1702e+07  1.09%   3.0    0s\n",
      "*  672   127              32    2.146884e+07 2.1701e+07  1.08%   3.0    0s\n",
      "H  695   181                    2.147439e+07 2.1701e+07  1.06%   2.9    0s\n",
      "H  707   181                    2.148900e+07 2.1701e+07  0.99%   2.9    0s\n",
      "H  731   181                    2.151777e+07 2.1701e+07  0.85%   2.8    0s\n",
      "H  807   181                    2.151819e+07 2.1701e+07  0.85%   2.8    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 4\n",
      "\n",
      "Explored 827 nodes (2350 simplex iterations) in 0.06 seconds (0.05 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 10: 2.15182e+07 2.15178e+07 2.1489e+07 ... 2.13639e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.151818546898e+07, best bound 2.170147026463e+07, gap 0.8518%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.3876178802449886, Left1: 6.001827110043678\n",
      "f_vars[i]: 0.6625, F_vars[i]: 0.6598, Q0_vars[i]: 1609.9317\n",
      "f_train: 0.662499099657594, F_train: 0.659821552883867, Q0_train: 1609.9317190840272\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 72.7431832173969, Left1: 8.53268846365063\n",
      "f_vars[i]: 0.6756, F_vars[i]: 0.6628, Q0_vars[i]: 1617.0813\n",
      "f_train: 0.6755812619218209, F_train: 0.6627517683924896, Q0_train: 1617.0812989521976\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 17.986173719096996, Left1: 12.98970777369982\n",
      "f_vars[i]: 0.5286, F_vars[i]: 0.6292, Q0_vars[i]: 1535.1130\n",
      "f_train: 0.5286042761417963, F_train: 0.6291575227478808, Q0_train: 1535.1130131246578\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 10.285008910035685, Left0: 16.40019411556625, Left1: 0.0\n",
      "f_vars[i]: 0.6681, F_vars[i]: 0.6611, Q0_vars[i]: 1612.9937\n",
      "f_train: 0.6680950913543826, F_train: 0.6610764871527932, Q0_train: 1612.993696183865\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 6.198725650894858, Left1: 8.073829484752878\n",
      "f_vars[i]: 0.6524, F_vars[i]: 0.6575, Q0_vars[i]: 1604.3773\n",
      "f_train: 0.6523733231215976, F_train: 0.6575450861437866, Q0_train: 1604.3772536436716\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 29.188012873800204, Lost1: 0.0, Left0: 0.0, Left1: 41.89451863771694\n",
      "f_vars[i]: 0.6060, F_vars[i]: 0.6470, Q0_vars[i]: 1578.7327\n",
      "f_train: 0.6060305718784149, F_train: 0.6470347910064332, Q0_train: 1578.732657093886\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 15.691585269218535, Left0: 15.074922426265516, Left1: 0.0\n",
      "f_vars[i]: 0.4843, F_vars[i]: 0.6188, Q0_vars[i]: 1509.7359\n",
      "f_train: 0.48427499994242407, F_train: 0.6187568443292358, Q0_train: 1509.7358759078072\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.803904737729386, Left1: 1.8159296273031487\n",
      "f_vars[i]: 0.6792, F_vars[i]: 0.6636, Q0_vars[i]: 1619.0290\n",
      "f_train: 0.679154733532844, F_train: 0.663550016583987, Q0_train: 1619.0289847735783\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 12.374515224631637, Left0: 49.55496513474975, Left1: 0.0\n",
      "f_vars[i]: 0.4797, F_vars[i]: 0.6177, Q0_vars[i]: 1507.1078\n",
      "f_train: 0.47971142052147964, F_train: 0.6176797286125868, Q0_train: 1507.1077672172405\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.466221752448746, Left0: 6.221736632402249, Left1: 0.0\n",
      "f_vars[i]: 0.6794, F_vars[i]: 0.6636, Q0_vars[i]: 1619.1760\n",
      "f_train: 0.6794247166814449, F_train: 0.663610288036052, Q0_train: 1619.1760441141084\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 39.577574340823844, Left1: 7.335138570589265\n",
      "f_vars[i]: 0.4424, F_vars[i]: 0.6088, Q0_vars[i]: 1485.5294\n",
      "f_train: 0.4424217671199826, F_train: 0.6088359378385044, Q0_train: 1485.5293582945424\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 42.17273952912933, Left1: 4.153277139962029\n",
      "f_vars[i]: 0.5791, F_vars[i]: 0.6409, Q0_vars[i]: 1563.6837\n",
      "f_train: 0.5791293773170407, F_train: 0.6408670514726752, Q0_train: 1563.6836798862662\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 41.26809636868438, Left1: 5.246160364990146\n",
      "f_vars[i]: 0.4423, F_vars[i]: 0.6088, Q0_vars[i]: 1485.4822\n",
      "f_train: 0.4423405668192504, F_train: 0.6088165994312137, Q0_train: 1485.4821735441233\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 6.704123323402911, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 0.5425, F_vars[i]: 0.6324, Q0_vars[i]: 1542.9891\n",
      "f_train: 0.5424643580711886, F_train: 0.6323855037841076, Q0_train: 1542.9891260465674\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 27.54342436839977, Left1: 23.521137678609307\n",
      "f_vars[i]: 0.5063, F_vars[i]: 0.6239, Q0_vars[i]: 1522.3665\n",
      "f_train: 0.5062775272765727, F_train: 0.6239334353689422, Q0_train: 1522.366500165418\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=7 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xfc7ea32c\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [6e+02, 2e+03]\n",
      "Presolve removed 60 rows and 102 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 233 rows, 162 columns, 624 nonzeros\n",
      "Presolved model has 33 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 129 continuous, 33 integer (33 binary)\n",
      "Found heuristic solution: objective 2.074695e+07\n",
      "\n",
      "Root relaxation: objective 2.175233e+07, 87 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1752e+07    0   20 2.0747e+07 2.1752e+07  4.85%     -    0s\n",
      "     0     2 2.1752e+07    0   20 2.0747e+07 2.1752e+07  4.85%     -    0s\n",
      "H   74    43                    2.084906e+07 2.1740e+07  4.27%   6.7    0s\n",
      "H  231    83                    2.112468e+07 2.1688e+07  2.67%   3.7    0s\n",
      "H  345    97                    2.113653e+07 2.1675e+07  2.55%   3.1    0s\n",
      "H  543   131                    2.151204e+07 2.1673e+07  0.75%   2.6    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 3\n",
      "\n",
      "Explored 567 nodes (1538 simplex iterations) in 0.04 seconds (0.04 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 5: 2.1512e+07 2.11365e+07 2.11247e+07 ... 2.0747e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.151203564749e+07, best bound 2.167282815492e+07, gap 0.7475%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 4.135829402649733, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 1.2325, F_vars[i]: 0.7743, Q0_vars[i]: 1889.1507\n",
      "f_train: 1.2325118441106626, F_train: 0.7742579033398528, Q0_train: 1889.150713386467\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 62.62357540067694, Left1: 5.269010610735904\n",
      "f_vars[i]: 1.2529, F_vars[i]: 0.7778, Q0_vars[i]: 1897.8109\n",
      "f_train: 1.2529333009824895, F_train: 0.777807216567782, Q0_train: 1897.8108608485088\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 6.1980775186325445, Lost1: 0.0, Left0: 0.0, Left1: 7.066910261341947\n",
      "f_vars[i]: 1.0235, F_vars[i]: 0.7357, Q0_vars[i]: 1794.9586\n",
      "f_train: 1.0234999614751943, F_train: 0.7356537886316437, Q0_train: 1794.9585966175216\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.31353149632502664, Lost1: 0.0, Left0: 0.0, Left1: 4.028198583840195\n",
      "f_vars[i]: 1.2412, F_vars[i]: 0.7758, Q0_vars[i]: 1892.8671\n",
      "f_train: 1.2412472733755604, F_train: 0.7757810456305654, Q0_train: 1892.8671046982981\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 7.31377099884628, Lost1: 0.0, Left0: 0.0, Left1: 10.965695692379747\n",
      "f_vars[i]: 1.2167, F_vars[i]: 0.7715, Q0_vars[i]: 1882.3807\n",
      "f_train: 1.2167053509142698, F_train: 0.7714832327413529, Q0_train: 1882.380655350304\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 46.71242776489976, Lost1: 0.0, Left0: 0.0, Left1: 58.092727655259864\n",
      "f_vars[i]: 1.1444, F_vars[i]: 0.7585, Q0_vars[i]: 1850.6532\n",
      "f_train: 1.1443636021482917, F_train: 0.7584799005173439, Q0_train: 1850.6531725032803\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 21.311521281953333, Lost1: 0.0, Left0: 0.0, Left1: 23.900247651040683\n",
      "f_vars[i]: 0.9543, F_vars[i]: 0.7220, Q0_vars[i]: 1761.5937\n",
      "f_train: 0.9543012782773685, F_train: 0.7219793765778393, Q0_train: 1761.5937124165966\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 10.614583474047777, Lost1: 0.0, Left0: 0.0, Left1: 10.226435158195914\n",
      "f_vars[i]: 1.2585, F_vars[i]: 0.7788, Q0_vars[i]: 1900.1594\n",
      "f_train: 1.2585115452293718, F_train: 0.7787697721665874, Q0_train: 1900.1594485585126\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 7.562898019201725, Left0: 14.123025348969577, Left1: 0.0\n",
      "f_vars[i]: 0.9472, F_vars[i]: 0.7205, Q0_vars[i]: 1758.0992\n",
      "f_train: 0.947177460483057, F_train: 0.7205471884165738, Q0_train: 1758.0992446496068\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 11.2402837440967, Lost1: 0.0, Left0: 0.0, Left1: 11.97147791040774\n",
      "f_vars[i]: 1.2589, F_vars[i]: 0.7788, Q0_vars[i]: 1900.3366\n",
      "f_train: 1.2589329930843913, F_train: 0.7788423737969009, Q0_train: 1900.336592919724\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.2785936908728949, Left1: 8.060302815395175\n",
      "f_vars[i]: 0.8890, F_vars[i]: 0.7087, Q0_vars[i]: 1729.1368\n",
      "f_train: 0.8889677369432114, F_train: 0.7086771037829438, Q0_train: 1729.136829468761\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.204354010915381, Left0: 23.733346000459164, Left1: 0.0\n",
      "f_vars[i]: 1.1024, F_vars[i]: 0.7507, Q0_vars[i]: 1831.6803\n",
      "f_train: 1.1023704229291382, F_train: 0.7507039879250892, Q0_train: 1831.6803331463655\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 2.5663816718536374, Left1: 1.3708274534915614\n",
      "f_vars[i]: 0.8888, F_vars[i]: 0.7087, Q0_vars[i]: 1729.0730\n",
      "f_train: 0.888840982022588, F_train: 0.7086509340473246, Q0_train: 1729.072976617533\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 26.730140700958145, Lost1: 0.0, Left0: 0.0, Left1: 16.462649246792015\n",
      "f_vars[i]: 1.0451, F_vars[i]: 0.7398, Q0_vars[i]: 1805.1721\n",
      "f_train: 1.0451357629309714, F_train: 0.7398397387485933, Q0_train: 1805.1721063737978\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.528352628987256, Left1: 11.720395797012998\n",
      "f_vars[i]: 0.9886, F_vars[i]: 0.7288, Q0_vars[i]: 1778.2862\n",
      "f_train: 0.988647562473383, F_train: 0.7288207078654247, Q0_train: 1778.2862199476206\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 210 rows, 435 columns and 960 nonzeros\n",
      "Model fingerprint: 0x01f8d46c\n",
      "Model has 105 general constraints\n",
      "Variable types: 315 continuous, 120 integer (120 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Presolve removed 198 rows and 409 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 12 rows, 26 columns, 61 nonzeros\n",
      "Presolved model has 6 SOS constraint(s)\n",
      "Variable types: 12 continuous, 14 integer (14 binary)\n",
      "Found heuristic solution: objective 2.176003e+07\n",
      "\n",
      "Root relaxation: interrupted, 10 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0          -    0      2.1760e+07 2.1776e+07  0.07%     -    0s\n",
      "\n",
      "Explored 1 nodes (10 simplex iterations) in 0.02 seconds (0.01 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.176e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.176003449640e+07, best bound 2.177617520935e+07, gap 0.0742%\n",
      "\n",
      "model.status is optimal: True\n",
      "model.status is TIME_LIMIT: False\n",
      "\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 1.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 1.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 1.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 1.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 1.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 1.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 1.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 667 and 669 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 667 and 669 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 435 rows, 741 columns and 1830 nonzeros\n",
      "Model fingerprint: 0x50e61fa6\n",
      "Model has 240 general constraints\n",
      "Variable types: 621 continuous, 120 integer (120 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 5e+06]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e-03, 1e+00]\n",
      "  GenCon coe range [1e+00, 1e+00]\n",
      "Presolve removed 22 rows and 219 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 533 rows, 523 columns, 1907 nonzeros\n",
      "Presolved model has 198 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 325 continuous, 198 integer (198 binary)\n",
      "\n",
      "Root relaxation: objective 2.178898e+07, 235 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1789e+07    0   49          - 2.1789e+07      -     -    0s\n",
      "     0     2 2.1789e+07    0   49          - 2.1789e+07      -     -    0s\n",
      "* 1964  1361              99    2.010459e+07 2.1785e+07  8.36%   3.6    0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_65248/565741137.py:107: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_65248/348315154.py:156: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H 2601  1724                    2.014654e+07 2.1784e+07  8.13%   3.4    0s\n",
      "H 2867  1724                    2.014654e+07 2.1784e+07  8.13%   3.5    0s\n",
      "H 3952  1772                    2.015352e+07 2.1784e+07  8.09%   3.6    0s\n",
      "H 6137  1659                    2.040034e+07 2.1782e+07  6.77%   4.2    0s\n",
      "H 6683  1679                    2.044642e+07 2.1778e+07  6.51%   4.4    0s\n",
      "H 6696  1600                    2.044642e+07 2.1778e+07  6.51%   4.4    0s\n",
      "H 6826  1487                    2.044642e+07 2.1778e+07  6.51%   4.5    0s\n",
      "* 8373  2154             108    2.044862e+07 2.1777e+07  6.50%   4.8    0s\n",
      "* 8374  2154             108    2.044891e+07 2.1777e+07  6.50%   4.8    0s\n",
      "* 8379  2154             108    2.044948e+07 2.1777e+07  6.49%   4.8    0s\n",
      "* 8380  2154             108    2.044981e+07 2.1777e+07  6.49%   4.8    0s\n",
      "H 8532  2219                    2.047836e+07 2.1777e+07  6.34%   4.9    0s\n",
      "*11293  3190              70    2.051011e+07 2.1774e+07  6.16%   5.3    0s\n",
      "H11484  2999                    2.070070e+07 2.1774e+07  5.18%   5.3    0s\n",
      "*13698  3631              94    2.077887e+07 2.1772e+07  4.78%   5.6    0s\n",
      "H14136  3546                    2.085722e+07 2.1772e+07  4.38%   5.7    0s\n",
      "*17295  3192              54    2.120999e+07 2.1769e+07  2.63%   6.0    1s\n",
      "H17559  3221                    2.122200e+07 2.1769e+07  2.58%   6.1    1s\n",
      "H18859  3404                    2.122282e+07 2.1768e+07  2.57%   6.2    1s\n",
      "*19910  2540              83    2.143781e+07 2.1766e+07  1.53%   6.3    1s\n",
      "H20377  2223                    2.150060e+07 2.1765e+07  1.23%   6.4    1s\n",
      "H21670  2214                    2.150060e+07 2.1759e+07  1.20%   6.9    1s\n",
      "*24807  1687              74    2.153532e+07 2.1734e+07  0.92%   8.3    1s\n",
      "\n",
      "Cutting planes:\n",
      "  Cover: 4\n",
      "  Implied bound: 1\n",
      "\n",
      "Explored 25150 nodes (214546 simplex iterations) in 1.57 seconds (2.59 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 10: 2.15353e+07 2.15006e+07 2.15006e+07 ... 2.07007e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.153532113667e+07, best bound 2.172485664277e+07, gap 0.8801%\n",
      "\n",
      "model.status is optimal: True\n",
      "model.status is TIME_LIMIT: False\n",
      "\n",
      "f_vars[i]: 0.6568, F_vars[i]: 0.6585, Q0_vars[i]: 1606.7882\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.6732, F_vars[i]: 0.6622, Q0_vars[i]: 1615.7778\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.4886, F_vars[i]: 0.6198, Q0_vars[i]: 1512.2412\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.6638, F_vars[i]: 0.6601, Q0_vars[i]: 1610.6394\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.6440, F_vars[i]: 0.6557, Q0_vars[i]: 1599.7978\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.5859, F_vars[i]: 0.6424, Q0_vars[i]: 1567.4574\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.4330, F_vars[i]: 0.6066, Q0_vars[i]: 1480.0284\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.6777, F_vars[i]: 0.6632, Q0_vars[i]: 1618.2251\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.4272, F_vars[i]: 0.6052, Q0_vars[i]: 1476.6897\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.6780, F_vars[i]: 0.6633, Q0_vars[i]: 1618.4098\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.3804, F_vars[i]: 0.5940, Q0_vars[i]: 1449.2614\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.5521, F_vars[i]: 0.6346, Q0_vars[i]: 1548.4338\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.3803, F_vars[i]: 0.5939, Q0_vars[i]: 1449.2014\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.5060, F_vars[i]: 0.6239, Q0_vars[i]: 1522.2273\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.4606, F_vars[i]: 0.6132, Q0_vars[i]: 1496.0678\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "all_Rs: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n",
      "Fold 3 Q_star: 2439.950183572415\n",
      "baseline_profit: 306678.61416639516\n",
      "f_vars[i]: 0.32541061694675016, F_vars[i]: 0.5806422920512136\n",
      "f_vars[i]: 0.2598256373873711, F_vars[i]: 0.5645934291277908\n",
      "f_vars[i]: 0.30360215889612857, F_vars[i]: 0.5753228574752685\n",
      "f_vars[i]: 0.2562361828291755, F_vars[i]: 0.5637108381236166\n",
      "f_vars[i]: 0.30399758750464145, F_vars[i]: 0.5754194682713999\n",
      "f_vars[i]: 0.25035581012416247, F_vars[i]: 0.5622640759459882\n",
      "f_vars[i]: 0.224436217268136, F_vars[i]: 0.5558747093699016\n",
      "f_vars[i]: 0.3186911880911338, F_vars[i]: 0.5790052515838362\n",
      "f_vars[i]: 0.14953923874732683, F_vars[i]: 0.537315298580547\n",
      "f_vars[i]: 0.1834250162538988, F_vars[i]: 0.5457281166952748\n",
      "f_vars[i]: 0.26451461370962065, F_vars[i]: 0.5657457582151076\n",
      "f_vars[i]: 0.19509623201904214, F_vars[i]: 0.5486199392166506\n",
      "f_vars[i]: 0.31067057855336094, F_vars[i]: 0.5770489333056159\n",
      "f_vars[i]: 0.18090922759455386, F_vars[i]: 0.5451043587675819\n",
      "f_vars[i]: 0.08578357326424091, F_vars[i]: 0.5214327516117564\n",
      "assigned_R: 6\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 210 rows, 435 columns and 960 nonzeros\n",
      "Model fingerprint: 0x8737c322\n",
      "Model has 105 general constraints\n",
      "Variable types: 315 continuous, 120 integer (120 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Presolve removed 199 rows and 410 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 11 rows, 25 columns, 59 nonzeros\n",
      "Presolved model has 6 SOS constraint(s)\n",
      "Variable types: 11 continuous, 14 integer (14 binary)\n",
      "Found heuristic solution: objective 1.153841e+07\n",
      "\n",
      "Root relaxation: interrupted, 8 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0          -    0      1.1538e+07 1.1539e+07  0.01%     -    0s\n",
      "\n",
      "Explored 1 nodes (8 simplex iterations) in 0.02 seconds (0.01 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 1.15384e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 1.153840747616e+07, best bound 1.153909207971e+07, gap 0.0059%\n",
      "\n",
      "model.status is optimal: True\n",
      "model.status is TIME_LIMIT: False\n",
      "\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 1.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 1.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 1.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 1.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 1.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 1.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 1.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 1.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 1.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 1.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "tau: [-0.0004 -0.0004 -0.001  -0.0004 -0.0004 -0.001   0.     -0.001 ]\n",
      "R: [0 0 0 0 0 0 1 0]\n",
      "max_r_index: 6\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.0004 -0.0004 -0.001  -0.0004 -0.0004 -0.001   0.     -0.001 ]\n",
      "R: [0 0 0 0 0 0 1 0]\n",
      "max_r_index: 6\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.0004 -0.0004 -0.001  -0.0004 -0.0004 -0.001   0.     -0.001 ]\n",
      "R: [0 0 0 0 0 0 1 0]\n",
      "max_r_index: 6\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.0004 -0.0004 -0.001  -0.0004 -0.0004 -0.001   0.     -0.001 ]\n",
      "R: [0 0 0 0 0 0 1 0]\n",
      "max_r_index: 6\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.0004 -0.0004 -0.001  -0.0004 -0.0004 -0.001   0.     -0.001 ]\n",
      "R: [0 0 0 0 0 0 1 0]\n",
      "max_r_index: 6\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.0004 -0.0004 -0.001  -0.0004 -0.0004 -0.001   0.     -0.001 ]\n",
      "R: [0 0 0 0 0 0 1 0]\n",
      "max_r_index: 6\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.0004 -0.0004 -0.001  -0.0004 -0.0004 -0.001   0.     -0.001 ]\n",
      "R: [0 0 0 0 0 0 1 0]\n",
      "max_r_index: 6\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.0004 -0.0004 -0.001  -0.0004 -0.0004 -0.001   0.     -0.001 ]\n",
      "R: [0 0 0 0 0 0 1 0]\n",
      "max_r_index: 6\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.0004 -0.0004 -0.001  -0.0004 -0.0004 -0.001   0.     -0.001 ]\n",
      "R: [0 0 0 0 0 0 1 0]\n",
      "max_r_index: 6\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.0004 -0.0004 -0.001  -0.0004 -0.0004 -0.001   0.     -0.001 ]\n",
      "R: [0 0 0 0 0 0 1 0]\n",
      "max_r_index: 6\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.0004 -0.0004 -0.001  -0.0004 -0.0004 -0.001   0.     -0.001 ]\n",
      "R: [0 0 0 0 0 0 1 0]\n",
      "max_r_index: 6\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.0004 -0.0004 -0.001  -0.0004 -0.0004 -0.001   0.     -0.001 ]\n",
      "R: [0 0 0 0 0 0 1 0]\n",
      "max_r_index: 6\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.0004 -0.0004 -0.001  -0.0004 -0.0004 -0.001   0.     -0.001 ]\n",
      "R: [0 0 0 0 0 0 1 0]\n",
      "max_r_index: 6\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.0004 -0.0004 -0.001  -0.0004 -0.0004 -0.001   0.     -0.001 ]\n",
      "R: [0 0 0 0 0 0 1 0]\n",
      "max_r_index: 6\n",
      "\n",
      "\n",
      "\n",
      "tau: [-0.0004 -0.0004 -0.001  -0.0004 -0.0004 -0.001   0.     -0.001 ]\n",
      "R: [0 0 0 0 0 0 1 0]\n",
      "max_r_index: 6\n",
      "\n",
      "\n",
      "\n",
      "All train fold profits:\n",
      "       baseline            S1            S2           S12   S15   S16  \\\n",
      "0  1.396090e+06  1.409222e+06  1.417773e+06  1.415376e+06  None  None   \n",
      "1  1.407958e+06  1.400510e+06  1.412611e+06  1.413255e+06  None  None   \n",
      "2  1.410063e+06  1.414303e+06  1.434546e+06  1.435688e+06  None  None   \n",
      "\n",
      "            S14  \n",
      "0  1.439797e+06  \n",
      "1  1.437315e+06  \n",
      "2  1.450669e+06  \n",
      "All test fold profits:\n",
      "        baseline             S1             S2            S12   S15   S16  \\\n",
      "0  256634.125790  645977.668330  467584.528253  468192.791809  None  None   \n",
      "1  339886.655088  688843.964069  513391.997473  512620.021676  None  None   \n",
      "2  306678.614166  666699.097555  524485.487585  528566.655914  None  None   \n",
      "\n",
      "             S14  \n",
      "0  734065.723733  \n",
      "1  782042.904370  \n",
      "2  769227.165077  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_65248/2788820283.py:74: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_65248/565741137.py:107: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_65248/904923607.py:90: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n"
     ]
    }
   ],
   "source": [
    "train_all_fold_profits = []\n",
    "train_all_fold_stimulation_results = []\n",
    "test_all_fold_profits = []\n",
    "test_all_fold_stimulation_results = []\n",
    "beta_records = {\"S12\": [], \"S15\": [], \"S16\": []}\n",
    "\n",
    "# 迴圈遍歷所有 fold\n",
    "for fold_idx in range(len(training_data_folds)):\n",
    "    print(f\"===== Processing Fold {fold_idx + 1} =====\")\n",
    "    # 取出該 fold 的訓練資料與需求資料\n",
    "    training_df, testing_df = training_data_folds[fold_idx]\n",
    "    demand_df_train, demand_df_test = demand_folds[fold_idx]\n",
    "\n",
    "    Q_star = calculate_Q_star(demand_df_train, service_level=service_lv)\n",
    "    print(f\"Fold {fold_idx + 1} Q_star: {Q_star}\")\n",
    "\n",
    "    # ====訓練階段====\n",
    "\n",
    "    mu_matrix, covariance_matrix = cal_mu_and_cov_matrix(demand_df_train)\n",
    "    Qk_hat_df_train = make_Qk_hat_df(\n",
    "        demand_df_train, T, service_lv, mu_matrix, covariance_matrix\n",
    "    )\n",
    "    training_profits, training_results, training_stimulation_results = (\n",
    "        perform_fold_training(training_df, demand_df_train, Qk_hat_df_train, Q_star)\n",
    "    )\n",
    "    train_all_fold_profits.append(training_profits)\n",
    "    train_all_fold_stimulation_results.append(training_stimulation_results)\n",
    "\n",
    "    if training_results[\"S12\"] is not None:\n",
    "        beta_records[\"S12\"].append(training_results[\"S12\"].iloc[0][\"beta_values\"])\n",
    "    else:\n",
    "        beta_records[\"S12\"].append(None)\n",
    "\n",
    "    if training_results[\"S15\"] is not None:\n",
    "        beta_records[\"S15\"].append(training_results[\"S15\"].iloc[0][\"beta_values\"])\n",
    "    else:\n",
    "        beta_records[\"S15\"].append(None)\n",
    "\n",
    "    if training_results[\"S16\"] is not None:\n",
    "        beta_records[\"S16\"].append(training_results[\"S16\"].iloc[0][\"beta_values\"])\n",
    "    else:\n",
    "        beta_records[\"S16\"].append(None)\n",
    "\n",
    "    # ====測試階段====\n",
    "    print(f\"Fold {fold_idx + 1} Q_star: {Q_star}\")\n",
    "\n",
    "    mu_matrix, covariance_matrix = cal_mu_and_cov_matrix(demand_df_test)\n",
    "    Qk_hat_df_test = make_Qk_hat_df(\n",
    "        demand_df_test, T, service_lv, mu_matrix, covariance_matrix\n",
    "    )\n",
    "    testing_profits, testing_stimulation_results = perform_fold_testing(\n",
    "        training_results[\"S1\"],\n",
    "        training_results[\"S2\"],\n",
    "        training_results[\"S12\"],\n",
    "        training_results[\"S15\"],\n",
    "        training_results[\"S16\"],\n",
    "        demand_df_test,\n",
    "        Qk_hat_df_test,\n",
    "        Q_star,\n",
    "        testing_df,\n",
    "    )\n",
    "\n",
    "    test_all_fold_profits.append(testing_profits)\n",
    "    test_all_fold_stimulation_results.append(testing_stimulation_results)\n",
    "\n",
    "\n",
    "# 將所有 fold 的結果轉換為 DataFrame 便於檢查與保存\n",
    "train_all_fold_profit_df = pd.DataFrame(train_all_fold_profits)\n",
    "print(\"All train fold profits:\")\n",
    "print(train_all_fold_profit_df)\n",
    "\n",
    "test_all_fold_profit_df = pd.DataFrame(test_all_fold_profits)\n",
    "print(\"All test fold profits:\")\n",
    "print(test_all_fold_profit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S12</th>\n",
       "      <th>S15</th>\n",
       "      <th>S16</th>\n",
       "      <th>S14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.396090e+06</td>\n",
       "      <td>1.409222e+06</td>\n",
       "      <td>1.417773e+06</td>\n",
       "      <td>1.415376e+06</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.439797e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.407958e+06</td>\n",
       "      <td>1.400510e+06</td>\n",
       "      <td>1.412611e+06</td>\n",
       "      <td>1.413255e+06</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.437315e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.410063e+06</td>\n",
       "      <td>1.414303e+06</td>\n",
       "      <td>1.434546e+06</td>\n",
       "      <td>1.435688e+06</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.450669e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       baseline            S1            S2           S12   S15   S16  \\\n",
       "0  1.396090e+06  1.409222e+06  1.417773e+06  1.415376e+06  None  None   \n",
       "1  1.407958e+06  1.400510e+06  1.412611e+06  1.413255e+06  None  None   \n",
       "2  1.410063e+06  1.414303e+06  1.434546e+06  1.435688e+06  None  None   \n",
       "\n",
       "            S14  \n",
       "0  1.439797e+06  \n",
       "1  1.437315e+06  \n",
       "2  1.450669e+06  "
      ]
     },
     "execution_count": 1553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all_fold_profit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S12</th>\n",
       "      <th>S15</th>\n",
       "      <th>S16</th>\n",
       "      <th>S14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>256634.125790</td>\n",
       "      <td>645977.668330</td>\n",
       "      <td>467584.528253</td>\n",
       "      <td>468192.791809</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>734065.723733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>339886.655088</td>\n",
       "      <td>688843.964069</td>\n",
       "      <td>513391.997473</td>\n",
       "      <td>512620.021676</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>782042.904370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>306678.614166</td>\n",
       "      <td>666699.097555</td>\n",
       "      <td>524485.487585</td>\n",
       "      <td>528566.655914</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>769227.165077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        baseline             S1             S2            S12   S15   S16  \\\n",
       "0  256634.125790  645977.668330  467584.528253  468192.791809  None  None   \n",
       "1  339886.655088  688843.964069  513391.997473  512620.021676  None  None   \n",
       "2  306678.614166  666699.097555  524485.487585  528566.655914  None  None   \n",
       "\n",
       "             S14  \n",
       "0  734065.723733  \n",
       "1  782042.904370  \n",
       "2  769227.165077  "
      ]
     },
     "execution_count": 1554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_all_fold_profit_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x900 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# train_all_fold_profit_df = train_all_fold_profit_df.drop(columns=[\"S12\", \"S15\", \"S16\"])\n",
    "# test_all_fold_profit_df = test_all_fold_profit_df.drop(columns=[\"S12\", \"S15\", \"S16\"])\n",
    "\n",
    "train_all_fold_profit_df = train_all_fold_profit_df.drop(columns=[\"S15\", \"S16\"])\n",
    "test_all_fold_profit_df = test_all_fold_profit_df.drop(columns=[\"S15\", \"S16\"])\n",
    "\n",
    "# 1️⃣ 計算平均 profit\n",
    "train_means = train_all_fold_profit_df.mean()\n",
    "test_means = test_all_fold_profit_df.mean()\n",
    "\n",
    "# 2️⃣ 定義 baseline & theory best\n",
    "baseline_train = train_means[\"baseline\"]\n",
    "baseline_test = test_means[\"baseline\"]\n",
    "theory_best_train = train_means[\"S14\"]\n",
    "theory_best_test = test_means[\"S14\"]\n",
    "\n",
    "# 3️⃣ 計算百分比變化：baseline & theory\n",
    "train_pct_base = (train_means - baseline_train) / baseline_train * 100\n",
    "test_pct_base = (test_means - baseline_test) / baseline_test * 100\n",
    "train_pct_theory = (train_means - theory_best_train) / theory_best_train * 100\n",
    "test_pct_theory = (test_means - theory_best_test) / theory_best_test * 100\n",
    "\n",
    "# 4️⃣ 建 DataFrame\n",
    "avg_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Method\": train_means.index,\n",
    "        \"Train\": train_means.values,\n",
    "        \"Test\": test_means.values,\n",
    "        \"Train_%_Base\": train_pct_base.values,\n",
    "        \"Test_%_Base\": test_pct_base.values,\n",
    "        \"Train_%_Theory\": train_pct_theory.values,\n",
    "        \"Test_%_Theory\": test_pct_theory.values,\n",
    "    }\n",
    ")\n",
    "\n",
    "avg_df_melted = avg_df.melt(\n",
    "    id_vars=[\n",
    "        \"Method\",\n",
    "        \"Train_%_Base\",\n",
    "        \"Test_%_Base\",\n",
    "        \"Train_%_Theory\",\n",
    "        \"Test_%_Theory\",\n",
    "    ],\n",
    "    value_vars=[\"Train\", \"Test\"],\n",
    "    var_name=\"Dataset\",\n",
    "    value_name=\"Average Profit\",\n",
    ")\n",
    "\n",
    "# 5️⃣ 畫圖\n",
    "plt.figure(figsize=(15, 9))\n",
    "ax = sns.barplot(x=\"Method\", y=\"Average Profit\", hue=\"Dataset\", data=avg_df_melted)\n",
    "\n",
    "# 6️⃣ 標註：baseline (%) 在第一行、theory (%) 括號內第二行\n",
    "for patch, (method, ds) in zip(\n",
    "    ax.patches, zip(avg_df_melted[\"Method\"], avg_df_melted[\"Dataset\"])\n",
    "):\n",
    "    if ds == \"Train\":\n",
    "        pct_base = avg_df.loc[avg_df.Method == method, \"Train_%_Base\"].values[0]\n",
    "        pct_theory = avg_df.loc[avg_df.Method == method, \"Train_%_Theory\"].values[0]\n",
    "    else:\n",
    "        pct_base = avg_df.loc[avg_df.Method == method, \"Test_%_Base\"].values[0]\n",
    "        pct_theory = avg_df.loc[avg_df.Method == method, \"Test_%_Theory\"].values[0]\n",
    "\n",
    "    ax.annotate(\n",
    "        f\"{pct_base:.1f}%\\n({pct_theory:.1f}%)\",\n",
    "        (patch.get_x() + patch.get_width() / 2, patch.get_height()),\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=9,\n",
    "        xytext=(0, 5),\n",
    "        textcoords=\"offset points\",\n",
    "    )\n",
    "\n",
    "plt.title(\"Average Profit (Train vs Test) — % Change vs Baseline / Theory Best\")\n",
    "plt.ylabel(\"Average Profit\")\n",
    "plt.xlabel(\"Method\")\n",
    "plt.xticks(rotation=30)\n",
    "plt.legend(title=\"Dataset\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 計算 baseline（訓練與測試）\n",
    "baseline_train = train_all_fold_profit_df[\"baseline\"].to_numpy().reshape(-1, 1)\n",
    "baseline_test = test_all_fold_profit_df[\"baseline\"].to_numpy().reshape(-1, 1)\n",
    "\n",
    "# # 計算百分比變化\n",
    "# train_relative = (\n",
    "#     (train_all_fold_profit_df.to_numpy() - baseline_train) / baseline_train * 100\n",
    "# )\n",
    "# test_relative = (\n",
    "#     (test_all_fold_profit_df.to_numpy() - baseline_test) / baseline_test * 100\n",
    "# )\n",
    "\n",
    "train_relative = (\n",
    "    (train_all_fold_profit_df.to_numpy() - baseline_train)\n",
    "    / np.abs(baseline_train)\n",
    "    * 100\n",
    ")\n",
    "test_relative = (\n",
    "    (test_all_fold_profit_df.to_numpy() - baseline_test) / np.abs(baseline_test) * 100\n",
    ")\n",
    "\n",
    "# 轉回 DataFrame，並保留 column names\n",
    "train_relative = pd.DataFrame(\n",
    "    train_relative,\n",
    "    columns=train_all_fold_profit_df.columns,\n",
    "    index=train_all_fold_profit_df.index,\n",
    ")\n",
    "test_relative = pd.DataFrame(\n",
    "    test_relative,\n",
    "    columns=test_all_fold_profit_df.columns,\n",
    "    index=test_all_fold_profit_df.index,\n",
    ")\n",
    "\n",
    "# 加入 fold 編號\n",
    "train_relative[\"Fold\"] = train_relative.index + 1\n",
    "test_relative[\"Fold\"] = test_relative.index + 1\n",
    "\n",
    "# 轉換成長格式\n",
    "train_long = train_relative.melt(\n",
    "    id_vars=\"Fold\", var_name=\"Method\", value_name=\"Relative Profit (%)\"\n",
    ")\n",
    "train_long[\"Dataset\"] = \"Train\"\n",
    "\n",
    "test_long = test_relative.melt(\n",
    "    id_vars=\"Fold\", var_name=\"Method\", value_name=\"Relative Profit (%)\"\n",
    ")\n",
    "test_long[\"Dataset\"] = \"Test\"\n",
    "\n",
    "# 合併數據\n",
    "fold_long = pd.concat([train_long, test_long], axis=0)\n",
    "\n",
    "# # === 1. 使用線圖 (Line Plot) 觀察不同 Fold 上的變化趨勢 ===\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.lineplot(\n",
    "#     data=fold_long,\n",
    "#     x=\"Fold\",\n",
    "#     y=\"Relative Profit (%)\",\n",
    "#     hue=\"Method\",\n",
    "#     style=\"Dataset\",\n",
    "#     markers=True,\n",
    "#     dashes=False,\n",
    "# )\n",
    "# plt.axhline(0, color=\"gray\", linestyle=\"--\", linewidth=1)  # 基準線\n",
    "# plt.title(\"Strategy Performance Across Folds (Relative to Baseline)\")\n",
    "# plt.legend(title=\"Method & Dataset\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "# plt.show()\n",
    "\n",
    "# # === 2. 使用箱型圖 (Box Plot) 查看策略穩定性 ===\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.boxplot(data=fold_long, x=\"Method\", y=\"Relative Profit (%)\", hue=\"Dataset\")\n",
    "# plt.axhline(0, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "# plt.title(\"Strategy Performance Distribution Across Folds\")\n",
    "# plt.xticks(rotation=30)\n",
    "# plt.legend(title=\"Dataset\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "# plt.show()\n",
    "\n",
    "# 3️⃣ Heatmap：同時顯示 vs Baseline & vs Theory Best（每 Fold 的 S14）\n",
    "theory_best_train = train_all_fold_profit_df[\"S14\"].to_numpy().reshape(-1, 1)\n",
    "theory_best_test = test_all_fold_profit_df[\"S14\"].to_numpy().reshape(-1, 1)\n",
    "\n",
    "# vs Theory (%) 計算\n",
    "# train_theory_rel = (\n",
    "#     (train_all_fold_profit_df.to_numpy() - theory_best_train) / theory_best_train * 100\n",
    "# )\n",
    "# test_theory_rel = (\n",
    "#     (test_all_fold_profit_df.to_numpy() - theory_best_test) / theory_best_test * 100\n",
    "# )\n",
    "train_theory_rel = (\n",
    "    (train_all_fold_profit_df.to_numpy() - theory_best_train)\n",
    "    / np.abs(theory_best_train)\n",
    "    * 100\n",
    ")\n",
    "test_theory_rel = (\n",
    "    (test_all_fold_profit_df.to_numpy() - theory_best_test)\n",
    "    / np.abs(theory_best_test)\n",
    "    * 100\n",
    ")\n",
    "\n",
    "# 回 DataFrame 並 melt\n",
    "train_theory_rel = pd.DataFrame(\n",
    "    train_theory_rel,\n",
    "    columns=train_all_fold_profit_df.columns,\n",
    "    index=train_all_fold_profit_df.index,\n",
    ")\n",
    "train_theory_rel[\"Fold\"] = train_theory_rel.index + 1\n",
    "train_theory_long = train_theory_rel.melt(\n",
    "    id_vars=\"Fold\", var_name=\"Method\", value_name=\"Relative vs Theory (%)\"\n",
    ")\n",
    "train_theory_long[\"Dataset\"] = \"Train\"\n",
    "\n",
    "test_theory_rel = pd.DataFrame(\n",
    "    test_theory_rel,\n",
    "    columns=test_all_fold_profit_df.columns,\n",
    "    index=test_all_fold_profit_df.index,\n",
    ")\n",
    "test_theory_rel[\"Fold\"] = test_theory_rel.index + 1\n",
    "test_theory_long = test_theory_rel.melt(\n",
    "    id_vars=\"Fold\", var_name=\"Method\", value_name=\"Relative vs Theory (%)\"\n",
    ")\n",
    "test_theory_long[\"Dataset\"] = \"Test\"\n",
    "\n",
    "# 合併 baseline (%) 與 theory (%) 資料\n",
    "merged = fold_long.merge(\n",
    "    pd.concat([train_theory_long, test_theory_long], axis=0),\n",
    "    on=[\"Fold\", \"Method\", \"Dataset\"],\n",
    ")\n",
    "\n",
    "# Pivot heatmap values + annotations\n",
    "heatmap_data = merged.pivot(\n",
    "    index=\"Fold\", columns=[\"Method\", \"Dataset\"], values=\"Relative Profit (%)\"\n",
    ")\n",
    "annot = merged.assign(\n",
    "    annot=merged[\"Relative Profit (%)\"].round(1).astype(str)\n",
    "    + \"\\n(\"\n",
    "    + merged[\"Relative vs Theory (%)\"].round(1).astype(str)\n",
    "    + \"%)\"\n",
    ").pivot(index=\"Fold\", columns=[\"Method\", \"Dataset\"], values=\"annot\")\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.heatmap(heatmap_data, annot=annot, fmt=\"\", cmap=\"coolwarm\", linewidths=0.5)\n",
    "plt.title(\"Relative Profit (%) Across Folds\\n(vs Baseline / (vs Theory Best))\")\n",
    "plt.ylabel(\"Fold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved as plots/plot_strategies_profits_scatter_train_med_with_holding_cost_0.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 訓練階段分佈\n",
    "\n",
    "baseline_data = []\n",
    "S1_data = []\n",
    "S2_data = []\n",
    "S12_data = []\n",
    "S14_data = []\n",
    "S15_data = []\n",
    "\n",
    "for result in train_all_fold_stimulation_results:\n",
    "    baseline_data.append(result[\"baseline\"])\n",
    "    S1_data.append(result[\"S1\"])\n",
    "    S2_data.append(result[\"S2\"])\n",
    "    # S12_data.append(result[\"S12\"])\n",
    "    # S14_data.append(result[\"S14\"])\n",
    "    # S15_data.append(result[\"S15\"])\n",
    "\n",
    "# 合併數據\n",
    "baseline_df = pd.concat(baseline_data, ignore_index=True)\n",
    "S1_df = pd.concat(S1_data, ignore_index=True)\n",
    "S2_df = pd.concat(S2_data, ignore_index=True)\n",
    "# S12_df = pd.concat(S12_data, ignore_index=True)\n",
    "# S14_df = pd.concat(S14_data, ignore_index=True)\n",
    "# S15_df = pd.concat(S15_data, ignore_index=True)\n",
    "\n",
    "\n",
    "dfs = {\n",
    "    \"baseline\": baseline_df,\n",
    "    \"S1\": S1_df,\n",
    "    \"S2\": S2_df,\n",
    "    # \"S12\": S12_df,\n",
    "    # \"S15\": S15_df,\n",
    "    # \"S14\": S14_df,\n",
    "}\n",
    "\n",
    "# 調用繪圖函數\n",
    "plot_strategies_profits_scatter(f\"{status}_{model_prefix}\", dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved as plots/plot_strategies_profits_scatter_train_med_with_holding_cost_0.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 測試結果分布圖\n",
    "\n",
    "baseline_data = []\n",
    "S1_data = []\n",
    "S2_data = []\n",
    "S12_data = []\n",
    "S14_data = []\n",
    "S15_data = []\n",
    "\n",
    "for result in test_all_fold_stimulation_results:\n",
    "    baseline_data.append(result[\"baseline\"])\n",
    "    S1_data.append(result[\"S1\"])\n",
    "    S2_data.append(result[\"S2\"])\n",
    "    # S12_data.append(result[\"S12\"])\n",
    "    # S14_data.append(result[\"S14\"])\n",
    "    # S15_data.append(result[\"S15\"])\n",
    "# 合併數據\n",
    "baseline_df = pd.concat(baseline_data, ignore_index=True)\n",
    "S1_df = pd.concat(S1_data, ignore_index=True)\n",
    "S2_df = pd.concat(S2_data, ignore_index=True)\n",
    "# S12_df = pd.concat(S12_data, ignore_index=True)\n",
    "# S14_df = pd.concat(S14_data, ignore_index=True)\n",
    "# S15_df = pd.concat(S15_data, ignore_index=True)\n",
    "\n",
    "dfs = {\n",
    "    \"baseline\": baseline_df,\n",
    "    \"S1\": S1_df,\n",
    "    \"S2\": S2_df,\n",
    "    # \"S12\": S12_df,\n",
    "    # \"S15\": S15_df,\n",
    "    # \"S14\": S14_df,\n",
    "}\n",
    "\n",
    "# 調用繪圖函數\n",
    "plot_strategies_profits_scatter(f\"{status}_{model_prefix}\", dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1559,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ast\n",
    "\n",
    "# summary_df = pd.read_csv(\n",
    "#     \"/Users/hanyuan/Github/Two-Phase-Newsvendor/results/summary.csv\"\n",
    "# )\n",
    "\n",
    "# records_str = summary_df.loc[0, \"train_df\"]\n",
    "# records = ast.literal_eval(records_str)\n",
    "\n",
    "# df_reconstructed = pd.DataFrame(records)\n",
    "# df_reconstructed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Processing Fold 1 =====\n",
      "training_df: \n",
      "       X1   X2        X3\n",
      "0   250.0  0.0  7.097627\n",
      "1   250.0  0.0  7.430379\n",
      "2   250.0  0.0  7.205527\n",
      "3   250.0  0.0  7.089766\n",
      "4   250.0  0.0  6.847310\n",
      "5   250.0  0.0  7.291788\n",
      "6   250.0  0.0  6.875174\n",
      "7   250.0  0.0  7.783546\n",
      "8   250.0  0.0  7.927326\n",
      "9   250.0  0.0  6.766883\n",
      "10  250.0  0.0  7.583450\n",
      "11  250.0  0.0  7.057790\n",
      "12  250.0  0.0  7.136089\n",
      "13  250.0  0.0  7.851193\n",
      "14  250.0  0.0  6.142072\n",
      "demand_df_train: \n",
      "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
      "0   216.269540  211.134274  215.128316  217.994763  229.527662  228.343740   \n",
      "1   213.412362  212.203824  210.885199  212.928863  214.608230  221.012875   \n",
      "2   204.681787  207.336518  210.952538  203.368635  201.143341  212.945396   \n",
      "3   198.383496  200.987261  197.538109  202.580936  202.908901  212.987482   \n",
      "4   219.811740  215.888884  220.591784  218.304163  224.051815  230.563012   \n",
      "5   220.360046  221.653541  221.084469  221.365066  219.588375  230.349881   \n",
      "6   206.804647  210.281255  211.971112  211.899313  212.103444  223.938525   \n",
      "7   197.500672  202.217054  202.132739  203.477299  205.711701  209.558780   \n",
      "8   204.862165  204.349647  204.410897  203.832857  198.517193  209.219411   \n",
      "9   214.729484  211.058905  213.111249  213.393977  216.269393  226.294654   \n",
      "10  203.536333  198.875464  199.443303  206.642554  213.162637  213.806483   \n",
      "11  211.399931  203.772432  204.362386  211.367124  219.630126  222.009609   \n",
      "12  200.333009  200.122945  201.407273  202.457942  209.620603  212.527752   \n",
      "13  215.485256  214.091043  212.898490  213.282515  211.999879  219.028557   \n",
      "14  223.772374  219.297995  227.067323  224.128681  227.334861  242.102041   \n",
      "\n",
      "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
      "0   242.806583  289.728142  294.085892  302.742662  \n",
      "1   232.696730  291.971737  299.898413  310.098635  \n",
      "2   217.246014  274.878251  284.616328  292.693517  \n",
      "3   223.541107  289.059699  300.204667  305.030320  \n",
      "4   282.302153  291.526875  302.196239  297.751466  \n",
      "5   239.096051  287.137346  298.313381  302.956429  \n",
      "6   279.861703  289.879410  300.275223  301.905500  \n",
      "7   218.989494  282.840421  291.370366  300.913051  \n",
      "8   213.080292  285.593964  296.148638  306.810950  \n",
      "9   277.908923  287.515460  293.452452  298.903205  \n",
      "10  226.483521  286.300518  295.724523  295.565024  \n",
      "11  239.661313  287.100126  295.098417  300.312782  \n",
      "12  224.286097  289.751327  295.640317  296.230690  \n",
      "13  226.998326  277.137760  290.303325  296.421243  \n",
      "14  285.157984  297.060136  300.922758  304.073340  \n",
      "testing_df: \n",
      "       X1   X2        X3\n",
      "0   100.0  1.0  2.174259\n",
      "1   100.0  1.0  2.040437\n",
      "2   100.0  1.0  3.665240\n",
      "3   100.0  1.0  3.556314\n",
      "4   100.0  1.0  3.740024\n",
      "5   100.0  1.0  3.957237\n",
      "6   100.0  1.0  3.598317\n",
      "7   100.0  1.0  2.922959\n",
      "8   100.0  1.0  3.561058\n",
      "9   100.0  1.0  2.236549\n",
      "10  100.0  1.0  3.279842\n",
      "11  100.0  1.0  2.286707\n",
      "12  100.0  1.0  3.889338\n",
      "13  100.0  1.0  3.043697\n",
      "14  100.0  1.0  2.829324\n",
      "demand_df_test: \n",
      "    demand_t1  demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
      "0   70.227917  81.121645  131.788409  141.803321  143.426979  147.673785   \n",
      "1   79.608727  91.639215  128.702757  135.028793  134.579449  140.268787   \n",
      "2   63.419471  70.874302   77.661979  132.558616  142.859878  148.998521   \n",
      "3   52.116936  63.450198   73.716363  123.035381  131.841477  138.583452   \n",
      "4   60.415934  67.035420   74.759950  125.505731  131.973688  142.549592   \n",
      "5   63.891435  69.705305   78.722662  124.306490  138.151168  143.032748   \n",
      "6   70.216180  78.598394   84.946904  121.995492  133.578784  137.888674   \n",
      "7   63.185446  71.742871  120.581034  130.522874  136.377091  141.022977   \n",
      "8   70.992077  75.616666   82.533829  125.466173  133.000874  141.053282   \n",
      "9   70.526757  84.725666  130.149324  137.570580  142.534312  143.754643   \n",
      "10  55.599240  61.360904   73.969731  125.839593  135.145787  139.117788   \n",
      "11  76.219043  89.003219  127.269401  135.126808  137.205275  141.572859   \n",
      "12  52.094021  62.108609   68.768801  123.756371  140.592759  141.971262   \n",
      "13  76.509810  77.459588   92.319729  128.061079  135.441582  139.470053   \n",
      "14  71.680424  85.624544  120.815521  130.085328  134.069275  139.907755   \n",
      "\n",
      "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
      "0   150.205352  144.538643  148.686424  152.970565  \n",
      "1   145.314588  142.865421  141.157079  144.668688  \n",
      "2   155.162599  155.783147  153.172861  154.443828  \n",
      "3   136.399301  138.619786  142.363281  140.167618  \n",
      "4   141.600813  144.825519  147.015787  148.199725  \n",
      "5   145.171105  149.727225  148.451307  149.989241  \n",
      "6   143.451611  143.435230  141.816459  143.709674  \n",
      "7   141.719665  141.606493  143.111705  139.494170  \n",
      "8   140.385933  143.311775  144.849568  141.009104  \n",
      "9   141.951848  142.737482  144.830817  144.223385  \n",
      "10  140.487488  143.253560  142.044079  141.546400  \n",
      "11  140.719360  140.781289  142.703000  138.273542  \n",
      "12  141.598922  153.777150  147.074707  142.399240  \n",
      "13  144.019581  140.131849  141.812887  142.555552  \n",
      "14  138.392343  148.279216  141.817695  142.604815  \n",
      "===== Processing Fold 2 =====\n",
      "training_df: \n",
      "       X1   X2        X3\n",
      "0   250.0  0.0  6.529111\n",
      "1   250.0  0.0  7.548467\n",
      "2   250.0  0.0  6.912301\n",
      "3   250.0  0.0  7.136868\n",
      "4   250.0  0.0  6.037580\n",
      "5   250.0  0.0  7.235271\n",
      "6   250.0  0.0  7.224191\n",
      "7   250.0  0.0  7.233868\n",
      "8   250.0  0.0  7.887496\n",
      "9   250.0  0.0  7.363641\n",
      "10  250.0  0.0  6.719016\n",
      "11  250.0  0.0  6.874064\n",
      "12  250.0  0.0  7.395262\n",
      "13  250.0  0.0  6.120451\n",
      "14  250.0  0.0  7.333533\n",
      "demand_df_train: \n",
      "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
      "0   222.161187  222.674769  225.353917  223.221310  222.893692  238.065400   \n",
      "1   220.530094  219.738950  218.759769  220.933432  220.124623  228.300609   \n",
      "2   213.362537  218.822792  216.870371  217.362713  219.563800  229.111736   \n",
      "3   199.797687  207.323601  203.789124  207.736732  210.971595  217.800933   \n",
      "4   201.639849  204.461900  204.373246  211.688475  219.980465  230.453114   \n",
      "5   203.068617  210.253707  211.044927  208.252652  210.515431  217.622674   \n",
      "6   200.028086  200.649557  201.110990  203.196222  208.172300  212.642934   \n",
      "7   209.370477  211.540854  211.088956  213.227575  217.505323  222.607287   \n",
      "8   212.532495  213.315555  214.680239  211.469208  208.301130  217.041472   \n",
      "9   207.618493  211.794800  208.888392  213.191496  215.856144  221.701392   \n",
      "10  207.056248  210.847827  208.026988  209.464407  214.390723  222.751866   \n",
      "11  206.903862  203.906252  207.385176  205.308491  204.528274  217.356427   \n",
      "12  206.768808  202.093273  201.684832  207.410315  211.014986  215.716571   \n",
      "13  211.774461  215.380556  214.549172  217.086505  225.127256  235.226440   \n",
      "14  216.725708  216.467046  218.712706  218.300728  222.101593  227.007575   \n",
      "\n",
      "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
      "0   280.312076  287.113818  295.476806  301.581639  \n",
      "1   239.480837  278.599581  292.608620  299.370778  \n",
      "2   264.688890  278.406242  285.268849  285.786165  \n",
      "3   231.228251  281.000002  285.687011  285.367038  \n",
      "4   279.671471  284.587074  289.916916  290.508358  \n",
      "5   225.661659  285.838794  290.975307  292.078159  \n",
      "6   225.213431  291.325190  296.608369  302.124771  \n",
      "7   231.530616  282.838947  288.006589  291.168008  \n",
      "8   222.363761  259.051539  279.508591  284.723369  \n",
      "9   231.422106  289.526303  300.437872  305.779847  \n",
      "10  280.193543  295.421032  298.712701  297.452760  \n",
      "11  277.360165  290.208239  298.996474  304.379612  \n",
      "12  228.428223  270.682926  285.297802  290.140345  \n",
      "13  272.923294  287.175093  287.743459  285.591008  \n",
      "14  233.518253  273.349587  282.149117  284.578008  \n",
      "testing_df: \n",
      "       X1   X2        X3\n",
      "0   100.0  1.0  3.341276\n",
      "1   100.0  1.0  2.420765\n",
      "2   100.0  1.0  2.257853\n",
      "3   100.0  1.0  2.630857\n",
      "4   100.0  1.0  2.727422\n",
      "5   100.0  1.0  3.140394\n",
      "6   100.0  1.0  2.877203\n",
      "7   100.0  1.0  3.976748\n",
      "8   100.0  1.0  2.204090\n",
      "9   100.0  1.0  2.417754\n",
      "10  100.0  1.0  2.322619\n",
      "11  100.0  1.0  3.306217\n",
      "12  100.0  1.0  2.506583\n",
      "13  100.0  1.0  2.932622\n",
      "14  100.0  1.0  2.488851\n",
      "demand_df_test: \n",
      "    demand_t1  demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
      "0   72.009341  74.997743   87.005613  128.348847  132.655500  142.127494   \n",
      "1   75.795766  83.482632  141.773017  150.698577  153.139419  157.886776   \n",
      "2   69.530409  78.997508  139.540892  144.071128  143.380065  150.365428   \n",
      "3   68.809892  78.215789  128.691086  141.307123  149.945005  149.781344   \n",
      "4   64.970365  70.317737  144.067324  148.114171  154.964918  157.228781   \n",
      "5   61.214051  71.651536   83.195967  142.057095  151.063978  154.218832   \n",
      "6   68.135098  77.074529  116.844346  133.674097  137.638788  143.839906   \n",
      "7   67.593216  71.811630   78.765094  123.220756  134.731523  142.090958   \n",
      "8   82.760314  98.611711  142.416633  144.507976  144.328414  150.527009   \n",
      "9   78.667055  87.035540  135.495516  145.326754  154.982092  152.497608   \n",
      "10  73.323629  85.298402  134.014373  142.154358  144.857784  148.793222   \n",
      "11  66.698211  76.821448   83.183982  136.220205  146.781319  149.712745   \n",
      "12  65.400532  74.729399  133.985731  142.957392  152.664942  150.652859   \n",
      "13  61.466612  68.275961  126.848571  133.236399  138.154667  143.807840   \n",
      "14  70.101169  80.342774  125.119997  136.763122  140.617546  144.351719   \n",
      "\n",
      "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
      "0   143.667318  146.757340  145.226417  146.246406  \n",
      "1   157.120115  160.255430  159.174422  154.083678  \n",
      "2   143.087074  150.143303  151.464211  150.393109  \n",
      "3   152.159759  146.176481  151.359503  156.142474  \n",
      "4   154.225794  161.729377  158.960790  160.413033  \n",
      "5   157.783124  159.201692  156.785961  157.766049  \n",
      "6   148.444796  141.058813  145.839363  148.821352  \n",
      "7   142.116537  141.833349  147.603113  144.935219  \n",
      "8   149.120515  152.715787  151.569603  151.212534  \n",
      "9   152.332204  154.227160  153.781491  150.241387  \n",
      "10  151.988611  153.420355  149.963613  149.547872  \n",
      "11  154.821903  153.684922  152.712027  154.495989  \n",
      "12  149.533798  153.490008  152.052310  148.127874  \n",
      "13  141.438731  141.799862  145.915902  141.017522  \n",
      "14  146.299292  144.897715  145.727324  147.517382  \n",
      "===== Processing Fold 3 =====\n",
      "training_df: \n",
      "       X1   X2        X3\n",
      "0   250.0  0.0  6.317939\n",
      "1   250.0  0.0  6.220750\n",
      "2   250.0  0.0  7.312659\n",
      "3   250.0  0.0  6.276366\n",
      "4   250.0  0.0  6.393165\n",
      "5   250.0  0.0  6.737450\n",
      "6   250.0  0.0  7.641986\n",
      "7   250.0  0.0  6.194203\n",
      "8   250.0  0.0  7.675890\n",
      "9   250.0  0.0  6.192197\n",
      "10  250.0  0.0  7.952919\n",
      "11  250.0  0.0  6.937302\n",
      "12  250.0  0.0  7.953522\n",
      "13  250.0  0.0  7.209691\n",
      "14  250.0  0.0  7.478527\n",
      "demand_df_train: \n",
      "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
      "0   216.647776  217.707632  217.106637  216.842714  219.597076  233.419212   \n",
      "1   206.392192  207.466613  209.843167  207.604607  213.000352  224.961254   \n",
      "2   208.757150  211.215125  210.251555  213.156271  218.505110  222.001409   \n",
      "3   211.765499  214.318603  215.414811  216.141472  219.949536  233.053752   \n",
      "4   212.809346  217.810872  213.306858  217.226836  220.572888  233.189850   \n",
      "5   215.874024  216.634876  219.161295  220.970899  229.078910  234.109029   \n",
      "6   208.663645  212.202013  212.214505  209.993864  212.365034  216.827046   \n",
      "7   214.795873  214.957004  218.508049  221.137495  226.253158  238.703949   \n",
      "8   204.887138  207.948928  204.303492  203.239600  207.493960  209.886562   \n",
      "9   213.251598  213.261233  212.440552  219.307496  221.331998  236.889734   \n",
      "10  208.525023  203.488282  205.712190  203.930813  203.325865  209.200737   \n",
      "11  205.089368  202.923453  206.838589  205.766863  206.676825  217.322137   \n",
      "12  200.903965  205.939596  203.960886  203.417689  204.627082  208.684890   \n",
      "13  213.954358  215.974160  219.545605  218.086512  222.010790  227.634165   \n",
      "14  208.134237  213.335557  212.206389  209.640137  210.502901  217.426165   \n",
      "\n",
      "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
      "0   281.223054  286.606612  295.373362  295.021682  \n",
      "1   275.069930  290.849170  293.042855  290.427386  \n",
      "2   233.240220  284.029835  294.011162  298.315636  \n",
      "3   285.949828  296.587134  299.984362  300.882037  \n",
      "4   283.261878  291.515898  295.193378  301.422180  \n",
      "5   272.091637  289.444930  292.637615  290.154113  \n",
      "6   222.394845  288.244280  297.610300  300.054982  \n",
      "7   283.869552  292.548952  301.227187  296.088081  \n",
      "8   219.793122  286.423417  297.882888  307.923009  \n",
      "9   296.471696  298.622569  307.131742  309.556117  \n",
      "10  211.768872  282.906452  294.373221  295.898815  \n",
      "11  276.893707  286.436047  296.672410  301.681387  \n",
      "12  216.679969  282.292518  293.965063  298.664190  \n",
      "13  232.487659  282.208998  294.230272  299.601931  \n",
      "14  223.577690  277.934792  282.421103  285.004960  \n",
      "testing_df: \n",
      "       X1   X2        X3\n",
      "0   100.0  1.0  2.078376\n",
      "1   100.0  1.0  2.565614\n",
      "2   100.0  1.0  2.240393\n",
      "3   100.0  1.0  2.592280\n",
      "4   100.0  1.0  2.237455\n",
      "5   100.0  1.0  2.635966\n",
      "6   100.0  1.0  2.828526\n",
      "7   100.0  1.0  2.128295\n",
      "8   100.0  1.0  3.384944\n",
      "9   100.0  1.0  3.133203\n",
      "10  100.0  1.0  2.530779\n",
      "11  100.0  1.0  3.046496\n",
      "12  100.0  1.0  2.187881\n",
      "13  100.0  1.0  3.151893\n",
      "14  100.0  1.0  3.858592\n",
      "demand_df_test: \n",
      "    demand_t1  demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
      "0   76.726007  85.292909  133.499628  142.686827  151.989907  148.099649   \n",
      "1   73.215452  84.322469  140.436462  147.706836  153.427440  155.765750   \n",
      "2   81.614354  93.288630  142.735808  149.774088  154.774819  155.977932   \n",
      "3   53.997127  65.378692  122.601776  137.369862  143.971341  145.596807   \n",
      "4   79.623523  88.635007  129.643968  136.108997  141.327015  142.297723   \n",
      "5   66.573648  73.473881  116.509127  130.907484  138.170199  139.414829   \n",
      "6   61.543065  69.925424  118.981441  128.541003  130.878560  138.357764   \n",
      "7   77.934606  89.308782  127.931099  137.811266  140.377104  143.458587   \n",
      "8   61.555771  65.481206   76.431186  141.016287  148.612409  155.152840   \n",
      "9   71.879524  75.816228   88.691319  125.840719  138.654339  137.945803   \n",
      "10  62.698196  78.611085  139.791254  143.076516  142.163674  150.919528   \n",
      "11  64.781553  72.263140   83.800937  130.848821  141.944226  142.279298   \n",
      "12  75.532997  88.519768  134.606680  145.260208  152.214092  151.198150   \n",
      "13  61.766267  71.418492   79.609229  136.806694  149.697938  149.059237   \n",
      "14  68.819794  74.071775   80.358485  123.003555  129.832291  140.982057   \n",
      "\n",
      "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
      "0   147.917016  153.114936  149.021591  145.097141  \n",
      "1   155.706461  157.681604  157.247505  159.518788  \n",
      "2   156.344506  152.764874  157.058150  156.135556  \n",
      "3   148.718305  148.766359  147.117258  151.321785  \n",
      "4   143.193646  140.258585  143.374846  140.789340  \n",
      "5   143.089660  141.209537  141.000788  144.971862  \n",
      "6   139.188552  143.200519  140.266246  142.386797  \n",
      "7   144.180047  142.103770  144.426712  143.175555  \n",
      "8   160.099228  158.393803  158.380157  160.635284  \n",
      "9   139.968061  144.014399  140.495582  140.628759  \n",
      "10  145.896928  149.493779  152.352166  146.679443  \n",
      "11  146.301937  144.274959  144.628356  146.560884  \n",
      "12  151.674544  151.286388  152.224362  152.695641  \n",
      "13  151.665693  152.244795  151.654347  150.452055  \n",
      "14  145.590577  148.889060  145.948128  145.404458  \n"
     ]
    }
   ],
   "source": [
    "for fold_idx in range(len(training_data_folds)):\n",
    "    print(f\"===== Processing Fold {fold_idx + 1} =====\")\n",
    "    # 取出該 fold 的訓練資料與需求資料\n",
    "    training_df, testing_df = training_data_folds[fold_idx]\n",
    "    demand_df_train, demand_df_test = demand_folds[fold_idx]\n",
    "\n",
    "    print(f\"training_df: \\n{training_df}\")\n",
    "    print(f\"demand_df_train: \\n{demand_df_train}\")\n",
    "    print(f\"testing_df: \\n{testing_df}\")\n",
    "    print(f\"demand_df_test: \\n{demand_df_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>216.647776</td>\n",
       "      <td>217.707632</td>\n",
       "      <td>217.106637</td>\n",
       "      <td>216.842714</td>\n",
       "      <td>219.597076</td>\n",
       "      <td>233.419212</td>\n",
       "      <td>281.223054</td>\n",
       "      <td>286.606612</td>\n",
       "      <td>295.373362</td>\n",
       "      <td>295.021682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>206.392192</td>\n",
       "      <td>207.466613</td>\n",
       "      <td>209.843167</td>\n",
       "      <td>207.604607</td>\n",
       "      <td>213.000352</td>\n",
       "      <td>224.961254</td>\n",
       "      <td>275.069930</td>\n",
       "      <td>290.849170</td>\n",
       "      <td>293.042855</td>\n",
       "      <td>290.427386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>208.757150</td>\n",
       "      <td>211.215125</td>\n",
       "      <td>210.251555</td>\n",
       "      <td>213.156271</td>\n",
       "      <td>218.505110</td>\n",
       "      <td>222.001409</td>\n",
       "      <td>233.240220</td>\n",
       "      <td>284.029835</td>\n",
       "      <td>294.011162</td>\n",
       "      <td>298.315636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211.765499</td>\n",
       "      <td>214.318603</td>\n",
       "      <td>215.414811</td>\n",
       "      <td>216.141472</td>\n",
       "      <td>219.949536</td>\n",
       "      <td>233.053752</td>\n",
       "      <td>285.949828</td>\n",
       "      <td>296.587134</td>\n",
       "      <td>299.984362</td>\n",
       "      <td>300.882037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>212.809346</td>\n",
       "      <td>217.810872</td>\n",
       "      <td>213.306858</td>\n",
       "      <td>217.226836</td>\n",
       "      <td>220.572888</td>\n",
       "      <td>233.189850</td>\n",
       "      <td>283.261878</td>\n",
       "      <td>291.515898</td>\n",
       "      <td>295.193378</td>\n",
       "      <td>301.422180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "0  216.647776  217.707632  217.106637  216.842714  219.597076  233.419212   \n",
       "1  206.392192  207.466613  209.843167  207.604607  213.000352  224.961254   \n",
       "2  208.757150  211.215125  210.251555  213.156271  218.505110  222.001409   \n",
       "3  211.765499  214.318603  215.414811  216.141472  219.949536  233.053752   \n",
       "4  212.809346  217.810872  213.306858  217.226836  220.572888  233.189850   \n",
       "\n",
       "    demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "0  281.223054  286.606612  295.373362  295.021682  \n",
       "1  275.069930  290.849170  293.042855  290.427386  \n",
       "2  233.240220  284.029835  294.011162  298.315636  \n",
       "3  285.949828  296.587134  299.984362  300.882037  \n",
       "4  283.261878  291.515898  295.193378  301.422180  "
      ]
     },
     "execution_count": 1561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76.726007</td>\n",
       "      <td>85.292909</td>\n",
       "      <td>133.499628</td>\n",
       "      <td>142.686827</td>\n",
       "      <td>151.989907</td>\n",
       "      <td>148.099649</td>\n",
       "      <td>147.917016</td>\n",
       "      <td>153.114936</td>\n",
       "      <td>149.021591</td>\n",
       "      <td>145.097141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73.215452</td>\n",
       "      <td>84.322469</td>\n",
       "      <td>140.436462</td>\n",
       "      <td>147.706836</td>\n",
       "      <td>153.427440</td>\n",
       "      <td>155.765750</td>\n",
       "      <td>155.706461</td>\n",
       "      <td>157.681604</td>\n",
       "      <td>157.247505</td>\n",
       "      <td>159.518788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.614354</td>\n",
       "      <td>93.288630</td>\n",
       "      <td>142.735808</td>\n",
       "      <td>149.774088</td>\n",
       "      <td>154.774819</td>\n",
       "      <td>155.977932</td>\n",
       "      <td>156.344506</td>\n",
       "      <td>152.764874</td>\n",
       "      <td>157.058150</td>\n",
       "      <td>156.135556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.997127</td>\n",
       "      <td>65.378692</td>\n",
       "      <td>122.601776</td>\n",
       "      <td>137.369862</td>\n",
       "      <td>143.971341</td>\n",
       "      <td>145.596807</td>\n",
       "      <td>148.718305</td>\n",
       "      <td>148.766359</td>\n",
       "      <td>147.117258</td>\n",
       "      <td>151.321785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.623523</td>\n",
       "      <td>88.635007</td>\n",
       "      <td>129.643968</td>\n",
       "      <td>136.108997</td>\n",
       "      <td>141.327015</td>\n",
       "      <td>142.297723</td>\n",
       "      <td>143.193646</td>\n",
       "      <td>140.258585</td>\n",
       "      <td>143.374846</td>\n",
       "      <td>140.789340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   demand_t1  demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "0  76.726007  85.292909  133.499628  142.686827  151.989907  148.099649   \n",
       "1  73.215452  84.322469  140.436462  147.706836  153.427440  155.765750   \n",
       "2  81.614354  93.288630  142.735808  149.774088  154.774819  155.977932   \n",
       "3  53.997127  65.378692  122.601776  137.369862  143.971341  145.596807   \n",
       "4  79.623523  88.635007  129.643968  136.108997  141.327015  142.297723   \n",
       "\n",
       "    demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "0  147.917016  153.114936  149.021591  145.097141  \n",
       "1  155.706461  157.681604  157.247505  159.518788  \n",
       "2  156.344506  152.764874  157.058150  156.135556  \n",
       "3  148.718305  148.766359  147.117258  151.321785  \n",
       "4  143.193646  140.258585  143.374846  140.789340  "
      ]
     },
     "execution_count": 1562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Qk_hat_k2</th>\n",
       "      <th>Qk_hat_k3</th>\n",
       "      <th>Qk_hat_k4</th>\n",
       "      <th>Qk_hat_k5</th>\n",
       "      <th>Qk_hat_k6</th>\n",
       "      <th>Qk_hat_k7</th>\n",
       "      <th>Qk_hat_k8</th>\n",
       "      <th>Qk_hat_k9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1327.556091</td>\n",
       "      <td>1313.863760</td>\n",
       "      <td>1323.753555</td>\n",
       "      <td>1341.450027</td>\n",
       "      <td>1340.901501</td>\n",
       "      <td>1336.798594</td>\n",
       "      <td>1333.242991</td>\n",
       "      <td>1335.642211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1313.069378</td>\n",
       "      <td>1328.628503</td>\n",
       "      <td>1336.626359</td>\n",
       "      <td>1370.181494</td>\n",
       "      <td>1370.067265</td>\n",
       "      <td>1384.047741</td>\n",
       "      <td>1383.690384</td>\n",
       "      <td>1383.490833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1347.728425</td>\n",
       "      <td>1365.324931</td>\n",
       "      <td>1365.503153</td>\n",
       "      <td>1396.960416</td>\n",
       "      <td>1397.087606</td>\n",
       "      <td>1401.439730</td>\n",
       "      <td>1402.952999</td>\n",
       "      <td>1401.211673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1233.762716</td>\n",
       "      <td>1261.705212</td>\n",
       "      <td>1271.919590</td>\n",
       "      <td>1264.597860</td>\n",
       "      <td>1264.105834</td>\n",
       "      <td>1262.319750</td>\n",
       "      <td>1265.939404</td>\n",
       "      <td>1266.018576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1339.513031</td>\n",
       "      <td>1329.221297</td>\n",
       "      <td>1331.942771</td>\n",
       "      <td>1298.853685</td>\n",
       "      <td>1298.985543</td>\n",
       "      <td>1289.184434</td>\n",
       "      <td>1289.069098</td>\n",
       "      <td>1287.215295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Qk_hat_k2    Qk_hat_k3    Qk_hat_k4    Qk_hat_k5    Qk_hat_k6  \\\n",
       "0  1327.556091  1313.863760  1323.753555  1341.450027  1340.901501   \n",
       "1  1313.069378  1328.628503  1336.626359  1370.181494  1370.067265   \n",
       "2  1347.728425  1365.324931  1365.503153  1396.960416  1397.087606   \n",
       "3  1233.762716  1261.705212  1271.919590  1264.597860  1264.105834   \n",
       "4  1339.513031  1329.221297  1331.942771  1298.853685  1298.985543   \n",
       "\n",
       "     Qk_hat_k7    Qk_hat_k8    Qk_hat_k9  \n",
       "0  1336.798594  1333.242991  1335.642211  \n",
       "1  1384.047741  1383.690384  1383.490833  \n",
       "2  1401.439730  1402.952999  1401.211673  \n",
       "3  1262.319750  1265.939404  1266.018576  \n",
       "4  1289.184434  1289.069098  1287.215295  "
      ]
     },
     "execution_count": 1563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_matrix, covariance_matrix = cal_mu_and_cov_matrix(demand_df_test)\n",
    "Qk_hat_df_test = make_Qk_hat_df(\n",
    "    demand_df_test, T, service_lv, mu_matrix, covariance_matrix\n",
    ")\n",
    "Qk_hat_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1564,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2439.950183572415)"
      ]
     },
     "execution_count": 1564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2439.950183572415)"
      ]
     },
     "execution_count": 1565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R(T)</th>\n",
       "      <th>F</th>\n",
       "      <th>Q0</th>\n",
       "      <th>Q1</th>\n",
       "      <th>average_profits</th>\n",
       "      <th>average_losses</th>\n",
       "      <th>average_lefts</th>\n",
       "      <th>average_operation_profits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[243.99501835724152, 243.99501835724152, 243.9...</td>\n",
       "      <td>[2269.95107075639, 2144.5231165888654, 2173.44...</td>\n",
       "      <td>1.414303e+06</td>\n",
       "      <td>13.041585</td>\n",
       "      <td>58.057253</td>\n",
       "      <td>1.445351e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[487.99003671448304, 487.99003671448304, 487.9...</td>\n",
       "      <td>[2025.9372217432917, 1899.407887152837, 1930.2...</td>\n",
       "      <td>1.400996e+06</td>\n",
       "      <td>13.287333</td>\n",
       "      <td>90.587270</td>\n",
       "      <td>1.445203e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>[1951.9601468579322, 1951.9601468579322, 1951....</td>\n",
       "      <td>[523.4497811581105, 471.9663895204849, 442.392...</td>\n",
       "      <td>1.400309e+06</td>\n",
       "      <td>1.703915</td>\n",
       "      <td>127.054584</td>\n",
       "      <td>1.452153e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>[731.9850550717246, 731.9850550717246, 731.985...</td>\n",
       "      <td>[1780.5736633861006, 1656.8543342108806, 1685....</td>\n",
       "      <td>1.388309e+06</td>\n",
       "      <td>13.233072</td>\n",
       "      <td>122.467215</td>\n",
       "      <td>1.445236e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[975.9800734289661, 975.9800734289661, 975.980...</td>\n",
       "      <td>[1483.59642709431, 1402.3642031024478, 1473.13...</td>\n",
       "      <td>1.383626e+06</td>\n",
       "      <td>9.090525</td>\n",
       "      <td>146.603148</td>\n",
       "      <td>1.447721e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[487.99003671448304, 487.99003671448304, 487.9...</td>\n",
       "      <td>[1997.5575478142553, 1939.2001775168476, 1918....</td>\n",
       "      <td>-2.318004e+05</td>\n",
       "      <td>1052.429165</td>\n",
       "      <td>1055.152815</td>\n",
       "      <td>8.217182e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>[731.9850550717246, 731.9850550717246, 731.985...</td>\n",
       "      <td>[1743.424872944318, 1691.9414813066924, 1662.3...</td>\n",
       "      <td>-3.013963e+05</td>\n",
       "      <td>1096.210920</td>\n",
       "      <td>1097.797418</td>\n",
       "      <td>7.954492e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[243.99501835724152, 243.99501835724152, 243.9...</td>\n",
       "      <td>[2241.552566171497, 2183.195195874089, 2162.47...</td>\n",
       "      <td>-6.221924e+05</td>\n",
       "      <td>1296.424183</td>\n",
       "      <td>1299.147833</td>\n",
       "      <td>6.753212e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[487.99003671448304, 487.99003671448304, 487.9...</td>\n",
       "      <td>[1987.4198913015596, 1935.936499663934, 1906.3...</td>\n",
       "      <td>-6.917884e+05</td>\n",
       "      <td>1340.205939</td>\n",
       "      <td>1341.792436</td>\n",
       "      <td>6.490522e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[243.99501835724152, 243.99501835724152, 243.9...</td>\n",
       "      <td>[2231.414909658801, 2179.9315180211756, 2150.3...</td>\n",
       "      <td>-1.082180e+06</td>\n",
       "      <td>1584.200957</td>\n",
       "      <td>1585.787454</td>\n",
       "      <td>5.026551e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    R(T)    F                                                 Q0  \\\n",
       "0      2  0.1  [243.99501835724152, 243.99501835724152, 243.9...   \n",
       "10     3  0.2  [487.99003671448304, 487.99003671448304, 487.9...   \n",
       "70     9  0.8  [1951.9601468579322, 1951.9601468579322, 1951....   \n",
       "20     4  0.3  [731.9850550717246, 731.9850550717246, 731.985...   \n",
       "30     5  0.4  [975.9800734289661, 975.9800734289661, 975.980...   \n",
       "..   ...  ...                                                ...   \n",
       "55     8  0.2  [487.99003671448304, 487.99003671448304, 487.9...   \n",
       "65     9  0.3  [731.9850550717246, 731.9850550717246, 731.985...   \n",
       "54     8  0.1  [243.99501835724152, 243.99501835724152, 243.9...   \n",
       "64     9  0.2  [487.99003671448304, 487.99003671448304, 487.9...   \n",
       "63     9  0.1  [243.99501835724152, 243.99501835724152, 243.9...   \n",
       "\n",
       "                                                   Q1  average_profits  \\\n",
       "0   [2269.95107075639, 2144.5231165888654, 2173.44...     1.414303e+06   \n",
       "10  [2025.9372217432917, 1899.407887152837, 1930.2...     1.400996e+06   \n",
       "70  [523.4497811581105, 471.9663895204849, 442.392...     1.400309e+06   \n",
       "20  [1780.5736633861006, 1656.8543342108806, 1685....     1.388309e+06   \n",
       "30  [1483.59642709431, 1402.3642031024478, 1473.13...     1.383626e+06   \n",
       "..                                                ...              ...   \n",
       "55  [1997.5575478142553, 1939.2001775168476, 1918....    -2.318004e+05   \n",
       "65  [1743.424872944318, 1691.9414813066924, 1662.3...    -3.013963e+05   \n",
       "54  [2241.552566171497, 2183.195195874089, 2162.47...    -6.221924e+05   \n",
       "64  [1987.4198913015596, 1935.936499663934, 1906.3...    -6.917884e+05   \n",
       "63  [2231.414909658801, 2179.9315180211756, 2150.3...    -1.082180e+06   \n",
       "\n",
       "    average_losses  average_lefts  average_operation_profits  \n",
       "0        13.041585      58.057253               1.445351e+06  \n",
       "10       13.287333      90.587270               1.445203e+06  \n",
       "70        1.703915     127.054584               1.452153e+06  \n",
       "20       13.233072     122.467215               1.445236e+06  \n",
       "30        9.090525     146.603148               1.447721e+06  \n",
       "..             ...            ...                        ...  \n",
       "55     1052.429165    1055.152815               8.217182e+05  \n",
       "65     1096.210920    1097.797418               7.954492e+05  \n",
       "54     1296.424183    1299.147833               6.753212e+05  \n",
       "64     1340.205939    1341.792436               6.490522e+05  \n",
       "63     1584.200957    1585.787454               5.026551e+05  \n",
       "\n",
       "[72 rows x 8 columns]"
      ]
     },
     "execution_count": 1566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_1, stimulation_results_df_1 = None, None\n",
    "\n",
    "results_df_1, stimulation_results_df_1 = grid_fixed_F_fixed_R(\n",
    "    assigned_Ts=ASSIGNED_TS,\n",
    "    assigned_Fs=ASSIGNED_FS,\n",
    "    cost=cost,\n",
    "    price=price,\n",
    "    salvage_value=salvage_value,\n",
    "    Qk_hat_df=Qk_hat_df_train,\n",
    "    demand_df_train=demand_df_train,\n",
    "    Q_star=Q_star,\n",
    ")\n",
    "\n",
    "results_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R: 2, F: 0.1\n",
      "R: 3, F: 0.2\n",
      "R: 9, F: 0.8\n",
      "R: 4, F: 0.30000000000000004\n",
      "R: 5, F: 0.4\n",
      "R: 8, F: 0.7000000000000001\n",
      "R: 7, F: 0.6000000000000001\n",
      "R: 6, F: 0.5\n",
      "R: 7, F: 0.5\n",
      "R: 8, F: 0.6000000000000001\n",
      "R: 2, F: 0.2\n",
      "R: 6, F: 0.4\n",
      "R: 3, F: 0.30000000000000004\n",
      "R: 9, F: 0.9\n",
      "R: 4, F: 0.4\n",
      "R: 5, F: 0.5\n",
      "R: 8, F: 0.8\n",
      "R: 7, F: 0.7000000000000001\n",
      "R: 6, F: 0.6000000000000001\n",
      "R: 5, F: 0.30000000000000004\n",
      "R: 9, F: 0.7000000000000001\n",
      "R: 2, F: 0.30000000000000004\n",
      "R: 4, F: 0.2\n",
      "R: 3, F: 0.4\n",
      "R: 4, F: 0.5\n",
      "R: 5, F: 0.6000000000000001\n",
      "R: 8, F: 0.9\n",
      "R: 7, F: 0.8\n",
      "R: 6, F: 0.7000000000000001\n",
      "R: 3, F: 0.1\n",
      "R: 2, F: 0.4\n",
      "R: 3, F: 0.5\n",
      "R: 4, F: 0.6000000000000001\n",
      "R: 5, F: 0.7000000000000001\n",
      "R: 7, F: 0.9\n",
      "R: 6, F: 0.8\n",
      "R: 2, F: 0.5\n",
      "R: 3, F: 0.6000000000000001\n",
      "R: 4, F: 0.7000000000000001\n",
      "R: 5, F: 0.8\n",
      "R: 6, F: 0.9\n",
      "R: 7, F: 0.4\n",
      "R: 8, F: 0.5\n",
      "R: 2, F: 0.6000000000000001\n",
      "R: 6, F: 0.30000000000000004\n",
      "R: 3, F: 0.7000000000000001\n",
      "R: 4, F: 0.8\n",
      "R: 5, F: 0.9\n",
      "R: 5, F: 0.2\n",
      "R: 9, F: 0.6000000000000001\n",
      "R: 2, F: 0.7000000000000001\n",
      "R: 4, F: 0.1\n",
      "R: 3, F: 0.8\n",
      "R: 4, F: 0.9\n",
      "R: 2, F: 0.8\n",
      "R: 3, F: 0.9\n",
      "R: 2, F: 0.9\n",
      "R: 7, F: 0.30000000000000004\n",
      "R: 8, F: 0.4\n",
      "R: 6, F: 0.2\n",
      "R: 5, F: 0.1\n",
      "R: 9, F: 0.5\n",
      "R: 7, F: 0.2\n",
      "R: 8, F: 0.30000000000000004\n",
      "R: 6, F: 0.1\n",
      "R: 9, F: 0.4\n",
      "R: 7, F: 0.1\n",
      "R: 8, F: 0.2\n",
      "R: 9, F: 0.30000000000000004\n",
      "R: 8, F: 0.1\n",
      "R: 9, F: 0.2\n",
      "R: 9, F: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "result = results_df_1.iloc[:, 0:2]\n",
    "for i in range(len(result)):\n",
    "    print(f\"R: {result.iloc[i, 0]}, F: {result.iloc[i, 1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R(T)</th>\n",
       "      <th>F</th>\n",
       "      <th>Q0</th>\n",
       "      <th>Q1</th>\n",
       "      <th>average_profits</th>\n",
       "      <th>average_losses</th>\n",
       "      <th>average_lefts</th>\n",
       "      <th>average_operation_profits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>[731.9850550717246, 731.9850550717246, 731.985...</td>\n",
       "      <td>[604.8135392291935, 652.0626856585942, 669.454...</td>\n",
       "      <td>739326.687160</td>\n",
       "      <td>6.554651</td>\n",
       "      <td>56.007361</td>\n",
       "      <td>765662.422135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[487.99003671448304, 487.99003671448304, 487.9...</td>\n",
       "      <td>[853.459989988143, 882.1914569676458, 908.9703...</td>\n",
       "      <td>728448.749818</td>\n",
       "      <td>2.862513</td>\n",
       "      <td>94.278616</td>\n",
       "      <td>767877.704484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[975.9800734289661, 975.9800734289661, 975.980...</td>\n",
       "      <td>[359.6621377502245, 407.5107599456462, 425.231...</td>\n",
       "      <td>715854.471730</td>\n",
       "      <td>28.821212</td>\n",
       "      <td>47.888216</td>\n",
       "      <td>752302.485353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[975.9800734289661, 975.9800734289661, 975.980...</td>\n",
       "      <td>[357.2629172343859, 407.71031018582994, 426.97...</td>\n",
       "      <td>713205.847564</td>\n",
       "      <td>0.482057</td>\n",
       "      <td>139.527240</td>\n",
       "      <td>769305.978084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[243.99501835724152, 243.99501835724152, 243.9...</td>\n",
       "      <td>[1079.758536505809, 1092.6313403393742, 1121.5...</td>\n",
       "      <td>711167.910326</td>\n",
       "      <td>31.901102</td>\n",
       "      <td>50.364948</td>\n",
       "      <td>750454.551103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[2195.9551652151736, 2195.9551652151736, 2195....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>-314466.592964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2710.154514</td>\n",
       "      <td>769595.212557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[2195.9551652151736, 2195.9551652151736, 2195....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>-369313.503986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2847.271791</td>\n",
       "      <td>769595.212557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[2195.9551652151736, 2195.9551652151736, 2195....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>-415063.594638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2961.647018</td>\n",
       "      <td>769595.212557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[243.99501835724152, 243.99501835724152, 243.9...</td>\n",
       "      <td>[1091.647192821949, 1139.4958150173707, 1157.2...</td>\n",
       "      <td>-417541.196948</td>\n",
       "      <td>741.887033</td>\n",
       "      <td>742.179924</td>\n",
       "      <td>324462.992695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[2195.9551652151736, 2195.9551652151736, 2195....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>-446418.460993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3040.034184</td>\n",
       "      <td>769595.212557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    R(T)    F                                                 Q0  \\\n",
       "47     7  0.3  [731.9850550717246, 731.9850550717246, 731.985...   \n",
       "28     5  0.2  [487.99003671448304, 487.99003671448304, 487.9...   \n",
       "66     9  0.4  [975.9800734289661, 975.9800734289661, 975.980...   \n",
       "57     8  0.4  [975.9800734289661, 975.9800734289661, 975.980...   \n",
       "18     4  0.1  [243.99501835724152, 243.99501835724152, 243.9...   \n",
       "..   ...  ...                                                ...   \n",
       "35     5  0.9  [2195.9551652151736, 2195.9551652151736, 2195....   \n",
       "26     4  0.9  [2195.9551652151736, 2195.9551652151736, 2195....   \n",
       "17     3  0.9  [2195.9551652151736, 2195.9551652151736, 2195....   \n",
       "63     9  0.1  [243.99501835724152, 243.99501835724152, 243.9...   \n",
       "8      2  0.9  [2195.9551652151736, 2195.9551652151736, 2195....   \n",
       "\n",
       "                                                   Q1  average_profits  \\\n",
       "47  [604.8135392291935, 652.0626856585942, 669.454...    739326.687160   \n",
       "28  [853.459989988143, 882.1914569676458, 908.9703...    728448.749818   \n",
       "66  [359.6621377502245, 407.5107599456462, 425.231...    715854.471730   \n",
       "57  [357.2629172343859, 407.71031018582994, 426.97...    713205.847564   \n",
       "18  [1079.758536505809, 1092.6313403393742, 1121.5...    711167.910326   \n",
       "..                                                ...              ...   \n",
       "35      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   -314466.592964   \n",
       "26      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   -369313.503986   \n",
       "17      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   -415063.594638   \n",
       "63  [1091.647192821949, 1139.4958150173707, 1157.2...   -417541.196948   \n",
       "8       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   -446418.460993   \n",
       "\n",
       "    average_losses  average_lefts  average_operation_profits  \n",
       "47        6.554651      56.007361              765662.422135  \n",
       "28        2.862513      94.278616              767877.704484  \n",
       "66       28.821212      47.888216              752302.485353  \n",
       "57        0.482057     139.527240              769305.978084  \n",
       "18       31.901102      50.364948              750454.551103  \n",
       "..             ...            ...                        ...  \n",
       "35        0.000000    2710.154514              769595.212557  \n",
       "26        0.000000    2847.271791              769595.212557  \n",
       "17        0.000000    2961.647018              769595.212557  \n",
       "63      741.887033     742.179924              324462.992695  \n",
       "8         0.000000    3040.034184              769595.212557  \n",
       "\n",
       "[72 rows x 8 columns]"
      ]
     },
     "execution_count": 1568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_1, stimulation_results_df_1 = None, None\n",
    "\n",
    "results_df_1, stimulation_results_df_1 = grid_fixed_F_fixed_R(\n",
    "    assigned_Ts=ASSIGNED_TS,\n",
    "    assigned_Fs=ASSIGNED_FS,\n",
    "    cost=cost,\n",
    "    price=price,\n",
    "    salvage_value=salvage_value,\n",
    "    Qk_hat_df=Qk_hat_df_test,\n",
    "    demand_df_train=demand_df_test,\n",
    "    Q_star=Q_star,\n",
    ")\n",
    "\n",
    "results_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1569,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R: 7, F: 0.30000000000000004\n",
      "R: 5, F: 0.2\n",
      "R: 9, F: 0.4\n",
      "R: 8, F: 0.4\n",
      "R: 4, F: 0.1\n",
      "R: 3, F: 0.1\n",
      "R: 6, F: 0.30000000000000004\n",
      "R: 6, F: 0.2\n",
      "R: 9, F: 0.5\n",
      "R: 2, F: 0.1\n",
      "R: 4, F: 0.2\n",
      "R: 7, F: 0.4\n",
      "R: 5, F: 0.30000000000000004\n",
      "R: 8, F: 0.5\n",
      "R: 3, F: 0.2\n",
      "R: 8, F: 0.30000000000000004\n",
      "R: 6, F: 0.4\n",
      "R: 2, F: 0.2\n",
      "R: 4, F: 0.30000000000000004\n",
      "R: 7, F: 0.5\n",
      "R: 5, F: 0.4\n",
      "R: 5, F: 0.1\n",
      "R: 3, F: 0.30000000000000004\n",
      "R: 9, F: 0.6000000000000001\n",
      "R: 6, F: 0.5\n",
      "R: 2, F: 0.30000000000000004\n",
      "R: 4, F: 0.4\n",
      "R: 7, F: 0.2\n",
      "R: 8, F: 0.6000000000000001\n",
      "R: 5, F: 0.5\n",
      "R: 3, F: 0.4\n",
      "R: 7, F: 0.6000000000000001\n",
      "R: 2, F: 0.4\n",
      "R: 4, F: 0.5\n",
      "R: 9, F: 0.30000000000000004\n",
      "R: 6, F: 0.6000000000000001\n",
      "R: 3, F: 0.5\n",
      "R: 9, F: 0.7000000000000001\n",
      "R: 6, F: 0.1\n",
      "R: 2, F: 0.5\n",
      "R: 5, F: 0.6000000000000001\n",
      "R: 8, F: 0.7000000000000001\n",
      "R: 4, F: 0.6000000000000001\n",
      "R: 8, F: 0.2\n",
      "R: 7, F: 0.7000000000000001\n",
      "R: 3, F: 0.6000000000000001\n",
      "R: 2, F: 0.6000000000000001\n",
      "R: 6, F: 0.7000000000000001\n",
      "R: 9, F: 0.8\n",
      "R: 5, F: 0.7000000000000001\n",
      "R: 7, F: 0.1\n",
      "R: 8, F: 0.8\n",
      "R: 4, F: 0.7000000000000001\n",
      "R: 7, F: 0.8\n",
      "R: 3, F: 0.7000000000000001\n",
      "R: 9, F: 0.2\n",
      "R: 2, F: 0.7000000000000001\n",
      "R: 6, F: 0.8\n",
      "R: 9, F: 0.9\n",
      "R: 5, F: 0.8\n",
      "R: 8, F: 0.9\n",
      "R: 4, F: 0.8\n",
      "R: 8, F: 0.1\n",
      "R: 7, F: 0.9\n",
      "R: 3, F: 0.8\n",
      "R: 2, F: 0.8\n",
      "R: 6, F: 0.9\n",
      "R: 5, F: 0.9\n",
      "R: 4, F: 0.9\n",
      "R: 3, F: 0.9\n",
      "R: 9, F: 0.1\n",
      "R: 2, F: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "result = results_df_1.iloc[:, 0:2]\n",
    "for i in range(len(result)):\n",
    "    print(f\"R: {result.iloc[i, 0]}, F: {result.iloc[i, 1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1570,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.317939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.220750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.312659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.276366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.393165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      X1   X2        X3\n",
       "0  250.0  0.0  6.317939\n",
       "1  250.0  0.0  6.220750\n",
       "2  250.0  0.0  7.312659\n",
       "3  250.0  0.0  6.276366\n",
       "4  250.0  0.0  6.393165"
      ]
     },
     "execution_count": 1570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1571,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>216.647776</td>\n",
       "      <td>217.707632</td>\n",
       "      <td>217.106637</td>\n",
       "      <td>216.842714</td>\n",
       "      <td>219.597076</td>\n",
       "      <td>233.419212</td>\n",
       "      <td>281.223054</td>\n",
       "      <td>286.606612</td>\n",
       "      <td>295.373362</td>\n",
       "      <td>295.021682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>206.392192</td>\n",
       "      <td>207.466613</td>\n",
       "      <td>209.843167</td>\n",
       "      <td>207.604607</td>\n",
       "      <td>213.000352</td>\n",
       "      <td>224.961254</td>\n",
       "      <td>275.069930</td>\n",
       "      <td>290.849170</td>\n",
       "      <td>293.042855</td>\n",
       "      <td>290.427386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>208.757150</td>\n",
       "      <td>211.215125</td>\n",
       "      <td>210.251555</td>\n",
       "      <td>213.156271</td>\n",
       "      <td>218.505110</td>\n",
       "      <td>222.001409</td>\n",
       "      <td>233.240220</td>\n",
       "      <td>284.029835</td>\n",
       "      <td>294.011162</td>\n",
       "      <td>298.315636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211.765499</td>\n",
       "      <td>214.318603</td>\n",
       "      <td>215.414811</td>\n",
       "      <td>216.141472</td>\n",
       "      <td>219.949536</td>\n",
       "      <td>233.053752</td>\n",
       "      <td>285.949828</td>\n",
       "      <td>296.587134</td>\n",
       "      <td>299.984362</td>\n",
       "      <td>300.882037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>212.809346</td>\n",
       "      <td>217.810872</td>\n",
       "      <td>213.306858</td>\n",
       "      <td>217.226836</td>\n",
       "      <td>220.572888</td>\n",
       "      <td>233.189850</td>\n",
       "      <td>283.261878</td>\n",
       "      <td>291.515898</td>\n",
       "      <td>295.193378</td>\n",
       "      <td>301.422180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "0  216.647776  217.707632  217.106637  216.842714  219.597076  233.419212   \n",
       "1  206.392192  207.466613  209.843167  207.604607  213.000352  224.961254   \n",
       "2  208.757150  211.215125  210.251555  213.156271  218.505110  222.001409   \n",
       "3  211.765499  214.318603  215.414811  216.141472  219.949536  233.053752   \n",
       "4  212.809346  217.810872  213.306858  217.226836  220.572888  233.189850   \n",
       "\n",
       "    demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "0  281.223054  286.606612  295.373362  295.021682  \n",
       "1  275.069930  290.849170  293.042855  290.427386  \n",
       "2  233.240220  284.029835  294.011162  298.315636  \n",
       "3  285.949828  296.587134  299.984362  300.882037  \n",
       "4  283.261878  291.515898  295.193378  301.422180  "
      ]
     },
     "execution_count": 1571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76.726007</td>\n",
       "      <td>85.292909</td>\n",
       "      <td>133.499628</td>\n",
       "      <td>142.686827</td>\n",
       "      <td>151.989907</td>\n",
       "      <td>148.099649</td>\n",
       "      <td>147.917016</td>\n",
       "      <td>153.114936</td>\n",
       "      <td>149.021591</td>\n",
       "      <td>145.097141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73.215452</td>\n",
       "      <td>84.322469</td>\n",
       "      <td>140.436462</td>\n",
       "      <td>147.706836</td>\n",
       "      <td>153.427440</td>\n",
       "      <td>155.765750</td>\n",
       "      <td>155.706461</td>\n",
       "      <td>157.681604</td>\n",
       "      <td>157.247505</td>\n",
       "      <td>159.518788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.614354</td>\n",
       "      <td>93.288630</td>\n",
       "      <td>142.735808</td>\n",
       "      <td>149.774088</td>\n",
       "      <td>154.774819</td>\n",
       "      <td>155.977932</td>\n",
       "      <td>156.344506</td>\n",
       "      <td>152.764874</td>\n",
       "      <td>157.058150</td>\n",
       "      <td>156.135556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.997127</td>\n",
       "      <td>65.378692</td>\n",
       "      <td>122.601776</td>\n",
       "      <td>137.369862</td>\n",
       "      <td>143.971341</td>\n",
       "      <td>145.596807</td>\n",
       "      <td>148.718305</td>\n",
       "      <td>148.766359</td>\n",
       "      <td>147.117258</td>\n",
       "      <td>151.321785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.623523</td>\n",
       "      <td>88.635007</td>\n",
       "      <td>129.643968</td>\n",
       "      <td>136.108997</td>\n",
       "      <td>141.327015</td>\n",
       "      <td>142.297723</td>\n",
       "      <td>143.193646</td>\n",
       "      <td>140.258585</td>\n",
       "      <td>143.374846</td>\n",
       "      <td>140.789340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   demand_t1  demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "0  76.726007  85.292909  133.499628  142.686827  151.989907  148.099649   \n",
       "1  73.215452  84.322469  140.436462  147.706836  153.427440  155.765750   \n",
       "2  81.614354  93.288630  142.735808  149.774088  154.774819  155.977932   \n",
       "3  53.997127  65.378692  122.601776  137.369862  143.971341  145.596807   \n",
       "4  79.623523  88.635007  129.643968  136.108997  141.327015  142.297723   \n",
       "\n",
       "    demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "0  147.917016  153.114936  149.021591  145.097141  \n",
       "1  155.706461  157.681604  157.247505  159.518788  \n",
       "2  156.344506  152.764874  157.058150  156.135556  \n",
       "3  148.718305  148.766359  147.117258  151.321785  \n",
       "4  143.193646  140.258585  143.374846  140.789340  "
      ]
     },
     "execution_count": 1572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Qk_hat_k2</th>\n",
       "      <th>Qk_hat_k3</th>\n",
       "      <th>Qk_hat_k4</th>\n",
       "      <th>Qk_hat_k5</th>\n",
       "      <th>Qk_hat_k6</th>\n",
       "      <th>Qk_hat_k7</th>\n",
       "      <th>Qk_hat_k8</th>\n",
       "      <th>Qk_hat_k9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2513.946089</td>\n",
       "      <td>2513.927258</td>\n",
       "      <td>2512.558718</td>\n",
       "      <td>2459.576501</td>\n",
       "      <td>2458.613982</td>\n",
       "      <td>2482.734196</td>\n",
       "      <td>2485.547585</td>\n",
       "      <td>2475.409928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2388.518135</td>\n",
       "      <td>2387.397924</td>\n",
       "      <td>2388.839389</td>\n",
       "      <td>2378.344277</td>\n",
       "      <td>2382.912705</td>\n",
       "      <td>2438.709524</td>\n",
       "      <td>2427.190214</td>\n",
       "      <td>2423.926536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2417.442070</td>\n",
       "      <td>2418.245378</td>\n",
       "      <td>2417.663914</td>\n",
       "      <td>2449.113718</td>\n",
       "      <td>2452.384182</td>\n",
       "      <td>2413.429298</td>\n",
       "      <td>2406.473179</td>\n",
       "      <td>2394.352304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2454.234816</td>\n",
       "      <td>2455.480857</td>\n",
       "      <td>2456.327560</td>\n",
       "      <td>2459.188516</td>\n",
       "      <td>2458.357909</td>\n",
       "      <td>2482.921323</td>\n",
       "      <td>2483.762027</td>\n",
       "      <td>2497.761703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2467.001282</td>\n",
       "      <td>2471.308571</td>\n",
       "      <td>2468.981434</td>\n",
       "      <td>2477.945614</td>\n",
       "      <td>2477.035417</td>\n",
       "      <td>2490.348567</td>\n",
       "      <td>2494.383814</td>\n",
       "      <td>2489.961909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Qk_hat_k2    Qk_hat_k3    Qk_hat_k4    Qk_hat_k5    Qk_hat_k6  \\\n",
       "0  2513.946089  2513.927258  2512.558718  2459.576501  2458.613982   \n",
       "1  2388.518135  2387.397924  2388.839389  2378.344277  2382.912705   \n",
       "2  2417.442070  2418.245378  2417.663914  2449.113718  2452.384182   \n",
       "3  2454.234816  2455.480857  2456.327560  2459.188516  2458.357909   \n",
       "4  2467.001282  2471.308571  2468.981434  2477.945614  2477.035417   \n",
       "\n",
       "     Qk_hat_k7    Qk_hat_k8    Qk_hat_k9  \n",
       "0  2482.734196  2485.547585  2475.409928  \n",
       "1  2438.709524  2427.190214  2423.926536  \n",
       "2  2413.429298  2406.473179  2394.352304  \n",
       "3  2482.921323  2483.762027  2497.761703  \n",
       "4  2490.348567  2494.383814  2489.961909  "
      ]
     },
     "execution_count": 1573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qk_hat_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Qk_hat_k2</th>\n",
       "      <th>Qk_hat_k3</th>\n",
       "      <th>Qk_hat_k4</th>\n",
       "      <th>Qk_hat_k5</th>\n",
       "      <th>Qk_hat_k6</th>\n",
       "      <th>Qk_hat_k7</th>\n",
       "      <th>Qk_hat_k8</th>\n",
       "      <th>Qk_hat_k9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1327.556091</td>\n",
       "      <td>1313.863760</td>\n",
       "      <td>1323.753555</td>\n",
       "      <td>1341.450027</td>\n",
       "      <td>1340.901501</td>\n",
       "      <td>1336.798594</td>\n",
       "      <td>1333.242991</td>\n",
       "      <td>1335.642211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1313.069378</td>\n",
       "      <td>1328.628503</td>\n",
       "      <td>1336.626359</td>\n",
       "      <td>1370.181494</td>\n",
       "      <td>1370.067265</td>\n",
       "      <td>1384.047741</td>\n",
       "      <td>1383.690384</td>\n",
       "      <td>1383.490833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1347.728425</td>\n",
       "      <td>1365.324931</td>\n",
       "      <td>1365.503153</td>\n",
       "      <td>1396.960416</td>\n",
       "      <td>1397.087606</td>\n",
       "      <td>1401.439730</td>\n",
       "      <td>1402.952999</td>\n",
       "      <td>1401.211673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1233.762716</td>\n",
       "      <td>1261.705212</td>\n",
       "      <td>1271.919590</td>\n",
       "      <td>1264.597860</td>\n",
       "      <td>1264.105834</td>\n",
       "      <td>1262.319750</td>\n",
       "      <td>1265.939404</td>\n",
       "      <td>1266.018576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1339.513031</td>\n",
       "      <td>1329.221297</td>\n",
       "      <td>1331.942771</td>\n",
       "      <td>1298.853685</td>\n",
       "      <td>1298.985543</td>\n",
       "      <td>1289.184434</td>\n",
       "      <td>1289.069098</td>\n",
       "      <td>1287.215295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Qk_hat_k2    Qk_hat_k3    Qk_hat_k4    Qk_hat_k5    Qk_hat_k6  \\\n",
       "0  1327.556091  1313.863760  1323.753555  1341.450027  1340.901501   \n",
       "1  1313.069378  1328.628503  1336.626359  1370.181494  1370.067265   \n",
       "2  1347.728425  1365.324931  1365.503153  1396.960416  1397.087606   \n",
       "3  1233.762716  1261.705212  1271.919590  1264.597860  1264.105834   \n",
       "4  1339.513031  1329.221297  1331.942771  1298.853685  1298.985543   \n",
       "\n",
       "     Qk_hat_k7    Qk_hat_k8    Qk_hat_k9  \n",
       "0  1336.798594  1333.242991  1335.642211  \n",
       "1  1384.047741  1383.690384  1383.490833  \n",
       "2  1401.439730  1402.952999  1401.211673  \n",
       "3  1262.319750  1265.939404  1266.018576  \n",
       "4  1289.184434  1289.069098  1287.215295  "
      ]
     },
     "execution_count": 1574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qk_hat_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1575,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++++++++++++++++++++++ THis is R=0 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x3149f492\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [2e+02, 2e+03]\n",
      "Presolve removed 63 rows and 99 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 230 rows, 165 columns, 607 nonzeros\n",
      "Presolved model has 39 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 126 continuous, 39 integer (39 binary)\n",
      "\n",
      "Root relaxation: objective 2.145746e+07, 88 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1457e+07    0   23          - 2.1457e+07      -     -    0s\n",
      "H    0     0                    1.535866e+07 2.1457e+07  39.7%     -    0s\n",
      "     0     2 2.1457e+07    0   22 1.5359e+07 2.1457e+07  39.7%     -    0s\n",
      "H   66    52                    2.138878e+07 2.1423e+07  0.16%   2.8    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 5\n",
      "\n",
      "Explored 89 nodes (324 simplex iterations) in 0.03 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 2.13888e+07 1.53587e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.138877740288e+07, best bound 2.142169189787e+07, gap 0.1539%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.942744256666603, Left1: 34.40033169493654\n",
      "f_vars[i]: -2.3237, F_vars[i]: 0.0892, Q0_vars[i]: 217.5924\n",
      "f_train: -2.32370051981091, F_train: 0.08917902314184205, Q0_train: 217.59237388574616\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 30.13939082157094, Left0: 11.599672299804748, Left1: 0.0\n",
      "f_vars[i]: -2.3217, F_vars[i]: 0.0893, Q0_vars[i]: 217.9922\n",
      "f_train: -2.321684659874063, F_train: 0.08934289929277733, Q0_train: 217.99222353030385\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.780135226845218, Left1: 23.958598818924656\n",
      "f_vars[i]: -2.3443, F_vars[i]: 0.0875, Q0_vars[i]: 213.5378\n",
      "f_train: -2.3443326756445684, F_train: 0.08751729701505546, Q0_train: 213.53784491764614\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 39.812219486902734, Left0: 5.997831937831509, Left1: 0.0\n",
      "f_vars[i]: -2.3228, F_vars[i]: 0.0892, Q0_vars[i]: 217.7633\n",
      "f_train: -2.322838220808601, F_train: 0.08924908916495145, Q0_train: 217.76333149169412\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 19.30870245813685, Left0: 4.473992631227483, Left1: 0.0\n",
      "f_vars[i]: -2.3253, F_vars[i]: 0.0891, Q0_vars[i]: 217.2833\n",
      "f_train: -2.3252608235922048, F_train: 0.0890523669249368, Q0_train: 217.2833390260576\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 24.325608015315538\n",
      "f_vars[i]: -2.3324, F_vars[i]: 0.0885, Q0_vars[i]: 215.8740\n",
      "f_train: -2.3324018828229, F_train: 0.0884747670917031, Q0_train: 215.87402420692763\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 3.54694125445274, Left1: 35.72797391986842\n",
      "f_vars[i]: -2.3512, F_vars[i]: 0.0870, Q0_vars[i]: 212.2106\n",
      "f_train: -2.3511634739571767, F_train: 0.08697333775573979, Q0_train: 212.21061142302295\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 16.792373578614843, Left0: 3.305603056156021, Left1: 0.0\n",
      "f_vars[i]: -2.3211, F_vars[i]: 0.0894, Q0_vars[i]: 218.1016\n",
      "f_train: -2.321134015560789, F_train: 0.08938771025647861, Q0_train: 218.10156004941283\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.186755455772054, Left1: 20.32889123741552\n",
      "f_vars[i]: -2.3519, F_vars[i]: 0.0869, Q0_vars[i]: 212.0744\n",
      "f_train: -2.3518666862196067, F_train: 0.08691751260633504, Q0_train: 212.07440083948487\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 55.85462099144115, Left0: 4.858136765004755, Left1: 0.0\n",
      "f_vars[i]: -2.3211, F_vars[i]: 0.0894, Q0_vars[i]: 218.1098\n",
      "f_train: -2.3210924132475093, F_train: 0.08939109664059755, Q0_train: 218.10982265796548\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 2.438752957684239, Left1: 95.47284252627833\n",
      "f_vars[i]: -2.3576, F_vars[i]: 0.0865, Q0_vars[i]: 210.9644\n",
      "f_train: -2.3576127331522723, F_train: 0.08646257099327641, Q0_train: 210.96436596718775\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 33.71646139994209, Left0: 9.968603967671758, Left1: 0.0\n",
      "f_vars[i]: -2.3365, F_vars[i]: 0.0881, Q0_vars[i]: 215.0597\n",
      "f_train: -2.33654714866461, F_train: 0.08814103369666983, Q0_train: 215.05973134845195\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 10.057436261563694, Left1: 2.260117205147708\n",
      "f_vars[i]: -2.3576, F_vars[i]: 0.0865, Q0_vars[i]: 210.9620\n",
      "f_train: -2.3576252454900497, F_train: 0.08646158268893359, Q0_train: 210.96195455382505\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 55.270566432113355\n",
      "f_vars[i]: -2.3422, F_vars[i]: 0.0877, Q0_vars[i]: 213.9544\n",
      "f_train: -2.342196944309139, F_train: 0.08768800260878261, Q0_train: 213.95435806239752\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.733439586055052, Left1: 69.63978634475234\n",
      "f_vars[i]: -2.3478, F_vars[i]: 0.0872, Q0_vars[i]: 212.8684\n",
      "f_train: -2.347773054814954, F_train: 0.08724294475041541, Q0_train: 212.86843905917414\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=1 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xe4020d76\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [4e+02, 2e+03]\n",
      "Presolve removed 65 rows and 103 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 228 rows, 161 columns, 600 nonzeros\n",
      "Presolved model has 37 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 124 continuous, 37 integer (37 binary)\n",
      "\n",
      "Root relaxation: objective 2.145249e+07, 89 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1452e+07    0   22          - 2.1452e+07      -     -    0s\n",
      "H    0     0                    1.662303e+07 2.1452e+07  29.1%     -    0s\n",
      "     0     2 2.1452e+07    0   21 1.6623e+07 2.1452e+07  29.1%     -    0s\n",
      "H   55    34                    2.107288e+07 2.1419e+07  1.64%   2.7    0s\n",
      "H   76    46                    2.118501e+07 2.1419e+07  1.11%   3.5    0s\n",
      "H  207    84                    2.127503e+07 2.1416e+07  0.66%   4.1    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 4\n",
      "\n",
      "Explored 255 nodes (1129 simplex iterations) in 0.03 seconds (0.03 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 4: 2.1275e+07 2.1185e+07 2.10729e+07 1.6623e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.127503444278e+07, best bound 2.141562619115e+07, gap 0.6608%\n",
      "Model status: 2\n",
      "Lost0: 5.276280313727568, Lost1: 0.0, Left0: 0.0, Left1: 39.6577813528088\n",
      "f_vars[i]: -1.5447, F_vars[i]: 0.1759, Q0_vars[i]: 429.0791\n",
      "f_train: -1.5446819173954325, F_train: 0.1758556921965728, Q0_train: 429.0791284572819\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 31.259601900358575, Left0: 13.235715275585097, Left1: 0.0\n",
      "f_vars[i]: -1.5503, F_vars[i]: 0.1750, Q0_vars[i]: 427.0945\n",
      "f_train: -1.5503043732435076, F_train: 0.17504231155918487, Q0_train: 427.094520221773\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 29.837185837151083, Left1: 24.761905991686035\n",
      "f_vars[i]: -1.4871, F_vars[i]: 0.1844, Q0_vars[i]: 449.8095\n",
      "f_train: -1.4871365576683204, F_train: 0.18435190348421004, Q0_train: 449.8094607482224\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 38.566178894592895, Left0: 2.145208786973943, Left1: 0.0\n",
      "f_vars[i]: -1.5471, F_vars[i]: 0.1755, Q0_vars[i]: 428.2293\n",
      "f_train: -1.547086964482138, F_train: 0.17550739928829032, Q0_train: 428.2293111117811\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 15.001412972206992, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.5403, F_vars[i]: 0.1765, Q0_vars[i]: 430.6202\n",
      "f_train: -1.5403300579435133, F_train: 0.1764872991896379, Q0_train: 430.62021805595674\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.219949228534593, Left1: 23.862424122477933\n",
      "f_vars[i]: -1.5204, F_vars[i]: 0.1794, Q0_vars[i]: 437.7288\n",
      "f_train: -1.5204128556125482, F_train: 0.17940073236524137, Q0_train: 437.72884986759635\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 35.975739347290755, Left1: 37.82163447040216\n",
      "f_vars[i]: -1.4681, F_vars[i]: 0.1872, Q0_vars[i]: 456.8414\n",
      "f_train: -1.4680847072804344, F_train: 0.187233903592073, Q0_train: 456.84139744045837\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 3.1992054222660045, Lost1: 14.89591518118398, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.5518, F_vars[i]: 0.1748, Q0_vars[i]: 426.5537\n",
      "f_train: -1.551840181006133, F_train: 0.17482064774752323, Q0_train: 426.55367156381783\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 44.73403342417873, Left1: 21.436829194529537\n",
      "f_vars[i]: -1.4661, F_vars[i]: 0.1875, Q0_vars[i]: 457.5701\n",
      "f_train: -1.4661233706691612, F_train: 0.18753255774772273, Q0_train: 457.5700987023606\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 57.50821958039751, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.5520, F_vars[i]: 0.1748, Q0_vars[i]: 426.5128\n",
      "f_train: -1.5519562144493877, F_train: 0.1748039095815223, Q0_train: 426.5128312726112\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 51.54462260968103, Left1: 87.22883264854977\n",
      "f_vars[i]: -1.4501, F_vars[i]: 0.1900, Q0_vars[i]: 463.5579\n",
      "f_train: -1.45009701160058, F_train: 0.18998663628479265, Q0_train: 463.5579280793855\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 38.879467024925134, Left0: 33.884361312419514, Left1: 0.0\n",
      "f_vars[i]: -1.5089, F_vars[i]: 0.1811, Q0_vars[i]: 441.8972\n",
      "f_train: -1.5088512516798862, F_train: 0.18110909999378746, Q0_train: 441.8971817764766\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 56.72747123555155, Left1: 5.309550922806011\n",
      "f_vars[i]: -1.4501, F_vars[i]: 0.1900, Q0_vars[i]: 463.5710\n",
      "f_train: -1.4500621133095715, F_train: 0.18999200690072654, Q0_train: 463.57103211471923\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 17.699586499821862, Left1: 56.113439841190484\n",
      "f_vars[i]: -1.4931, F_vars[i]: 0.1835, Q0_vars[i]: 447.6281\n",
      "f_train: -1.4930933480768758, F_train: 0.1834578866929348, Q0_train: 447.6281043142336\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 31.87082715205679, Left1: 73.67751618630064\n",
      "f_vars[i]: -1.4775, F_vars[i]: 0.1858, Q0_vars[i]: 453.3406\n",
      "f_train: -1.477540960458137, F_train: 0.18579913003466939, Q0_train: 453.34062143568656\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=2 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xf14f3675\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [6e+02, 2e+03]\n",
      "Presolve removed 65 rows and 103 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 228 rows, 161 columns, 600 nonzeros\n",
      "Presolved model has 37 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 124 continuous, 37 integer (37 binary)\n",
      "\n",
      "Root relaxation: objective 2.145367e+07, 91 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1454e+07    0   22          - 2.1454e+07      -     -    0s\n",
      "H    0     0                    1.789670e+07 2.1454e+07  19.9%     -    0s\n",
      "     0     2 2.1454e+07    0   21 1.7897e+07 2.1454e+07  19.9%     -    0s\n",
      "H   56    34                    2.089105e+07 2.1421e+07  2.54%   3.0    0s\n",
      "H   57    34                    2.120533e+07 2.1421e+07  1.02%   3.0    0s\n",
      "H   98    38                    2.121863e+07 2.1421e+07  0.95%   4.9    0s\n",
      "H  105    38                    2.124360e+07 2.1421e+07  0.83%   5.2    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 4\n",
      "\n",
      "Explored 111 nodes (695 simplex iterations) in 0.03 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 5: 2.12436e+07 2.12186e+07 2.12053e+07 ... 1.78967e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.124360253818e+07, best bound 2.142076136030e+07, gap 0.8339%\n",
      "Model status: 2\n",
      "Lost0: 9.39960964493747, Lost1: 0.0, Left0: 0.0, Left1: 42.41257068406867\n",
      "f_vars[i]: -1.0297, F_vars[i]: 0.2631, Q0_vars[i]: 642.0624\n",
      "f_train: -1.0296822289509007, F_train: 0.2631457153504923, Q0_train: 642.0624364757282\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 29.818136485067498, Left0: 15.95655847507237, Left1: 0.0\n",
      "f_vars[i]: -1.0348, F_vars[i]: 0.2622, Q0_vars[i]: 639.6585\n",
      "f_train: -1.03476947148563, F_train: 0.26216048803948605, Q0_train: 639.6585309173779\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 36.773954866769145, Left1: 24.1804424244267\n",
      "f_vars[i]: -0.9776, F_vars[i]: 0.2734, Q0_vars[i]: 666.9978\n",
      "f_train: -0.9776147321860696, F_train: 0.2733653292322143, Q0_train: 666.997785242475\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.465475838164366, Lost1: 37.25400034956741, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.0319, F_vars[i]: 0.2627, Q0_vars[i]: 641.0334\n",
      "f_train: -1.0318583345830514, F_train: 0.2627239858984992, Q0_train: 641.0334376219197\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 17.32854987015139, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.0257, F_vars[i]: 0.2639, Q0_vars[i]: 643.9271\n",
      "f_train: -1.025744632088038, F_train: 0.2639099273153003, Q0_train: 643.9270755995497\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.8350030580183324, Left1: 24.756151872247983\n",
      "f_vars[i]: -1.0077, F_vars[i]: 0.2674, Q0_vars[i]: 652.5052\n",
      "f_train: -1.0077233898393179, F_train: 0.2674256233230849, Q0_train: 652.5051987191284\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 42.30494315020405, Left1: 38.464802348741614\n",
      "f_vars[i]: -0.9604, F_vars[i]: 0.2768, Q0_vars[i]: 675.3851\n",
      "f_train: -0.9603764672218845, F_train: 0.27680282619752744, Q0_train: 675.3851065940204\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 9.258026889663313, Lost1: 7.38213495610108, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.0362, F_vars[i]: 0.2619, Q0_vars[i]: 639.0029\n",
      "f_train: -1.0361590825001605, F_train: 0.2618917811444134, Q0_train: 639.0028994794183\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 59.11268830949484, Left1: 19.319834330839058\n",
      "f_vars[i]: -0.9586, F_vars[i]: 0.2772, Q0_vars[i]: 676.2522\n",
      "f_train: -0.9586018343384255, F_train: 0.27715821824542847, Q0_train: 676.2522454865366\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 59.327205819866776, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.0363, F_vars[i]: 0.2619, Q0_vars[i]: 638.9534\n",
      "f_train: -1.0362640704776431, F_train: 0.26187148700576957, Q0_train: 638.9533827921088\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 65.63792250765846, Left1: 85.69613599996092\n",
      "f_vars[i]: -0.9441, F_vars[i]: 0.2801, Q0_vars[i]: 683.3634\n",
      "f_train: -0.9441010578568386, F_train: 0.28007269284367425, Q0_train: 683.3634183175436\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 37.66255081484519, Left0: 42.6664020221142, Left1: 0.0\n",
      "f_vars[i]: -0.9973, F_vars[i]: 0.2695, Q0_vars[i]: 657.5178\n",
      "f_train: -0.9972623591286782, F_train: 0.2694800145878977, Q0_train: 657.5178110628381\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 72.5745057232723, Left1: 5.551228736449048\n",
      "f_vars[i]: -0.9441, F_vars[i]: 0.2801, Q0_vars[i]: 683.3790\n",
      "f_train: -0.944069481607028, F_train: 0.2800790596696447, Q0_train: 683.378953055739\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 14.91463910141465, Left1: 58.463952009389914\n",
      "f_vars[i]: -0.9830, F_vars[i]: 0.2723, Q0_vars[i]: 664.3888\n",
      "f_train: -0.9830044832762885, F_train: 0.27229603545731407, Q0_train: 664.3887617001143\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 37.53780524946092, Left1: 74.2366098646578\n",
      "f_vars[i]: -0.9689, F_vars[i]: 0.2751, Q0_vars[i]: 671.2140\n",
      "f_train: -0.9689325599124562, F_train: 0.27509331678132887, Q0_train: 671.2139887801479\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=3 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x48fd12ac\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [8e+02, 2e+03]\n",
      "Presolve removed 69 rows and 108 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 224 rows, 156 columns, 589 nonzeros\n",
      "Presolved model has 36 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 120 continuous, 36 integer (36 binary)\n",
      "\n",
      "Root relaxation: objective 2.156037e+07, 90 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1560e+07    0   22          - 2.1560e+07      -     -    0s\n",
      "H    0     0                    1.929042e+07 2.1560e+07  11.8%     -    0s\n",
      "     0     2 2.1560e+07    0   21 1.9290e+07 2.1560e+07  11.8%     -    0s\n",
      "H   64    50                    2.138913e+07 2.1536e+07  0.69%   2.7    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 4\n",
      "\n",
      "Explored 87 nodes (325 simplex iterations) in 0.02 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 2.13891e+07 1.92904e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.138912793496e+07, best bound 2.153626626820e+07, gap 0.6879%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 19.96925689541854, Left0: 8.860548283794463, Left1: 0.0\n",
      "f_vars[i]: -0.5775, F_vars[i]: 0.3595, Q0_vars[i]: 877.1653\n",
      "f_train: -0.5775292177713176, F_train: 0.35950131856149947, Q0_train: 877.1653082186559\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 40.3132492362638, Left0: 46.9083289808495, Left1: 0.0\n",
      "f_vars[i]: -0.5757, F_vars[i]: 0.3599, Q0_vars[i]: 878.2149\n",
      "f_train: -0.5756615031858249, F_train: 0.35993149150429105, Q0_train: 878.2149087693881\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 23.07454264966865, Left1: 55.63024619922476\n",
      "f_vars[i]: -0.5966, F_vars[i]: 0.3551, Q0_vars[i]: 866.4546\n",
      "f_train: -0.5966451184727075, F_train: 0.355111612326802, Q0_train: 866.4546436854768\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 34.85851986290061, Left0: 19.973830201554463, Left1: 0.0\n",
      "f_vars[i]: -0.5767, F_vars[i]: 0.3597, Q0_vars[i]: 877.6142\n",
      "f_train: -0.5767302890391027, F_train: 0.3596853006295742, Q0_train: 877.6142152994289\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 8.364370059295652, Left0: 15.199369346910657, Left1: 0.0\n",
      "f_vars[i]: -0.5790, F_vars[i]: 0.3592, Q0_vars[i]: 876.3533\n",
      "f_train: -0.5789748549789706, F_train: 0.3591685136178581, Q0_train: 876.3532807353243\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 28.808026756610616\n",
      "f_vars[i]: -0.5856, F_vars[i]: 0.3576, Q0_vars[i]: 872.6411\n",
      "f_train: -0.58559111845901, F_train: 0.3576470946346468, Q0_train: 872.6410942079473\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 19.847543599214994, Left1: 8.343415849739358\n",
      "f_vars[i]: -0.6030, F_vars[i]: 0.3537, Q0_vars[i]: 862.9216\n",
      "f_train: -0.6029739220794557, F_train: 0.35366360236685673, Q0_train: 862.9215715178937\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.103287352601239, Left1: 10.03251624022164\n",
      "f_vars[i]: -0.5752, F_vars[i]: 0.3600, Q0_vars[i]: 878.5017\n",
      "f_train: -0.5751513256697576, F_train: 0.36004903501226654, Q0_train: 878.5017090732506\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 7.453617130940984, Left0: 42.17906396040846, Left1: 0.0\n",
      "f_vars[i]: -0.6036, F_vars[i]: 0.3535, Q0_vars[i]: 862.5582\n",
      "f_train: -0.6036254553408845, F_train: 0.3535146854105718, Q0_train: 862.5582215630692\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 20.262499848900354, Left1: 0.3339373402283172\n",
      "f_vars[i]: -0.5751, F_vars[i]: 0.3601, Q0_vars[i]: 878.5234\n",
      "f_train: -0.5751127807064484, F_train: 0.36005791634884343, Q0_train: 878.5233790920618\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 37.93553245142103, Left1: 47.68684095931985\n",
      "f_vars[i]: -0.6089, F_vars[i]: 0.3523, Q0_vars[i]: 859.5918\n",
      "f_train: -0.6089492258414533, F_train: 0.35229893095542497, Q0_train: 859.5918412570547\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 25.398860530621732, Left0: 49.87116086517715, Left1: 0.0\n",
      "f_vars[i]: -0.5894, F_vars[i]: 0.3568, Q0_vars[i]: 870.4894\n",
      "f_train: -0.589431749115828, F_train: 0.35676524806448506, Q0_train: 870.4894325071984\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 45.36325026982757, Left1: 25.278930225381828\n",
      "f_vars[i]: -0.6090, F_vars[i]: 0.3523, Q0_vars[i]: 859.5854\n",
      "f_train: -0.6089608186487401, F_train: 0.35229628566224663, Q0_train: 859.5853868734786\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 37.32163303968764\n",
      "f_vars[i]: -0.5947, F_vars[i]: 0.3556, Q0_vars[i]: 867.5606\n",
      "f_train: -0.5946663418260948, F_train: 0.3555648965424874, Q0_train: 867.5606345907489\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 21.358053228748098, Left1: 38.82356117777044\n",
      "f_vars[i]: -0.5998, F_vars[i]: 0.3544, Q0_vars[i]: 864.6744\n",
      "f_train: -0.5998326645113498, F_train: 0.35438197842991737, Q0_train: 864.6743733248325\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=4 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xad440d6c\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 1e+03]\n",
      "Presolve removed 59 rows and 81 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 234 rows, 183 columns, 625 nonzeros\n",
      "Presolved model has 53 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 130 continuous, 53 integer (53 binary)\n",
      "\n",
      "Root relaxation: objective 2.156336e+07, 102 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1563e+07    0   23          - 2.1563e+07      -     -    0s\n",
      "H    0     0                    2.058791e+07 2.1563e+07  4.74%     -    0s\n",
      "     0     2 2.1563e+07    0   22 2.0588e+07 2.1563e+07  4.74%     -    0s\n",
      "H   34    26                    2.058791e+07 2.1544e+07  4.64%   4.4    0s\n",
      "H   64    48                    2.133264e+07 2.1539e+07  0.97%   3.9    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 7\n",
      "\n",
      "Explored 87 nodes (403 simplex iterations) in 0.03 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 3: 2.13326e+07 2.05879e+07 2.05879e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.133264062299e+07, best bound 2.153935694645e+07, gap 0.9690%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 20.93177558043567, Left0: 24.629889803438367, Left1: 0.0\n",
      "f_vars[i]: -0.1766, F_vars[i]: 0.4560, Q0_vars[i]: 1112.5321\n",
      "f_train: -0.17659723117709067, F_train: 0.45596507433440175, Q0_train: 1112.5320668248335\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 35.744820611710566, Left0: 70.73247482415609, Left1: 0.0\n",
      "f_vars[i]: -0.1725, F_vars[i]: 0.4570, Q0_vars[i]: 1115.0394\n",
      "f_train: -0.17245536914923051, F_train: 0.4569926944166363, Q0_train: 1115.0394086331244\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 25.04042586168281, Left1: 58.900710818974176\n",
      "f_vars[i]: -0.2190, F_vars[i]: 0.4455, Q0_vars[i]: 1086.9259\n",
      "f_train: -0.21898883846999193, F_train: 0.4454705348312034, Q0_train: 1086.9259132374966\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 35.689126453713016, Left0: 36.014198544150766, Left1: 0.0\n",
      "f_vars[i]: -0.1748, F_vars[i]: 0.4564, Q0_vars[i]: 1113.6045\n",
      "f_train: -0.1748255190511427, F_train: 0.4564046010594461, Q0_train: 1113.6044901382902\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 9.274567123335146, Left0: 28.86488422172689, Left1: 0.0\n",
      "f_vars[i]: -0.1798, F_vars[i]: 0.4552, Q0_vars[i]: 1110.5920\n",
      "f_train: -0.1798030903072533, F_train: 0.4551699388822131, Q0_train: 1110.5919759323008\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 34.51583235980638\n",
      "f_vars[i]: -0.1945, F_vars[i]: 0.4515, Q0_vars[i]: 1101.7200\n",
      "f_train: -0.19447538054214666, F_train: 0.4515338106588232, Q0_train: 1101.7200042061477\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 23.03281012190133, Left1: 6.9228683679016285\n",
      "f_vars[i]: -0.2330, F_vars[i]: 0.4420, Q0_vars[i]: 1078.4733\n",
      "f_train: -0.23302365489439705, F_train: 0.4420062708304744, Q0_train: 1078.4732816529745\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 20.07245466297565, Left1: 10.072256205063468\n",
      "f_vars[i]: -0.1713, F_vars[i]: 0.4573, Q0_vars[i]: 1115.7245\n",
      "f_train: -0.17132399452824712, F_train: 0.4572734590806502, Q0_train: 1115.7244604266257\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 2.0996114127169676, Left0: 49.73066190998025, Left1: 0.0\n",
      "f_vars[i]: -0.2345, F_vars[i]: 0.4416, Q0_vars[i]: 1077.6039\n",
      "f_train: -0.23446850139094452, F_train: 0.44164994853796197, Q0_train: 1077.6038730099478\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.098385348809188, Left0: 36.18291215693734, Left1: 0.0\n",
      "f_vars[i]: -0.1712, F_vars[i]: 0.4573, Q0_vars[i]: 1115.7762\n",
      "f_train: -0.17123851684277228, F_train: 0.4572946725350684, Q0_train: 1115.7762201986275\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 45.52183478983411, Left1: 45.83627627412943\n",
      "f_vars[i]: -0.2463, F_vars[i]: 0.4387, Q0_vars[i]: 1070.5054\n",
      "f_train: -0.24627454662538292, F_train: 0.43874067155239715, Q0_train: 1070.505382094956\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 27.569813064115806, Left0: 69.28046490099793, Left1: 0.0\n",
      "f_vars[i]: -0.2030, F_vars[i]: 0.4494, Q0_vars[i]: 1096.5757\n",
      "f_train: -0.20299240043590797, F_train: 0.4494254449744442, Q0_train: 1096.5756969675094\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 51.63934284190876, Left1: 23.18328581901187\n",
      "f_vars[i]: -0.2463, F_vars[i]: 0.4387, Q0_vars[i]: 1070.4899\n",
      "f_train: -0.24630025494755944, F_train: 0.4387343409575806, Q0_train: 1070.4899357589713\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 35.67269860664419\n",
      "f_vars[i]: -0.2146, F_vars[i]: 0.4466, Q0_vars[i]: 1089.5714\n",
      "f_train: -0.21460068413534047, F_train: 0.44655478310529484, Q0_train: 1089.571425012904\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 28.847324287148037, Left1: 34.57010825180896\n",
      "f_vars[i]: -0.2261, F_vars[i]: 0.4437, Q0_vars[i]: 1082.6670\n",
      "f_train: -0.22605757156339726, F_train: 0.44372505024360476, Q0_train: 1082.6670177975625\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=5 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x823ede9c\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 1e+03]\n",
      "Presolve removed 57 rows and 79 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 236 rows, 185 columns, 633 nonzeros\n",
      "Presolved model has 53 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 132 continuous, 53 integer (53 binary)\n",
      "\n",
      "Root relaxation: objective 2.169825e+07, 99 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1698e+07    0   22          - 2.1698e+07      -     -    0s\n",
      "H    0     0                    2.019005e+07 2.1698e+07  7.47%     -    0s\n",
      "     0     2 2.1698e+07    0   21 2.0190e+07 2.1698e+07  7.47%     -    0s\n",
      "H   31    28                    2.129104e+07 2.1689e+07  1.87%   2.9    0s\n",
      "H   55    22                    2.138490e+07 2.1687e+07  1.41%  14.0    0s\n",
      "H  184    68                    2.142368e+07 2.1687e+07  1.23%   9.4    0s\n",
      "H  249    67                    2.145444e+07 2.1687e+07  1.08%   7.8    0s\n",
      "H  387    69                    2.149693e+07 2.1687e+07  0.88%   5.7    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 3\n",
      "\n",
      "Explored 454 nodes (2434 simplex iterations) in 0.04 seconds (0.04 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 6: 2.14969e+07 2.14544e+07 2.14237e+07 ... 2.019e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Warning: max constraint violation (5.8792e-06) exceeds tolerance\n",
      "Best objective 2.149693038764e+07, best bound 2.168712791072e+07, gap 0.8848%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.466824952796969, Left1: 3.188438344676797\n",
      "f_vars[i]: 0.1789, F_vars[i]: 0.5446, Q0_vars[i]: 1328.7879\n",
      "f_train: 0.1788605581090434, F_train: 0.544596312448138, Q0_train: 1328.7878725306946\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 63.89319703224908, Left1: 20.051998198768615\n",
      "f_vars[i]: 0.1861, F_vars[i]: 0.5464, Q0_vars[i]: 1333.1614\n",
      "f_train: 0.18609025091048736, F_train: 0.5463887712829674, Q0_train: 1333.1613827937824\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 19.945826147479693\n",
      "f_vars[i]: 0.1049, F_vars[i]: 0.5262, Q0_vars[i]: 1283.8830\n",
      "f_train: 0.10486526419881426, F_train: 0.5261923179741835, Q0_train: 1283.8830428355036\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 11.125712641672635, Left0: 20.015351890681814, Left1: 0.0\n",
      "f_vars[i]: 0.1820, F_vars[i]: 0.5454, Q0_vars[i]: 1330.6590\n",
      "f_train: 0.1819531126936813, F_train: 0.5453631941487493, Q0_train: 1330.6590256768795\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 10.484122011407862, Left1: 4.038582673085557\n",
      "f_vars[i]: 0.1733, F_vars[i]: 0.5432, Q0_vars[i]: 1325.4008\n",
      "f_train: 0.17326467477930468, F_train: 0.5432081280754585, Q0_train: 1325.400771815743\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 25.950158228570587, Lost1: 0.0, Left0: 0.0, Left1: 26.301576169995343\n",
      "f_vars[i]: 0.1477, F_vars[i]: 0.5368, Q0_vars[i]: 1309.8789\n",
      "f_train: 0.14765393488058598, F_train: 0.5368465649334768, Q0_train: 1309.8788746596572\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 3.2943662157824747, Lost1: 13.956432116423457, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 0.0804, F_vars[i]: 0.5201, Q0_vars[i]: 1268.9717\n",
      "f_train: 0.08036724601506229, F_train: 0.5200810042435543, Q0_train: 1268.9717417765862\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 11.677328396322537\n",
      "f_vars[i]: 0.1881, F_vars[i]: 0.5469, Q0_vars[i]: 1334.3555\n",
      "f_train: 0.18806508515123238, F_train: 0.5468781851672745, Q0_train: 1334.3555282906404\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 12.624467048278234, Left0: 29.676074826617764, Left1: 0.0\n",
      "f_vars[i]: 0.0778, F_vars[i]: 0.5195, Q0_vars[i]: 1267.4358\n",
      "f_train: 0.07784524111846824, F_train: 0.5194514884618635, Q0_train: 1267.435754629488\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.14212207762921025, Left0: 17.96312776588877, Left1: 0.0\n",
      "f_vars[i]: 0.1882, F_vars[i]: 0.5469, Q0_vars[i]: 1334.4457\n",
      "f_train: 0.18821428795016792, F_train: 0.5469151577256044, Q0_train: 1334.4457394911246\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 20.696863690404598, Left1: 16.115566661028197\n",
      "f_vars[i]: 0.0572, F_vars[i]: 0.5143, Q0_vars[i]: 1254.8798\n",
      "f_train: 0.05723758213060015, F_train: 0.5143054901792068, Q0_train: 1254.8797751750565\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 14.609873500394542, Left0: 56.23766637435233, Left1: 0.0\n",
      "f_vars[i]: 0.1328, F_vars[i]: 0.5331, Q0_vars[i]: 1300.8549\n",
      "f_train: 0.13278732730131482, F_train: 0.5331481391571047, Q0_train: 1300.854900007669\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 27.31831655322867, Left1: 6.208203740174213\n",
      "f_vars[i]: 0.0572, F_vars[i]: 0.5143, Q0_vars[i]: 1254.8524\n",
      "f_train: 0.05719270780341912, F_train: 0.5142942807736162, Q0_train: 1254.852424783828\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 28.664065418571198, Lost1: 0.0, Left0: 0.0, Left1: 28.11683675827704\n",
      "f_vars[i]: 0.1125, F_vars[i]: 0.5281, Q0_vars[i]: 1288.5415\n",
      "f_train: 0.11252486454075161, F_train: 0.528101570912419, Q0_train: 1288.5415248926377\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.129588199378418, Left1: 26.13651216175333\n",
      "f_vars[i]: 0.0925, F_vars[i]: 0.5231, Q0_vars[i]: 1276.3750\n",
      "f_train: 0.09252666662676423, F_train: 0.5231151779015962, Q0_train: 1276.3749743505161\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=6 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xab689e2b\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [8e+02, 2e+03]\n",
      "Presolve removed 60 rows and 102 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 233 rows, 162 columns, 624 nonzeros\n",
      "Presolved model has 33 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 129 continuous, 33 integer (33 binary)\n",
      "Found heuristic solution: objective 2.065836e+07\n",
      "\n",
      "Root relaxation: objective 2.171196e+07, 87 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1712e+07    0   20 2.0658e+07 2.1712e+07  5.10%     -    0s\n",
      "H    0     0                    2.079021e+07 2.1712e+07  4.43%     -    0s\n",
      "     0     2 2.1712e+07    0   20 2.0790e+07 2.1712e+07  4.43%     -    0s\n",
      "H  227    73                    2.136391e+07 2.1702e+07  1.58%   3.7    0s\n",
      "*  423   109              22    2.136392e+07 2.1702e+07  1.58%   3.2    0s\n",
      "H  512   131                    2.146875e+07 2.1702e+07  1.09%   3.1    0s\n",
      "H  548   131                    2.146883e+07 2.1702e+07  1.09%   3.0    0s\n",
      "H  565   127                    2.146883e+07 2.1702e+07  1.09%   3.0    0s\n",
      "*  672   127              32    2.146884e+07 2.1701e+07  1.08%   3.0    0s\n",
      "H  695   181                    2.147439e+07 2.1701e+07  1.06%   2.9    0s\n",
      "H  707   181                    2.148900e+07 2.1701e+07  0.99%   2.9    0s\n",
      "H  731   181                    2.151777e+07 2.1701e+07  0.85%   2.8    0s\n",
      "H  807   181                    2.151819e+07 2.1701e+07  0.85%   2.8    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 4\n",
      "\n",
      "Explored 827 nodes (2350 simplex iterations) in 0.06 seconds (0.05 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 10: 2.15182e+07 2.15178e+07 2.1489e+07 ... 2.13639e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.151818546898e+07, best bound 2.170147026463e+07, gap 0.8518%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.3876178802449886, Left1: 6.001827110043678\n",
      "f_vars[i]: 0.6625, F_vars[i]: 0.6598, Q0_vars[i]: 1609.9317\n",
      "f_train: 0.662499099657594, F_train: 0.659821552883867, Q0_train: 1609.9317190840272\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 72.7431832173969, Left1: 8.53268846365063\n",
      "f_vars[i]: 0.6756, F_vars[i]: 0.6628, Q0_vars[i]: 1617.0813\n",
      "f_train: 0.6755812619218209, F_train: 0.6627517683924896, Q0_train: 1617.0812989521976\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 17.986173719096996, Left1: 12.98970777369982\n",
      "f_vars[i]: 0.5286, F_vars[i]: 0.6292, Q0_vars[i]: 1535.1130\n",
      "f_train: 0.5286042761417963, F_train: 0.6291575227478808, Q0_train: 1535.1130131246578\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 10.285008910035685, Left0: 16.40019411556625, Left1: 0.0\n",
      "f_vars[i]: 0.6681, F_vars[i]: 0.6611, Q0_vars[i]: 1612.9937\n",
      "f_train: 0.6680950913543826, F_train: 0.6610764871527932, Q0_train: 1612.993696183865\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 6.198725650894858, Left1: 8.073829484752878\n",
      "f_vars[i]: 0.6524, F_vars[i]: 0.6575, Q0_vars[i]: 1604.3773\n",
      "f_train: 0.6523733231215976, F_train: 0.6575450861437866, Q0_train: 1604.3772536436716\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 29.188012873800204, Lost1: 0.0, Left0: 0.0, Left1: 41.89451863771694\n",
      "f_vars[i]: 0.6060, F_vars[i]: 0.6470, Q0_vars[i]: 1578.7327\n",
      "f_train: 0.6060305718784149, F_train: 0.6470347910064332, Q0_train: 1578.732657093886\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 15.691585269218535, Left0: 15.074922426265516, Left1: 0.0\n",
      "f_vars[i]: 0.4843, F_vars[i]: 0.6188, Q0_vars[i]: 1509.7359\n",
      "f_train: 0.48427499994242407, F_train: 0.6187568443292358, Q0_train: 1509.7358759078072\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.803904737729386, Left1: 1.8159296273031487\n",
      "f_vars[i]: 0.6792, F_vars[i]: 0.6636, Q0_vars[i]: 1619.0290\n",
      "f_train: 0.679154733532844, F_train: 0.663550016583987, Q0_train: 1619.0289847735783\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 12.374515224631637, Left0: 49.55496513474975, Left1: 0.0\n",
      "f_vars[i]: 0.4797, F_vars[i]: 0.6177, Q0_vars[i]: 1507.1078\n",
      "f_train: 0.47971142052147964, F_train: 0.6176797286125868, Q0_train: 1507.1077672172405\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.466221752448746, Left0: 6.221736632402249, Left1: 0.0\n",
      "f_vars[i]: 0.6794, F_vars[i]: 0.6636, Q0_vars[i]: 1619.1760\n",
      "f_train: 0.6794247166814449, F_train: 0.663610288036052, Q0_train: 1619.1760441141084\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 39.577574340823844, Left1: 7.335138570589265\n",
      "f_vars[i]: 0.4424, F_vars[i]: 0.6088, Q0_vars[i]: 1485.5294\n",
      "f_train: 0.4424217671199826, F_train: 0.6088359378385044, Q0_train: 1485.5293582945424\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 42.17273952912933, Left1: 4.153277139962029\n",
      "f_vars[i]: 0.5791, F_vars[i]: 0.6409, Q0_vars[i]: 1563.6837\n",
      "f_train: 0.5791293773170407, F_train: 0.6408670514726752, Q0_train: 1563.6836798862662\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 41.26809636868438, Left1: 5.246160364990146\n",
      "f_vars[i]: 0.4423, F_vars[i]: 0.6088, Q0_vars[i]: 1485.4822\n",
      "f_train: 0.4423405668192504, F_train: 0.6088165994312137, Q0_train: 1485.4821735441233\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 6.704123323402911, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 0.5425, F_vars[i]: 0.6324, Q0_vars[i]: 1542.9891\n",
      "f_train: 0.5424643580711886, F_train: 0.6323855037841076, Q0_train: 1542.9891260465674\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 27.54342436839977, Left1: 23.521137678609307\n",
      "f_vars[i]: 0.5063, F_vars[i]: 0.6239, Q0_vars[i]: 1522.3665\n",
      "f_train: 0.5062775272765727, F_train: 0.6239334353689422, Q0_train: 1522.366500165418\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=7 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xfc7ea32c\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [6e+02, 2e+03]\n",
      "Presolve removed 60 rows and 102 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 233 rows, 162 columns, 624 nonzeros\n",
      "Presolved model has 33 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 129 continuous, 33 integer (33 binary)\n",
      "Found heuristic solution: objective 2.074695e+07\n",
      "\n",
      "Root relaxation: objective 2.175233e+07, 87 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1752e+07    0   20 2.0747e+07 2.1752e+07  4.85%     -    0s\n",
      "     0     2 2.1752e+07    0   20 2.0747e+07 2.1752e+07  4.85%     -    0s\n",
      "H   74    43                    2.084906e+07 2.1740e+07  4.27%   6.7    0s\n",
      "H  231    83                    2.112468e+07 2.1688e+07  2.67%   3.7    0s\n",
      "H  345    97                    2.113653e+07 2.1675e+07  2.55%   3.1    0s\n",
      "H  543   131                    2.151204e+07 2.1673e+07  0.75%   2.6    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 3\n",
      "\n",
      "Explored 567 nodes (1538 simplex iterations) in 0.04 seconds (0.04 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 5: 2.1512e+07 2.11365e+07 2.11247e+07 ... 2.0747e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.151203564749e+07, best bound 2.167282815492e+07, gap 0.7475%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 4.135829402649733, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 1.2325, F_vars[i]: 0.7743, Q0_vars[i]: 1889.1507\n",
      "f_train: 1.2325118441106626, F_train: 0.7742579033398528, Q0_train: 1889.150713386467\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 62.62357540067694, Left1: 5.269010610735904\n",
      "f_vars[i]: 1.2529, F_vars[i]: 0.7778, Q0_vars[i]: 1897.8109\n",
      "f_train: 1.2529333009824895, F_train: 0.777807216567782, Q0_train: 1897.8108608485088\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 6.1980775186325445, Lost1: 0.0, Left0: 0.0, Left1: 7.066910261341947\n",
      "f_vars[i]: 1.0235, F_vars[i]: 0.7357, Q0_vars[i]: 1794.9586\n",
      "f_train: 1.0234999614751943, F_train: 0.7356537886316437, Q0_train: 1794.9585966175216\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.31353149632502664, Lost1: 0.0, Left0: 0.0, Left1: 4.028198583840195\n",
      "f_vars[i]: 1.2412, F_vars[i]: 0.7758, Q0_vars[i]: 1892.8671\n",
      "f_train: 1.2412472733755604, F_train: 0.7757810456305654, Q0_train: 1892.8671046982981\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 7.31377099884628, Lost1: 0.0, Left0: 0.0, Left1: 10.965695692379747\n",
      "f_vars[i]: 1.2167, F_vars[i]: 0.7715, Q0_vars[i]: 1882.3807\n",
      "f_train: 1.2167053509142698, F_train: 0.7714832327413529, Q0_train: 1882.380655350304\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 46.71242776489976, Lost1: 0.0, Left0: 0.0, Left1: 58.092727655259864\n",
      "f_vars[i]: 1.1444, F_vars[i]: 0.7585, Q0_vars[i]: 1850.6532\n",
      "f_train: 1.1443636021482917, F_train: 0.7584799005173439, Q0_train: 1850.6531725032803\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 21.311521281953333, Lost1: 0.0, Left0: 0.0, Left1: 23.900247651040683\n",
      "f_vars[i]: 0.9543, F_vars[i]: 0.7220, Q0_vars[i]: 1761.5937\n",
      "f_train: 0.9543012782773685, F_train: 0.7219793765778393, Q0_train: 1761.5937124165966\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 10.614583474047777, Lost1: 0.0, Left0: 0.0, Left1: 10.226435158195914\n",
      "f_vars[i]: 1.2585, F_vars[i]: 0.7788, Q0_vars[i]: 1900.1594\n",
      "f_train: 1.2585115452293718, F_train: 0.7787697721665874, Q0_train: 1900.1594485585126\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 7.562898019201725, Left0: 14.123025348969577, Left1: 0.0\n",
      "f_vars[i]: 0.9472, F_vars[i]: 0.7205, Q0_vars[i]: 1758.0992\n",
      "f_train: 0.947177460483057, F_train: 0.7205471884165738, Q0_train: 1758.0992446496068\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 11.2402837440967, Lost1: 0.0, Left0: 0.0, Left1: 11.97147791040774\n",
      "f_vars[i]: 1.2589, F_vars[i]: 0.7788, Q0_vars[i]: 1900.3366\n",
      "f_train: 1.2589329930843913, F_train: 0.7788423737969009, Q0_train: 1900.336592919724\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.2785936908728949, Left1: 8.060302815395175\n",
      "f_vars[i]: 0.8890, F_vars[i]: 0.7087, Q0_vars[i]: 1729.1368\n",
      "f_train: 0.8889677369432114, F_train: 0.7086771037829438, Q0_train: 1729.136829468761\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.204354010915381, Left0: 23.733346000459164, Left1: 0.0\n",
      "f_vars[i]: 1.1024, F_vars[i]: 0.7507, Q0_vars[i]: 1831.6803\n",
      "f_train: 1.1023704229291382, F_train: 0.7507039879250892, Q0_train: 1831.6803331463655\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 2.5663816718536374, Left1: 1.3708274534915614\n",
      "f_vars[i]: 0.8888, F_vars[i]: 0.7087, Q0_vars[i]: 1729.0730\n",
      "f_train: 0.888840982022588, F_train: 0.7086509340473246, Q0_train: 1729.072976617533\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 26.730140700958145, Lost1: 0.0, Left0: 0.0, Left1: 16.462649246792015\n",
      "f_vars[i]: 1.0451, F_vars[i]: 0.7398, Q0_vars[i]: 1805.1721\n",
      "f_train: 1.0451357629309714, F_train: 0.7398397387485933, Q0_train: 1805.1721063737978\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.528352628987256, Left1: 11.720395797012998\n",
      "f_vars[i]: 0.9886, F_vars[i]: 0.7288, Q0_vars[i]: 1778.2862\n",
      "f_train: 0.988647562473383, F_train: 0.7288207078654247, Q0_train: 1778.2862199476206\n",
      "f_train, F_train, Q0_train 都相等\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R(T)</th>\n",
       "      <th>R</th>\n",
       "      <th>average_profits</th>\n",
       "      <th>average_losses</th>\n",
       "      <th>average_lefts</th>\n",
       "      <th>average_operation_profits</th>\n",
       "      <th>alpha_values</th>\n",
       "      <th>F_vars</th>\n",
       "      <th>f_vars</th>\n",
       "      <th>Q0_vars</th>\n",
       "      <th>Q1_vars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]</td>\n",
       "      <td>1.434546e+06</td>\n",
       "      <td>5.247298</td>\n",
       "      <td>30.833165</td>\n",
       "      <td>1.450027e+06</td>\n",
       "      <td>[0.006051714831513595, 0.0, -0.134605539196010...</td>\n",
       "      <td>[0.659821552883867, 0.6627517683924896, 0.6291...</td>\n",
       "      <td>[0.6624990996575941, 0.6755812619218209, 0.528...</td>\n",
       "      <td>[1609.9317190840272, 1617.0812989521976, 1535....</td>\n",
       "      <td>[875.6158654447111, 810.108915279132, 871.3601...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]</td>\n",
       "      <td>1.434136e+06</td>\n",
       "      <td>9.689161</td>\n",
       "      <td>18.532544</td>\n",
       "      <td>1.447362e+06</td>\n",
       "      <td>[0.010240182265778445, 0.0, -0.210121320763390...</td>\n",
       "      <td>[0.7742579033398518, 0.777807216567782, 0.7356...</td>\n",
       "      <td>[1.232511844110657, 1.2529333009824895, 1.0234...</td>\n",
       "      <td>[1889.1507133864645, 1897.8108608485088, 1794....</td>\n",
       "      <td>[586.2592146295781, 526.1156755299068, 599.393...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]</td>\n",
       "      <td>1.433129e+06</td>\n",
       "      <td>7.357813</td>\n",
       "      <td>28.044134</td>\n",
       "      <td>1.448761e+06</td>\n",
       "      <td>[0.0025953592346893567, 0.0, -0.07438806201181...</td>\n",
       "      <td>[0.5445963124481379, 0.5463887712829674, 0.526...</td>\n",
       "      <td>[0.17886055810904336, 0.18609025091048734, 0.1...</td>\n",
       "      <td>[1328.7878725306944, 1333.1613827937824, 1283....</td>\n",
       "      <td>[1153.9463232326773, 1105.5481411726655, 1129....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]</td>\n",
       "      <td>1.425942e+06</td>\n",
       "      <td>9.090525</td>\n",
       "      <td>40.813075</td>\n",
       "      <td>1.447721e+06</td>\n",
       "      <td>[-0.0018244602185753906, 0.0, -0.0192173681817...</td>\n",
       "      <td>[0.35950131856149947, 0.35993149150429105, 0.3...</td>\n",
       "      <td>[-0.5775292177713176, -0.5756615031858249, -0....</td>\n",
       "      <td>[877.1653082186559, 878.2149087693881, 866.454...</td>\n",
       "      <td>[1582.4111923046203, 1500.1293677620258, 1582....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>1.425918e+06</td>\n",
       "      <td>13.041585</td>\n",
       "      <td>29.018317</td>\n",
       "      <td>1.445351e+06</td>\n",
       "      <td>[-0.008770623601192223, 0.0, -0.02074167161838...</td>\n",
       "      <td>[0.08917826363963888, 0.08934275196196835, 0.0...</td>\n",
       "      <td>[-2.32370051981091, -2.321684659874063, -2.344...</td>\n",
       "      <td>[217.5905207382061, 217.99186405046942, 213.53...</td>\n",
       "      <td>[2296.3555683754253, 2170.5262708956375, 2203....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]</td>\n",
       "      <td>1.422176e+06</td>\n",
       "      <td>8.960540</td>\n",
       "      <td>50.617581</td>\n",
       "      <td>1.447799e+06</td>\n",
       "      <td>[0.00037060799079072525, 0.0, -0.0426166225640...</td>\n",
       "      <td>[0.4559649343541702, 0.4569926935960077, 0.445...</td>\n",
       "      <td>[-0.17659723117709064, -0.17245536914923051, -...</td>\n",
       "      <td>[1112.5317252800417, 1115.0394066308313, 1086....</td>\n",
       "      <td>[1346.0822565582173, 1267.8732985251359, 1365....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1.418336e+06</td>\n",
       "      <td>13.639085</td>\n",
       "      <td>46.182974</td>\n",
       "      <td>1.444992e+06</td>\n",
       "      <td>[-0.0076407192968197795, 0.0, 0.05785081133761...</td>\n",
       "      <td>[0.17585569219657235, 0.1750423115591844, 0.18...</td>\n",
       "      <td>[-1.5446819173954356, -1.5503043732435107, -1....</td>\n",
       "      <td>[429.07912845728083, 427.0945202217718, 449.80...</td>\n",
       "      <td>[2084.848130000494, 1960.3034036455454, 1968.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>1.416240e+06</td>\n",
       "      <td>13.859713</td>\n",
       "      <td>50.759743</td>\n",
       "      <td>1.444860e+06</td>\n",
       "      <td>[-0.005441550507021547, 0.0, 0.052343871798671...</td>\n",
       "      <td>[0.26314571535049286, 0.2621604880394866, 0.27...</td>\n",
       "      <td>[-1.0296822289508978, -1.034769471485627, -0.9...</td>\n",
       "      <td>[642.0624364757296, 639.6585309173793, 666.997...</td>\n",
       "      <td>[1870.4962819820958, 1749.1808583652285, 1750....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R(T)                                              R  average_profits  \\\n",
       "6     8  [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]     1.434546e+06   \n",
       "7     9  [7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]     1.434136e+06   \n",
       "5     7  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]     1.433129e+06   \n",
       "3     5  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]     1.425942e+06   \n",
       "0     2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]     1.425918e+06   \n",
       "4     6  [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]     1.422176e+06   \n",
       "1     3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]     1.418336e+06   \n",
       "2     4  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]     1.416240e+06   \n",
       "\n",
       "   average_losses  average_lefts  average_operation_profits  \\\n",
       "6        5.247298      30.833165               1.450027e+06   \n",
       "7        9.689161      18.532544               1.447362e+06   \n",
       "5        7.357813      28.044134               1.448761e+06   \n",
       "3        9.090525      40.813075               1.447721e+06   \n",
       "0       13.041585      29.018317               1.445351e+06   \n",
       "4        8.960540      50.617581               1.447799e+06   \n",
       "1       13.639085      46.182974               1.444992e+06   \n",
       "2       13.859713      50.759743               1.444860e+06   \n",
       "\n",
       "                                        alpha_values  \\\n",
       "6  [0.006051714831513595, 0.0, -0.134605539196010...   \n",
       "7  [0.010240182265778445, 0.0, -0.210121320763390...   \n",
       "5  [0.0025953592346893567, 0.0, -0.07438806201181...   \n",
       "3  [-0.0018244602185753906, 0.0, -0.0192173681817...   \n",
       "0  [-0.008770623601192223, 0.0, -0.02074167161838...   \n",
       "4  [0.00037060799079072525, 0.0, -0.0426166225640...   \n",
       "1  [-0.0076407192968197795, 0.0, 0.05785081133761...   \n",
       "2  [-0.005441550507021547, 0.0, 0.052343871798671...   \n",
       "\n",
       "                                              F_vars  \\\n",
       "6  [0.659821552883867, 0.6627517683924896, 0.6291...   \n",
       "7  [0.7742579033398518, 0.777807216567782, 0.7356...   \n",
       "5  [0.5445963124481379, 0.5463887712829674, 0.526...   \n",
       "3  [0.35950131856149947, 0.35993149150429105, 0.3...   \n",
       "0  [0.08917826363963888, 0.08934275196196835, 0.0...   \n",
       "4  [0.4559649343541702, 0.4569926935960077, 0.445...   \n",
       "1  [0.17585569219657235, 0.1750423115591844, 0.18...   \n",
       "2  [0.26314571535049286, 0.2621604880394866, 0.27...   \n",
       "\n",
       "                                              f_vars  \\\n",
       "6  [0.6624990996575941, 0.6755812619218209, 0.528...   \n",
       "7  [1.232511844110657, 1.2529333009824895, 1.0234...   \n",
       "5  [0.17886055810904336, 0.18609025091048734, 0.1...   \n",
       "3  [-0.5775292177713176, -0.5756615031858249, -0....   \n",
       "0  [-2.32370051981091, -2.321684659874063, -2.344...   \n",
       "4  [-0.17659723117709064, -0.17245536914923051, -...   \n",
       "1  [-1.5446819173954356, -1.5503043732435107, -1....   \n",
       "2  [-1.0296822289508978, -1.034769471485627, -0.9...   \n",
       "\n",
       "                                             Q0_vars  \\\n",
       "6  [1609.9317190840272, 1617.0812989521976, 1535....   \n",
       "7  [1889.1507133864645, 1897.8108608485088, 1794....   \n",
       "5  [1328.7878725306944, 1333.1613827937824, 1283....   \n",
       "3  [877.1653082186559, 878.2149087693881, 866.454...   \n",
       "0  [217.5905207382061, 217.99186405046942, 213.53...   \n",
       "4  [1112.5317252800417, 1115.0394066308313, 1086....   \n",
       "1  [429.07912845728083, 427.0945202217718, 449.80...   \n",
       "2  [642.0624364757296, 639.6585309173793, 666.997...   \n",
       "\n",
       "                                             Q1_vars  \n",
       "6  [875.6158654447111, 810.108915279132, 871.3601...  \n",
       "7  [586.2592146295781, 526.1156755299068, 599.393...  \n",
       "5  [1153.9463232326773, 1105.5481411726655, 1129....  \n",
       "3  [1582.4111923046203, 1500.1293677620258, 1582....  \n",
       "0  [2296.3555683754253, 2170.5262708956375, 2203....  \n",
       "4  [1346.0822565582173, 1267.8732985251359, 1365....  \n",
       "1  [2084.848130000494, 1960.3034036455454, 1968.4...  \n",
       "2  [1870.4962819820958, 1749.1808583652285, 1750....  "
      ]
     },
     "execution_count": 1575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_2, stimulation_results_df_2 = None, None\n",
    "results_df_2, stimulation_results_df_2 = grid_flexible_F_fixed_R(\n",
    "    assigned_Ts=ASSIGNED_TS,\n",
    "    salvage_value=salvage_value,\n",
    "    cost=cost,\n",
    "    price=price,\n",
    "    Q_star=Q_star,\n",
    "    demand_df_train=demand_df_train,\n",
    "    Qk_hat_df_train=Qk_hat_df_train,\n",
    "    training_df=training_df,\n",
    ")\n",
    "\n",
    "results_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1576,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++++++++++++++++++++++ THis is R=0 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 481 nonzeros\n",
      "Model fingerprint: 0x2ca04d36\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 1e+03]\n",
      "  GenCon const rng [5e+01, 1e+03]\n",
      "Presolve removed 44 rows and 62 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 249 rows, 202 columns, 680 nonzeros\n",
      "Presolved model has 61 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 141 continuous, 61 integer (61 binary)\n",
      "Found heuristic solution: objective -9624209.498\n",
      "\n",
      "Root relaxation: objective 1.135763e+07, 87 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 1.1358e+07    0   23 -9624209.5 1.1358e+07   218%     -    0s\n",
      "     0     2 1.1358e+07    0   22 -9624209.5 1.1358e+07   218%     -    0s\n",
      "H  888   394                    3764679.6768 1.1086e+07   194%   2.6    0s\n",
      "H 1000   454                    1.099246e+07 1.1086e+07  0.85%   2.5    0s\n",
      "* 1010   454              49    1.099246e+07 1.1086e+07  0.85%   2.4    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 12\n",
      "\n",
      "Explored 1203 nodes (2729 simplex iterations) in 0.07 seconds (0.10 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 4: 1.09925e+07 1.09925e+07 3.76468e+06 -9.62421e+06 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 1.099246295396e+07, best bound 1.106370132604e+07, gap 0.6481%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 5.889519778737622, Left0: 0.22905030319213998, Left1: 0.0\n",
      "f_vars[i]: -3.4245, F_vars[i]: 0.0315, Q0_vars[i]: 76.9554\n",
      "f_train: -3.4244591927580315, F_train: 0.03153973751736611, Q0_train: 76.95538834532321\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.3961446021078245, Lost1: 69.56324632376118, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -3.5101, F_vars[i]: 0.0290, Q0_vars[i]: 70.8193\n",
      "f_train: -3.5101467755557567, F_train: 0.029024899054991313, Q0_train: 70.81930777739687\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 6.754388690912037, Lost1: 45.98590356845125, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -3.4530, F_vars[i]: 0.0307, Q0_vars[i]: 74.8600\n",
      "f_train: -3.4529522115476685, F_train: 0.030680939956878, Q0_train: 74.85996507995873\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 31.076597848549344, Left0: 16.500260006671052, Left1: 0.0\n",
      "f_vars[i]: -3.5148, F_vars[i]: 0.0289, Q0_vars[i]: 70.4975\n",
      "f_train: -3.5148364421031952, F_train: 0.02889302425757489, Q0_train: 70.49753984123208\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 4.7257479303473815, Lost1: 0.0, Left0: 0.0, Left1: 58.986128529064445\n",
      "f_vars[i]: -3.4524, F_vars[i]: 0.0307, Q0_vars[i]: 74.8975\n",
      "f_train: -3.4524355792050168, F_train: 0.03069630813227535, Q0_train: 74.89746266234066\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 3.3998229551513504, Left1: 50.34018148416271\n",
      "f_vars[i]: -3.5225, F_vars[i]: 0.0287, Q0_vars[i]: 69.9735\n",
      "f_train: -3.5225192213985075, F_train: 0.028678237623389873, Q0_train: 69.97347115372347\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 6.165134488989167, Left1: 51.632536742404\n",
      "f_vars[i]: -3.5564, F_vars[i]: 0.0277, Q0_vars[i]: 67.7082\n",
      "f_train: -3.5563834883976804, F_train: 0.02774982852805775, Q0_train: 67.70819921113755\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.6308185526407186, Lost1: 0.0, Left0: 0.0, Left1: 43.46680796232636\n",
      "f_vars[i]: -3.4332, F_vars[i]: 0.0313, Q0_vars[i]: 76.3038\n",
      "f_train: -3.43323820923844, F_train: 0.03127268262340532, Q0_train: 76.30378770777969\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 20.803831114202467, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -3.6542, F_vars[i]: 0.0252, Q0_vars[i]: 61.5558\n",
      "f_train: -3.6542373124198533, F_train: 0.025228290090323825, Q0_train: 61.55577103710375\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 7.609416459267899, Lost1: 0.0, Left0: 0.0, Left1: 111.23119672583812\n",
      "f_vars[i]: -3.6100, F_vars[i]: 0.0263, Q0_vars[i]: 64.2688\n",
      "f_train: -3.609965127153243, F_train: 0.026340213973735288, Q0_train: 64.2688099205521\n",
      "f_train, F_train, Q0_train 不相等\n",
      "Lost0: 0.0, Lost1: 42.0138772326045, Left0: 8.54351329981742, Left1: 0.0\n",
      "f_vars[i]: -3.5040, F_vars[i]: 0.0292, Q0_vars[i]: 71.2418\n",
      "f_train: -3.5040205702942977, F_train: 0.029198049602777425, Q0_train: 71.24178648825325\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.448374741103449, Left1: 60.58179526156414\n",
      "f_vars[i]: -3.5947, F_vars[i]: 0.0267, Q0_vars[i]: 65.2299\n",
      "f_train: -3.5947165401452925, F_train: 0.0267341228744235, Q0_train: 65.22992801509712\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 32.579833956761604, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -3.4437, F_vars[i]: 0.0310, Q0_vars[i]: 75.5330\n",
      "f_train: -3.443717234290722, F_train: 0.030956778234407747, Q0_train: 75.53299673585373\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 2.297181720176013, Left1: 11.448228384860613\n",
      "f_vars[i]: -3.6133, F_vars[i]: 0.0263, Q0_vars[i]: 64.0634\n",
      "f_train: -3.613252035992698, F_train: 0.02625604768383103, Q0_train: 64.0634483660496\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 12.068710870440764, Lost1: 0.0, Left0: 0.0, Left1: 104.09871099263682\n",
      "f_vars[i]: -3.7375, F_vars[i]: 0.0233, Q0_vars[i]: 56.7505\n",
      "f_train: -3.7375348738677436, F_train: 0.023258874866962907, Q0_train: 56.75049600133397\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=1 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 481 nonzeros\n",
      "Model fingerprint: 0xe6207d21\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 1e+03]\n",
      "  GenCon const rng [1e+02, 1e+03]\n",
      "Presolve removed 48 rows and 71 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 245 rows, 193 columns, 668 nonzeros\n",
      "Presolved model has 57 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 136 continuous, 57 integer (57 binary)\n",
      "Found heuristic solution: objective -9153886.051\n",
      "\n",
      "Root relaxation: objective 1.140469e+07, 93 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 1.1405e+07    0   21 -9153886.1 1.1405e+07   225%     -    0s\n",
      "     0     2 1.1405e+07    0   20 -9153886.1 1.1405e+07   225%     -    0s\n",
      "H  887   406                    4553351.7959 1.1198e+07   146%   2.2    0s\n",
      "H  999   472                    1.104816e+07 1.1198e+07  1.35%   2.1    0s\n",
      "* 1006   472              45    1.104817e+07 1.1198e+07  1.35%   2.1    0s\n",
      "* 1471   498              34    1.104817e+07 1.1175e+07  1.15%   2.1    0s\n",
      "H 1530   498                    1.108375e+07 1.1167e+07  0.75%   2.1    0s\n",
      "* 1554   498              47    1.108375e+07 1.1167e+07  0.75%   2.1    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 10\n",
      "\n",
      "Explored 1755 nodes (3949 simplex iterations) in 0.07 seconds (0.07 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 7: 1.10838e+07 1.10837e+07 1.10482e+07 ... -9.15389e+06\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 1.108375485766e+07, best bound 1.116688150374e+07, gap 0.7500%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 19.581851009953198, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -2.6433, F_vars[i]: 0.0664, Q0_vars[i]: 162.0189\n",
      "f_train: -2.643309877939718, F_train: 0.06640255076294996, Q0_train: 162.01891592373636\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 56.40026532958268, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -2.6733, F_vars[i]: 0.0646, Q0_vars[i]: 157.5379\n",
      "f_train: -2.673321969964289, F_train: 0.06456604024310936, Q0_train: 157.5379217437186\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 14.387683950207796, Lost1: 20.75610160912788, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -2.6533, F_vars[i]: 0.0658, Q0_vars[i]: 160.5159\n",
      "f_train: -2.653289563140911, F_train: 0.06578654828077692, Q0_train: 160.51590055427718\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.1341018646103294, Left0: 37.92004735373634, Left1: 0.0\n",
      "f_vars[i]: -2.6750, F_vars[i]: 0.0645, Q0_vars[i]: 157.2960\n",
      "f_train: -2.674964526556398, F_train: 0.0644669052406747, Q0_train: 157.2960372763297\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 7.7146636528947825, Lost1: 0.0, Left0: 0.0, Left1: 51.68331001601382\n",
      "f_vars[i]: -2.6531, F_vars[i]: 0.0658, Q0_vars[i]: 160.5430\n",
      "f_train: -2.6531086125655263, F_train: 0.06579767013781303, Q0_train: 160.5430373313941\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 16.85283727877204, Left1: 23.55198231478016\n",
      "f_vars[i]: -2.6777, F_vars[i]: 0.0643, Q0_vars[i]: 156.9005\n",
      "f_train: -2.6776554214525663, F_train: 0.06430480495988884, Q0_train: 156.90052066646913\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 23.699683224258486, Left1: 43.372026997401235\n",
      "f_vars[i]: -2.6895, F_vars[i]: 0.0636, Q0_vars[i]: 155.1682\n",
      "f_train: -2.6895163873514756, F_train: 0.06359481163825847, Q0_train: 155.1681723310219\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 5.68810156025387, Lost1: 0.0, Left0: 0.0, Left1: 63.66897251228215\n",
      "f_vars[i]: -2.6464, F_vars[i]: 0.0662, Q0_vars[i]: 161.5544\n",
      "f_train: -2.646384730116576, F_train: 0.06621218463230337, Q0_train: 161.55443204831923\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 77.38042462521935, Left0: 23.223420533844664, Left1: 0.0\n",
      "f_vars[i]: -2.7238, F_vars[i]: 0.0616, Q0_vars[i]: 150.2621\n",
      "f_train: -2.723789707657899, F_train: 0.06158408918914043, Q0_train: 150.26210972218317\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.767575181427421, Left1: 42.11380642245376\n",
      "f_vars[i]: -2.7083, F_vars[i]: 0.0625, Q0_vars[i]: 152.4636\n",
      "f_train: -2.7082833664242236, F_train: 0.06248633936299439, Q0_train: 152.4635551995064\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 16.544687867226894, Left1: 30.785700246166925\n",
      "f_vars[i]: -2.6712, F_vars[i]: 0.0647, Q0_vars[i]: 157.8544\n",
      "f_train: -2.671176265416848, F_train: 0.06469575607827467, Q0_train: 157.85442191954246\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 16.18396585033627, Left1: 40.97230066313682\n",
      "f_vars[i]: -2.7029, F_vars[i]: 0.0628, Q0_vars[i]: 153.2287\n",
      "f_train: -2.7029425459507648, F_train: 0.06279994627663198, Q0_train: 153.228740446006\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 3.050386990038742, Lost1: 0.0, Left0: 0.0, Left1: 5.2704138103013065\n",
      "f_vars[i]: -2.6501, F_vars[i]: 0.0660, Q0_vars[i]: 161.0016\n",
      "f_train: -2.650055010616135, F_train: 0.06598561902254156, Q0_train: 161.0016232471897\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 19.11400516942156, Left1: 16.84288705280619\n",
      "f_vars[i]: -2.7094, F_vars[i]: 0.0624, Q0_vars[i]: 152.2991\n",
      "f_train: -2.7094346068647313, F_train: 0.062418931589114254, Q0_train: 152.29908358925334\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 3.308501806133306, Left1: 46.27643898895053\n",
      "f_vars[i]: -2.7530, F_vars[i]: 0.0599, Q0_vars[i]: 146.2004\n",
      "f_train: -2.752964694254239, F_train: 0.059919433583797685, Q0_train: 146.2004329723423\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=2 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 481 nonzeros\n",
      "Model fingerprint: 0x03144d14\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 1e+03]\n",
      "  GenCon const rng [2e+02, 1e+03]\n",
      "Presolve removed 46 rows and 62 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 247 rows, 202 columns, 674 nonzeros\n",
      "Presolved model has 59 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 143 continuous, 59 integer (59 binary)\n",
      "Found heuristic solution: objective -8467634.680\n",
      "\n",
      "Root relaxation: objective 1.141116e+07, 92 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 1.1411e+07    0   22 -8467634.7 1.1411e+07   235%     -    0s\n",
      "     0     2 1.1411e+07    0   21 -8467634.7 1.1411e+07   235%     -    0s\n",
      "H  657   272                    -8467634.245 1.1215e+07   232%   2.5    0s\n",
      "H  735   342                    4944673.1164 1.1215e+07   127%   2.4    0s\n",
      "*  745   342              44    4944673.6361 1.1215e+07   127%   2.3    0s\n",
      "*  838   376              41    1.064518e+07 1.1215e+07  5.36%   2.2    0s\n",
      "* 1298   422              43    1.064518e+07 1.1215e+07  5.36%   1.8    0s\n",
      "H 1344   422                    1.087286e+07 1.1215e+07  3.15%   1.8    0s\n",
      "H 1386   422                    1.103011e+07 1.1215e+07  1.68%   1.8    0s\n",
      "H 1527   404                    1.103273e+07 1.1199e+07  1.50%   1.8    0s\n",
      "* 1529   404              56    1.103274e+07 1.1199e+07  1.50%   1.8    0s\n",
      "H 1577   404                    1.103526e+07 1.1199e+07  1.48%   1.8    0s\n",
      "H 1882   468                    1.105140e+07 1.1195e+07  1.30%   2.0    0s\n",
      "H 1936   468                    1.107473e+07 1.1195e+07  1.09%   2.0    0s\n",
      "H 1969   468                    1.109773e+07 1.1195e+07  0.88%   2.0    0s\n",
      "H 2058   468                    1.110302e+07 1.1195e+07  0.83%   2.0    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 13\n",
      "\n",
      "Explored 2115 nodes (4467 simplex iterations) in 0.08 seconds (0.08 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 10: 1.1103e+07 1.10977e+07 1.10747e+07 ... 1.06452e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 1.110301780321e+07, best bound 1.119492086449e+07, gap 0.8277%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 9.692055732586368, Left0: 8.828305961754491, Left1: 0.0\n",
      "f_vars[i]: -1.9483, F_vars[i]: 0.1247, Q0_vars[i]: 304.3469\n",
      "f_train: -1.9483364713228655, F_train: 0.12473486237305755, Q0_train: 304.34685034502166\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 18.235522104313645, Lost1: 30.166887625082836, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -2.0441, F_vars[i]: 0.1146, Q0_vars[i]: 279.7389\n",
      "f_train: -2.0441047980937372, F_train: 0.11464941529526103, Q0_train: 279.73886189614217\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 21.674092346922805, Lost1: 13.291471953249584, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.9802, F_vars[i]: 0.1213, Q0_vars[i]: 295.9647\n",
      "f_train: -1.980181560716693, F_train: 0.12129948474514465, Q0_train: 295.96470007115505\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 36.46576843800369, Left1: 7.08027661092774\n",
      "f_vars[i]: -2.0493, F_vars[i]: 0.1141, Q0_vars[i]: 278.4434\n",
      "f_train: -2.0493461820107246, F_train: 0.11411846262208365, Q0_train: 278.4433638237548\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.7876017126205284, Lost1: 0.0, Left0: 0.0, Left1: 48.47772296306505\n",
      "f_vars[i]: -1.9796, F_vars[i]: 0.1214, Q0_vars[i]: 296.1149\n",
      "f_train: -1.9796041489914926, F_train: 0.12136104216375855, Q0_train: 296.1148971060023\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 19.77567218098261, Left1: 36.17055756247362\n",
      "f_vars[i]: -2.0579, F_vars[i]: 0.1133, Q0_vars[i]: 276.3323\n",
      "f_train: -2.0579328044131655, F_train: 0.11325326633360681, Q0_train: 276.33232798085953\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 16.74305674454331, Left1: 56.29256668560197\n",
      "f_vars[i]: -2.0958, F_vars[i]: 0.1095, Q0_vars[i]: 267.1930\n",
      "f_train: -2.09578104428578, F_train: 0.10950755813024489, Q0_train: 267.1929865624579\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 6.568257432274028, Left1: 51.466653170856034\n",
      "f_vars[i]: -1.9581, F_vars[i]: 0.1237, Q0_vars[i]: 301.7427\n",
      "f_train: -1.958148298096032, F_train: 0.12366758394340391, Q0_train: 301.7427441446654\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 78.54409310968595, Left0: 38.79265004931699, Left1: 0.0\n",
      "f_vars[i]: -2.2051, F_vars[i]: 0.0993, Q0_vars[i]: 242.2608\n",
      "f_train: -2.205146913747366, F_train: 0.09928924577407312, Q0_train: 242.26081345321634\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 16.886867814400375, Left1: 41.13174202869527\n",
      "f_vars[i]: -2.1557, F_vars[i]: 0.1038, Q0_vars[i]: 253.2739\n",
      "f_train: -2.155666312625941, F_train: 0.10380291350313682, Q0_train: 253.2739378573302\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.33856363064455763, Left1: 28.259382633818632\n",
      "f_vars[i]: -2.0373, F_vars[i]: 0.1153, Q0_vars[i]: 281.4391\n",
      "f_train: -2.037257873391359, F_train: 0.11534624773313268, Q0_train: 281.4390983308463\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 36.32287699145911, Left1: 28.3525326858545\n",
      "f_vars[i]: -2.1386, F_vars[i]: 0.1054, Q0_vars[i]: 257.1685\n",
      "f_train: -2.1386238005642024, F_train: 0.10539908107586704, Q0_train: 257.16850721942563\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.6455836369038934, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.9699, F_vars[i]: 0.1224, Q0_vars[i]: 298.6594\n",
      "f_train: -1.96986013151087, F_train: 0.12240391086957916, Q0_train: 298.6594447962112\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.9523370021966, Left0: 39.64731772625987, Left1: 0.0\n",
      "f_vars[i]: -2.1593, F_vars[i]: 0.1035, Q0_vars[i]: 252.4413\n",
      "f_train: -2.1593399109411844, F_train: 0.10346166354408097, Q0_train: 252.4413049570878\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.5594782905553757, Lost1: 0.0, Left0: 0.0, Left1: 37.02776803562256\n",
      "f_vars[i]: -2.2982, F_vars[i]: 0.0913, Q0_vars[i]: 222.6906\n",
      "f_train: -2.298244044317492, F_train: 0.09126849295430295, Q0_train: 222.69057613822915\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=3 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 481 nonzeros\n",
      "Model fingerprint: 0xefee7262\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 1e+03]\n",
      "  GenCon const rng [3e+02, 9e+02]\n",
      "Presolve removed 36 rows and 57 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 257 rows, 207 columns, 710 nonzeros\n",
      "Presolved model has 57 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 150 continuous, 57 integer (57 binary)\n",
      "Found heuristic solution: objective -7644935.824\n",
      "\n",
      "Root relaxation: objective 1.151161e+07, 88 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 1.1512e+07    0   20 -7644935.8 1.1512e+07   251%     -    0s\n",
      "     0     2 1.1512e+07    0   20 -7644935.8 1.1512e+07   251%     -    0s\n",
      "H  489   266                    7782012.0261 1.1462e+07  47.3%   2.9    0s\n",
      "H  516   266                    9845923.5488 1.1462e+07  16.4%   2.8    0s\n",
      "*  914   358              45    9845925.8977 1.1462e+07  16.4%   2.2    0s\n",
      "H  999   452                    1.091802e+07 1.1462e+07  4.98%   2.1    0s\n",
      "* 1208   460              55    1.091803e+07 1.1461e+07  4.97%   1.9    0s\n",
      "H 1532   502                    1.123002e+07 1.1461e+07  2.06%   1.8    0s\n",
      "* 1537   502              35    1.123002e+07 1.1461e+07  2.06%   1.8    0s\n",
      "* 1619   502              39    1.126715e+07 1.1461e+07  1.72%   1.7    0s\n",
      "H 1656   502                    1.130106e+07 1.1461e+07  1.41%   1.8    0s\n",
      "* 1666   502              39    1.130107e+07 1.1461e+07  1.41%   1.8    0s\n",
      "H 1787   614                    1.130921e+07 1.1444e+07  1.19%   1.8    0s\n",
      "* 1801   614              54    1.130921e+07 1.1444e+07  1.19%   1.8    0s\n",
      "* 1891   614              31    1.131071e+07 1.1430e+07  1.05%   1.9    0s\n",
      "* 1892   614              31    1.131180e+07 1.1430e+07  1.04%   1.9    0s\n",
      "* 1893   614              30    1.131268e+07 1.1430e+07  1.03%   1.9    0s\n",
      "* 2220   420              50    1.131446e+07 1.1416e+07  0.89%   2.0    0s\n",
      "* 2251   420              47    1.131496e+07 1.1414e+07  0.87%   2.0    0s\n",
      "* 2252   420              47    1.131510e+07 1.1414e+07  0.87%   2.0    0s\n",
      "* 2254   420              45    1.131862e+07 1.1414e+07  0.84%   2.0    0s\n",
      "* 2395   420              32    1.131961e+07 1.1403e+07  0.74%   2.1    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 6\n",
      "\n",
      "Explored 2547 nodes (5610 simplex iterations) in 0.09 seconds (0.09 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 10: 1.13196e+07 1.13186e+07 1.13151e+07 ... 1.13092e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 1.131960971247e+07, best bound 1.132328844295e+07, gap 0.0325%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 29.611532059763164, Left1: 8.004416106988089\n",
      "f_vars[i]: -1.4388, F_vars[i]: 0.1917, Q0_vars[i]: 467.8171\n",
      "f_train: -1.4387937098238643, F_train: 0.191732219014064, Q0_train: 467.8170629801119\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 21.41174709035323, Lost1: 0.0, Left0: 0.0, Left1: 6.564472346465209\n",
      "f_vars[i]: -1.5583, F_vars[i]: 0.1739, Q0_vars[i]: 424.2692\n",
      "f_train: -1.5583442622164778, F_train: 0.17388436300728108, Q0_train: 424.2691834399879\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 14.443065471851867, Lost1: 0.0, Left0: 0.0, Left1: 10.934764277039449\n",
      "f_vars[i]: -1.4785, F_vars[i]: 0.1856, Q0_vars[i]: 452.9694\n",
      "f_train: -1.4785469158826152, F_train: 0.1856469993948391, Q0_train: 452.9694302531057\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.24145392174305158, Left0: 42.63244113812541, Left1: 0.0\n",
      "f_vars[i]: -1.5649, F_vars[i]: 0.1729, Q0_vars[i]: 421.9808\n",
      "f_train: -1.5648872432176681, F_train: 0.17294647757975448, Q0_train: 421.9807897189245\n",
      "f_train, F_train, Q0_train 不相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 19.22388142764835, Left1: 13.601035064893154\n",
      "f_vars[i]: -1.4778, F_vars[i]: 0.1858, Q0_vars[i]: 453.2354\n",
      "f_train: -1.4778261150392336, F_train: 0.18575599633807596, Q0_train: 453.23537736476527\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 30.78880383377107, Left1: 6.495490931338921\n",
      "f_vars[i]: -1.5756, F_vars[i]: 0.1714, Q0_vars[i]: 418.2530\n",
      "f_train: -1.575606188468269, F_train: 0.1714186532712223, Q0_train: 418.252974516855\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 23.14147037982591, Left1: 4.024397665539347\n",
      "f_vars[i]: -1.6229, F_vars[i]: 0.1648, Q0_vars[i]: 402.1324\n",
      "f_train: -1.622853312193056, F_train: 0.16481173938346563, Q0_train: 402.132433763576\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 30.217404508903428, Left1: 14.179349747103174\n",
      "f_vars[i]: -1.4510, F_vars[i]: 0.1898, Q0_vars[i]: 463.2032\n",
      "f_train: -1.4510421154321105, F_train: 0.189841235248523, Q0_train: 463.2031567942477\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 13.866719082282607, Left1: 8.182216175233016\n",
      "f_vars[i]: -1.7594, F_vars[i]: 0.1469, Q0_vars[i]: 358.3512\n",
      "f_train: -1.7593780959904457, F_train: 0.14686824599597212, Q0_train: 358.3512037788308\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 15.421922186647418, Left1: 5.143845668125902\n",
      "f_vars[i]: -1.6976, F_vars[i]: 0.1548, Q0_vars[i]: 377.6498\n",
      "f_train: -1.697609937391019, F_train: 0.15477767885396032, Q0_train: 377.6498259326328\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 3.0961006273685197, Left1: 5.641356362339712\n",
      "f_vars[i]: -1.5498, F_vars[i]: 0.1751, Q0_vars[i]: 427.2733\n",
      "f_train: -1.5497970351951857, F_train: 0.1751155845205324, Q0_train: 427.2733025972638\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 32.79465450947541, Left1: 9.763335716486722\n",
      "f_vars[i]: -1.6763, F_vars[i]: 0.1576, Q0_vars[i]: 384.4907\n",
      "f_train: -1.6763352446002253, F_train: 0.15758135295273243, Q0_train: 384.490651064609\n",
      "f_train, F_train, Q0_train 不相等\n",
      "Lost0: 0.0, Lost1: 2.3468499681893817, Left0: 13.819815366497018, Left1: 0.0\n",
      "f_vars[i]: -1.4657, F_vars[i]: 0.1876, Q0_vars[i]: 457.7415\n",
      "f_train: -1.4656623578596935, F_train: 0.1876028096670378, Q0_train: 457.7415098857897\n",
      "f_train, F_train, Q0_train 不相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 26.585696972444648, Left1: 5.7501885409173745\n",
      "f_vars[i]: -1.7022, F_vars[i]: 0.1542, Q0_vars[i]: 376.1883\n",
      "f_train: -1.7021958033308788, F_train: 0.15417869809037654, Q0_train: 376.1883427085702\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 21.9938220039993, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.8756, F_vars[i]: 0.1329, Q0_vars[i]: 324.2590\n",
      "f_train: -1.8755941118811086, F_train: 0.13289576309168669, Q0_train: 324.2590415515571\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=4 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 481 nonzeros\n",
      "Model fingerprint: 0xa7a8998c\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 1e+03]\n",
      "  GenCon const rng [5e+02, 8e+02]\n",
      "Presolve removed 40 rows and 60 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 253 rows, 204 columns, 696 nonzeros\n",
      "Presolved model has 55 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 149 continuous, 55 integer (55 binary)\n",
      "Found heuristic solution: objective -6781718.824\n",
      "\n",
      "Root relaxation: objective 1.151151e+07, 88 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 1.1512e+07    0   20 -6781718.8 1.1512e+07   270%     -    0s\n",
      "     0     2 1.1512e+07    0   20 -6781718.8 1.1512e+07   270%     -    0s\n",
      "H  310   134                    -6781715.915 1.1462e+07   269%   3.3    0s\n",
      "H  513   262                    1.001858e+07 1.1462e+07  14.4%   2.5    0s\n",
      "H  631   252                    1.001858e+07 1.1462e+07  14.4%   2.4    0s\n",
      "*  740   292              32    1.087911e+07 1.1462e+07  5.36%   2.3    0s\n",
      "H  859   316                    1.117753e+07 1.1462e+07  2.54%   2.2    0s\n",
      "H  916   316                    1.124254e+07 1.1462e+07  1.95%   2.2    0s\n",
      "H  935   316                    1.127696e+07 1.1462e+07  1.64%   2.2    0s\n",
      "H 1065   277                    1.128815e+07 1.1460e+07  1.52%   2.3    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 6\n",
      "\n",
      "Explored 1203 nodes (2967 simplex iterations) in 0.06 seconds (0.06 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 8: 1.12881e+07 1.1277e+07 1.12425e+07 ... -6.78172e+06\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 1.128814888039e+07, best bound 1.139254861262e+07, gap 0.9249%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 15.351708877145143, Left1: 7.45588999922154\n",
      "f_vars[i]: -1.1083, F_vars[i]: 0.2482, Q0_vars[i]: 605.5470\n",
      "f_train: -1.1083423145468414, F_train: 0.24818006151816085, Q0_train: 605.5469866602498\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 34.67920401292895, Lost1: 0.0, Left0: 0.0, Left1: 19.717700910685384\n",
      "f_vars[i]: -1.2008, F_vars[i]: 0.2313, Q0_vars[i]: 564.4295\n",
      "f_train: -1.2008262120505864, F_train: 0.2313282705799354, Q0_train: 564.4294562670027\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 30.53269100406814, Lost1: 0.0, Left0: 0.0, Left1: 27.151580254933386\n",
      "f_vars[i]: -1.1391, F_vars[i]: 0.2425, Q0_vars[i]: 591.6550\n",
      "f_train: -1.139095258477278, F_train: 0.24248651135272792, Q0_train: 591.655007888923\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.7334794888906799, Left0: 38.91760168935048, Left1: 0.0\n",
      "f_vars[i]: -1.2059, F_vars[i]: 0.2304, Q0_vars[i]: 562.2364\n",
      "f_train: -1.2058878397233366, F_train: 0.23042945894285582, Q0_train: 562.2364006481133\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 16.566445882808125, Left1: 13.732892479401357\n",
      "f_vars[i]: -1.1385, F_vars[i]: 0.2426, Q0_vars[i]: 591.9050\n",
      "f_train: -1.1385376494157908, F_train: 0.24258895148556262, Q0_train: 591.9049567098382\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 33.022236235507194, Left1: 6.288577017925263\n",
      "f_vars[i]: -1.2142, F_vars[i]: 0.2290, Q0_vars[i]: 558.6566\n",
      "f_train: -1.21417997902395, F_train: 0.22896228758918638, Q0_train: 558.6565756343954\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 33.1994055077231, Left1: 4.437978409900779\n",
      "f_vars[i]: -1.2507, F_vars[i]: 0.2226, Q0_vars[i]: 543.0689\n",
      "f_train: -1.2507301919711877, F_train: 0.2225737646937914, Q0_train: 543.0688980230198\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 27.88067337258701, Left1: 14.710694979323307\n",
      "f_vars[i]: -1.1178, F_vars[i]: 0.2464, Q0_vars[i]: 601.2435\n",
      "f_train: -1.117817639137038, F_train: 0.24641631342776457, Q0_train: 601.2435291833119\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 6.690163918550979, Left1: 8.988761302735611\n",
      "f_vars[i]: -1.3563, F_vars[i]: 0.2048, Q0_vars[i]: 499.7870\n",
      "f_train: -1.3563452967008827, F_train: 0.20483492940672143, Q0_train: 499.7870236079726\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 18.162692054450872, Left1: 4.605913747370096\n",
      "f_vars[i]: -1.3086, F_vars[i]: 0.2127, Q0_vars[i]: 519.0448\n",
      "f_train: -1.308561660953689, F_train: 0.21272762982491356, Q0_train: 519.0448194422225\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.9625610516247924, Left1: 6.204795847306514\n",
      "f_vars[i]: -1.1942, F_vars[i]: 0.2325, Q0_vars[i]: 567.3033\n",
      "f_train: -1.1942141065273728, F_train: 0.23250609353616392, Q0_train: 567.3032856052682\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 32.16317499293757, Left1: 9.44638494176911\n",
      "f_vars[i]: -1.2921, F_vars[i]: 0.2155, Q0_vars[i]: 525.8019\n",
      "f_train: -1.2921036315417815, F_train: 0.21549696219567535, Q0_train: 525.8018524686358\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 2.6795474256190914, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.1291, F_vars[i]: 0.2443, Q0_vars[i]: 596.1337\n",
      "f_train: -1.1291278085598608, F_train: 0.2443220966603925, Q0_train: 596.133744597322\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 18.29801825623599, Left1: 5.170934868612335\n",
      "f_vars[i]: -1.3121, F_vars[i]: 0.2121, Q0_vars[i]: 517.5966\n",
      "f_train: -1.3121092711241136, F_train: 0.2121341007886586, Q0_train: 517.5966381612567\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 11.081594741362409, Lost1: 10.40062801840645, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.4462, F_vars[i]: 0.1906, Q0_vars[i]: 465.0043\n",
      "f_train: -1.4462496081977299, F_train: 0.1905794261068667, Q0_train: 465.0043057145749\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=5 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 481 nonzeros\n",
      "Model fingerprint: 0xd9b14fbe\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 1e+03]\n",
      "  GenCon const rng [6e+02, 8e+02]\n",
      "Presolve removed 32 rows and 49 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 261 rows, 215 columns, 723 nonzeros\n",
      "Presolved model has 59 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 156 continuous, 59 integer (59 binary)\n",
      "Found heuristic solution: objective -5903120.147\n",
      "\n",
      "Root relaxation: objective 1.153416e+07, 85 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 1.1534e+07    0   21 -5903120.1 1.1534e+07   295%     -    0s\n",
      "     0     2 1.1534e+07    0   21 -5903120.1 1.1534e+07   295%     -    0s\n",
      "H  270   126                    -5903119.978 1.1522e+07   295%   3.7    0s\n",
      "H  505   244                    8077132.3565 1.1522e+07  42.6%   2.5    0s\n",
      "*  736   330              33    8077132.9974 1.1522e+07  42.6%   2.4    0s\n",
      "H  747   330                    8165582.2925 1.1522e+07  41.1%   2.4    0s\n",
      "*  756   330              37    8165583.3451 1.1522e+07  41.1%   2.4    0s\n",
      "*  868   420              41    1.127649e+07 1.1522e+07  2.17%   2.2    0s\n",
      "* 1134   430              40    1.127649e+07 1.1435e+07  1.40%   2.4    0s\n",
      "H 1221   482                    1.127704e+07 1.1435e+07  1.40%   2.5    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 6\n",
      "\n",
      "Explored 1755 nodes (4291 simplex iterations) in 0.08 seconds (0.08 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 8: 1.1277e+07 1.12765e+07 1.12765e+07 ... -5.90312e+06\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Warning: max constraint violation (3.7052e-06) exceeds tolerance\n",
      "Best objective 1.127704067670e+07, best bound 1.127793539063e+07, gap 0.0079%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 15.796450182592366, Left1: 3.3529837052763014\n",
      "f_vars[i]: -0.8045, F_vars[i]: 0.3091, Q0_vars[i]: 754.0914\n",
      "f_train: -0.8045168393496075, F_train: 0.309060153144241, Q0_train: 754.0913773992096\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 40.406027930625896, Lost1: 0.0, Left0: 0.0, Left1: 39.425000234933925\n",
      "f_vars[i]: -0.8817, F_vars[i]: 0.2928, Q0_vars[i]: 714.4691\n",
      "f_train: -0.8817214690965085, F_train: 0.29282117526763274, Q0_train: 714.4690803481508\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 37.38457293234194, Lost1: 0.0, Left0: 0.0, Left1: 38.355585899627336\n",
      "f_vars[i]: -0.8302, F_vars[i]: 0.3036, Q0_vars[i]: 740.7813\n",
      "f_train: -0.8301890883990208, F_train: 0.30360508991303176, Q0_train: 740.7812948668214\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 2.51956347257817, Left0: 43.41969677689303, Left1: 0.0\n",
      "f_vars[i]: -0.8859, F_vars[i]: 0.2919, Q0_vars[i]: 712.3360\n",
      "f_train: -0.8859468650945039, F_train: 0.29194695981685553, Q0_train: 712.3360381985451\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 23.38498396601915, Left1: 3.9317837124635844\n",
      "f_vars[i]: -0.8297, F_vars[i]: 0.3037, Q0_vars[i]: 741.0215\n",
      "f_train: -0.8297236019489727, F_train: 0.30370351626224673, Q0_train: 741.0214502556569\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 43.7997499159884, Left1: 0.01689927614484077\n",
      "f_vars[i]: -0.8929, F_vars[i]: 0.2905, Q0_vars[i]: 708.8497\n",
      "f_train: -0.8928690597877764, F_train: 0.2905181092432064, Q0_train: 708.8497139790725\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0738272898768173, Left0: 45.37518414296517, Left1: 0.0\n",
      "f_vars[i]: -0.9234, F_vars[i]: 0.2843, Q0_vars[i]: 693.6035\n",
      "f_train: -0.9233808108485232, F_train: 0.28426953189206555, Q0_train: 693.6034965240898\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.4320227964672085, Left0: 33.1547852241564, Left1: 0.0\n",
      "f_vars[i]: -0.8124, F_vars[i]: 0.3074, Q0_vars[i]: 749.9763\n",
      "f_train: -0.8124267452517481, F_train: 0.30737361222029747, Q0_train: 749.9763015622311\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 2.4275235129354726, Left1: 0.974150531147302\n",
      "f_vars[i]: -1.0115, F_vars[i]: 0.2667, Q0_vars[i]: 650.6790\n",
      "f_train: -1.0115472406424888, F_train: 0.26667716246736606, Q0_train: 650.6789915168206\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 31.059335677100535, Left1: 5.11437886782835\n",
      "f_vars[i]: -0.9717, F_vars[i]: 0.2746, Q0_vars[i]: 669.8887\n",
      "f_train: -0.9716579409330612, F_train: 0.2745501627842959, Q0_train: 669.8887200853792\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 7.940216707513741\n",
      "f_vars[i]: -0.8762, F_vars[i]: 0.2940, Q0_vars[i]: 717.2611\n",
      "f_train: -0.8762017497448618, F_train: 0.2939654875253746, Q0_train: 717.2611452514923\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 40.66679136804112, Left1: 0.013845841426018524\n",
      "f_vars[i]: -0.9579, F_vars[i]: 0.2773, Q0_vars[i]: 676.5861\n",
      "f_train: -0.9579189431031043, F_train: 0.2772950505447433, Q0_train: 676.5861094803685\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.2512927426988654, Lost1: 1.3041534800554473, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -0.8219, F_vars[i]: 0.3054, Q0_vars[i]: 745.0808\n",
      "f_train: -0.8218683612112008, F_train: 0.30536720265583045, Q0_train: 745.0807621770883\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 20.09113995793018, Left1: 2.1007561060606577\n",
      "f_vars[i]: -0.9746, F_vars[i]: 0.2740, Q0_vars[i]: 668.4505\n",
      "f_train: -0.9746194503102248, F_train: 0.2739607059347463, Q0_train: 668.4504747371127\n",
      "f_train, F_train, Q0_train 不相等\n",
      "Lost0: 1.5677049320787546, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.0866, F_vars[i]: 0.2523, Q0_vars[i]: 615.5003\n",
      "f_train: -1.08659845787177, F_train: 0.25225935196768445, Q0_train: 615.5002521414101\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=6 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 481 nonzeros\n",
      "Model fingerprint: 0x1ac7674f\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 1e+03]\n",
      "  GenCon const rng [4e+02, 9e+02]\n",
      "Presolve removed 30 rows and 45 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 263 rows, 219 columns, 730 nonzeros\n",
      "Presolved model has 60 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 159 continuous, 60 integer (60 binary)\n",
      "Found heuristic solution: objective -5015306.221\n",
      "\n",
      "Root relaxation: objective 1.153843e+07, 84 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 1.1538e+07    0   21 -5015306.2 1.1538e+07   330%     -    0s\n",
      "     0     2 1.1538e+07    0   21 -5015306.2 1.1538e+07   330%     -    0s\n",
      "H  511   218                    9204304.6164 1.1530e+07  25.3%   2.5    0s\n",
      "*  837   330              39    1.106785e+07 1.1530e+07  4.18%   2.2    0s\n",
      "H 1003   264                    1.107398e+07 1.1530e+07  4.12%   2.2    0s\n",
      "H 1152   264                    1.122157e+07 1.1433e+07  1.88%   2.9    0s\n",
      "H 1364   135                    1.123826e+07 1.1295e+07  0.51%   3.0    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 7\n",
      "\n",
      "Explored 1452 nodes (4316 simplex iterations) in 0.07 seconds (0.08 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 6: 1.12383e+07 1.12216e+07 1.1074e+07 ... -5.01531e+06\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 1.123826351267e+07, best bound 1.129537587473e+07, gap 0.5082%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.20261993228257325, Left0: 21.302709767218573, Left1: 0.0\n",
      "f_vars[i]: -0.5239, F_vars[i]: 0.3719, Q0_vars[i]: 907.5147\n",
      "f_train: -0.523903885981488, F_train: 0.37193982862645747, Q0_train: 907.5146531350175\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 40.66199516522738, Lost1: 0.0, Left0: 0.0, Left1: 39.323610354011585\n",
      "f_vars[i]: -0.5905, F_vars[i]: 0.3565, Q0_vars[i]: 869.9189\n",
      "f_train: -0.5904508784033516, F_train: 0.35653140855184234, Q0_train: 869.9188757453994\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 39.571911187452656, Lost1: 0.0, Left0: 0.0, Left1: 42.0561936298762\n",
      "f_vars[i]: -0.5460, F_vars[i]: 0.3668, Q0_vars[i]: 894.9382\n",
      "f_train: -0.5460322346121876, F_train: 0.36678544987239936, Q0_train: 894.9382257478517\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 50.247306900228466, Left1: 1.10009074369475\n",
      "f_vars[i]: -0.5941, F_vars[i]: 0.3557, Q0_vars[i]: 867.8812\n",
      "f_train: -0.5940929837586885, F_train: 0.3556962858276713, Q0_train: 867.8812179012529\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 34.335730379347126, Left1: 3.8164479525904653\n",
      "f_vars[i]: -0.5456, F_vars[i]: 0.3669, Q0_vars[i]: 895.1656\n",
      "f_train: -0.5456310057821889, F_train: 0.36687864180620633, Q0_train: 895.1656094238514\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 56.40885595331662, Left1: 1.9358423215156222\n",
      "f_vars[i]: -0.6001, F_vars[i]: 0.3543, Q0_vars[i]: 864.5477\n",
      "f_train: -0.6000596108807408, F_train: 0.3543300558625493, Q0_train: 864.5476848470512\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.7287639012516252, Left0: 62.50787704597991, Left1: 0.0\n",
      "f_vars[i]: -0.6264, F_vars[i]: 0.3483, Q0_vars[i]: 849.9237\n",
      "f_train: -0.6263593972183447, F_train: 0.34833649105345604, Q0_train: 849.9236852908509\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.9881665927834433, Left0: 42.63049179972802, Left1: 0.0\n",
      "f_vars[i]: -0.5307, F_vars[i]: 0.3703, Q0_vars[i]: 903.6320\n",
      "f_train: -0.5307218766881727, F_train: 0.37034853749898516, Q0_train: 903.6319820564242\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.017086377646592155, Lost1: 0.0, Left0: 0.0, Left1: 0.3485689059091328\n",
      "f_vars[i]: -0.7024, F_vars[i]: 0.3313, Q0_vars[i]: 808.3318\n",
      "f_train: -0.7023549787604907, F_train: 0.33129030568772144, Q0_train: 808.3318421785174\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.02590670589995625, Left0: 48.22770262794626, Left1: 0.0\n",
      "f_vars[i]: -0.6680, F_vars[i]: 0.3390, Q0_vars[i]: 827.0237\n",
      "f_train: -0.667972158271888, F_train: 0.3389510570863639, Q0_train: 827.0236939599378\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.426737059753634, Left1: 2.017516629151089\n",
      "f_vars[i]: -0.5857, F_vars[i]: 0.3576, Q0_vars[i]: 872.5839\n",
      "f_train: -0.5856931232911384, F_train: 0.3576236608284957, Q0_train: 872.5839168883272\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 51.29036003143813, Left1: 0.6814359117792037\n",
      "f_vars[i]: -0.6561, F_vars[i]: 0.3416, Q0_vars[i]: 833.5103\n",
      "f_train: -0.6561297469104004, F_train: 0.3416095453418128, Q0_train: 833.5102728668454\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.9470198837497037, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -0.5389, F_vars[i]: 0.3685, Q0_vars[i]: 899.0064\n",
      "f_train: -0.53886013404092, F_train: 0.36845278395464737, Q0_train: 899.0064378479092\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 25.60515355553116, Left1: 0.8629305629045803\n",
      "f_vars[i]: -0.6705, F_vars[i]: 0.3384, Q0_vars[i]: 825.6287\n",
      "f_train: -0.670524848994264, F_train: 0.33837932829035344, Q0_train: 825.6287041791584\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 11.094807720132394, Left1: 0.5108753723097266\n",
      "f_vars[i]: -0.7670, F_vars[i]: 0.3171, Q0_vars[i]: 773.7533\n",
      "f_train: -0.7670458243818196, F_train: 0.3171184999585288, Q0_train: 773.7533421880213\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=7 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 481 nonzeros\n",
      "Model fingerprint: 0x622afcdf\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 1e+03]\n",
      "  GenCon const rng [3e+02, 1e+03]\n",
      "Presolve removed 30 rows and 38 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 263 rows, 226 columns, 730 nonzeros\n",
      "Presolved model has 67 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 159 continuous, 67 integer (67 binary)\n",
      "Found heuristic solution: objective -4124227.304\n",
      "\n",
      "Root relaxation: objective 1.154002e+07, 91 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 1.1540e+07    0   21 -4124227.3 1.1540e+07   380%     -    0s\n",
      "     0     2 1.1540e+07    0   21 -4124227.3 1.1540e+07   380%     -    0s\n",
      "H  484   244                    1.015100e+07 1.1534e+07  13.6%   2.9    0s\n",
      "H  577   240                    1.015100e+07 1.1534e+07  13.6%   2.6    0s\n",
      "H  631   240                    1.015100e+07 1.1534e+07  13.6%   2.6    0s\n",
      "H  831   292                    1.064103e+07 1.1534e+07  8.39%   2.6    0s\n",
      "*  834   292              39    1.064103e+07 1.1534e+07  8.39%   2.6    0s\n",
      "H 1114   266                    1.064103e+07 1.1534e+07  8.39%   3.1    0s\n",
      "H 1116   266                    1.067685e+07 1.1534e+07  8.03%   3.1    0s\n",
      "* 1164   266              33    1.074659e+07 1.1534e+07  7.32%   3.3    0s\n",
      "* 1260   342              39    1.074659e+07 1.1534e+07  7.32%   3.8    0s\n",
      "H 1455   408                    1.082269e+07 1.1534e+07  6.57%   3.7    0s\n",
      "H 1761   472                    1.087140e+07 1.1328e+07  4.20%   3.9    0s\n",
      "H 1912   472                    1.092810e+07 1.1321e+07  3.59%   4.0    0s\n",
      "H 1997   472                    1.094316e+07 1.1321e+07  3.45%   4.1    0s\n",
      "* 2024   472              43    1.094317e+07 1.1321e+07  3.45%   4.0    0s\n",
      "H 2120   403                    1.099007e+07 1.1313e+07  2.94%   4.0    0s\n",
      "* 2508   403              56    1.101474e+07 1.1297e+07  2.56%   3.8    0s\n",
      "* 2573   559              38    1.109812e+07 1.1262e+07  1.48%   3.8    0s\n",
      "H 2633   559                    1.116629e+07 1.1258e+07  0.82%   3.8    0s\n",
      "H 2676   559                    1.119615e+07 1.1226e+07  0.27%   3.8    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 4\n",
      "\n",
      "Explored 3063 nodes (11194 simplex iterations) in 0.12 seconds (0.13 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 10: 1.11961e+07 1.11663e+07 1.10981e+07 ... 1.08227e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 1.119614505013e+07, best bound 1.120914471937e+07, gap 0.1161%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 19.189291406351686, Left1: 2.196600583550662\n",
      "f_vars[i]: -0.2663, F_vars[i]: 0.4338, Q0_vars[i]: 1058.5162\n",
      "f_train: -0.26625401116994224, F_train: 0.43382695994437714, Q0_train: 1058.5161705549458\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 46.21064417639104, Lost1: 0.0, Left0: 0.0, Left1: 44.67270912499357\n",
      "f_vars[i]: -0.3274, F_vars[i]: 0.4189, Q0_vars[i]: 1022.0518\n",
      "f_train: -0.3273635359588629, F_train: 0.41888225340762014, Q0_train: 1022.0518310971496\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 40.920074792387936, Lost1: 0.0, Left0: 0.0, Left1: 41.66303103286419\n",
      "f_vars[i]: -0.2866, F_vars[i]: 0.4288, Q0_vars[i]: 1046.3549\n",
      "f_train: -0.28657428140264085, F_train: 0.42884274577958786, Q0_train: 1046.354936288604\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 53.66568645233076, Left1: 1.1792622672604125\n",
      "f_vars[i]: -0.3307, F_vars[i]: 0.4181, Q0_vars[i]: 1020.0660\n",
      "f_train: -0.3307080496535598, F_train: 0.41806835375026563, Q0_train: 1020.0659564787779\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 45.48667290445741, Left1: 1.9626452802996823\n",
      "f_vars[i]: -0.2862, F_vars[i]: 0.4289, Q0_vars[i]: 1046.5751\n",
      "f_train: -0.28620583645508557, F_train: 0.42893299381403216, Q0_train: 1046.5751369968134\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 67.46661560605651, Left1: 0.22538539457019624\n",
      "f_vars[i]: -0.3362, F_vars[i]: 0.4167, Q0_vars[i]: 1016.8150\n",
      "f_train: -0.3361871514844865, F_train: 0.4167359598386895, Q0_train: 1016.814981709637\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.860070791483281, Left0: 71.90489939809348, Left1: 0.0\n",
      "f_vars[i]: -0.3603, F_vars[i]: 0.4109, Q0_vars[i]: 1002.5212\n",
      "f_train: -0.36033801670996135, F_train: 0.41087774409093575, Q0_train: 1002.5212271204985\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.5704962924235133, Left0: 51.660297216335806, Left1: 0.0\n",
      "f_vars[i]: -0.2725, F_vars[i]: 0.4323, Q0_vars[i]: 1054.7656\n",
      "f_train: -0.2725149127815362, F_train: 0.43228979209777624, Q0_train: 1054.7655575854503\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 5.166420145052939, Lost1: 0.0, Left0: 0.0, Left1: 5.43710720720884\n",
      "f_vars[i]: -0.4301, F_vars[i]: 0.3941, Q0_vars[i]: 961.5763\n",
      "f_train: -0.4301240987714617, F_train: 0.3940966983168843, Q0_train: 961.5763114035645\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.9872760267322747, Left0: 57.22149083394464, Left1: 0.0\n",
      "f_vars[i]: -0.3986, F_vars[i]: 0.4017, Q0_vars[i]: 980.0319\n",
      "f_train: -0.39855065353382296, F_train: 0.40166061070346887, Q0_train: 980.0318808197371\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 11.996682263300102, Left1: 0.9148985200399693\n",
      "f_vars[i]: -0.3230, F_vars[i]: 0.4199, Q0_vars[i]: 1024.6476\n",
      "f_train: -0.322994530788407, F_train: 0.4199461316084329, Q0_train: 1024.6476409085215\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.3294724164349532, Left0: 59.92065493331842, Left1: 0.0\n",
      "f_vars[i]: -0.3877, F_vars[i]: 0.4043, Q0_vars[i]: 986.4155\n",
      "f_train: -0.3876758701015718, F_train: 0.40427691263561677, Q0_train: 986.4155271993623\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.0851508332818867, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -0.2800, F_vars[i]: 0.4305, Q0_vars[i]: 1050.2928\n",
      "f_train: -0.2799882037799275, F_train: 0.43045666806365224, Q0_train: 1050.2928262618784\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 26.38928425841067, Left1: 0.864753664930447\n",
      "f_vars[i]: -0.4009, F_vars[i]: 0.4011, Q0_vars[i]: 978.6576\n",
      "f_train: -0.4008947672390462, F_train: 0.40109738143913637, Q0_train: 978.6576294728358\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 15.644446795164697, Left1: 1.4065826238730779\n",
      "f_vars[i]: -0.4895, F_vars[i]: 0.3800, Q0_vars[i]: 927.1920\n",
      "f_train: -0.48952914008500453, F_train: 0.38000449649135787, Q0_train: 927.1920409724318\n",
      "f_train, F_train, Q0_train 都相等\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R(T)</th>\n",
       "      <th>R</th>\n",
       "      <th>average_profits</th>\n",
       "      <th>average_losses</th>\n",
       "      <th>average_lefts</th>\n",
       "      <th>average_operation_profits</th>\n",
       "      <th>alpha_values</th>\n",
       "      <th>F_vars</th>\n",
       "      <th>f_vars</th>\n",
       "      <th>Q0_vars</th>\n",
       "      <th>Q1_vars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]</td>\n",
       "      <td>754640.649196</td>\n",
       "      <td>4.029129</td>\n",
       "      <td>25.299021</td>\n",
       "      <td>767177.735019</td>\n",
       "      <td>[-0.009288359982061258, 0.0, -0.24536359809976...</td>\n",
       "      <td>[0.19173215358508425, 0.17388448178539448, 0.1...</td>\n",
       "      <td>[-1.4387937098238643, -1.5583442622164778, -1....</td>\n",
       "      <td>[467.81690333666074, 424.2694732526675, 452.96...</td>\n",
       "      <td>[873.6331233659653, 945.9120204294613, 943.990...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]</td>\n",
       "      <td>752543.260006</td>\n",
       "      <td>6.007143</td>\n",
       "      <td>24.608452</td>\n",
       "      <td>765990.926770</td>\n",
       "      <td>[-0.007138407770080382, 0.0, -0.18981243836737...</td>\n",
       "      <td>[0.24818006151816085, 0.2313282705799354, 0.24...</td>\n",
       "      <td>[-1.1083423145468414, -1.2008262120505864, -1....</td>\n",
       "      <td>[605.5469866602498, 564.4294562670027, 591.655...</td>\n",
       "      <td>[735.3545139346106, 805.6378090567691, 805.432...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]</td>\n",
       "      <td>751802.712868</td>\n",
       "      <td>5.929278</td>\n",
       "      <td>26.693416</td>\n",
       "      <td>766037.645934</td>\n",
       "      <td>[-0.004751909138388111, 0.0, -0.15845351916441...</td>\n",
       "      <td>[0.309060153144241, 0.2928208891486767, 0.3036...</td>\n",
       "      <td>[-0.8045168393496075, -0.8817228508005526, -0....</td>\n",
       "      <td>[754.0913773992096, 714.4683822321515, 740.781...</td>\n",
       "      <td>[582.7072169017061, 669.5793584981708, 660.658...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]</td>\n",
       "      <td>749217.568438</td>\n",
       "      <td>5.742898</td>\n",
       "      <td>33.715416</td>\n",
       "      <td>766149.473767</td>\n",
       "      <td>[-0.0024003943457312003, 0.0, -0.1365799586581...</td>\n",
       "      <td>[0.3719398286264574, 0.35653140855184234, 0.36...</td>\n",
       "      <td>[-0.5239038859814881, -0.5904508784033518, -0....</td>\n",
       "      <td>[907.5146531350173, 869.9188757453994, 894.938...</td>\n",
       "      <td>[425.72833752833543, 513.7715078693979, 508.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]</td>\n",
       "      <td>746409.670845</td>\n",
       "      <td>6.408640</td>\n",
       "      <td>38.737933</td>\n",
       "      <td>765750.028338</td>\n",
       "      <td>[-5.583752474166381e-05, 0.0, -0.1254201890354...</td>\n",
       "      <td>[0.43382695994437714, 0.41888225340762014, 0.4...</td>\n",
       "      <td>[-0.2662540111699422, -0.32736353595886286, -0...</td>\n",
       "      <td>[1058.5161705549458, 1022.0518310971496, 1046....</td>\n",
       "      <td>[277.12604062424435, 361.43900227746593, 354.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>740201.188294</td>\n",
       "      <td>12.169942</td>\n",
       "      <td>36.975236</td>\n",
       "      <td>762293.247617</td>\n",
       "      <td>[-0.015398247933078084, 0.0, -0.19655334726790...</td>\n",
       "      <td>[0.12473486237305755, 0.11464941529526103, 0.1...</td>\n",
       "      <td>[-1.9483364713228655, -2.0441047980937372, -1....</td>\n",
       "      <td>[304.34685034502166, 279.73886189614217, 295.9...</td>\n",
       "      <td>[1019.4067045180271, 1056.8874968004766, 1069....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>738916.991089</td>\n",
       "      <td>13.872905</td>\n",
       "      <td>35.076838</td>\n",
       "      <td>761271.469334</td>\n",
       "      <td>[-0.025152895763734938, 0.0, -0.06159632672767...</td>\n",
       "      <td>[0.06640255076294996, 0.0645660402431093, 0.06...</td>\n",
       "      <td>[-2.643309877939718, -2.673321969964289, -2.65...</td>\n",
       "      <td>[162.01891592373636, 157.53792174371847, 160.5...</td>\n",
       "      <td>[1151.8448436619483, 1171.0905813527158, 1204....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>732830.864974</td>\n",
       "      <td>18.873202</td>\n",
       "      <td>35.291262</td>\n",
       "      <td>758271.291080</td>\n",
       "      <td>[-0.030589481786886114, 0.0, -0.17586379324015...</td>\n",
       "      <td>[0.031539601822535575, 0.029024899054991345, 0...</td>\n",
       "      <td>[-3.4244591927580315, -3.5101467755557563, -3....</td>\n",
       "      <td>[76.95505725669655, 70.81930777739694, 74.8599...</td>\n",
       "      <td>[1250.6010335602036, 1242.250069722751, 1272.8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R(T)                                              R  average_profits  \\\n",
       "3     5  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]    754640.649196   \n",
       "4     6  [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]    752543.260006   \n",
       "5     7  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]    751802.712868   \n",
       "6     8  [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]    749217.568438   \n",
       "7     9  [7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]    746409.670845   \n",
       "2     4  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]    740201.188294   \n",
       "1     3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]    738916.991089   \n",
       "0     2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]    732830.864974   \n",
       "\n",
       "   average_losses  average_lefts  average_operation_profits  \\\n",
       "3        4.029129      25.299021              767177.735019   \n",
       "4        6.007143      24.608452              765990.926770   \n",
       "5        5.929278      26.693416              766037.645934   \n",
       "6        5.742898      33.715416              766149.473767   \n",
       "7        6.408640      38.737933              765750.028338   \n",
       "2       12.169942      36.975236              762293.247617   \n",
       "1       13.872905      35.076838              761271.469334   \n",
       "0       18.873202      35.291262              758271.291080   \n",
       "\n",
       "                                        alpha_values  \\\n",
       "3  [-0.009288359982061258, 0.0, -0.24536359809976...   \n",
       "4  [-0.007138407770080382, 0.0, -0.18981243836737...   \n",
       "5  [-0.004751909138388111, 0.0, -0.15845351916441...   \n",
       "6  [-0.0024003943457312003, 0.0, -0.1365799586581...   \n",
       "7  [-5.583752474166381e-05, 0.0, -0.1254201890354...   \n",
       "2  [-0.015398247933078084, 0.0, -0.19655334726790...   \n",
       "1  [-0.025152895763734938, 0.0, -0.06159632672767...   \n",
       "0  [-0.030589481786886114, 0.0, -0.17586379324015...   \n",
       "\n",
       "                                              F_vars  \\\n",
       "3  [0.19173215358508425, 0.17388448178539448, 0.1...   \n",
       "4  [0.24818006151816085, 0.2313282705799354, 0.24...   \n",
       "5  [0.309060153144241, 0.2928208891486767, 0.3036...   \n",
       "6  [0.3719398286264574, 0.35653140855184234, 0.36...   \n",
       "7  [0.43382695994437714, 0.41888225340762014, 0.4...   \n",
       "2  [0.12473486237305755, 0.11464941529526103, 0.1...   \n",
       "1  [0.06640255076294996, 0.0645660402431093, 0.06...   \n",
       "0  [0.031539601822535575, 0.029024899054991345, 0...   \n",
       "\n",
       "                                              f_vars  \\\n",
       "3  [-1.4387937098238643, -1.5583442622164778, -1....   \n",
       "4  [-1.1083423145468414, -1.2008262120505864, -1....   \n",
       "5  [-0.8045168393496075, -0.8817228508005526, -0....   \n",
       "6  [-0.5239038859814881, -0.5904508784033518, -0....   \n",
       "7  [-0.2662540111699422, -0.32736353595886286, -0...   \n",
       "2  [-1.9483364713228655, -2.0441047980937372, -1....   \n",
       "1  [-2.643309877939718, -2.673321969964289, -2.65...   \n",
       "0  [-3.4244591927580315, -3.5101467755557563, -3....   \n",
       "\n",
       "                                             Q0_vars  \\\n",
       "3  [467.81690333666074, 424.2694732526675, 452.96...   \n",
       "4  [605.5469866602498, 564.4294562670027, 591.655...   \n",
       "5  [754.0913773992096, 714.4683822321515, 740.781...   \n",
       "6  [907.5146531350173, 869.9188757453994, 894.938...   \n",
       "7  [1058.5161705549458, 1022.0518310971496, 1046....   \n",
       "2  [304.34685034502166, 279.73886189614217, 295.9...   \n",
       "1  [162.01891592373636, 157.53792174371847, 160.5...   \n",
       "0  [76.95505725669655, 70.81930777739694, 74.8599...   \n",
       "\n",
       "                                             Q1_vars  \n",
       "3  [873.6331233659653, 945.9120204294613, 943.990...  \n",
       "4  [735.3545139346106, 805.6378090567691, 805.432...  \n",
       "5  [582.7072169017061, 669.5793584981708, 660.658...  \n",
       "6  [425.72833752833543, 513.7715078693979, 508.01...  \n",
       "7  [277.12604062424435, 361.43900227746593, 354.8...  \n",
       "2  [1019.4067045180271, 1056.8874968004766, 1069....  \n",
       "1  [1151.8448436619483, 1171.0905813527158, 1204....  \n",
       "0  [1250.6010335602036, 1242.250069722751, 1272.8...  "
      ]
     },
     "execution_count": 1576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_2, stimulation_results_df_2 = None, None\n",
    "results_df_2, stimulation_results_df_2 = grid_flexible_F_fixed_R(\n",
    "    assigned_Ts=ASSIGNED_TS,\n",
    "    salvage_value=salvage_value,\n",
    "    cost=cost,\n",
    "    price=price,\n",
    "    Q_star=Q_star,\n",
    "    demand_df_train=demand_df_test,\n",
    "    Qk_hat_df_train=Qk_hat_df_test,\n",
    "    training_df=testing_df,\n",
    ")\n",
    "\n",
    "results_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1577,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_vars 中有 -1 的個數： 3\n"
     ]
    }
   ],
   "source": [
    "num_neg_ones = results_df_2.iloc[0][\"F_vars\"].count(-1)\n",
    "print(\"F_vars 中有 -1 的個數：\", num_neg_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1805.5631358435871)"
      ]
     },
     "execution_count": 1578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_star * 0.74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "      <th>sum_first_8</th>\n",
       "      <th>sum</th>\n",
       "      <th>Lost_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76.726007</td>\n",
       "      <td>85.292909</td>\n",
       "      <td>133.499628</td>\n",
       "      <td>142.686827</td>\n",
       "      <td>151.989907</td>\n",
       "      <td>148.099649</td>\n",
       "      <td>147.917016</td>\n",
       "      <td>153.114936</td>\n",
       "      <td>149.021591</td>\n",
       "      <td>145.097141</td>\n",
       "      <td>1039.326879</td>\n",
       "      <td>1333.445611</td>\n",
       "      <td>571.509976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73.215452</td>\n",
       "      <td>84.322469</td>\n",
       "      <td>140.436462</td>\n",
       "      <td>147.706836</td>\n",
       "      <td>153.427440</td>\n",
       "      <td>155.765750</td>\n",
       "      <td>155.706461</td>\n",
       "      <td>157.681604</td>\n",
       "      <td>157.247505</td>\n",
       "      <td>159.518788</td>\n",
       "      <td>1068.262475</td>\n",
       "      <td>1385.028768</td>\n",
       "      <td>643.993002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.614354</td>\n",
       "      <td>93.288630</td>\n",
       "      <td>142.735808</td>\n",
       "      <td>149.774088</td>\n",
       "      <td>154.774819</td>\n",
       "      <td>155.977932</td>\n",
       "      <td>156.344506</td>\n",
       "      <td>152.764874</td>\n",
       "      <td>157.058150</td>\n",
       "      <td>156.135556</td>\n",
       "      <td>1087.275011</td>\n",
       "      <td>1400.468717</td>\n",
       "      <td>634.305196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.997127</td>\n",
       "      <td>65.378692</td>\n",
       "      <td>122.601776</td>\n",
       "      <td>137.369862</td>\n",
       "      <td>143.971341</td>\n",
       "      <td>145.596807</td>\n",
       "      <td>148.718305</td>\n",
       "      <td>148.766359</td>\n",
       "      <td>147.117258</td>\n",
       "      <td>151.321785</td>\n",
       "      <td>966.400270</td>\n",
       "      <td>1264.839313</td>\n",
       "      <td>967.400270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.623523</td>\n",
       "      <td>88.635007</td>\n",
       "      <td>129.643968</td>\n",
       "      <td>136.108997</td>\n",
       "      <td>141.327015</td>\n",
       "      <td>142.297723</td>\n",
       "      <td>143.193646</td>\n",
       "      <td>140.258585</td>\n",
       "      <td>143.374846</td>\n",
       "      <td>140.789340</td>\n",
       "      <td>1001.088464</td>\n",
       "      <td>1285.252650</td>\n",
       "      <td>547.853087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   demand_t1  demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "0  76.726007  85.292909  133.499628  142.686827  151.989907  148.099649   \n",
       "1  73.215452  84.322469  140.436462  147.706836  153.427440  155.765750   \n",
       "2  81.614354  93.288630  142.735808  149.774088  154.774819  155.977932   \n",
       "3  53.997127  65.378692  122.601776  137.369862  143.971341  145.596807   \n",
       "4  79.623523  88.635007  129.643968  136.108997  141.327015  142.297723   \n",
       "\n",
       "    demand_t7   demand_t8   demand_t9  demand_t10  sum_first_8          sum  \\\n",
       "0  147.917016  153.114936  149.021591  145.097141  1039.326879  1333.445611   \n",
       "1  155.706461  157.681604  157.247505  159.518788  1068.262475  1385.028768   \n",
       "2  156.344506  152.764874  157.058150  156.135556  1087.275011  1400.468717   \n",
       "3  148.718305  148.766359  147.117258  151.321785   966.400270  1264.839313   \n",
       "4  143.193646  140.258585  143.374846  140.789340  1001.088464  1285.252650   \n",
       "\n",
       "       Lost_0  \n",
       "0  571.509976  \n",
       "1  643.993002  \n",
       "2  634.305196  \n",
       "3  967.400270  \n",
       "4  547.853087  "
      ]
     },
     "execution_count": 1579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df_test_analysis = demand_df_test.copy()\n",
    "demand_df_test_analysis[\"sum_first_8\"] = demand_df_test_analysis.iloc[:, :8].sum(axis=1)\n",
    "demand_df_test_analysis[\"sum\"] = demand_df_test_analysis.iloc[:, :10].sum(axis=1)\n",
    "\n",
    "demand_df_test_analysis[\"Lost_0\"] = (\n",
    "    demand_df_test_analysis[\"sum_first_8\"] - results_df_2.iloc[0][\"Q0_vars\"]\n",
    ")\n",
    "demand_df_test_analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "      <th>sum_first_8</th>\n",
       "      <th>sum</th>\n",
       "      <th>Lost_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76.726007</td>\n",
       "      <td>85.292909</td>\n",
       "      <td>133.499628</td>\n",
       "      <td>142.686827</td>\n",
       "      <td>151.989907</td>\n",
       "      <td>148.099649</td>\n",
       "      <td>147.917016</td>\n",
       "      <td>153.114936</td>\n",
       "      <td>149.021591</td>\n",
       "      <td>145.097141</td>\n",
       "      <td>1039.326879</td>\n",
       "      <td>1333.445611</td>\n",
       "      <td>571.509976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73.215452</td>\n",
       "      <td>84.322469</td>\n",
       "      <td>140.436462</td>\n",
       "      <td>147.706836</td>\n",
       "      <td>153.427440</td>\n",
       "      <td>155.765750</td>\n",
       "      <td>155.706461</td>\n",
       "      <td>157.681604</td>\n",
       "      <td>157.247505</td>\n",
       "      <td>159.518788</td>\n",
       "      <td>1068.262475</td>\n",
       "      <td>1385.028768</td>\n",
       "      <td>643.993002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.614354</td>\n",
       "      <td>93.288630</td>\n",
       "      <td>142.735808</td>\n",
       "      <td>149.774088</td>\n",
       "      <td>154.774819</td>\n",
       "      <td>155.977932</td>\n",
       "      <td>156.344506</td>\n",
       "      <td>152.764874</td>\n",
       "      <td>157.058150</td>\n",
       "      <td>156.135556</td>\n",
       "      <td>1087.275011</td>\n",
       "      <td>1400.468717</td>\n",
       "      <td>634.305196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.997127</td>\n",
       "      <td>65.378692</td>\n",
       "      <td>122.601776</td>\n",
       "      <td>137.369862</td>\n",
       "      <td>143.971341</td>\n",
       "      <td>145.596807</td>\n",
       "      <td>148.718305</td>\n",
       "      <td>148.766359</td>\n",
       "      <td>147.117258</td>\n",
       "      <td>151.321785</td>\n",
       "      <td>966.400270</td>\n",
       "      <td>1264.839313</td>\n",
       "      <td>967.400270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.623523</td>\n",
       "      <td>88.635007</td>\n",
       "      <td>129.643968</td>\n",
       "      <td>136.108997</td>\n",
       "      <td>141.327015</td>\n",
       "      <td>142.297723</td>\n",
       "      <td>143.193646</td>\n",
       "      <td>140.258585</td>\n",
       "      <td>143.374846</td>\n",
       "      <td>140.789340</td>\n",
       "      <td>1001.088464</td>\n",
       "      <td>1285.252650</td>\n",
       "      <td>547.853087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>66.573648</td>\n",
       "      <td>73.473881</td>\n",
       "      <td>116.509127</td>\n",
       "      <td>130.907484</td>\n",
       "      <td>138.170199</td>\n",
       "      <td>139.414829</td>\n",
       "      <td>143.089660</td>\n",
       "      <td>141.209537</td>\n",
       "      <td>141.000788</td>\n",
       "      <td>144.971862</td>\n",
       "      <td>949.348366</td>\n",
       "      <td>1235.321016</td>\n",
       "      <td>531.095422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>61.543065</td>\n",
       "      <td>69.925424</td>\n",
       "      <td>118.981441</td>\n",
       "      <td>128.541003</td>\n",
       "      <td>130.878560</td>\n",
       "      <td>138.357764</td>\n",
       "      <td>139.188552</td>\n",
       "      <td>143.200519</td>\n",
       "      <td>140.266246</td>\n",
       "      <td>142.386797</td>\n",
       "      <td>930.616328</td>\n",
       "      <td>1213.269370</td>\n",
       "      <td>528.483924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>77.934606</td>\n",
       "      <td>89.308782</td>\n",
       "      <td>127.931099</td>\n",
       "      <td>137.811266</td>\n",
       "      <td>140.377104</td>\n",
       "      <td>143.458587</td>\n",
       "      <td>144.180047</td>\n",
       "      <td>142.103770</td>\n",
       "      <td>144.426712</td>\n",
       "      <td>143.175555</td>\n",
       "      <td>1003.105260</td>\n",
       "      <td>1290.707528</td>\n",
       "      <td>539.902104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>61.555771</td>\n",
       "      <td>65.481206</td>\n",
       "      <td>76.431186</td>\n",
       "      <td>141.016287</td>\n",
       "      <td>148.612409</td>\n",
       "      <td>155.152840</td>\n",
       "      <td>160.099228</td>\n",
       "      <td>158.393803</td>\n",
       "      <td>158.380157</td>\n",
       "      <td>160.635284</td>\n",
       "      <td>966.742732</td>\n",
       "      <td>1285.758172</td>\n",
       "      <td>608.391562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>71.879524</td>\n",
       "      <td>75.816228</td>\n",
       "      <td>88.691319</td>\n",
       "      <td>125.840719</td>\n",
       "      <td>138.654339</td>\n",
       "      <td>137.945803</td>\n",
       "      <td>139.968061</td>\n",
       "      <td>144.014399</td>\n",
       "      <td>140.495582</td>\n",
       "      <td>140.628759</td>\n",
       "      <td>922.810390</td>\n",
       "      <td>1203.934731</td>\n",
       "      <td>545.160679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>62.698196</td>\n",
       "      <td>78.611085</td>\n",
       "      <td>139.791254</td>\n",
       "      <td>143.076516</td>\n",
       "      <td>142.163674</td>\n",
       "      <td>150.919528</td>\n",
       "      <td>145.896928</td>\n",
       "      <td>149.493779</td>\n",
       "      <td>152.352166</td>\n",
       "      <td>146.679443</td>\n",
       "      <td>1012.650959</td>\n",
       "      <td>1311.682568</td>\n",
       "      <td>585.377807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>64.781553</td>\n",
       "      <td>72.263140</td>\n",
       "      <td>83.800937</td>\n",
       "      <td>130.848821</td>\n",
       "      <td>141.944226</td>\n",
       "      <td>142.279298</td>\n",
       "      <td>146.301937</td>\n",
       "      <td>144.274959</td>\n",
       "      <td>144.628356</td>\n",
       "      <td>146.560884</td>\n",
       "      <td>926.494872</td>\n",
       "      <td>1217.684113</td>\n",
       "      <td>927.494872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>75.532997</td>\n",
       "      <td>88.519768</td>\n",
       "      <td>134.606680</td>\n",
       "      <td>145.260208</td>\n",
       "      <td>152.214092</td>\n",
       "      <td>151.198150</td>\n",
       "      <td>151.674544</td>\n",
       "      <td>151.286388</td>\n",
       "      <td>152.224362</td>\n",
       "      <td>152.695641</td>\n",
       "      <td>1050.292826</td>\n",
       "      <td>1355.212829</td>\n",
       "      <td>1051.292826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>61.766267</td>\n",
       "      <td>71.418492</td>\n",
       "      <td>79.609229</td>\n",
       "      <td>136.806694</td>\n",
       "      <td>149.697938</td>\n",
       "      <td>149.059237</td>\n",
       "      <td>151.665693</td>\n",
       "      <td>152.244795</td>\n",
       "      <td>151.654347</td>\n",
       "      <td>150.452055</td>\n",
       "      <td>952.268345</td>\n",
       "      <td>1254.374747</td>\n",
       "      <td>576.081967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>68.819794</td>\n",
       "      <td>74.071775</td>\n",
       "      <td>80.358485</td>\n",
       "      <td>123.003555</td>\n",
       "      <td>129.832291</td>\n",
       "      <td>140.982057</td>\n",
       "      <td>145.590577</td>\n",
       "      <td>148.889060</td>\n",
       "      <td>145.948128</td>\n",
       "      <td>145.404458</td>\n",
       "      <td>911.547594</td>\n",
       "      <td>1202.900180</td>\n",
       "      <td>587.287806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    demand_t1  demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "0   76.726007  85.292909  133.499628  142.686827  151.989907  148.099649   \n",
       "1   73.215452  84.322469  140.436462  147.706836  153.427440  155.765750   \n",
       "2   81.614354  93.288630  142.735808  149.774088  154.774819  155.977932   \n",
       "3   53.997127  65.378692  122.601776  137.369862  143.971341  145.596807   \n",
       "4   79.623523  88.635007  129.643968  136.108997  141.327015  142.297723   \n",
       "5   66.573648  73.473881  116.509127  130.907484  138.170199  139.414829   \n",
       "6   61.543065  69.925424  118.981441  128.541003  130.878560  138.357764   \n",
       "7   77.934606  89.308782  127.931099  137.811266  140.377104  143.458587   \n",
       "8   61.555771  65.481206   76.431186  141.016287  148.612409  155.152840   \n",
       "9   71.879524  75.816228   88.691319  125.840719  138.654339  137.945803   \n",
       "10  62.698196  78.611085  139.791254  143.076516  142.163674  150.919528   \n",
       "11  64.781553  72.263140   83.800937  130.848821  141.944226  142.279298   \n",
       "12  75.532997  88.519768  134.606680  145.260208  152.214092  151.198150   \n",
       "13  61.766267  71.418492   79.609229  136.806694  149.697938  149.059237   \n",
       "14  68.819794  74.071775   80.358485  123.003555  129.832291  140.982057   \n",
       "\n",
       "     demand_t7   demand_t8   demand_t9  demand_t10  sum_first_8          sum  \\\n",
       "0   147.917016  153.114936  149.021591  145.097141  1039.326879  1333.445611   \n",
       "1   155.706461  157.681604  157.247505  159.518788  1068.262475  1385.028768   \n",
       "2   156.344506  152.764874  157.058150  156.135556  1087.275011  1400.468717   \n",
       "3   148.718305  148.766359  147.117258  151.321785   966.400270  1264.839313   \n",
       "4   143.193646  140.258585  143.374846  140.789340  1001.088464  1285.252650   \n",
       "5   143.089660  141.209537  141.000788  144.971862   949.348366  1235.321016   \n",
       "6   139.188552  143.200519  140.266246  142.386797   930.616328  1213.269370   \n",
       "7   144.180047  142.103770  144.426712  143.175555  1003.105260  1290.707528   \n",
       "8   160.099228  158.393803  158.380157  160.635284   966.742732  1285.758172   \n",
       "9   139.968061  144.014399  140.495582  140.628759   922.810390  1203.934731   \n",
       "10  145.896928  149.493779  152.352166  146.679443  1012.650959  1311.682568   \n",
       "11  146.301937  144.274959  144.628356  146.560884   926.494872  1217.684113   \n",
       "12  151.674544  151.286388  152.224362  152.695641  1050.292826  1355.212829   \n",
       "13  151.665693  152.244795  151.654347  150.452055   952.268345  1254.374747   \n",
       "14  145.590577  148.889060  145.948128  145.404458   911.547594  1202.900180   \n",
       "\n",
       "         Lost_0  \n",
       "0    571.509976  \n",
       "1    643.993002  \n",
       "2    634.305196  \n",
       "3    967.400270  \n",
       "4    547.853087  \n",
       "5    531.095422  \n",
       "6    528.483924  \n",
       "7    539.902104  \n",
       "8    608.391562  \n",
       "9    545.160679  \n",
       "10   585.377807  \n",
       "11   927.494872  \n",
       "12  1051.292826  \n",
       "13   576.081967  \n",
       "14   587.287806  "
      ]
     },
     "execution_count": 1580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df_test_analysis[demand_df_test_analysis[\"Lost_0\"] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R(T)                                                                         5\n",
       "R                                [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
       "average_profits                                                  754640.649196\n",
       "average_losses                                                        4.029129\n",
       "average_lefts                                                        25.299021\n",
       "average_operation_profits                                        767177.735019\n",
       "alpha_values                 [-0.009288359982061258, 0.0, -0.24536359809976...\n",
       "F_vars                       [0.19173215358508425, 0.17388448178539448, 0.1...\n",
       "f_vars                       [-1.4387937098238643, -1.5583442622164778, -1....\n",
       "Q0_vars                      [467.81690333666074, 424.2694732526675, 452.96...\n",
       "Q1_vars                      [873.6331233659653, 945.9120204294613, 943.990...\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 1581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demand_df_test_analysis.head()\n",
    "results_df_2.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00928836,  0.        , -0.2453636 ,  0.        ])"
      ]
     },
     "execution_count": 1582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_values = results_df_2.iloc[0][\"alpha_values\"]\n",
    "alpha_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### S12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1583,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 667 and 669 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 667 and 669 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 435 rows, 741 columns and 1830 nonzeros\n",
      "Model fingerprint: 0x50e61fa6\n",
      "Model has 240 general constraints\n",
      "Variable types: 621 continuous, 120 integer (120 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 5e+06]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e-03, 1e+00]\n",
      "  GenCon coe range [1e+00, 1e+00]\n",
      "Presolve removed 22 rows and 219 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 533 rows, 523 columns, 1907 nonzeros\n",
      "Presolved model has 198 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 325 continuous, 198 integer (198 binary)\n",
      "\n",
      "Root relaxation: objective 2.178898e+07, 235 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1789e+07    0   49          - 2.1789e+07      -     -    0s\n",
      "     0     2 2.1789e+07    0   49          - 2.1789e+07      -     -    0s\n",
      "* 1964  1361              99    2.010459e+07 2.1785e+07  8.36%   3.6    0s\n",
      "H 2601  1724                    2.014654e+07 2.1784e+07  8.13%   3.4    0s\n",
      "H 2867  1724                    2.014654e+07 2.1784e+07  8.13%   3.5    0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_65248/348315154.py:156: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H 3952  1772                    2.015352e+07 2.1784e+07  8.09%   3.6    0s\n",
      "H 6137  1659                    2.040034e+07 2.1782e+07  6.77%   4.2    0s\n",
      "H 6683  1679                    2.044642e+07 2.1778e+07  6.51%   4.4    0s\n",
      "H 6696  1600                    2.044642e+07 2.1778e+07  6.51%   4.4    0s\n",
      "H 6826  1487                    2.044642e+07 2.1778e+07  6.51%   4.5    0s\n",
      "* 8373  2154             108    2.044862e+07 2.1777e+07  6.50%   4.8    0s\n",
      "* 8374  2154             108    2.044891e+07 2.1777e+07  6.50%   4.8    0s\n",
      "* 8379  2154             108    2.044948e+07 2.1777e+07  6.49%   4.8    0s\n",
      "* 8380  2154             108    2.044981e+07 2.1777e+07  6.49%   4.8    0s\n",
      "H 8532  2219                    2.047836e+07 2.1777e+07  6.34%   4.9    0s\n",
      "*11293  3190              70    2.051011e+07 2.1774e+07  6.16%   5.3    0s\n",
      "H11484  2999                    2.070070e+07 2.1774e+07  5.18%   5.3    0s\n",
      "*13698  3631              94    2.077887e+07 2.1772e+07  4.78%   5.6    0s\n",
      "H14136  3546                    2.085722e+07 2.1772e+07  4.38%   5.7    0s\n",
      "*17295  3192              54    2.120999e+07 2.1769e+07  2.63%   6.0    1s\n",
      "H17559  3221                    2.122200e+07 2.1769e+07  2.58%   6.1    1s\n",
      "H18859  3404                    2.122282e+07 2.1768e+07  2.57%   6.2    1s\n",
      "*19910  2540              83    2.143781e+07 2.1766e+07  1.53%   6.3    1s\n",
      "H20377  2223                    2.150060e+07 2.1765e+07  1.23%   6.4    1s\n",
      "H21670  2214                    2.150060e+07 2.1759e+07  1.20%   6.9    1s\n",
      "*24807  1687              74    2.153532e+07 2.1734e+07  0.92%   8.3    1s\n",
      "\n",
      "Cutting planes:\n",
      "  Cover: 4\n",
      "  Implied bound: 1\n",
      "\n",
      "Explored 25150 nodes (214546 simplex iterations) in 1.56 seconds (2.59 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 10: 2.15353e+07 2.15006e+07 2.15006e+07 ... 2.07007e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.153532113667e+07, best bound 2.172485664277e+07, gap 0.8801%\n",
      "\n",
      "model.status is optimal: True\n",
      "model.status is TIME_LIMIT: False\n",
      "\n",
      "f_vars[i]: 0.6568, F_vars[i]: 0.6585, Q0_vars[i]: 1606.7882\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.6732, F_vars[i]: 0.6622, Q0_vars[i]: 1615.7778\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.4886, F_vars[i]: 0.6198, Q0_vars[i]: 1512.2412\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.6638, F_vars[i]: 0.6601, Q0_vars[i]: 1610.6394\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.6440, F_vars[i]: 0.6557, Q0_vars[i]: 1599.7978\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.5859, F_vars[i]: 0.6424, Q0_vars[i]: 1567.4574\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.4330, F_vars[i]: 0.6066, Q0_vars[i]: 1480.0284\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.6777, F_vars[i]: 0.6632, Q0_vars[i]: 1618.2251\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.4272, F_vars[i]: 0.6052, Q0_vars[i]: 1476.6897\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.6780, F_vars[i]: 0.6633, Q0_vars[i]: 1618.4098\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.3804, F_vars[i]: 0.5940, Q0_vars[i]: 1449.2614\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.5521, F_vars[i]: 0.6346, Q0_vars[i]: 1548.4338\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.3803, F_vars[i]: 0.5939, Q0_vars[i]: 1449.2014\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.5060, F_vars[i]: 0.6239, Q0_vars[i]: 1522.2273\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.4606, F_vars[i]: 0.6132, Q0_vars[i]: 1496.0678\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.001\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "all_Rs: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_profits</th>\n",
       "      <th>average_losses</th>\n",
       "      <th>average_lefts</th>\n",
       "      <th>average_operation_profits</th>\n",
       "      <th>alpha_values</th>\n",
       "      <th>beta_values</th>\n",
       "      <th>tau_values</th>\n",
       "      <th>gamma_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.435688e+06</td>\n",
       "      <td>7.708805</td>\n",
       "      <td>20.592702</td>\n",
       "      <td>1.448550e+06</td>\n",
       "      <td>[0.006898665065614452, 0.0, -0.169026921386503...</td>\n",
       "      <td>[[-4e-06, 0.0, 0.0, 0.0], [-4e-06, 0.0, 0.0, 0...</td>\n",
       "      <td>[[-0.001, -0.001, -0.001, -0.001, -0.001, -0.0...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   average_profits  average_losses  average_lefts  average_operation_profits  \\\n",
       "0     1.435688e+06        7.708805      20.592702               1.448550e+06   \n",
       "\n",
       "                                        alpha_values  \\\n",
       "0  [0.006898665065614452, 0.0, -0.169026921386503...   \n",
       "\n",
       "                                         beta_values  \\\n",
       "0  [[-4e-06, 0.0, 0.0, 0.0], [-4e-06, 0.0, 0.0, 0...   \n",
       "\n",
       "                                          tau_values gamma_values  \n",
       "0  [[-0.001, -0.001, -0.001, -0.001, -0.001, -0.0...         None  "
      ]
     },
     "execution_count": 1583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_12, stimulation_results_df_12 = None, None\n",
    "results_df_12, stimulation_results_df_12 = fully_flexible_beta_with_softmax_12(\n",
    "    salvage_value=salvage_value,\n",
    "    cost=cost,\n",
    "    price=price,\n",
    "    Q_star=Q_star,\n",
    "    demand_df_train=demand_df_train,\n",
    "    Qk_hat_df=Qk_hat_df_train,\n",
    "    training_df=training_df,\n",
    ")\n",
    "\n",
    "results_df_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1584,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R(T)</th>\n",
       "      <th>F</th>\n",
       "      <th>f_values</th>\n",
       "      <th>profits</th>\n",
       "      <th>losses</th>\n",
       "      <th>lefts</th>\n",
       "      <th>operation_profits</th>\n",
       "      <th>Q0</th>\n",
       "      <th>Q1</th>\n",
       "      <th>hc0</th>\n",
       "      <th>hc1</th>\n",
       "      <th>Left0s</th>\n",
       "      <th>Left1s</th>\n",
       "      <th>lost0s</th>\n",
       "      <th>lost1s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0.658533</td>\n",
       "      <td>0.656764</td>\n",
       "      <td>1.483629e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.245391</td>\n",
       "      <td>1.487727e+06</td>\n",
       "      <td>1606.787665</td>\n",
       "      <td>878.759919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.243564</td>\n",
       "      <td>6.001827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0.662217</td>\n",
       "      <td>0.673192</td>\n",
       "      <td>1.419206e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>79.972211</td>\n",
       "      <td>1.451195e+06</td>\n",
       "      <td>1615.777638</td>\n",
       "      <td>811.412576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.439522</td>\n",
       "      <td>8.532688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>0.619784</td>\n",
       "      <td>0.488630</td>\n",
       "      <td>1.423077e+06</td>\n",
       "      <td>4.885578</td>\n",
       "      <td>17.875286</td>\n",
       "      <td>1.433159e+06</td>\n",
       "      <td>1512.241261</td>\n",
       "      <td>894.231918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.875286</td>\n",
       "      <td>4.885578</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0.660112</td>\n",
       "      <td>0.663791</td>\n",
       "      <td>1.478468e+06</td>\n",
       "      <td>10.285009</td>\n",
       "      <td>14.045696</td>\n",
       "      <td>1.490257e+06</td>\n",
       "      <td>1610.639198</td>\n",
       "      <td>873.122829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.045696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.285009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0.655668</td>\n",
       "      <td>0.644049</td>\n",
       "      <td>1.487909e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.692970</td>\n",
       "      <td>1.491786e+06</td>\n",
       "      <td>1599.797669</td>\n",
       "      <td>894.586145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.619141</td>\n",
       "      <td>8.073829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>0.642414</td>\n",
       "      <td>0.585856</td>\n",
       "      <td>1.418271e+06</td>\n",
       "      <td>40.463233</td>\n",
       "      <td>53.169738</td>\n",
       "      <td>1.463816e+06</td>\n",
       "      <td>1567.457437</td>\n",
       "      <td>925.406397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.169738</td>\n",
       "      <td>40.463233</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.606581</td>\n",
       "      <td>0.432965</td>\n",
       "      <td>1.409512e+06</td>\n",
       "      <td>15.691585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.418927e+06</td>\n",
       "      <td>1480.028310</td>\n",
       "      <td>884.850620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.632644</td>\n",
       "      <td>1.058942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.663221</td>\n",
       "      <td>0.677679</td>\n",
       "      <td>1.504127e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.815930</td>\n",
       "      <td>1.504854e+06</td>\n",
       "      <td>1618.225080</td>\n",
       "      <td>891.680150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.815930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.605213</td>\n",
       "      <td>0.427234</td>\n",
       "      <td>1.387365e+06</td>\n",
       "      <td>12.374515</td>\n",
       "      <td>19.136861</td>\n",
       "      <td>1.402445e+06</td>\n",
       "      <td>1476.689663</td>\n",
       "      <td>860.717939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.136861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.374515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>0.663296</td>\n",
       "      <td>0.678018</td>\n",
       "      <td>1.509417e+06</td>\n",
       "      <td>4.466222</td>\n",
       "      <td>5.455382</td>\n",
       "      <td>1.514279e+06</td>\n",
       "      <td>1618.409690</td>\n",
       "      <td>905.388824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.455382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.466222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>0.593972</td>\n",
       "      <td>0.380409</td>\n",
       "      <td>1.387220e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.644548</td>\n",
       "      <td>1.391478e+06</td>\n",
       "      <td>1449.261193</td>\n",
       "      <td>877.204216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.309409</td>\n",
       "      <td>7.335139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>0.634617</td>\n",
       "      <td>0.552075</td>\n",
       "      <td>1.431350e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.075895</td>\n",
       "      <td>1.443780e+06</td>\n",
       "      <td>1548.433558</td>\n",
       "      <td>862.020503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.922618</td>\n",
       "      <td>4.153277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>0.593947</td>\n",
       "      <td>0.380307</td>\n",
       "      <td>1.387388e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.233265</td>\n",
       "      <td>1.391482e+06</td>\n",
       "      <td>1449.201182</td>\n",
       "      <td>875.180827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.987105</td>\n",
       "      <td>5.246160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>0.623876</td>\n",
       "      <td>0.506034</td>\n",
       "      <td>1.414177e+06</td>\n",
       "      <td>27.465930</td>\n",
       "      <td>20.761807</td>\n",
       "      <td>1.438961e+06</td>\n",
       "      <td>1522.227319</td>\n",
       "      <td>896.803008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.761807</td>\n",
       "      <td>27.465930</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>0.613155</td>\n",
       "      <td>0.460594</td>\n",
       "      <td>1.394204e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.765545</td>\n",
       "      <td>1.404110e+06</td>\n",
       "      <td>1496.067483</td>\n",
       "      <td>867.637586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.244407</td>\n",
       "      <td>23.521138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    R(T)         F  f_values       profits     losses      lefts  \\\n",
       "0      8  0.658533  0.656764  1.483629e+06   0.000000  10.245391   \n",
       "1      8  0.662217  0.673192  1.419206e+06   0.000000  79.972211   \n",
       "2      8  0.619784  0.488630  1.423077e+06   4.885578  17.875286   \n",
       "3      8  0.660112  0.663791  1.478468e+06  10.285009  14.045696   \n",
       "4      8  0.655668  0.644049  1.487909e+06   0.000000   9.692970   \n",
       "5      8  0.642414  0.585856  1.418271e+06  40.463233  53.169738   \n",
       "6      8  0.606581  0.432965  1.409512e+06  15.691585   0.000000   \n",
       "7      8  0.663221  0.677679  1.504127e+06   0.000000   1.815930   \n",
       "8      8  0.605213  0.427234  1.387365e+06  12.374515  19.136861   \n",
       "9      8  0.663296  0.678018  1.509417e+06   4.466222   5.455382   \n",
       "10     8  0.593972  0.380409  1.387220e+06   0.000000  10.644548   \n",
       "11     8  0.634617  0.552075  1.431350e+06   0.000000  31.075895   \n",
       "12     8  0.593947  0.380307  1.387388e+06   0.000000  10.233265   \n",
       "13     8  0.623876  0.506034  1.414177e+06  27.465930  20.761807   \n",
       "14     8  0.613155  0.460594  1.394204e+06   0.000000  24.765545   \n",
       "\n",
       "    operation_profits           Q0          Q1  hc0  hc1     Left0s  \\\n",
       "0        1.487727e+06  1606.787665  878.759919  0.0  0.0   4.243564   \n",
       "1        1.451195e+06  1615.777638  811.412576  0.0  0.0  71.439522   \n",
       "2        1.433159e+06  1512.241261  894.231918  0.0  0.0   0.000000   \n",
       "3        1.490257e+06  1610.639198  873.122829  0.0  0.0  14.045696   \n",
       "4        1.491786e+06  1599.797669  894.586145  0.0  0.0   1.619141   \n",
       "5        1.463816e+06  1567.457437  925.406397  0.0  0.0   0.000000   \n",
       "6        1.418927e+06  1480.028310  884.850620  0.0  0.0   0.000000   \n",
       "7        1.504854e+06  1618.225080  891.680150  0.0  0.0   0.000000   \n",
       "8        1.402445e+06  1476.689663  860.717939  0.0  0.0  19.136861   \n",
       "9        1.514279e+06  1618.409690  905.388824  0.0  0.0   5.455382   \n",
       "10       1.391478e+06  1449.261193  877.204216  0.0  0.0   3.309409   \n",
       "11       1.443780e+06  1548.433558  862.020503  0.0  0.0  26.922618   \n",
       "12       1.391482e+06  1449.201182  875.180827  0.0  0.0   4.987105   \n",
       "13       1.438961e+06  1522.227319  896.803008  0.0  0.0   0.000000   \n",
       "14       1.404110e+06  1496.067483  867.637586  0.0  0.0   1.244407   \n",
       "\n",
       "       Left1s     lost0s     lost1s  \n",
       "0    6.001827   0.000000   0.000000  \n",
       "1    8.532688   0.000000   0.000000  \n",
       "2   17.875286   4.885578   0.000000  \n",
       "3    0.000000   0.000000  10.285009  \n",
       "4    8.073829   0.000000   0.000000  \n",
       "5   53.169738  40.463233   0.000000  \n",
       "6    0.000000  14.632644   1.058942  \n",
       "7    1.815930   0.000000   0.000000  \n",
       "8    0.000000   0.000000  12.374515  \n",
       "9    0.000000   0.000000   4.466222  \n",
       "10   7.335139   0.000000   0.000000  \n",
       "11   4.153277   0.000000   0.000000  \n",
       "12   5.246160   0.000000   0.000000  \n",
       "13  20.761807  27.465930   0.000000  \n",
       "14  23.521138   0.000000   0.000000  "
      ]
     },
     "execution_count": 1584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stimulation_results_df_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 667 and 669 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 667 and 669 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 435 rows, 741 columns and 1965 nonzeros\n",
      "Model fingerprint: 0xbd28005d\n",
      "Model has 240 general constraints\n",
      "Variable types: 621 continuous, 120 integer (120 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 5e+06]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e-03, 1e+00]\n",
      "  GenCon coe range [1e+00, 1e+00]\n",
      "Presolve removed 16 rows and 209 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 539 rows, 533 columns, 1925 nonzeros\n",
      "Presolved model has 202 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 331 continuous, 202 integer (202 binary)\n",
      "\n",
      "Root relaxation: objective 1.154314e+07, 211 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 1.1543e+07    0   44          - 1.1543e+07      -     -    0s\n",
      "     0     2 1.1543e+07    0   44          - 1.1543e+07      -     -    0s\n",
      "H 2718  1594                    1.067486e+07 1.1541e+07  8.11%   3.8    0s\n",
      "H 2746  1541                    1.098796e+07 1.1541e+07  5.03%   4.0    0s\n",
      "H 2749  1464                    1.098797e+07 1.1541e+07  5.03%   4.0    0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_65248/348315154.py:156: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H 6341  1615                    1.098797e+07 1.1541e+07  5.03%   6.0    0s\n",
      "*10779  3263              86    1.109520e+07 1.1540e+07  4.01%   6.1    0s\n",
      "H11315  3513                    1.109757e+07 1.1540e+07  3.99%   6.1    0s\n",
      "*11541  3259              82    1.114628e+07 1.1540e+07  3.53%   6.1    0s\n",
      "H11795  3349                    1.115357e+07 1.1540e+07  3.46%   6.2    0s\n",
      "H11816  3349                    1.115357e+07 1.1540e+07  3.46%   6.2    0s\n",
      "H11950  3349                    1.115357e+07 1.1540e+07  3.46%   6.2    0s\n",
      "*12349  3375              82    1.117198e+07 1.1540e+07  3.29%   6.3    0s\n",
      "*12422  3086              84    1.121008e+07 1.1540e+07  2.94%   6.3    0s\n",
      "H12616  3068                    1.122496e+07 1.1540e+07  2.81%   6.4    0s\n",
      "*18253  4058             109    1.129678e+07 1.1534e+07  2.10%   7.5    1s\n",
      "H18713  4056                    1.130842e+07 1.1534e+07  1.99%   7.7    1s\n",
      "H25369  5373                    1.130944e+07 1.1520e+07  1.86%   9.0    1s\n",
      "*25373  5373              68    1.130944e+07 1.1520e+07  1.86%   9.0    1s\n",
      "H25727  5373                    1.131646e+07 1.1518e+07  1.78%   9.0    1s\n",
      "H25783  5373                    1.131646e+07 1.1518e+07  1.78%   9.0    1s\n",
      "*38154  6265              78    1.131880e+07 1.1487e+07  1.49%  10.5    2s\n",
      "*38163  6264              82    1.131889e+07 1.1487e+07  1.49%  10.5    2s\n",
      "H39508  6148                    1.132195e+07 1.1482e+07  1.42%  10.7    2s\n",
      "H39508  6148                    1.132195e+07 1.1482e+07  1.42%  10.7    2s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 7\n",
      "\n",
      "Explored 53821 nodes (670331 simplex iterations) in 3.60 seconds (6.72 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 10: 1.1322e+07 1.1322e+07 1.13189e+07 ... 1.12968e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 1.132195184340e+07, best bound 1.143112078217e+07, gap 0.9642%\n",
      "\n",
      "model.status is optimal: True\n",
      "model.status is TIME_LIMIT: False\n",
      "\n",
      "f_vars[i]: -1.4506, F_vars[i]: 0.1899, Q0_vars[i]: 463.3667\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -1.0\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -2.0783755845086413\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -2.0783755845086413\n",
      "第 5 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -1.0\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -2.0783755845086413\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.5386356918962771\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -2.0783755845086413\n",
      "*** 於第[5]天進貨 ***\n",
      "\n",
      "f_vars[i]: -1.5669, F_vars[i]: 0.1727, Q0_vars[i]: 421.2707\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -1.0\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -2.565613925152819\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -2.565613925152819\n",
      "第 5 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -1.0\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -2.565613925152819\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.6649092887800263\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -2.565613925152819\n",
      "*** 於第[5]天進貨 ***\n",
      "\n",
      "f_vars[i]: -1.4893, F_vars[i]: 0.1840, Q0_vars[i]: 449.0220\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -1.0\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -2.2403931224263376\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -2.2403931224263376\n",
      "第 5 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -1.0\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -2.2403931224263376\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.5806244591268455\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -2.2403931224263376\n",
      "*** 於第[5]天進貨 ***\n",
      "\n",
      "f_vars[i]: -1.5733, F_vars[i]: 0.1717, Q0_vars[i]: 419.0566\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -1.0\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -2.59228039504429\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -2.59228039504429\n",
      "第 5 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -1.0\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -2.59228039504429\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.6718202208403735\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -2.59228039504429\n",
      "*** 於第[5]天進貨 ***\n",
      "\n",
      "f_vars[i]: -1.4886, F_vars[i]: 0.1841, Q0_vars[i]: 449.2790\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -1.0\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -2.237455437908488\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -2.237455437908488\n",
      "第 5 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -1.0\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -2.237455437908488\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.5798631233294856\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -2.237455437908488\n",
      "*** 於第[5]天進貨 ***\n",
      "\n",
      "f_vars[i]: -1.5837, F_vars[i]: 0.1703, Q0_vars[i]: 415.4492\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -1.0\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -2.635966358787952\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -2.635966358787952\n",
      "第 5 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -1.0\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -2.635966358787952\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.6831419566626244\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -2.635966358787952\n",
      "*** 於第[5]天進貨 ***\n",
      "\n",
      "f_vars[i]: -1.6297, F_vars[i]: 0.1639, Q0_vars[i]: 399.8425\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -1.0\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -2.82852598902934\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -2.82852598902934\n",
      "第 5 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -1.0\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -2.82852598902934\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.7330460694897014\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -2.82852598902934\n",
      "*** 於第[5]天進貨 ***\n",
      "\n",
      "f_vars[i]: -1.4625, F_vars[i]: 0.1881, Q0_vars[i]: 458.9099\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -1.0\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -2.128294992697569\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -2.128294992697569\n",
      "第 5 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -1.0\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -2.128294992697569\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.5515728988040712\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -2.128294992697569\n",
      "*** 於第[5]天進貨 ***\n",
      "\n",
      "f_vars[i]: -1.7625, F_vars[i]: 0.1465, Q0_vars[i]: 357.3920\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -1.0\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -3.3849442387400397\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -3.3849442387400397\n",
      "第 5 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -1.0\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -3.3849442387400397\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.8772484606025153\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -3.3849442387400397\n",
      "*** 於第[5]天進貨 ***\n",
      "\n",
      "f_vars[i]: -1.7024, F_vars[i]: 0.1541, Q0_vars[i]: 376.1165\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -1.0\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -3.1332029084131503\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -3.1332029084131503\n",
      "第 5 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -1.0\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -3.1332029084131503\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.8120067080289204\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -3.1332029084131503\n",
      "*** 於第[5]天進貨 ***\n",
      "\n",
      "f_vars[i]: -1.5586, F_vars[i]: 0.1738, Q0_vars[i]: 424.1771\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -1.0\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -2.530778981878891\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -2.530778981878891\n",
      "第 5 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -1.0\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -2.530778981878891\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.6558813999266476\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -2.530778981878891\n",
      "*** 於第[5]天進貨 ***\n",
      "\n",
      "f_vars[i]: -1.6817, F_vars[i]: 0.1569, Q0_vars[i]: 382.7489\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -1.0\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -3.0464961069333993\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -3.0464961069333993\n",
      "第 5 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -1.0\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -3.0464961069333993\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.7895356116807596\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -3.0464961069333993\n",
      "*** 於第[5]天進貨 ***\n",
      "\n",
      "f_vars[i]: -1.4767, F_vars[i]: 0.1859, Q0_vars[i]: 453.6333\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -1.0\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -2.1878810215168834\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -2.1878810215168834\n",
      "第 5 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -1.0\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -2.1878810215168834\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.5670153251391702\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -2.1878810215168834\n",
      "*** 於第[5]天進貨 ***\n",
      "\n",
      "f_vars[i]: -1.7069, F_vars[i]: 0.1536, Q0_vars[i]: 374.6992\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -1.0\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -3.1518929911123585\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -3.1518929911123585\n",
      "第 5 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -1.0\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -3.1518929911123585\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.8168504647114581\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -3.1518929911123585\n",
      "*** 於第[5]天進貨 ***\n",
      "\n",
      "f_vars[i]: -1.8756, F_vars[i]: 0.1329, Q0_vars[i]: 324.2598\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -1.0\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -3.858592395152428\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -3.858592395152428\n",
      "第 5 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -1.0\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -3.858592395152428\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -1.0\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -3.858592395152428\n",
      "*** 於第[5]天進貨 ***\n",
      "\n",
      "all_Rs: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_profits</th>\n",
       "      <th>average_losses</th>\n",
       "      <th>average_lefts</th>\n",
       "      <th>average_operation_profits</th>\n",
       "      <th>alpha_values</th>\n",
       "      <th>beta_values</th>\n",
       "      <th>tau_values</th>\n",
       "      <th>gamma_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>754796.78956</td>\n",
       "      <td>4.492233</td>\n",
       "      <td>23.519357</td>\n",
       "      <td>766899.872517</td>\n",
       "      <td>[0.0, 0.0, -0.2387265447202306, -0.95444302763...</td>\n",
       "      <td>[[0.0, -1.0, 0.0, 0.0], [0.0, 0.0, -1.0, 0.0],...</td>\n",
       "      <td>[[-1.0, -2.0783755845086413, -2.07837558450864...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   average_profits  average_losses  average_lefts  average_operation_profits  \\\n",
       "0     754796.78956        4.492233      23.519357              766899.872517   \n",
       "\n",
       "                                        alpha_values  \\\n",
       "0  [0.0, 0.0, -0.2387265447202306, -0.95444302763...   \n",
       "\n",
       "                                         beta_values  \\\n",
       "0  [[0.0, -1.0, 0.0, 0.0], [0.0, 0.0, -1.0, 0.0],...   \n",
       "\n",
       "                                          tau_values gamma_values  \n",
       "0  [[-1.0, -2.0783755845086413, -2.07837558450864...         None  "
      ]
     },
     "execution_count": 1585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_12, stimulation_results_df_12 = None, None\n",
    "results_df_12, stimulation_results_df_12 = fully_flexible_beta_with_softmax_12(\n",
    "    salvage_value=salvage_value,\n",
    "    cost=cost,\n",
    "    price=price,\n",
    "    Q_star=Q_star,\n",
    "    demand_df_train=demand_df_test,\n",
    "    Qk_hat_df=Qk_hat_df_test,\n",
    "    training_df=testing_df,\n",
    ")\n",
    "\n",
    "results_df_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R(T)</th>\n",
       "      <th>F</th>\n",
       "      <th>f_values</th>\n",
       "      <th>profits</th>\n",
       "      <th>losses</th>\n",
       "      <th>lefts</th>\n",
       "      <th>operation_profits</th>\n",
       "      <th>Q0</th>\n",
       "      <th>Q1</th>\n",
       "      <th>hc0</th>\n",
       "      <th>hc1</th>\n",
       "      <th>Left0s</th>\n",
       "      <th>Left1s</th>\n",
       "      <th>lost0s</th>\n",
       "      <th>lost1s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.189908</td>\n",
       "      <td>-1.450606</td>\n",
       "      <td>786801.080269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.165715</td>\n",
       "      <td>800067.366357</td>\n",
       "      <td>463.366670</td>\n",
       "      <td>878.083356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.161299</td>\n",
       "      <td>8.004416</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.172655</td>\n",
       "      <td>-1.566923</td>\n",
       "      <td>797899.372213</td>\n",
       "      <td>24.410499</td>\n",
       "      <td>9.563224</td>\n",
       "      <td>816370.961528</td>\n",
       "      <td>421.270721</td>\n",
       "      <td>948.910773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.563224</td>\n",
       "      <td>24.410499</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.184029</td>\n",
       "      <td>-1.489284</td>\n",
       "      <td>812259.149193</td>\n",
       "      <td>18.390876</td>\n",
       "      <td>14.882575</td>\n",
       "      <td>829246.704623</td>\n",
       "      <td>449.022004</td>\n",
       "      <td>947.938411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.882575</td>\n",
       "      <td>18.390876</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.171748</td>\n",
       "      <td>-1.573289</td>\n",
       "      <td>742730.201607</td>\n",
       "      <td>0.241454</td>\n",
       "      <td>39.709104</td>\n",
       "      <td>758758.715727</td>\n",
       "      <td>419.056562</td>\n",
       "      <td>845.541298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.709104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.184135</td>\n",
       "      <td>-1.488583</td>\n",
       "      <td>759604.169936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.868550</td>\n",
       "      <td>771151.590130</td>\n",
       "      <td>449.279011</td>\n",
       "      <td>849.574674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.267515</td>\n",
       "      <td>13.601035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.170270</td>\n",
       "      <td>-1.583718</td>\n",
       "      <td>727400.387838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.480554</td>\n",
       "      <td>741192.609368</td>\n",
       "      <td>415.449203</td>\n",
       "      <td>826.367304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.985063</td>\n",
       "      <td>6.495491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>0.163873</td>\n",
       "      <td>-1.629687</td>\n",
       "      <td>718011.251258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.875927</td>\n",
       "      <td>727961.622183</td>\n",
       "      <td>399.842463</td>\n",
       "      <td>817.451305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.851530</td>\n",
       "      <td>4.024398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>0.188082</td>\n",
       "      <td>-1.462524</td>\n",
       "      <td>758383.125063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.103479</td>\n",
       "      <td>774424.516533</td>\n",
       "      <td>458.909881</td>\n",
       "      <td>845.976996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.924129</td>\n",
       "      <td>14.179350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>0.146475</td>\n",
       "      <td>-1.762519</td>\n",
       "      <td>763019.264951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.089096</td>\n",
       "      <td>771454.903353</td>\n",
       "      <td>357.391330</td>\n",
       "      <td>936.549058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.906880</td>\n",
       "      <td>8.182216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>0.154149</td>\n",
       "      <td>-1.702422</td>\n",
       "      <td>714747.955090</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.032209</td>\n",
       "      <td>722360.838704</td>\n",
       "      <td>376.116152</td>\n",
       "      <td>832.962425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.888363</td>\n",
       "      <td>5.143846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>0.173847</td>\n",
       "      <td>-1.558607</td>\n",
       "      <td>784752.998319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.641356</td>\n",
       "      <td>787009.540864</td>\n",
       "      <td>424.177051</td>\n",
       "      <td>893.146874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.641356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>0.156868</td>\n",
       "      <td>-1.681723</td>\n",
       "      <td>714283.346169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.817804</td>\n",
       "      <td>730610.467739</td>\n",
       "      <td>382.748920</td>\n",
       "      <td>844.698529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.054468</td>\n",
       "      <td>9.763336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>0.185919</td>\n",
       "      <td>-1.476748</td>\n",
       "      <td>806426.029649</td>\n",
       "      <td>2.346850</td>\n",
       "      <td>9.713619</td>\n",
       "      <td>811719.587313</td>\n",
       "      <td>453.633272</td>\n",
       "      <td>899.232707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.713619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.346850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>0.153568</td>\n",
       "      <td>-1.706884</td>\n",
       "      <td>740285.990193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.847146</td>\n",
       "      <td>752624.848476</td>\n",
       "      <td>374.697639</td>\n",
       "      <td>885.427297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.096957</td>\n",
       "      <td>5.750189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>0.132896</td>\n",
       "      <td>-1.875591</td>\n",
       "      <td>695347.521648</td>\n",
       "      <td>21.993822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>708543.814851</td>\n",
       "      <td>324.259788</td>\n",
       "      <td>856.646570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.993822</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    R(T)         F  f_values        profits     losses      lefts  \\\n",
       "0      5  0.189908 -1.450606  786801.080269   0.000000  33.165715   \n",
       "1      5  0.172655 -1.566923  797899.372213  24.410499   9.563224   \n",
       "2      5  0.184029 -1.489284  812259.149193  18.390876  14.882575   \n",
       "3      5  0.171748 -1.573289  742730.201607   0.241454  39.709104   \n",
       "4      5  0.184135 -1.488583  759604.169936   0.000000  28.868550   \n",
       "5      5  0.170270 -1.583718  727400.387838   0.000000  34.480554   \n",
       "6      5  0.163873 -1.629687  718011.251258   0.000000  24.875927   \n",
       "7      5  0.188082 -1.462524  758383.125063   0.000000  40.103479   \n",
       "8      5  0.146475 -1.762519  763019.264951   0.000000  21.089096   \n",
       "9      5  0.154149 -1.702422  714747.955090   0.000000  19.032209   \n",
       "10     5  0.173847 -1.558607  784752.998319   0.000000   5.641356   \n",
       "11     5  0.156868 -1.681723  714283.346169   0.000000  40.817804   \n",
       "12     5  0.185919 -1.476748  806426.029649   2.346850   9.713619   \n",
       "13     5  0.153568 -1.706884  740285.990193   0.000000  30.847146   \n",
       "14     5  0.132896 -1.875591  695347.521648  21.993822   0.000000   \n",
       "\n",
       "    operation_profits          Q0          Q1  hc0  hc1     Left0s     Left1s  \\\n",
       "0       800067.366357  463.366670  878.083356  0.0  0.0  25.161299   8.004416   \n",
       "1       816370.961528  421.270721  948.910773  0.0  0.0   0.000000   9.563224   \n",
       "2       829246.704623  449.022004  947.938411  0.0  0.0   0.000000  14.882575   \n",
       "3       758758.715727  419.056562  845.541298  0.0  0.0  39.709104   0.000000   \n",
       "4       771151.590130  449.279011  849.574674  0.0  0.0  15.267515  13.601035   \n",
       "5       741192.609368  415.449203  826.367304  0.0  0.0  27.985063   6.495491   \n",
       "6       727961.622183  399.842463  817.451305  0.0  0.0  20.851530   4.024398   \n",
       "7       774424.516533  458.909881  845.976996  0.0  0.0  25.924129  14.179350   \n",
       "8       771454.903353  357.391330  936.549058  0.0  0.0  12.906880   8.182216   \n",
       "9       722360.838704  376.116152  832.962425  0.0  0.0  13.888363   5.143846   \n",
       "10      787009.540864  424.177051  893.146874  0.0  0.0   0.000000   5.641356   \n",
       "11      730610.467739  382.748920  844.698529  0.0  0.0  31.054468   9.763336   \n",
       "12      811719.587313  453.633272  899.232707  0.0  0.0   9.713619   0.000000   \n",
       "13      752624.848476  374.697639  885.427297  0.0  0.0  25.096957   5.750189   \n",
       "14      708543.814851  324.259788  856.646570  0.0  0.0   0.000000   0.000000   \n",
       "\n",
       "       lost0s    lost1s  \n",
       "0    0.000000  0.000000  \n",
       "1   24.410499  0.000000  \n",
       "2   18.390876  0.000000  \n",
       "3    0.000000  0.241454  \n",
       "4    0.000000  0.000000  \n",
       "5    0.000000  0.000000  \n",
       "6    0.000000  0.000000  \n",
       "7    0.000000  0.000000  \n",
       "8    0.000000  0.000000  \n",
       "9    0.000000  0.000000  \n",
       "10   0.000000  0.000000  \n",
       "11   0.000000  0.000000  \n",
       "12   0.000000  2.346850  \n",
       "13   0.000000  0.000000  \n",
       "14  21.993822  0.000000  "
      ]
     },
     "execution_count": 1586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stimulation_results_df_12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++++++++++++++++++++++ THis is R=0 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x3149f492\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [2e+02, 2e+03]\n",
      "Presolve removed 63 rows and 99 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 230 rows, 165 columns, 607 nonzeros\n",
      "Presolved model has 39 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 126 continuous, 39 integer (39 binary)\n",
      "\n",
      "Root relaxation: objective 2.145746e+07, 88 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1457e+07    0   23          - 2.1457e+07      -     -    0s\n",
      "H    0     0                    1.535866e+07 2.1457e+07  39.7%     -    0s\n",
      "     0     2 2.1457e+07    0   22 1.5359e+07 2.1457e+07  39.7%     -    0s\n",
      "H   66    52                    2.138878e+07 2.1423e+07  0.16%   2.8    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 5\n",
      "\n",
      "Explored 89 nodes (324 simplex iterations) in 0.03 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 2.13888e+07 1.53587e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.138877740288e+07, best bound 2.142169189787e+07, gap 0.1539%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.942744256666603, Left1: 34.40033169493654\n",
      "f_train: -2.32370051981091, F_train: 0.08917902314184205, Q0_train: 217.59237388574616\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 30.13939082157094, Left0: 11.599672299804748, Left1: 0.0\n",
      "f_train: -2.321684659874063, F_train: 0.08934289929277733, Q0_train: 217.99222353030385\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.780135226845218, Left1: 23.958598818924656\n",
      "f_train: -2.3443326756445684, F_train: 0.08751729701505546, Q0_train: 213.53784491764614\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 39.812219486902734, Left0: 5.997831937831509, Left1: 0.0\n",
      "f_train: -2.322838220808601, F_train: 0.08924908916495145, Q0_train: 217.76333149169412\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 19.30870245813685, Left0: 4.473992631227483, Left1: 0.0\n",
      "f_train: -2.3252608235922048, F_train: 0.0890523669249368, Q0_train: 217.2833390260576\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 24.325608015315538\n",
      "f_train: -2.3324018828229, F_train: 0.0884747670917031, Q0_train: 215.87402420692763\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 3.54694125445274, Left1: 35.72797391986842\n",
      "f_train: -2.3511634739571767, F_train: 0.08697333775573979, Q0_train: 212.21061142302295\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 16.792373578614843, Left0: 3.305603056156021, Left1: 0.0\n",
      "f_train: -2.321134015560789, F_train: 0.08938771025647861, Q0_train: 218.10156004941283\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.186755455772054, Left1: 20.32889123741552\n",
      "f_train: -2.3518666862196067, F_train: 0.08691751260633504, Q0_train: 212.07440083948487\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 55.85462099144115, Left0: 4.858136765004755, Left1: 0.0\n",
      "f_train: -2.3210924132475093, F_train: 0.08939109664059755, Q0_train: 218.10982265796548\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 2.438752957684239, Left1: 95.47284252627833\n",
      "f_train: -2.3576127331522723, F_train: 0.08646257099327641, Q0_train: 210.96436596718775\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 33.71646139994209, Left0: 9.968603967671758, Left1: 0.0\n",
      "f_train: -2.33654714866461, F_train: 0.08814103369666983, Q0_train: 215.05973134845195\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 10.057436261563694, Left1: 2.260117205147708\n",
      "f_train: -2.3576252454900497, F_train: 0.08646158268893359, Q0_train: 210.96195455382505\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 55.270566432113355\n",
      "f_train: -2.342196944309139, F_train: 0.08768800260878261, Q0_train: 213.95435806239752\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.733439586055052, Left1: 69.63978634475234\n",
      "f_train: -2.347773054814954, F_train: 0.08724294475041541, Q0_train: 212.86843905917414\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=1 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xe4020d76\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [4e+02, 2e+03]\n",
      "Presolve removed 65 rows and 103 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 228 rows, 161 columns, 600 nonzeros\n",
      "Presolved model has 37 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 124 continuous, 37 integer (37 binary)\n",
      "\n",
      "Root relaxation: objective 2.145249e+07, 89 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1452e+07    0   22          - 2.1452e+07      -     -    0s\n",
      "H    0     0                    1.662303e+07 2.1452e+07  29.1%     -    0s\n",
      "     0     2 2.1452e+07    0   21 1.6623e+07 2.1452e+07  29.1%     -    0s\n",
      "H   55    34                    2.107288e+07 2.1419e+07  1.64%   2.7    0s\n",
      "H   76    46                    2.118501e+07 2.1419e+07  1.11%   3.5    0s\n",
      "H  207    84                    2.127503e+07 2.1416e+07  0.66%   4.1    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 4\n",
      "\n",
      "Explored 255 nodes (1129 simplex iterations) in 0.03 seconds (0.03 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 4: 2.1275e+07 2.1185e+07 2.10729e+07 1.6623e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.127503444278e+07, best bound 2.141562619115e+07, gap 0.6608%\n",
      "Model status: 2\n",
      "Lost0: 5.276280313727568, Lost1: 0.0, Left0: 0.0, Left1: 39.6577813528088\n",
      "f_train: -1.5446819173954325, F_train: 0.1758556921965728, Q0_train: 429.0791284572819\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 31.259601900358575, Left0: 13.235715275585097, Left1: 0.0\n",
      "f_train: -1.5503043732435076, F_train: 0.17504231155918487, Q0_train: 427.094520221773\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 29.837185837151083, Left1: 24.761905991686035\n",
      "f_train: -1.4871365576683204, F_train: 0.18435190348421004, Q0_train: 449.8094607482224\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 38.566178894592895, Left0: 2.145208786973943, Left1: 0.0\n",
      "f_train: -1.547086964482138, F_train: 0.17550739928829032, Q0_train: 428.2293111117811\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 15.001412972206992, Left0: 0.0, Left1: 0.0\n",
      "f_train: -1.5403300579435133, F_train: 0.1764872991896379, Q0_train: 430.62021805595674\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.219949228534593, Left1: 23.862424122477933\n",
      "f_train: -1.5204128556125482, F_train: 0.17940073236524137, Q0_train: 437.72884986759635\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 35.975739347290755, Left1: 37.82163447040216\n",
      "f_train: -1.4680847072804344, F_train: 0.187233903592073, Q0_train: 456.84139744045837\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 3.1992054222660045, Lost1: 14.89591518118398, Left0: 0.0, Left1: 0.0\n",
      "f_train: -1.551840181006133, F_train: 0.17482064774752323, Q0_train: 426.55367156381783\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 44.73403342417873, Left1: 21.436829194529537\n",
      "f_train: -1.4661233706691612, F_train: 0.18753255774772273, Q0_train: 457.5700987023606\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 57.50821958039751, Left0: 0.0, Left1: 0.0\n",
      "f_train: -1.5519562144493877, F_train: 0.1748039095815223, Q0_train: 426.5128312726112\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 51.54462260968103, Left1: 87.22883264854977\n",
      "f_train: -1.45009701160058, F_train: 0.18998663628479265, Q0_train: 463.5579280793855\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 38.879467024925134, Left0: 33.884361312419514, Left1: 0.0\n",
      "f_train: -1.5088512516798862, F_train: 0.18110909999378746, Q0_train: 441.8971817764766\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 56.72747123555155, Left1: 5.309550922806011\n",
      "f_train: -1.4500621133095715, F_train: 0.18999200690072654, Q0_train: 463.57103211471923\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 17.699586499821862, Left1: 56.113439841190484\n",
      "f_train: -1.4930933480768758, F_train: 0.1834578866929348, Q0_train: 447.6281043142336\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 31.87082715205679, Left1: 73.67751618630064\n",
      "f_train: -1.477540960458137, F_train: 0.18579913003466939, Q0_train: 453.34062143568656\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=2 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xf14f3675\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [6e+02, 2e+03]\n",
      "Presolve removed 65 rows and 103 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 228 rows, 161 columns, 600 nonzeros\n",
      "Presolved model has 37 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 124 continuous, 37 integer (37 binary)\n",
      "\n",
      "Root relaxation: objective 2.145367e+07, 91 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1454e+07    0   22          - 2.1454e+07      -     -    0s\n",
      "H    0     0                    1.789670e+07 2.1454e+07  19.9%     -    0s\n",
      "     0     2 2.1454e+07    0   21 1.7897e+07 2.1454e+07  19.9%     -    0s\n",
      "H   56    34                    2.089105e+07 2.1421e+07  2.54%   3.0    0s\n",
      "H   57    34                    2.120533e+07 2.1421e+07  1.02%   3.0    0s\n",
      "H   98    38                    2.121863e+07 2.1421e+07  0.95%   4.9    0s\n",
      "H  105    38                    2.124360e+07 2.1421e+07  0.83%   5.2    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 4\n",
      "\n",
      "Explored 111 nodes (695 simplex iterations) in 0.03 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 5: 2.12436e+07 2.12186e+07 2.12053e+07 ... 1.78967e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.124360253818e+07, best bound 2.142076136030e+07, gap 0.8339%\n",
      "Model status: 2\n",
      "Lost0: 9.39960964493747, Lost1: 0.0, Left0: 0.0, Left1: 42.41257068406867\n",
      "f_train: -1.0296822289509007, F_train: 0.2631457153504923, Q0_train: 642.0624364757282\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 29.818136485067498, Left0: 15.95655847507237, Left1: 0.0\n",
      "f_train: -1.03476947148563, F_train: 0.26216048803948605, Q0_train: 639.6585309173779\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 36.773954866769145, Left1: 24.1804424244267\n",
      "f_train: -0.9776147321860696, F_train: 0.2733653292322143, Q0_train: 666.997785242475\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.465475838164366, Lost1: 37.25400034956741, Left0: 0.0, Left1: 0.0\n",
      "f_train: -1.0318583345830514, F_train: 0.2627239858984992, Q0_train: 641.0334376219197\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 17.32854987015139, Left0: 0.0, Left1: 0.0\n",
      "f_train: -1.025744632088038, F_train: 0.2639099273153003, Q0_train: 643.9270755995497\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.8350030580183324, Left1: 24.756151872247983\n",
      "f_train: -1.0077233898393179, F_train: 0.2674256233230849, Q0_train: 652.5051987191284\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 42.30494315020405, Left1: 38.464802348741614\n",
      "f_train: -0.9603764672218845, F_train: 0.27680282619752744, Q0_train: 675.3851065940204\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 9.258026889663313, Lost1: 7.38213495610108, Left0: 0.0, Left1: 0.0\n",
      "f_train: -1.0361590825001605, F_train: 0.2618917811444134, Q0_train: 639.0028994794183\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 59.11268830949484, Left1: 19.319834330839058\n",
      "f_train: -0.9586018343384255, F_train: 0.27715821824542847, Q0_train: 676.2522454865366\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 59.327205819866776, Left0: 0.0, Left1: 0.0\n",
      "f_train: -1.0362640704776431, F_train: 0.26187148700576957, Q0_train: 638.9533827921088\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 65.63792250765846, Left1: 85.69613599996092\n",
      "f_train: -0.9441010578568386, F_train: 0.28007269284367425, Q0_train: 683.3634183175436\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 37.66255081484519, Left0: 42.6664020221142, Left1: 0.0\n",
      "f_train: -0.9972623591286782, F_train: 0.2694800145878977, Q0_train: 657.5178110628381\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 72.5745057232723, Left1: 5.551228736449048\n",
      "f_train: -0.944069481607028, F_train: 0.2800790596696447, Q0_train: 683.378953055739\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 14.91463910141465, Left1: 58.463952009389914\n",
      "f_train: -0.9830044832762885, F_train: 0.27229603545731407, Q0_train: 664.3887617001143\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 37.53780524946092, Left1: 74.2366098646578\n",
      "f_train: -0.9689325599124562, F_train: 0.27509331678132887, Q0_train: 671.2139887801479\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=3 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x48fd12ac\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [8e+02, 2e+03]\n",
      "Presolve removed 69 rows and 108 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 224 rows, 156 columns, 589 nonzeros\n",
      "Presolved model has 36 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 120 continuous, 36 integer (36 binary)\n",
      "\n",
      "Root relaxation: objective 2.156037e+07, 90 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1560e+07    0   22          - 2.1560e+07      -     -    0s\n",
      "H    0     0                    1.929042e+07 2.1560e+07  11.8%     -    0s\n",
      "     0     2 2.1560e+07    0   21 1.9290e+07 2.1560e+07  11.8%     -    0s\n",
      "H   64    50                    2.138913e+07 2.1536e+07  0.69%   2.7    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 4\n",
      "\n",
      "Explored 87 nodes (325 simplex iterations) in 0.03 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 2.13891e+07 1.92904e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.138912793496e+07, best bound 2.153626626820e+07, gap 0.6879%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 19.96925689541854, Left0: 8.860548283794463, Left1: 0.0\n",
      "f_train: -0.5775292177713176, F_train: 0.35950131856149947, Q0_train: 877.1653082186559\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 40.3132492362638, Left0: 46.9083289808495, Left1: 0.0\n",
      "f_train: -0.5756615031858249, F_train: 0.35993149150429105, Q0_train: 878.2149087693881\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 23.07454264966865, Left1: 55.63024619922476\n",
      "f_train: -0.5966451184727075, F_train: 0.355111612326802, Q0_train: 866.4546436854768\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 34.85851986290061, Left0: 19.973830201554463, Left1: 0.0\n",
      "f_train: -0.5767302890391027, F_train: 0.3596853006295742, Q0_train: 877.6142152994289\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 8.364370059295652, Left0: 15.199369346910657, Left1: 0.0\n",
      "f_train: -0.5789748549789706, F_train: 0.3591685136178581, Q0_train: 876.3532807353243\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 28.808026756610616\n",
      "f_train: -0.58559111845901, F_train: 0.3576470946346468, Q0_train: 872.6410942079473\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 19.847543599214994, Left1: 8.343415849739358\n",
      "f_train: -0.6029739220794557, F_train: 0.35366360236685673, Q0_train: 862.9215715178937\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.103287352601239, Left1: 10.03251624022164\n",
      "f_train: -0.5751513256697576, F_train: 0.36004903501226654, Q0_train: 878.5017090732506\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 7.453617130940984, Left0: 42.17906396040846, Left1: 0.0\n",
      "f_train: -0.6036254553408845, F_train: 0.3535146854105718, Q0_train: 862.5582215630692\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 20.262499848900354, Left1: 0.3339373402283172\n",
      "f_train: -0.5751127807064484, F_train: 0.36005791634884343, Q0_train: 878.5233790920618\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 37.93553245142103, Left1: 47.68684095931985\n",
      "f_train: -0.6089492258414533, F_train: 0.35229893095542497, Q0_train: 859.5918412570547\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 25.398860530621732, Left0: 49.87116086517715, Left1: 0.0\n",
      "f_train: -0.589431749115828, F_train: 0.35676524806448506, Q0_train: 870.4894325071984\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 45.36325026982757, Left1: 25.278930225381828\n",
      "f_train: -0.6089608186487401, F_train: 0.35229628566224663, Q0_train: 859.5853868734786\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 37.32163303968764\n",
      "f_train: -0.5946663418260948, F_train: 0.3555648965424874, Q0_train: 867.5606345907489\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 21.358053228748098, Left1: 38.82356117777044\n",
      "f_train: -0.5998326645113498, F_train: 0.35438197842991737, Q0_train: 864.6743733248325\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=4 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xad440d6c\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 1e+03]\n",
      "Presolve removed 59 rows and 81 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 234 rows, 183 columns, 625 nonzeros\n",
      "Presolved model has 53 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 130 continuous, 53 integer (53 binary)\n",
      "\n",
      "Root relaxation: objective 2.156336e+07, 102 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1563e+07    0   23          - 2.1563e+07      -     -    0s\n",
      "H    0     0                    2.058791e+07 2.1563e+07  4.74%     -    0s\n",
      "     0     2 2.1563e+07    0   22 2.0588e+07 2.1563e+07  4.74%     -    0s\n",
      "H   34    26                    2.058791e+07 2.1544e+07  4.64%   4.4    0s\n",
      "H   64    48                    2.133264e+07 2.1539e+07  0.97%   3.9    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 7\n",
      "\n",
      "Explored 87 nodes (403 simplex iterations) in 0.03 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 3: 2.13326e+07 2.05879e+07 2.05879e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.133264062299e+07, best bound 2.153935694645e+07, gap 0.9690%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 20.93177558043567, Left0: 24.629889803438367, Left1: 0.0\n",
      "f_train: -0.17659723117709067, F_train: 0.45596507433440175, Q0_train: 1112.5320668248335\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 35.744820611710566, Left0: 70.73247482415609, Left1: 0.0\n",
      "f_train: -0.17245536914923051, F_train: 0.4569926944166363, Q0_train: 1115.0394086331244\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 25.04042586168281, Left1: 58.900710818974176\n",
      "f_train: -0.21898883846999193, F_train: 0.4454705348312034, Q0_train: 1086.9259132374966\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 35.689126453713016, Left0: 36.014198544150766, Left1: 0.0\n",
      "f_train: -0.1748255190511427, F_train: 0.4564046010594461, Q0_train: 1113.6044901382902\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 9.274567123335146, Left0: 28.86488422172689, Left1: 0.0\n",
      "f_train: -0.1798030903072533, F_train: 0.4551699388822131, Q0_train: 1110.5919759323008\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 34.51583235980638\n",
      "f_train: -0.19447538054214666, F_train: 0.4515338106588232, Q0_train: 1101.7200042061477\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 23.03281012190133, Left1: 6.9228683679016285\n",
      "f_train: -0.23302365489439705, F_train: 0.4420062708304744, Q0_train: 1078.4732816529745\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 20.07245466297565, Left1: 10.072256205063468\n",
      "f_train: -0.17132399452824712, F_train: 0.4572734590806502, Q0_train: 1115.7244604266257\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 2.0996114127169676, Left0: 49.73066190998025, Left1: 0.0\n",
      "f_train: -0.23446850139094452, F_train: 0.44164994853796197, Q0_train: 1077.6038730099478\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.098385348809188, Left0: 36.18291215693734, Left1: 0.0\n",
      "f_train: -0.17123851684277228, F_train: 0.4572946725350684, Q0_train: 1115.7762201986275\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 45.52183478983411, Left1: 45.83627627412943\n",
      "f_train: -0.24627454662538292, F_train: 0.43874067155239715, Q0_train: 1070.505382094956\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 27.569813064115806, Left0: 69.28046490099793, Left1: 0.0\n",
      "f_train: -0.20299240043590797, F_train: 0.4494254449744442, Q0_train: 1096.5756969675094\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 51.63934284190876, Left1: 23.18328581901187\n",
      "f_train: -0.24630025494755944, F_train: 0.4387343409575806, Q0_train: 1070.4899357589713\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 35.67269860664419\n",
      "f_train: -0.21460068413534047, F_train: 0.44655478310529484, Q0_train: 1089.571425012904\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 28.847324287148037, Left1: 34.57010825180896\n",
      "f_train: -0.22605757156339726, F_train: 0.44372505024360476, Q0_train: 1082.6670177975625\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=5 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x823ede9c\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 1e+03]\n",
      "Presolve removed 57 rows and 79 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 236 rows, 185 columns, 633 nonzeros\n",
      "Presolved model has 53 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 132 continuous, 53 integer (53 binary)\n",
      "\n",
      "Root relaxation: objective 2.169825e+07, 99 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1698e+07    0   22          - 2.1698e+07      -     -    0s\n",
      "H    0     0                    2.019005e+07 2.1698e+07  7.47%     -    0s\n",
      "     0     2 2.1698e+07    0   21 2.0190e+07 2.1698e+07  7.47%     -    0s\n",
      "H   31    28                    2.129104e+07 2.1689e+07  1.87%   2.9    0s\n",
      "H   55    22                    2.138490e+07 2.1687e+07  1.41%  14.0    0s\n",
      "H  184    68                    2.142368e+07 2.1687e+07  1.23%   9.4    0s\n",
      "H  249    67                    2.145444e+07 2.1687e+07  1.08%   7.8    0s\n",
      "H  387    69                    2.149693e+07 2.1687e+07  0.88%   5.7    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 3\n",
      "\n",
      "Explored 454 nodes (2434 simplex iterations) in 0.05 seconds (0.04 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 6: 2.14969e+07 2.14544e+07 2.14237e+07 ... 2.019e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Warning: max constraint violation (5.8792e-06) exceeds tolerance\n",
      "Best objective 2.149693038764e+07, best bound 2.168712791072e+07, gap 0.8848%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.466824952796969, Left1: 3.188438344676797\n",
      "f_train: 0.1788605581090434, F_train: 0.544596312448138, Q0_train: 1328.7878725306946\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 63.89319703224908, Left1: 20.051998198768615\n",
      "f_train: 0.18609025091048736, F_train: 0.5463887712829674, Q0_train: 1333.1613827937824\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 19.945826147479693\n",
      "f_train: 0.10486526419881426, F_train: 0.5261923179741835, Q0_train: 1283.8830428355036\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 11.125712641672635, Left0: 20.015351890681814, Left1: 0.0\n",
      "f_train: 0.1819531126936813, F_train: 0.5453631941487493, Q0_train: 1330.6590256768795\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 10.484122011407862, Left1: 4.038582673085557\n",
      "f_train: 0.17326467477930468, F_train: 0.5432081280754585, Q0_train: 1325.400771815743\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 25.950158228570587, Lost1: 0.0, Left0: 0.0, Left1: 26.301576169995343\n",
      "f_train: 0.14765393488058598, F_train: 0.5368465649334768, Q0_train: 1309.8788746596572\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 3.2943662157824747, Lost1: 13.956432116423457, Left0: 0.0, Left1: 0.0\n",
      "f_train: 0.08036724601506229, F_train: 0.5200810042435543, Q0_train: 1268.9717417765862\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 11.677328396322537\n",
      "f_train: 0.18806508515123238, F_train: 0.5468781851672745, Q0_train: 1334.3555282906404\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 12.624467048278234, Left0: 29.676074826617764, Left1: 0.0\n",
      "f_train: 0.07784524111846824, F_train: 0.5194514884618635, Q0_train: 1267.435754629488\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.14212207762921025, Left0: 17.96312776588877, Left1: 0.0\n",
      "f_train: 0.18821428795016792, F_train: 0.5469151577256044, Q0_train: 1334.4457394911246\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 20.696863690404598, Left1: 16.115566661028197\n",
      "f_train: 0.05723758213060015, F_train: 0.5143054901792068, Q0_train: 1254.8797751750565\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 14.609873500394542, Left0: 56.23766637435233, Left1: 0.0\n",
      "f_train: 0.13278732730131482, F_train: 0.5331481391571047, Q0_train: 1300.854900007669\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 27.31831655322867, Left1: 6.208203740174213\n",
      "f_train: 0.05719270780341912, F_train: 0.5142942807736162, Q0_train: 1254.852424783828\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 28.664065418571198, Lost1: 0.0, Left0: 0.0, Left1: 28.11683675827704\n",
      "f_train: 0.11252486454075161, F_train: 0.528101570912419, Q0_train: 1288.5415248926377\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.129588199378418, Left1: 26.13651216175333\n",
      "f_train: 0.09252666662676423, F_train: 0.5231151779015962, Q0_train: 1276.3749743505161\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=6 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xab689e2b\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [8e+02, 2e+03]\n",
      "Presolve removed 60 rows and 102 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 233 rows, 162 columns, 624 nonzeros\n",
      "Presolved model has 33 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 129 continuous, 33 integer (33 binary)\n",
      "Found heuristic solution: objective 2.065836e+07\n",
      "\n",
      "Root relaxation: objective 2.171196e+07, 87 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1712e+07    0   20 2.0658e+07 2.1712e+07  5.10%     -    0s\n",
      "H    0     0                    2.079021e+07 2.1712e+07  4.43%     -    0s\n",
      "     0     2 2.1712e+07    0   20 2.0790e+07 2.1712e+07  4.43%     -    0s\n",
      "H  227    73                    2.136391e+07 2.1702e+07  1.58%   3.7    0s\n",
      "*  423   109              22    2.136392e+07 2.1702e+07  1.58%   3.2    0s\n",
      "H  512   131                    2.146875e+07 2.1702e+07  1.09%   3.1    0s\n",
      "H  548   131                    2.146883e+07 2.1702e+07  1.09%   3.0    0s\n",
      "H  565   127                    2.146883e+07 2.1702e+07  1.09%   3.0    0s\n",
      "*  672   127              32    2.146884e+07 2.1701e+07  1.08%   3.0    0s\n",
      "H  695   181                    2.147439e+07 2.1701e+07  1.06%   2.9    0s\n",
      "H  707   181                    2.148900e+07 2.1701e+07  0.99%   2.9    0s\n",
      "H  731   181                    2.151777e+07 2.1701e+07  0.85%   2.8    0s\n",
      "H  807   181                    2.151819e+07 2.1701e+07  0.85%   2.8    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 4\n",
      "\n",
      "Explored 827 nodes (2350 simplex iterations) in 0.06 seconds (0.05 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 10: 2.15182e+07 2.15178e+07 2.1489e+07 ... 2.13639e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.151818546898e+07, best bound 2.170147026463e+07, gap 0.8518%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.3876178802449886, Left1: 6.001827110043678\n",
      "f_train: 0.662499099657594, F_train: 0.659821552883867, Q0_train: 1609.9317190840272\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 72.7431832173969, Left1: 8.53268846365063\n",
      "f_train: 0.6755812619218209, F_train: 0.6627517683924896, Q0_train: 1617.0812989521976\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 17.986173719096996, Left1: 12.98970777369982\n",
      "f_train: 0.5286042761417963, F_train: 0.6291575227478808, Q0_train: 1535.1130131246578\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 10.285008910035685, Left0: 16.40019411556625, Left1: 0.0\n",
      "f_train: 0.6680950913543826, F_train: 0.6610764871527932, Q0_train: 1612.993696183865\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 6.198725650894858, Left1: 8.073829484752878\n",
      "f_train: 0.6523733231215976, F_train: 0.6575450861437866, Q0_train: 1604.3772536436716\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 29.188012873800204, Lost1: 0.0, Left0: 0.0, Left1: 41.89451863771694\n",
      "f_train: 0.6060305718784149, F_train: 0.6470347910064332, Q0_train: 1578.732657093886\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 15.691585269218535, Left0: 15.074922426265516, Left1: 0.0\n",
      "f_train: 0.48427499994242407, F_train: 0.6187568443292358, Q0_train: 1509.7358759078072\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.803904737729386, Left1: 1.8159296273031487\n",
      "f_train: 0.679154733532844, F_train: 0.663550016583987, Q0_train: 1619.0289847735783\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 12.374515224631637, Left0: 49.55496513474975, Left1: 0.0\n",
      "f_train: 0.47971142052147964, F_train: 0.6176797286125868, Q0_train: 1507.1077672172405\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.466221752448746, Left0: 6.221736632402249, Left1: 0.0\n",
      "f_train: 0.6794247166814449, F_train: 0.663610288036052, Q0_train: 1619.1760441141084\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 39.577574340823844, Left1: 7.335138570589265\n",
      "f_train: 0.4424217671199826, F_train: 0.6088359378385044, Q0_train: 1485.5293582945424\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 42.17273952912933, Left1: 4.153277139962029\n",
      "f_train: 0.5791293773170407, F_train: 0.6408670514726752, Q0_train: 1563.6836798862662\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 41.26809636868438, Left1: 5.246160364990146\n",
      "f_train: 0.4423405668192504, F_train: 0.6088165994312137, Q0_train: 1485.4821735441233\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 6.704123323402911, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_train: 0.5424643580711886, F_train: 0.6323855037841076, Q0_train: 1542.9891260465674\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 27.54342436839977, Left1: 23.521137678609307\n",
      "f_train: 0.5062775272765727, F_train: 0.6239334353689422, Q0_train: 1522.366500165418\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=7 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xfc7ea32c\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 2e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [6e+02, 2e+03]\n",
      "Presolve removed 60 rows and 102 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 233 rows, 162 columns, 624 nonzeros\n",
      "Presolved model has 33 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 129 continuous, 33 integer (33 binary)\n",
      "Found heuristic solution: objective 2.074695e+07\n",
      "\n",
      "Root relaxation: objective 2.175233e+07, 87 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.1752e+07    0   20 2.0747e+07 2.1752e+07  4.85%     -    0s\n",
      "     0     2 2.1752e+07    0   20 2.0747e+07 2.1752e+07  4.85%     -    0s\n",
      "H   74    43                    2.084906e+07 2.1740e+07  4.27%   6.7    0s\n",
      "H  231    83                    2.112468e+07 2.1688e+07  2.67%   3.7    0s\n",
      "H  345    97                    2.113653e+07 2.1675e+07  2.55%   3.1    0s\n",
      "H  543   131                    2.151204e+07 2.1673e+07  0.75%   2.6    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 3\n",
      "\n",
      "Explored 567 nodes (1538 simplex iterations) in 0.05 seconds (0.04 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 5: 2.1512e+07 2.11365e+07 2.11247e+07 ... 2.0747e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.151203564749e+07, best bound 2.167282815492e+07, gap 0.7475%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 4.135829402649733, Left0: 0.0, Left1: 0.0\n",
      "f_train: 1.2325118441106626, F_train: 0.7742579033398528, Q0_train: 1889.150713386467\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 62.62357540067694, Left1: 5.269010610735904\n",
      "f_train: 1.2529333009824895, F_train: 0.777807216567782, Q0_train: 1897.8108608485088\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 6.1980775186325445, Lost1: 0.0, Left0: 0.0, Left1: 7.066910261341947\n",
      "f_train: 1.0234999614751943, F_train: 0.7356537886316437, Q0_train: 1794.9585966175216\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.31353149632502664, Lost1: 0.0, Left0: 0.0, Left1: 4.028198583840195\n",
      "f_train: 1.2412472733755604, F_train: 0.7757810456305654, Q0_train: 1892.8671046982981\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 7.31377099884628, Lost1: 0.0, Left0: 0.0, Left1: 10.965695692379747\n",
      "f_train: 1.2167053509142698, F_train: 0.7714832327413529, Q0_train: 1882.380655350304\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 46.71242776489976, Lost1: 0.0, Left0: 0.0, Left1: 58.092727655259864\n",
      "f_train: 1.1443636021482917, F_train: 0.7584799005173439, Q0_train: 1850.6531725032803\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 21.311521281953333, Lost1: 0.0, Left0: 0.0, Left1: 23.900247651040683\n",
      "f_train: 0.9543012782773685, F_train: 0.7219793765778393, Q0_train: 1761.5937124165966\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 10.614583474047777, Lost1: 0.0, Left0: 0.0, Left1: 10.226435158195914\n",
      "f_train: 1.2585115452293718, F_train: 0.7787697721665874, Q0_train: 1900.1594485585126\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 7.562898019201725, Left0: 14.123025348969577, Left1: 0.0\n",
      "f_train: 0.947177460483057, F_train: 0.7205471884165738, Q0_train: 1758.0992446496068\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 11.2402837440967, Lost1: 0.0, Left0: 0.0, Left1: 11.97147791040774\n",
      "f_train: 1.2589329930843913, F_train: 0.7788423737969009, Q0_train: 1900.336592919724\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.2785936908728949, Left1: 8.060302815395175\n",
      "f_train: 0.8889677369432114, F_train: 0.7086771037829438, Q0_train: 1729.136829468761\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.204354010915381, Left0: 23.733346000459164, Left1: 0.0\n",
      "f_train: 1.1023704229291382, F_train: 0.7507039879250892, Q0_train: 1831.6803331463655\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 2.5663816718536374, Left1: 1.3708274534915614\n",
      "f_train: 0.888840982022588, F_train: 0.7086509340473246, Q0_train: 1729.072976617533\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 26.730140700958145, Lost1: 0.0, Left0: 0.0, Left1: 16.462649246792015\n",
      "f_train: 1.0451357629309714, F_train: 0.7398397387485933, Q0_train: 1805.1721063737978\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.528352628987256, Left1: 11.720395797012998\n",
      "f_train: 0.988647562473383, F_train: 0.7288207078654247, Q0_train: 1778.2862199476206\n",
      "f_train, F_train, Q0_train 都相等\n",
      "alphas: [ 0.00605171  0.         -0.13460554  0.        ]\n",
      "==================================================\n",
      "X_train: [250.0, 0.0, 6.31793916729104, 1]\n",
      "f_train: 0.662499099657594, demand_trian: 2479.5457574186944, F_train: 0.659821552883867, Q0_train: 1609.9317190840272\n",
      "X_test: [100.0, 1.0, 2.0783755845086413, 1]\n",
      "f_test: 0.32541061694675016, demand_test: 1333.445610595638, F_test: 0.5806422920512136 ,Q0_test: 1416.7382670802665\n",
      "==================================================\n",
      "X_train: [250.0, 0.0, 6.22075028232861, 1]\n",
      "f_train: 0.6755812619218209, demand_trian: 2418.6575257676777, F_train: 0.6627517683924896, Q0_train: 1617.0812989521976\n",
      "X_test: [100.0, 1.0, 2.565613925152819, 1]\n",
      "f_test: 0.2598256373873711, demand_test: 1385.028768426017, F_test: 0.5645934291277908 ,Q0_test: 1377.5798410441323\n",
      "==================================================\n",
      "X_train: [250.0, 0.0, 7.312659178930547, 1]\n",
      "f_train: 0.5286042761417963, demand_trian: 2393.4834715624675, F_train: 0.6291575227478808, Q0_train: 1535.1130131246578\n",
      "X_test: [100.0, 1.0, 2.2403931224263376, 1]\n",
      "f_test: 0.30360215889612857, demand_test: 1400.4687169463973, F_test: 0.5753228574752685 ,Q0_test: 1403.7591117101877\n",
      "==================================================\n",
      "X_train: [250.0, 0.0, 6.276365902697227, 1]\n",
      "f_train: 0.6680950913543826, demand_trian: 2494.047035794437, F_train: 0.6610764871527932, Q0_train: 1612.993696183865\n",
      "X_test: [100.0, 1.0, 2.59228039504429, 1]\n",
      "f_test: 0.2562361828291755, demand_test: 1264.8393134664223, F_test: 0.5637108381236166 ,Q0_test: 1375.4263629614782\n",
      "==================================================\n",
      "X_train: [250.0, 0.0, 6.3931647233601065, 1]\n",
      "f_train: 0.6523733231215976, demand_trian: 2486.309984343267, F_train: 0.6575450861437866, Q0_train: 1604.3772536436716\n",
      "X_test: [100.0, 1.0, 2.237455437908488, 1]\n",
      "f_test: 0.30399758750464145, demand_test: 1285.2526502160526, F_test: 0.5754194682713999 ,Q0_test: 1403.9948372399435\n",
      "==================================================\n",
      "X_train: [250.0, 0.0, 6.737450341321928, 1]\n",
      "f_train: 0.6060305718784149, demand_trian: 2480.157328349497, F_train: 0.6470347910064332, Q0_train: 1578.732657093886\n",
      "X_test: [100.0, 1.0, 2.635966358787952, 1]\n",
      "f_test: 0.25035581012416247, demand_test: 1235.321015614005, F_test: 0.5622640759459882 ,Q0_test: 1371.8963353205882\n",
      "==================================================\n",
      "X_train: [250.0, 0.0, 7.64198645969587, 1]\n",
      "f_train: 0.48427499994242407, demand_trian: 2380.5705155510013, F_train: 0.6187568443292358, Q0_train: 1509.7358759078072\n",
      "X_test: [100.0, 1.0, 2.82852598902934, 1]\n",
      "f_test: 0.224436217268136, demand_test: 1213.2693703054997, F_test: 0.5558747093699016 ,Q0_test: 1356.3065991703543\n",
      "==================================================\n",
      "X_train: [250.0, 0.0, 6.194202551586122, 1]\n",
      "f_train: 0.679154733532844, demand_trian: 2508.089300260684, F_train: 0.663550016583987, Q0_train: 1619.0289847735783\n",
      "X_test: [100.0, 1.0, 2.128294992697569, 1]\n",
      "f_test: 0.3186911880911338, demand_test: 1290.7075275545822, F_test: 0.5790052515838362 ,Q0_test: 1412.7439698913734\n",
      "==================================================\n",
      "X_train: [250.0, 0.0, 7.675889814997608, 1]\n",
      "f_train: 0.47971142052147964, demand_trian: 2349.7821168042547, F_train: 0.6176797286125868, Q0_train: 1507.1077672172405\n",
      "X_test: [100.0, 1.0, 3.3849442387400397, 1]\n",
      "f_test: 0.14953923874732683, demand_test: 1285.7581722542673, F_test: 0.537315298580547 ,Q0_test: 1311.0225614078727\n",
      "==================================================\n",
      "X_train: [250.0, 0.0, 6.192196815787926, 1]\n",
      "f_train: 0.6794247166814449, demand_trian: 2528.2647354791284, F_train: 0.663610288036052, Q0_train: 1619.1760441141084\n",
      "X_test: [100.0, 1.0, 3.1332029084131503, 1]\n",
      "f_test: 0.1834250162538988, demand_test: 1203.934731174047, F_test: 0.5457281166952748 ,Q0_test: 1331.5494185112639\n",
      "==================================================\n",
      "X_train: [250.0, 0.0, 7.952918930026792, 1]\n",
      "f_train: 0.4424217671199826, demand_trian: 2319.1302711448484, F_train: 0.6088359378385044, Q0_train: 1485.5293582945424\n",
      "X_test: [100.0, 1.0, 2.530778981878891, 1]\n",
      "f_test: 0.26451461370962065, demand_test: 1311.6825681071168, F_test: 0.5657457582151076 ,Q0_test: 1380.391466612267\n",
      "==================================================\n",
      "X_train: [250.0, 0.0, 6.937302403295403, 1]\n",
      "f_train: 0.5791293773170407, demand_trian: 2406.3007833209504, F_train: 0.6408670514726752, Q0_train: 1563.6836798862662\n",
      "X_test: [100.0, 1.0, 3.0464961069333993, 1]\n",
      "f_test: 0.19509623201904214, demand_test: 1217.6841128981964, F_test: 0.5486199392166506 ,Q0_test: 1338.6053214031538\n",
      "==================================================\n",
      "X_train: [250.0, 0.0, 7.953522176380674, 1]\n",
      "f_train: 0.4423405668192504, demand_trian: 2319.1358485697365, F_train: 0.6088165994312137, Q0_train: 1485.4821735441233\n",
      "X_test: [100.0, 1.0, 2.1878810215168834, 1]\n",
      "f_test: 0.31067057855336094, demand_test: 1355.2128288232193, F_test: 0.5770489333056159 ,Q0_test: 1407.9706507493038\n",
      "==================================================\n",
      "X_train: [250.0, 0.0, 7.209691039490092, 1]\n",
      "f_train: 0.5424643580711886, demand_trian: 2425.734449998191, F_train: 0.6323855037841076, Q0_train: 1542.9891260465674\n",
      "X_test: [100.0, 1.0, 3.1518929911123585, 1]\n",
      "f_test: 0.18090922759455386, demand_test: 1254.3747474607492, F_test: 0.5451043587675819 ,Q0_test: 1330.027480241085\n",
      "==================================================\n",
      "X_train: [250.0, 0.0, 7.478527158796603, 1]\n",
      "f_train: 0.5062775272765727, demand_trian: 2340.183930727458, F_train: 0.6239334353689422, Q0_train: 1522.366500165418\n",
      "X_test: [100.0, 1.0, 3.858592395152428, 1]\n",
      "f_test: 0.08578357326424091, demand_test: 1202.9001800882077, F_test: 0.5214327516117564 ,Q0_test: 1272.2699380157744\n"
     ]
    }
   ],
   "source": [
    "# 線性模型預測公式\n",
    "def compute_f_F_Q(X_data, alphas, Q_star):\n",
    "    f = sum(X_data[j] * alphas[j] for j in range(len(alphas)))\n",
    "    big_f = 1 / (1 + np.exp(-f))\n",
    "    q0 = big_f * Q_star\n",
    "    # print(f\"f_vars[i]: {f:.4f}, F_vars[i]: {big_f:.4f}, Q0_vars[i]: {q0:.4f}\")\n",
    "    return f, big_f, q0\n",
    "\n",
    "\n",
    "results_df_2, stimulation_results_df_2 = grid_flexible_F_fixed_R(\n",
    "    assigned_Ts=ASSIGNED_TS,\n",
    "    salvage_value=salvage_value,\n",
    "    cost=cost,\n",
    "    price=price,\n",
    "    Q_star=Q_star,\n",
    "    demand_df_train=demand_df_train,\n",
    "    Qk_hat_df_train=Qk_hat_df_train,\n",
    "    training_df=training_df,\n",
    ")\n",
    "\n",
    "alphas = np.array(results_df_2.iloc[0][\"alpha_values\"])\n",
    "print(f\"alphas: {alphas}\")\n",
    "\n",
    "train_result_list = []\n",
    "test_result_list = []\n",
    "\n",
    "for i in range(len(training_df)):\n",
    "    # 計算訓練與測試的 f_vars, F_vars, Q0_vars\n",
    "    X_train = training_df.iloc[i, :].values.flatten().tolist()\n",
    "    X_test = testing_df.iloc[i, :].values.flatten().tolist()\n",
    "\n",
    "    # 加入 bias 特徵\n",
    "    X_train.append(1)\n",
    "    X_test.append(1)\n",
    "    f_train, F_train, Q0_train = compute_f_F_Q(X_train, alphas, Q_star)\n",
    "    f_test, F_test, Q0_test = compute_f_F_Q(X_test, alphas, Q_star)\n",
    "\n",
    "    demand_train = sum(demand_df_train.iloc[i, :].values.flatten().tolist())\n",
    "    demand_test = sum(demand_df_test.iloc[i, :].values.flatten().tolist())\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"X_train: {X_train}\")\n",
    "    print(\n",
    "        f\"f_train: {f_train}, demand_trian: {demand_train}, F_train: {F_train}, Q0_train: {Q0_train}\"\n",
    "    )\n",
    "    print(f\"X_test: {X_test}\")\n",
    "    print(\n",
    "        f\"f_test: {f_test}, demand_test: {demand_test}, F_test: {F_test} ,Q0_test: {Q0_test}\"\n",
    "    )\n",
    "\n",
    "    # 計算結果\n",
    "    train_result_list.append((f_train, F_train, Q0_train))\n",
    "    test_result_list.append((f_test, F_test, Q0_test))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "BmCtfhVmxlqf",
    "HTASer1nQ6iQ",
    "aRmALsClGzQB",
    "zg9HWiZOypqj",
    "FTJPzWLlAz8L",
    "yXuk_hytiwhv",
    "lQUlr1TGYuqf",
    "uleVduhQ5KpR",
    "igerpH_M5KpT",
    "6EOHpsM05KpT"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
