{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpAJ7uLZxpkB"
   },
   "source": [
    "# Week HW 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmCtfhVmxlqf"
   },
   "source": [
    "# Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9zBt0n0EZLVO",
    "outputId": "6e9e44a1-d4ec-4ca4-f089-7102126a2f8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter WLSAccessID\n",
      "Set parameter WLSSecret\n",
      "Set parameter LicenseID to value 2563044\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n"
     ]
    }
   ],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import gurobipy_pandas as gppd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gurobipy import min_, max_\n",
    "from scipy.stats import multivariate_normal, norm\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "params = {\n",
    "    \"WLSACCESSID\": \"73a6e3bf-2a9d-41e8-85eb-dd9b9eda802b\",\n",
    "    \"WLSSECRET\": \"c394298a-96ea-4c8c-9d5e-ef2bd5032427\",\n",
    "    \"LICENSEID\": 2563044,\n",
    "}\n",
    "\n",
    "env = gp.Env(params=params)\n",
    "model = gp.Model(env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTASer1nQ6iQ"
   },
   "source": [
    "# Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2lZY1EXmRAie"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "#####################\n",
    "\n",
    "salvage_value = 0\n",
    "cost = 400\n",
    "price = 1000\n",
    "holding_cost = 0\n",
    "\n",
    "model_prefix = f\"med_with_holding_cost_{holding_cost}\"\n",
    "\n",
    "#####################\n",
    "\n",
    "CHUNK_SIZE = 30\n",
    "data_size = CHUNK_SIZE * 3\n",
    "train_size = 0.5\n",
    "testing_size = 0.5\n",
    "\n",
    "T = 10\n",
    "service_level = 0.95  # 服務水準\n",
    "M = 5000000\n",
    "LASSO_BETA = 100\n",
    "LASSO_ALPHA = 0.1\n",
    "LASSO_BETA_SECOND_TRAIN = 0.9\n",
    "\n",
    "\n",
    "ASSIGNED_FS = np.arange(0.1, 1.0, 0.1)\n",
    "ASSIGNED_TS = list(range(2, T))  # 2 到 T-1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Gurobi Model Constants\n",
    "THREADS = 12\n",
    "TIME_LIMIT = 20000\n",
    "MIPGAP = 0.01\n",
    "CURRENT_TIMESTAMP = int(datetime.now().strftime(\"%Y%m%d%H%M\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRmALsClGzQB"
   },
   "source": [
    "# Utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models' Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_parameters(\n",
    "    name: str,\n",
    "    alpha_values=None,\n",
    "    beta_values=None,\n",
    "    f_values=None,\n",
    "    tau_values=None,\n",
    "    data_size=data_size,\n",
    "    current_timestamp=CURRENT_TIMESTAMP,\n",
    "):\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "    params = {}\n",
    "    if alpha_values is not None:\n",
    "        params[\"alpha\"] = alpha_values\n",
    "    if beta_values is not None:\n",
    "        params[\"beta\"] = beta_values\n",
    "    if f_values is not None:\n",
    "        params[\"f_values\"] = f_values\n",
    "    if tau_values is not None:\n",
    "        params[\"tau_values\"] = tau_values\n",
    "\n",
    "    # 如果有參數才進行保存\n",
    "    if params:\n",
    "        with open(f\"models/{name}_{data_size}_{current_timestamp}.pkl\", \"wb\") as f:\n",
    "            pickle.dump(params, f)\n",
    "        print(\n",
    "            f\"Model parameters saved as models/{name}_{data_size}_{current_timestamp}.pkl\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"No parameters provided to save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_model_parameters(name: str, data_size: int):\n",
    "    # 構建檔案的路徑\n",
    "    file_path = f\"models/{name}_{data_size}_{CURRENT_TIMESTAMP}.pkl\"\n",
    "\n",
    "    # 檢查檔案是否存在\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "        print(f\"Model parameters file '{file_path}' has been deleted.\")\n",
    "    else:\n",
    "        print(f\"File '{file_path}' does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_models(model_prefix):\n",
    "    file_paths = sorted(glob.glob(f\"models/{model_prefix}_*.pkl\"))\n",
    "\n",
    "    # 逐一讀取並打印每個檔案的內容\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            params = pickle.load(f)\n",
    "            print(f\"Contents of {file_path}:\")\n",
    "            print(params)\n",
    "            print()  # 空行分隔每個檔案的內容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_models(\"linear_constraint_med_with_holding_cost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_models(\"med_with_holding_cost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_strategies_profits_scatter(save_type, dfs: dict):\n",
    "    names = list(dfs.keys())\n",
    "    df_list = [dfs[name] for name in names]\n",
    "\n",
    "    if len(df_list) <= 1:\n",
    "        print(\"No dataframes to plot.\")\n",
    "        return\n",
    "\n",
    "    pairs = list(itertools.combinations(range(len(df_list)), 2))\n",
    "    num_pairs = len(pairs)\n",
    "    grid_size = math.ceil(math.sqrt(num_pairs))\n",
    "    fig, axes = plt.subplots(grid_size, grid_size, figsize=(15, 15))\n",
    "    fig.suptitle(\"Scatter Plots of Profits (Matrix View)\")\n",
    "\n",
    "    for idx, (i, j) in enumerate(pairs):\n",
    "        row, col = divmod(idx, grid_size)\n",
    "        df_i, df_j = df_list[i], df_list[j]\n",
    "\n",
    "        if df_i is None or df_j is None or df_i.empty or df_j.empty:\n",
    "            continue\n",
    "        if len(df_i) != len(df_j):\n",
    "            continue\n",
    "\n",
    "        ax = axes[row, col]\n",
    "        ax.scatter(df_i[\"profits\"], df_j[\"profits\"], alpha=0.6)\n",
    "        ax.plot(\n",
    "            [\n",
    "                min(df_i[\"profits\"].min(), df_j[\"profits\"].min()),\n",
    "                max(df_i[\"profits\"].max(), df_j[\"profits\"].max()),\n",
    "            ],\n",
    "            [\n",
    "                min(df_i[\"profits\"].min(), df_j[\"profits\"].min()),\n",
    "                max(df_i[\"profits\"].max(), df_j[\"profits\"].max()),\n",
    "            ],\n",
    "            \"k--\",\n",
    "            linewidth=1,\n",
    "        )\n",
    "        ax.set_xlabel(names[i])\n",
    "        ax.set_ylabel(names[j])\n",
    "        ax.set_title(f\"{names[i]} vs {names[j]}\")\n",
    "\n",
    "    # Remove empty subplots\n",
    "    for idx in range(num_pairs, grid_size * grid_size):\n",
    "        row, col = divmod(idx, grid_size)\n",
    "        fig.delaxes(axes[row, col])\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "    os.makedirs(\"plots\", exist_ok=True)\n",
    "    save_path = f\"plots/plot_strategies_profits_scatter_{save_type}.png\"\n",
    "    plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "    print(f\"Plot saved as {save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_relative_profit_deviation(save_type, baseline_profit, max_profits):\n",
    "    \"\"\"\n",
    "    繪製多個策略相對於基準的平均利潤偏差。\n",
    "\n",
    "    :param baseline_profit: 基準利潤值\n",
    "    :param max_profits: 各策略的最大利潤列表，包含 None 值或 -1 表示無效數據\n",
    "    \"\"\"\n",
    "    print(f\"Baseline is: {baseline_profit}\")\n",
    "    for i, profit in enumerate(max_profits):\n",
    "        print(f\"S{i+1}'s profit: {profit}\")\n",
    "\n",
    "    # 計算相對值\n",
    "    ratios = {}\n",
    "    for idx, max_profit in enumerate(max_profits, start=1):\n",
    "        if max_profit is not None and max_profit != -1:\n",
    "            if baseline_profit != 0:\n",
    "                ratio = (max_profit - baseline_profit) / abs(baseline_profit)\n",
    "                ratios[f\"S{idx}\"] = ratio\n",
    "            else:\n",
    "                # 基準利潤為零時，直接記錄增量\n",
    "                ratio = max_profit\n",
    "                ratios[f\"S{idx}\"] = ratio\n",
    "\n",
    "    # 設置 y 軸範圍\n",
    "    if ratios:\n",
    "        y_min = min(ratios.values()) - 0.1\n",
    "        y_max = max(ratios.values()) + 0.1\n",
    "    else:\n",
    "        y_min, y_max = -0.1, 0.1\n",
    "\n",
    "    # 創建圖表顯示結果\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    if ratios:\n",
    "        bars = plt.bar(\n",
    "            ratios.keys(), ratios.values(), color=plt.cm.tab10(range(len(ratios)))\n",
    "        )\n",
    "\n",
    "        # 在每個柱狀圖上標出數值\n",
    "        for bar in bars:\n",
    "            yval = bar.get_height()\n",
    "            plt.text(\n",
    "                bar.get_x() + bar.get_width() / 2,\n",
    "                yval,\n",
    "                f\"{yval:.4f}\",\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "            )\n",
    "\n",
    "    # 添加基準線，表示基準值（No Opt）\n",
    "    plt.axhline(y=0, color=\"gray\", linestyle=\"--\", label=\"Baseline (No Opt)\")\n",
    "\n",
    "    # 設置圖表標題和軸標籤\n",
    "    plt.title(\"Relative Avg Profit Deviation from Baseline (1)\")\n",
    "    plt.xlabel(\"Strategies\")\n",
    "    plt.ylabel(\"Deviation from Baseline (1)\")\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.legend()\n",
    "\n",
    "    name = \"plot_relative_profit_deviation\"\n",
    "\n",
    "    os.makedirs(\"plots\", exist_ok=True)\n",
    "    save_path = f\"plots/{name}_{save_type}_{data_size}_{CURRENT_TIMESTAMP}.png\"\n",
    "\n",
    "    plt.savefig(save_path, format=\"png\", bbox_inches=\"tight\")\n",
    "    print(f\"Plot saved as {save_path}\")\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_relative_profit_comparison(\n",
    "    save_type,\n",
    "    train_baseline_profit,\n",
    "    test_baseline_profit,\n",
    "    test_max_profits,\n",
    "    train_max_profits,\n",
    "):\n",
    "\n",
    "    # Calculate relative deviations from baseline for test and train data\n",
    "    test_ratios, train_ratios = {}, {}\n",
    "    for idx, (test_profit, train_profit) in enumerate(\n",
    "        zip(test_max_profits, train_max_profits), start=1\n",
    "    ):\n",
    "        if test_profit is not None and test_profit != -1:\n",
    "            if test_baseline_profit != 0:\n",
    "                test_ratio = (test_profit - test_baseline_profit) / abs(\n",
    "                    test_baseline_profit\n",
    "                )  # Relative deviation\n",
    "            else:\n",
    "                test_ratio = test_profit  # Use profit directly if baseline is zero\n",
    "            test_ratios[f\"S{idx}\"] = test_ratio\n",
    "\n",
    "        if train_profit is not None and train_profit != -1:\n",
    "            if train_baseline_profit != 0:\n",
    "                train_ratio = (train_profit - train_baseline_profit) / abs(\n",
    "                    train_baseline_profit\n",
    "                )  # Relative deviation\n",
    "            else:\n",
    "                train_ratio = train_profit  # Use profit directly if baseline is zero\n",
    "            train_ratios[f\"S{idx}\"] = train_ratio\n",
    "\n",
    "    # Define the fixed range of the y-axis\n",
    "    max_value = max(\n",
    "        max(test_ratios.values(), default=0), max(train_ratios.values(), default=0)\n",
    "    )\n",
    "    y_max = min(max_value + 0.1, 1.0)  # Limit max y to 1.0\n",
    "    y_min = -y_max  # Keep symmetric scaling\n",
    "\n",
    "    # Ensure y-axis tick marks are at intervals of 0.05\n",
    "    y_ticks = np.arange(y_min, y_max + 0.05, 0.05)  # Generate ticks\n",
    "\n",
    "    # Create bar plot for relative profit deviation comparison\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    bar_width = 0.35\n",
    "    indices = np.arange(len(train_ratios))\n",
    "\n",
    "    # Plot bars for train and test ratios, with train on the left for each pair\n",
    "    train_bars = plt.bar(\n",
    "        indices - bar_width / 2,\n",
    "        train_ratios.values(),\n",
    "        bar_width,\n",
    "        label=\"Train Data\",\n",
    "        color=\"salmon\",\n",
    "    )\n",
    "    test_bars = plt.bar(\n",
    "        indices + bar_width / 2,\n",
    "        test_ratios.values(),\n",
    "        bar_width,\n",
    "        label=\"Test Data\",\n",
    "        color=\"skyblue\",\n",
    "    )\n",
    "\n",
    "    # Add baseline line\n",
    "    plt.axhline(y=0, color=\"gray\", linestyle=\"--\", label=\"Baseline (No Opt)\")\n",
    "\n",
    "    # Add labels for each bar\n",
    "    for bar in train_bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            yval,\n",
    "            f\"{yval:.2f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "        )\n",
    "    for bar in test_bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            yval,\n",
    "            f\"{yval:.2f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "        )\n",
    "\n",
    "    # Set plot labels and title\n",
    "    plt.xlabel(\"Strategies\")\n",
    "    plt.ylabel(\"Deviation from Baseline\")\n",
    "    plt.title(\"Relative Profit Deviation Comparison between Train and Test Data\")\n",
    "    plt.xticks(indices, train_ratios.keys())\n",
    "\n",
    "    # Set fixed y-axis range and ticks\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.yticks(y_ticks)  # Apply fixed 0.05 intervals\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    name = \"plot_relative_profit_comparison\"\n",
    "\n",
    "    os.makedirs(\"plots\", exist_ok=True)\n",
    "    save_path = f\"plots/{name}_{save_type}.png\"\n",
    "\n",
    "    plt.savefig(save_path, format=\"png\", bbox_inches=\"tight\")\n",
    "    print(f\"Plot saved as {save_path}\")\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_Q0_Q1_distribution(save_type, stimulation_results_dfs):\n",
    "\n",
    "    for idx, df in enumerate(stimulation_results_dfs, start=1):\n",
    "        if df is None or len(df) == 0:\n",
    "            continue\n",
    "\n",
    "        df[\"Q0\"] = pd.to_numeric(df[\"Q0\"], errors=\"coerce\")\n",
    "        df[\"Q1\"] = pd.to_numeric(df[\"Q1\"], errors=\"coerce\")\n",
    "        df.dropna(subset=[\"Q0\", \"Q1\"], inplace=True)\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(df[\"Q0\"], bins=20, alpha=0.6, label=\"Q0\", edgecolor=\"black\")\n",
    "        plt.hist(df[\"Q1\"], bins=20, alpha=0.6, label=\"Q1\", edgecolor=\"black\")\n",
    "        plt.title(f\"Histogram of Q0 and Q1 for stimulation_results_df_{idx}\")\n",
    "        plt.xlabel(\"Value\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        name = \"plot_Q0_Q1_distribution\"\n",
    "\n",
    "        os.makedirs(\"plots\", exist_ok=True)\n",
    "        save_path = (\n",
    "            f\"plots/{name}_{save_type}_{data_size}_S{idx}_{CURRENT_TIMESTAMP}.png\"\n",
    "        )\n",
    "\n",
    "        plt.savefig(save_path, format=\"png\", bbox_inches=\"tight\")\n",
    "        print(f\"Plot saved as {save_path}\")\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_profits_deviation_box_plot(\n",
    "    save_type, stimulation_results_dfs, baseline_avg_profits\n",
    "):\n",
    "\n",
    "    for idx, df in enumerate(stimulation_results_dfs, start=1):\n",
    "        if df is not None and \"profits\" in df.columns:\n",
    "            df[\"profits\"] = pd.to_numeric(df[\"profits\"], errors=\"coerce\")\n",
    "            df.dropna(subset=[\"profits\"], inplace=True)\n",
    "\n",
    "            # Calculate deviation\n",
    "            df[\"Deviation\"] = df[\"profits\"] - baseline_avg_profits\n",
    "\n",
    "            # Plot deviation as a boxplot\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.boxplot(y=df[\"Deviation\"])\n",
    "            plt.axhline(0, color=\"red\", linestyle=\"--\", label=\"Baseline\")\n",
    "            plt.title(\n",
    "                f\"Boxplot of Deviation of Profits from Baseline for stimulation_results_df_{idx}\"\n",
    "            )\n",
    "            plt.ylabel(\"Deviation\")\n",
    "            plt.legend()\n",
    "            plt.grid(True, axis=\"y\")\n",
    "\n",
    "            name = \"plot_profits_deviation_box_plot\"\n",
    "\n",
    "            os.makedirs(\"plots\", exist_ok=True)\n",
    "            save_path = (\n",
    "                f\"plots/{name}_{save_type}_{data_size}_S{idx}_{CURRENT_TIMESTAMP}.png\"\n",
    "            )\n",
    "\n",
    "            plt.savefig(save_path, format=\"png\", bbox_inches=\"tight\")\n",
    "            print(f\"Plot saved as {save_path}\")\n",
    "\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"Skipping stimulation_results_df_{idx}: Missing 'profits' column.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 線性模型預測公式\n",
    "def compute_f_F_Q(X_data, alphas, Q_star):\n",
    "    f = sum(X_data[j] * alphas[j] for j in range(len(alphas)))\n",
    "    big_f = 1 / (1 + np.exp(-f))\n",
    "    q0 = big_f * Q_star\n",
    "    print(f\"f_vars[i]: {f:.4f}, F_vars[i]: {big_f:.4f}, Q0_vars[i]: {q0:.4f}\")\n",
    "    return f, big_f, q0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def truncate_to_2(x):\n",
    "    return math.floor(x * 100) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "96OwNkWqLEx1"
   },
   "outputs": [],
   "source": [
    "# Function to replace negative values with 0\n",
    "def replace_negative_with_zero(df):\n",
    "    return df.applymap(lambda x: max(x, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ruyH6M8Jc5yW"
   },
   "outputs": [],
   "source": [
    "def check_values(\n",
    "    Q1_vars,\n",
    "    Q_hat_adjusteds,\n",
    "    Q0_vars,\n",
    "    Sold_0s,\n",
    "    total_demand_up_to_k_minus_1_vars,\n",
    "    Sold_1s,\n",
    "    total_demand_from_k_to_T_vars,\n",
    "    Q1_plus_lefts,\n",
    "    Left_0s,\n",
    "    Lost_0s,\n",
    "    Left_1s,\n",
    "    Lost_1s,\n",
    "):\n",
    "\n",
    "    # 用於存儲每個條件的統計結果\n",
    "    results = {\n",
    "        \"Condition\": [],\n",
    "        \"Average_Error_Percentage\": [],\n",
    "        \"Max_Error_Percentage\": [],\n",
    "        \"Min_Error_Percentage\": [],\n",
    "        \"Max_Error\": [],\n",
    "        \"Min_Error\": [],\n",
    "    }\n",
    "\n",
    "    # 定義存儲每個條件下的誤差和誤差百分比\n",
    "    conditions_errors = {\n",
    "        \"Q1_vars\": [],\n",
    "        \"Sold_0s\": [],\n",
    "        \"Sold_1s\": [],\n",
    "        \"Left_0s\": [],\n",
    "        \"Left_1s\": [],\n",
    "        \"Lost_0s\": [],\n",
    "        \"Lost_1s\": [],\n",
    "    }\n",
    "\n",
    "    # 存儲每個條件下的誤差百分比\n",
    "    conditions_error_percentage = {\n",
    "        \"Q1_vars\": [],\n",
    "        \"Sold_0s\": [],\n",
    "        \"Sold_1s\": [],\n",
    "        \"Left_0s\": [],\n",
    "        \"Left_1s\": [],\n",
    "        \"Lost_0s\": [],\n",
    "        \"Lost_1s\": [],\n",
    "    }\n",
    "\n",
    "    # 遍歷每一個變量集合\n",
    "    for i in range(len(Q1_vars)):\n",
    "        # 提取變量的值\n",
    "        Q1 = Q1_vars[i].X\n",
    "        Q_hat_adjusted = Q_hat_adjusteds[i].X\n",
    "        Q0 = Q0_vars[i].X\n",
    "        Sold_0 = Sold_0s[i].X\n",
    "        total_demand_up_to_k_minus_1 = total_demand_up_to_k_minus_1_vars[i].X\n",
    "        Sold_1 = Sold_1s[i].X\n",
    "        total_demand_from_k_to_T = total_demand_from_k_to_T_vars[i].X\n",
    "        Q1_plus_left = Q1_plus_lefts[i].X\n",
    "        Left_0 = Left_0s[i].X\n",
    "        Lost_0 = Lost_0s[i].X\n",
    "        Left_1 = Left_1s[i].X\n",
    "        Lost_1 = Lost_1s[i].X\n",
    "\n",
    "        # 計算理論值\n",
    "        theoretical_sold_0 = min(total_demand_up_to_k_minus_1, Q0)\n",
    "        theoretical_left_0 = max(Q0 - theoretical_sold_0, 0)\n",
    "        theoretical_Q1_plus_left = Q1 + theoretical_left_0  # Q1_plus_left 的理論值\n",
    "        theoretical_sold_1 = min(total_demand_from_k_to_T, theoretical_Q1_plus_left)\n",
    "        theoretical_left_1 = max(theoretical_Q1_plus_left - theoretical_sold_1, 0)\n",
    "        theoretical_lost_0 = max(total_demand_up_to_k_minus_1 - Q0, 0)\n",
    "        theoretical_lost_1 = max(total_demand_from_k_to_T - theoretical_Q1_plus_left, 0)\n",
    "\n",
    "        # 檢查條件 2：Sold_0 一定等於理論值\n",
    "        if not (Sold_0 == theoretical_sold_0):\n",
    "            error = abs(Sold_0 - theoretical_sold_0)\n",
    "            conditions_errors[\"Sold_0s\"].append(error)\n",
    "            # 計算誤差百分比\n",
    "            conditions_error_percentage[\"Sold_0s\"].append(\n",
    "                (error / theoretical_sold_0) * 100 if theoretical_sold_0 != 0 else 0\n",
    "            )\n",
    "\n",
    "        # 檢查條件 3：Sold_1 一定等於理論值\n",
    "        if not (Sold_1 == theoretical_sold_1):\n",
    "            error = abs(Sold_1 - theoretical_sold_1)\n",
    "            conditions_errors[\"Sold_1s\"].append(error)\n",
    "            # 計算誤差百分比\n",
    "            conditions_error_percentage[\"Sold_1s\"].append(\n",
    "                (error / theoretical_sold_1) * 100 if theoretical_sold_1 != 0 else 0\n",
    "            )\n",
    "\n",
    "        # 檢查條件 4：Left_0 一定等於理論值\n",
    "        if not (Left_0 == theoretical_left_0):\n",
    "            error = abs(Left_0 - theoretical_left_0)\n",
    "            conditions_errors[\"Left_0s\"].append(error)\n",
    "            # 計算誤差百分比\n",
    "            conditions_error_percentage[\"Left_0s\"].append(\n",
    "                (error / theoretical_left_0) * 100 if theoretical_left_0 != 0 else 0\n",
    "            )\n",
    "\n",
    "        # 檢查條件 5：Left_1 一定等於理論值\n",
    "        if not (Left_1 == theoretical_left_1):\n",
    "            error = abs(Left_1 - theoretical_left_1)\n",
    "            conditions_errors[\"Left_1s\"].append(error)\n",
    "            # 計算誤差百分比\n",
    "            conditions_error_percentage[\"Left_1s\"].append(\n",
    "                (error / theoretical_left_1) * 100 if theoretical_left_1 != 0 else 0\n",
    "            )\n",
    "\n",
    "        # 檢查條件 6：Lost_0 一定等於理論值\n",
    "        if not (Lost_0 == theoretical_lost_0):\n",
    "            error = abs(Lost_0 - theoretical_lost_0)\n",
    "            conditions_errors[\"Lost_0s\"].append(error)\n",
    "            # 計算誤差百分比\n",
    "            conditions_error_percentage[\"Lost_0s\"].append(\n",
    "                (error / theoretical_lost_0) * 100 if theoretical_lost_0 != 0 else 0\n",
    "            )\n",
    "\n",
    "        # 檢查條件 7：Lost_1 一定等於理論值\n",
    "        if not (Lost_1 == theoretical_lost_1):\n",
    "            error = abs(Lost_1 - theoretical_lost_1)\n",
    "            conditions_errors[\"Lost_1s\"].append(error)\n",
    "            # 計算誤差百分比\n",
    "            conditions_error_percentage[\"Lost_1s\"].append(\n",
    "                (error / theoretical_lost_1) * 100 if theoretical_lost_1 != 0 else 0\n",
    "            )\n",
    "\n",
    "    # 計算每個條件的統計結果\n",
    "    for condition, errors in conditions_errors.items():\n",
    "        error_percentages = conditions_error_percentage[condition]\n",
    "        if errors:\n",
    "            # 統計數據，並將所有數值四捨五入至小數點后三位\n",
    "            avg_error_percentage = (\n",
    "                round(sum(error_percentages) / len(error_percentages), 3)\n",
    "                if error_percentages\n",
    "                else 0.0\n",
    "            )\n",
    "            max_error_percentage = (\n",
    "                round(max(error_percentages), 3) if error_percentages else 0.0\n",
    "            )\n",
    "            min_error_percentage = (\n",
    "                round(min(error_percentages), 3) if error_percentages else 0.0\n",
    "            )\n",
    "            max_error = round(max(errors), 3) if errors else 0.0\n",
    "            min_error = round(min(errors), 3) if errors else 0.0\n",
    "\n",
    "            # 存儲結果\n",
    "            results[\"Condition\"].append(condition)\n",
    "            results[\"Average_Error_Percentage\"].append(avg_error_percentage)\n",
    "            results[\"Max_Error_Percentage\"].append(max_error_percentage)\n",
    "            results[\"Min_Error_Percentage\"].append(min_error_percentage)\n",
    "            results[\"Max_Error\"].append(max_error)\n",
    "            results[\"Min_Error\"].append(min_error)\n",
    "\n",
    "    # 轉換為 DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "eNMFp-eLU956"
   },
   "outputs": [],
   "source": [
    "# Calculate service level\n",
    "def calculate_service_level(*, salvage_value, cost, price):\n",
    "\n",
    "    cu = price - cost\n",
    "    co = cost - salvage_value\n",
    "    service_lv = cu / (co + cu)\n",
    "\n",
    "    return service_lv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_service_level(salvage_value=salvage_value, cost=cost, price=price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_s3_related_strtegies_result(\n",
    "    *,\n",
    "    all_Rs,\n",
    "    losses,\n",
    "    lefts,\n",
    "    profits,\n",
    "    operation_profits,\n",
    "    alpha_values,\n",
    "    beta_values,\n",
    "    F_vars,\n",
    "    Q0_vars,\n",
    "    Q1_vars,\n",
    "    f_values,\n",
    "    tau_values,\n",
    "    holding_costs_0s,\n",
    "    holding_costs_1s,\n",
    "    all_left0s,\n",
    "    all_left1s,\n",
    "    all_lost0s,\n",
    "    all_lost1s,\n",
    "    gamma_values=None\n",
    "):\n",
    "\n",
    "    results_dict = {\n",
    "        \"average_profits\": [sum(profits) / len(profits) if profits else 0],\n",
    "        \"average_losses\": [sum(losses) / len(losses) if losses else 0],\n",
    "        \"average_lefts\": [sum(lefts) / len(lefts) if lefts else 0],\n",
    "        \"average_operation_profits\": [\n",
    "            sum(operation_profits) / len(operation_profits) if operation_profits else 0\n",
    "        ],\n",
    "        \"alpha_values\": [alpha_values],\n",
    "        \"beta_values\": [beta_values],\n",
    "        \"tau_values\": [tau_values],\n",
    "        \"gamma_values\": [gamma_values],\n",
    "    }\n",
    "    stimulations_result = {\n",
    "        \"R(T)\": all_Rs,\n",
    "        # \"R\": [x - 2 for x in all_Rs],\n",
    "        \"F\": F_vars,\n",
    "        \"f_values\": f_values,\n",
    "        \"profits\": profits,\n",
    "        \"losses\": losses,\n",
    "        \"lefts\": lefts,\n",
    "        \"operation_profits\": operation_profits,\n",
    "        \"Q0\": Q0_vars,\n",
    "        \"Q1\": Q1_vars,\n",
    "        \"hc0\": holding_costs_0s,\n",
    "        \"hc1\": holding_costs_1s,\n",
    "        \"Left0s\": all_left0s,\n",
    "        \"Left1s\": all_left1s,\n",
    "        \"lost0s\": all_lost0s,\n",
    "        \"lost1s\": all_lost1s,\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(results_dict).sort_values(\n",
    "        by=\"average_profits\", ascending=False\n",
    "    ), pd.DataFrame(stimulations_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zg9HWiZOypqj"
   },
   "source": [
    "# Generate Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LS641siV6sA_"
   },
   "source": [
    "## Data1: Training data for LR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qIeKRFI5LRNJ"
   },
   "source": [
    "### Making full data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lf_ktM4A9qZV",
    "outputId": "2c0e47cb-7ee1-4e26-add4-5c6afe560c3e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.744068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>254.356465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.575947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>251.010920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.013817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>291.630992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.724416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>288.907838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.118274</td>\n",
       "      <td>0.0</td>\n",
       "      <td>293.500607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>18.487144</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.239247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>17.267713</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.453517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>18.610278</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69.280813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>19.331912</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.044144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>19.877608</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.318389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X1   X2          X3\n",
       "0   17.744068  0.0  254.356465\n",
       "1   18.575947  0.0  251.010920\n",
       "2   18.013817  0.0  291.630992\n",
       "3   17.724416  0.0  288.907838\n",
       "4   17.118274  0.0  293.500607\n",
       "..        ...  ...         ...\n",
       "85  18.487144  1.0   62.239247\n",
       "86  17.267713  1.0   63.453517\n",
       "87  18.610278  1.0   69.280813\n",
       "88  19.331912  1.0   67.044144\n",
       "89  19.877608  1.0   60.318389\n",
       "\n",
       "[90 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# full_df = pd.DataFrame(\n",
    "#     {\n",
    "#         \"X1\": np.zeros(data_size),\n",
    "#         \"X2\": np.zeros(data_size),\n",
    "#         \"X3\": np.zeros(data_size),\n",
    "#         \"X4\": np.random.uniform(5, 15, data_size),\n",
    "#     }\n",
    "# )\n",
    "\n",
    "full_df = pd.DataFrame(\n",
    "    {\n",
    "        \"X1\": np.zeros(data_size),\n",
    "        \"X2\": np.zeros(data_size),\n",
    "        \"X3\": np.zeros(data_size),  # 將作為轉折時間\n",
    "        # \"X4\": np.random.uniform(5, 15, data_size),\n",
    "    }\n",
    ")\n",
    "\n",
    "for i in range(0, data_size, CHUNK_SIZE):\n",
    "    half_chunk = CHUNK_SIZE // 2\n",
    "    # 訓練 (前 half_chunk)\n",
    "    full_df.loc[i : i + half_chunk - 1, \"X1\"] = np.random.uniform(\n",
    "        15, 20, size=half_chunk\n",
    "    )\n",
    "    full_df.loc[i : i + half_chunk - 1, \"X2\"] = 0\n",
    "    full_df.loc[i : i + half_chunk - 1, \"X3\"] = np.random.uniform(\n",
    "        250, 300, size=half_chunk\n",
    "    )\n",
    "\n",
    "    # 測試 (後 half_chunk)\n",
    "    full_df.loc[i + half_chunk : i + CHUNK_SIZE - 1, \"X1\"] = np.random.uniform(\n",
    "        15, 20, size=half_chunk\n",
    "    )\n",
    "    full_df.loc[i + half_chunk : i + CHUNK_SIZE - 1, \"X2\"] = 1\n",
    "    full_df.loc[i + half_chunk : i + CHUNK_SIZE - 1, \"X3\"] = np.random.uniform(\n",
    "        60, 70, size=half_chunk\n",
    "    )\n",
    "\n",
    "\n",
    "# # 初始化 X3\n",
    "# X3_values = np.zeros(data_size)\n",
    "\n",
    "# # 對每個 chunk 設定對應的 X3 範圍\n",
    "# for i in range(0, data_size, CHUNK_SIZE):\n",
    "#     half_chunk = CHUNK_SIZE // 2\n",
    "#     # 訓練資料 X3：200~250\n",
    "#     X3_values[i : i + half_chunk] = np.random.uniform(\n",
    "#         250, 300, size=min(half_chunk, data_size - i)\n",
    "#     )\n",
    "#     # 測試資料 X3：40~90\n",
    "#     X3_values[i + half_chunk : i + CHUNK_SIZE] = np.random.uniform(\n",
    "#         50, 100, size=min(half_chunk, data_size - i - half_chunk)\n",
    "#     )\n",
    "\n",
    "# # 填入 full_df\n",
    "# full_df[\"X3\"] = X3_values\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(0)\n",
    "\n",
    "# # 初始化 full_df，包含 X1, X2, X3, X4\n",
    "# # 其他變數 (例如 X4) 用 uniform 隨機數\n",
    "# full_df = pd.DataFrame(\n",
    "#     {\n",
    "#         \"X1\": np.zeros(data_size),\n",
    "#         \"X2\": np.zeros(data_size),\n",
    "#         \"X3\": np.zeros(data_size),  # 將作為轉折時間\n",
    "#         # \"X4\": np.random.uniform(5, 15, data_size),\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# # # 根據 chunk，對第一半 (訓練) 設定 X1=1，對第二半 (測試) 設定 X2=1，\n",
    "# # # 並設定 X3 為轉折時間:\n",
    "# # #  訓練：X3 ~ Uniform(7, 9)\n",
    "# # #  測試：X3 ~ Uniform(2, 4)\n",
    "# # for i in range(0, data_size, CHUNK_SIZE):\n",
    "# #     half_chunk = CHUNK_SIZE // 2\n",
    "# #     # 訓練 (前 half_chunk)\n",
    "# #     full_df.loc[i : i + half_chunk - 1, \"X1\"] = 1\n",
    "# #     full_df.loc[i : i + half_chunk - 1, \"X2\"] = 0\n",
    "# #     full_df.loc[i : i + half_chunk - 1, \"X3\"] = np.random.uniform(7, 9, size=half_chunk)\n",
    "\n",
    "# #     # 測試 (後 half_chunk)\n",
    "# #     full_df.loc[i + half_chunk : i + CHUNK_SIZE - 1, \"X1\"] = 0\n",
    "# #     full_df.loc[i + half_chunk : i + CHUNK_SIZE - 1, \"X2\"] = 1\n",
    "# #     full_df.loc[i + half_chunk : i + CHUNK_SIZE - 1, \"X3\"] = np.random.uniform(\n",
    "# #         2, 4, size=half_chunk\n",
    "# #     )\n",
    "\n",
    "# for i in range(0, data_size, CHUNK_SIZE):\n",
    "#     half_chunk = CHUNK_SIZE // 2\n",
    "#     # 訓練部分（前 half_chunk）\n",
    "#     full_df.loc[i : i + half_chunk - 1, \"X1\"] = 250\n",
    "#     full_df.loc[i : i + half_chunk - 1, \"X2\"] = 0\n",
    "#     full_df.loc[i : i + half_chunk - 1, \"X3\"] = np.random.uniform(6, 8, size=half_chunk)\n",
    "\n",
    "#     # 測試部分（後 half_chunk）\n",
    "#     full_df.loc[i + half_chunk : i + CHUNK_SIZE - 1, \"X1\"] = 100\n",
    "#     full_df.loc[i + half_chunk : i + CHUNK_SIZE - 1, \"X2\"] = 1\n",
    "#     full_df.loc[i + half_chunk : i + CHUNK_SIZE - 1, \"X3\"] = np.random.uniform(\n",
    "#         2, 4, size=half_chunk\n",
    "#     )\n",
    "\n",
    "# # 顯示 full_df（部分）\n",
    "# full_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QK33A94iyiRx",
    "outputId": "2ba8de7b-27cf-4945-f51d-2a536cafd7d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_num = full_df.shape[1]\n",
    "features_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBjAqX8vLWW1"
   },
   "source": [
    "### Split training and testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# def train_data_split_and_normalized(data, train_size=0.5):\n",
    "#     folds = []\n",
    "#     scalers = []\n",
    "\n",
    "#     # 計算訓練集的大小\n",
    "#     train_len = int(len(data) * train_size)\n",
    "\n",
    "#     # 將資料切分為前半部分為訓練集，後半部分為測試集\n",
    "#     train_data = data.iloc[:train_len].reset_index(drop=True)\n",
    "#     test_data = data.iloc[train_len:].reset_index(drop=True)\n",
    "\n",
    "#     # # 標準化處理\n",
    "#     # scaler = StandardScaler()\n",
    "#     # train_data_normalized = scaler.fit_transform(train_data)\n",
    "#     # test_data_normalized = scaler.transform(test_data)\n",
    "\n",
    "#     # # 將標準化資料轉回 DataFrame\n",
    "#     # train_data_normalized = pd.DataFrame(train_data_normalized, columns=data.columns)\n",
    "#     # test_data_normalized = pd.DataFrame(test_data_normalized, columns=data.columns)\n",
    "\n",
    "#     # # 將資料加入 folds 與 scaler\n",
    "#     # folds.append((train_data_normalized, test_data_normalized))\n",
    "#     # scalers.append(scaler)\n",
    "\n",
    "#     # 將資料加入 folds 與 scaler\n",
    "#     folds.append((train_data, test_data))\n",
    "#     scalers.append(None)\n",
    "\n",
    "#     return folds, scalers\n",
    "\n",
    "\n",
    "# training_data_folds, scalers = train_data_split_and_normalized(full_df, train_size)\n",
    "\n",
    "# for i, (train, test) in enumerate(training_data_folds):\n",
    "#     print(f\"Fold {i + 1}:\")\n",
    "#     print(f\"Train size: {train.shape}, Test size: {test.shape}\")\n",
    "#     print(\"Train (normalized):\")\n",
    "#     print(train.head())\n",
    "#     print(\"Test (normalized):\")\n",
    "#     print(test.head())\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Train size: (15, 3), Test size: (15, 3)\n",
      "Train (normalized):\n",
      "(15, 3)\n",
      "          X1   X2          X3\n",
      "0  17.744068  0.0  254.356465\n",
      "1  18.575947  0.0  251.010920\n",
      "2  18.013817  0.0  291.630992\n",
      "3  17.724416  0.0  288.907838\n",
      "4  17.118274  0.0  293.500607\n",
      "Test (normalized):\n",
      "(15, 3)\n",
      "          X1   X2         X3\n",
      "0  16.322778  1.0  66.706379\n",
      "1  18.871168  1.0  62.103826\n",
      "2  17.280752  1.0  61.289263\n",
      "3  17.842170  1.0  63.154284\n",
      "4  15.093949  1.0  63.637108\n",
      "\n",
      "Fold 2:\n",
      "Train size: (15, 3), Test size: (15, 3)\n",
      "Train (normalized):\n",
      "(15, 3)\n",
      "          X1   X2          X3\n",
      "0  15.794848  0.0  251.959390\n",
      "1  15.551876  0.0  264.140348\n",
      "2  18.281648  0.0  256.009828\n",
      "3  15.690915  0.0  264.807010\n",
      "4  15.982912  0.0  255.936386\n",
      "Test (normalized):\n",
      "(15, 3)\n",
      "          X1   X2         X3\n",
      "0  16.592845  1.0  65.761573\n",
      "1  18.337052  1.0  65.920419\n",
      "2  15.658989  1.0  65.722519\n",
      "3  18.581636  1.0  62.230816\n",
      "4  16.447030  1.0  69.527490\n",
      "\n",
      "Fold 3:\n",
      "Train size: (15, 3), Test size: (15, 3)\n",
      "Train (normalized):\n",
      "(15, 3)\n",
      "          X1   X2          X3\n",
      "0  18.626271  0.0  279.543638\n",
      "1  17.506622  0.0  278.716262\n",
      "2  19.780418  0.0  282.660041\n",
      "3  18.219951  0.0  282.605164\n",
      "4  17.119275  0.0  271.570922\n",
      "Test (normalized):\n",
      "(15, 3)\n",
      "          X1   X2         X3\n",
      "0  15.747242  1.0  68.558033\n",
      "1  19.340630  1.0  60.117141\n",
      "2  15.812465  1.0  63.599781\n",
      "3  18.077798  1.0  67.299906\n",
      "4  15.619100  1.0  61.716297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def train_data_split_and_normalized_k_fold(data, train_size=0.5, chunk_size=CHUNK_SIZE):\n",
    "\n",
    "    folds = []\n",
    "    scalers = []\n",
    "    train_chunk = int(train_size * chunk_size)\n",
    "    n = len(data)\n",
    "\n",
    "    # 依序將資料切分成 chunk_size 大小的子集\n",
    "    for start in range(0, n, chunk_size):\n",
    "        if start + chunk_size > n:\n",
    "            break  # 若剩餘資料不足一個完整的 chunk，則跳過\n",
    "        chunk = data.iloc[start : start + chunk_size].reset_index(drop=True)\n",
    "        train_data = chunk.iloc[:train_chunk].reset_index(drop=True)\n",
    "        test_data = chunk.iloc[train_chunk:].reset_index(drop=True)\n",
    "\n",
    "        # # 建立並使用 StandardScaler 分別標準化當前的訓練與測試資料\n",
    "        # scaler = StandardScaler()\n",
    "        # train_data_normalized = scaler.fit_transform(train_data)\n",
    "        # test_data_normalized = scaler.transform(test_data)\n",
    "\n",
    "        # # 轉回 DataFrame 格式\n",
    "        # train_data_normalized = pd.DataFrame(\n",
    "        #     train_data_normalized, columns=data.columns\n",
    "        # )\n",
    "        # test_data_normalized = pd.DataFrame(test_data_normalized, columns=data.columns)\n",
    "\n",
    "        # folds.append((train_data_normalized, test_data_normalized))\n",
    "        # scalers.append(scaler)\n",
    "\n",
    "        folds.append((train_data, test_data))\n",
    "        scalers.append(None)\n",
    "\n",
    "    return folds, scalers\n",
    "\n",
    "\n",
    "training_data_folds, scalers = train_data_split_and_normalized_k_fold(full_df)\n",
    "\n",
    "for i, (train, test) in enumerate(training_data_folds):\n",
    "    print(f\"Fold {i + 1}:\")\n",
    "    print(f\"Train size: {train.shape}, Test size: {test.shape}\")\n",
    "    print(\"Train (normalized):\")\n",
    "    print(train.shape)\n",
    "    print(train.head())\n",
    "    print(\"Test (normalized):\")\n",
    "    print(test.shape)\n",
    "    print(test.head())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8_ZeISZmXmZ"
   },
   "source": [
    "## Data2: demand_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8sxaCcInWRTC"
   },
   "source": [
    "### mu of each time(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "54SdjO8-NCOc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu_matrix shape: (90, 10)\n",
      "mu_matrix[:3]: \n",
      "[[254.35646499 254.35646499 254.35646499 254.35646499 254.35646499\n",
      "  254.35646499 254.35646499 254.35646499 254.35646499 254.35646499]\n",
      " [251.01091987 251.01091987 251.01091987 251.01091987 251.01091987\n",
      "  251.01091987 251.01091987 251.01091987 251.01091987 251.01091987]\n",
      " [291.63099228 291.63099228 291.63099228 291.63099228 291.63099228\n",
      "  291.63099228 291.63099228 291.63099228 291.63099228 291.63099228]]\n",
      "mu_matrix[CHUNK_SIZE : CHUNK_SIZE + 3]: \n",
      "[[251.95938961 251.95938961 251.95938961 251.95938961 251.95938961\n",
      "  251.95938961 251.95938961 251.95938961 251.95938961 251.95938961]\n",
      " [264.14034813 264.14034813 264.14034813 264.14034813 264.14034813\n",
      "  264.14034813 264.14034813 264.14034813 264.14034813 264.14034813]\n",
      " [256.00982806 256.00982806 256.00982806 256.00982806 256.00982806\n",
      "  256.00982806 256.00982806 256.00982806 256.00982806 256.00982806]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>t4</th>\n",
       "      <th>t5</th>\n",
       "      <th>t6</th>\n",
       "      <th>t7</th>\n",
       "      <th>t8</th>\n",
       "      <th>t9</th>\n",
       "      <th>t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.356465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251.010920</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>251.010920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>291.630992</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>291.630992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.907838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>293.500607</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>293.500607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>298.930917</td>\n",
       "      <td>298.930917</td>\n",
       "      <td>298.930917</td>\n",
       "      <td>298.930917</td>\n",
       "      <td>298.930917</td>\n",
       "      <td>298.930917</td>\n",
       "      <td>298.930917</td>\n",
       "      <td>298.930917</td>\n",
       "      <td>298.930917</td>\n",
       "      <td>298.930917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>289.957928</td>\n",
       "      <td>289.957928</td>\n",
       "      <td>289.957928</td>\n",
       "      <td>289.957928</td>\n",
       "      <td>289.957928</td>\n",
       "      <td>289.957928</td>\n",
       "      <td>289.957928</td>\n",
       "      <td>289.957928</td>\n",
       "      <td>289.957928</td>\n",
       "      <td>289.957928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>273.073968</td>\n",
       "      <td>273.073968</td>\n",
       "      <td>273.073968</td>\n",
       "      <td>273.073968</td>\n",
       "      <td>273.073968</td>\n",
       "      <td>273.073968</td>\n",
       "      <td>273.073968</td>\n",
       "      <td>273.073968</td>\n",
       "      <td>273.073968</td>\n",
       "      <td>273.073968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>289.026459</td>\n",
       "      <td>289.026459</td>\n",
       "      <td>289.026459</td>\n",
       "      <td>289.026459</td>\n",
       "      <td>289.026459</td>\n",
       "      <td>289.026459</td>\n",
       "      <td>289.026459</td>\n",
       "      <td>289.026459</td>\n",
       "      <td>289.026459</td>\n",
       "      <td>289.026459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>255.913721</td>\n",
       "      <td>255.913721</td>\n",
       "      <td>255.913721</td>\n",
       "      <td>255.913721</td>\n",
       "      <td>255.913721</td>\n",
       "      <td>255.913721</td>\n",
       "      <td>255.913721</td>\n",
       "      <td>255.913721</td>\n",
       "      <td>255.913721</td>\n",
       "      <td>255.913721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>281.996051</td>\n",
       "      <td>281.996051</td>\n",
       "      <td>281.996051</td>\n",
       "      <td>281.996051</td>\n",
       "      <td>281.996051</td>\n",
       "      <td>281.996051</td>\n",
       "      <td>281.996051</td>\n",
       "      <td>281.996051</td>\n",
       "      <td>281.996051</td>\n",
       "      <td>281.996051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>257.167664</td>\n",
       "      <td>257.167664</td>\n",
       "      <td>257.167664</td>\n",
       "      <td>257.167664</td>\n",
       "      <td>257.167664</td>\n",
       "      <td>257.167664</td>\n",
       "      <td>257.167664</td>\n",
       "      <td>257.167664</td>\n",
       "      <td>257.167664</td>\n",
       "      <td>257.167664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>297.233446</td>\n",
       "      <td>297.233446</td>\n",
       "      <td>297.233446</td>\n",
       "      <td>297.233446</td>\n",
       "      <td>297.233446</td>\n",
       "      <td>297.233446</td>\n",
       "      <td>297.233446</td>\n",
       "      <td>297.233446</td>\n",
       "      <td>297.233446</td>\n",
       "      <td>297.233446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>276.092416</td>\n",
       "      <td>276.092416</td>\n",
       "      <td>276.092416</td>\n",
       "      <td>276.092416</td>\n",
       "      <td>276.092416</td>\n",
       "      <td>276.092416</td>\n",
       "      <td>276.092416</td>\n",
       "      <td>276.092416</td>\n",
       "      <td>276.092416</td>\n",
       "      <td>276.092416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>270.733097</td>\n",
       "      <td>270.733097</td>\n",
       "      <td>270.733097</td>\n",
       "      <td>270.733097</td>\n",
       "      <td>270.733097</td>\n",
       "      <td>270.733097</td>\n",
       "      <td>270.733097</td>\n",
       "      <td>270.733097</td>\n",
       "      <td>270.733097</td>\n",
       "      <td>270.733097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>66.706379</td>\n",
       "      <td>66.706379</td>\n",
       "      <td>66.706379</td>\n",
       "      <td>66.706379</td>\n",
       "      <td>66.706379</td>\n",
       "      <td>66.706379</td>\n",
       "      <td>66.706379</td>\n",
       "      <td>66.706379</td>\n",
       "      <td>66.706379</td>\n",
       "      <td>66.706379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>62.103826</td>\n",
       "      <td>62.103826</td>\n",
       "      <td>62.103826</td>\n",
       "      <td>62.103826</td>\n",
       "      <td>62.103826</td>\n",
       "      <td>62.103826</td>\n",
       "      <td>62.103826</td>\n",
       "      <td>62.103826</td>\n",
       "      <td>62.103826</td>\n",
       "      <td>62.103826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>61.289263</td>\n",
       "      <td>61.289263</td>\n",
       "      <td>61.289263</td>\n",
       "      <td>61.289263</td>\n",
       "      <td>61.289263</td>\n",
       "      <td>61.289263</td>\n",
       "      <td>61.289263</td>\n",
       "      <td>61.289263</td>\n",
       "      <td>61.289263</td>\n",
       "      <td>61.289263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>63.154284</td>\n",
       "      <td>63.154284</td>\n",
       "      <td>63.154284</td>\n",
       "      <td>63.154284</td>\n",
       "      <td>63.154284</td>\n",
       "      <td>63.154284</td>\n",
       "      <td>63.154284</td>\n",
       "      <td>63.154284</td>\n",
       "      <td>63.154284</td>\n",
       "      <td>63.154284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>63.637108</td>\n",
       "      <td>63.637108</td>\n",
       "      <td>63.637108</td>\n",
       "      <td>63.637108</td>\n",
       "      <td>63.637108</td>\n",
       "      <td>63.637108</td>\n",
       "      <td>63.637108</td>\n",
       "      <td>63.637108</td>\n",
       "      <td>63.637108</td>\n",
       "      <td>63.637108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>65.701968</td>\n",
       "      <td>65.701968</td>\n",
       "      <td>65.701968</td>\n",
       "      <td>65.701968</td>\n",
       "      <td>65.701968</td>\n",
       "      <td>65.701968</td>\n",
       "      <td>65.701968</td>\n",
       "      <td>65.701968</td>\n",
       "      <td>65.701968</td>\n",
       "      <td>65.701968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>64.386015</td>\n",
       "      <td>64.386015</td>\n",
       "      <td>64.386015</td>\n",
       "      <td>64.386015</td>\n",
       "      <td>64.386015</td>\n",
       "      <td>64.386015</td>\n",
       "      <td>64.386015</td>\n",
       "      <td>64.386015</td>\n",
       "      <td>64.386015</td>\n",
       "      <td>64.386015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>69.883738</td>\n",
       "      <td>69.883738</td>\n",
       "      <td>69.883738</td>\n",
       "      <td>69.883738</td>\n",
       "      <td>69.883738</td>\n",
       "      <td>69.883738</td>\n",
       "      <td>69.883738</td>\n",
       "      <td>69.883738</td>\n",
       "      <td>69.883738</td>\n",
       "      <td>69.883738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>61.020448</td>\n",
       "      <td>61.020448</td>\n",
       "      <td>61.020448</td>\n",
       "      <td>61.020448</td>\n",
       "      <td>61.020448</td>\n",
       "      <td>61.020448</td>\n",
       "      <td>61.020448</td>\n",
       "      <td>61.020448</td>\n",
       "      <td>61.020448</td>\n",
       "      <td>61.020448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>62.088768</td>\n",
       "      <td>62.088768</td>\n",
       "      <td>62.088768</td>\n",
       "      <td>62.088768</td>\n",
       "      <td>62.088768</td>\n",
       "      <td>62.088768</td>\n",
       "      <td>62.088768</td>\n",
       "      <td>62.088768</td>\n",
       "      <td>62.088768</td>\n",
       "      <td>62.088768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>61.613095</td>\n",
       "      <td>61.613095</td>\n",
       "      <td>61.613095</td>\n",
       "      <td>61.613095</td>\n",
       "      <td>61.613095</td>\n",
       "      <td>61.613095</td>\n",
       "      <td>61.613095</td>\n",
       "      <td>61.613095</td>\n",
       "      <td>61.613095</td>\n",
       "      <td>61.613095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>66.531083</td>\n",
       "      <td>66.531083</td>\n",
       "      <td>66.531083</td>\n",
       "      <td>66.531083</td>\n",
       "      <td>66.531083</td>\n",
       "      <td>66.531083</td>\n",
       "      <td>66.531083</td>\n",
       "      <td>66.531083</td>\n",
       "      <td>66.531083</td>\n",
       "      <td>66.531083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>62.532916</td>\n",
       "      <td>62.532916</td>\n",
       "      <td>62.532916</td>\n",
       "      <td>62.532916</td>\n",
       "      <td>62.532916</td>\n",
       "      <td>62.532916</td>\n",
       "      <td>62.532916</td>\n",
       "      <td>62.532916</td>\n",
       "      <td>62.532916</td>\n",
       "      <td>62.532916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>64.663108</td>\n",
       "      <td>64.663108</td>\n",
       "      <td>64.663108</td>\n",
       "      <td>64.663108</td>\n",
       "      <td>64.663108</td>\n",
       "      <td>64.663108</td>\n",
       "      <td>64.663108</td>\n",
       "      <td>64.663108</td>\n",
       "      <td>64.663108</td>\n",
       "      <td>64.663108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>62.444256</td>\n",
       "      <td>62.444256</td>\n",
       "      <td>62.444256</td>\n",
       "      <td>62.444256</td>\n",
       "      <td>62.444256</td>\n",
       "      <td>62.444256</td>\n",
       "      <td>62.444256</td>\n",
       "      <td>62.444256</td>\n",
       "      <td>62.444256</td>\n",
       "      <td>62.444256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            t1          t2          t3          t4          t5          t6  \\\n",
       "0   254.356465  254.356465  254.356465  254.356465  254.356465  254.356465   \n",
       "1   251.010920  251.010920  251.010920  251.010920  251.010920  251.010920   \n",
       "2   291.630992  291.630992  291.630992  291.630992  291.630992  291.630992   \n",
       "3   288.907838  288.907838  288.907838  288.907838  288.907838  288.907838   \n",
       "4   293.500607  293.500607  293.500607  293.500607  293.500607  293.500607   \n",
       "5   298.930917  298.930917  298.930917  298.930917  298.930917  298.930917   \n",
       "6   289.957928  289.957928  289.957928  289.957928  289.957928  289.957928   \n",
       "7   273.073968  273.073968  273.073968  273.073968  273.073968  273.073968   \n",
       "8   289.026459  289.026459  289.026459  289.026459  289.026459  289.026459   \n",
       "9   255.913721  255.913721  255.913721  255.913721  255.913721  255.913721   \n",
       "10  281.996051  281.996051  281.996051  281.996051  281.996051  281.996051   \n",
       "11  257.167664  257.167664  257.167664  257.167664  257.167664  257.167664   \n",
       "12  297.233446  297.233446  297.233446  297.233446  297.233446  297.233446   \n",
       "13  276.092416  276.092416  276.092416  276.092416  276.092416  276.092416   \n",
       "14  270.733097  270.733097  270.733097  270.733097  270.733097  270.733097   \n",
       "15   66.706379   66.706379   66.706379   66.706379   66.706379   66.706379   \n",
       "16   62.103826   62.103826   62.103826   62.103826   62.103826   62.103826   \n",
       "17   61.289263   61.289263   61.289263   61.289263   61.289263   61.289263   \n",
       "18   63.154284   63.154284   63.154284   63.154284   63.154284   63.154284   \n",
       "19   63.637108   63.637108   63.637108   63.637108   63.637108   63.637108   \n",
       "20   65.701968   65.701968   65.701968   65.701968   65.701968   65.701968   \n",
       "21   64.386015   64.386015   64.386015   64.386015   64.386015   64.386015   \n",
       "22   69.883738   69.883738   69.883738   69.883738   69.883738   69.883738   \n",
       "23   61.020448   61.020448   61.020448   61.020448   61.020448   61.020448   \n",
       "24   62.088768   62.088768   62.088768   62.088768   62.088768   62.088768   \n",
       "25   61.613095   61.613095   61.613095   61.613095   61.613095   61.613095   \n",
       "26   66.531083   66.531083   66.531083   66.531083   66.531083   66.531083   \n",
       "27   62.532916   62.532916   62.532916   62.532916   62.532916   62.532916   \n",
       "28   64.663108   64.663108   64.663108   64.663108   64.663108   64.663108   \n",
       "29   62.444256   62.444256   62.444256   62.444256   62.444256   62.444256   \n",
       "\n",
       "            t7          t8          t9         t10  \n",
       "0   254.356465  254.356465  254.356465  254.356465  \n",
       "1   251.010920  251.010920  251.010920  251.010920  \n",
       "2   291.630992  291.630992  291.630992  291.630992  \n",
       "3   288.907838  288.907838  288.907838  288.907838  \n",
       "4   293.500607  293.500607  293.500607  293.500607  \n",
       "5   298.930917  298.930917  298.930917  298.930917  \n",
       "6   289.957928  289.957928  289.957928  289.957928  \n",
       "7   273.073968  273.073968  273.073968  273.073968  \n",
       "8   289.026459  289.026459  289.026459  289.026459  \n",
       "9   255.913721  255.913721  255.913721  255.913721  \n",
       "10  281.996051  281.996051  281.996051  281.996051  \n",
       "11  257.167664  257.167664  257.167664  257.167664  \n",
       "12  297.233446  297.233446  297.233446  297.233446  \n",
       "13  276.092416  276.092416  276.092416  276.092416  \n",
       "14  270.733097  270.733097  270.733097  270.733097  \n",
       "15   66.706379   66.706379   66.706379   66.706379  \n",
       "16   62.103826   62.103826   62.103826   62.103826  \n",
       "17   61.289263   61.289263   61.289263   61.289263  \n",
       "18   63.154284   63.154284   63.154284   63.154284  \n",
       "19   63.637108   63.637108   63.637108   63.637108  \n",
       "20   65.701968   65.701968   65.701968   65.701968  \n",
       "21   64.386015   64.386015   64.386015   64.386015  \n",
       "22   69.883738   69.883738   69.883738   69.883738  \n",
       "23   61.020448   61.020448   61.020448   61.020448  \n",
       "24   62.088768   62.088768   62.088768   62.088768  \n",
       "25   61.613095   61.613095   61.613095   61.613095  \n",
       "26   66.531083   66.531083   66.531083   66.531083  \n",
       "27   62.532916   62.532916   62.532916   62.532916  \n",
       "28   64.663108   64.663108   64.663108   64.663108  \n",
       "29   62.444256   62.444256   62.444256   62.444256  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 設定 b0, b1, b2\n",
    "b0 = 0\n",
    "b1 = 0\n",
    "b2 = 0\n",
    "b3 = 1\n",
    "# b4 = 0\n",
    "bt = 0\n",
    "\n",
    "\n",
    "def cal_mu_matrix_with_random_noise(data_size, T, training_df, sigma_t):\n",
    "    np.random.seed(0)\n",
    "\n",
    "    # 初始化 mu_matrix\n",
    "    mu_matrix = np.zeros((data_size, T))\n",
    "\n",
    "    # 生成每個 t 的隨機數\n",
    "    random_noises = np.random.normal(0, sigma_t, T)\n",
    "\n",
    "    # 計算 mu_matrix\n",
    "    for t in range(1, T + 1):\n",
    "        mu_matrix[:, t - 1] = (\n",
    "            b0 * random_noises[t - 1]\n",
    "            + b1 * training_df[\"X1\"]\n",
    "            + b2 * training_df[\"X2\"]\n",
    "            + b3 * training_df[\"X3\"]\n",
    "            # + b4 * training_df[\"X4\"]\n",
    "            + bt * t\n",
    "        )\n",
    "\n",
    "    return mu_matrix\n",
    "\n",
    "\n",
    "mu_matrix = cal_mu_matrix_with_random_noise(data_size, T, full_df, sigma_t=1)\n",
    "\n",
    "print(f\"mu_matrix shape: {mu_matrix.shape}\")\n",
    "print(f\"mu_matrix[:3]: \\n{mu_matrix[:3]}\")\n",
    "print(\n",
    "    f\"mu_matrix[CHUNK_SIZE : CHUNK_SIZE + 3]: \\n{mu_matrix[CHUNK_SIZE : CHUNK_SIZE + 3]}\"\n",
    ")\n",
    "\n",
    "\n",
    "mu_df = pd.DataFrame(mu_matrix, columns=[f\"t{t}\" for t in range(1, T + 1)])\n",
    "mu_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cal_mu_matrix_with_turning_point(\n",
    "#     data_size, T, training_df, sigma_t, delta=50, gamma=1.0\n",
    "# ):\n",
    "#     np.random.seed(0)\n",
    "#     mu_matrix = np.zeros((data_size, T))\n",
    "#     random_noises = np.random.normal(0, sigma_t, T)\n",
    "\n",
    "#     # 用 X1, X2 區分高低 baseline，X3 作為轉折點\n",
    "#     for i in range(data_size):\n",
    "#         # 根據 X1 / X2 決定 baseline range\n",
    "#         if training_df.loc[i, \"X2\"] == 1:\n",
    "\n",
    "#             # 低 baseline\n",
    "#             # baseline1 = np.random.uniform(50, 100)\n",
    "#             # baseline2 = np.random.uniform(100, 150)\n",
    "#             baseline1 = np.random.uniform(100, 120)\n",
    "#             baseline2 = np.random.uniform(160, 180)\n",
    "\n",
    "#         else:\n",
    "#             # 高 baseline\n",
    "#             baseline1 = np.random.uniform(120, 140)\n",
    "#             baseline2 = np.random.uniform(160, 180)\n",
    "\n",
    "#         # 將 X3 視為轉折點\n",
    "#         t_switch = training_df.loc[i, \"X3\"]\n",
    "\n",
    "#         # 對於每一個時間點，生成一個平滑轉折項\n",
    "#         for t in range(1, T + 1):\n",
    "#             # 基本線性部分：當 t < t_switch 則為 baseline1，之後用 baseline2\n",
    "#             if t < t_switch:\n",
    "#                 mu_base = baseline1\n",
    "#             else:\n",
    "#                 mu_base = baseline2\n",
    "#             # 加上轉折項（使轉折更平滑或更明顯）\n",
    "#             turning_term = delta / (1 + np.exp(-gamma * (t - t_switch)))\n",
    "#             mu_matrix[i, t - 1] = mu_base + turning_term\n",
    "#     return mu_matrix\n",
    "\n",
    "\n",
    "# mu_matrix = cal_mu_matrix_with_turning_point(\n",
    "#     data_size, T, full_df, 1, delta=50, gamma=1.0\n",
    "# )\n",
    "# mu_df = pd.DataFrame(mu_matrix, columns=[f\"t{t}\" for t in range(1, T + 1)])\n",
    "# mu_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前 25 筆資料的 row 總和平均： 1923.8017141614046\n",
      "後 25 筆資料的 row 總和平均： 1499.1527685666672\n"
     ]
    }
   ],
   "source": [
    "# 每一筆 row 的總和\n",
    "row_sums = mu_df.sum(axis=1)\n",
    "\n",
    "# 前 25 筆 row 的總和平均\n",
    "first_25_avg = row_sums.head(25).mean()\n",
    "\n",
    "# 後 25 筆（第 6 到第 30 筆）的 row 總和平均\n",
    "last_25_avg = row_sums.iloc[5:30].mean()\n",
    "\n",
    "print(\"前 25 筆資料的 row 總和平均：\", first_25_avg)\n",
    "print(\"後 25 筆資料的 row 總和平均：\", last_25_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices: [0, 1, 2]\n",
      "Test indices: [15, 16, 17]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAHqCAYAAADVi/1VAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB960lEQVR4nO3df3zN9f//8fvZsF+2M8bZj8wshPktS7ZCEUspStIbIclbWxr9QN/8GO/Mj0jelaLy4/3mrR+IvKMmUspvqaSWECpMja1Zhu18/9jHeXdsODs7Oz92btfL5Vzee71ez/N8PR47ve1xeZzX6/kymM1mswAAAAAAAAAn8nF1AAAAAAAAAPA+NKUAAAAAAADgdDSlAAAAAAAA4HQ0pQAAAAAAAOB0NKUAAAAAAADgdDSlAAAAAAAA4HQ0pQAAAAAAAOB0NKUAAAAAAADgdDSlAAAAAAAA4HQ0pQDYbdCgQapXr56rw6h0Fi5cKIPBoJ9++snVoZQb/40AAABHoD4CKieaUkAlZDAYbHp98sknrg7VyieffGIVn5+fn8LDw9WpUydNmTJFJ0+edHWIbuGnn36y+TOuDIUbAAAVzZm1U35+viZOnGjzXNRHtqE+AjxTFVcHAMDx/vWvf1ltL168WBkZGSX2N2nSpFznmT9/voqKiso1R2lGjBih+Ph4FRYW6uTJk/riiy80YcIEzZo1S2+//bZuvfVWh5/Tk9SuXbvEZzlz5kz9/PPPeuGFF0qMBQAAV+as2kkqbkqlpaVJkjp16mTz+6iProz6CPBMNKWASqh///5W21u3blVGRkaJ/ZfKz89XYGCgzeepWrWqXfFdzc0336zevXtb7fvqq6/UtWtX3Xvvvdq3b58iIyMr5NyeICgoqMRnuWzZMp06deqKn7HZbNbZs2cVEBBQ0SECAOBR7K2dnIn66MqojwDPxO17gJfq1KmTmjVrpl27dqlDhw4KDAzUM888I0latWqV7rjjDkVFRcnPz0/169fX5MmTVVhYaDXHpffDX7xs+vnnn9e8efNUv359+fn5KT4+Xjt27ChXvC1bttTs2bN1+vRpvfTSS1bHfvnlFz300EMKDw+Xn5+fmjZtqjfffNNqzMVL399++22lpaXpmmuuUXBwsHr37q2cnBwVFBQoNTVVJpNJ1atX1+DBg1VQUGA1x4IFC3TrrbfKZDLJz89PcXFxmjt3bolY69WrpzvvvFObN2/WDTfcIH9/f1177bVavHhxibHffvutbr31VgUEBKhOnTr6xz/+4bCrzy7G8eGHH6pt27YKCAjQa6+9Jkk6ffq0UlNTFR0dLT8/PzVo0EDTpk2zOndZP8/33ntPzZo1k7+/v5o1a6aVK1c6JA8AANxBUVGRZs+eraZNm8rf31/h4eEaNmyYTp06ZTVu586d6tatm2rVqqWAgADFxsbqoYceklT8t/XiVTppaWmW28kmTpxoV0zUR2VHfQS4F66UArzY77//rttvv119+/ZV//79FR4eLql4Icnq1atr1KhRql69ujZs2KDx48crNzdXM2bMuOq8S5cu1R9//KFhw4bJYDBo+vTpuueee3Tw4MFyXV3Vu3dvDRkyRB999JGee+45SdKJEyd04403ymAwKCUlRbVr19batWs1ZMgQ5ebmKjU11WqO9PR0BQQEaMyYMfrxxx/1z3/+U1WrVpWPj49OnTqliRMnauvWrVq4cKFiY2M1fvx4y3vnzp2rpk2b6q677lKVKlX0/vvv69FHH1VRUZGSk5OtzvPjjz9a4h04cKDefPNNDRo0SNdff72aNm0qSTp+/LhuueUWXbhwQWPGjFFQUJDmzZvn0G/qMjMz9cADD2jYsGEaOnSoGjVqpPz8fHXs2FG//PKLhg0bprp16+qLL77Q2LFjdezYMc2ePdtqDls+z48++kj33nuv4uLilJ6ert9//12DBw9WnTp1HJYLAACuNGzYMC1cuFCDBw/WiBEjdOjQIb300kv68ssv9fnnn6tq1arKyspS165dVbt2bY0ZM0ahoaH66aeftGLFCknFt43NnTtXw4cPV69evXTPPfdIklq0aGF3XNRHZUd9BLgRM4BKLzk52Xzp/907duxolmR+9dVXS4zPz88vsW/YsGHmwMBA89mzZy37Bg4caI6JibFsHzp0yCzJHBYWZs7OzrbsX7VqlVmS+f33379inBs3bjRLMr/zzjuXHdOyZUtzjRo1LNtDhgwxR0ZGmn/77TercX379jUbjUZLLhfnbtasmfncuXOWcQ888IDZYDCYb7/9dqv3t2/f3io3s7n030u3bt3M1157rdW+mJgYsyTzp59+atmXlZVl9vPzMz/xxBOWfampqWZJ5m3btlmNMxqNZknmQ4cOXfb3cKk77rijRLwX41i3bp3V/smTJ5uDgoLMP/zwg9X+MWPGmH19fc1Hjhwxm81l+zxbtWpljoyMNJ8+fdqy76OPPjJLKhEXAADu7tLa6bPPPjNLMi9ZssRq3Lp166z2r1y50izJvGPHjsvOffLkSbMk84QJE2yKhfqI+giozLh9D/Bifn5+Gjx4cIn9f/0m6o8//tBvv/2mm2++Wfn5+fr++++vOu/999+vGjVqWLZvvvlmSdLBgwfLHXP16tX1xx9/SCpeA2D58uXq0aOHzGazfvvtN8urW7duysnJ0e7du63e/+CDD1pdrdWuXTuZzWbLZfV/3X/06FFduHDBsu+vv5ecnBz99ttv6tixow4ePKicnByr98fFxVnyloq/GW3UqJHV7+CDDz7QjTfeqBtuuMFqXL9+/ez51ZQqNjZW3bp1s9r3zjvv6Oabb1aNGjWsfmddunRRYWGhPv30U6vxV/s8jx07pj179mjgwIEyGo2Wcbfddpvi4uIclgsAAK7yzjvvyGg06rbbbrP623n99derevXq2rhxoyQpNDRUkrRmzRqdP3/eafFRH5UN9RHgPrh9D/Bi11xzjapVq1Zi/7fffqtnn31WGzZsUG5urtWxS4uL0tStW9dq++If7EvXXLBHXl6egoODJUknT57U6dOnNW/ePM2bN6/U8VlZWVeM7WKREB0dXWJ/UVGRcnJyFBYWJkn6/PPPNWHCBG3ZskX5+flW43NycqwKjkvPIxX/Hv76Ozh8+LDatWtXYlyjRo1KzcUesbGxJfbt379fX3/99WWfPHO139mln+fhw4clSQ0bNiwxV6NGjUoUvgAAeJr9+/crJydHJpOp1OMX/3Z27NhR9957r9LS0vTCCy+oU6dO6tmzp/72t7/Jz8+vwuKjPiob6iPAfdCUArxYaffmnz59Wh07dlRISIgmTZqk+vXry9/fX7t379bo0aNtWmTS19e31P1ms7lc8Z4/f14//PCDmjVrJkmWWPr376+BAweW+p5L12i4XGxXi/nAgQPq3LmzGjdurFmzZik6OlrVqlXTBx98oBdeeKHE76WifgdlVdpnXFRUpNtuu01PP/10qe+57rrrrLbdJRcAAFylqKhIJpNJS5YsKfX4xUaGwWDQu+++q61bt+r999/Xhx9+qIceekgzZ87U1q1bVb16dYfHRn1UdtRHgPugKQXAyieffKLff/9dK1asUIcOHSz7Dx065MKoir377rv6888/LZdb165dW8HBwSosLFSXLl0q9Nzvv/++CgoKtHr1aqtvxi5erm+PmJgY7d+/v8T+zMxMu+e0Rf369ZWXl+ew31lMTIwkuSQXAACcoX79+lq/fr0SExNtWnD7xhtv1I033qjnnntOS5cuVb9+/bRs2TI9/PDDMhgMDo2N+sgxqI8A12BNKQBWLn7r89dvec6dO6dXXnnFVSFJkr766iulpqaqRo0alie5+Pr66t5779Xy5cu1d+/eEu85efKkw85f2u8lJydHCxYssHvO7t27a+vWrdq+fbtl38mTJy/7Layj9OnTR1u2bNGHH35Y4tjp06et1omwRWRkpFq1aqVFixZZ3d6ZkZGhffv2lTteAABcrU+fPiosLNTkyZNLHLtw4YJOnz4tqfjWrUuvlGnVqpUkqaCgQJIUGBgoSZb3lAf1keNQHwGuwZVSAKwkJCSoRo0aGjhwoEaMGCGDwaB//etfTr0U+bPPPtPZs2dVWFio33//XZ9//rlWr14to9GolStXKiIiwjJ26tSp2rhxo9q1a6ehQ4cqLi5O2dnZ2r17t9avX6/s7GyHxNS1a1dVq1ZNPXr00LBhw5SXl6f58+fLZDLp2LFjds359NNP61//+peSkpL0+OOPWx55HBMTo6+//tohcZfmqaee0urVq3XnnXdaHsN85swZffPNN3r33Xf1008/qVatWmWaMz09XXfccYduuukmPfTQQ8rOztY///lPNW3aVHl5eRWUCQAAztGxY0cNGzZM6enp2rNnj7p27aqqVatq//79euedd/Tiiy+qd+/eWrRokV555RX16tVL9evX1x9//KH58+crJCRE3bt3l1R861hcXJzeeustXXfddapZs6aaNWtmuf3ucqiPqI+AyoimFAArYWFhWrNmjZ544gk9++yzqlGjhvr376/OnTuXeEpJRZkzZ44kqWrVqgoNDVWTJk2UlpamoUOHllh8Mjw8XNu3b9ekSZO0YsUKvfLKKwoLC1PTpk01bdo0h8XUqFEjvfvuu3r22Wf15JNPKiIiQsOHD1ft2rVLPJnGVpGRkdq4caMee+wxTZ06VWFhYfr73/+uqKgoDRkyxGGxXyowMFCbNm3SlClT9M4772jx4sUKCQnRddddp7S0NKsFSW2VlJSkd955R88++6zGjh2r+vXra8GCBVq1apU++eQTxycBAICTvfrqq7r++uv12muv6ZlnnlGVKlVUr1499e/fX4mJiZKKm1fbt2/XsmXLdOLECRmNRt1www1asmSJ1eLar7/+uh577DGNHDlS586d04QJE67alKI+oj4CKiODmZXYAAAAAAAA4GSsKQUAAAAAAACnoykFAAAAAAAAp6MpBQAAAAAAAKejKQUAAAAAAACnoykFAAAAAAAAp6MpBQAAAAAAAKer4uoA3EFRUZF+/fVXBQcHy2AwuDocAADgxsxms/744w9FRUXJx8d7vt+jXgIAALaytV6iKSXp119/VXR0tKvDAAAAHuTo0aOqU6eOq8NwGuolAABQVlerl2hKSQoODpZU/MsKCQlxcTQAAMCd5ebmKjo62lI/eAvqJQAAYCtb6yWaUpLlEvSQkBCKLAAAYBNvu4WNegkAAJTV1eol71kIAQAAAAAAAG6DphQAAAAAAACcjqYUAAAAAAAAnI6mFAAAAAAAAJyOphQAAAAAAACcjqYUAAAAAAAAnI6mFAAAAAAAAJyOphQAAAAAAACcjqYUAAAAAAAAnI6mFAAAAAAAAJyOphQAAAAAAACcroqrA6jsCosKtTtrt07mn1TtwNpqY2ojXx9fV4dVLuTkGcjJM5CT56iMeZET3EVhkVnbD2Ur64+zMgX764bYmvL1Mbg6rHIhJ89ATp6hMuYkVc68yMkzuFNONKUq0PrD6zV1+1SdyD9h2RceGK4xN4xRl5guLozMfuTkGcjJM5CT56iMeZET3MW6vceU9v4+Hcs5a9kXafTXhB5xSmoW6cLI7EdOnoGcPENlzEmqnHmRk2dwt5wMZrPZ7PSzupnc3FwZjUbl5OQoJCTEIXOuP7xeoz4ZJbOsf70GFXcfZ3Wa5XEFMjl5BnLyDOTkOSpjXuRUPhVRN3iCish73d5jGv7v3bq0GL34Xe3c/m08rugnJ89ATp6hMuYkVc68yMkzODMnW+sGmlJyfJFVWFSobsu7WX1Te6nwwHCtvGulx9xSUFhUqJ6reyorP+uyY8jJ9ciJnFylMuYkVc68vDEngwwKDwzXunvXOSQnmlKOqpfMumnaBqtvav/KICk8xF8Zozp4zG0ShUVmdZm1SSdyC0o9Tk7ugZzIyZUqY17kVHlyijD6a/PoWx2SE02pMnB0kbXj+A499OFDDogMAAA4ypvd3lR8RHy556Ep5Zi8txz4XQ/M3+qAyAAAgKP8Z+iNal8/rNzz2Fo38PS9CnAy/6SrQwAAAJfg77N7yfqj9CukAACA6zj77zMLnVeA2oG1bRr3SudXdH349RUcjWPsOrFLj3786FXHkZNrkRM5uUplzEmqnHl5c062/n2Gc5iC/W0at3BwvG6IrVnB0TjG9kPZGrRgx1XHkZNrkRM5uVJlzIucKldOtv59dhSaUhWgjamNwgPDlZWfVWLBVel/a1skRCV4zHodCVEJ5OQByImcXKUy5iRVzry8Oac2pjYuiA6Xc0NsTUUa/XU852wpn9r/1ra4uWFtj1mv4+aGtcnJA5ATOblSZcyLnCpXTs5usnH7XgXw9fHVmBvGSPrfU38uurg9+obRHlPsS+TkKcjJM5CT56iMeZET3IWvj0ETesRJki4t5y9uT+gR5zHFvkROnoKcPENlzEmqnHmRk2dw15xoSlWQLjFdNKvTLJkCTVb7wwPDPfJR2xI5eQpy8gzk5DkqY17kBHeR1CxSc/u3UYTR+laBCKO/Rz5qWyInT0FOnqEy5iRVzrzIyTO4Y048fU8V+xSdwqJC7c7arZP5J1U7sLbamNp4/De15OQZyMkzkJPnqIx5kZN9ePpeRdRLZm0/lK2sP87KFFx864AnfftcGnLyDOTkGSpjTlLlzIucPIMzcrK1bqApJe8tLgEAQNl5a93grXkDAICys7Vu4PY9AAAAAAAAOB1NKQAAAAAAADgdTSkAAAAAAAA4nUubUunp6YqPj1dwcLBMJpN69uypzMxMqzEHDhxQr169VLt2bYWEhKhPnz46ceKE1Zjs7Gz169dPISEhCg0N1ZAhQ5SXl+fMVAAAAAAAAFAGLm1Kbdq0ScnJydq6dasyMjJ0/vx5de3aVWfOnJEknTlzRl27dpXBYNCGDRv0+eef69y5c+rRo4eKioos8/Tr10/ffvutMjIytGbNGn366ad65JFHXJUWAAAAAAAArsKtnr538uRJmUwmbdq0SR06dNBHH32k22+/XadOnbKs1p6Tk6MaNWroo48+UpcuXfTdd98pLi5OO3bsUNu2bSVJ69atU/fu3fXzzz8rKirqquflaTIAAMBW3lo3eGveAACg7Dzy6Xs5OTmSpJo1a0qSCgoKZDAY5OfnZxnj7+8vHx8fbd68WZK0ZcsWhYaGWhpSktSlSxf5+Pho27ZtpZ6noKBAubm5Vi8AAAAAAAA4j9s0pYqKipSamqrExEQ1a9ZMknTjjTcqKChIo0ePVn5+vs6cOaMnn3xShYWFOnbsmCTp+PHjMplMVnNVqVJFNWvW1PHjx0s9V3p6uoxGo+UVHR1dsckBAAAAAADAits0pZKTk7V3714tW7bMsq927dp655139P7776t69eoyGo06ffq02rRpIx8f+0MfO3ascnJyLK+jR486IgUAAAAAAADYqIqrA5CklJQUywLlderUsTrWtWtXHThwQL/99puqVKmi0NBQRURE6Nprr5UkRUREKCsry+o9Fy5cUHZ2tiIiIko9n5+fn9UtgQAAAAAAAHAul14pZTablZKSopUrV2rDhg2KjY297NhatWopNDRUGzZsUFZWlu666y5JUvv27XX69Gnt2rXLMnbDhg0qKipSu3btKjwHAAAAAAAAlJ1Lr5RKTk7W0qVLtWrVKgUHB1vWgDIajQoICJAkLViwQE2aNFHt2rW1ZcsWPf744xo5cqQaNWokSWrSpImSkpI0dOhQvfrqqzp//rxSUlLUt29fm568BwAAAAAAAOdzaVNq7ty5kqROnTpZ7V+wYIEGDRokScrMzNTYsWOVnZ2tevXq6f/9v/+nkSNHWo1fsmSJUlJS1LlzZ/n4+Ojee+/VnDlznJECAAAAAAAA7GAwm81mVwfharm5uTIajcrJyVFISIirwwEAAG7MW+sGb80bAACUna11g9s8fQ8AAAAAAADeg6YUAAAAAAAAnI6mFAAAAAAAAJyOphQAAAAAAACcjqYUAAAAAAAAnI6mFAAAAAAAAJyOphQAAAAAAACcjqYUAAAAAAAAnI6mFAAAAAAAAJyOphQAAAAAAACcjqYUAAAAAAAAnI6mFAAAAAAAAJyOphQAAAAAAACcjqYUAAAAAAAAnI6mFAAAAAAAAJyOphQAAAAAAACcjqYUAAAAAAAAnI6mFAAAAAAAAJyOphQAAAAAAACcjqYUAAAAAAAAnI6mFAAAAAAAAJyOphQAAAAAAACcjqYUAACAh/vll1/Uv39/hYWFKSAgQM2bN9fOnTutxnz33Xe66667ZDQaFRQUpPj4eB05csRFEQMAAEhVXB0AAAAA7Hfq1CklJibqlltu0dq1a1W7dm3t379fNWrUsIw5cOCAbrrpJg0ZMkRpaWkKCQnRt99+K39/fxdGDgAAvB1NKQAAAA82bdo0RUdHa8GCBZZ9sbGxVmP+3//7f+revbumT59u2Ve/fn2nxQgAAFAabt8DAADwYKtXr1bbtm113333yWQyqXXr1po/f77leFFRkf773//quuuuU7du3WQymdSuXTu99957rgsaAABANKUAAAA82sGDBzV37lw1bNhQH374oYYPH64RI0Zo0aJFkqSsrCzl5eVp6tSpSkpK0kcffaRevXrpnnvu0aZNmy47b0FBgXJzc61eAAAAjsTtewAAAB6sqKhIbdu21ZQpUyRJrVu31t69e/Xqq69q4MCBKioqkiTdfffdGjlypCSpVatW+uKLL/Tqq6+qY8eOpc6bnp6utLQ05yQBAAC8EldKAQAAeLDIyEjFxcVZ7WvSpInlyXq1atVSlSpVrjimNGPHjlVOTo7ldfToUccHDwAAvBpXSgEAAHiwxMREZWZmWu374YcfFBMTI0mqVq2a4uPjrzimNH5+fvLz83N8wAAAAP+HphQAAIAHGzlypBISEjRlyhT16dNH27dv17x58zRv3jzLmKeeekr333+/OnTooFtuuUXr1q3T+++/r08++cR1gQMAAK/H7XsAAAAeLD4+XitXrtR//vMfNWvWTJMnT9bs2bPVr18/y5hevXrp1Vdf1fTp09W8eXO9/vrrWr58uW666SYXRg4AALydwWw2m10dhKvl5ubKaDQqJydHISEhrg4HAAC4MW+tG7w1bwAAUHa21g1cKQUAAAAAAACnc2lTKj09XfHx8QoODpbJZFLPnj1LLMJ5/PhxDRgwQBEREQoKClKbNm20fPlyqzH16tWTwWCwek2dOtWZqQAAAAAAAKAMXNqU2rRpk5KTk7V161ZlZGTo/Pnz6tq1q86cOWMZ8+CDDyozM1OrV6/WN998o3vuuUd9+vTRl19+aTXXpEmTdOzYMcvrsccec3Y6AAAAAAAAsJFLn763bt06q+2FCxfKZDJp165d6tChgyTpiy++0Ny5c3XDDTdIkp599lm98MIL2rVrl1q3bm15b3BwsCIiIpwXPAAAAAAAAOzmVmtK5eTkSJJq1qxp2ZeQkKC33npL2dnZKioq0rJly3T27Fl16tTJ6r1Tp05VWFiYWrdurRkzZujChQvODB0AAAAAAABl4NIrpf6qqKhIqampSkxMVLNmzSz73377bd1///0KCwtTlSpVFBgYqJUrV6pBgwaWMSNGjFCbNm1Us2ZNffHFFxo7dqyOHTumWbNmlXqugoICFRQUWLZzc3MrLjEAAAAAAACU4DZNqeTkZO3du1ebN2+22j9u3DidPn1a69evV61atfTee++pT58++uyzz9S8eXNJ0qhRoyzjW7RooWrVqmnYsGFKT0+Xn59fiXOlp6crLS2tYhMCAAAAAADAZRnMZrPZ1UGkpKRo1apV+vTTTxUbG2vZf+DAATVo0EB79+5V06ZNLfu7dOmiBg0a6NVXXy11vm+//VbNmjXT999/r0aNGpU4XtqVUtHR0crJyVFISIgDMwMAAJVNbm6ujEaj19UN3po3AAAoO1vrBpdeKWU2m/XYY49p5cqV+uSTT6waUpKUn58vSfLxsV76ytfXV0VFRZedd8+ePfLx8ZHJZCr1uJ+fX6lXUAEAAAAAAMA5XNqUSk5O1tKlS7Vq1SoFBwfr+PHjkiSj0aiAgAA1btxYDRo00LBhw/T8888rLCxM7733njIyMrRmzRpJ0pYtW7Rt2zbdcsstCg4O1pYtWzRy5Ej1799fNWrUcGV6AAAAAAAAuAyXNqXmzp0rSSWepLdgwQINGjRIVatW1QcffKAxY8aoR48eysvLU4MGDbRo0SJ1795dUvFVT8uWLdPEiRNVUFCg2NhYjRw50mqdKQAAAAAAALgXl9++dzUNGzbU8uXLL3u8TZs22rp1qyPDAgAAAAAAQAXzufoQAAAAAAAAwLFoSgEAAAAAAMDpaEoBAAAAAADA6WhKAQAAAAAAwOloSgEAAAAAAMDpaEoBAAAAAADA6WhKAQAAAAAAwOloSgEAAAAAAMDpaEoBAAAAAADA6WhKAQAAAAAAwOloSgEAAAAAAMDpaEoBAAAAAADA6WhKAQAAAAAAwOloSgEAAAAAAMDpaEoBAAAAAADA6WhKAQAAAAAAwOloSgEAAAAAAMDpaEoBAAAAAADA6WhKAQAAAAAAwOloSgEAAAAAAMDpaEoBAAAAAADA6WhKAQAAAAAAwOloSgEAAAAAAMDpaEoBAAAAAADA6WhKAQAAAAAAwOloSgEAAAAAAMDpaEoBAAAAAADA6WhKAQAAAAAAwOloSgEAAAAAAMDpaEoBAAAAAADA6WhKAQAAAAAAwOloSgEAAAAAAMDpaEoBAAAAAADA6WhKAQAAAAAAwOlc2pRKT09XfHy8goODZTKZ1LNnT2VmZlqNOX78uAYMGKCIiAgFBQWpTZs2Wr58udWY7Oxs9evXTyEhIQoNDdWQIUOUl5fnzFQAAAAAAABQBi5tSm3atEnJycnaunWrMjIydP78eXXt2lVnzpyxjHnwwQeVmZmp1atX65tvvtE999yjPn366Msvv7SM6devn7799ltlZGRozZo1+vTTT/XII4+4IiUAAAAAAADYwGA2m82uDuKikydPymQyadOmTerQoYMkqXr16po7d64GDBhgGRcWFqZp06bp4Ycf1nfffae4uDjt2LFDbdu2lSStW7dO3bt3188//6yoqKirnjc3N1dGo1E5OTkKCQmpmOQAAECl4K11g7fmDQAAys7WusGt1pTKycmRJNWsWdOyLyEhQW+99Zays7NVVFSkZcuW6ezZs+rUqZMkacuWLQoNDbU0pCSpS5cu8vHx0bZt25waPwAAAAAAAGxTxdUBXFRUVKTU1FQlJiaqWbNmlv1vv/227r//foWFhalKlSoKDAzUypUr1aBBA0nFa06ZTCaruapUqaKaNWvq+PHjpZ6roKBABQUFlu3c3NwKyAgAAAAAAACX4zZXSiUnJ2vv3r1atmyZ1f5x48bp9OnTWr9+vXbu3KlRo0apT58++uabb+w+V3p6uoxGo+UVHR1d3vABAAAAAABQBm5xpVRKSoplgfI6depY9h84cEAvvfSS9u7dq6ZNm0qSWrZsqc8++0wvv/yyXn31VUVERCgrK8tqvgsXLig7O1sRERGlnm/s2LEaNWqUZTs3N5fGFAAAAAAAgBO59Eops9mslJQUrVy5Uhs2bFBsbKzV8fz8fEmSj491mL6+vioqKpIktW/fXqdPn9auXbssxzds2KCioiK1a9eu1PP6+fkpJCTE6gUAAAAAAADncemVUsnJyVq6dKlWrVql4OBgyxpQRqNRAQEBaty4sRo0aKBhw4bp+eefV1hYmN577z1lZGRozZo1kqQmTZooKSlJQ4cO1auvvqrz588rJSVFffv2tenJewAAAAAAAHA+l14pNXfuXOXk5KhTp06KjIy0vN566y1JUtWqVfXBBx+odu3a6tGjh1q0aKHFixdr0aJF6t69u2WeJUuWqHHjxurcubO6d++um266SfPmzXNVWgAAAAAAALgKl14pZTabrzqmYcOGWr58+RXH1KxZU0uXLnVUWAAAAAAAAKhgbvP0PQAAANjnl19+Uf/+/RUWFqaAgAA1b95cO3futBwfNGiQDAaD1SspKcmFEQMAALjJ0/cAAABgn1OnTikxMVG33HKL1q5dq9q1a2v//v2qUaOG1bikpCQtWLDAsu3n5+fsUAEAAKzQlAIAAPBg06ZNU3R0tFXD6dInGkvFTaiIiAhnhgYAAHBF3L4HAADgwVavXq22bdvqvvvuk8lkUuvWrTV//vwS4z755BOZTCY1atRIw4cP1++//+6CaAEAAP6HphQAAIAHO3jwoObOnauGDRvqww8/1PDhwzVixAgtWrTIMiYpKUmLFy/Wxx9/rGnTpmnTpk26/fbbVVhYeNl5CwoKlJuba/UCAABwJIPZlkfgXeLQoUP67LPPdPjwYeXn56t27dpq3bq12rdvL39//4qIs0Ll5ubKaDQqJydHISEhrg4HAAC4MUfVDY6qp6pVq6a2bdvqiy++sOwbMWKEduzYoS1btpT6noMHD6p+/fpav369OnfuXOqYiRMnKi0trcR+6iUAAHA1ttZLZVpTasmSJXrxxRe1c+dOhYeHKyoqSgEBAcrOztaBAwfk7++vfv36afTo0YqJiSl3EgAAAJWNo+upyMhIxcXFWe1r0qSJli9fftn3XHvttapVq5Z+/PHHyzalxo4dq1GjRlm2c3NzFR0dbWOWAAAAV2dzU6p169aqVq2aBg0apOXLl5coSgoKCrRlyxYtW7ZMbdu21SuvvKL77rvP4QEDAAB4qoqopxITE5WZmWm174cffrhiQ+vnn3/W77//rsjIyMuO8fPz4wl9AACgQtl8+96HH36obt262TTp77//rp9++knXX399uYJzFm7fAwAAtipP3VAR9dSOHTuUkJCgtLQ09enTR9u3b9fQoUM1b9489evXT3l5eUpLS9O9996riIgIHThwQE8//bT++OMPffPNNzY3nqiXAACArWytG+xaU6qyocgCAAC2cse6Yc2aNRo7dqz279+v2NhYjRo1SkOHDpUk/fnnn+rZs6e+/PJLnT59WlFRUeratasmT56s8PBwm8/hjnkDAAD3VCFrSl105MiRKx6vW7euPdMCAAB4DUfWU3feeafuvPPOUo8FBAToww8/LFNsAAAAzmBXU6pevXoyGAyXPX6lxwsDAACAegoAAMCuptSXX35ptX3+/Hl9+eWXmjVrlp577jmHBAYAAFCZUU8BAABvZ1dTqmXLliX2tW3bVlFRUZoxY4buueeecgcGAABQmVFPAQAAb+fjyMkaNWqkHTt2OHJKAAAAr0I9BQAAvIVdV0rl5uZabZvNZh07dkwTJ05Uw4YNHRIYAABAZUY9BQAAvJ1dTanQ0NASC3OazWZFR0dr2bJlDgkMAACgMqOeAgAA3s6uptTGjRuttn18fFS7dm01aNBAVarYNSUAAIBXoZ4CAADezq6Kp2PHjo6OAwAAwKtQTwEAAG9n99dwv/76qzZv3qysrCwVFRVZHRsxYkS5AwMAAKjsqKcAAIA3s6sptXDhQg0bNkzVqlVTWFiY1XoIBoOBIgoAAOAqqKcAAIC3M5jNZnNZ3xQdHa2///3vGjt2rHx8fCoiLqfKzc2V0WhUTk6OQkJCXB0OAABwY46qGzytnqJeAgAAtrK1brCrAsrPz1ffvn09ooACAABwR9RTAADA29lVBQ0ZMkTvvPOOo2MBAADwGtRTAADA29l1+15hYaHuvPNO/fnnn2revLmqVq1qdXzWrFkOC9AZuBwdAADYylF1g6fVU9RLAADAVrbWDXYtdJ6enq4PP/xQjRo1kqQSC3MCAADgyqinAACAt7OrKTVz5ky9+eabGjRokIPDAQAA8A7UUwAAwNvZtaaUn5+fEhMTHR0LAACA16CeAgAA3s6uptTjjz+uf/7zn46OBQAAwGtQTwEAAG9n1+1727dv14YNG7RmzRo1bdq0xMKcK1ascEhwAAAAlRX1FAAA8HZ2NaVCQ0N1zz33ODoWAAAAr0E9BQAAvJ1dTakFCxY4Og4AAACvQj0FAAC8nV1rSgEAAAAAAADlYXNTKikpSVu3br3quD/++EPTpk3Tyy+/XK7AAAAAKhvqKQAAgP+x+fa9++67T/fee6+MRqN69Oihtm3bKioqSv7+/jp16pT27dunzZs364MPPtAdd9yhGTNmVGTcAAAAHod6CgAA4H8MZrPZbOvggoICvfPOO3rrrbe0efNm5eTkFE9iMCguLk7dunXTkCFD1KRJE5vmS09P14oVK/T9998rICBACQkJmjZtmho1aiRJ+umnnxQbG1vqe99++23dd999lvNf6j//+Y/69u1rUxy5ubkyGo3KyclRSEiITe8BAADeqbx1g6PrKWehXgIAALaytW4oU1PqUjk5Ofrzzz8VFhZW4jHGtkhKSlLfvn0VHx+vCxcu6JlnntHevXu1b98+BQUFqbCwUCdPnrR6z7x58zRjxgwdO3ZM1atXL07CYNCCBQuUlJRkGRcaGip/f3+b4qDIAgAAtnJ03VDeespZqJcAAICtbK0b7Hr63kVGo1FGo9Hu969bt85qe+HChTKZTNq1a5c6dOggX19fRUREWI1ZuXKl+vTpY2lIXRQaGlpiLAAAgLsrbz0FAADgqcrVlHK0i5ev16xZs9Tju3bt0p49e0pd9DM5OVkPP/ywrr32Wv3973/X4MGDS72tTyq+bL6goMCynZub64DoAQBwvMLCQp0/f97VYXiVqlWrytfX19VhAACAKygqKtK5c+dcHYbXclS95DZNqaKiIqWmpioxMVHNmjUrdcwbb7yhJk2aKCEhwWr/pEmTdOuttyowMFAfffSRHn30UeXl5WnEiBGlzpOenq60tDSH5wAAgKOYzWYdP35cp0+fdnUoXuniFdiX+4ILAAC4zrlz53To0CEVFRW5OhSv5oh6qVxrSjnS8OHDtXbtWm3evFl16tQpcfzPP/9UZGSkxo0bpyeeeOKKc40fP14LFizQ0aNHSz1e2pVS0dHRrJEAAHAbx44d0+nTp2UymRQYGEhzxEnMZrPy8/OVlZWl0NBQRUZGlhjjrWsreWveAAD3YjabdeTIEZ0/f15RUVHy8fFxdUhex5H1kltcKZWSkqI1a9bo008/LbUhJUnvvvuu8vPz9eCDD151vnbt2mny5MkqKCiQn59fieN+fn6l7gcAwB0UFhZaGlJhYWGuDsfrBAQESJKysrJkMpm4lQ8AADdy4cIF5efnKyoqSoGBga4Ox2s5ql4qV1Pq3LlzysrKKnHJXN26dW16v9ls1mOPPaaVK1fqk08+UWxs7GXHvvHGG7rrrrtUu3btq867Z88e1ahRg8YTAMAjXVxDikLLdS7+7s+fP1/hTany1lMAAHiTwsJCSVK1atVcHAkcUS/Z1ZTav3+/HnroIX3xxRdW+81mswwGg+U/kqtJTk7W0qVLtWrVKgUHB+v48eOSip9Cc7HrJkk//vijPv30U33wwQcl5nj//fd14sQJ3XjjjfL391dGRoamTJmiJ5980p7UAABwG9yy5zrO+N07qp4CAMAbUSe5niM+A7uaUoMGDVKVKlW0Zs0aRUZG2h3I3LlzJUmdOnWy2r9gwQINGjTIsv3mm2+qTp066tq1a4k5qlatqpdfflkjR46U2WxWgwYNNGvWLA0dOtSumAAAAJzBUfUUAACAp7KrKbVnzx7t2rVLjRs3LtfJbV1jfcqUKZoyZUqpx5KSkpSUlFSuOAAAgPuqV6+eUlNTlZqa6upQHMpR9RQAAICnsmuZ+ri4OP3222+OjgUAADhYYZFZWw78rlV7ftGWA7+rsKjiHrprMBiu+Jo4caJd8+7YsUOPPPJIuWIzm80aP368IiMjFRAQoC5dumj//v3lmrO8qKcAAHCdylAjXZz7vffeu+q45557TgkJCQoMDFRoaKjNcS5btszu2Gxh15VS06ZN09NPP60pU6aoefPmqlq1qtVxHhMMAIDrrdt7TGnv79OxnLOWfZFGf03oEaekZiUf3Vtex44ds/z81ltvafz48crMzLTsq169uuVns9mswsJCValy9VLEloecXM306dM1Z84cLVq0SLGxsRo3bpy6deumffv2yd/fv9zz24N6CgAA13DnGqminDt3Tvfdd5/at2+vN95447LjFixYYHU32uUaWI5i15VSXbp00datW9W5c2eZTCbVqFFDNWrUUGhoqGrUqOHoGAEAQBmt23tMw/+926rYkqTjOWc1/N+7tW7vscu8034RERGWl9FolMFgsGx///33Cg4O1tq1a3X99dfLz89Pmzdv1oEDB3T33XcrPDxc1atXV3x8vNavX281b7169TR79mzLtsFg0Ouvv65evXopMDBQDRs21OrVqy8bl9ls1uzZs/Xss8/q7rvvVosWLbR48WL9+uuvNn2zWFGopwAAcD53q5EiIiK0bNkyNWnSRP7+/mrcuLFeeeUVy3vPnTunlJQURUZGyt/fXzExMUpPT5dUXCNJUq9evWQwGCzbpUlLS9PIkSPVvHnzK8YaGhpqFVtFf3ln15VSGzdudHQcAADgCsxms/48b9vT2AqLzJqw+luVdhG6WZJB0sTV+5TYoJZ8fa68uHZAVV+HLsA9ZswYPf/887r22mtVo0YNHT16VN27d9dzzz0nPz8/LV68WD169FBmZqbq1q172XnS0tI0ffp0zZgxQ//85z/Vr18/HT58WDVr1iwx9tChQzp+/Li6dOli2Wc0GtWuXTtt2bJFffv2dVh+ZUE9BQBA+bmqRpIcUyctWbJE48eP10svvaTWrVvryy+/1NChQxUUFKSBAwdqzpw5Wr16td5++23VrVtXR48e1dGjRyUVL3FgMpksVzf5+vqWKxZJSk5O1sMPP6xrr71Wf//73zV48OAKfRiLXU2pjh07OjoOAABwBX+eL1Tc+A8dMpdZ0vHcs2o+8aOrjt03qZsCq9lVLpRq0qRJuu222yzbNWvWVMuWLS3bkydP1sqVK7V69WqlpKRcdp5BgwbpgQcekFT8QJQ5c+Zo+/btpT785Pjx45Kk8PBwq/3h4eGWY65APQUAQPm5qkaSHFMnTZgwQTNnztQ999wjSYqNjdW+ffv02muvaeDAgTpy5IgaNmyom266SQaDQTExMZb3Xlzi4OLVTeU1adIk3XrrrQoMDNRHH32kRx99VHl5eRoxYkS5576ccv328vPzdeTIEZ07d85qf4sWLcoVFAAAqJzatm1rtZ2Xl6eJEyfqv//9r44dO6YLFy7ozz//1JEjR644z19rjaCgIIWEhCgrK6tCYq5o1FMAAHinM2fO6MCBAxoyZIiGDh1q2X/hwgUZjUZJxV/E3XbbbWrUqJGSkpJ05513qmvXrhUSz7hx4yw/t27dWmfOnNGMGTPcryl18uRJDR48WGvXri31eGGhbZfOAQAA2wRU9dW+Sd1sGrv9ULYGLdhx1XELB8frhtiSt7tdel5HCgoKstp+8sknlZGRoeeff14NGjRQQECAevfuXaJBc6lLFwU3GAwqKioqdezFbw5PnDihyMj/LV564sQJtWrVyo4sHIN6CgCA8nNVjXTx3OWRl5cnSZo/f77atWtndezirXht2rTRoUOHtHbtWq1fv159+vRRly5d9O6775br3LZo166dJk+erIKCAvn5+VXIOexqSqWmpur06dPatm2bOnXqpJUrV+rEiRP6xz/+oZkzZzo6RgAAvJ7BYLD58vCbG9ZWpNFfx3POlrpmgkFShNFfNzesbdN6CRXp888/16BBg9SrVy9JxcXZTz/95NBzxMbGKiIiQh9//LGlCZWbm6tt27Zp+PDhDj1XWVBPAQBQfp5cI4WHhysqKkoHDx5Uv379LjsuJCRE999/v+6//3717t1bSUlJys7OVs2aNVW1atUK+yJrz549qlGjRoU1pCQ7m1IbNmzQqlWr1LZtW/n4+CgmJka33XabQkJClJ6erjvuuMPRcQIAABv5+hg0oUechv97twySVdF1sbya0CPO5Q0pSWrYsKFWrFihHj16yGAwaNy4cZe94sleBoNBqamp+sc//qGGDRsqNjZW48aNU1RUlHr27OnQc5UF9RQAAM7ljjVSWlqaRowYIaPRqKSkJBUUFGjnzp06deqURo0apVmzZikyMlKtW7eWj4+P3nnnHUVERCg0NFRS8RP4Pv74YyUmJsrPz++yT/A9cuSIsrOzdeTIERUWFmrPnj2SpAYNGqh69ep6//33deLECd14443y9/dXRkaGpkyZoieffLJC8/ex501nzpyRyWSSJNWoUUMnT56UJDVv3ly7d+92XHQAAMAuSc0iNbd/G0UYrR/jG2H019z+bZTULPIy73SuWbNmqUaNGkpISFCPHj3UrVs3tWnTxuHnefrpp/XYY4/pkUceUXx8vPLy8rRu3boKf8zxlVBPAQDgfO5WIz388MN6/fXXtWDBAjVv3lwdO3bUwoULFRsbK0kKDg7W9OnT1bZtW8XHx+unn37SBx98IB+f4nbOzJkzlZGRoejoaLVu3fqy5xk/frxat26tCRMmKC8vT61bt1br1q21c+dOScVLI7z88stq3769WrVqpddee02zZs3ShAkTKjR/g9lsLu2qtSuKj4/XP/7xD3Xr1k133XWXQkNDlZ6erjlz5ujdd9/VgQMHKiLWCpObmyuj0aicnByFhIS4OhwAgJc7e/asDh06pNjY2HI3TQqLzNp+KFtZf5yVKdhfN8TWdIsrpNzdlT4DR9UNnlZPUS8BANyBo+okaqTyc0S9ZNfte48//riOHTsmqfjxhUlJSVqyZImqVaumhQsX2jMlAACoAL4+BrWvH+bqMFAK6ikAAFyHGsk92NWU6t+/v+Xn66+/XocPH9b333+vunXrqlatWg4LDgAAoLKingIAAN7OrjWlLjp37pwyMzNVrVo1tWnThgIKAACgjKinAACAt7KrKZWfn68hQ4YoMDBQTZs21ZEjRyRJjz32mKZOnerQAAEAACoj6ikAAODt7GpKjR07Vl999ZU++eQTq8WsunTporfeesthwQEAAFRW1FMAAMDb2bWm1Hvvvae33npLN954owyG/61O37RpU7d7UgwAAIA7op4CAADezq4rpU6ePCmTyVRi/5kzZ6yKKgAAAJSOegoAAHg7u5pSbdu21X//+1/L9sXC6fXXX1f79u0dExkAAEAlRj0FAAC8nV23702ZMkW333679u3bpwsXLujFF1/Uvn379MUXX2jTpk2OjhEAAKDSoZ4CAADezq4rpW666Sbt2bNHFy5cUPPmzfXRRx/JZDJpy5Ytuv766x0dIwAA8GL16tXT7NmzXR2Gw1FPAQAAb2dXU0qS6tevr/nz52v79u3at2+f/v3vf6t58+aOjA0AAJRXUaF06DPpm3eL/7eosMJOZTAYrviaOHGiXfPu2LFDjzzySLliW7Fihbp27aqwsDAZDAbt2bOnXPM5CvUUAAAuUglqpItzv/fee1cd99xzzykhIUGBgYEKDQ297LiFCxeqRYsW8vf3l8lkUnJyst2x2cKu2/cAAIAH2LdaWjdayv31f/tCoqSkaVLcXQ4/3bFjxyw/v/XWWxo/frwyMzMt+6pXr2752Ww2q7CwUFWqXL0UqV27drljO3PmjG666Sb16dNHQ4cOLfd87uaXX37R6NGjtXbtWuXn56tBgwZasGCB2rZtW2Ls3//+d7322mt64YUXlJqa6vxgAQBwNTeukSrKuXPndN9996l9+/Z64403Sh0za9YszZw5UzNmzFC7du105swZ/fTTTxUaV5mulPL19bXpBQAAXGzfauntB62LLUnKPVa8f99qh58yIiLC8jIajTIYDJbt77//XsHBwVq7dq2uv/56+fn5afPmzTpw4IDuvvtuhYeHq3r16oqPj9f69eut5r309j2DwaDXX39dvXr1UmBgoBo2bKjVq6+cz4ABAzR+/Hh16dLF4XmXlaPrqVOnTikxMVFVq1bV2rVrtW/fPs2cOVM1atQoMXblypXaunWroqKiHJkSAACew81qpIiICC1btkxNmjSRv7+/GjdurFdeecXy3nPnziklJUWRkZHy9/dXTEyM0tPTJRXXSJLUq1cvGQwGy3Zp0tLSNHLkyMtekX3q1Ck9++yzWrx4sf72t7+pfv36atGihe66y/FNur8q05VSZrNZMTExGjhwoFq3bl1RMQEAgEuZzdL5fNvGFhVKa5+WZC5tIkmG4m8Hr+0k+Vyl+VE1UPq/p8I5wpgxY/T888/r2muvVY0aNXT06FF1795dzz33nPz8/LR48WL16NFDmZmZqlu37mXnSUtL0/Tp0zVjxgz985//VL9+/XT48GHVrFnTYbFWFEfXU9OmTVN0dLQWLFhg2RcbG1ti3C+//KLHHntMH374oe64445ynxcAALfgqhpJckidtGTJEo0fP14vvfSSWrdurS+//FJDhw5VUFCQBg4cqDlz5mj16tV6++23VbduXR09elRHjx6VVLzEgclk0oIFC5SUlFSui4QyMjJUVFSkX375RU2aNNEff/yhhIQEzZw5U9HR0eXK8UrK1JTavn273njjDb344ouKjY3VQw89pH79+pX6TRwAAHCg8/nSFEdd3WIu/nZwqg0FxjO/StWCHHReadKkSbrtttss2zVr1lTLli0t25MnT9bKlSu1evVqpaSkXHaeQYMG6YEHHpBU/BS7OXPmaPv27UpKSnJYrBXF0fXU6tWr1a1bN913333atGmTrrnmGj366KNWtykWFRVpwIABeuqpp9S0aVOb5i0oKFBBQYFlOzc31674AACoUK6qkSSH1EkTJkzQzJkzdc8990gq/mJp3759eu211zRw4EAdOXJEDRs21E033SSDwaCYmBjLey8ucRAaGqqIiIhyxXHw4EEVFRVpypQpevHFF2U0GvXss8/qtttu09dff61q1aqVa/7LKdPte23bttXcuXN17NgxjRo1SitXrlSdOnXUt29fZWRkVEiAAACg8rh0jaO8vDw9+eSTatKkiUJDQ1W9enV99913OnLkyBXnadGiheXnoKAghYSEKCsrq0JidjRH11MHDx7U3Llz1bBhQ3344YcaPny4RowYoUWLFlnGTJs2TVWqVNGIESNsnjc9PV1Go9HyqshvSQEA8EZnzpzRgQMHNGTIEFWvXt3y+sc//qEDBw5IKv4ibs+ePWrUqJFGjBihjz76qEJiKSoq0vnz5zVnzhx169ZNN954o/7zn/9o//792rhxY4WcU7JzoXN/f3/1799f/fv316FDhzRkyBAlJSXp5MmTHnHZPAAAHqdqYPG3cbY4/IW0pPfVx/V7V4pJuPp5HSgoyPrbxCeffFIZGRl6/vnn1aBBAwUEBKh37946d+7clcOqWtVq22AwqKioyKGxVjRH1VNFRUVq27atpkyZIklq3bq19u7dq1dffVUDBw7Url279OKLL2r37t0ylOEWg7Fjx2rUqFGW7dzcXBpTAAD346oa6eK5yyEvL0+SNH/+fLVr187q2MVb8dq0aaNDhw5p7dq1Wr9+vfr06aMuXbro3XffLde5LxUZGSlJiouLs+yrXbu2atWqddUvC8vD7qfv/fzzz1q4cKEWLlyo/Px8PfXUUwoJCXFkbAAA4CKDwfbLw+vfWvwEmdxjKn3NBEPx8fq32rZeQgX6/PPPNWjQIPXq1UtScXFW0U95cSeOqKciIyOtCkhJatKkiZYvXy5J+uyzz5SVlWW1RldhYaGeeOIJzZ49+7K/bz8/P/n5+ZUtIQAAnM2Da6Tw8HBFRUXp4MGD6tev32XHhYSE6P7779f999+v3r17KykpSdnZ2apZs6aqVq2qwsLCcseSmJgoScrMzFSdOnUkSdnZ2frtt9+sbhl0tDI1pc6dO6eVK1fqjTfe0Geffabbb79ds2fP1u23385T9wAAcBc+vsWPNH77QUkGWRdd/3elTNJUlzekJKlhw4ZasWKFevToIYPBoHHjxlXIFU/Z2dk6cuSIfv21+JvUi49hvvjUG2dydD2VmJho9VhpSfrhhx8sBeSAAQNKPHWwW7duGjBggAYPHmx/IgAAeBo3rJHS0tI0YsQIGY1GJSUlqaCgQDt37tSpU6c0atQozZo1S5GRkWrdurV8fHz0zjvvKCIiQqGhoZKKn8D38ccfKzExUX5+fpddo/LIkSOWeqiwsFB79uyRJDVo0EDVq1fXddddp7vvvluPP/645s2bp5CQEI0dO1aNGzfWLbfcUmH5l6kpFRkZqeDgYA0cOFCvvPKKTCaTpOL7IP+KK6YAAHCxuLukPouLnyDz10ceh0QVF1txFft4X1vNmjVLDz30kBISElSrVi2NHj26QhbUXr16tVUDpm/fvpKKFxedOHGiw893JY6up0aOHKmEhARNmTJFffr00fbt2zVv3jzNmzdPkhQWFqawsDCr91StWlURERFq1KiRAzICAMCDuFmN9PDDDyswMFAzZszQU089paCgIDVv3lypqamSpODgYE2fPl379++Xr6+v4uPj9cEHH8jHp3iJ8JkzZ2rUqFGaP3++rrnmmsteAT1+/Hir9SYvPgF448aN6tSpkyRp8eLFGjlypO644w75+PioY8eOWrduXYllExzJYDabS7tmrVQXk5ZU6poEZrNZBoPBIZeOOVNubq6MRqNycnJoqAEAXO7s2bM6dOiQYmNj5e/vX77JigqL10/IOyFVDy9eH8ENrpByd1f6DMpbN1REPbVmzRqNHTtW+/fvV2xsrEaNGmX19L1L1atXT6mpqZaC1xbUSwAAd+CwOokaqdwcUS+V6UqpilxxHQAAVAAfXyn2ZldHgb+oiHrqzjvv1J133mnzeG9atwsAgFJRI7mFMjWlOnbsWFFxAAAAeAXqKQAAgGI+Vx9ScdLT0xUfH6/g4GCZTCb17NnTaqHOn376SQaDodTXO++8Yxl35MgR3XHHHQoMDJTJZNJTTz2lCxcuuCIlAAAAAAAA2MClTalNmzYpOTlZW7duVUZGhs6fP6+uXbtaFvqMjo7WsWPHrF5paWmqXr26br/9dknFjzS+4447dO7cOX3xxRdatGiRFi5cqPHjx7syNQAAAAAAAFxBmW7fc7R169ZZbS9cuFAmk0m7du1Shw4d5OvrW+IxzStXrlSfPn1UvXp1SdJHH32kffv2af369QoPD1erVq00efJkjR49WhMnTlS1atWclg8AAAAAAABs49IrpS6Vk5MjSapZs2apx3ft2qU9e/ZoyJAhln1btmxR8+bNFR4ebtnXrVs35ebm6ttvvy11noKCAuXm5lq9AAAAAAAA4Dxu05QqKipSamqqEhMT1axZs1LHvPHGG2rSpIkSEhIs+44fP27VkJJk2T5+/Hip86Snp8toNFpe0dHRDsoCAAAAAAAAtrD59r177rnH5klXrFhR5kCSk5O1d+9ebd68udTjf/75p5YuXapx48aVee5LjR07VqNGjbJs5+bm0pgCAAAVrqLrKQAAAE9i85VSf72yKCQkRB9//LF27txpOb5r1y59/PHHMhqNZQ4iJSVFa9as0caNG1WnTp1Sx7z77rvKz8/Xgw8+aLU/IiJCJ06csNp3cfvS9agu8vPzU0hIiNULAAC4p3r16mn27NmuDsMhKrKeAgAA8DQ2N6UWLFhgeYWHh6tPnz46dOiQVqxYoRUrVujgwYPq27evatWqZfPJzWazUlJStHLlSm3YsEGxsbGXHfvGG2/orrvuUu3ata32t2/fXt98842ysrIs+zIyMhQSEqK4uDibYwEAAOVjMBiu+Jo4caJd8+7YsUOPPPKI3XGdP39eo0ePVvPmzRUUFKSoqCg9+OCD+vXXX+2e014VUU8BAAD3VlE10sW533vvvauOe+6555SQkKDAwECFhoaWOL5w4cLLxvfXfouj2fX0vTfffFObN2+Wr6+vZZ+vr69GjRqlhIQEzZgxw6Z5kpOTtXTpUq1atUrBwcGWNaCMRqMCAgIs43788Ud9+umn+uCDD0rM0bVrV8XFxWnAgAGaPn26jh8/rmeffVbJycny8/OzJz0AACqNwqJC7c7arZP5J1U7sLbamNrI18f36m+0w7Fjxyw/v/XWWxo/frwyMzMt+y4+OVcq/mKqsLBQVapcvRS59AupssrPz9fu3bs1btw4tWzZUqdOndLjjz+uu+66y+oqJWdzVD0FAADKzl1rpIpy7tw53XfffWrfvr3eeOONEsfvv/9+JSUlWe0bNGiQzp49K5PJVGFx2bXQ+YULF/T999+X2P/999+rqKjI5nnmzp2rnJwcderUSZGRkZbXW2+9ZTXuzTffVJ06ddS1a9cSc/j6+mrNmjXy9fVV+/bt1b9/fz344IOaNGlS2RMDAKASWX94vbot76aHPnxIoz8brYc+fEjdlnfT+sPrK+R8ERERlpfRaJTBYLBsf//99woODtbatWt1/fXXy8/PT5s3b9aBAwd09913Kzw8XNWrV1d8fLzWr7eO79Lb9wwGg15//XX16tVLgYGBatiwoVavXn3ZuIxGozIyMtSnTx81atRIN954o1566SXt2rVLR44cqZDfhS0cVU8BAICycacaKSIiQsuWLVOTJk3k7++vxo0b65VXXrG899y5c0pJSVFkZKT8/f0VExOj9PR0ScU1kiT16tVLBoPBsl2atLQ0jRw5Us2bNy/1eEBAgFVMvr6+2rBhg4YMGeKw30Np7LpSavDgwRoyZIgOHDigG264QZK0bds2TZ06VYMHD7Z5HrPZbNO4KVOmaMqUKZc9HhMTU+pVVAAAeKv1h9dr1CejZJb139qs/CyN+mSUZnWapS4xXZwe15gxY/T888/r2muvVY0aNXT06FF1795dzz33nPz8/LR48WL16NFDmZmZqlu37mXnSUtL0/Tp0zVjxgz985//VL9+/XT48GHVrFnTpjhycnJkMBhKvXzdWRxVTwEAANu5W420ZMkSjR8/Xi+99JJat26tL7/8UkOHDlVQUJAGDhyoOXPmaPXq1Xr77bdVt25dHT16VEePHpVUvMSByWTSggULlJSUZHX1dXktXrxYgYGB6t27t8PmLI1dTannn39eERERmjlzpuUytMjISD311FN64oknHBogAAAo/iLnzwt/2jS2sKhQ6dvTSxRbkiz7pm6fqnYR7a56mXpAlQAZDIayB3wZkyZN0m233WbZrlmzplq2bGnZnjx5slauXKnVq1crJSXlsvMMGjRIDzzwgKTiL6/mzJmj7du3l7jsvDRnz57V6NGj9cADD7j0YSfUUwAAlJ+raiTJMXXShAkTNHPmTMsTemNjY7Vv3z699tprGjhwoI4cOaKGDRvqpptuksFgUExMjOW9F5c4CA0NveyD3uz1xhtv6G9/+5vV0koVwa6mlI+Pj55++mk9/fTTys3NlSSeYAcAQAX688Kfare0ncPmO5F/QgnLEq46btvftimwaqDDztu2bVur7by8PE2cOFH//e9/dezYMV24cEF//vnnVW+ra9GiheXnoKAghYSE2LQI5/nz59WnTx+ZzWbNnTvXviQchHoKAIDyc1WNJJW/Tjpz5owOHDigIUOGaOjQoZb9Fy5csDyJd9CgQbrtttvUqFEjJSUl6c477yx1aSNH2rJli7777jv961//qtDzSHY2pf6K4gkAANgqKCjIavvJJ59URkaGnn/+eTVo0EABAQHq3bu3zp07d8V5qlatarVtMBiuug7TxYbU4cOHtWHDBreqYdwpFgAA4Bx5eXmSpPnz56tdO+vG2sVb8dq0aaNDhw5p7dq1Wr9+vfr06aMuXbro3XffrbC4Xn/9dbVq1UrXX399hZ3jIruaUidOnNCTTz6pjz/+WFlZWSXWhiosLHRIcAAAoFhAlQBt+9s2m8buOrFLj3786FXHvdL5FV0ffuViI6BKxV6y/fnnn2vQoEHq1auXpOLi7KeffnL4eS42pPbv36+NGzcqLCzM4ecoK+opAADKz1U10sVzl0d4eLiioqJ08OBB9evX77LjQkJCdP/99+v+++9X7969lZSUpOzsbNWsWVNVq1Z1aM2Ql5ent99+27KYekWzqyk1aNAgHTlyROPGjVNkZKRD15oAAAAlGQwGmy8PT4hKUHhguLLys0pdM8Egg8IDw5UQlVBhjz62VcOGDbVixQr16NFDBoNB48aNc/iT586fP6/evXtr9+7dWrNmjQoLC3X8+HFJxWtaVatWzaHnsxX1FAAA5efpNVJaWppGjBgho9GopKQkFRQUaOfOnTp16pRGjRqlWbNmKTIyUq1bt5aPj4/eeecdRUREWB7WUq9ePX388cdKTEyUn5+fatSoUep5jhw5ouzsbB05ckSFhYXas2ePJKlBgwaqXr26Zdxbb72lCxcuqH///hWduiQ7m1KbN2/WZ599platWjk4HAAAUF6+Pr4ac8MYjfpklAwyWBVdBhU3PkbfMNrlDSlJmjVrlh566CElJCSoVq1aGj16tGV9JUf55ZdftHr1akkqUbts3LhRnTp1cuj5bEU9BQCAc7ljjfTwww8rMDBQM2bM0FNPPaWgoCA1b95cqampkqTg4GBNnz5d+/fvl6+vr+Lj4/XBBx/Ix8dHkjRz5kyNGjVK8+fP1zXXXHPZK87Hjx+vRYsWWbZbt24tqWQt9MYbb+iee+5x2hOKDeZLrxW3QVxcnJYsWWJJwtPl5ubKaDQqJyeHNR0AAC539uxZHTp0SLGxsfL397d7nvWH12vq9qk6kX/Csi8iMEKjbxjt1Ecde6IrfQaOqhs8rZ6iXgIAuANH1EnUSI7hiHrJriulZs+erTFjxui1115TvXr17JkCAABUsC4xXXRL9C3anbVbJ/NPqnZgbbUxtXGLK6RAPQUAgKtQI7kPu5pS999/v/Lz81W/fn0FBgaWeAJOdna2Q4IDAADl4+vjq/iIeFeHgVJQTwEA4DrUSO7B7iulAAAAYD/qKQAA4O3sakoNHDjQ0XEAAAB4FeopAADg7exqSv3V2bNnde7cOat9LH4JAABgO+opAADgjXzsedOZM2eUkpIik8mkoKAg1ahRw+oFAADKz44H5MJBnPG7p54CAMB+1Emu54jPwK6m1NNPP60NGzZo7ty58vPz0+uvv660tDRFRUVp8eLF5Q4KAABvdnHB6/z8fBdH4r0u/u4vXXzckainAAAoO1/f4ifkXXqFMZzPEfWSXbfvvf/++1q8eLE6deqkwYMH6+abb1aDBg0UExOjJUuWqF+/fnYHBACAt/P19VVoaKiysrIkSYGBgTIYDC6OyjuYzWbl5+crKytLoaGhlsK3IlBPAQBQdlWqVFFgYKBOnjypqlWrysfHrmttUA6OrJfsakplZ2fr2muvlVS83sHFRxbfdNNNGj58uN3BAACAYhEREZJkaUzBuUJDQy2fQUWhngIAoOwMBoMiIyN16NAhHT582NXheDVH1Et2NaWuvfZaHTp0SHXr1lXjxo319ttv64YbbtD777+v0NDQcgUEAAD+V3CZTCadP3/e1eF4lapVq1boFVIXUU8BAGCfatWqqWHDhtzC50KOqpfsakoNHjxYX331lTp27KgxY8aoR48eeumll3T+/HnNmjWr3EEBAIBivr6+TmmQwPmopwAAsJ+Pj4/8/f1dHQbKyWB2wHLphw8f1q5du9SgQQO1aNHCEXE5VW5uroxGo3Jycnj8MgAAuKKKqhvcvZ6iXgIAALaytW6w60qpS8XExCgmJsYRUwEAAHgl6ikAAOBt7G5K7dixQxs3blRWVpaKioqsjnHJOQAAwNVRTwEAAG9mV1NqypQpevbZZ9WoUSOFh4dbPaaaR1YDAABcHfUUAADwdnY1pV588UW9+eabGjRokIPDAQAA8A7UUwAAwNv52PUmHx8lJiY6OhYAAACvQT0FAAC8nV1NqZEjR+rll192dCwAAABeg3oKAAB4O7tu33vyySd1xx13qH79+oqLi1PVqlWtjq9YscIhwQEAAFRW1FMAAMDb2dWUGjFihDZu3KhbbrlFYWFhLMYJAABQRtRTAADA29nVlFq0aJGWL1+uO+64w9HxAAAAeAXqKQAA4O3sWlOqZs2aql+/vqNjAQAA8BrUUwAAwNvZ1ZSaOHGiJkyYoPz8fEfHAwAA4BWopwAAgLez6/a9OXPm6MCBAwoPD1e9evVKLMy5e/duhwQHAABQWVFPAQAAb2dXU6pnz54ODgMAAMC7UE8BAABvZzCbzWZXB+Fqubm5MhqNysnJUUhIiKvDAQAAbsxb6wZvzRsAAJSdrXWDXWtKSdLp06f1+uuva+zYscrOzpZUfJn5L7/8Yu+UAAAAXoV6CgAAeDO7mlJff/21rrvuOk2bNk3PP/+8Tp8+LUlasWKFxo4da/M86enpio+PV3BwsEwmk3r27KnMzMwS47Zs2aJbb71VQUFBCgkJUYcOHfTnn39ajterV08Gg8HqNXXqVHtSAwAAcApH1VMAAACeyq6m1KhRozRo0CDt379f/v7+lv3du3fXp59+avM8mzZtUnJysrZu3aqMjAydP39eXbt21ZkzZyxjtmzZoqSkJHXt2lXbt2/Xjh07lJKSIh8f69AnTZqkY8eOWV6PPfaYPakBAAA4haPqKQAAAE9l10LnO3bs0GuvvVZi/zXXXKPjx4/bPM+6deusthcuXCiTyaRdu3apQ4cOkqSRI0dqxIgRGjNmjGVco0aNSswVHBysiIgIm88NAADgSo6qpwAAADyVXVdK+fn5KTc3t8T+H374QbVr17Y7mJycHElSzZo1JUlZWVnatm2bTCaTEhISFB4ero4dO2rz5s0l3jt16lSFhYWpdevWmjFjhi5cuGB3HAAAABWtouopAAAAT2FXU+quu+7SpEmTdP78eUmSwWDQkSNHNHr0aN177712BVJUVKTU1FQlJiaqWbNmkqSDBw9KkiZOnKihQ4dq3bp1atOmjTp37qz9+/db3jtixAgtW7ZMGzdu1LBhwzRlyhQ9/fTTlz1XQUGBcnNzrV4AAADOVBH1FAAAgCcxmM1mc1nflJOTo969e2vnzp36448/FBUVpePHj6t9+/b64IMPFBQUVOZAhg8frrVr12rz5s2qU6eOJOmLL75QYmKixo4dqylTpljGtmjRQnfccYfS09NLnevNN9/UsGHDlJeXJz8/vxLHJ06cqLS0tFLz4hHHAADgSmx9xPHVVEQ9VZEclTcAAKj8bK0b7FpTymg0KiMjQ5s3b9bXX3+tvLw8tWnTRl26dLEr2JSUFK1Zs0affvqppSElSZGRkZKkuLg4q/FNmjTRkSNHLjtfu3btdOHCBf3000+lrj81duxYjRo1yrKdm5ur6Ohou2IHAACwh6PrKQAAAE9jV1Pqoptuukk33XST3e83m8167LHHtHLlSn3yySeKjY21Ol6vXj1FRUUpMzPTav8PP/yg22+//bLz7tmzRz4+PjKZTKUe9/PzK/UKKgAAAGcrbz0FAADgqcrclCoqKtLChQu1YsUK/fTTTzIYDIqNjVXv3r01YMAAGQwGm+dKTk7W0qVLtWrVKgUHB1ueNGM0GhUQECCDwaCnnnpKEyZMUMuWLdWqVSstWrRI33//vd59911J0pYtW7Rt2zbdcsstCg4O1pYtWzRy5Ej1799fNWrUKGt6AAAAFc6R9RQAAICnKtOaUmazWT169NAHH3ygli1bqnHjxjKbzfruu+/0zTff6K677tJ7771n+8kvU3AtWLBAgwYNsmxPnTpVL7/8srKzs9WyZUtNnz7d8o3i7t279eijj+r7779XQUGBYmNjNWDAAI0aNcrmq6FYIwEAANiqvHWDo+spZ6FeAgAAtqqQNaUWLlyoTz/9VB9//LFuueUWq2MbNmxQz549tXjxYj344IM2zWdrP2zMmDEaM2ZMqcfatGmjrVu32jQPAACAqzm6ngIAAPBUPmUZ/J///EfPPPNMiQJKkm699VaNGTNGS5YscVhwAAAAlU1F1FO//PKL+vfvr7CwMAUEBKh58+bauXOn5fjEiRPVuHFjBQUFqUaNGurSpYu2bdtW7lwAAADKo0xNqa+//lpJSUmXPX777bfrq6++KndQAAAAlZWj66lTp04pMTFRVatW1dq1a7Vv3z7NnDnTam3N6667Ti+99JK++eYbbd68WfXq1VPXrl118uTJcuUCAABQHmW6fS87O1vh4eGXPR4eHq5Tp06VOygAAIDKytH11LRp0xQdHa0FCxZY9l36ROO//e1vVtuzZs3SG2+8oa+//lqdO3e2+VwAAACOVKYrpQoLC1WlyuX7WL6+vrpw4UK5gwIAAKisHF1PrV69Wm3bttV9990nk8mk1q1ba/78+Zcdf+7cOc2bN09Go1EtW7a87LiCggLl5uZavQAAABypTFdKmc1mDRo06LJPtSsoKHBIUAAAAJWVo+upgwcPau7cuRo1apSeeeYZ7dixQyNGjFC1atU0cOBAy7g1a9aob9++ys/PV2RkpDIyMlSrVq3Lzpuenq60tLQyxQIAAFAWBrOtj8CTNHjwYJvG/fXycU/AI44BAICtyls3OLqeqlatmtq2basvvvjCsm/EiBHasWOHtmzZYtl35swZHTt2TL/99pvmz5+vDRs2aNu2bTKZTKXOW1BQYNUgy83NVXR0NPUSAAC4KlvrpTJdKeVpzSYAAAB34+h6KjIyUnFxcVb7mjRpouXLl1vtCwoKUoMGDdSgQQPdeOONatiwod544w2NHTu21Hn9/PwuezUXAACAI5RpTSkAAAC4l8TERGVmZlrt++GHHxQTE3PF9xUVFbH0AgAAcCmaUgAAAB5s5MiR2rp1q6ZMmaIff/xRS5cu1bx585ScnCyp+La9Z555Rlu3btXhw4e1a9cuPfTQQ/rll1903333uTh6AADgzcp0+x4AAADcS3x8vFauXKmxY8dq0qRJio2N1ezZs9WvXz9JxU/z+/7777Vo0SL99ttvCgsLU3x8vD777DM1bdrUxdEDAABvVqaFzisrFjoHAAC28ta6wVvzBgAAZWdr3cDtewAAAAAAAHA6mlIAAAAAAABwOppSAAAAAAAAcDqaUgAAAAAAAHA6mlIAAAAAAABwOppSAAAAAAAAcDqaUgAAAAAAAHA6mlIAAAAAAABwOppSAAAAAAAAcDqaUgAAAAAAAHA6mlIAAAAAAABwOppSAAAAAAAAcDqaUgAAAAAAAHA6mlIAAAAAAABwOppSAAAAAAAAcDqaUgAAAAAAAHA6mlIAAAAAAABwOppSAAAAAAAAcDqaUgAAAAAAAHA6mlIAAAAAAABwOppSAAAAAAAAcDqaUgAAAAAAAHA6mlIAAAAAAABwOpc2pdLT0xUfH6/g4GCZTCb17NlTmZmZJcZt2bJFt956q4KCghQSEqIOHTrozz//tBzPzs5Wv379FBISotDQUA0ZMkR5eXnOTAUAAAAAAABl4NKm1KZNm5ScnKytW7cqIyND58+fV9euXXXmzBnLmC1btigpKUldu3bV9u3btWPHDqWkpMjH53+h9+vXT99++60yMjK0Zs0affrpp3rkkUdckRIAAAAAAABsYDCbzWZXB3HRyZMnZTKZtGnTJnXo0EGSdOONN+q2227T5MmTS33Pd999p7i4OO3YsUNt27aVJK1bt07du3fXzz//rKioqKueNzc3V0ajUTk5OQoJCXFcQgAAoNLx1rrBW/MGAABlZ2vd4FZrSuXk5EiSatasKUnKysrStm3bZDKZlJCQoPDwcHXs2FGbN2+2vGfLli0KDQ21NKQkqUuXLvLx8dG2bducmwAAAAAAAABs4jZNqaKiIqWmpioxMVHNmjWTJB08eFCSNHHiRA0dOlTr1q1TmzZt1LlzZ+3fv1+SdPz4cZlMJqu5qlSpopo1a+r48eOlnqugoEC5ublWLwAAAAAAADiP2zSlkpOTtXfvXi1btsyyr6ioSJI0bNgwDR48WK1bt9YLL7ygRo0a6c0337T7XOnp6TIajZZXdHR0ueMHAAAAAACA7dyiKZWSkqI1a9Zo48aNqlOnjmV/ZGSkJCkuLs5qfJMmTXTkyBFJUkREhLKysqyOX7hwQdnZ2YqIiCj1fGPHjlVOTo7ldfToUUemAwAAAAAAgKtwaVPKbDYrJSVFK1eu1IYNGxQbG2t1vF69eoqKilJmZqbV/h9++EExMTGSpPbt2+v06dPatWuX5fiGDRtUVFSkdu3alXpePz8/hYSEWL0AAAAAAADgPFVcefLk5GQtXbpUq1atUnBwsGUNKKPRqICAABkMBj311FOaMGGCWrZsqVatWmnRokX6/vvv9e6770oqvmoqKSlJQ4cO1auvvqrz588rJSVFffv2tenJewAAAAAAAHA+lzal5s6dK0nq1KmT1f4FCxZo0KBBkqTU1FSdPXtWI0eOVHZ2tlq2bKmMjAzVr1/fMn7JkiVKSUlR586d5ePjo3vvvVdz5sxxVhoAAAAAAAAoI4PZbDa7OghXy83NldFoVE5ODrfyAQCAK/LWusFb8wYAAGVna93gFgudAwAAAAAAwLvQlAIAAAAAAIDT0ZQCAAAAAACA09GUAgAAAAAAgNPRlAIAAAAAAIDT0ZQCAAAAAACA09GUAgAAAAAAgNPRlAIAAAAAAIDT0ZQCAAAAAACA09GUAgAAAAAAgNPRlAIAAAAAAIDT0ZQCAAAAAACA09GUAgAAAAAAgNPRlAIAAAAAAIDT0ZQCAAAAAACA01VxdQAAAADwckWF0uEvpLwTUvVwKSZB8vF1dVTlQ06egZw8Q2XMSaqceZGTZ3CjnGhKAQAAwHX2rZbWjZZyf/3fvpAoKWmaFHeX6+IqD3LyDOTkGSpjTlLlzIucPIOb5WQwm81mp5/VzeTm5spoNConJ0chISGuDgcAALgxb60bKiTvfaultx+UdGk5aij+nz6LPa/oJyfPQE6eoTLmJFXOvMjJMzgxJ1vrBppS8t7iEgAAlJ231g0Oz7uoUJrdzPqbWisGKSRSenSb59wmUVQovXyD9MexywwgJ7dATk4NzW6VMSepcuZFTk4NzW425RQlpX7jkJxoSpWBtxaXAACg7Ly1bnB43oc+kxbdWf55AACA4wxcI8XeXO5pbK0bePoeAAAAnC/vhKsjAAAAl3Ly32cWOgcAAIDzVQ+3bVy/d4ufCuQJDn8hLel99XHk5FrkVPHxOEJlzEmqnHmRU8XH4wi25mTr32cHoSkFAAAA54tJKF67IveYSi64KlnWtqh/q+es11H/VnLyBOTk7OjsUxlzkipnXuTk7OjsY2tOTm6ycfseAACAh/vll1/Uv39/hYWFKSAgQM2bN9fOnTslSefPn9fo0aPVvHlzBQUFKSoqSg8++KB+/fVyC4w7iY9v8eOnJVme+mPxf9tJUz2n2JfIyVOQk2eojDlJlTMvcvIMbpoTTSkAAAAPdurUKSUmJqpq1apau3at9u3bp5kzZ6pGjRqSpPz8fO3evVvjxo3T7t27tWLFCmVmZuquu9zgMdZxdxU/fjok0np/SJRnPmpbIidPQU6eoTLmJFXOvMjJM7hhTjx9T977FB0AAFB27lY3jBkzRp9//rk+++wzm9+zY8cO3XDDDTp8+LDq1q1r03sqNO+iwuK1LvJOFK9lEZPgWd8+l4acPAM5eYbKmJNUOfMiJ8/ghJxsrRtoSsn9iksAAOC+3K1uiIuLU7du3fTzzz9r06ZNuuaaa/Too49q6NChl33P+vXr1bVrV50+ffqyORQUFKigoMCynZubq+joaLfJGwAAuC9b6yVu3wMAAPBgBw8e1Ny5c9WwYUN9+OGHGj58uEaMGKFFixaVOv7s2bMaPXq0HnjggSsWienp6TIajZZXdHR0RaUAAAC8FFdKyf2+8QQAAO7L3eqGatWqqW3btvriiy8s+0aMGKEdO3Zoy5YtVmPPnz+ve++9Vz///LM++eSTK8bPlVIAAMBeXCkFAADgBSIjIxUXF2e1r0mTJjpy5IjVvvPnz6tPnz46fPiwMjIyrtpY8vPzU0hIiNULAADAkaq4OgAAAADYLzExUZmZmVb7fvjhB8XExFi2Lzak9u/fr40bNyosLMzZYQIAAJRAUwoAAMCDjRw5UgkJCZoyZYr69Omj7du3a968eZo3b56k4oZU7969tXv3bq1Zs0aFhYU6fvy4JKlmzZqqVq2aK8MHAABejKYUAACAB4uPj9fKlSs1duxYTZo0SbGxsZo9e7b69esnSfrll1+0evVqSVKrVq2s3rtx40Z16tTJyREDAAAUoykFAADg4e68807deeedpR6rV6+eeK4NAABwRyx0DgAAAAAAAKdzaVMqPT1d8fHxCg4OlslkUs+ePUss1NmpUycZDAar19///nerMZceNxgMWrZsmTNTAQAAAAAAQBm49Pa9TZs2KTk5WfHx8bpw4YKeeeYZde3aVfv27VNQUJBl3NChQzVp0iTLdmBgYIm5FixYoKSkJMt2aGhohcYOAAAAAAAA+7m0KbVu3Tqr7YULF8pkMmnXrl3q0KGDZX9gYKAiIiKuOFdoaOhVxwAAAAAAAMA9uNWaUjk5OZKKH0/8V0uWLFGtWrXUrFkzjR07Vvn5+SXem5ycrFq1aumGG27Qm2++ecUFPQsKCpSbm2v1AgAAAAAAgPO4zdP3ioqKlJqaqsTERDVr1syy/29/+5tiYmIUFRWlr7/+WqNHj1ZmZqZWrFhhGTNp0iTdeuutCgwM1EcffaRHH31UeXl5GjFiRKnnSk9PV1paWoXnBAAAAAAAgNIZzG7yjODhw4dr7dq12rx5s+rUqXPZcRs2bFDnzp31448/qn79+qWOGT9+vBYsWKCjR4+WerygoEAFBQWW7dzcXEVHRysnJ0chISHlS+QShUVmbT+Uraw/zsoU7K8bYmvK18fg0HM4Gzl5BnLyDOTkOSpjXuRkn9zcXBmNxgqpG9yZt+YNAADKzta6wS2ulEpJSdGaNWv06aefXrEhJUnt2rWTpCs2pdq1a6fJkyeroKBAfn5+JY77+fmVut/R1u09prT39+lYzlnLvkijvyb0iFNSs8gKP39FICfPQE6egZw8R2XMi5wAAADgai5dU8psNislJUUrV67Uhg0bFBsbe9X37NmzR5IUGXn54nLPnj2qUaOGUxpPl7Nu7zEN//duq8JYko7nnNXwf+/Wur3HXBSZ/cjJM5CTZyAnz1EZ8yInAAAAuAOXXimVnJyspUuXatWqVQoODtbx48clSUajUQEBATpw4ICWLl2q7t27KywsTF9//bVGjhypDh06qEWLFpKk999/XydOnNCNN94of39/ZWRkaMqUKXryySddlldhkVlp7+9TafdFmiUZJE1cvU+JDWp5zG0ShUVmTVj9LTm5OXIiJ1epjDlJlTMvb80p7f19ui0uwmNyAgAA8AYuXVPKYCi9MFywYIEGDRqko0ePqn///tq7d6/OnDmj6Oho9erVS88++6zlnsR169Zp7Nix+vHHH2U2m9WgQQMNHz5cQ4cOlY+PbReCOXqNhC0HftcD87eWex4AAOA4/xl6o9rXDyv3PN66tpK35g0AAMrOI9aUulo/LDo6Wps2bbrimKSkJCUlJTkyrHLL+uPs1QcBAACn4u8zAACAe3GLhc4rG1Owv03jFg6O1w2xNSs4GsfYfihbgxbsuOo4cnItciInV6mMOUmVMy9vzsnWv88AAABwDppSFeCG2JqKNPrreM7ZUte3MEiKMPrr5oa1PWZti5sb1iYnD0BO5OQqlTEnqXLm5c05eUqTDQAAwFu49Ol7lZWvj0ETesRJKi6E/+ri9oQecR5T7Evk5CnIyTOQk+eojHmREwAAANwFTakKktQsUnP7t1GE0fpWgQijv+b2b6OkZpEuisx+5OQZyMkzkJPnqIx5kRMAAADcgUufvucuKvJpMoVFZm0/lK2sP87KFFx864Cnf1NLTp6BnDwDOXmOypgXOdnHW59C5615AwCAsrO1bqApJYosAABgO2+tG7w1bwAAUHa21g3cvgcAAAAAAACnoykFAAAAAAAAp6MpBQAAAAAAAKejKQUAAAAAAACnoykFAAAAAAAAp6MpBQAAAAAAAKejKQUAAAAAAACnoykFAAAAAAAAp6MpBQAAAAAAAKejKQUAAAAAAACnoykFAAAAAAAAp6MpBQAAAAAAAKejKQUAAAAAAACnoykFAAAAAAAAp6MpBQAAAAAAAKejKQUAAAAAAACnoykFAAAAAAAAp6MpBQAAAAAAAKer4uoAKr2iQunwF1LeCal6uBSTIPn4ujqq8iEnz0BOnoGcPEdlzIuc4CYKiwq1O2u3TuafVO3A2mpjaiNfD//cyMkzkJNnqIw5SZUzL3LyDO6UE02pirRvtbRutJT76//2hURJSdOkuLtcF1d5kJNnICfPQE6eozLmRU5wE+sPr9fU7VN1Iv+EZV94YLjG3DBGXWK6uDAy+5GTZyAnz1AZc5IqZ17k5BncLSeD2Ww2O/2sbiY3N1dGo1E5OTkKCQlxzKT7VktvPyjp0l+vofh/+iz2vAKZnDwDOXkGcvIclTEvciqXCqkbPEBF5L3+8HqN+mSUzJd8bob/+9xmdZrlcUU/OXkGcvIMlTEnqXLmRU6ewZk52Vo30JRSBRRZRYXS7GbW39RaMUghkdKj2zznloKiQunlG6Q/jl1mADm5BXJyamh2IyenhlYulTEvr80pSkr9xiE50ZRyTN6FRYXqtryb1Te1lwoPDNfKu1Z6zG0ShUWF6rm6p7Lysy47hpxcj5zIyZUqY17kVDlyMsig8MBwrbt3nUNyoilVBg4vLg99Ji26s/zzAAAAxxm4Roq9udzT0JRyTN47ju/QQx8+5IDIAACAo7zZ7U3FR8SXex5b6waevlcR8i7/jR8AAHAR/j67lZP5J10dAgAAuISz/z6z0HlFqB5u27h+7xY/FcgTHP5CWtL76uPIybXIqeLjcQRyqvh4HKUy5uXNOdn69xlOUTuwtk3jXun8iq4Pv76Co3GMXSd26dGPH73qOHJyLXIiJ1eqjHmRU+XKyda/z45CU6oixCQUr12Re0wlF1yVLGtb1L/Vc9brqH8rOXkCcnJ2dPYhJ2dHZ7/KmJc35+QpTTYv0cbURuGB4crKzyqx4Kr0v7UtEqISPGa9joSoBHLyAORETq5UGfMip8qVUxtTG6fGxe17FcHHt/jx05IsT/2x+L/tpKmeU+xL5OQpyMkzkJPnqIx5kRPchK+Pr8bcMEbS/576c9HF7dE3jPaYYl8iJ09BTp6hMuYkVc68yMkzuGtONKUqStxdxY+fDom03h8S5ZmP2pbIyVOQk2cgJ89RGfMiJ7iJLjFdNKvTLJkCTVb7wwPDPfJR2xI5eQpy8gyVMSepcuZFTp7BHXNy6dP30tPTtWLFCn3//fcKCAhQQkKCpk2bpkaNGlnGdOrUSZs2bbJ637Bhw/Tqq69ato8cOaLhw4dr48aNql69ugYOHKj09HRVqWLb3YkV+hSdosLitS7yThSvZRGT4Pnf1JKTZyAnz0BOnqMy5kVOduHpe47Pu7CoULuzdutk/knVDqytNqY2HvXtc2nIyTOQk2eojDlJlTMvcvIMzsjJ1rrBpU2ppKQk9e3bV/Hx8bpw4YKeeeYZ7d27V/v27VNQUJCk4qbUddddp0mTJlneFxgYaEmqsLBQrVq1UkREhGbMmKFjx47pwQcf1NChQzVlyhSb4vDW4hIAAJSdt9YN3po3AAAoO1vrBpcudL5u3Tqr7YULF8pkMmnXrl3q0KGDZX9gYKAiIiJKneOjjz7Svn37tH79eoWHh6tVq1aaPHmyRo8erYkTJ6patWoVmgMAAAAAAADKzq3WlMrJyZEk1axZ02r/kiVLVKtWLTVr1kxjx45Vfn6+5diWLVvUvHlzhYf/7zHP3bp1U25urr799ttSz1NQUKDc3FyrFwAAAAAAAJzHpVdK/VVRUZFSU1OVmJioZs2aWfb/7W9/U0xMjKKiovT1119r9OjRyszM1IoVKyRJx48ft2pISbJsHz9+vNRzpaenKy0trYIyAQAAAAAAwNW4TVMqOTlZe/fu1ebNm632P/LII5afmzdvrsjISHXu3FkHDhxQ/fr17TrX2LFjNWrUKMt2bm6uoqOj7QscAAAAAAAAZeYWt++lpKRozZo12rhxo+rUqXPFse3atZMk/fjjj5KkiIgInThxwmrMxe3LrUPl5+enkJAQqxcAAAAAAACcx6VNKbPZrJSUFK1cuVIbNmxQbGzsVd+zZ88eSVJkZKQkqX379vrmm2+UlZVlGZORkaGQkBDFxcVVSNwAAAAAAAAoH5fevpecnKylS5dq1apVCg4OtqwBZTQaFRAQoAMHDmjp0qXq3r27wsLC9PXXX2vkyJHq0KGDWrRoIUnq2rWr4uLiNGDAAE2fPl3Hjx/Xs88+q+TkZPn5+bkyPQAAAAAAAFyGS6+Umjt3rnJyctSpUydFRkZaXm+99ZYkqVq1alq/fr26du2qxo0b64knntC9996r999/3zKHr6+v1qxZI19fX7Vv3179+/fXgw8+qEmTJrkqLQAAAAAAAFyFS6+UMpvNVzweHR2tTZs2XXWemJgYffDBB44KCwAAAAAAABXMLRY6BwAAAAAAgHehKQUAAAAAAACnc+nte+7i4m2Eubm5Lo4EAAC4u4v1wtWWIahsqJcAAICtbK2XaEpJ+uOPPyQVr2EFAABgiz/++ENGo9HVYTgN9RIAACirq9VLBrO3fc1XiqKiIv36668KDg6WwWBwdTgeITc3V9HR0Tp69KhCQkJcHQ4ug8/JM/A5eQ4+K89Q0Z+T2WzWH3/8oaioKPn4eM9KCNRLZce/GZ6Bz8kz8Dl5Dj4rz+Au9RJXSkny8fFRnTp1XB2GRwoJCeEfGg/A5+QZ+Jw8B5+VZ6jIz8mbrpC6iHrJfvyb4Rn4nDwDn5Pn4LPyDK6ul7zn6z0AAAAAAAC4DZpSAAAAAAAAcDqaUrCLn5+fJkyYID8/P1eHgivgc/IMfE6eg8/KM/A5wV3w36Jn4HPyDHxOnoPPyjO4y+fEQucAAAAAAABwOq6UAgAAAAAAgNPRlAIAAAAAAIDT0ZQCAAAAAACA09GUgs3S09MVHx+v4OBgmUwm9ezZU5mZma4OC1cxdepUGQwGpaamujoUlOKXX35R//79FRYWpoCAADVv3lw7d+50dVj4i8LCQo0bN06xsbEKCAhQ/fr1NXnyZLEko+t9+umn6tGjh6KiomQwGPTee+9ZHTebzRo/frwiIyMVEBCgLl26aP/+/a4JFl6FmskzUTO5L+ol90e95L7cvV6iKQWbbdq0ScnJydq6dasyMjJ0/vx5de3aVWfOnHF1aLiMHTt26LXXXlOLFi1cHQpKcerUKSUmJqpq1apau3at9u3bp5kzZ6pGjRquDg1/MW3aNM2dO1cvvfSSvvvuO02bNk3Tp0/XP//5T1eH5vXOnDmjli1b6uWXXy71+PTp0zVnzhy9+uqr2rZtm4KCgtStWzedPXvWyZHC21AzeR5qJvdFveQZqJfcl7vXSzx9D3Y7efKkTCaTNm3apA4dOrg6HFwiLy9Pbdq00SuvvKJ//OMfatWqlWbPnu3qsPAXY8aM0eeff67PPvvM1aHgCu68806Fh4frjTfesOy79957FRAQoH//+98ujAx/ZTAYtHLlSvXs2VNS8bd+UVFReuKJJ/Tkk09KknJychQeHq6FCxeqb9++LowW3oaayb1RM7k36iXPQL3kGdyxXuJKKdgtJydHklSzZk0XR4LSJCcn64477lCXLl1cHQouY/Xq1Wrbtq3uu+8+mUwmtW7dWvPnz3d1WLhEQkKCPv74Y/3www+SpK+++kqbN2/W7bff7uLIcCWHDh3S8ePHrf4NNBqNateunbZs2eLCyOCNqJncGzWTe6Ne8gzUS57JHeqlKk45CyqdoqIipaamKjExUc2aNXN1OLjEsmXLtHv3bu3YscPVoeAKDh48qLlz52rUqFF65plntGPHDo0YMULVqlXTwIEDXR0e/s+YMWOUm5urxo0by9fXV4WFhXruuefUr18/V4eGKzh+/LgkKTw83Gp/eHi45RjgDNRM7o2ayf1RL3kG6iXP5A71Ek0p2CU5OVl79+7V5s2bXR0KLnH06FE9/vjjysjIkL+/v6vDwRUUFRWpbdu2mjJliiSpdevW2rt3r1599VWKLDfy9ttva8mSJVq6dKmaNm2qPXv2KDU1VVFRUXxOAK6Kmsl9UTN5Buolz0C9BHtx+x7KLCUlRWvWrNHGjRtVp04dV4eDS+zatUtZWVlq06aNqlSpoipVqmjTpk2aM2eOqlSposLCQleHiP8TGRmpuLg4q31NmjTRkSNHXBQRSvPUU09pzJgx6tu3r5o3b64BAwZo5MiRSk9Pd3VouIKIiAhJ0okTJ6z2nzhxwnIMqGjUTO6NmskzUC95Buolz+QO9RJNKdjMbDYrJSVFK1eu1IYNGxQbG+vqkFCKzp0765tvvtGePXssr7Zt26pfv37as2ePfH19XR0i/k9iYmKJR4T/8MMPiomJcVFEKE1+fr58fKz/XPr6+qqoqMhFEcEWsbGxioiI0Mcff2zZl5ubq23btql9+/YujAzegJrJM1AzeQbqJc9AveSZ3KFe4vY92Cw5OVlLly7VqlWrFBwcbLnH1Gg0KiAgwMXR4aLg4OASa1YEBQUpLCyMtSzczMiRI5WQkKApU6aoT58+2r59u+bNm6d58+a5OjT8RY8ePfTcc8+pbt26atq0qb788kvNmjVLDz30kKtD83p5eXn68ccfLduHDh3Snj17VLNmTdWtW1epqan6xz/+oYYNGyo2Nlbjxo1TVFSU5YkzQEWhZvIM1EyegXrJM1AvuS+3r5fMgI0klfpasGCBq0PDVXTs2NH8+OOPuzoMlOL99983N2vWzOzn52du3Lixed68ea4OCZfIzc01P/744+a6deua/f39zddee635//2//2cuKChwdWheb+PGjaX+XRo4cKDZbDabi4qKzOPGjTOHh4eb/fz8zJ07dzZnZma6Nmh4BWomz0XN5J6ol9wf9ZL7cvd6yWA2m83OaX8BAAAAAAAAxVhTCgAAAAAAAE5HUwoAAAAAAABOR1MKAAAAAAAATkdTCgAAAAAAAE5HUwoAAAAAAABOR1MKAAAAAAAATkdTCgAAAAAAAE5HUwoAAAAAAABOR1MKgFsbNGiQevbs6eowHOaTTz6RwWDQ6dOnyzVPvXr1NHv2bIfEBAAAPBv1UumolwD3R1MKgMsYDIYrviZOnKgXX3xRCxcudHpsF4uhi6/w8HDde++9OnjwYLnmTUhI0LFjx2Q0Gh0UKQAAqMyolwBUZlVcHQAA73Xs2DHLz2+99ZbGjx+vzMxMy77q1aurevXqrgjNIjMzU8HBwdq/f78eeeQR9ejRQ19//bV8fX3LPNf58+dVrVo1RUREVECkAACgMqJeAlCZcaUUAJeJiIiwvIxGowwGg9W+6tWrl7gcvVOnTnrssceUmpqqGjVqKDw8XPPnz9eZM2c0ePBgBQcHq0GDBlq7dq3Vufbu3avbb79d1atXV3h4uAYMGKDffvvtqjGaTCZFRkaqQ4cOGj9+vPbt26cff/xRkrRq1Sq1adNG/v7+uvbaa5WWlqYLFy5Y3mswGDR37lzdddddCgoK0nPPPVfq5ejLly9X06ZN5efnp3r16mnmzJlWMWRlZalHjx4KCAhQbGyslixZYsdvGwAAeCLqpWLUS0DlRFMKgMdZtGiRatWqpe3bt+uxxx7T8OHDdd999ykhIUG7d+9W165dNWDAAOXn50uSTp8+rVtvvVWtW7fWzp07tW7dOp04cUJ9+vQp03kDAgIkSefOndNnn32mBx98UI8//rj27dun1157TQsXLtRzzz1n9Z6JEyeqV69e+uabb/TQQw+VmHPXrl3q06eP+vbtq2+++UYTJ07UuHHjrC7BHzRokI4ePaqNGzfq3Xff1SuvvKKsrKwy/tYAAIA3oV6iXgI8ghkA3MCCBQvMRqOxxP6BAwea7777bst2x44dzTfddJNl+8KFC+agoCDzgAEDLPuOHTtmlmTesmWL2Ww2mydPnmzu2rWr1bxHjx41SzJnZmaWGs/GjRvNksynTp0ym81m86+//mpOSEgwX3PNNeaCggJz586dzVOmTLF6z7/+9S9zZGSkZVuSOTU19Yrz/u1vfzPfdtttVmOeeuopc1xcnNlsNpszMzPNkszbt2+3HP/uu+/MkswvvPBCqbEDAIDKiXrpf6iXgMqBNaUAeJwWLVpYfvb19VVYWJiaN29u2RceHi5Jlm/HvvrqK23cuLHU9RYOHDig66677rLnqlOnjsxms/Lz89WyZUstX75c1apV01dffaXPP//c6pu+wsJCnT17Vvn5+QoMDJQktW3b9oq5fPfdd7r77rut9iUmJmr27NkqLCzUd999pypVquj666+3HG/cuLFCQ0OvOC8AAPBu1EvUS4AnoCkFwONUrVrVattgMFjtMxgMkqSioiJJUl5ennr06KFp06aVmCsyMvKK5/rss88UEhIik8mk4OBgy/68vDylpaXpnnvuKfEef39/y89BQUE2ZAQAAOBY1EsAPAFNKQCVXps2bbR8+XLVq1dPVaqU7Z+92NjYUr9la9OmjTIzM9WgQYNyxdakSRN9/vnnVvs+//xzXXfddfL19VXjxo114cIF7dq1S/Hx8ZKKn3Dz14U/AQAAyot6CYArsNA5gEovOTlZ2dnZeuCBB7Rjxw4dOHBAH374oQYPHqzCwkK75hw/frwWL16stLQ0ffvtt/ruu++0bNkyPfvss2Wa54knntDHH3+syZMn64cfftCiRYv00ksv6cknn5QkNWrUSElJSRo2bJi2bdumXbt26eGHH7YsIgoAAOAI1EsAXIGmFIBKLyoqSp9//rkKCwvVtWtXNW/eXKmpqQoNDZWPj33/DHbr1k1r1qzRRx99pPj4eN1444164YUXFBMTU6Z52rRpo7ffflvLli1Ts2bNNH78eE2aNEmDBg2yjFmwYIGioqLUsWNH3XPPPXrkkUdkMpnsihsAAKA01EsAXMFgNpvNrg4CAAAAAAAA3oUrpQAAAAAAAOB0NKUAAAAAAADgdDSlAAAAAAAA4HQ0pQAAAAAAAOB0NKUAAAAAAADgdDSlAAAAAAAA4HQ0pQAAAAAAAOB0NKUAAAAAAADgdDSlAAAAAAAA4HQ0pQAAAAAAAOB0NKUAAAAAAADgdDSlAAAAAAAA4HT/H6bqpD8TUIe9AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 現在我們從 full_df 中取出第一個 chunk（共 CHUNK_SIZE 筆），並分別選出前 3 筆訓練與後 3 筆測試觀測\n",
    "chunk_indices = range(0, CHUNK_SIZE)\n",
    "train_indices = [i for i in chunk_indices if full_df.loc[i, \"X2\"] == 0][:3]\n",
    "test_indices = [i for i in chunk_indices if full_df.loc[i, \"X2\"] == 1][:3]\n",
    "\n",
    "print(\"Train indices:\", train_indices)\n",
    "print(\"Test indices:\", test_indices)\n",
    "\n",
    "# 繪圖：X軸為 t=1..T, Y軸為 mu\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 畫出訓練資料趨勢\n",
    "plt.subplot(1, 2, 1)\n",
    "for i in train_indices:\n",
    "    plt.plot(range(1, T + 1), mu_matrix[i, :], marker=\"o\", label=f\"Train {i}\")\n",
    "plt.title(\"Train Demand Trend\")\n",
    "plt.xlabel(\"Time Period\")\n",
    "plt.ylabel(\"Demand Mean (mu)\")\n",
    "plt.legend()\n",
    "\n",
    "# 畫出測試資料趨勢\n",
    "plt.subplot(1, 2, 2)\n",
    "for i in test_indices:\n",
    "    plt.plot(range(1, T + 1), mu_matrix[i, :], marker=\"o\", label=f\"Test {i}\")\n",
    "plt.title(\"Test Demand Trend\")\n",
    "plt.xlabel(\"Time Period\")\n",
    "plt.ylabel(\"Demand Mean (mu)\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLArWn7yNAR0"
   },
   "source": [
    "### sigma matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MV_pdKuXNCRO",
    "outputId": "f8f01814-2bfe-4428-d764-0ddcd4d5795d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (90, 3)\n",
      "coefficients.shape: (3, 10)\n",
      "coefficients: [[ 0.43037873  0.20552675  0.08976637 -0.1526904   0.29178823 -0.12482558\n",
      "   0.783546    0.92732552 -0.23311696  0.58345008]\n",
      " [ 0.05778984  0.13608912  0.85119328 -0.85792788 -0.8257414  -0.95956321\n",
      "   0.66523969  0.5563135   0.7400243   0.95723668]\n",
      " [ 0.59831713 -0.07704128  0.56105835 -0.76345115  0.27984204 -0.71329343\n",
      "   0.88933783  0.04369664 -0.17067612 -0.47088878]]\n"
     ]
    }
   ],
   "source": [
    "X = full_df.values\n",
    "feature_num = X.shape[1]\n",
    "print(f\"X.shape: {X.shape}\")\n",
    "\n",
    "# 生成輸入特徵矩陣 X (shape: feature_num * data_size)\n",
    "np.random.seed(0)\n",
    "\n",
    "# 隨機生成常數項 c 和係數向量 coefficients\n",
    "c = np.random.uniform(0, 1)\n",
    "coefficients = np.random.uniform(-1, 1, (feature_num, T))  # shape: (feature_num, T)\n",
    "\n",
    "print(f\"coefficients.shape: {coefficients.shape}\")\n",
    "print(f\"coefficients: {coefficients}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YirRAft9lcD4",
    "outputId": "d4233ae9-50b8-456b-c963-bd23826b8882"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value range: (np.float64(4.0272318378257487e-101), np.float64(1.0))\n",
      "New Value range: (np.float64(1.2081695513477245e-100), np.float64(3.0))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((90, 10),\n",
       " array([[3.00000000e+000, 6.15001987e-007, 3.00000000e+000,\n",
       "         1.59851432e-085, 3.00000000e+000, 9.10228636e-080,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.16196204e-020,\n",
       "         1.56533256e-047],\n",
       "        [3.00000000e+000, 9.44205568e-007, 3.00000000e+000,\n",
       "         1.81054848e-084, 3.00000000e+000, 8.92142828e-079,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.69416411e-020,\n",
       "         1.22906399e-046],\n",
       "        [3.00000000e+000, 3.67960049e-008, 3.00000000e+000,\n",
       "         6.71411518e-098, 3.00000000e+000, 2.49831072e-091,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.88345983e-023,\n",
       "         4.36670099e-055],\n",
       "        [3.00000000e+000, 4.27643558e-008, 3.00000000e+000,\n",
       "         5.61146214e-097, 3.00000000e+000, 1.80680972e-090,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.20705214e-023,\n",
       "         1.32959541e-054],\n",
       "        [3.00000000e+000, 2.65039486e-008, 3.00000000e+000,\n",
       "         1.84705603e-098, 3.00000000e+000, 7.36252067e-092,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.68670682e-023,\n",
       "         1.07371270e-055],\n",
       "        [3.00000000e+000, 2.19181785e-008, 3.00000000e+000,\n",
       "         2.46777762e-100, 3.00000000e+000, 1.33226099e-093,\n",
       "         3.00000000e+000, 3.00000000e+000, 5.15259327e-024,\n",
       "         1.59195590e-056],\n",
       "        [3.00000000e+000, 3.53233304e-008, 3.00000000e+000,\n",
       "         2.73199939e-097, 3.00000000e+000, 9.13480131e-091,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.03796940e-023,\n",
       "         5.92970617e-055],\n",
       "        [3.00000000e+000, 2.06859967e-007, 3.00000000e+000,\n",
       "         7.65560397e-092, 3.00000000e+000, 1.16921033e-085,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.19280864e-022,\n",
       "         6.32857605e-051],\n",
       "        [3.00000000e+000, 6.51647213e-008, 3.00000000e+000,\n",
       "         3.72300696e-097, 3.00000000e+000, 1.27836117e-090,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.92896434e-023,\n",
       "         4.26610891e-054],\n",
       "        [3.00000000e+000, 4.60222792e-007, 3.00000000e+000,\n",
       "         5.52356893e-086, 3.00000000e+000, 3.32329982e-080,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.08012697e-020,\n",
       "         4.64112776e-048],\n",
       "        [3.00000000e+000, 9.38653023e-008, 3.00000000e+000,\n",
       "         9.09750815e-095, 3.00000000e+000, 2.14355033e-088,\n",
       "         3.00000000e+000, 3.00000000e+000, 7.82492350e-023,\n",
       "         7.07856900e-053],\n",
       "        [3.00000000e+000, 4.85208234e-007, 3.00000000e+000,\n",
       "         1.89772011e-086, 3.00000000e+000, 1.24078884e-080,\n",
       "         3.00000000e+000, 3.00000000e+000, 7.36034845e-021,\n",
       "         3.93068479e-048],\n",
       "        [3.00000000e+000, 2.30598010e-008, 3.00000000e+000,\n",
       "         9.57053181e-100, 3.00000000e+000, 4.69388527e-093,\n",
       "         3.00000000e+000, 3.00000000e+000, 7.53800983e-024,\n",
       "         2.82124115e-056],\n",
       "        [3.00000000e+000, 1.69737872e-007, 3.00000000e+000,\n",
       "         7.44663850e-093, 3.00000000e+000, 1.32944866e-086,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.83363379e-022,\n",
       "         1.68605926e-051],\n",
       "        [3.00000000e+000, 1.06587774e-007, 3.00000000e+000,\n",
       "         8.55560683e-091, 3.00000000e+000, 1.03636178e-084,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.23922378e-021,\n",
       "         1.73858234e-051],\n",
       "        [3.00000000e+000, 7.49515217e-001, 3.00000000e+000,\n",
       "         1.39035916e-023, 3.00000000e+000, 5.61820992e-022,\n",
       "         3.00000000e+000, 2.99999999e+000, 2.75290686e-006,\n",
       "         4.22141092e-009],\n",
       "        [3.00000000e+000, 1.33482846e+000, 3.00000000e+000,\n",
       "         3.16352432e-022, 3.00000000e+000, 1.08948974e-020,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.33385762e-006,\n",
       "         1.63092661e-007],\n",
       "        [3.00000000e+000, 1.14304407e+000, 3.00000000e+000,\n",
       "         7.51128723e-022, 3.00000000e+000, 2.37561494e-020,\n",
       "         3.00000000e+000, 2.99999999e+000, 5.55061570e-006,\n",
       "         9.46284474e-008],\n",
       "        [3.00000000e+000, 1.12309159e+000, 3.00000000e+000,\n",
       "         1.66002329e-022, 3.00000000e+000, 5.85593220e-021,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.54209720e-006,\n",
       "         5.45599635e-008],\n",
       "        [3.00000000e+000, 7.40501221e-001, 3.00000000e+000,\n",
       "         1.74690539e-022, 3.00000000e+000, 5.84804907e-021,\n",
       "         3.00000000e+000, 2.99999995e+000, 6.19020627e-006,\n",
       "         8.74510628e-009],\n",
       "        [3.00000000e+000, 1.02272001e+000, 3.00000000e+000,\n",
       "         2.28604050e-023, 3.00000000e+000, 9.22655601e-022,\n",
       "         3.00000000e+000, 3.00000000e+000, 2.16526339e-006,\n",
       "         1.89756713e-008],\n",
       "        [3.00000000e+000, 1.08816786e+000, 3.00000000e+000,\n",
       "         6.26962243e-023, 3.00000000e+000, 2.36698880e-021,\n",
       "         3.00000000e+000, 3.00000000e+000, 2.72808686e-006,\n",
       "         3.46973766e-008],\n",
       "        [3.00000000e+000, 8.17398397e-001, 3.00000000e+000,\n",
       "         9.39285604e-025, 3.00000000e+000, 4.67523411e-023,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.06144548e-006,\n",
       "         2.64312619e-009],\n",
       "        [3.00000000e+000, 1.52740056e+000, 3.00000000e+000,\n",
       "         6.35585475e-022, 3.00000000e+000, 2.12267451e-020,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.29186200e-006,\n",
       "         4.45405295e-007],\n",
       "        [3.00000000e+000, 1.26573378e+000, 3.00000000e+000,\n",
       "         3.43403506e-022, 3.00000000e+000, 1.16664026e-020,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.72257503e-006,\n",
       "         1.25438575e-007],\n",
       "        [3.00000000e+000, 1.05651632e+000, 3.00000000e+000,\n",
       "         6.31519507e-022, 3.00000000e+000, 2.00288008e-020,\n",
       "         3.00000000e+000, 2.99999999e+000, 5.87839212e-006,\n",
       "         6.12852402e-008],\n",
       "        [3.00000000e+000, 8.61781322e-001, 3.00000000e+000,\n",
       "         1.39335457e-023, 3.00000000e+000, 5.71676385e-022,\n",
       "         3.00000000e+000, 2.99999999e+000, 2.31993804e-006,\n",
       "         7.58271065e-009],\n",
       "        [3.00000000e+000, 1.25260383e+000, 3.00000000e+000,\n",
       "         2.41712654e-022, 3.00000000e+000, 8.41517762e-021,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.38780180e-006,\n",
       "         1.06569358e-007],\n",
       "        [3.00000000e+000, 7.20352921e-001, 3.00000000e+000,\n",
       "         7.73299257e-023, 3.00000000e+000, 2.74123319e-021,\n",
       "         3.00000000e+000, 2.99999996e+000, 4.95084531e-006,\n",
       "         6.08751893e-009],\n",
       "        [3.00000000e+000, 1.23448451e+000, 3.00000000e+000,\n",
       "         2.64806892e-022, 3.00000000e+000, 9.13890878e-021,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.56544385e-006,\n",
       "         1.01545366e-007],\n",
       "        [3.00000000e+000, 4.95557063e-007, 3.00000000e+000,\n",
       "         1.34200749e-084, 3.00000000e+000, 6.41777255e-079,\n",
       "         3.00000000e+000, 3.00000000e+000, 2.75558473e-020,\n",
       "         1.55205811e-047],\n",
       "        [3.00000000e+000, 1.84437148e-007, 3.00000000e+000,\n",
       "         1.27384483e-088, 3.00000000e+000, 1.11466945e-082,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.64682513e-021,\n",
       "         4.34792335e-050],\n",
       "        [3.00000000e+000, 6.04701811e-007, 3.00000000e+000,\n",
       "         4.16749205e-086, 3.00000000e+000, 2.61715757e-080,\n",
       "         3.00000000e+000, 3.00000000e+000, 7.73059915e-021,\n",
       "         9.83339866e-048],\n",
       "        [3.00000000e+000, 1.80282401e-007, 3.00000000e+000,\n",
       "         7.49646248e-089, 3.00000000e+000, 6.80911345e-083,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.15081567e-021,\n",
       "         3.44490784e-050],\n",
       "        [3.00000000e+000, 3.79153766e-007, 3.00000000e+000,\n",
       "         6.26124369e-086, 3.00000000e+000, 3.67449488e-080,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.33777860e-020,\n",
       "         2.66224542e-048],\n",
       "        [3.00000000e+000, 2.10039775e-007, 3.00000000e+000,\n",
       "         2.73087164e-089, 3.00000000e+000, 2.70567477e-083,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.99878817e-021,\n",
       "         4.03564354e-050],\n",
       "        [3.00000000e+000, 2.30715845e-007, 3.00000000e+000,\n",
       "         4.90011806e-091, 3.00000000e+000, 6.58280177e-085,\n",
       "         3.00000000e+000, 3.00000000e+000, 5.18793704e-022,\n",
       "         1.56469471e-050],\n",
       "        [3.00000000e+000, 4.22402309e-007, 3.00000000e+000,\n",
       "         5.42603932e-085, 3.00000000e+000, 2.73875982e-079,\n",
       "         3.00000000e+000, 3.00000000e+000, 2.39346271e-020,\n",
       "         7.19955619e-048],\n",
       "        [3.00000000e+000, 8.03930494e-008, 3.00000000e+000,\n",
       "         1.18140462e-095, 3.00000000e+000, 3.19626785e-089,\n",
       "         3.00000000e+000, 3.00000000e+000, 4.73499138e-023,\n",
       "         2.35048241e-053],\n",
       "        [3.00000000e+000, 6.09127827e-008, 3.00000000e+000,\n",
       "         2.54136997e-093, 3.00000000e+000, 4.52201020e-087,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.29114545e-022,\n",
       "         5.22796853e-053],\n",
       "        [3.00000000e+000, 4.80304052e-007, 3.00000000e+000,\n",
       "         1.27851005e-088, 3.00000000e+000, 1.20828129e-082,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.54187553e-021,\n",
       "         8.19711830e-049],\n",
       "        [3.00000000e+000, 1.05561205e-007, 3.00000000e+000,\n",
       "         1.00060238e-092, 3.00000000e+000, 1.68208776e-086,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.08627017e-022,\n",
       "         4.30165122e-052],\n",
       "        [3.00000000e+000, 9.29978586e-007, 3.00000000e+000,\n",
       "         8.89012359e-086, 3.00000000e+000, 5.46580825e-080,\n",
       "         3.00000000e+000, 3.00000000e+000, 6.65760841e-021,\n",
       "         4.64672379e-047],\n",
       "        [3.00000000e+000, 9.91120521e-008, 3.00000000e+000,\n",
       "         1.20632091e-093, 3.00000000e+000, 2.35878237e-087,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.67950480e-022,\n",
       "         1.85068647e-052],\n",
       "        [3.00000000e+000, 2.91734200e-008, 3.00000000e+000,\n",
       "         1.51013975e-099, 3.00000000e+000, 7.29844330e-093,\n",
       "         3.00000000e+000, 3.00000000e+000, 7.03977153e-024,\n",
       "         6.67659223e-056],\n",
       "        [3.00000000e+000, 8.23936474e-001, 3.00000000e+000,\n",
       "         2.74460795e-023, 3.00000000e+000, 1.06570890e-021,\n",
       "         3.00000000e+000, 2.99999999e+000, 3.03726027e-006,\n",
       "         7.71092447e-009],\n",
       "        [3.00000000e+000, 1.04597912e+000, 3.00000000e+000,\n",
       "         1.86273049e-023, 3.00000000e+000, 7.65378166e-022,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.96843883e-006,\n",
       "         1.97963403e-008],\n",
       "        [3.00000000e+000, 7.15945789e-001, 3.00000000e+000,\n",
       "         3.26103635e-023, 3.00000000e+000, 1.23129496e-021,\n",
       "         3.00000000e+000, 2.99999997e+000, 3.80120761e-006,\n",
       "         4.55474833e-009],\n",
       "        [3.00000000e+000, 1.28370642e+000, 3.00000000e+000,\n",
       "         3.00099624e-022, 3.00000000e+000, 1.03176288e-020,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.49017076e-006,\n",
       "         1.29747766e-007],\n",
       "        [3.00000000e+000, 6.46909145e-001, 3.00000000e+000,\n",
       "         1.58311479e-024, 3.00000000e+000, 7.39502948e-023,\n",
       "         3.00000000e+000, 2.99999999e+000, 1.65234595e-006,\n",
       "         1.20229807e-009],\n",
       "        [3.00000000e+000, 8.00417086e-001, 3.00000000e+000,\n",
       "         8.15057504e-023, 3.00000000e+000, 2.91103766e-021,\n",
       "         3.00000000e+000, 2.99999998e+000, 4.43255522e-006,\n",
       "         9.53819968e-009],\n",
       "        [3.00000000e+000, 8.64665312e-001, 3.00000000e+000,\n",
       "         2.84176125e-024, 3.00000000e+000, 1.31168028e-022,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.40128615e-006,\n",
       "         4.71955518e-009],\n",
       "        [3.00000000e+000, 6.06456498e-001, 3.00000000e+000,\n",
       "         1.34446535e-023, 3.00000000e+000, 5.32736156e-022,\n",
       "         3.00000000e+000, 2.99999996e+000, 3.48461203e-006,\n",
       "         1.80623083e-009],\n",
       "        [3.00000000e+000, 1.32679471e+000, 3.00000000e+000,\n",
       "         1.56096355e-022, 3.00000000e+000, 5.65871913e-021,\n",
       "         3.00000000e+000, 3.00000000e+000, 2.69604088e-006,\n",
       "         1.26973863e-007],\n",
       "        [3.00000000e+000, 5.57730285e-001, 3.00000000e+000,\n",
       "         5.68358193e-024, 3.00000000e+000, 2.37987637e-022,\n",
       "         3.00000000e+000, 2.99999995e+000, 2.91889908e-006,\n",
       "         1.00800003e-009],\n",
       "        [3.00000000e+000, 1.15839749e+000, 3.00000000e+000,\n",
       "         8.22289310e-023, 3.00000000e+000, 3.06751192e-021,\n",
       "         3.00000000e+000, 3.00000000e+000, 2.71514357e-006,\n",
       "         5.12447110e-008],\n",
       "        [3.00000000e+000, 6.64981199e-001, 3.00000000e+000,\n",
       "         2.77648189e-024, 3.00000000e+000, 1.24779099e-022,\n",
       "         3.00000000e+000, 2.99999999e+000, 1.90997171e-006,\n",
       "         1.59204239e-009],\n",
       "        [3.00000000e+000, 1.09969435e+000, 3.00000000e+000,\n",
       "         1.92035557e-023, 3.00000000e+000, 7.92251880e-022,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.85264328e-006,\n",
       "         2.53796895e-008],\n",
       "        [3.00000000e+000, 1.10093952e+000, 3.00000000e+000,\n",
       "         1.62891102e-024, 3.00000000e+000, 8.06425623e-023,\n",
       "         3.00000000e+000, 3.00000000e+000, 8.51474836e-007,\n",
       "         1.19568574e-008],\n",
       "        [3.00000000e+000, 7.31055489e-001, 3.00000000e+000,\n",
       "         1.19062535e-023, 3.00000000e+000, 4.85354510e-022,\n",
       "         3.00000000e+000, 2.99999998e+000, 2.70123527e-006,\n",
       "         3.63632874e-009],\n",
       "        [3.00000000e+000, 1.05899468e-007, 3.00000000e+000,\n",
       "         6.22429517e-094, 3.00000000e+000, 1.28486637e-087,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.28502029e-022,\n",
       "         1.85037549e-052],\n",
       "        [3.00000000e+000, 8.96680378e-008, 3.00000000e+000,\n",
       "         1.38887729e-093, 3.00000000e+000, 2.66599462e-087,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.92129043e-022,\n",
       "         1.42152594e-052],\n",
       "        [3.00000000e+000, 1.05594534e-007, 3.00000000e+000,\n",
       "         4.83362534e-095, 3.00000000e+000, 1.20473913e-088,\n",
       "         3.00000000e+000, 3.00000000e+000, 5.76850444e-023,\n",
       "         8.36353800e-053],\n",
       "        [3.00000000e+000, 7.69469866e-008, 3.00000000e+000,\n",
       "         6.39656686e-095, 3.00000000e+000, 1.52225536e-088,\n",
       "         3.00000000e+000, 3.00000000e+000, 8.37750802e-023,\n",
       "         3.45308504e-053],\n",
       "        [3.00000000e+000, 1.43594079e-007, 3.00000000e+000,\n",
       "         3.44728921e-091, 3.00000000e+000, 4.57443095e-085,\n",
       "         3.00000000e+000, 3.00000000e+000, 7.11946910e-022,\n",
       "         3.27988738e-051],\n",
       "        [3.00000000e+000, 2.88719202e-008, 3.00000000e+000,\n",
       "         5.83444061e-099, 3.00000000e+000, 2.54978200e-092,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.08691244e-023,\n",
       "         9.79686642e-056],\n",
       "        [3.00000000e+000, 1.21161675e-007, 3.00000000e+000,\n",
       "         5.37367162e-090, 3.00000000e+000, 5.74242373e-084,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.96768025e-021,\n",
       "         4.53024556e-051],\n",
       "        [3.00000000e+000, 1.24487209e-007, 3.00000000e+000,\n",
       "         3.19379347e-091, 3.00000000e+000, 4.21318213e-085,\n",
       "         3.00000000e+000, 3.00000000e+000, 7.90436910e-022,\n",
       "         2.06761739e-051],\n",
       "        [3.00000000e+000, 3.10607510e-008, 3.00000000e+000,\n",
       "         6.68055204e-099, 3.00000000e+000, 2.90760125e-092,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.06195268e-023,\n",
       "         1.27790213e-055],\n",
       "        [3.00000000e+000, 2.95432978e-008, 3.00000000e+000,\n",
       "         2.33751889e-097, 3.00000000e+000, 7.79311135e-091,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.39765449e-023,\n",
       "         3.26744092e-055],\n",
       "        [3.00000000e+000, 6.13713935e-008, 3.00000000e+000,\n",
       "         9.03764966e-096, 3.00000000e+000, 2.44020856e-089,\n",
       "         3.00000000e+000, 3.00000000e+000, 5.55056917e-023,\n",
       "         9.45763248e-054],\n",
       "        [3.00000000e+000, 5.16879978e-007, 3.00000000e+000,\n",
       "         1.06263819e-085, 3.00000000e+000, 6.14923561e-080,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.19513615e-020,\n",
       "         8.10197042e-048],\n",
       "        [3.00000000e+000, 1.62905647e-008, 3.00000000e+000,\n",
       "         3.48258942e-099, 3.00000000e+000, 1.50970777e-092,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.54729111e-023,\n",
       "         1.44521463e-056],\n",
       "        [3.00000000e+000, 4.24571773e-008, 3.00000000e+000,\n",
       "         7.77031249e-096, 3.00000000e+000, 2.05939375e-089,\n",
       "         3.00000000e+000, 3.00000000e+000, 7.37597764e-023,\n",
       "         2.91634663e-054],\n",
       "        [3.00000000e+000, 1.87532458e-008, 3.00000000e+000,\n",
       "         1.20816955e-100, 3.00000000e+000, 6.78967756e-094,\n",
       "         3.00000000e+000, 3.00000000e+000, 4.73686044e-024,\n",
       "         7.92301198e-057],\n",
       "        [3.00000000e+000, 6.12517949e-001, 3.00000000e+000,\n",
       "         3.69277487e-024, 3.00000000e+000, 1.61136498e-022,\n",
       "         3.00000000e+000, 2.99999998e+000, 2.29513492e-006,\n",
       "         1.26168629e-009],\n",
       "        [3.00000000e+000, 1.52131232e+000, 3.00000000e+000,\n",
       "         1.34199331e-021, 3.00000000e+000, 4.23845069e-020,\n",
       "         3.00000000e+000, 3.00000000e+000, 4.19448229e-006,\n",
       "         5.46608864e-007],\n",
       "        [3.00000000e+000, 8.27622049e-001, 3.00000000e+000,\n",
       "         1.61064193e-022, 3.00000000e+000, 5.49063618e-021,\n",
       "         3.00000000e+000, 2.99999997e+000, 5.26900407e-006,\n",
       "         1.35351388e-008],\n",
       "        [3.00000000e+000, 9.40054552e-001, 3.00000000e+000,\n",
       "         6.76014074e-024, 3.00000000e+000, 2.95524892e-022,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.65240535e-006,\n",
       "         8.88754321e-009],\n",
       "        [3.00000000e+000, 8.92233215e-001, 3.00000000e+000,\n",
       "         6.98738013e-022, 3.00000000e+000, 2.15560746e-020,\n",
       "         3.00000000e+000, 2.99999997e+000, 7.60178366e-006,\n",
       "         2.93526228e-008],\n",
       "        [3.00000000e+000, 1.21502194e+000, 3.00000000e+000,\n",
       "         2.79059991e-023, 3.00000000e+000, 1.13470752e-021,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.80025412e-006,\n",
       "         4.68383507e-008],\n",
       "        [3.00000000e+000, 1.44983840e+000, 3.00000000e+000,\n",
       "         1.01528227e-021, 3.00000000e+000, 3.24824776e-020,\n",
       "         3.00000000e+000, 3.00000000e+000, 4.18663341e-006,\n",
       "         3.74515367e-007],\n",
       "        [3.00000000e+000, 1.18673348e+000, 3.00000000e+000,\n",
       "         4.00517860e-022, 3.00000000e+000, 1.33351934e-020,\n",
       "         3.00000000e+000, 3.00000000e+000, 4.31007837e-006,\n",
       "         9.41416946e-008],\n",
       "        [3.00000000e+000, 1.16772087e+000, 3.00000000e+000,\n",
       "         1.81138218e-021, 3.00000000e+000, 5.38343196e-020,\n",
       "         3.00000000e+000, 2.99999999e+000, 7.09519432e-006,\n",
       "         1.37963815e-007],\n",
       "        [3.00000000e+000, 5.95799203e-001, 3.00000000e+000,\n",
       "         6.30797883e-024, 3.00000000e+000, 2.63842692e-022,\n",
       "         3.00000000e+000, 2.99999997e+000, 2.80209018e-006,\n",
       "         1.33735924e-009],\n",
       "        [3.00000000e+000, 1.26898857e+000, 3.00000000e+000,\n",
       "         3.02507547e-022, 3.00000000e+000, 1.03774537e-020,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.56277405e-006,\n",
       "         1.22301707e-007],\n",
       "        [3.00000000e+000, 1.02582043e+000, 3.00000000e+000,\n",
       "         1.44209309e-022, 3.00000000e+000, 5.08208138e-021,\n",
       "         3.00000000e+000, 2.99999999e+000, 3.84803418e-006,\n",
       "         3.38936662e-008],\n",
       "        [3.00000000e+000, 9.12414154e-001, 3.00000000e+000,\n",
       "         1.37356993e-024, 3.00000000e+000, 6.73106024e-023,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.04081960e-006,\n",
       "         4.77092038e-009],\n",
       "        [3.00000000e+000, 1.12766391e+000, 3.00000000e+000,\n",
       "         6.78567695e-024, 3.00000000e+000, 3.03275205e-022,\n",
       "         3.00000000e+000, 3.00000000e+000, 1.28856517e-006,\n",
       "         2.08384267e-008],\n",
       "        [3.00000000e+000, 1.59234091e+000, 3.00000000e+000,\n",
       "         1.06026770e-021, 3.00000000e+000, 3.43363720e-020,\n",
       "         3.00000000e+000, 3.00000000e+000, 3.57599450e-006,\n",
       "         6.80118616e-007]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 進行矩陣運算\n",
    "# X.T 的形狀為 (data_size, feature_num)，X.T @ coefficients 的形狀為 (feature_num, T)\n",
    "linear_combination = c + X @ coefficients\n",
    "\n",
    "# 使用 sigmoid 函數將值映射到 [0, 1] 之間\n",
    "sigma_matrix = 1 / (1 + np.exp(-linear_combination))  # shape: (data_size, T)\n",
    "# print(f\"sigma_matrix.shape: {sigma_matrix.shape}\")\n",
    "# print(f\"sigma_matrix: {sigma_matrix}\")\n",
    "\n",
    "# 計算每個元素的最小值和最大值\n",
    "min_value = np.min(sigma_matrix)\n",
    "max_value = np.max(sigma_matrix)\n",
    "print(f\"Value range: {(min_value, max_value)}\")\n",
    "\n",
    "# 再將值縮放到 [2, 10] 的範圍\n",
    "# shape: (data_size, T)\n",
    "# sigma_matrix = 0 + sigma_matrix * 300\n",
    "\n",
    "# sigma_matrix = 0 + sigma_matrix * 200\n",
    "# sigma_matrix = 100 + sigma_matrix * 100\n",
    "# sigma_matrix = 0 + sigma_matrix * 10\n",
    "sigma_matrix = 0 + sigma_matrix * 3\n",
    "# sigma_matrix = 50 + sigma_matrix * 50\n",
    "# sigma_matrix = 0 + sigma_matrix * 2\n",
    "# sigma_matrix = 10 + sigma_matrix * 5\n",
    "# sigma_matrix = 0 + sigma_matrix * 1\n",
    "\n",
    "\n",
    "# sigma_matrix = 0 + sigma_matrix * 80\n",
    "# sigma_matrix = 40 + sigma_matrix * 40\n",
    "# sigma_matrix = 0 + sigma_matrix * 40\n",
    "# sigma_matrix = 20 + sigma_matrix * 20\n",
    "# sigma_matrix = 0 + sigma_matrix * 5\n",
    "\n",
    "# sigma_matrix = 0 + sigma_matrix * 8\n",
    "# sigma_matrix = 4 + sigma_matrix * 4\n",
    "# sigma_matrix = 0 + sigma_matrix * 4\n",
    "# sigma_matrix = 2 + sigma_matrix * 2\n",
    "# sigma_matrix = 0 + sigma_matrix * 0.3\n",
    "\n",
    "# 計算每個元素的最小值和最大值\n",
    "min_value = np.min(sigma_matrix)\n",
    "max_value = np.max(sigma_matrix)\n",
    "print(f\"New Value range: {(min_value, max_value)}\")\n",
    "\n",
    "# 輸出 sigma_matrix 的形狀和內容\n",
    "sigma_matrix_shape = sigma_matrix.shape\n",
    "sigma_matrix_content = sigma_matrix\n",
    "\n",
    "sigma_matrix_shape, sigma_matrix_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNQRS392qk1H"
   },
   "source": [
    "### corr matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6t2w0Y7EYxB0",
    "outputId": "72618685-7498-42d7-e92c-67457a485da5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr_matrix shape: (10, 10)\n",
      "corr_matrix: \n",
      "[[ 1.          0.35424279  0.5557836   0.58741064 -0.38777369 -0.16148427\n",
      "  -0.0990728  -0.27594366 -0.48889127 -0.02092469]\n",
      " [ 0.35424279  1.          0.64567134  0.34424882 -0.53396229 -0.11871438\n",
      "  -0.3666009   0.07223015  0.10995817 -0.04912633]\n",
      " [ 0.5557836   0.64567134  1.          0.259728   -0.42849166 -0.23652044\n",
      "  -0.55154321  0.01056255 -0.4142461  -0.12870872]\n",
      " [ 0.58741064  0.34424882  0.259728    1.         -0.43371556 -0.07896157\n",
      "   0.16623268 -0.63102156  0.08913915  0.24417687]\n",
      " [-0.38777369 -0.53396229 -0.42849166 -0.43371556  1.          0.37139904\n",
      "   0.30031034  0.29401969 -0.15371929 -0.10854857]\n",
      " [-0.16148427 -0.11871438 -0.23652044 -0.07896157  0.37139904  1.\n",
      "   0.65829169  0.52050763 -0.34173775  0.14741869]\n",
      " [-0.0990728  -0.3666009  -0.55154321  0.16623268  0.30031034  0.65829169\n",
      "   1.          0.03894138 -0.00977194  0.48587032]\n",
      " [-0.27594366  0.07223015  0.01056255 -0.63102156  0.29401969  0.52050763\n",
      "   0.03894138  1.         -0.20365855  0.13048727]\n",
      " [-0.48889127  0.10995817 -0.4142461   0.08913915 -0.15371929 -0.34173775\n",
      "  -0.00977194 -0.20365855  1.          0.35511152]\n",
      " [-0.02092469 -0.04912633 -0.12870872  0.24417687 -0.10854857  0.14741869\n",
      "   0.48587032  0.13048727  0.35511152  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Generate correlation matrix\n",
    "np.random.seed(0)\n",
    "\n",
    "A = np.random.uniform(-1, 1, (T, T))\n",
    "corr_matrix = np.dot(A, A.T)\n",
    "\n",
    "D = np.diag(1 / np.sqrt(np.diag(corr_matrix)))\n",
    "corr_matrix = D @ corr_matrix @ D\n",
    "\n",
    "print(f\"corr_matrix shape: {corr_matrix.shape}\")\n",
    "print(f\"corr_matrix: \\n{corr_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxpp4zz0qxAA"
   },
   "source": [
    "### cov matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ft_GZABHZ754",
    "outputId": "a7b0c34d-fecb-4cda-c58a-ded5cb35b8a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cov_matrices shape: (90, 10, 10)\n",
      "cov_matrices: \n",
      "[[ 9.00000000e+000  6.53580061e-007  5.00205241e+000  2.81695297e-085\n",
      "  -3.48996324e+000 -4.40962825e-080 -8.91655219e-001 -2.48349295e+000\n",
      "  -1.70421930e-020 -9.82623188e-049]\n",
      " [ 6.53580061e-007  3.78227444e-013  1.19126747e-006  3.38427395e-092\n",
      "  -9.85163603e-007 -6.64554083e-087 -6.76380850e-007  1.33265054e-007\n",
      "   7.85770906e-028 -4.72930647e-055]\n",
      " [ 5.00205241e+000  1.19126747e-006  9.00000000e+000  1.24553678e-085\n",
      "  -3.85642497e+000 -6.45863021e-080 -4.96388886e+000  9.50629143e-002\n",
      "  -1.44401472e-020 -6.04415847e-048]\n",
      " [ 2.81695297e-085  3.38427395e-092  1.24553678e-085  2.55524802e-170\n",
      "  -2.07990158e-085 -1.14890155e-165  7.97175933e-086 -3.02609098e-085\n",
      "   1.65568211e-106  6.10980952e-133]\n",
      " [-3.48996324e+000 -9.85163603e-007 -3.85642497e+000 -2.07990158e-085\n",
      "   9.00000000e+000  1.01417413e-079  2.70279307e+000  2.64617719e+000\n",
      "  -5.35847928e-021 -5.09743830e-048]\n",
      " [-4.40962825e-080 -6.64554083e-087 -6.45863021e-080 -1.14890155e-165\n",
      "   1.01417413e-079  8.28516171e-159  1.79758785e-079  1.42134284e-079\n",
      "  -3.61439311e-100  2.10043700e-127]\n",
      " [-8.91655219e-001 -6.76380850e-007 -4.96388886e+000  7.97175933e-086\n",
      "   2.70279307e+000  1.79758785e-079  9.00000000e+000  3.50472395e-001\n",
      "  -3.40638856e-022  2.28164587e-047]\n",
      " [-2.48349295e+000  1.33265054e-007  9.50629143e-002 -3.02609098e-085\n",
      "   2.64617719e+000  1.42134284e-079  3.50472395e-001  9.00000000e+000\n",
      "  -7.09930513e-021  6.12767894e-048]\n",
      " [-1.70421930e-020  7.85770906e-028 -1.44401472e-020  1.65568211e-106\n",
      "  -5.35847928e-021 -3.61439311e-100 -3.40638856e-022 -7.09930513e-021\n",
      "   1.35015577e-040  6.45897075e-068]\n",
      " [-9.82623188e-049 -4.72930647e-055 -6.04415847e-048  6.10980952e-133\n",
      "  -5.09743830e-048  2.10043700e-127  2.28164587e-047  6.12767894e-048\n",
      "   6.45897075e-068  2.45026601e-094]]\n"
     ]
    }
   ],
   "source": [
    "# Generate covariance matrices\n",
    "cov_matrices = []\n",
    "for i in range(data_size):\n",
    "    cov_matrix = np.zeros((T, T))  # 每一個模擬都會有 T*T 的共變異矩陣\n",
    "    for j in range(T):\n",
    "        for k in range(T):\n",
    "            cov_matrix[j, k] = (\n",
    "                corr_matrix[j, k] * sigma_matrix[i, j] * sigma_matrix[i, k]\n",
    "            )\n",
    "    cov_matrices.append(cov_matrix)\n",
    "\n",
    "print(f\"cov_matrices shape: {np.array(cov_matrices).shape}\")\n",
    "print(f\"cov_matrices: \\n{cov_matrices[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "36jbx5j7Tt0D",
    "outputId": "62658998-8158-425b-c756-8448e4c96db5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All covariance matrices are positive definite: False\n"
     ]
    }
   ],
   "source": [
    "def is_positive_definite(matrix):\n",
    "    return np.all(np.linalg.eigvals(matrix) > 0)\n",
    "\n",
    "\n",
    "positive_definite_check = all(is_positive_definite(cov) for cov in cov_matrices)\n",
    "print(\"All covariance matrices are positive definite:\", positive_definite_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDjqi0k25thw"
   },
   "source": [
    "### MVN stimulation for demand_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kz-UdBRYc2Hb",
    "outputId": "4e19fe37-abd4-4435-d5b9-9e964c44ceb0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>251.794016</td>\n",
       "      <td>254.356464</td>\n",
       "      <td>247.741536</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>261.523870</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.087872</td>\n",
       "      <td>252.716034</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.356465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251.056784</td>\n",
       "      <td>251.010919</td>\n",
       "      <td>248.192143</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>250.249903</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>252.054546</td>\n",
       "      <td>246.842220</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>251.010920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>297.528249</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>294.250464</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>283.569719</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>285.767294</td>\n",
       "      <td>287.835884</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>291.630992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>289.066894</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.355508</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>285.816090</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>292.681865</td>\n",
       "      <td>290.851589</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.907838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298.072424</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>299.903104</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>296.615372</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>290.943971</td>\n",
       "      <td>295.944768</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>293.500607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>65.746933</td>\n",
       "      <td>65.853934</td>\n",
       "      <td>70.574162</td>\n",
       "      <td>62.239247</td>\n",
       "      <td>55.130102</td>\n",
       "      <td>62.239247</td>\n",
       "      <td>57.888206</td>\n",
       "      <td>63.679955</td>\n",
       "      <td>62.239243</td>\n",
       "      <td>62.239247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>61.329502</td>\n",
       "      <td>63.260741</td>\n",
       "      <td>60.017189</td>\n",
       "      <td>63.453517</td>\n",
       "      <td>66.141381</td>\n",
       "      <td>63.453517</td>\n",
       "      <td>65.584679</td>\n",
       "      <td>64.101433</td>\n",
       "      <td>63.453519</td>\n",
       "      <td>63.453517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>66.822772</td>\n",
       "      <td>69.549069</td>\n",
       "      <td>66.237491</td>\n",
       "      <td>69.280813</td>\n",
       "      <td>70.547457</td>\n",
       "      <td>69.280813</td>\n",
       "      <td>70.842404</td>\n",
       "      <td>73.111604</td>\n",
       "      <td>69.280814</td>\n",
       "      <td>69.280813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>62.577572</td>\n",
       "      <td>67.210049</td>\n",
       "      <td>65.172995</td>\n",
       "      <td>67.044144</td>\n",
       "      <td>70.357863</td>\n",
       "      <td>67.044144</td>\n",
       "      <td>68.535449</td>\n",
       "      <td>70.440907</td>\n",
       "      <td>67.044145</td>\n",
       "      <td>67.044144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>59.277409</td>\n",
       "      <td>59.472203</td>\n",
       "      <td>62.933669</td>\n",
       "      <td>60.318389</td>\n",
       "      <td>57.697020</td>\n",
       "      <td>60.318389</td>\n",
       "      <td>59.467526</td>\n",
       "      <td>57.168997</td>\n",
       "      <td>60.318390</td>\n",
       "      <td>60.318390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "0   251.794016  254.356464  247.741536  254.356465  261.523870  254.356465   \n",
       "1   251.056784  251.010919  248.192143  251.010920  250.249903  251.010920   \n",
       "2   297.528249  291.630992  294.250464  291.630992  283.569719  291.630992   \n",
       "3   289.066894  288.907838  288.355508  288.907838  285.816090  288.907838   \n",
       "4   298.072424  293.500607  299.903104  293.500607  296.615372  293.500607   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "85   65.746933   65.853934   70.574162   62.239247   55.130102   62.239247   \n",
       "86   61.329502   63.260741   60.017189   63.453517   66.141381   63.453517   \n",
       "87   66.822772   69.549069   66.237491   69.280813   70.547457   69.280813   \n",
       "88   62.577572   67.210049   65.172995   67.044144   70.357863   67.044144   \n",
       "89   59.277409   59.472203   62.933669   60.318389   57.697020   60.318389   \n",
       "\n",
       "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "0   254.087872  252.716034  254.356465  254.356465  \n",
       "1   252.054546  246.842220  251.010920  251.010920  \n",
       "2   285.767294  287.835884  291.630992  291.630992  \n",
       "3   292.681865  290.851589  288.907838  288.907838  \n",
       "4   290.943971  295.944768  293.500607  293.500607  \n",
       "..         ...         ...         ...         ...  \n",
       "85   57.888206   63.679955   62.239243   62.239247  \n",
       "86   65.584679   64.101433   63.453519   63.453517  \n",
       "87   70.842404   73.111604   69.280814   69.280813  \n",
       "88   68.535449   70.440907   67.044145   67.044144  \n",
       "89   59.467526   57.168997   60.318390   60.318390  \n",
       "\n",
       "[90 rows x 10 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simulate_demand_data(data_size, T, cov_matrices, mu_matrix):\n",
    "    np.random.seed(0)\n",
    "\n",
    "    simulated_data = np.array(\n",
    "        [\n",
    "            np.random.multivariate_normal(mu_matrix[i], cov_matrices[i])\n",
    "            for i in range(data_size)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    demand_df = pd.DataFrame(\n",
    "        simulated_data, columns=[f\"demand_t{t}\" for t in range(1, T + 1)]\n",
    "    )\n",
    "    return demand_df\n",
    "\n",
    "\n",
    "demand_df = simulate_demand_data(data_size, T, cov_matrices, mu_matrix)\n",
    "demand_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9SB3AS8eLXlJ"
   },
   "source": [
    "### Replace negative values to 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jj5Gvln1Lb2X",
    "outputId": "09dc87db-1439-4d01-a41e-7bd0e7a0f1ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27336/2799096767.py:3: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df.applymap(lambda x: max(x, 0))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>251.794016</td>\n",
       "      <td>254.356464</td>\n",
       "      <td>247.741536</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>261.523870</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.087872</td>\n",
       "      <td>252.716034</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.356465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251.056784</td>\n",
       "      <td>251.010919</td>\n",
       "      <td>248.192143</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>250.249903</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>252.054546</td>\n",
       "      <td>246.842220</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>251.010920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>297.528249</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>294.250464</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>283.569719</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>285.767294</td>\n",
       "      <td>287.835884</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>291.630992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>289.066894</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.355508</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>285.816090</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>292.681865</td>\n",
       "      <td>290.851589</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.907838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298.072424</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>299.903104</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>296.615372</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>290.943971</td>\n",
       "      <td>295.944768</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>293.500607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>65.746933</td>\n",
       "      <td>65.853934</td>\n",
       "      <td>70.574162</td>\n",
       "      <td>62.239247</td>\n",
       "      <td>55.130102</td>\n",
       "      <td>62.239247</td>\n",
       "      <td>57.888206</td>\n",
       "      <td>63.679955</td>\n",
       "      <td>62.239243</td>\n",
       "      <td>62.239247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>61.329502</td>\n",
       "      <td>63.260741</td>\n",
       "      <td>60.017189</td>\n",
       "      <td>63.453517</td>\n",
       "      <td>66.141381</td>\n",
       "      <td>63.453517</td>\n",
       "      <td>65.584679</td>\n",
       "      <td>64.101433</td>\n",
       "      <td>63.453519</td>\n",
       "      <td>63.453517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>66.822772</td>\n",
       "      <td>69.549069</td>\n",
       "      <td>66.237491</td>\n",
       "      <td>69.280813</td>\n",
       "      <td>70.547457</td>\n",
       "      <td>69.280813</td>\n",
       "      <td>70.842404</td>\n",
       "      <td>73.111604</td>\n",
       "      <td>69.280814</td>\n",
       "      <td>69.280813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>62.577572</td>\n",
       "      <td>67.210049</td>\n",
       "      <td>65.172995</td>\n",
       "      <td>67.044144</td>\n",
       "      <td>70.357863</td>\n",
       "      <td>67.044144</td>\n",
       "      <td>68.535449</td>\n",
       "      <td>70.440907</td>\n",
       "      <td>67.044145</td>\n",
       "      <td>67.044144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>59.277409</td>\n",
       "      <td>59.472203</td>\n",
       "      <td>62.933669</td>\n",
       "      <td>60.318389</td>\n",
       "      <td>57.697020</td>\n",
       "      <td>60.318389</td>\n",
       "      <td>59.467526</td>\n",
       "      <td>57.168997</td>\n",
       "      <td>60.318390</td>\n",
       "      <td>60.318390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "0   251.794016  254.356464  247.741536  254.356465  261.523870  254.356465   \n",
       "1   251.056784  251.010919  248.192143  251.010920  250.249903  251.010920   \n",
       "2   297.528249  291.630992  294.250464  291.630992  283.569719  291.630992   \n",
       "3   289.066894  288.907838  288.355508  288.907838  285.816090  288.907838   \n",
       "4   298.072424  293.500607  299.903104  293.500607  296.615372  293.500607   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "85   65.746933   65.853934   70.574162   62.239247   55.130102   62.239247   \n",
       "86   61.329502   63.260741   60.017189   63.453517   66.141381   63.453517   \n",
       "87   66.822772   69.549069   66.237491   69.280813   70.547457   69.280813   \n",
       "88   62.577572   67.210049   65.172995   67.044144   70.357863   67.044144   \n",
       "89   59.277409   59.472203   62.933669   60.318389   57.697020   60.318389   \n",
       "\n",
       "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "0   254.087872  252.716034  254.356465  254.356465  \n",
       "1   252.054546  246.842220  251.010920  251.010920  \n",
       "2   285.767294  287.835884  291.630992  291.630992  \n",
       "3   292.681865  290.851589  288.907838  288.907838  \n",
       "4   290.943971  295.944768  293.500607  293.500607  \n",
       "..         ...         ...         ...         ...  \n",
       "85   57.888206   63.679955   62.239243   62.239247  \n",
       "86   65.584679   64.101433   63.453519   63.453517  \n",
       "87   70.842404   73.111604   69.280814   69.280813  \n",
       "88   68.535449   70.440907   67.044145   67.044144  \n",
       "89   59.467526   57.168997   60.318390   60.318390  \n",
       "\n",
       "[90 rows x 10 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df = replace_negative_with_zero(demand_df)\n",
    "demand_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJ_lOKc5Sx_y"
   },
   "source": [
    "### Validate the mean and std of total demand\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ypOKYMaS8cm"
   },
   "source": [
    "檢查生成的需求數據是否符合上述總需求的特性。例如，從生成的需求 demand_df 中計算總需求\n",
    "𝐷\n",
    "D，然後檢查其均值和標準差是否接近理論值（即均值為所有\n",
    "𝜇\n",
    "𝑡\n",
    "μ\n",
    "t\n",
    "​\n",
    "的和，標準差根據共變異數矩陣計算）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OYoBmwqpUMLF",
    "outputId": "5ed51381-2231-42d6-c082-01af32258d0a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>theoretical_mean</th>\n",
       "      <th>empirical_mean</th>\n",
       "      <th>theoretical_std</th>\n",
       "      <th>empirical_std</th>\n",
       "      <th>std_relative_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2543.564650</td>\n",
       "      <td>2539.645651</td>\n",
       "      <td>5.934835</td>\n",
       "      <td>3.208153</td>\n",
       "      <td>84.992292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2510.109199</td>\n",
       "      <td>2503.450193</td>\n",
       "      <td>5.934835</td>\n",
       "      <td>1.501990</td>\n",
       "      <td>295.131489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2916.309923</td>\n",
       "      <td>2907.106572</td>\n",
       "      <td>5.934835</td>\n",
       "      <td>3.833263</td>\n",
       "      <td>54.824635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2889.078375</td>\n",
       "      <td>2891.311133</td>\n",
       "      <td>5.934835</td>\n",
       "      <td>1.655663</td>\n",
       "      <td>258.456665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2935.006074</td>\n",
       "      <td>2948.982676</td>\n",
       "      <td>5.934835</td>\n",
       "      <td>2.541082</td>\n",
       "      <td>133.555385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>622.392469</td>\n",
       "      <td>627.830276</td>\n",
       "      <td>6.175676</td>\n",
       "      <td>4.042657</td>\n",
       "      <td>52.762794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>634.535168</td>\n",
       "      <td>634.248994</td>\n",
       "      <td>6.109878</td>\n",
       "      <td>1.689231</td>\n",
       "      <td>261.695820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>692.808129</td>\n",
       "      <td>694.234050</td>\n",
       "      <td>6.082276</td>\n",
       "      <td>1.840933</td>\n",
       "      <td>230.390993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>670.441440</td>\n",
       "      <td>672.471413</td>\n",
       "      <td>6.136350</td>\n",
       "      <td>2.186541</td>\n",
       "      <td>180.641854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>603.183893</td>\n",
       "      <td>597.290383</td>\n",
       "      <td>6.276710</td>\n",
       "      <td>1.505996</td>\n",
       "      <td>316.781412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    theoretical_mean  empirical_mean  theoretical_std  empirical_std  \\\n",
       "0        2543.564650     2539.645651         5.934835       3.208153   \n",
       "1        2510.109199     2503.450193         5.934835       1.501990   \n",
       "2        2916.309923     2907.106572         5.934835       3.833263   \n",
       "3        2889.078375     2891.311133         5.934835       1.655663   \n",
       "4        2935.006074     2948.982676         5.934835       2.541082   \n",
       "..               ...             ...              ...            ...   \n",
       "85        622.392469      627.830276         6.175676       4.042657   \n",
       "86        634.535168      634.248994         6.109878       1.689231   \n",
       "87        692.808129      694.234050         6.082276       1.840933   \n",
       "88        670.441440      672.471413         6.136350       2.186541   \n",
       "89        603.183893      597.290383         6.276710       1.505996   \n",
       "\n",
       "    std_relative_error  \n",
       "0            84.992292  \n",
       "1           295.131489  \n",
       "2            54.824635  \n",
       "3           258.456665  \n",
       "4           133.555385  \n",
       "..                 ...  \n",
       "85           52.762794  \n",
       "86          261.695820  \n",
       "87          230.390993  \n",
       "88          180.641854  \n",
       "89          316.781412  \n",
       "\n",
       "[90 rows x 5 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_theoretical_vs_empirical(demand_df, cov_matrices, mu_matrix):\n",
    "    results = []\n",
    "    for i in range(len(demand_df)):\n",
    "\n",
    "        demand_i = demand_df.iloc[i, :]\n",
    "\n",
    "        # theoretical mean\n",
    "        theoretical_mean = mu_matrix[i].sum()\n",
    "\n",
    "        # theoretical std\n",
    "        variance_sum = np.sum(np.diag(cov_matrices[i]))\n",
    "        covariance_sum = np.sum(cov_matrices[i]) - variance_sum\n",
    "        theoretical_variance = variance_sum + covariance_sum\n",
    "        theoretical_std = np.sqrt(theoretical_variance)\n",
    "\n",
    "        # empirical mean and std\n",
    "        empirical_mean = demand_i.sum()\n",
    "        empirical_std = demand_i.std(ddof=0)  # 指定除以 n 而非 n-1\n",
    "        std_relative_error = abs(theoretical_std - empirical_std) / empirical_std * 100\n",
    "\n",
    "        # save the results\n",
    "        results.append(\n",
    "            {\n",
    "                \"theoretical_mean\": theoretical_mean,\n",
    "                \"empirical_mean\": empirical_mean,\n",
    "                \"theoretical_std\": theoretical_std,\n",
    "                \"empirical_std\": empirical_std,\n",
    "                \"std_relative_error\": std_relative_error,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "results_df = check_theoretical_vs_empirical(demand_df, cov_matrices, mu_matrix)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-QM7SNl1okD"
   },
   "source": [
    "### Validate normal distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_pKfG7Hq1vHo",
    "outputId": "55ca004b-bca0-468b-f047-ec36a691b1f5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>251.794016</td>\n",
       "      <td>254.356464</td>\n",
       "      <td>247.741536</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>261.523870</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.087872</td>\n",
       "      <td>252.716034</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.356465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251.056784</td>\n",
       "      <td>251.010919</td>\n",
       "      <td>248.192143</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>250.249903</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>252.054546</td>\n",
       "      <td>246.842220</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>251.010920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>297.528249</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>294.250464</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>283.569719</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>285.767294</td>\n",
       "      <td>287.835884</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>291.630992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>289.066894</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.355508</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>285.816090</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>292.681865</td>\n",
       "      <td>290.851589</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.907838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298.072424</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>299.903104</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>296.615372</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>290.943971</td>\n",
       "      <td>295.944768</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>293.500607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>65.746933</td>\n",
       "      <td>65.853934</td>\n",
       "      <td>70.574162</td>\n",
       "      <td>62.239247</td>\n",
       "      <td>55.130102</td>\n",
       "      <td>62.239247</td>\n",
       "      <td>57.888206</td>\n",
       "      <td>63.679955</td>\n",
       "      <td>62.239243</td>\n",
       "      <td>62.239247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>61.329502</td>\n",
       "      <td>63.260741</td>\n",
       "      <td>60.017189</td>\n",
       "      <td>63.453517</td>\n",
       "      <td>66.141381</td>\n",
       "      <td>63.453517</td>\n",
       "      <td>65.584679</td>\n",
       "      <td>64.101433</td>\n",
       "      <td>63.453519</td>\n",
       "      <td>63.453517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>66.822772</td>\n",
       "      <td>69.549069</td>\n",
       "      <td>66.237491</td>\n",
       "      <td>69.280813</td>\n",
       "      <td>70.547457</td>\n",
       "      <td>69.280813</td>\n",
       "      <td>70.842404</td>\n",
       "      <td>73.111604</td>\n",
       "      <td>69.280814</td>\n",
       "      <td>69.280813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>62.577572</td>\n",
       "      <td>67.210049</td>\n",
       "      <td>65.172995</td>\n",
       "      <td>67.044144</td>\n",
       "      <td>70.357863</td>\n",
       "      <td>67.044144</td>\n",
       "      <td>68.535449</td>\n",
       "      <td>70.440907</td>\n",
       "      <td>67.044145</td>\n",
       "      <td>67.044144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>59.277409</td>\n",
       "      <td>59.472203</td>\n",
       "      <td>62.933669</td>\n",
       "      <td>60.318389</td>\n",
       "      <td>57.697020</td>\n",
       "      <td>60.318389</td>\n",
       "      <td>59.467526</td>\n",
       "      <td>57.168997</td>\n",
       "      <td>60.318390</td>\n",
       "      <td>60.318390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "0   251.794016  254.356464  247.741536  254.356465  261.523870  254.356465   \n",
       "1   251.056784  251.010919  248.192143  251.010920  250.249903  251.010920   \n",
       "2   297.528249  291.630992  294.250464  291.630992  283.569719  291.630992   \n",
       "3   289.066894  288.907838  288.355508  288.907838  285.816090  288.907838   \n",
       "4   298.072424  293.500607  299.903104  293.500607  296.615372  293.500607   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "85   65.746933   65.853934   70.574162   62.239247   55.130102   62.239247   \n",
       "86   61.329502   63.260741   60.017189   63.453517   66.141381   63.453517   \n",
       "87   66.822772   69.549069   66.237491   69.280813   70.547457   69.280813   \n",
       "88   62.577572   67.210049   65.172995   67.044144   70.357863   67.044144   \n",
       "89   59.277409   59.472203   62.933669   60.318389   57.697020   60.318389   \n",
       "\n",
       "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "0   254.087872  252.716034  254.356465  254.356465  \n",
       "1   252.054546  246.842220  251.010920  251.010920  \n",
       "2   285.767294  287.835884  291.630992  291.630992  \n",
       "3   292.681865  290.851589  288.907838  288.907838  \n",
       "4   290.943971  295.944768  293.500607  293.500607  \n",
       "..         ...         ...         ...         ...  \n",
       "85   57.888206   63.679955   62.239243   62.239247  \n",
       "86   65.584679   64.101433   63.453519   63.453517  \n",
       "87   70.842404   73.111604   69.280814   69.280813  \n",
       "88   68.535449   70.440907   67.044145   67.044144  \n",
       "89   59.467526   57.168997   60.318390   60.318390  \n",
       "\n",
       "[90 rows x 10 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bVUx-51j2NEz",
    "outputId": "977a455f-19f4-4bb0-9415-4ebf9a65f5b1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x800 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 創建 2x5 的子圖網格\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "fig.suptitle(\"Normal Distributions of Demand Columns\")\n",
    "\n",
    "for idx, column in enumerate(demand_df.columns):\n",
    "    data = demand_df[column].dropna()  # 移除缺失值\n",
    "    mean, std_dev = np.mean(data), np.std(data)\n",
    "\n",
    "    # 產生 x 值範圍\n",
    "    x = np.linspace(mean - 3 * std_dev, mean + 3 * std_dev, 100)\n",
    "    pdf = norm.pdf(x, mean, std_dev)\n",
    "\n",
    "    # 確定當前的軸位置\n",
    "    ax = axes[idx // 5, idx % 5]\n",
    "    ax.hist(data, bins=15, density=True, alpha=0.6, color=\"skyblue\")\n",
    "    ax.plot(\n",
    "        x,\n",
    "        pdf,\n",
    "        \"r-\",\n",
    "        label=f\"Normal Distribution\\nMean={mean:.2f}, StdDev={std_dev:.2f}\",\n",
    "    )\n",
    "    ax.set_xlabel(column)\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.legend()\n",
    "\n",
    "# 移除空白子圖（若有）\n",
    "for idx in range(len(demand_df.columns), 10):\n",
    "    fig.delaxes(axes[idx // 5, idx % 5])\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79eqz9n_cweM"
   },
   "source": [
    "### Validate the covariance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LRxNQvrdcnxf",
    "outputId": "787e0b16-4a37-4522-d09f-0ea4383dfb1e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>demand_t1</th>\n",
       "      <td>11500.121499</td>\n",
       "      <td>11437.913773</td>\n",
       "      <td>11491.817461</td>\n",
       "      <td>11449.279979</td>\n",
       "      <td>11421.185949</td>\n",
       "      <td>11449.279979</td>\n",
       "      <td>11433.606145</td>\n",
       "      <td>11464.092453</td>\n",
       "      <td>11449.279975</td>\n",
       "      <td>11449.279978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t2</th>\n",
       "      <td>11437.913773</td>\n",
       "      <td>11384.045435</td>\n",
       "      <td>11434.337551</td>\n",
       "      <td>11395.461660</td>\n",
       "      <td>11371.288335</td>\n",
       "      <td>11395.461660</td>\n",
       "      <td>11380.612522</td>\n",
       "      <td>11413.068444</td>\n",
       "      <td>11395.461657</td>\n",
       "      <td>11395.461660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t3</th>\n",
       "      <td>11491.817461</td>\n",
       "      <td>11434.337551</td>\n",
       "      <td>11492.345369</td>\n",
       "      <td>11445.297344</td>\n",
       "      <td>11417.879197</td>\n",
       "      <td>11445.297344</td>\n",
       "      <td>11425.363324</td>\n",
       "      <td>11462.865280</td>\n",
       "      <td>11445.297340</td>\n",
       "      <td>11445.297344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t4</th>\n",
       "      <td>11449.279979</td>\n",
       "      <td>11395.461660</td>\n",
       "      <td>11445.297344</td>\n",
       "      <td>11407.517926</td>\n",
       "      <td>11383.949213</td>\n",
       "      <td>11407.517926</td>\n",
       "      <td>11393.252462</td>\n",
       "      <td>11424.882556</td>\n",
       "      <td>11407.517923</td>\n",
       "      <td>11407.517925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t5</th>\n",
       "      <td>11421.185949</td>\n",
       "      <td>11371.288335</td>\n",
       "      <td>11417.879197</td>\n",
       "      <td>11383.949213</td>\n",
       "      <td>11369.605301</td>\n",
       "      <td>11383.949213</td>\n",
       "      <td>11371.762863</td>\n",
       "      <td>11404.029308</td>\n",
       "      <td>11383.949211</td>\n",
       "      <td>11383.949213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t6</th>\n",
       "      <td>11449.279979</td>\n",
       "      <td>11395.461660</td>\n",
       "      <td>11445.297344</td>\n",
       "      <td>11407.517926</td>\n",
       "      <td>11383.949213</td>\n",
       "      <td>11407.517925</td>\n",
       "      <td>11393.252462</td>\n",
       "      <td>11424.882556</td>\n",
       "      <td>11407.517923</td>\n",
       "      <td>11407.517925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t7</th>\n",
       "      <td>11433.606145</td>\n",
       "      <td>11380.612522</td>\n",
       "      <td>11425.363324</td>\n",
       "      <td>11393.252462</td>\n",
       "      <td>11371.762863</td>\n",
       "      <td>11393.252462</td>\n",
       "      <td>11388.486336</td>\n",
       "      <td>11411.147017</td>\n",
       "      <td>11393.252460</td>\n",
       "      <td>11393.252462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t8</th>\n",
       "      <td>11464.092453</td>\n",
       "      <td>11413.068444</td>\n",
       "      <td>11462.865280</td>\n",
       "      <td>11424.882556</td>\n",
       "      <td>11404.029308</td>\n",
       "      <td>11424.882556</td>\n",
       "      <td>11411.147017</td>\n",
       "      <td>11449.352112</td>\n",
       "      <td>11424.882554</td>\n",
       "      <td>11424.882556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t9</th>\n",
       "      <td>11449.279975</td>\n",
       "      <td>11395.461657</td>\n",
       "      <td>11445.297340</td>\n",
       "      <td>11407.517923</td>\n",
       "      <td>11383.949211</td>\n",
       "      <td>11407.517923</td>\n",
       "      <td>11393.252460</td>\n",
       "      <td>11424.882554</td>\n",
       "      <td>11407.517920</td>\n",
       "      <td>11407.517922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t10</th>\n",
       "      <td>11449.279978</td>\n",
       "      <td>11395.461660</td>\n",
       "      <td>11445.297344</td>\n",
       "      <td>11407.517925</td>\n",
       "      <td>11383.949213</td>\n",
       "      <td>11407.517925</td>\n",
       "      <td>11393.252462</td>\n",
       "      <td>11424.882556</td>\n",
       "      <td>11407.517922</td>\n",
       "      <td>11407.517925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               demand_t1     demand_t2     demand_t3     demand_t4  \\\n",
       "demand_t1   11500.121499  11437.913773  11491.817461  11449.279979   \n",
       "demand_t2   11437.913773  11384.045435  11434.337551  11395.461660   \n",
       "demand_t3   11491.817461  11434.337551  11492.345369  11445.297344   \n",
       "demand_t4   11449.279979  11395.461660  11445.297344  11407.517926   \n",
       "demand_t5   11421.185949  11371.288335  11417.879197  11383.949213   \n",
       "demand_t6   11449.279979  11395.461660  11445.297344  11407.517926   \n",
       "demand_t7   11433.606145  11380.612522  11425.363324  11393.252462   \n",
       "demand_t8   11464.092453  11413.068444  11462.865280  11424.882556   \n",
       "demand_t9   11449.279975  11395.461657  11445.297340  11407.517923   \n",
       "demand_t10  11449.279978  11395.461660  11445.297344  11407.517925   \n",
       "\n",
       "               demand_t5     demand_t6     demand_t7     demand_t8  \\\n",
       "demand_t1   11421.185949  11449.279979  11433.606145  11464.092453   \n",
       "demand_t2   11371.288335  11395.461660  11380.612522  11413.068444   \n",
       "demand_t3   11417.879197  11445.297344  11425.363324  11462.865280   \n",
       "demand_t4   11383.949213  11407.517926  11393.252462  11424.882556   \n",
       "demand_t5   11369.605301  11383.949213  11371.762863  11404.029308   \n",
       "demand_t6   11383.949213  11407.517925  11393.252462  11424.882556   \n",
       "demand_t7   11371.762863  11393.252462  11388.486336  11411.147017   \n",
       "demand_t8   11404.029308  11424.882556  11411.147017  11449.352112   \n",
       "demand_t9   11383.949211  11407.517923  11393.252460  11424.882554   \n",
       "demand_t10  11383.949213  11407.517925  11393.252462  11424.882556   \n",
       "\n",
       "               demand_t9    demand_t10  \n",
       "demand_t1   11449.279975  11449.279978  \n",
       "demand_t2   11395.461657  11395.461660  \n",
       "demand_t3   11445.297340  11445.297344  \n",
       "demand_t4   11407.517923  11407.517925  \n",
       "demand_t5   11383.949211  11383.949213  \n",
       "demand_t6   11407.517923  11407.517925  \n",
       "demand_t7   11393.252460  11393.252462  \n",
       "demand_t8   11424.882554  11424.882556  \n",
       "demand_t9   11407.517920  11407.517922  \n",
       "demand_t10  11407.517922  11407.517925  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sfelD3W3dxO8",
    "outputId": "8bbaf932-fa69-4d5d-9a3d-91f3dd739124"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>demand_t1</th>\n",
       "      <td>11491.121499</td>\n",
       "      <td>11437.374121</td>\n",
       "      <td>11486.815409</td>\n",
       "      <td>11449.279979</td>\n",
       "      <td>11424.675912</td>\n",
       "      <td>11449.279979</td>\n",
       "      <td>11434.497800</td>\n",
       "      <td>11466.575946</td>\n",
       "      <td>11449.279977</td>\n",
       "      <td>11449.279978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t2</th>\n",
       "      <td>11437.374121</td>\n",
       "      <td>11383.492713</td>\n",
       "      <td>11433.353939</td>\n",
       "      <td>11395.461660</td>\n",
       "      <td>11372.101770</td>\n",
       "      <td>11395.461660</td>\n",
       "      <td>11381.171000</td>\n",
       "      <td>11412.958409</td>\n",
       "      <td>11395.461657</td>\n",
       "      <td>11395.461660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t3</th>\n",
       "      <td>11486.815409</td>\n",
       "      <td>11433.353939</td>\n",
       "      <td>11483.345369</td>\n",
       "      <td>11445.297344</td>\n",
       "      <td>11421.735622</td>\n",
       "      <td>11445.297344</td>\n",
       "      <td>11430.327213</td>\n",
       "      <td>11462.770217</td>\n",
       "      <td>11445.297342</td>\n",
       "      <td>11445.297344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t4</th>\n",
       "      <td>11449.279979</td>\n",
       "      <td>11395.461660</td>\n",
       "      <td>11445.297344</td>\n",
       "      <td>11407.517926</td>\n",
       "      <td>11383.949213</td>\n",
       "      <td>11407.517926</td>\n",
       "      <td>11393.252462</td>\n",
       "      <td>11424.882556</td>\n",
       "      <td>11407.517923</td>\n",
       "      <td>11407.517925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t5</th>\n",
       "      <td>11424.675912</td>\n",
       "      <td>11372.101770</td>\n",
       "      <td>11421.735622</td>\n",
       "      <td>11383.949213</td>\n",
       "      <td>11360.605301</td>\n",
       "      <td>11383.949213</td>\n",
       "      <td>11369.060070</td>\n",
       "      <td>11401.383131</td>\n",
       "      <td>11383.949211</td>\n",
       "      <td>11383.949213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t6</th>\n",
       "      <td>11449.279979</td>\n",
       "      <td>11395.461660</td>\n",
       "      <td>11445.297344</td>\n",
       "      <td>11407.517926</td>\n",
       "      <td>11383.949213</td>\n",
       "      <td>11407.517925</td>\n",
       "      <td>11393.252462</td>\n",
       "      <td>11424.882556</td>\n",
       "      <td>11407.517923</td>\n",
       "      <td>11407.517925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t7</th>\n",
       "      <td>11434.497800</td>\n",
       "      <td>11381.171000</td>\n",
       "      <td>11430.327213</td>\n",
       "      <td>11393.252462</td>\n",
       "      <td>11369.060070</td>\n",
       "      <td>11393.252462</td>\n",
       "      <td>11379.486336</td>\n",
       "      <td>11410.796545</td>\n",
       "      <td>11393.252460</td>\n",
       "      <td>11393.252462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t8</th>\n",
       "      <td>11466.575946</td>\n",
       "      <td>11412.958409</td>\n",
       "      <td>11462.770217</td>\n",
       "      <td>11424.882556</td>\n",
       "      <td>11401.383131</td>\n",
       "      <td>11424.882556</td>\n",
       "      <td>11410.796545</td>\n",
       "      <td>11440.352112</td>\n",
       "      <td>11424.882555</td>\n",
       "      <td>11424.882556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t9</th>\n",
       "      <td>11449.279977</td>\n",
       "      <td>11395.461657</td>\n",
       "      <td>11445.297342</td>\n",
       "      <td>11407.517923</td>\n",
       "      <td>11383.949211</td>\n",
       "      <td>11407.517923</td>\n",
       "      <td>11393.252460</td>\n",
       "      <td>11424.882555</td>\n",
       "      <td>11407.517920</td>\n",
       "      <td>11407.517922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t10</th>\n",
       "      <td>11449.279978</td>\n",
       "      <td>11395.461660</td>\n",
       "      <td>11445.297344</td>\n",
       "      <td>11407.517925</td>\n",
       "      <td>11383.949213</td>\n",
       "      <td>11407.517925</td>\n",
       "      <td>11393.252462</td>\n",
       "      <td>11424.882556</td>\n",
       "      <td>11407.517922</td>\n",
       "      <td>11407.517925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               demand_t1     demand_t2     demand_t3     demand_t4  \\\n",
       "demand_t1   11491.121499  11437.374121  11486.815409  11449.279979   \n",
       "demand_t2   11437.374121  11383.492713  11433.353939  11395.461660   \n",
       "demand_t3   11486.815409  11433.353939  11483.345369  11445.297344   \n",
       "demand_t4   11449.279979  11395.461660  11445.297344  11407.517926   \n",
       "demand_t5   11424.675912  11372.101770  11421.735622  11383.949213   \n",
       "demand_t6   11449.279979  11395.461660  11445.297344  11407.517926   \n",
       "demand_t7   11434.497800  11381.171000  11430.327213  11393.252462   \n",
       "demand_t8   11466.575946  11412.958409  11462.770217  11424.882556   \n",
       "demand_t9   11449.279977  11395.461657  11445.297342  11407.517923   \n",
       "demand_t10  11449.279978  11395.461660  11445.297344  11407.517925   \n",
       "\n",
       "               demand_t5     demand_t6     demand_t7     demand_t8  \\\n",
       "demand_t1   11424.675912  11449.279979  11434.497800  11466.575946   \n",
       "demand_t2   11372.101770  11395.461660  11381.171000  11412.958409   \n",
       "demand_t3   11421.735622  11445.297344  11430.327213  11462.770217   \n",
       "demand_t4   11383.949213  11407.517926  11393.252462  11424.882556   \n",
       "demand_t5   11360.605301  11383.949213  11369.060070  11401.383131   \n",
       "demand_t6   11383.949213  11407.517925  11393.252462  11424.882556   \n",
       "demand_t7   11369.060070  11393.252462  11379.486336  11410.796545   \n",
       "demand_t8   11401.383131  11424.882556  11410.796545  11440.352112   \n",
       "demand_t9   11383.949211  11407.517923  11393.252460  11424.882555   \n",
       "demand_t10  11383.949213  11407.517925  11393.252462  11424.882556   \n",
       "\n",
       "               demand_t9    demand_t10  \n",
       "demand_t1   11449.279977  11449.279978  \n",
       "demand_t2   11395.461657  11395.461660  \n",
       "demand_t3   11445.297342  11445.297344  \n",
       "demand_t4   11407.517923  11407.517925  \n",
       "demand_t5   11383.949211  11383.949213  \n",
       "demand_t6   11407.517923  11407.517925  \n",
       "demand_t7   11393.252460  11393.252462  \n",
       "demand_t8   11424.882555  11424.882556  \n",
       "demand_t9   11407.517920  11407.517922  \n",
       "demand_t10  11407.517922  11407.517925  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empirical_covariance = demand_df.cov()\n",
    "covariance_diff = np.abs(empirical_covariance - np.array(cov_matrices).mean(axis=0))\n",
    "covariance_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zoLCr9riPt8d"
   },
   "source": [
    "### Validate the corr matrix of damand_df is close to original setting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>251.794016</td>\n",
       "      <td>254.356464</td>\n",
       "      <td>247.741536</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>261.523870</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.087872</td>\n",
       "      <td>252.716034</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.356465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251.056784</td>\n",
       "      <td>251.010919</td>\n",
       "      <td>248.192143</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>250.249903</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>252.054546</td>\n",
       "      <td>246.842220</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>251.010920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>297.528249</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>294.250464</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>283.569719</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>285.767294</td>\n",
       "      <td>287.835884</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>291.630992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>289.066894</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.355508</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>285.816090</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>292.681865</td>\n",
       "      <td>290.851589</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.907838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298.072424</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>299.903104</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>296.615372</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>290.943971</td>\n",
       "      <td>295.944768</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>293.500607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>65.746933</td>\n",
       "      <td>65.853934</td>\n",
       "      <td>70.574162</td>\n",
       "      <td>62.239247</td>\n",
       "      <td>55.130102</td>\n",
       "      <td>62.239247</td>\n",
       "      <td>57.888206</td>\n",
       "      <td>63.679955</td>\n",
       "      <td>62.239243</td>\n",
       "      <td>62.239247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>61.329502</td>\n",
       "      <td>63.260741</td>\n",
       "      <td>60.017189</td>\n",
       "      <td>63.453517</td>\n",
       "      <td>66.141381</td>\n",
       "      <td>63.453517</td>\n",
       "      <td>65.584679</td>\n",
       "      <td>64.101433</td>\n",
       "      <td>63.453519</td>\n",
       "      <td>63.453517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>66.822772</td>\n",
       "      <td>69.549069</td>\n",
       "      <td>66.237491</td>\n",
       "      <td>69.280813</td>\n",
       "      <td>70.547457</td>\n",
       "      <td>69.280813</td>\n",
       "      <td>70.842404</td>\n",
       "      <td>73.111604</td>\n",
       "      <td>69.280814</td>\n",
       "      <td>69.280813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>62.577572</td>\n",
       "      <td>67.210049</td>\n",
       "      <td>65.172995</td>\n",
       "      <td>67.044144</td>\n",
       "      <td>70.357863</td>\n",
       "      <td>67.044144</td>\n",
       "      <td>68.535449</td>\n",
       "      <td>70.440907</td>\n",
       "      <td>67.044145</td>\n",
       "      <td>67.044144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>59.277409</td>\n",
       "      <td>59.472203</td>\n",
       "      <td>62.933669</td>\n",
       "      <td>60.318389</td>\n",
       "      <td>57.697020</td>\n",
       "      <td>60.318389</td>\n",
       "      <td>59.467526</td>\n",
       "      <td>57.168997</td>\n",
       "      <td>60.318390</td>\n",
       "      <td>60.318390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "0   251.794016  254.356464  247.741536  254.356465  261.523870  254.356465   \n",
       "1   251.056784  251.010919  248.192143  251.010920  250.249903  251.010920   \n",
       "2   297.528249  291.630992  294.250464  291.630992  283.569719  291.630992   \n",
       "3   289.066894  288.907838  288.355508  288.907838  285.816090  288.907838   \n",
       "4   298.072424  293.500607  299.903104  293.500607  296.615372  293.500607   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "85   65.746933   65.853934   70.574162   62.239247   55.130102   62.239247   \n",
       "86   61.329502   63.260741   60.017189   63.453517   66.141381   63.453517   \n",
       "87   66.822772   69.549069   66.237491   69.280813   70.547457   69.280813   \n",
       "88   62.577572   67.210049   65.172995   67.044144   70.357863   67.044144   \n",
       "89   59.277409   59.472203   62.933669   60.318389   57.697020   60.318389   \n",
       "\n",
       "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "0   254.087872  252.716034  254.356465  254.356465  \n",
       "1   252.054546  246.842220  251.010920  251.010920  \n",
       "2   285.767294  287.835884  291.630992  291.630992  \n",
       "3   292.681865  290.851589  288.907838  288.907838  \n",
       "4   290.943971  295.944768  293.500607  293.500607  \n",
       "..         ...         ...         ...         ...  \n",
       "85   57.888206   63.679955   62.239243   62.239247  \n",
       "86   65.584679   64.101433   63.453519   63.453517  \n",
       "87   70.842404   73.111604   69.280814   69.280813  \n",
       "88   68.535449   70.440907   67.044145   67.044144  \n",
       "89   59.467526   57.168997   60.318390   60.318390  \n",
       "\n",
       "[90 rows x 10 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YLqFAdfQPz6O",
    "outputId": "aaa6eb63-394c-40f8-8d58-665e9fb63026"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Matrix from demand_df:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>demand_t1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999648</td>\n",
       "      <td>0.999616</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.998820</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.999077</td>\n",
       "      <td>0.999075</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.999612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t2</th>\n",
       "      <td>0.999648</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999674</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999514</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999504</td>\n",
       "      <td>0.999686</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t3</th>\n",
       "      <td>0.999616</td>\n",
       "      <td>0.999674</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999602</td>\n",
       "      <td>0.998869</td>\n",
       "      <td>0.999602</td>\n",
       "      <td>0.998695</td>\n",
       "      <td>0.999306</td>\n",
       "      <td>0.999602</td>\n",
       "      <td>0.999602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t4</th>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999602</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999584</td>\n",
       "      <td>0.999691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t5</th>\n",
       "      <td>0.998820</td>\n",
       "      <td>0.999514</td>\n",
       "      <td>0.998869</td>\n",
       "      <td>0.999596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999596</td>\n",
       "      <td>0.999360</td>\n",
       "      <td>0.999528</td>\n",
       "      <td>0.999596</td>\n",
       "      <td>0.999596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t6</th>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999602</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999584</td>\n",
       "      <td>0.999691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t7</th>\n",
       "      <td>0.999077</td>\n",
       "      <td>0.999504</td>\n",
       "      <td>0.998695</td>\n",
       "      <td>0.999584</td>\n",
       "      <td>0.999360</td>\n",
       "      <td>0.999584</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999323</td>\n",
       "      <td>0.999584</td>\n",
       "      <td>0.999584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t8</th>\n",
       "      <td>0.999075</td>\n",
       "      <td>0.999686</td>\n",
       "      <td>0.999306</td>\n",
       "      <td>0.999691</td>\n",
       "      <td>0.999528</td>\n",
       "      <td>0.999691</td>\n",
       "      <td>0.999323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999691</td>\n",
       "      <td>0.999691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t9</th>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999602</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999584</td>\n",
       "      <td>0.999691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demand_t10</th>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999602</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999584</td>\n",
       "      <td>0.999691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            demand_t1  demand_t2  demand_t3  demand_t4  demand_t5  demand_t6  \\\n",
       "demand_t1    1.000000   0.999648   0.999616   0.999612   0.998820   0.999612   \n",
       "demand_t2    0.999648   1.000000   0.999674   0.999972   0.999514   0.999972   \n",
       "demand_t3    0.999616   0.999674   1.000000   0.999602   0.998869   0.999602   \n",
       "demand_t4    0.999612   0.999972   0.999602   1.000000   0.999596   1.000000   \n",
       "demand_t5    0.998820   0.999514   0.998869   0.999596   1.000000   0.999596   \n",
       "demand_t6    0.999612   0.999972   0.999602   1.000000   0.999596   1.000000   \n",
       "demand_t7    0.999077   0.999504   0.998695   0.999584   0.999360   0.999584   \n",
       "demand_t8    0.999075   0.999686   0.999306   0.999691   0.999528   0.999691   \n",
       "demand_t9    0.999612   0.999972   0.999602   1.000000   0.999596   1.000000   \n",
       "demand_t10   0.999612   0.999972   0.999602   1.000000   0.999596   1.000000   \n",
       "\n",
       "            demand_t7  demand_t8  demand_t9  demand_t10  \n",
       "demand_t1    0.999077   0.999075   0.999612    0.999612  \n",
       "demand_t2    0.999504   0.999686   0.999972    0.999972  \n",
       "demand_t3    0.998695   0.999306   0.999602    0.999602  \n",
       "demand_t4    0.999584   0.999691   1.000000    1.000000  \n",
       "demand_t5    0.999360   0.999528   0.999596    0.999596  \n",
       "demand_t6    0.999584   0.999691   1.000000    1.000000  \n",
       "demand_t7    1.000000   0.999323   0.999584    0.999584  \n",
       "demand_t8    0.999323   1.000000   0.999691    0.999691  \n",
       "demand_t9    0.999584   0.999691   1.000000    1.000000  \n",
       "demand_t10   0.999584   0.999691   1.000000    1.000000  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_matrix = demand_df.corr()\n",
    "print(\"Correlation Matrix from demand_df:\")\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bsBxErYBQDXT",
    "outputId": "0b94e967-9e3d-4114-f049-cada8da8e427"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original corr_matrix shape: (10, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.354243</td>\n",
       "      <td>0.555784</td>\n",
       "      <td>0.587411</td>\n",
       "      <td>-0.387774</td>\n",
       "      <td>-0.161484</td>\n",
       "      <td>-0.099073</td>\n",
       "      <td>-0.275944</td>\n",
       "      <td>-0.488891</td>\n",
       "      <td>-0.020925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.354243</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.645671</td>\n",
       "      <td>0.344249</td>\n",
       "      <td>-0.533962</td>\n",
       "      <td>-0.118714</td>\n",
       "      <td>-0.366601</td>\n",
       "      <td>0.072230</td>\n",
       "      <td>0.109958</td>\n",
       "      <td>-0.049126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.555784</td>\n",
       "      <td>0.645671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.259728</td>\n",
       "      <td>-0.428492</td>\n",
       "      <td>-0.236520</td>\n",
       "      <td>-0.551543</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>-0.414246</td>\n",
       "      <td>-0.128709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.587411</td>\n",
       "      <td>0.344249</td>\n",
       "      <td>0.259728</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.433716</td>\n",
       "      <td>-0.078962</td>\n",
       "      <td>0.166233</td>\n",
       "      <td>-0.631022</td>\n",
       "      <td>0.089139</td>\n",
       "      <td>0.244177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.387774</td>\n",
       "      <td>-0.533962</td>\n",
       "      <td>-0.428492</td>\n",
       "      <td>-0.433716</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.371399</td>\n",
       "      <td>0.300310</td>\n",
       "      <td>0.294020</td>\n",
       "      <td>-0.153719</td>\n",
       "      <td>-0.108549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.161484</td>\n",
       "      <td>-0.118714</td>\n",
       "      <td>-0.236520</td>\n",
       "      <td>-0.078962</td>\n",
       "      <td>0.371399</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.658292</td>\n",
       "      <td>0.520508</td>\n",
       "      <td>-0.341738</td>\n",
       "      <td>0.147419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.099073</td>\n",
       "      <td>-0.366601</td>\n",
       "      <td>-0.551543</td>\n",
       "      <td>0.166233</td>\n",
       "      <td>0.300310</td>\n",
       "      <td>0.658292</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.038941</td>\n",
       "      <td>-0.009772</td>\n",
       "      <td>0.485870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.275944</td>\n",
       "      <td>0.072230</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>-0.631022</td>\n",
       "      <td>0.294020</td>\n",
       "      <td>0.520508</td>\n",
       "      <td>0.038941</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.203659</td>\n",
       "      <td>0.130487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.488891</td>\n",
       "      <td>0.109958</td>\n",
       "      <td>-0.414246</td>\n",
       "      <td>0.089139</td>\n",
       "      <td>-0.153719</td>\n",
       "      <td>-0.341738</td>\n",
       "      <td>-0.009772</td>\n",
       "      <td>-0.203659</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.355112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.020925</td>\n",
       "      <td>-0.049126</td>\n",
       "      <td>-0.128709</td>\n",
       "      <td>0.244177</td>\n",
       "      <td>-0.108549</td>\n",
       "      <td>0.147419</td>\n",
       "      <td>0.485870</td>\n",
       "      <td>0.130487</td>\n",
       "      <td>0.355112</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.000000  0.354243  0.555784  0.587411 -0.387774 -0.161484 -0.099073   \n",
       "1  0.354243  1.000000  0.645671  0.344249 -0.533962 -0.118714 -0.366601   \n",
       "2  0.555784  0.645671  1.000000  0.259728 -0.428492 -0.236520 -0.551543   \n",
       "3  0.587411  0.344249  0.259728  1.000000 -0.433716 -0.078962  0.166233   \n",
       "4 -0.387774 -0.533962 -0.428492 -0.433716  1.000000  0.371399  0.300310   \n",
       "5 -0.161484 -0.118714 -0.236520 -0.078962  0.371399  1.000000  0.658292   \n",
       "6 -0.099073 -0.366601 -0.551543  0.166233  0.300310  0.658292  1.000000   \n",
       "7 -0.275944  0.072230  0.010563 -0.631022  0.294020  0.520508  0.038941   \n",
       "8 -0.488891  0.109958 -0.414246  0.089139 -0.153719 -0.341738 -0.009772   \n",
       "9 -0.020925 -0.049126 -0.128709  0.244177 -0.108549  0.147419  0.485870   \n",
       "\n",
       "          7         8         9  \n",
       "0 -0.275944 -0.488891 -0.020925  \n",
       "1  0.072230  0.109958 -0.049126  \n",
       "2  0.010563 -0.414246 -0.128709  \n",
       "3 -0.631022  0.089139  0.244177  \n",
       "4  0.294020 -0.153719 -0.108549  \n",
       "5  0.520508 -0.341738  0.147419  \n",
       "6  0.038941 -0.009772  0.485870  \n",
       "7  1.000000 -0.203659  0.130487  \n",
       "8 -0.203659  1.000000  0.355112  \n",
       "9  0.130487  0.355112  1.000000  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Original corr_matrix shape: {corr_matrix.shape}\")\n",
    "corr_matrix_df = pd.DataFrame(corr_matrix)\n",
    "corr_matrix_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hne073eTB2gq"
   },
   "source": [
    "### Split test and train demand_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Train Data:\n",
      "(15, 10)\n",
      "Test Data:\n",
      "(15, 10)\n",
      "========================================\n",
      "Fold 2:\n",
      "Train Data:\n",
      "(15, 10)\n",
      "Test Data:\n",
      "(15, 10)\n",
      "========================================\n",
      "Fold 3:\n",
      "Train Data:\n",
      "(15, 10)\n",
      "Test Data:\n",
      "(15, 10)\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "def demand_data_split_data_k_fold(data):\n",
    "    folds = []\n",
    "    chunk_size = CHUNK_SIZE  # 每組 60 筆資料\n",
    "    train_chunk = int(train_size * chunk_size)\n",
    "\n",
    "    n = len(data)\n",
    "    # 依序切分每一個 chunk\n",
    "    for start in range(0, n, chunk_size):\n",
    "        # 若剩餘資料不足 60 筆，這裡直接跳過\n",
    "        if start + chunk_size > n:\n",
    "            break\n",
    "        chunk = data.iloc[start : start + chunk_size].reset_index(drop=True)\n",
    "        train_data = chunk.iloc[:train_chunk].reset_index(drop=True)\n",
    "        test_data = chunk.iloc[train_chunk:].reset_index(drop=True)\n",
    "        folds.append((train_data, test_data))\n",
    "\n",
    "    return folds\n",
    "\n",
    "\n",
    "# 使用函數切分資料\n",
    "demand_folds = demand_data_split_data_k_fold(demand_df)\n",
    "\n",
    "# 印出結果，每個 fold 的訓練與測試資料\n",
    "for i, (train_data, test_data) in enumerate(demand_folds, 1):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(\"Train Data:\")\n",
    "    print(train_data.shape)\n",
    "    print(\"Test Data:\")\n",
    "    print(test_data.shape)\n",
    "    print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJ2ej5ZlAg1e"
   },
   "source": [
    "### Define the Q star(Q optimal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "JZM_eOn8ldpT"
   },
   "outputs": [],
   "source": [
    "def calculate_Q_star(demand_df, service_level=0.95):\n",
    "\n",
    "    # 計算每一行的總和\n",
    "    demand_sum = demand_df.sum(axis=1)\n",
    "\n",
    "    # 計算總和的均值和標準差\n",
    "    mean_sum = demand_sum.mean()\n",
    "    std_sum = demand_sum.std()\n",
    "\n",
    "    # 計算總和的95%百分位數值\n",
    "    Q_star = norm.ppf(service_level, loc=mean_sum, scale=std_sum)\n",
    "\n",
    "    # 打印結果\n",
    "    print(f\"mean of sum: {mean_sum}\")\n",
    "    print(f\"std of sum: {std_sum}\")\n",
    "    print(f\"{service_level*100} percentile of sum: {Q_star}\")\n",
    "\n",
    "    return Q_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "  0   251.794016  254.356464  247.741536  254.356465  261.523870  254.356465   \n",
       "  1   251.056784  251.010919  248.192143  251.010920  250.249903  251.010920   \n",
       "  2   297.528249  291.630992  294.250464  291.630992  283.569719  291.630992   \n",
       "  3   289.066894  288.907838  288.355508  288.907838  285.816090  288.907838   \n",
       "  4   298.072424  293.500607  299.903104  293.500607  296.615372  293.500607   \n",
       "  5   301.401948  298.930917  300.714683  298.930917  294.785980  298.930917   \n",
       "  6   291.672619  289.957928  291.788015  289.957928  285.872455  289.957928   \n",
       "  7   269.341662  273.073968  269.572013  273.073968  271.669642  273.073968   \n",
       "  8   291.803572  289.026459  288.668454  289.026459  282.672846  289.026459   \n",
       "  9   258.259455  255.913721  255.439341  255.913721  255.976937  255.913721   \n",
       "  10  278.551022  281.996051  281.029925  281.996051  289.535263  281.996051   \n",
       "  11  256.151738  257.167663  252.945792  257.167664  264.788247  257.167664   \n",
       "  12  295.186828  297.233446  298.436136  297.233446  301.105487  297.233446   \n",
       "  13  278.898077  276.092416  278.517826  276.092416  274.536813  276.092416   \n",
       "  14  276.126061  270.733097  271.699824  270.733097  268.070512  270.733097   \n",
       "  \n",
       "       demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "  0   254.087872  252.716034  254.356465  254.356465  \n",
       "  1   252.054546  246.842220  251.010920  251.010920  \n",
       "  2   285.767294  287.835884  291.630992  291.630992  \n",
       "  3   292.681865  290.851589  288.907838  288.907838  \n",
       "  4   290.943971  295.944768  293.500607  293.500607  \n",
       "  5   299.484772  298.727945  298.930917  298.930917  \n",
       "  6   290.444897  292.664979  289.957928  289.957928  \n",
       "  7   273.459253  273.376911  273.073968  273.073968  \n",
       "  8   287.717318  286.983188  289.026459  289.026459  \n",
       "  9   255.911150  251.612160  255.913721  255.913721  \n",
       "  10  285.332026  287.403702  281.996051  281.996051  \n",
       "  11  262.220107  256.201799  257.167664  257.167664  \n",
       "  12  295.272601  298.475322  297.233446  297.233446  \n",
       "  13  276.925605  274.583612  276.092416  276.092416  \n",
       "  14  266.551512  268.201901  270.733097  270.733097  ,\n",
       "      demand_t1  demand_t2  demand_t3  demand_t4  demand_t5  demand_t6  \\\n",
       "  0   69.049446  66.984864  65.276090  66.706379  64.399509  66.706379   \n",
       "  1   62.472855  61.379065  62.263812  62.103826  59.547465  62.103826   \n",
       "  2   57.026718  60.339037  58.994137  61.289263  61.559450  61.289263   \n",
       "  3   62.944633  65.536993  64.153686  63.154284  59.520451  63.154284   \n",
       "  4   66.458142  64.430325  65.691033  63.637108  58.415305  63.637108   \n",
       "  5   65.340264  66.665934  65.624076  65.701968  65.763430  65.701968   \n",
       "  6   60.459442  64.184997  61.973620  64.386015  65.111260  64.386015   \n",
       "  7   71.557122  70.563024  74.662817  69.883738  69.277905  69.883738   \n",
       "  8   63.840751  62.306341  66.968545  61.020448  59.275984  61.020448   \n",
       "  9   62.969099  64.263725  64.029270  62.088768  60.721711  62.088768   \n",
       "  10  60.057707  60.871552  60.104051  61.613095  62.302393  61.613095   \n",
       "  11  68.193840  67.527301  72.362407  66.531083  64.621767  66.531083   \n",
       "  12  55.740736  63.143807  63.924512  62.532916  65.056794  62.532916   \n",
       "  13  67.989985  63.983761  64.570792  64.663108  66.958315  64.663108   \n",
       "  14  58.797450  62.278203  63.120200  62.444256  58.121198  62.444256   \n",
       "  \n",
       "      demand_t7  demand_t8  demand_t9  demand_t10  \n",
       "  0   71.005184  64.088969  66.706381   66.706379  \n",
       "  1   63.271804  55.331312  62.103825   62.103826  \n",
       "  2   63.232738  60.581985  61.289264   61.289263  \n",
       "  3   62.573906  68.894022  63.154284   63.154283  \n",
       "  4   62.211406  62.929656  63.637111   63.637108  \n",
       "  5   62.072328  64.226544  65.701970   65.701968  \n",
       "  6   66.214844  63.597722  64.386018   64.386015  \n",
       "  7   68.924536  69.361419  69.883738   69.883738  \n",
       "  8   59.005480  60.829499  61.020442   61.020448  \n",
       "  9   60.879685  62.634618  62.088772   62.088768  \n",
       "  10  61.283812  63.885645  61.613092   61.613095  \n",
       "  11  65.714526  66.642278  66.531082   66.531083  \n",
       "  12  56.151613  66.725960  62.532920   62.532916  \n",
       "  13  65.885875  61.730881  64.663100   64.663108  \n",
       "  14  57.806186  61.151295  62.444260   62.444256  ),\n",
       " (     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "  0   256.519623  251.959390  252.619473  251.959390  246.815799  251.959390   \n",
       "  1   266.557046  264.140348  264.160430  264.140348  262.456134  264.140348   \n",
       "  2   255.104623  256.009829  259.397400  256.009828  253.201453  256.009828   \n",
       "  3   258.328805  264.807010  266.027383  264.807010  264.784493  264.807010   \n",
       "  4   253.416118  255.936386  254.214539  255.936386  256.695107  255.936386   \n",
       "  5   263.215996  265.899159  268.949097  265.899159  263.130433  265.899159   \n",
       "  6   267.820993  270.713150  268.501904  270.713150  272.402984  270.713150   \n",
       "  7   250.255196  253.207375  252.917631  253.207375  253.511599  253.207375   \n",
       "  8   291.872275  284.623606  289.498687  284.623606  279.906507  284.623606   \n",
       "  9   276.428735  278.330073  277.122965  278.330073  276.905217  278.330073   \n",
       "  10  261.244738  263.269475  267.407733  263.269475  263.036084  263.269475   \n",
       "  11  281.624515  276.162403  277.291903  276.162403  272.064668  276.162403   \n",
       "  12  256.640801  254.697025  253.216210  254.697026  257.734949  254.697026   \n",
       "  13  276.596581  278.797325  282.033169  278.797325  278.763871  278.797325   \n",
       "  14  297.215013  296.464810  297.943972  296.464810  296.618148  296.464810   \n",
       "  \n",
       "       demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "  0   252.404141  247.642667  251.959390  251.959390  \n",
       "  1   268.037060  263.302797  264.140348  264.140348  \n",
       "  2   254.294350  257.262525  256.009828  256.009828  \n",
       "  3   265.545294  267.617149  264.807010  264.807010  \n",
       "  4   259.314176  259.850532  255.936386  255.936386  \n",
       "  5   261.011138  267.280099  265.899159  265.899159  \n",
       "  6   270.361907  270.006558  270.713150  270.713150  \n",
       "  7   251.010061  255.083055  253.207375  253.207375  \n",
       "  8   286.218363  285.561041  284.623606  284.623606  \n",
       "  9   280.820443  281.184906  278.330073  278.330073  \n",
       "  10  260.086461  263.477115  263.269475  263.269475  \n",
       "  11  274.337136  273.932259  276.162403  276.162403  \n",
       "  12  260.510507  256.621323  254.697026  254.697026  \n",
       "  13  274.790903  280.071033  278.797325  278.797325  \n",
       "  14  293.376616  299.036274  296.464810  296.464810  ,\n",
       "      demand_t1  demand_t2  demand_t3  demand_t4  demand_t5  demand_t6  \\\n",
       "  0   68.370121  64.894454  67.199076  65.761573  63.053747  65.761573   \n",
       "  1   66.587610  64.979976  69.411094  65.920419  65.768066  65.920419   \n",
       "  2   70.933664  66.187890  69.618863  65.722519  60.188051  65.722519   \n",
       "  3   63.476652  63.427189  58.172863  62.230816  63.207280  62.230816   \n",
       "  4   72.298368  69.469709  69.557802  69.527490  69.049027  69.527490   \n",
       "  5   61.418697  64.596306  63.090749  64.471254  64.412447  64.471254   \n",
       "  6   68.349991  68.233833  65.527941  68.464087  66.683151  68.464087   \n",
       "  7   69.173899  67.791676  68.980601  66.994793  66.269833  66.994793   \n",
       "  8   65.242553  65.421038  68.671875  62.974370  57.570268  62.974370   \n",
       "  9   67.587048  68.232925  69.938504  68.137978  72.345359  68.137978   \n",
       "  10  61.458167  62.971443  63.673554  63.965057  63.243366  63.965057   \n",
       "  11  62.593521  68.252412  63.791590  68.811032  69.928345  68.811032   \n",
       "  12  64.041609  65.899146  66.197404  65.812729  69.316660  65.812729   \n",
       "  13  74.367057  70.734412  75.902168  68.817354  67.054075  68.817354   \n",
       "  14  66.151275  66.585163  64.513272  66.925316  65.898617  66.925316   \n",
       "  \n",
       "      demand_t7  demand_t8  demand_t9  demand_t10  \n",
       "  0   63.984974  62.127812  65.761570   65.761573  \n",
       "  1   64.382597  68.059276  65.920415   65.920419  \n",
       "  2   61.025759  66.547948  65.722519   65.722519  \n",
       "  3   66.306121  62.062609  62.230823   62.230816  \n",
       "  4   62.861684  67.820569  69.527490   69.527490  \n",
       "  5   63.799314  63.693119  64.471254   64.471254  \n",
       "  6   76.051808  69.090667  68.464087   68.464087  \n",
       "  7   68.198098  71.791799  66.994793   66.994793  \n",
       "  8   58.224097  57.855352  62.974371   62.974369  \n",
       "  9   66.220593  70.069887  68.137978   68.137978  \n",
       "  10  63.568947  62.804834  63.965054   63.965057  \n",
       "  11  73.798658  71.999444  68.811034   68.811032  \n",
       "  12  62.910571  70.182959  65.812727   65.812729  \n",
       "  13  65.788339  68.993258  68.817352   68.817354  \n",
       "  14  69.469320  67.743843  66.925316   66.925316  ),\n",
       " (     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "  0   283.936601  279.543638  285.077369  279.543638  276.931626  279.543638   \n",
       "  1   280.752154  278.716263  284.554707  278.716262  277.019908  278.716262   \n",
       "  2   280.810270  282.660041  281.793406  282.660041  283.966752  282.660041   \n",
       "  3   282.690695  282.605164  284.501807  282.605163  280.263205  282.605164   \n",
       "  4   269.794746  271.570922  270.571046  271.570922  268.258034  271.570922   \n",
       "  5   292.141287  294.827330  296.363870  294.827330  297.636415  294.827330   \n",
       "  6   268.295270  268.378094  272.289189  268.378094  267.061530  268.378094   \n",
       "  7   274.284449  271.793246  275.891790  271.793246  271.007436  271.793246   \n",
       "  8   295.561676  294.596168  295.346168  294.596168  293.901419  294.596168   \n",
       "  9   291.572767  290.309699  289.337801  290.309699  287.979840  290.309699   \n",
       "  10  289.359045  285.194429  290.753028  285.194429  285.165963  285.194429   \n",
       "  11  259.085891  255.011345  255.041535  255.011344  252.753361  255.011344   \n",
       "  12  294.703610  295.974131  298.873793  295.974131  294.749160  295.974131   \n",
       "  13  288.208942  285.712065  285.303854  285.712065  283.167061  285.712065   \n",
       "  14  297.971527  299.942350  303.764967  299.942350  296.928688  299.942350   \n",
       "  \n",
       "       demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "  0   279.497137  277.402834  279.543638  279.543638  \n",
       "  1   272.022711  278.462176  278.716262  278.716262  \n",
       "  2   284.073037  284.669504  282.660041  282.660041  \n",
       "  3   280.973891  281.791857  282.605164  282.605164  \n",
       "  4   273.396903  267.461509  271.570922  271.570922  \n",
       "  5   290.725323  299.869873  294.827330  294.827330  \n",
       "  6   264.194145  269.637850  268.378094  268.378094  \n",
       "  7   271.264363  278.902212  271.793246  271.793246  \n",
       "  8   293.952546  289.434761  294.596168  294.596168  \n",
       "  9   296.220290  291.572601  290.309699  290.309699  \n",
       "  10  280.959832  286.639870  285.194429  285.194429  \n",
       "  11  255.233465  254.206041  255.011344  255.011344  \n",
       "  12  295.417869  296.365897  295.974131  295.974131  \n",
       "  13  283.449034  289.498190  285.712065  285.712065  \n",
       "  14  293.866069  299.198634  299.942350  299.942350  ,\n",
       "      demand_t1  demand_t2  demand_t3  demand_t4  demand_t5  demand_t6  \\\n",
       "  0   65.625929  67.884966  68.750730  68.558033  74.175914  68.558033   \n",
       "  1   60.770111  61.058111  59.574148  60.117141  58.717761  60.117141   \n",
       "  2   66.073532  64.930685  65.683239  63.599781  63.459309  63.599781   \n",
       "  3   63.121389  66.381203  61.668540  67.299906  67.404706  67.299906   \n",
       "  4   64.915095  62.604395  65.471782  61.716297  63.127936  61.716297   \n",
       "  5   63.427651  63.458016  59.857699  65.210366  66.962546  65.210366   \n",
       "  6   60.438469  59.245399  60.450320  60.543380  56.855468  60.543380   \n",
       "  7   62.564427  62.207089  62.998637  61.999965  61.345170  61.999965   \n",
       "  8   60.300860  59.014437  58.383848  60.185218  60.029247  60.185218   \n",
       "  9   66.947411  67.567002  67.449213  67.936977  72.133012  67.936977   \n",
       "  10  65.746933  65.853934  70.574162  62.239247  55.130102  62.239247   \n",
       "  11  61.329502  63.260741  60.017189  63.453517  66.141381  63.453517   \n",
       "  12  66.822772  69.549069  66.237491  69.280813  70.547457  69.280813   \n",
       "  13  62.577572  67.210049  65.172995  67.044144  70.357863  67.044144   \n",
       "  14  59.277409  59.472203  62.933669  60.318389  57.697020  60.318389   \n",
       "  \n",
       "      demand_t7  demand_t8  demand_t9  demand_t10  \n",
       "  0   65.559446  71.308420  68.558033   68.558033  \n",
       "  1   57.979551  58.390955  60.117144   60.117141  \n",
       "  2   64.215938  63.806809  63.599781   63.599781  \n",
       "  3   70.525694  68.097560  67.299908   67.299906  \n",
       "  4   61.250627  60.709187  61.716291   61.716297  \n",
       "  5   68.788190  65.421392  65.210367   65.210366  \n",
       "  6   59.175878  58.100125  60.543382   60.543380  \n",
       "  7   64.147963  63.211996  61.999964   61.999965  \n",
       "  8   62.275329  58.171283  60.185214   60.185218  \n",
       "  9   64.609175  66.191955  67.936978   67.936977  \n",
       "  10  57.888206  63.679955  62.239243   62.239247  \n",
       "  11  65.584679  64.101433  63.453519   63.453517  \n",
       "  12  70.842404  73.111604  69.280814   69.280813  \n",
       "  13  68.535449  70.440907  67.044145   67.044144  \n",
       "  14  59.467526  57.168997  60.318390   60.318390  )]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AxUzUg3JmmDz",
    "outputId": "90d6c954-d522-46e7-bccd-09ce837a852f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of sum: 2779.8596331748327\n",
      "std of sum: 169.30737789635148\n",
      "95.0 percentile of sum: 3058.3454877772897\n",
      "Q_star: 3058.3454877772897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# demand_df_train_1 = demand_folds[0][0]\n",
    "# Q_star = calculate_Q_star(demand_df_train_1, service_level=0.95)\n",
    "# print(f\"Q_star: {Q_star}\\n\")\n",
    "\n",
    "# demand_df_train_2 = demand_folds[1][0]\n",
    "# Q_star = calculate_Q_star(demand_df_train_2, service_level=0.95)\n",
    "# print(f\"Q_star: {Q_star}\\n\")\n",
    "\n",
    "demand_df_train_1 = demand_folds[0][0]\n",
    "Q_star = calculate_Q_star(demand_df_train_1, service_level=0.95)\n",
    "print(f\"Q_star: {Q_star}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pl8jIyaJmbAj"
   },
   "source": [
    "## Data3: Qk hat df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFQx0fsxhSfc"
   },
   "source": [
    "### Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "kY0mTXa7hdfH"
   },
   "outputs": [],
   "source": [
    "# 計算條件分佈的函數\n",
    "def calculate_conditional_distribution(mu, covariance_matrix, x_observed, k):\n",
    "    mu_1 = mu[:k]\n",
    "    mu_2 = mu[k:]\n",
    "    Sigma_11 = covariance_matrix[:k, :k]\n",
    "    Sigma_22 = covariance_matrix[k:, k:]\n",
    "    Sigma_12 = covariance_matrix[k:, :k]\n",
    "    Sigma_21 = covariance_matrix[:k, k:]\n",
    "\n",
    "    # Compute conditional mean and covariance\n",
    "    Sigma_11_inv = np.linalg.pinv(Sigma_11)\n",
    "    mu_cond = mu_2 + np.dot(Sigma_12, np.dot(Sigma_11_inv, (x_observed - mu_1)))\n",
    "    sigma_cond = Sigma_22 - np.dot(Sigma_12, np.dot(Sigma_11_inv, Sigma_21))\n",
    "\n",
    "    return mu_cond, sigma_cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "uSbq87Meihmj"
   },
   "outputs": [],
   "source": [
    "def cal_Var_Y(sigma_cond):\n",
    "\n",
    "    # Extract the variances (diagonal elements)\n",
    "    variances = np.diag(sigma_cond)\n",
    "\n",
    "    # Calculate the sum of covariances (off-diagonal elements)\n",
    "    covariances_sum = np.sum(sigma_cond) - np.sum(variances)\n",
    "\n",
    "    # Total variance for the sum of mu_cond\n",
    "    total_variance = np.sum(variances) + covariances_sum\n",
    "\n",
    "    return total_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "FySGAFQrrKX0"
   },
   "outputs": [],
   "source": [
    "def cal_Qk_hat(mu_cond, sigma_cond, service_level, x_observed):\n",
    "    # predict_quantity = mu_cond + norm.ppf(service_level) * np.sqrt(np.diag(sigma_cond))\n",
    "    # Qk_hat = x_observed.sum() + predict_quantity.sum()\n",
    "\n",
    "    mean_Y = np.sum(mu_cond)\n",
    "    var_Y = cal_Var_Y(sigma_cond)\n",
    "\n",
    "    sd_Y = np.sqrt(var_Y)\n",
    "    if sd_Y < 0 or np.isnan(sd_Y):  # scale must be positive\n",
    "        sd_Y = 1e-6\n",
    "\n",
    "    percentile_95_Y = norm.ppf(service_level, loc=mean_Y, scale=sd_Y)\n",
    "\n",
    "    # print(f\"        mean_Y: {mean_Y}\")\n",
    "    # print(f\"        sd_Y: {sd_Y}\")\n",
    "    # print(f\"    percentile_95_Y: {percentile_95_Y}\")\n",
    "\n",
    "    Qk_hat = x_observed.sum() + percentile_95_Y\n",
    "    return Qk_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "rZp0UnPjm0Zb"
   },
   "outputs": [],
   "source": [
    "def cal_mu_and_cov_matrix(demand_df_train):\n",
    "\n",
    "    mu_matrix = demand_df_train.mean().values\n",
    "    covariance_matrix = demand_df_train.cov().values\n",
    "\n",
    "    # print(f\"mu_matrix: {mu_matrix}\")\n",
    "    # print(f\"covariance_matrix: \\n{covariance_matrix}\\n\")\n",
    "\n",
    "    return mu_matrix, covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "aaJEWprdphY9"
   },
   "outputs": [],
   "source": [
    "def make_Qk_hat_df(demand_df, T, service_level, mu_matrix, covariance_matrix):\n",
    "    results_df = pd.DataFrame(index=demand_df.index)\n",
    "\n",
    "    for index, row_data in demand_df.iterrows():\n",
    "        for k in range(2, T):\n",
    "            # print(f\"Now processing index: {index}, t={k}\")\n",
    "\n",
    "            x_observed = row_data[\n",
    "                : k - 1\n",
    "            ].values  # 取出前 k 個觀測值 -> Qk_hat_2(t=2): 則 observerd: T=1\n",
    "\n",
    "            mu_cond, sigma_cond = calculate_conditional_distribution(\n",
    "                mu_matrix, covariance_matrix, x_observed, len(x_observed)\n",
    "            )\n",
    "\n",
    "            Qk_hat = cal_Qk_hat(mu_cond, sigma_cond, service_level, x_observed)\n",
    "\n",
    "            results_df.loc[index, f\"Qk_hat_k{k}\"] = Qk_hat\n",
    "\n",
    "            # print(f\"    x_observed: {x_observed}\")\n",
    "            # print(f\"    mu_cond: {mu_cond}\")\n",
    "            # print(f\"    sigma_cond: \\n{sigma_cond}\")\n",
    "            # print(f\"    Qk_hat: {Qk_hat}\")\n",
    "            # print(\"\\n\")\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKbvvh-lkIlB"
   },
   "source": [
    "公式連結：https://jujueffectivelife.notion.site/Qk-eab4d89ec36345efbf3a0d4a4f488474?pvs=4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ixG_NmrKPrC"
   },
   "source": [
    "### Validate the consistency of condMVN in Python and R\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJwMUzx5hoWN"
   },
   "source": [
    "#### Given mu and sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eI8aDJT_FHnD",
    "outputId": "fa4f1da8-e77d-4e55-fa91-384b463f751c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigma_11: \n",
      "[[5 1]\n",
      " [1 8]]\n",
      "\n",
      "Sigma_22: \n",
      "[[10  1]\n",
      " [ 1  7]]\n",
      "\n",
      "Sigma_12: \n",
      "[[0 1]\n",
      " [2 0]]\n",
      "\n",
      "Sigma_21: \n",
      "[[0 2]\n",
      " [1 0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "# Define the mean vector and the covariance matrix\n",
    "mu = np.array([10, 20, 30, 40])\n",
    "covariance_matrix = np.array([[5, 1, 0, 2], [1, 8, 1, 0], [0, 1, 10, 1], [2, 0, 1, 7]])\n",
    "\n",
    "# Mean and covariance partitioning\n",
    "mu_1 = mu[:2]\n",
    "mu_2 = mu[2:]\n",
    "Sigma_11 = covariance_matrix[:2, :2]\n",
    "Sigma_22 = covariance_matrix[2:, 2:]\n",
    "Sigma_12 = covariance_matrix[2:, :2]\n",
    "Sigma_21 = covariance_matrix[:2, 2:]\n",
    "\n",
    "print(f\"Sigma_11: \\n{Sigma_11}\\n\")\n",
    "print(f\"Sigma_22: \\n{Sigma_22}\\n\")\n",
    "print(f\"Sigma_12: \\n{Sigma_12}\\n\")\n",
    "print(f\"Sigma_21: \\n{Sigma_21}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H7bmBDjVhH9J",
    "outputId": "8825f168-b07c-46c2-f8fb-e20f26e8b4be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu_cond: [31.38461538 37.84615385]\n",
      "sigma_cond: \n",
      "[[9.87179487 1.05128205]\n",
      " [1.05128205 6.17948718]]\n"
     ]
    }
   ],
   "source": [
    "# Observed values of X1 and X2\n",
    "x_observed = np.array([6, 30])\n",
    "\n",
    "mu_cond, sigma_cond = calculate_conditional_distribution(\n",
    "    mu, covariance_matrix, x_observed, len(x_observed)\n",
    ")\n",
    "print(f\"mu_cond: {mu_cond}\")\n",
    "print(f\"sigma_cond: \\n{sigma_cond}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K3-lRrG4q4lq",
    "outputId": "6b7a3ed8-4681-46fc-db04-d1e90ca512d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional density at X3 = 30, X4 = 40: 0.012061749355189695\n",
      "Conditional cumulative probability up to X3 = 30, X4 = 40: 0.2790601403798458\n",
      "Qk_hat of x_observed: 112.23905144741786\n"
     ]
    }
   ],
   "source": [
    "# Define the conditional distribution\n",
    "conditional_dist = multivariate_normal(mean=mu_cond, cov=sigma_cond)\n",
    "\n",
    "# Values at which to evaluate the PDF and CDF\n",
    "x3, x4 = 30, 40  # These can be any values of interest\n",
    "\n",
    "# Calculate the PDF\n",
    "pdf_value = conditional_dist.pdf([x3, x4])\n",
    "print(f\"Conditional density at X3 = {x3}, X4 = {x4}: {pdf_value}\")\n",
    "\n",
    "# Calculate the CDF\n",
    "cdf_value = conditional_dist.cdf([x3, x4])\n",
    "print(f\"Conditional cumulative probability up to X3 = {x3}, X4 = {x4}: {cdf_value}\")\n",
    "\n",
    "# Qk hat\n",
    "Qk_hat = cal_Qk_hat(mu_cond, sigma_cond, service_level, x_observed)\n",
    "print(f\"Qk_hat of x_observed: {Qk_hat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75v9w7MUqe4f"
   },
   "source": [
    "```\n",
    "R 中運行的結果\n",
    "```\n",
    "\n",
    "![image.png](data:image/png;base64,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)\n",
    "![image.png](data:image/png;base64,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)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_b25RnwonwV2",
    "outputId": "94fc223a-b8c1-4c38-cb37-f2d9faa004ca"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "mean_Y = np.sum(mu_cond)\n",
    "var_Y = cal_Var_Y(sigma_cond)\n",
    "\n",
    "percentile_95_Y = norm.ppf(service_level, loc=mean_Y, scale=np.sqrt(var_Y))\n",
    "\n",
    "# Generate normal distribution data\n",
    "x_values = np.linspace(mean_Y - 4 * np.sqrt(var_Y), mean_Y + 4 * np.sqrt(var_Y), 1000)\n",
    "y_values = norm.pdf(x_values, loc=mean_Y, scale=np.sqrt(var_Y))\n",
    "\n",
    "# Create dataframe\n",
    "data = pd.DataFrame({\"x\": x_values, \"y\": y_values})\n",
    "\n",
    "# Plot distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data[\"x\"], data[\"y\"], color=\"blue\")\n",
    "plt.axvline(x=percentile_95_Y, color=\"red\", linestyle=\"dashed\")\n",
    "plt.fill_between(\n",
    "    data[\"x\"], data[\"y\"], where=(data[\"x\"] <= percentile_95_Y), color=\"red\", alpha=0.3\n",
    ")\n",
    "plt.title(\"Distribution of X3 + X4\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.annotate(\n",
    "    \"95th Percentile\",\n",
    "    xy=(percentile_95_Y, max(y_values)),\n",
    "    xytext=(percentile_95_Y, max(y_values) * 1.1),\n",
    "    arrowprops=dict(facecolor=\"red\", shrink=0.05),\n",
    "    color=\"red\",\n",
    "    ha=\"center\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9unedSCMe4Lt"
   },
   "source": [
    "```\n",
    "以下為 R 程式結果\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fcBXYzDZZJg0"
   },
   "source": [
    "![image.png](data:image/png;base64,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)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbc-cfXeKUWl"
   },
   "source": [
    "P(X3,X4∣X1=10,X2=20) 的 R 計算如下\n",
    "\n",
    "```\n",
    "install.packages(\"condMVNorm\")\n",
    "install.packages(\"mvtnorm\")\n",
    "library(condMVNorm)\n",
    "library(mvtnorm)\n",
    "library(ggplot2)\n",
    "\n",
    "# Define the mean vector and covariance matrix\n",
    "mu <- c(10, 20, 30, 40)\n",
    "sigma <- matrix(c(\n",
    "    5, 1, 0, 2,\n",
    "    1, 8, 1, 0,\n",
    "    0, 1, 10, 1,\n",
    "    2, 0, 1, 7\n",
    "), nrow = 4, byrow = TRUE)\n",
    "\n",
    "# Observed values of X1 and X2\n",
    "x_observed <- c(6, 30)\n",
    "\n",
    "# Compute the conditional mean and covariance using condMVNorm\n",
    "conditional_results <- condMVN(mean = mu, sigma = sigma, dependent.ind = c(3, 4), given.ind = c(1, 2), X.given = x_observed)\n",
    "\n",
    "# Print the conditional mean and covariance\n",
    "print(conditional_results$condMean)\n",
    "print(conditional_results$condVar)\n",
    "\n",
    "# Extract the conditional mean and covariance\n",
    "mu_cond <- conditional_results$condMean\n",
    "Sigma_cond <- conditional_results$condVar\n",
    "\n",
    "# Print the conditional mean and covariance\n",
    "print(mu_cond)\n",
    "print(Sigma_cond)\n",
    "\n",
    "# Values at which to evaluate the PDF and CDF\n",
    "x_values <- c(30, 40)\n",
    "\n",
    "# Calculate the PDF\n",
    "pdf_value <- dmvnorm(x_values, mean = mu_cond, sigma = Sigma_cond)\n",
    "cat(\"Conditional density at X3 =\", x_values[1], \", X4 =\", x_values[2], \": \", pdf_value, \"\\n\")\n",
    "\n",
    "# Calculate the CDF\n",
    "cdf_value <- pmvnorm(upper = x_values, mean = mu_cond, sigma = Sigma_cond)\n",
    "cat(\"Conditional cumulative probability up to X3 =\", x_values[1], \", X4 =\", x_values[2], \": \", cdf_value, \"\\n\")\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gsOfLgI-tdM"
   },
   "source": [
    "#### Conditional mean and variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "77QPjnQS-zHN",
    "outputId": "7531e890-df7f-4c69-ad05-c1ca3455641a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "公式計算的Y的均值: 5\n",
      "公式計算的Y的方差: 3.0\n",
      "模擬計算的Y的均值: 5.01077089723792\n",
      "模擬計算的Y的方差: 2.9701945334779807\n"
     ]
    }
   ],
   "source": [
    "def cal_Var_Y(sigma_cond):\n",
    "    variances = np.diag(sigma_cond)\n",
    "    covariances_sum = np.sum(sigma_cond) - np.sum(variances)\n",
    "    total_variance = np.sum(variances) + covariances_sum\n",
    "\n",
    "    return total_variance\n",
    "\n",
    "\n",
    "def simulate_Y(mu_cond, sigma_cond, num_samples=10000):\n",
    "    samples = np.random.multivariate_normal(mu_cond, sigma_cond, num_samples)\n",
    "\n",
    "    Y = samples[:, 0] + samples[:, 1]\n",
    "\n",
    "    mean_Y = np.mean(Y)\n",
    "    var_Y = np.var(Y)\n",
    "\n",
    "    return mean_Y, var_Y\n",
    "\n",
    "\n",
    "mu_cond = [2, 3]\n",
    "sigma_cond = [[1, 0.5], [0.5, 1]]\n",
    "\n",
    "mean_Y_formula = np.sum(mu_cond)\n",
    "var_Y_formula = cal_Var_Y(sigma_cond)\n",
    "\n",
    "mean_Y_simulated, var_Y_simulated = simulate_Y(mu_cond, sigma_cond)\n",
    "\n",
    "print(f\"公式計算的Y的均值: {mean_Y_formula}\")\n",
    "print(f\"公式計算的Y的方差: {var_Y_formula}\")\n",
    "print(f\"模擬計算的Y的均值: {mean_Y_simulated}\")\n",
    "print(f\"模擬計算的Y的方差: {var_Y_simulated}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Teqw8lLAkV9"
   },
   "source": [
    "### Calculate Qk hat for 2~T-1 of demand_df_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_df_train = demand_folds[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZO2S6yw1pl0Q",
    "outputId": "6ab08c48-dc46-4e6f-8102-41f13107803f"
   },
   "outputs": [],
   "source": [
    "_, _ = cal_mu_and_cov_matrix(demand_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ZFqe6xB10hB",
    "outputId": "e49ad786-9c88-42d3-a91a-c742572252a7"
   },
   "outputs": [],
   "source": [
    "mu_matrix, covariance_matrix = cal_mu_and_cov_matrix(demand_df)\n",
    "Qk_hat_df = make_Qk_hat_df(demand_df, T, service_level, mu_matrix, covariance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u63PjHtxm9Di",
    "outputId": "d8b1fb44-98b2-4c85-c9b6-115c73b0d241"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Qk_hat_k2</th>\n",
       "      <th>Qk_hat_k3</th>\n",
       "      <th>Qk_hat_k4</th>\n",
       "      <th>Qk_hat_k5</th>\n",
       "      <th>Qk_hat_k6</th>\n",
       "      <th>Qk_hat_k7</th>\n",
       "      <th>Qk_hat_k8</th>\n",
       "      <th>Qk_hat_k9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2559.273366</td>\n",
       "      <td>2555.425299</td>\n",
       "      <td>2557.763194</td>\n",
       "      <td>2549.249085</td>\n",
       "      <td>2554.148448</td>\n",
       "      <td>2554.148449</td>\n",
       "      <td>2545.961968</td>\n",
       "      <td>2539.645932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2551.930233</td>\n",
       "      <td>2522.990411</td>\n",
       "      <td>2524.289216</td>\n",
       "      <td>2517.679819</td>\n",
       "      <td>2514.363727</td>\n",
       "      <td>2514.363727</td>\n",
       "      <td>2510.788668</td>\n",
       "      <td>2503.450474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3014.804803</td>\n",
       "      <td>2932.075551</td>\n",
       "      <td>2932.265875</td>\n",
       "      <td>2927.629736</td>\n",
       "      <td>2919.000411</td>\n",
       "      <td>2919.000411</td>\n",
       "      <td>2910.642312</td>\n",
       "      <td>2907.106851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2930.526293</td>\n",
       "      <td>2902.474153</td>\n",
       "      <td>2902.959321</td>\n",
       "      <td>2897.311015</td>\n",
       "      <td>2891.561732</td>\n",
       "      <td>2891.561732</td>\n",
       "      <td>2893.322961</td>\n",
       "      <td>2891.311413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3020.225009</td>\n",
       "      <td>2950.255189</td>\n",
       "      <td>2948.788280</td>\n",
       "      <td>2946.578934</td>\n",
       "      <td>2953.074687</td>\n",
       "      <td>2953.074688</td>\n",
       "      <td>2951.745745</td>\n",
       "      <td>2948.982952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>706.169241</td>\n",
       "      <td>669.069453</td>\n",
       "      <td>667.286387</td>\n",
       "      <td>638.766247</td>\n",
       "      <td>632.587325</td>\n",
       "      <td>632.587325</td>\n",
       "      <td>631.232001</td>\n",
       "      <td>627.830560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>662.169842</td>\n",
       "      <td>642.362767</td>\n",
       "      <td>643.332936</td>\n",
       "      <td>640.100084</td>\n",
       "      <td>639.989902</td>\n",
       "      <td>639.989902</td>\n",
       "      <td>637.757982</td>\n",
       "      <td>634.249271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>716.885029</td>\n",
       "      <td>705.000093</td>\n",
       "      <td>705.875232</td>\n",
       "      <td>699.058314</td>\n",
       "      <td>697.126057</td>\n",
       "      <td>697.126057</td>\n",
       "      <td>694.651961</td>\n",
       "      <td>694.234330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>674.601122</td>\n",
       "      <td>680.804922</td>\n",
       "      <td>680.885918</td>\n",
       "      <td>675.930202</td>\n",
       "      <td>675.975899</td>\n",
       "      <td>675.975900</td>\n",
       "      <td>674.927444</td>\n",
       "      <td>672.471691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>641.730161</td>\n",
       "      <td>605.137515</td>\n",
       "      <td>603.816064</td>\n",
       "      <td>609.452235</td>\n",
       "      <td>604.236425</td>\n",
       "      <td>604.236425</td>\n",
       "      <td>603.857140</td>\n",
       "      <td>597.290659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Qk_hat_k2    Qk_hat_k3    Qk_hat_k4    Qk_hat_k5    Qk_hat_k6  \\\n",
       "0   2559.273366  2555.425299  2557.763194  2549.249085  2554.148448   \n",
       "1   2551.930233  2522.990411  2524.289216  2517.679819  2514.363727   \n",
       "2   3014.804803  2932.075551  2932.265875  2927.629736  2919.000411   \n",
       "3   2930.526293  2902.474153  2902.959321  2897.311015  2891.561732   \n",
       "4   3020.225009  2950.255189  2948.788280  2946.578934  2953.074687   \n",
       "..          ...          ...          ...          ...          ...   \n",
       "85   706.169241   669.069453   667.286387   638.766247   632.587325   \n",
       "86   662.169842   642.362767   643.332936   640.100084   639.989902   \n",
       "87   716.885029   705.000093   705.875232   699.058314   697.126057   \n",
       "88   674.601122   680.804922   680.885918   675.930202   675.975899   \n",
       "89   641.730161   605.137515   603.816064   609.452235   604.236425   \n",
       "\n",
       "      Qk_hat_k7    Qk_hat_k8    Qk_hat_k9  \n",
       "0   2554.148449  2545.961968  2539.645932  \n",
       "1   2514.363727  2510.788668  2503.450474  \n",
       "2   2919.000411  2910.642312  2907.106851  \n",
       "3   2891.561732  2893.322961  2891.311413  \n",
       "4   2953.074688  2951.745745  2948.982952  \n",
       "..          ...          ...          ...  \n",
       "85   632.587325   631.232001   627.830560  \n",
       "86   639.989902   637.757982   634.249271  \n",
       "87   697.126057   694.651961   694.234330  \n",
       "88   675.975900   674.927444   672.471691  \n",
       "89   604.236425   603.857140   597.290659  \n",
       "\n",
       "[90 rows x 8 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qk_hat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5PqgJQzymc9c"
   },
   "source": [
    "### Plot the distribuction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H5rCKosmEf1a",
    "outputId": "8c1b9eb9-a602-473a-cb5a-9034f367148b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_star is: 3058.3454877772897\n",
      "Early bias: -1330.4694728557483\n",
      "Mid bias: -1347.85574711975\n",
      "Late bias: -1352.7191141247265\n"
     ]
    }
   ],
   "source": [
    "# 將 T 個時期分成三份\n",
    "early_values = Qk_hat_df.iloc[:, : T // 3].mean(axis=1)\n",
    "mid_values = Qk_hat_df.iloc[:, T // 3 : 2 * T // 3].mean(axis=1)\n",
    "late_values = Qk_hat_df.iloc[:, 2 * T // 3 :].mean(axis=1)\n",
    "\n",
    "# 計算與 Q_star 的差距\n",
    "early_diff = early_values - Q_star\n",
    "mid_diff = mid_values - Q_star\n",
    "late_diff = late_values - Q_star\n",
    "\n",
    "# 繪製直方圖\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# 早期\n",
    "plt.hist(early_diff, bins=10, alpha=0.5, label=\"Early\", color=\"blue\", edgecolor=\"black\")\n",
    "# 中期\n",
    "plt.hist(mid_diff, bins=10, alpha=0.5, label=\"Mid\", color=\"green\", edgecolor=\"black\")\n",
    "# 晚期\n",
    "plt.hist(late_diff, bins=10, alpha=0.5, label=\"Late\", color=\"red\", edgecolor=\"black\")\n",
    "\n",
    "plt.axvline(0, color=\"grey\", linestyle=\"--\")\n",
    "\n",
    "plt.xlabel(\"Difference from Q star\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of Differences from Q star at Different Times\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 計算偏差\n",
    "early_bias = np.mean(early_diff)\n",
    "mid_bias = np.mean(mid_diff)\n",
    "late_bias = np.mean(late_diff)\n",
    "\n",
    "print(f\"Q_star is: {Q_star}\")\n",
    "print(f\"Early bias: {early_bias}\")\n",
    "print(f\"Mid bias: {mid_bias}\")\n",
    "print(f\"Late bias: {late_bias}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EdNJAb6XEzwb",
    "outputId": "e157524f-5345-410d-e5a8-1bec824f9606"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAbpCAYAAACWuLF1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAADrd0lEQVR4nOzdd5yU1b0/8O9shaX3oggoWLARURF7QRGNFXsDY0kiFkST/LjGrkGjsWOLCsbeS7xiQ/QmKkZRLGgQjYpKE8sCLrDt+f3hZa7rLrIsywyD7/frNS+eOc8zz3ynnNndD+ecSSVJkgQAAAAAZFBetgsAAAAA4OdHKAUAAABAxgmlAAAAAMg4oRQAAAAAGSeUAgAAACDjhFIAAAAAZJxQCgAAAICME0oBAAAAkHFCKQAAAAAyTigFsIbr0aNHDBs2LNtlrPEuu+yyWHfddSM/Pz/69u3bqOfeeeedY+edd67RNmfOnDjooIOiXbt2kUql4qqrroqIiOnTp8cee+wRrVq1ilQqFY8++mij1rImeuqpp6Jv377RpEmTSKVS8e2332a7JFYDqVQqzjvvvBptr732Wmy77bbRrFmzSKVSMWXKlIjwHho2bFj06NEj22UAkIOEUgA5ZNy4cZFKpeL111+vc//OO+8cm2yyyUrfz5NPPlnrjzGW7Zlnnonf//73sd1228XYsWPjT3/60zKPHTZsWKRSqfSlefPmse6668ZBBx0UDz30UFRXV9frPk8//fR4+umnY9SoUXHHHXfEnnvuGRERQ4cOjXfeeScuvvjiuOOOO2LLLbdslMe4pvrqq6/ikEMOiaZNm8aYMWPijjvuiGbNmmW7rOV66aWX4oADDohOnTpFcXFx9OjRI37zm9/EZ5991mj3sTp/Dtx9993pILY+evToke5zeXl50bp169h0003jxBNPjFdffbVe56ioqIiDDz44vv7667jyyivjjjvuiO7du+fUe2jmzJlx3nnnpcO0n/LDz6mfurzwwgurvG4A1lwF2S4AgFVr2rRpkZe3Yv8H8eSTT8aYMWNW2z9IVzfPP/985OXlxa233hpFRUXLPb64uDhuueWWiIhYtGhRfPrpp/H3v/89DjrooNh5553jsccei5YtW6aPf+aZZ+q8z/322y/OPPPMdNuiRYvilVdeibPOOitOPvnkRnhka77XXnstFixYEBdeeGEMHDgw2+XUy7XXXhunnXZarLvuunHKKadEly5d4v33349bbrkl7rvvvhg/fnxss802K30/q/PnwN133x3vvvtujBgxot636du3b5xxxhkREbFgwYJ4//3344EHHoi//vWvcfrpp8cVV1xR4/hFixZFQcH//ar80Ucfxaeffhp//etf4/jjj0+3P/XUUznzHpo5c2acf/750aNHj+WO6LzjjjtqXP/b3/4Wzz77bK32jTbaKP7617/WO1AHgB8SSgGs4YqLi7Ndwgr77rvvVtuRBnWZO3duNG3atF6BVEREQUFBHHXUUTXaLrroorjkkkti1KhRccIJJ8R9992X3lfXeefOnRutW7eu0fbll19GRNRqXxmLFy+OoqKiFQ42c8XcuXMjon7PWVlZWZSUlKziin7aSy+9FCNGjIjtt98+nnrqqRr1/Pa3v43tttsuhgwZElOnTm3U90Fjqa6ujvLy8mjSpEnG73uttdaq1e8uvfTSOOKII+LKK6+M3r17x29/+9v0vh/XuKz3yoq8h+prdfgM/PFzNWnSpHj22WdrtQPASkkAyBljx45NIiJ57bXX6ty/0047JRtvvHGNtu7duydDhw5NXy8vL0/OO++8pFevXklxcXHStm3bZLvttkueeeaZJEmSZOjQoUlE1LostXDhwmTkyJHJ2muvnRQVFSXrr79+ctlllyXV1dU17resrCw55ZRTknbt2iXNmzdP9tlnn+Tzzz9PIiI599xz08ede+65SUQkU6dOTQ4//PCkdevWSd++fZMkSZK33norGTp0aNKzZ8+kuLg46dSpU3Lssccm8+bNq3FfS88xbdq05Mgjj0xatmyZtG/fPvnjH/+YVFdXJzNmzEj23XffpEWLFkmnTp2Syy+/vF7Pd0VFRXLBBRck6667blJUVJR07949GTVqVLJ48eL0MXU9V2PHjl3mOYcOHZo0a9Zsmfv32GOPJJVKJdOmTUu37bTTTslOO+2UJMn/vQd+fFn6HPzw0r179/Q5Pv/88+TYY49NOnbsmBQVFSV9+vRJbr311hr3PXHixCQiknvuuSc566yzkq5duyapVCr55ptvkiRJkkmTJiWDBg1KWrZsmTRt2jTZcccdk3/+8581zrG0junTpydDhw5NWrVqlbRs2TIZNmxY8t1339V6vHfccUey1VZbJU2bNk1at26d7LDDDsnTTz9d45gnn3wy2X777ZOSkpKkefPmyV577ZW8++67NY6ZNWtWMmzYsGSttdZKioqKks6dOyf77rtv8vHHHy/zud5pp51qPWdL+8rSvvT6668nO+ywQ9K0adPktNNOS5IkSebMmZP86le/Sjp27JgUFxcnm222WTJu3Lga5/7444+TiEguu+yy5Lrrrkt69uyZNG3aNNl9992TGTNmJNXV1ckFF1yQrLXWWkmTJk2SfffdN/nqq6+WWetSgwYNSvLz85P//Oc/de6//fbbk4hILr300p88z8p+Dlx22WXJgAEDkrZt2yZNmjRJtthii+SBBx6odT8RkQwfPjy58847kz59+iQFBQXJI488ssy6Hn300WSvvfZKunTpkhQVFSXrrrtucsEFFySVlZXpY+p63X74Xq9L9+7dk7333rvOfQsWLEjatm2brLXWWjU+x374WVXX87G0Xy7rPZQkK9Zn6voMTJLv+8gWW2yRNGnSJGnTpk1y6KGHJjNmzKhxjqXv16lTpyY777xz0rRp06Rr16413gdL+/eKfF790PDhw2u8B35o6NChNV6Dxnr/r6q+D8Dqw0gpgBxUWloa8+bNq9VeUVGx3Nued955MXr06Dj++ONj6623jvnz58frr78eb7zxRuy+++7x61//OmbOnFnnNI0kSWLfffeNiRMnxnHHHRd9+/aNp59+On73u9/FF198EVdeeWX62GHDhsX9998fRx99dGyzzTbx4osvxt57773Mug4++ODo3bt3/OlPf4okSSIi4tlnn43//Oc/ceyxx0bnzp1j6tSpcfPNN8fUqVNj0qRJkUqlapzj0EMPjY022iguueSS+O///u+46KKLom3btnHTTTfFrrvuGpdeemncddddceaZZ8ZWW20VO+64408+V8cff3zcfvvtcdBBB8UZZ5wRr776aowePTref//9eOSRRyLi+ykuN998c/zrX/9KT8nbdtttl/s6LMvRRx8dzzzzTDz77LOx/vrr19q/4447xh133BFHH3107L777nHMMcdERMRmm20WrVu3jtNPPz0OP/zw2GuvvaJ58+YR8f2i6Ntss02kUqk4+eSTo0OHDjF+/Pg47rjjYv78+bWmQF144YVRVFQUZ555ZixZsiSKiori+eefj8GDB0e/fv3i3HPPjby8vBg7dmzsuuuu8Y9//CO23nrrGuc45JBDomfPnjF69Oh444034pZbbomOHTvGpZdemj7m/PPPj/POOy+23XbbuOCCC6KoqCheffXVeP7552OPPfZIP79Dhw6NQYMGxaWXXhplZWVxww03xPbbbx9vvvlmenHlpaODTjnllOjRo0fMnTs3nn322ZgxY8YyF2A+66yzYoMNNoibb745LrjggujZs2est9566f1fffVVDB48OA477LA46qijolOnTrFo0aLYeeed48MPP4yTTz45evbsGQ888EAMGzYsvv322zjttNNq3Mddd90V5eXlccopp8TXX38df/7zn+OQQw6JXXfdNV544YX4wx/+EB9++GFce+21ceaZZ8Ztt922zPdGWVlZTJgwIXbYYYfo2bNnnccceuihceKJJ8bf//73+P3vf7/Mc63M50BExNVXXx377rtvHHnkkVFeXh733ntvHHzwwfHEE0/U6ufPP/983H///XHyySdH+/btf3JB7HHjxkXz5s1j5MiR0bx583j++efjnHPOifnz58dll10WEd+/bqWlpfH555+nP3OWvtcbonnz5nHAAQfErbfeGu+9915svPHGtY759a9/HWuttVb86U9/ilNPPTW22mqr6NSpU0TEMt9DK9pn6voMvPjii+Pss8+OQw45JI4//vj48ssv49prr40dd9wx3nzzzRqjs7755pvYc88948ADD4xDDjkkHnzwwfjDH/4Qm266aQwePDg22mijuOCCC+Kcc86JE088MXbYYYeIWLnPq+VZmff/quz7AKxGshyKAbACljVK5oeX5Y2U2nzzzZc5YmCpZf2P+KOPPppERHLRRRfVaD/ooIOSVCqVfPjhh0mSJMnkyZOTiEhGjBhR47hhw4Ytc6TU4YcfXuv+ysrKarXdc889SUQk//M//1PrHCeeeGK6rbKyMll77bWTVCqVXHLJJen2b775JmnatGmN56QuU6ZMSSIiOf7442u0n3nmmUlEJM8//3y6bXmjn35oece++eabSUQkp59+errthyOllor/HYHyQz8cnfBDxx13XNKlS5daI8wOO+ywpFWrVunneelIinXXXbfGc19dXZ307t07GTRoUI2RJGVlZUnPnj2T3XffPd229LX41a9+VeO+DjjggKRdu3bp69OnT0/y8vKSAw44IKmqqqpx7NL7WLBgQdK6devkhBNOqLF/9uzZSatWrdLt33zzTZ2Puz6WNfpw6QiYG2+8sUb7VVddlUREcuedd6bbysvLkwEDBiTNmzdP5s+fnyTJ/70WHTp0SL799tv0saNGjUoiItl8882TioqKdPvhhx+eFBUV1RiF92NL35NLR2wty2abbZa0bdv2J49Zmc+BJKndN8vLy5NNNtkk2XXXXWu0R0SSl5eXTJ069Sfva1nnTZIk+fWvf52UlJTUeG723nvv5Y6O+qGfGimVJEly5ZVXJhGRPPbYYzVq/+Fn1dL+8eMRYXW9hxrSZ378GfjJJ58k+fn5ycUXX1yj/Z133kkKCgpqtC99v/7tb39Lty1ZsiTp3LlzMmTIkHTba6+9tkKjo36oISOlGvr+z0TfB2D1sGYuEAGwhhszZkw8++yztS6bbbbZcm/bunXrmDp1akyfPn2F7/fJJ5+M/Pz8OPXUU2u0n3HGGZEkSYwfPz4ivl/4NyLipJNOqnHcKaecssxz/+Y3v6nV1rRp0/T24sWLY968eekFnN94441ax/9w8eH8/PzYcsstI0mSOO6449LtrVu3jg022CD+85//LLOWiO8fa0TEyJEja7QvXSj5v//7v3/y9g21dMTHggULGuV8SZLEQw89FPvss08kSRLz5s1LXwYNGhSlpaW1nsuhQ4fWeO6nTJkS06dPjyOOOCK++uqr9O2/++672G233eJ//ud/ai1y/OPXc4cddoivvvoq5s+fHxERjz76aFRXV8c555xTa72qpSPgnn322fj222/j8MMPr1F3fn5+9O/fPyZOnBgRkV7P64UXXohvvvmmUZ63iO/XYzv22GNrtD355JPRuXPnOPzww9NthYWFceqpp8bChQvjxRdfrHH8wQcfHK1atUpf79+/f0R8v17PDxfR7t+/f5SXl8cXX3yxzHqWvidatGjxk3W3aNFiue+flfkciKjZN7/55psoLS2NHXbYoc5+udNOO0WfPn1W+LwLFiyIefPmxQ477BBlZWXx73//u0G11kdj97vG6DMPP/xwVFdXxyGHHFLj/d+5c+fo3bt3+v3/w8fww/WeioqKYuutt17uZ92q1ND3f7b7PgCZY/oeQA7aeuutY8stt6zV3qZNmzqn9f3QBRdcEPvtt1+sv/76sckmm8See+4ZRx99dL0CrU8//TS6du1a64/ijTbaKL1/6b95eXm1phj16tVrmeeuazrS119/Heeff37ce++96cWElyotLa11/DrrrFPjeqtWraJJkybRvn37Wu1fffXVMmv54WP4cc2dO3eO1q1bpx9rY1u4cGFELD94qK8vv/wyvv3227j55pvj5ptvrvOYHz+3P34tlgYXQ4cOXeb9lJaWRps2bdLXf/xaLN33zTffRMuWLeOjjz6KvLy8nwwrlt7vrrvuWuf+pd9QWFxcHJdeemmcccYZ0alTp9hmm23il7/8ZRxzzDHRuXPnZZ5/edZaa61ai8x/+umn0bt371pB2o/7wFJ1vScjIrp161Zn+0/9Yb30PbG84GTBggXRsWPHnzxmZT4HIiKeeOKJuOiii2LKlCmxZMmSdPuPp9RG1N23l2Xq1Knxxz/+MZ5//vl0gLlUXX2+sTR2v2tIn6mr3yVJEr17967z9oWFhTWur7322rWe/zZt2sTbb7+9QrU3poa+/7Pd9wHIHKEUwM/MjjvuGB999FE89thj8cwzz8Qtt9wSV155Zdx44401Rhpl2g9HSCx1yCGHxMsvvxy/+93vom/fvtG8efOorq6OPffcs86vH8/Pz69XW0Sk12xZnrr+yF6V3n333Yj46QBvRSx9no466qhl/oH84yDix6/F0nNcdtlly/wa+R+v6bOyz/sP7/eOO+6o8w/MH460GDFiROyzzz7x6KOPxtNPPx1nn312jB49Op5//vn4xS9+Ue/7/KG63pMralnPQ0Oen969e0dBQcFPhgxLliyJadOm1Vqv6MdW5nPgH//4R+y7776x4447xvXXXx9dunSJwsLCGDt2bNx99921jq/v8/jtt9/GTjvtFC1btowLLrgg1ltvvWjSpEm88cYb8Yc//KHOPt9YVlW/W5E+U1e/S6VSMX78+DrfL6uizzW2hr7/s933AcgcoRTAz1Dbtm3j2GOPjWOPPTYWLlwYO+64Y5x33nnpP0aXFcR07949nnvuuViwYEGNEQVLp9V07949/W91dXV8/PHHNf6X/8MPP6x3jd98801MmDAhzj///DjnnHPS7Q2dbrSilj6G6dOnp0fBRHy/aPi3336bfqyN7Y477ohUKhW77757o5yvQ4cO0aJFi6iqqoqBAwc26BxLF25u2bJlg89R1zmrq6vjvffeW+Yf7Uvvt2PHjvW63/XWWy/OOOOMOOOMM2L69OnRt2/f+Mtf/hJ33nlno9Qc8f374u23347q6uoao6V+3AdWhZKSkthtt93iueeei08//bTO+7r//vtjyZIlcfDBBy/3fA39HHjooYeiSZMm8fTTT0dxcXG6fezYsQ18ZN974YUX4quvvoqHH364xpcQfPzxx7WObcyweOHChfHII49Et27davT1ldEYfWa99daLJEmiZ8+edX7pQUNkOmRvqNWx7wOwalhTCuBn5sfT1po3bx69evWqMQWnWbNmEfH9yIUf2muvvaKqqiquu+66Gu1XXnllpFKpGDx4cEREDBo0KCIirr/++hrHXXvttfWuc+n/pP/4f/mvuuqqep9jZey111513t8VV1wREfGT3yTYUJdcckk888wzceihhy5zys6Kys/PjyFDhsRDDz2UHg3yQ19++eVyz9GvX79Yb7314vLLL09Pc1rRc/zY/vvvH3l5eXHBBRfUGgGz9DUfNGhQtGzZMv70pz/V+c2SS++3rKwsFi9eXGPfeuutFy1atKjxvm4Me+21V8yePTvuu+++dFtlZWVce+210bx589hpp50a9f5+7I9//GMkSRLDhg2LRYsW1dj38ccfx+9///vo1q1bHH300T95npX5HMjPz49UKhVVVVXptk8++SQeffTRBjyimueNqNnny8vLa32OLK2tMabzLVq0KI4++uj4+uuv46yzzmq00KYx+syBBx4Y+fn5cf7559f6HEySZLlTkOuyrNd0dbM69n0AVg0jpQB+Zvr06RM777xz9OvXL9q2bRuvv/56PPjgg3HyySenj+nXr19ERJx66qkxaNCgyM/Pj8MOOyz22Wef2GWXXeKss86KTz75JDbffPN45pln4rHHHosRI0ak/3e7X79+MWTIkLjqqqviq6++im222SZefPHF+OCDDyKifv9b37Jly9hxxx3jz3/+c1RUVMRaa60VzzzzTJ2jJlaFzTffPIYOHRo333xzelrRv/71r7j99ttj//33j1122aXB566srEz/D/7ixYvj008/jccffzzefvvt2GWXXZa59lNDXXLJJTFx4sTo379/nHDCCdGnT5/4+uuv44033ojnnnsuvv7665+8fV5eXtxyyy0xePDg2HjjjePYY4+NtdZaK7744ouYOHFitGzZMv7+97+vUE29evWKs846Ky688MLYYYcd4sADD4zi4uJ47bXXomvXrjF69Oho2bJl3HDDDXH00UfHFltsEYcddlh06NAhZsyYEf/93/8d2223XVx33XXxwQcfxG677RaHHHJI9OnTJwoKCuKRRx6JOXPmxGGHHbYyT10tJ554Ytx0000xbNiwmDx5cvTo0SMefPDBeOmll+Kqq65qtDWJlmX77bePK6+8MkaMGBGbbbZZDBs2LLp06RL//ve/469//Wvk5eXFo48+Gq1bt/7J86zM58Dee+8dV1xxRey5555xxBFHxNy5c2PMmDHRq1evlVq/aNttt402bdrE0KFD49RTT41UKhV33HFHndPP+vXrF/fdd1+MHDkyttpqq2jevHnss88+P3n+L774It3vFi5cGO+991488MADMXv27DjjjDPi17/+dYNr/7HG6DPrrbdeXHTRRTFq1Kj45JNPYv/9948WLVrExx9/HI888kiceOKJceaZZ65QXeutt160bt06brzxxmjRokU0a9Ys+vfvv0LrfmXC6tj3AVg1hFIAPzOnnnpqPP744/HMM8/EkiVLonv37nHRRRfF7373u/QxBx54YJxyyilx7733xp133hlJksRhhx0WeXl58fjjj8c555wT9913X4wdOzZ69OgRl112Wfpb6Zb629/+Fp07d4577rknHnnkkRg4cGDcd999scEGG0STJk3qVevdd98dp5xySowZMyaSJIk99tgjxo8fH127dm3U52RZbrnlllh33XVj3Lhx8cgjj0Tnzp1j1KhRce65567UeZcsWZIeyVJSUhIdO3aMfv36xTnnnBMHHHBArUW0V1anTp3iX//6V1xwwQXx8MMPx/XXXx/t2rWLjTfeOC699NJ6nWPnnXeOV155JS688MK47rrrYuHChdG5c+fo379/g/+Yv+CCC6Jnz55x7bXXxllnnRUlJSWx2Wab1Rjlc8QRR0TXrl3jkksuicsuuyyWLFkSa621Vuywww7pb8br1q1bHH744TFhwoS44447oqCgIDbccMO4//77Y8iQIQ2qbVmaNm0aL7zwQvy///f/4vbbb4/58+fHBhtsEGPHjo1hw4Y16n0ty6mnnhpbbLFFXH755engN0mS6NixY7z11lv1WuB5ZT4Hdt1117j11lvjkksuiREjRkTPnj3j0ksvjU8++WSlQql27drFE088EWeccUb88Y9/jDZt2sRRRx0Vu+22W3r05VInnXRSTJkyJcaOHRtXXnlldO/efbmh1JQpU+Loo4+OVCoVLVq0iG7dusU+++wTxx9//HLX4GqIxugz/+///b9Yf/3148orr4zzzz8/Ir5/v++xxx6x7777rnBNhYWFcfvtt8eoUaPiN7/5TVRWVsbYsWNXu1AqYvXr+wCsGqkkm6sfAvCzMmXKlPjFL34Rd955Zxx55JHZLgfWGBdeeGGcc845cdZZZ8VFF12U7XIAAOrFSCkAVolFixbV+japq666KvLy8mosYgysvLPPPjtmzpwZF198cayzzjpx4oknZrskAIDlMlIKgFXi/PPPj8mTJ8cuu+wSBQUFMX78+Bg/fnx6TR4AAODnTSgFwCrx7LPPxvnnnx/vvfdeLFy4MNZZZ504+uij46yzzoqCAgN1AQDg504oBQAAAEDGNe7X+wAAAABAPQilAAAAAMg4oRQAAAAAGSeUAgAAACDjhFIAAAAAZJxQCgAAAICME0oBAAAAkHFCKQAAAAAyTigFAAAAQMYJpQAAAADIOKEUAAAAABknlAIAAAAg44RSAAAAAGScUAoAAACAjBNKAQAAAJBxQikAAAAAMk4oBQAAAEDGCaUAAAAAyDihFAAAAAAZJ5QCAAAAIOOEUgAAAABknFAKAAAAgIwTSgEAAACQcUIpAAAAADJOKAUAAABAxgmlAAAAAMg4oRQAAAAAGSeUAgAAACDjhFIAAAAAZJxQCgAAAICME0oBAAAAkHFCKQAAAAAyTigFAAAAQMYJpQAAAADIOKEUAAAAABknlAIAAAAg44RSAAAAAGScUAoAAACAjBNKAQAAAJBxQikAAAAAMk4oBQAAAEDGCaUAAAAAyDihFAAAAAAZJ5QCAAAAIOOEUgAAAABknFAKAAAAgIwTSgEAAACQcUIpAAAAADJOKAUAAABAxgmlAAAAAMg4oRQAAAAAGSeUAgAAACDjhFIAAAAAZJxQCgAAAICME0oBAAAAkHFCKQAAAAAyTigFAAAAQMYJpQAAAADIOKEUAAAAABknlAIAAAAg44RSAAAAAGScUAoAAACAjBNKAQAAAJBxQikAAAAAMk4oBQAAAEDGCaUAAHJUKpWK8847L9tlAAA0iFAKAKARjRs3LlKp1DIvkyZNynaJAACrhYJsFwAAsCa64IILomfPnrXae/XqlYVqAABWP0IpAIBVYPDgwbHllls2+nmrq6ujvLw8mjRp0ujnBgDIJNP3AACy4PLLL49tt9022rVrF02bNo1+/frFgw8+WOu4VCoVJ598ctx1112x8cYbR3FxcTz11FO1jps4cWKkUql45JFHau27++67I5VKxSuvvLJKHgsAQEMYKQUAsAqUlpbGvHnzarSlUqlo165dRERcffXVse+++8aRRx4Z5eXlce+998bBBx8cTzzxROy99941bvf888/H/fffHyeffHK0b98+evToUev+dt555+jWrVvcddddccABB9TYd9ddd8V6660XAwYMaNwHCQCwEoRSAACrwMCBA2u1FRcXx+LFiyMi4oMPPoimTZum95188smxxRZbxBVXXFErlJo2bVq888470adPn2XeXyqViqOOOiquuOKKKC0tjVatWkVExJdffhnPPPNMnHXWWY3xsAAAGo1QCgBgFRgzZkysv/76Ndry8/PT2z8MpL755puoqqqKHXbYIe65555a59ppp51+MpBa6phjjonRo0fHgw8+GMcdd1xERNx3331RWVkZRx11VEMfCgDAKiGUAgBYBbbeeuufXOj8iSeeiIsuuiimTJkSS5YsSbenUqlax9b1LX512XDDDWOrrbaKu+66Kx1K3XXXXbHNNtv41j8AYLVjoXMAgAz7xz/+Efvuu280adIkrr/++njyySfj2WefjSOOOCKSJKl1/A9HVS3PMcccEy+++GJ8/vnn8dFHH8WkSZOMkgIAVktGSgEAZNhDDz0UTZo0iaeffjqKi4vT7WPHjl3pcx922GExcuTIuOeee2LRokVRWFgYhx566EqfFwCgsQmlAAAyLD8/P1KpVFRVVaXbPvnkk3j00UdX+tzt27ePwYMHx5133hmLFy+OPffcM9q3b7/S5wUAaGxCKQCAVWD8+PHx73//u1b7tttuG3vvvXdcccUVseeee8YRRxwRc+fOjTFjxkSvXr3i7bffXun7PuaYY+Kggw6KiIgLL7xwpc8HALAqCKUAAFaBc845p872sWPHxrBhw+LWW2+NSy65JEaMGBE9e/aMSy+9ND755JNGCaX22WefaNOmTVRXV8e+++670ucDAFgVUkldq2kCAJCzKisro2vXrrHPPvvErbfemu1yAADq5Nv3AADWMI8++mh8+eWXccwxx2S7FACAZTJSCgBgDfHqq6/G22+/HRdeeGG0b98+3njjjWyXBACwTEZKAQCsIW644Yb47W9/Gx07doy//e1v2S4HAOAnGSkFAAAAQMYZKQUAAABAxgmlAAAAAMi4gmwXsKpVV1fHzJkzo0WLFpFKpbJdDgAAAMAaLUmSWLBgQXTt2jXy8pY9HmqND6VmzpwZ3bp1y3YZAAAAAD8rn332Way99trL3L/Gh1ItWrSIiO+fiJYtW2a5GgAAAIDGVV5eHn/5y18iIuKMM86IoqKirNYzf/786NatWzqTWZY1PpRaOmWvZcuWQikAAABgjVNeXh5NmjSJiO/zj2yHUkstbxklC50DAAAAkHFCKQAAAAAybo2fvgcAAACwJisoKIjjjz8+vZ0rcqdSAAAAAGrJy8uLtdZaK9tlrDDT9wAAAADIOCOlAAAAAHJYVVVVTJo0KSIittlmm8jPz89yRfUjlAIAAADIYVVVVfHcc89FRMRWW22VM6GU6XsAAAAAZJxQCgAAAICME0oBAAAAkHFCKQAAAAAyTigFAAAAQMYJpQAAAADIuIJsFwAAAABAwxUUFMTQoUPT27kidyoFAAAAoJa8vLzo0aNHtstYYabvAQAAAJBxRkoBAAAA5LCqqqqYPHlyRET069cv8vPzs1xR/QilAAAAAHJYVVVVjB8/PiIi+vbtmzOhlOl7AAAAAGSckVI5prS0NMrKyrJdBj9SUlISrVq1ynYZAAAAkDOEUjmktLQ0Lrzwupg3ryLbpfAj7dsXxtlnnyyYAgAAgHoSSuWQsrKymDevIpo2PTBKSjpkuxz+V1nZlzFv3sNRVlYmlAIAAIB6EkrloJKSDtGiRZdsl8EPLFqU7QoAAAAgt1joHAAAAICMM1IKAAAAIIcVFBTE4Ycfnt7OFblTKQAAAAC15OXlxfrrr5/tMlaY6XsAAAAAZJyRUgAAAAA5rKqqKt55552IiNh0000jPz8/yxXVj1AKAAAAIIdVVVXFY489FhERffr0yZlQyvQ9AAAAADJOKAUAAABAxgmlAAAAAMg4oRQAAAAAGSeUAgAAACDjhFIAAAAAZFxBtgsAAAAAoOEKCgrioIMOSm/nitypFAAAAIBa8vLyYuONN852GSvM9D0AAAAAMs5IKQAAAIAcVl1dHe+//35ERGy00UaRl5cbY5Byo0oAAAAA6lRZWRkPPvhgPPjgg1FZWZntcupNKAUAAABAxgmlAAAAAMg4oRQAAAAAGSeUAgAAACDjhFIAAAAAZJxQCgAAAICMK8h2AQAAAAA0XH5+fuy3337p7VwhlAIAAADIYfn5+dG3b99sl7HCTN8DAAAAIOOMlAIAAADIYdXV1fHhhx9GRESvXr0iLy83xiDlRpUAAAAA1KmysjLuueeeuOeee6KysjLb5dSbUAoAAACAjBNKAQAAAJBxQikAAAAAMk4oBQAAAEDGCaUAAAAAyDihFAAAAAAZV5DtAgAAAABouPz8/Bg8eHB6O1cIpQAAAAByWH5+fmy99dbZLmOFmb4HAAAAQMYZKQUAAACQw6qrq2PGjBkREbHOOutEXl5ujEHKjSoBAAAAqFNlZWXcfvvtcfvtt0dlZWW2y6k3oRQAAAAAGSeUAgAAACDjhFIAAAAAZJxQCgAAAICMW21CqUsuuSRSqVSMGDEi3bZ48eIYPnx4tGvXLpo3bx5DhgyJOXPmZK9IAAAAABrFahFKvfbaa3HTTTfFZpttVqP99NNPj7///e/xwAMPxIsvvhgzZ86MAw88MEtVAgAAANBYsh5KLVy4MI488sj461//Gm3atEm3l5aWxq233hpXXHFF7LrrrtGvX78YO3ZsvPzyyzFp0qQsVgwAAACw+sjPz4+BAwfGwIEDIz8/P9vl1FvWQ6nhw4fH3nvvHQMHDqzRPnny5KioqKjRvuGGG8Y666wTr7zySqbLBAAAAFgt5efnx3bbbRfbbbddToVSBdm883vvvTfeeOONeO2112rtmz17dhQVFUXr1q1rtHfq1Clmz569zHMuWbIklixZkr4+f/78RqsXAAAAgMaRtZFSn332WZx22mlx1113RZMmTRrtvKNHj45WrVqlL926dWu0cwMAAACsbqqrq+OLL76IL774Iqqrq7NdTr1lLZSaPHlyzJ07N7bYYosoKCiIgoKCePHFF+Oaa66JgoKC6NSpU5SXl8e3335b43Zz5syJzp07L/O8o0aNitLS0vTls88+W8WPBAAAACB7Kisr45ZbbolbbrklKisrs11OvWVt+t5uu+0W77zzTo22Y489NjbccMP4wx/+EN26dYvCwsKYMGFCDBkyJCIipk2bFjNmzIgBAwYs87zFxcVRXFy8SmsHAAAAYOVkLZRq0aJFbLLJJjXamjVrFu3atUu3H3fccTFy5Mho27ZttGzZMk455ZQYMGBAbLPNNtkoGQAAAIBGktWFzpfnyiuvjLy8vBgyZEgsWbIkBg0aFNdff322ywIAAABgJa1WodQLL7xQ43qTJk1izJgxMWbMmOwUBAAAAMAqkbWFzgEAAAD4+RJKAQAAAJBxq9X0PQAAAABWTH5+fuy0007p7VwhlAIAAADIYfn5+bHzzjtnu4wVZvoeAAAAABlnpBQAAABADkuSJL788suIiOjQoUOkUqksV1Q/RkoBAAAA5LCKioq44YYb4oYbboiKiopsl1NvQikAAAAAMk4oBQAAAEDGCaUAAAAAyDihFAAAAAAZJ5QCAAAAIOOEUgAAAABkXEG2CwAAAACg4fLz82PAgAHp7VwhlAIAAADIYfn5+bHHHntku4wVZvoeAAAAABlnpBQAAABADkuSJEpLSyMiolWrVpFKpbJcUf0YKQUAAACQwyoqKuLqq6+Oq6++OioqKrJdTr0JpQAAAADIOKEUAAAAABknlAIAAAAg44RSAAAAAGScUAoAAACAjBNKAQAAAJBxBdkuAAAAAICGy8vLiy233DK9nSuEUgAAAAA5rKCgIPbee+9sl7HCcic+AwAAAGCNYaQUAAAAQA5LkiTKysoiIqKkpCRSqVSWK6ofI6UAAAAAclhFRUVcfvnlcfnll0dFRUW2y6k3oRQAAAAAGSeUAgAAACDjhFIAAAAAZJxQCgAAAICME0oBAAAAkHFCKQAAAAAyriDbBQAAAADQcHl5ebH55punt3OFUAoAAAAghxUUFMT++++f7TJWWO7EZwAAAACsMYyUAgAAAMhhSZJERUVFREQUFhZGKpXKckX1Y6QUAAAAQA6rqKiI0aNHx+jRo9PhVC4QSgEAAACQcUIpAAAAADJOKAUAAABAxgmlAAAAAMg4oRQAAAAAGSeUAgAAACDjCrJdAAAAAAANl5eXF3369Elv5wqhFAAAAEAOKygoiIMPPjjbZayw3InPAAAAAFhjCKUAAAAAyDjT9wAAAAByWHl5eYwePToiIkaNGhVFRUVZrqh+jJQCAAAAIOOEUgAAAABknFAKAAAAgIwTSgEAAACQcUIpAAAAADJOKAUAAABAxhVkuwAAAAAAGi4vLy969+6d3s4VQikAAACAHFZQUBBHHHFEtstYYbkTnwEAAACwxhBKAQAAAJBxpu8BAAAA5LDy8vK4/PLLIyLizDPPjKKioixXVD9CKQAAAIAcV1FRke0SVpjpewAAAABknFAKAAAAgIwTSgEAAACQcUIpAAAAADJOKAUAAABAxvn2PQAAAIAclkqlonv37untXCGUAgAAAMhhhYWFMWzYsGyXscJM3wMAAAAg44RSAAAAAGSc6XsAAAAAOay8vDyuvvrqiIg47bTToqioKMsV1Y9QCgAAACDHlZWVZbuEFWb6HgAAAAAZJ5QCAAAAIOOEUgAAAABknFAKAAAAgIwTSgEAAACQcb59DwAAACCHpVKp6Nq1a3o7VwilAAAAAHJYYWFhnHDCCdkuY4WZvgcAAABAxgmlAAAAAMg40/cAAAAAclhFRUWMGTMmIiKGDx8ehYWFWa6ofoRSAAAAADksSZIoLS1Nb+cK0/cAAAAAyDihFAAAAAAZJ5QCAAAAIOOEUgAAAABknFAKAAAAgIzz7XsAAAAAOSyVSkWHDh3S27kiqyOlbrjhhthss82iZcuW0bJlyxgwYECMHz8+vX/x4sUxfPjwaNeuXTRv3jyGDBkSc+bMyWLFAAAAAKuXwsLCOOmkk+Kkk06KwsLCbJdTb1kNpdZee+245JJLYvLkyfH666/HrrvuGvvtt19MnTo1IiJOP/30+Pvf/x4PPPBAvPjiizFz5sw48MADs1kyAAAAAI0gq9P39tlnnxrXL7744rjhhhti0qRJsfbaa8ett94ad999d+y6664RETF27NjYaKONYtKkSbHNNttko2QAAAAAGsFqs9B5VVVV3HvvvfHdd9/FgAEDYvLkyVFRUREDBw5MH7PhhhvGOuusE6+88soyz7NkyZKYP39+jQsAAADAmqqioiKuv/76uP7666OioiLb5dRb1kOpd955J5o3bx7FxcXxm9/8Jh555JHo06dPzJ49O4qKiqJ169Y1ju/UqVPMnj17mecbPXp0tGrVKn3p1q3bKn4EAAAAANmTJEl8+eWX8eWXX0aSJNkup96yHkptsMEGMWXKlHj11Vfjt7/9bQwdOjTee++9Bp9v1KhRUVpamr589tlnjVgtAAAAAI0hq2tKRUQUFRVFr169IiKiX79+8dprr8XVV18dhx56aJSXl8e3335bY7TUnDlzonPnzss8X3FxcRQXF6/qsgEAAABYCVkfKfVj1dXVsWTJkujXr18UFhbGhAkT0vumTZsWM2bMiAEDBmSxQgAAAABWVlZHSo0aNSoGDx4c66yzTixYsCDuvvvueOGFF+Lpp5+OVq1axXHHHRcjR46Mtm3bRsuWLeOUU06JAQMG+OY9AAAAgByX1VBq7ty5ccwxx8SsWbOiVatWsdlmm8XTTz8du+++e0REXHnllZGXlxdDhgyJJUuWxKBBg+L666/PZskAAAAANIKshlK33nrrT+5v0qRJjBkzJsaMGZOhigAAAABySyqVilatWqW3c0XWFzoHAAAAoOEKCwtjxIgR2S5jha12C50DAAAAsOYTSgEAAACQcabvAQAAAOSwioqKGDduXEREDBs2LAoLC7NbUD0JpQAAAAByWJIkMXPmzPR2rjB9DwAAAICME0oBAAAAkHFCKQAAAAAyTigFAAAAQMYJpQAAAADION++BwAAAJDjSkpKsl3CChNKAQAAAOSwoqKi+N3vfpftMlaY6XsAAAAAZJxQCgAAAICMM30PAAAAIIdVVFTEXXfdFRERRx55ZBQWFma5ovoRSgEAAADksCRJ4tNPP01v5wrT9wAAAADIOKEUAAAAABknlAIAAAAg44RSAAAAAGScUAoAAACAjPPtewAAAAA5rrCwMNslrDChFAAAAEAOKyoqiv/6r//KdhkrzPQ9AAAAADJOKAUAAABAxjUolPrPf/7T2HUAAAAA0ACVlZVx9913x9133x2VlZXZLqfeGhRK9erVK3bZZZe48847Y/HixY1dEwAAAAD1VF1dHdOnT4/p06dHdXV1tsuptwaFUm+88UZsttlmMXLkyOjcuXP8+te/jn/961+NXRsAAAAAa6gGhVJ9+/aNq6++OmbOnBm33XZbzJo1K7bffvvYZJNN4oorrogvv/yysesEAAAAYA2yUgudFxQUxIEHHhgPPPBAXHrppfHhhx/GmWeeGd26dYtjjjkmZs2a1Vh1AgAAALAGWalQ6vXXX4+TTjopunTpEldccUWceeaZ8dFHH8Wzzz4bM2fOjP3226+x6gQAAABgDVLQkBtdccUVMXbs2Jg2bVrstdde8be//S322muvyMv7PuPq2bNnjBs3Lnr06NGYtQIAAACwhmhQKHXDDTfEr371qxg2bFh06dKlzmM6duwYt95660oVBwAAAMCaqUGh1PTp05d7TFFRUQwdOrQhpwcAAACgnoqKiuLcc8/NdhkrrEFrSo0dOzYeeOCBWu0PPPBA3H777StdFAAAAABrtgaFUqNHj4727dvXau/YsWP86U9/WumiAAAAAFizNWj63owZM6Jnz5612rt37x4zZsxY6aIAAAAAqJ/Kysp45JFHIiLigAMOiIKCBsU9GdegkVIdO3aMt99+u1b7W2+9Fe3atVvpogAAAACon+rq6njvvffivffei+rq6myXU28NCqUOP/zwOPXUU2PixIlRVVUVVVVV8fzzz8dpp50Whx12WGPXCAAAAMAapkHjuS688ML45JNPYrfddksPCauuro5jjjnGmlIAAAAALFeDQqmioqK477774sILL4y33normjZtGptuuml07969sesDAAAAYA20Uitfrb/++rH++us3Vi0AAAAA/Ew0KJSqqqqKcePGxYQJE2Lu3Lm1FtF6/vnnG6U4AAAAANZMDQqlTjvttBg3blzsvffesckmm0QqlWrsugAAAIBVpLS0NMrKyrJdBj9SUlISrVq1ynYZGdOgUOree++N+++/P/baa6/GrgcAAABYhUpLS+PCC6+LefMqsl0KP9K+fWGcffbJKxxMFRYWxqhRo9LbuaLBC5336tWrsWsBAAAAVrGysrKYN68imjY9MEpKOmS7HP5XWdmXMW/ew1FWVrbCoVQqlYqioqJVVNmq06BQ6owzzoirr746rrvuOlP3AAAAIAeVlHSIFi26ZLsMfmDRomxXkFkNCqX++c9/xsSJE2P8+PGx8cYb1xoa9vDDDzdKcQAAAAD8tMrKynjiiSciIuKXv/xlFBQ0KO7JuAZV2bp16zjggAMauxYAAAAAVlB1dXW89dZbERE5tf53g0KpsWPHNnYdAAAAAPyM5DX0hpWVlfHcc8/FTTfdFAsWLIiIiJkzZ8bChQsbrTgAAAAA1kwNGin16aefxp577hkzZsyIJUuWxO677x4tWrSISy+9NJYsWRI33nhjY9cJAAAAwBqkQSOlTjvttNhyyy3jm2++iaZNm6bbDzjggJgwYUKjFQcAAADAmqlBI6X+8Y9/xMsvvxxFRUU12nv06BFffPFFoxQGAAAAwJqrQSOlqquro6qqqlb7559/Hi1atFjpogAAAABYszVopNQee+wRV111Vdx8880REZFKpWLhwoVx7rnn5tRXDwIAAADkusLCwjjzzDPT27miQaHUX/7ylxg0aFD06dMnFi9eHEcccURMnz492rdvH/fcc09j1wgAAADAMqRSqWjWrFm2y1hhDQql1l577Xjrrbfi3nvvjbfffjsWLlwYxx13XBx55JE1Fj4HAAAAgLo0KJSKiCgoKIijjjqqMWsBAAAAYAVVVlbG008/HRERgwYNioKCBsc9GdWgKv/2t7/95P5jjjmmQcUAAAAAsGKqq6vj9ddfj4iI3XffPcvV1F+DQqnTTjutxvWKioooKyuLoqKiKCkpEUoBAAAA8JPyGnKjb775psZl4cKFMW3atNh+++0tdA4AAADAcjUolKpL796945JLLqk1igoAAAAAfqzRQqmI7xc/nzlzZmOeEgAAAIA1UIPWlHr88cdrXE+SJGbNmhXXXXddbLfddo1SGAAAAABrrgaFUvvvv3+N66lUKjp06BC77rpr/OUvf2mMugAAAABYgzUolKqurm7sOgAAAABogMLCwvQa34WFhVmupv4aFEoBAAAAsHpIpVLRunXrbJexwhoUSo0cObLex15xxRUNuQsAAAAA1mANCqXefPPNePPNN6OioiI22GCDiIj44IMPIj8/P7bYYov0calUqnGqBAAAAKBOVVVVMWHChIiI2G233SI/Pz/LFdVPg0KpffbZJ1q0aBG33357tGnTJiIivvnmmzj22GNjhx12iDPOOKNRiwQAAACgblVVVfHKK69ERMTOO++cM6FUXkNu9Je//CVGjx6dDqQiItq0aRMXXXSRb98DAAAAYLkaFErNnz8/vvzyy1rtX375ZSxYsGCliwIAAABgzdagUOqAAw6IY489Nh5++OH4/PPP4/PPP4+HHnoojjvuuDjwwAMbu0YAAAAA1jANWlPqxhtvjDPPPDOOOOKIqKio+P5EBQVx3HHHxWWXXdaoBQIAAACw5mlQKFVSUhLXX399XHbZZfHRRx9FRMR6660XzZo1a9TiAAAAAFgzNWj63lKzZs2KWbNmRe/evaNZs2aRJElj1QUAAADAGqxBI6W++uqrOOSQQ2LixImRSqVi+vTpse6668Zxxx0Xbdq08Q18AAAAABlSWFgYv/3tb9PbuaJBI6VOP/30KCwsjBkzZkRJSUm6/dBDD42nnnqq0YoDAAAA4KelUqno2LFjdOzYMVKpVLbLqbcGjZR65pln4umnn4611167Rnvv3r3j008/bZTCAAAAAFhzNSiU+u6772qMkFrq66+/juLi4pUuCgAAAID6qaqqin/84x8REbHDDjtEfn5+liuqnwZN39thhx3ib3/7W/p6KpWK6urq+POf/xy77LJLoxUHAAAAwE+rqqqKF198MV588cWoqqrKdjn11qCRUn/+859jt912i9dffz3Ky8vj97//fUydOjW+/vrreOmllxq7RgAAAADWMA0aKbXJJpvEBx98ENtvv33st99+8d1338WBBx4Yb775Zqy33nqNXSMAAAAAa5gVHilVUVERe+65Z9x4441x1llnrYqaAAAAAFjDrfBIqcLCwnj77bdXRS0AAAAA/Ew0aPreUUcdFbfeemtj1wIAAADAz0SDFjqvrKyM2267LZ577rno169fNGvWrMb+K664olGKAwAAAGDNtEKh1H/+85/o0aNHvPvuu7HFFltERMQHH3xQ45hUKtV41QEAAADwkwoKCuL4449Pb+eKFaq0d+/eMWvWrJg4cWJERBx66KFxzTXXRKdOnVZJcQAAAAD8tLy8vFhrrbWyXcYKW6E1pZIkqXF9/Pjx8d133zX4zkePHh1bbbVVtGjRIjp27Bj7779/TJs2rcYxixcvjuHDh0e7du2iefPmMWTIkJgzZ06D7xMAAACA7GvQQudL/TikWlEvvvhiDB8+PCZNmhTPPvtsVFRUxB577FEj6Dr99NPj73//ezzwwAPx4osvxsyZM+PAAw9cqfsFAAAAWFNUVVXFSy+9FC+99FJUVVVlu5x6W6Hpe6lUqtaaUSuzhtRTTz1V4/q4ceOiY8eOMXny5Nhxxx2jtLQ0br311rj77rtj1113jYiIsWPHxkYbbRSTJk2KbbbZpsH3DQAAALAmqKqqiueeey4iIrbaaqvIz8/PckX1s0KhVJIkMWzYsCguLo6I76fW/eY3v6n17XsPP/xwg4opLS2NiIi2bdtGRMTkyZOjoqIiBg4cmD5mww03jHXWWSdeeeUVoRQAAABAjlqhUGro0KE1rh911FGNVkh1dXWMGDEitttuu9hkk00iImL27NlRVFQUrVu3rnFsp06dYvbs2XWeZ8mSJbFkyZL09fnz5zdajQAAAAA0jhUKpcaOHbuq6ojhw4fHu+++G//85z9X6jyjR4+O888/v5GqAgAAAGBVWKmFzhvLySefHE888URMnDgx1l577XR7586do7y8PL799tsax8+ZMyc6d+5c57lGjRoVpaWl6ctnn322KksHAAAAoAGyGkolSRInn3xyPPLII/H8889Hz549a+zv169fFBYWxoQJE9Jt06ZNixkzZsSAAQPqPGdxcXG0bNmyxgUAAACA1csKTd9rbMOHD4+77747HnvssWjRokV6nahWrVpF06ZNo1WrVnHcccfFyJEjo23bttGyZcs45ZRTYsCAARY5BwAAAMhhWQ2lbrjhhoiI2HnnnWu0jx07NoYNGxYREVdeeWXk5eXFkCFDYsmSJTFo0KC4/vrrM1wpAAAAwOqpoKAg/eV0BQVZjXpWSFYrTZJkucc0adIkxowZE2PGjMlARQAAAAC5JS8vL3r06JHtMlbYarHQOQAAAAA/L7kzpgsAAACAWqqqqmLy5MkR8f2XxuXn52e5ovoRSgEAAADksKqqqhg/fnxERPTt21coBQAAAKWlpVFWVpbtMviBOXPmRHl5ebbLAKEUAAAAq0ZpaWlceOF1MW9eRbZL4QfKyhbE1Kn/ibZtF0eLFtmuhp8zoRQAAACrRFlZWcybVxFNmx4YJSUdsl0O/6u6+r1YsuTaqKiozHYp/MwJpQAAAFilSko6RIsWXbJdBv9r4cI52S4BIiIiL9sFAAAAAPDzI5QCAAAAIONM3wMAAADIYQUFBXH44Yent3NF7lQKAAAAQC15eXmx/vrrZ7uMFWb6HgAAAAAZZ6QUAAAAQA6rqqqKd955JyIiNt1008jPz89yRfUjlAIAAADIYVVVVfHYY49FRESfPn1yJpQyfQ8AAACAjBNKAQAAAJBxQikAAAAAMk4oBQAAAEDGCaUAAAAAyDihFAAAAAAZV5DtAgAAAABouIKCgjjooIPS27kidyoFAAAAoJa8vLzYeOONs13GCjN9DwAAAICMM1IKAAAAIIdVV1fH+++/HxERG220UeTl5cYYpNyoEgAAAIA6VVZWxoMPPhgPPvhgVFZWZrucehNKAQAAAJBxQikAAAAAMk4oBQAAAEDGCaUAAAAAyDihFAAAAAAZJ5QCAAAAIOMKsl0AAAAAAA2Xn58f++23X3o7VwilAAAAAHJYfn5+9O3bN9tlrDDT9wAAAADIOCOlAAAAAHJYdXV1fPjhhxER0atXr8jLy40xSLlRJQAAAAB1qqysjHvuuSfuueeeqKyszHY59SaUAgAAACDjhFIAAAAAZJxQCgAAAICME0oBAAAAkHFCKQAAAAAyTigFAAAAQMYVZLsAAAAAABouPz8/Bg8enN7OFUIpAAAAgByWn58fW2+9dbbLWGGm7wEAAACQcUZKAQAAAOSw6urqmDFjRkRErLPOOpGXlxtjkHKjSgAAAADqVFlZGbfffnvcfvvtUVlZme1y6k0oBQAAAEDGCaUAAAAAyDihFAAAAAAZJ5QCAAAAIOOEUgAAAABknFAKAAAAgIwryHYBAAAAADRcfn5+DBw4ML2dK4RSAAAAADksPz8/tttuu2yXscJM3wMAAAAg44yUAgAAAMhh1dXVMWvWrIiI6NKlS+Tl5cYYpNyoEgAAAIA6VVZWxi233BK33HJLVFZWZrucehNKAQAAAJBxQikAAAAAMk4oBQAAAEDGCaUAAAAAyDihFAAAAAAZJ5QCAAAAIOMKsl0AAAAAAA2Xn58fO+20U3o7VwilAAAAAHJYfn5+7LzzztkuY4WZvgcAAABAxhkpBQAAAJDDkiSJL7/8MiIiOnToEKlUKssV1Y+RUgAAAAA5rKKiIm644Ya44YYboqKiItvl1JtQCgAAAICME0oBAAAAkHFCKQAAAAAyTigFAAAAQMYJpQAAAADIOKEUAAAAABlXkO0CAAAAAGi4/Pz8GDBgQHo7VwilAAAAAHJYfn5+7LHHHtkuY4WZvgcAAABAxhkpBQAAAJDDkiSJ0tLSiIho1apVpFKpLFdUP0ZKAQAAAOSwioqKuPrqq+Pqq6+OioqKbJdTb0IpAAAAADJOKAUAAABAxgmlAAAAAMg4oRQAAAAAGSeUAgAAACDjhFIAAAAAZFxBtgsAAAAAoOHy8vJiyy23TG/nCqEUAAAAQA4rKCiIvffeO9tlrLDcic8AAAAAWGMYKQUAAACQw5IkibKysoiIKCkpiVQqleWK6sdIKQAAAIAcVlFREZdffnlcfvnlUVFRke1y6i2rodT//M//xD777BNdu3aNVCoVjz76aI39SZLEOeecE126dImmTZvGwIEDY/r06dkpFgAAAIBGk9VQ6rvvvovNN988xowZU+f+P//5z3HNNdfEjTfeGK+++mo0a9YsBg0aFIsXL85wpQAAAAA0pqyuKTV48OAYPHhwnfuSJImrrroq/vjHP8Z+++0XERF/+9vfolOnTvHoo4/GYYcdlslSAQAAAGhEq+2aUh9//HHMnj07Bg4cmG5r1apV9O/fP1555ZVl3m7JkiUxf/78GhcAAAAAVi+rbSg1e/bsiIjo1KlTjfZOnTql99Vl9OjR0apVq/SlW7duq7ROAAAAAFbcahtKNdSoUaOitLQ0ffnss8+yXRIAAAAAP5LVNaV+SufOnSMiYs6cOdGlS5d0+5w5c6Jv377LvF1xcXEUFxev6vIAAAAAVgt5eXmx+eabp7dzxWpbac+ePaNz584xYcKEdNv8+fPj1VdfjQEDBmSxMgAAAIDVR0FBQey///6x//77R0HBajv+qJasVrpw4cL48MMP09c//vjjmDJlSrRt2zbWWWedGDFiRFx00UXRu3fv6NmzZ5x99tnRtWvX2H///bNXNAAAAAArLauh1Ouvvx677LJL+vrIkSMjImLo0KExbty4+P3vfx/fffddnHjiifHtt9/G9ttvH0899VQ0adIkWyUDAAAArFaSJImKioqIiCgsLIxUKpXliuonq6HUzjvvHEmSLHN/KpWKCy64IC644IIMVgUAAACQOyoqKmL06NER8f0XwBUVFWW5ovpZbdeUAgAAAGDNJZQCAAAAIOOEUgAAAABknFAKAAAAgIwTSgEAAACQcUIpAAAAADKuINsFAAAAANBweXl50adPn/R2rhBKAQAAAOSwgoKCOPjgg7NdxgrLnfgMAAAAgDWGUAoAAACAjDN9DwAAACCHlZeXx+jRoyMiYtSoUVFUVJTliurHSCkAAAAAMk4oBQAAAEDGCaUAAAAAyDihFAAAAAAZJ5QCAAAAIOOEUgAAAABkXEG2CwAAAACg4fLy8qJ3797p7VwhlAIAAADIYQUFBXHEEUdku4wVljvxGQAAAABrDKEUAAAAABln+h4AAABADisvL4/LL788IiLOPPPMKCoqynJF9SOUAgAAAMhxFRUV2S5hhZm+BwAAAEDGCaUAAAAAyDihFAAAAAAZJ5QCAAAAIOOEUgAAAABknG/fAwAAAMhhqVQqunfvnt7OFUIpAAAAgBxWWFgYw4YNy3YZK8z0PQAAAAAyTigFAAAAQMaZvgcAAACQw8rLy+Pqq6+OiIjTTjstioqKslxR/QilAAAAAHJcWVlZtktYYabvAQAAAJBxQikAAAAAMk4oBQAAAEDGCaUAAAAAyDihFAAAAAAZ59v3AAAAAHJYKpWKrl27prdzhVAKAAAAIIcVFhbGCSeckO0yVpjpewAAAABknFAKAAAAgIwzfQ8AAAAgh1VUVMSYMWMiImL48OFRWFiY5YrqRygFAAAAkMOSJInS0tL0dq4wfQ8AAACAjBNKAQAAAJBxQikAAAAAMk4oBQAAAEDGCaUAAAAAyDjfvgcAAACQw1KpVHTo0CG9nSuEUgAAAAA5rLCwME466aRsl7HCTN8DAAAAIOOEUgAAAABknOl7AAAAADmsoqIi/vrXv0ZExAknnBCFhYVZrqh+hFIAAAAAOSxJkvjyyy/T27nC9D0AAAAAMk4oBQAAAEDGCaUAAAAAyDihFAAAAAAZJ5QCAAAAION8+x4AAABADkulUtGqVav0dq4QSgEAAADksMLCwhgxYkS2y1hhpu8BAAAAkHFCKQAAAAAyzvQ9AAAAgBxWUVER48aNi4iIYcOGRWFhYXYLqiehFAAAAEAOS5IkZs6cmd7OFabvAQAAAJBxQikAAAAAMk4oBQAAAEDGCaUAAAAAyDihFAAAAAAZ59v3AAAAAHJcSUlJtktYYUIpAAAAgBxWVFQUv/vd77JdxgozfQ8AAACAjBNKAQAAAJBxpu8BAAAA5LCKioq46667IiLiyCOPjMLCwixXVD9CKQAAAIAcliRJfPrpp+ntXGH6HgAAAAAZJ5QCAAAAIOOEUgAAAABknFAKAAAAgIwTSgEAAACQcb59DwAAACDHFRYWZruEFSaUAgAA1gilpaVRVlaW7TL4gTlz5kR5eXm2y4A1XlFRUfzXf/1XtstYYUIpAAAg55WWlsaFF14X8+ZVZLsUfqCsbEFMnfqfaNt2cbRoke1qgNWNUAoAAMh5ZWVlMW9eRTRtemCUlHTIdjn8r+rq92LJkmujoqIy26UAqyGhFAAAsMYoKekQLVp0yXYZ/K+FC+dkuwT4WaisrIz7778/IiIOOeSQKCjIjbgnN6oEAAAAoE7V1dUxffr09HauyMt2AQAAAAD8/OREKDVmzJjo0aNHNGnSJPr37x//+te/sl0SAAAAACthtQ+l7rvvvhg5cmSce+658cYbb8Tmm28egwYNirlz52a7NAAAAAAaaLUPpa644oo44YQT4thjj40+ffrEjTfeGCUlJXHbbbdluzQAAAAAGmi1DqXKy8tj8uTJMXDgwHRbXl5eDBw4MF555ZUsVgYAAADAylitv31v3rx5UVVVFZ06darR3qlTp/j3v/9d522WLFkSS5YsSV8vLS2NiIj58+evukIzZMGCBVFeviS+/fbjWLJkQbbL4X8tWjQvysrmx0cffRQLFnhdVidJkkQqlcp2GfyI12X15HVZPXldVl9em9XP3Llzo6xsYeTn+115dVJaOiOqqyuitPTTKCxMsl0O/8vrsnpatGhelJcviQULFkSzZs1W6Lbl5eWxePHiiPg+/ygqKloVJdbb0gwmSX76/ZVKlndEFs2cOTPWWmutePnll2PAgAHp9t///vfx4osvxquvvlrrNuedd16cf/75mSwTAAAAgB/57LPPYu21117m/tV6pFT79u0jPz8/5syZU6N9zpw50blz5zpvM2rUqBg5cmT6enV1dXz99dfRrl27Vf6/WfPnz49u3brFZ599Fi1btlyl9wVrOv0JGo/+BI1Ln4LGoz9B41md+lOSJLFgwYLo2rXrTx63WodSRUVF0a9fv5gwYULsv//+EfF9yDRhwoQ4+eST67xNcXFxFBcX12hr3br1Kq60ppYtW2b9DQBrCv0JGo/+BI1Ln4LGoz9B41ld+lOrVq2We8xqHUpFRIwcOTKGDh0aW265ZWy99dZx1VVXxXfffRfHHntstksDAAAAoIFW+1Dq0EMPjS+//DLOOeecmD17dvTt2zeeeuqpWoufAwAAAJA7VvtQKiLi5JNPXuZ0vdVJcXFxnHvuubWmDwIrTn+CxqM/QePSp6Dx6E/QeHKxP63W374HAAAAwJopL9sFAAAAAPDzI5QCAAAAIOOEUgAAAABknFBqOT755JM47rjjomfPntG0adNYb7314txzz43y8vIax6RSqVqXSZMm1TjXAw88EBtuuGE0adIkNt1003jyySdr7E+SJM4555zo0qVLNG3aNAYOHBjTp0/PyOOETKhPf4qIePvtt2OHHXaIJk2aRLdu3eLPf/5zrXPpT/C9iy++OLbddtsoKSmJ1q1b13lMXT+j7r333hrHvPDCC7HFFltEcXFx9OrVK8aNG1frPGPGjIkePXpEkyZNon///vGvf/1rFTwiyJ769KcZM2bE3nvvHSUlJdGxY8f43e9+F5WVlTWO0Z+gth49etT6WXTJJZfUOKYxfgeEn7Nc/NkilFqOf//731FdXR033XRTTJ06Na688sq48cYb47/+679qHfvcc8/FrFmz0pd+/fql97388stx+OGHx3HHHRdvvvlm7L///rH//vvHu+++mz7mz3/+c1xzzTVx4403xquvvhrNmjWLQYMGxeLFizPyWGFVq09/mj9/fuyxxx7RvXv3mDx5clx22WVx3nnnxc0335w+Rn+C/1NeXh4HH3xw/Pa3v/3J48aOHVvjZ9T++++f3vfxxx/H3nvvHbvssktMmTIlRowYEccff3w8/fTT6WPuu+++GDlyZJx77rnxxhtvxOabbx6DBg2KuXPnrqqHBhm3vP5UVVUVe++9d5SXl8fLL78ct99+e4wbNy7OOeec9DH6EyzbBRdcUONn0SmnnJLe11i/A8LPVc7+bElYYX/+85+Tnj17pq9//PHHSUQkb7755jJvc8ghhyR77713jbb+/fsnv/71r5MkSZLq6uqkc+fOyWWXXZbe/+233ybFxcXJPffc07gPAFYjP+5P119/fdKmTZtkyZIl6bY//OEPyQYbbJC+rj9BbWPHjk1atWpV576ISB555JFl3vb3v/99svHGG9doO/TQQ5NBgwalr2+99dbJ8OHD09erqqqSrl27JqNHj16pumF1tKz+9OSTTyZ5eXnJ7Nmz02033HBD0rJly/TPLf0J6ta9e/fkyiuvXOb+xvgdEH7OcvVni5FSDVBaWhpt27at1b7vvvtGx44dY/vtt4/HH3+8xr5XXnklBg4cWKNt0KBB8corr0TE9/+rNnv27BrHtGrVKvr3758+BtZEP+5Pr7zySuy4445RVFSUbhs0aFBMmzYtvvnmm/Qx+hOsmOHDh0f79u1j6623jttuuy2SJEnvW16fKi8vj8mTJ9c4Ji8vLwYOHKhP8bPyyiuvxKabbhqdOnVKtw0aNCjmz58fU6dOTR+jP0HdLrnkkmjXrl384he/iMsuu6zG1NfG+B0Qfq5y+WdLQbYLyDUffvhhXHvttXH55Zen25o3bx5/+ctfYrvttou8vLx46KGHYv/9949HH3009t1334iImD17do1fYCIiOnXqFLNnz07vX9q2rGNgTVNXf5o9e3b07NmzxnFL+8Xs2bOjTZs2+hOsoAsuuCB23XXXKCkpiWeeeSZOOumkWLhwYZx66qkRseyfUfPnz49FixbFN998E1VVVXUe8+9//ztjjwOybVl9Zem+nzpGf+Ln7tRTT40tttgi2rZtGy+//HKMGjUqZs2aFVdccUVENM7vgPBzNW/evJz92fKzHSn1//7f/6tz4dcfXn784n3xxRex5557xsEHHxwnnHBCur19+/YxcuTI6N+/f2y11VZxySWXxFFHHRWXXXZZph8WZEVj9iegYX3qp5x99tmx3XbbxS9+8Yv4wx/+EL///e/9jOJno7H7E/B/VqR/jRw5MnbeeefYbLPN4je/+U385S9/iWuvvTaWLFmS5UcBZNPPdqTUGWecEcOGDfvJY9Zdd9309syZM2OXXXaJbbfdtsZie8vSv3//ePbZZ9PXO3fuHHPmzKlxzJw5c6Jz587p/UvbunTpUuOYvn37Lvf+IJsasz8tq68s3fdTx+hPrClWtE+tqP79+8eFF14YS5YsieLi4mX2qZYtW0bTpk0jPz8/8vPzf7LfweqqMftT586da32TUX1/RulPrIlWpn/1798/Kisr45NPPokNNtigUX4HhJ+r9u3b5+zPlp9tKNWhQ4fo0KFDvY794osvYpdddol+/frF2LFjIy9v+QPMpkyZUuOP4QEDBsSECRNixIgR6bZnn302BgwYEBERPXv2jM6dO8eECRPSfzTPnz8/Xn311eV+oxJkW2P2pwEDBsRZZ50VFRUVUVhYGBHf95UNNtgg2rRpkz5Gf2JNtiJ9qiGmTJkSbdq0ieLi4oj4vk/9+Cu1f9inioqKol+/fjFhwoT0t/ZVV1fHhAkT4uSTT15ldUJjaMz+NGDAgLj44otj7ty50bFjx4j4vq+0bNky+vTpkz5Gf+LnYmX615QpUyIvLy/dlxrjd0D4ucrpny3ZXml9dff5558nvXr1Snbbbbfk888/T2bNmpW+LDVu3Ljk7rvvTt5///3k/fffTy6++OIkLy8vue2229LHvPTSS0lBQUFy+eWXJ++//35y7rnnJoWFhck777yTPuaSSy5JWrdunTz22GPJ22+/ney3335Jz549k0WLFmX0McOqUp/+9O233yadOnVKjj766OTdd99N7r333qSkpCS56aab0sfoT/B/Pv300+TNN99Mzj///KR58+bJm2++mbz55pvJggULkiRJkscffzz561//mrzzzjvJ9OnTk+uvvz4pKSlJzjnnnPQ5/vOf/yQlJSXJ7373u+T9999PxowZk+Tn5ydPPfVU+ph77703KS4uTsaNG5e89957yYknnpi0bt26xreQQa5bXn+qrKxMNtlkk2SPPfZIpkyZkjz11FNJhw4dklGjRqXPoT9BbS+//HJy5ZVXJlOmTEk++uij5M4770w6dOiQHHPMMeljGut3QPi5ytWfLUKp5Rg7dmwSEXVelho3blyy0UYbJSUlJUnLli2TrbfeOnnggQdqnev+++9P1l9//aSoqCjZeOONk//+7/+usb+6ujo5++yzk06dOiXFxcXJbrvtlkybNm2VP0bIlPr0pyRJkrfeeivZfvvtk+Li4mSttdZKLrnkklrn0p/ge0OHDq2zT02cODFJkiQZP3580rdv36R58+ZJs2bNks033zy58cYbk6qqqhrnmThxYtK3b9+kqKgoWXfddZOxY8fWuq9rr702WWeddZKioqJk6623TiZNmpSBRwiZs7z+lCRJ8sknnySDBw9OmjZtmrRv3z4544wzkoqKihrn0Z+gpsmTJyf9+/dPWrVqlTRp0iTZaKONkj/96U/J4sWLaxzXGL8Dws9ZLv5sSSXJD74TGgAAAAAy4Gf77XsAAAAAZI9QCgAAAICME0oBAAAAkHFCKQAAAAAyTigFAAAAQMYJpQAAAADIOKEUAAAAABknlAIAAAAg44RSAAAAAGScUAoAWC2lUql49NFH09f//e9/xzbbbBNNmjSJvn37LrNtTfPoo49Gr169Ij8/P0aMGJHtcgAAGo1QCgDImGHDhkUqlYpUKhWFhYXRqVOn2H333eO2226L6urqGsfOmjUrBg8enL5+7rnnRrNmzWLatGkxYcKEZbataX7961/HQQcdFJ999llceOGF2S4nIiIWLVoU5557bqy//vpRXFwc7du3j4MPPjimTp3a4HN+8sknkUqlYsqUKY1XKACwWhNKAQAZteeee8asWbPik08+ifHjx8cuu+wSp512Wvzyl7+MysrK9HGdO3eO4uLi9PWPPvoott9+++jevXu0a9dumW0rqry8fOUe0Cq0cOHCmDt3bgwaNCi6du0aLVq0qHVMVVVVrUBvVVqyZEkMHDgwbrvttrjooovigw8+iCeffDIqKyujf//+MWnSpIzVsiwVFRXZLgEAqAehFACQUcXFxdG5c+dYa621Yosttoj/+q//isceeyzGjx8f48aNSx/3w+l7qVQqJk+eHBdccEGkUqk477zz6myLiPjss8/ikEMOidatW0fbtm1jv/32i08++SR93mHDhsX+++8fF198cXTt2jU22GCDFbrd5ZdfHl26dIl27drF8OHDawQgS5YsiT/84Q/RrVu3KC4ujl69esWtt96a3v/uu+/G4MGDo3nz5tGpU6c4+uijY968eXU+Ty+88EI6hNp1110jlUrFCy+8EOPGjYvWrVvH448/Hn369Ini4uKYMWNGfPPNN3HMMcdEmzZtoqSkJAYPHhzTp09Pn2/p7Z544onYYIMNoqSkJA466KAoKyuL22+/PXr06BFt2rSJU089Naqqqpb5+l111VXxyiuvxBNPPBGHHHJIdO/ePbbeeut46KGHYqONNorjjjsukiSp87bffPNNHHnkkdGhQ4do2rRp9O7dO8aOHRsRET179oyIiF/84heRSqVi5513joiI1157LXbfffdo3759tGrVKnbaaad44403apw3lUrFDTfcEPvuu280a9YsLr744mXWDwCsPoRSAEDW7brrrrH55pvHww8/XOf+WbNmxcYbbxxnnHFGzJo1K84888w62yoqKmLQoEHRokWL+Mc//hEvvfRSNG/ePPbcc88aI6ImTJgQ06ZNi2effTaeeOKJet9u4sSJ8dFHH8XEiRPj9ttvj3HjxtUI0o455pi455574pprron3338/brrppmjevHlERHz77bex6667xi9+8Yt4/fXX46mnnoo5c+bEIYccUudj3nbbbWPatGkREfHQQw/FrFmzYtttt42IiLKysrj00kvjlltuialTp0bHjh1j2LBh8frrr8fjjz8er7zySiRJEnvttVeN0KysrCyuueaauPfee+Opp56KF154IQ444IB48skn48knn4w77rgjbrrppnjwwQeX+Vrdfffdsfvuu8fmm29eoz0vLy9OP/30eO+99+Ktt96q87Znn312vPfeezF+/Ph4//3344Ybboj27dtHRMS//vWviIh47rnnYtasWen3woIFC2Lo0KHxz3/+MyZNmhS9e/eOvfbaKxYsWFDj3Oedd14ccMAB8c4778SvfvWrZdYPAKw+CrJdAABARMSGG24Yb7/9dp37OnfuHAUFBdG8efPo3LlzREQ0b968Vtudd94Z1dXVccstt0QqlYqIiLFjx0br1q3jhRdeiD322CMiIpo1axa33HJLFBUVrdDt2rRpE9ddd13k5+fHhhtuGHvvvXdMmDAhTjjhhPjggw/i/vvvj2effTYGDhwYERHrrrtu+jFcd9118Ytf/CL+9Kc/pdtuu+226NatW3zwwQex/vrr13jMRUVF0bFjx4iIaNu2bfoxRnw/Pe36669PB0PTp0+Pxx9/PF566aV0cHXXXXdFt27d4tFHH42DDz44fbsbbrgh1ltvvYiIOOigg+KOO+6IOXPmRPPmzaNPnz6xyy67xMSJE+PQQw+t87X44IMPYpdddqlz30YbbZQ+pq6F52fMmBG/+MUvYsstt4yIiB49eqT3dejQISIi2rVrV+Ox7rrrrjXOcfPNN0fr1q3jxRdfjF/+8pfp9iOOOCKOPfbYOusCAFZPQikAYLWQJEk6EGqot956Kz788MNaay8tXrw4Pvroo/T1TTfdNB1IrcjtNt5448jPz09f79KlS7zzzjsRETFlypTIz8+PnXbaaZm1TZw4MT1y6oc++uijWqHUTykqKorNNtssff3999+PgoKC6N+/f7qtXbt2scEGG8T777+fbispKUkHUhERnTp1ih49etSoqVOnTjF37tyfvP9lTc/7YX11+e1vfxtDhgyJN954I/bYY4/Yf//90yHassyZMyf++Mc/xgsvvBBz586NqqqqKCsrixkzZtQ4bmnQBQDkDqEUALBaeP/999PrCjXUwoULo1+/fnHXXXfV2rd0JE7E9yOlGnK7wsLCGvtSqVR6kfGmTZsut7Z99tknLr300lr7unTp8pO3/bGmTZs2KMCrq/6fekx16d27d42g64eWti8rYBs8eHB8+umn8eSTT8azzz4bu+22WwwfPjwuv/zyZd7f0KFD46uvvoqrr746unfvHsXFxTFgwIBaC9T/+DUFAFZ/1pQCALLu+eefj3feeSeGDBmyUufZYostYvr06dGxY8fo1atXjUurVq0a/XY/tOmmm0Z1dXW8+OKLy7yPqVOnRo8ePWrdx8oGKhtttFFUVlbGq6++mm776quvYtq0adGnT5+VOvePHX744fHcc8/VWjequro6rrzyythyyy1/8j47dOgQQ4cOjTvvvDOuuuqquPnmmyPi/0ZX/XiR9ZdeeilOPfXU2GuvvWLjjTeO4uLiZS4ODwDkFqEUAJBRS5YsidmzZ8cXX3wRb7zxRvzpT3+K/fbbL375y1/GMcccs1LnPvLII6N9+/ax3377xT/+8Y/4+OOP44UXXohTTz01Pv/880a/3Q/16NEjhg4dGr/61a/i0UcfTZ/j/vvvj4iI4cOHx9dffx2HH354vPbaa/HRRx/F008/Hccee+xPfttdffTu3Tv222+/OOGEE+Kf//xnvPXWW3HUUUfFWmutFfvtt99KnfvHTj/99Nh6661jn332iQceeCBmzJgRr732WgwZMiSmT58et99++zJve84558Rjjz0WH374YUydOjWeeOKJ9DpUHTt2jKZNm6YXgC8tLU0/tjvuuCPef//9ePXVV+PII49c7qg0ACA3CKUAgIx66qmnokuXLtGjR4/Yc889Y+LEiXHNNdfEY489VmO9poYoKSmJ//mf/4l11lknDjzwwNhoo43iuOOOi8WLF0fLli0b/XY/dsMNN8RBBx0UJ510Umy44YZxwgknxHfffRcREV27do2XXnopqqqqYo899ohNN900RowYEa1bt468vJX/lWzs2LHRr1+/+OUvfxkDBgyIJEniySefrDU9b2U1adIkJkyYEMccc0yMGjUq1ltvvdh6663j3XffjXffffcnR0kVFRXFqFGjYrPNNosdd9wx8vPz4957742IiIKCgrjmmmvipptuiq5du6bDtFtvvTW++eab2GKLLeLoo4+OU089Nb0APACQ21LJ8laqBACAnzB+/Pg44IAD4vLLL4+TTz452+UAADnCSCkAAFbK4MGDY/z48fH1119b7wkAqDcjpQAAAADIOCOlAAAAAMg4oRQAAAAAGSeUAgAAACDjhFIAAAAAZJxQCgAAAICME0oBAAAAkHFCKQAAAAAyTigFAAAAQMYJpQAAAADIOKEUAAAAABknlAIAAAAg44RSAAAAAGScUAoAAACAjBNKAQAAAJBxQikAgNVYKpWK8847b7nHnXfeeZFKpVZ9QQAAjUQoBQCQAePGjYtUKhWpVCr++c9/1tqfJEl069YtUqlU/PKXv8xChQAAmVWQ7QIAAH5OmjRpEnfffXdsv/32NdpffPHF+Pzzz6O4uLhG+6JFi6KgwK9sAMCax0gpAIAM2muvveKBBx6IysrKGu1333139OvXLzp37lyjvUmTJkIpAGCNJJQCAMigww8/PL766qt49tln023l5eXx4IMPxhFHHFHr+LrWlPrnP/8ZW221VTRp0iTWW2+9uOmmm1Z12QAAjU4oBQCQQT169IgBAwbEPffck24bP358lJaWxmGHHbbc27/zzjuxxx57xNy5c+O8886LY489Ns4999x45JFHVmXZAACNzlhwAIAMO+KII2LUqFGxaNGiaNq0adx1112x0047RdeuXZd723POOSeSJIl//OMfsc4660RExJAhQ2LTTTdd1WUDADQqI6UAADLskEMOiUWLFsUTTzwRCxYsiCeeeKLOqXs/VlVVFU8//XTsv//+6UAqImKjjTaKQYMGrcqSAQAanVAKACDDOnToEAMHDoy77747Hn744aiqqoqDDjpoubf78ssvY9GiRdG7d+9a+zbYYINVUSoAwCpj+h4AQBYcccQRccIJJ8Ts2bNj8ODB0bp162yXBACQUUZKAQBkwQEHHBB5eXkxadKkek3di/h+hFXTpk1j+vTptfZNmzatsUsEAFiljJQCAMiC5s2bxw033BCffPJJ7LPPPvW6TX5+fgwaNCgeffTRmDFjRnpdqffffz+efvrpVVkuAECjE0oBAGTJ0KFDV/g2559/fjz11FOxww47xEknnRSVlZVx7bXXxsYbbxxvv/32KqgSAGDVMH0PACCHbLbZZvH0009Hhw4d4pxzzonbbrstzj///DjggAOyXRoAwApJJUmSZLsIAAAAAH5ejJQCAAAAIOOEUgAAAABknFAKAAAAgIwTSgEAAACQcUIpAAAAADJOKAUAAABAxhVku4BVrbq6OmbOnBktWrSIVCqV7XIAAAAA1mhJksSCBQuia9eukZe37PFQa3woNXPmzOjWrVu2ywAAAAD4Wfnss89i7bXXXub+NT6UatGiRUR8/0S0bNkyy9UAAAAAZE55eXn85S9/iYiIM844I4qKilb5fc6fPz+6deuWzmSWZY0PpZZO2WvZsqVQCgAAAPhZKS8vjyZNmkTE99lIJkKppZa3jJKFzgEAAADIOKEUAAAAABm3xk/fAwAAAPi5KigoiOOPPz69vTpZvaoBAAAAoNHk5eXFWmutle0y6mT6HgAAAAAZZ6QUAAAAwBqqqqoqJk2aFBER22yzTeTn52e5ov8jlAIAAABYQ1VVVcVzzz0XERFbbbXVahVKmb4HAAAAQMYJpQAAAADIOKEUAAAAABknlAIAAAAg44RSAAAAAGScUAoAAACAjCvIdgEAAAAArBoFBQUxdOjQ9PbqZPWqBgAAAIBGk5eXFz169Mh2GXUyfQ8AAACAjDNSCgAAAGANVVVVFZMnT46IiH79+kV+fn6WK/o/QikAAACANVRVVVWMHz8+IiL69u27WoVSpu8BAAAAkHFGSuWY0tLSKCsry3YZ/EhJSUm0atUq22UAAABAzhBK5ZDS0tK48LILY97CedkuhR9p37x9nP27swVTAAAAUE9CqRxSVlYW8xbOi6abNo2S1iXZLof/VfZtWcx7Z16UlZUJpQAAAKCehFI5qKR1SbRo1yLbZfADi2JRtksAAACAnGKhcwAAAAAyzkgpAAAAgDVUQUFBHH744ent1cnqVQ0AAAAAjSYvLy/WX3/9bJdRJ9P3AAAAAMg4I6UAAAAA1lBVVVXxzjvvRETEpptuGvn5+Vmu6P8IpQAAAADWUFVVVfHYY49FRESfPn1Wq1DK9D0AAAAAMk4oBQAAAEDGCaUAAAAAyDihFAAAAAAZJ5QCAAAAIOOEUgAAAABkXEG2CwAAAABg1SgoKIiDDjoovb06Wb2qAQAAAKDR5OXlxcYbb5ztMupk+h4AAAAAGWekFAAAAMAaqrq6Ot5///2IiNhoo40iL2/1GZ+0+lQCAAAAQKOqrKyMBx98MB588MGorKzMdjk1CKUAAAAAyDihFAAAAAAZJ5QCAAAAIOOEUgAAAABknFAKAAAAgIwTSgEAAACQcQXZLgAAAACAVSM/Pz/222+/9PbqRCgFAAAAsIbKz8+Pvn37ZruMOpm+BwAAAEDGGSkFAAAAsIaqrq6ODz/8MCIievXqFXl5q8/4pNWnEgAAAAAaVWVlZdxzzz1xzz33RGVlZbbLqUEoBQAAAEDGCaUAAAAAyDihFAAAAAAZJ5QCAAAAIOOEUgAAAABknFAKAAAAgIwryHYBAAAAAKwa+fn5MXjw4PT26kQoBQAAALCGys/Pj6233jrbZdTJ9D0AAAAAMs5IKQAAAIA1VHV1dcyYMSMiItZZZ53Iy1t9xietPpUAAAAA0KgqKyvj9ttvj9tvvz0qKyuzXU4NQikAAAAAMk4oBQAAAEDGCaUAAAAAyDihFAAAAAAZt9qEUpdcckmkUqkYMWJEum3x4sUxfPjwaNeuXTRv3jyGDBkSc+bMyV6RAAAAADSK1SKUeu211+Kmm26KzTbbrEb76aefHn//+9/jgQceiBdffDFmzpwZBx54YJaqBAAAAKCxZD2UWrhwYRx55JHx17/+Ndq0aZNuLy0tjVtvvTWuuOKK2HXXXaNfv34xduzYePnll2PSpElZrBgAAAAgN+Tn58fAgQNj4MCBkZ+fn+1yash6KDV8+PDYe++9Y+DAgTXaJ0+eHBUVFTXaN9xww1hnnXXilVdeyXSZAAAAADknPz8/tttuu9huu+1Wu1CqIJt3fu+998Ybb7wRr732Wq19s2fPjqKiomjdunWN9k6dOsXs2bOXec4lS5bEkiVL0tfnz5/faPUCAAAA0DiyNlLqs88+i9NOOy3uuuuuaNKkSaOdd/To0dGqVav0pVu3bo12bgAAAIBcUl1dHV988UV88cUXUV1dne1yashaKDV58uSYO3dubLHFFlFQUBAFBQXx4osvxjXXXBMFBQXRqVOnKC8vj2+//bbG7ebMmROdO3de5nlHjRoVpaWl6ctnn322ih8JAAAAwOqpsrIybrnllrjllluisrIy2+XUkLXpe7vttlu88847NdqOPfbY2HDDDeMPf/hDdOvWLQoLC2PChAkxZMiQiIiYNm1azJgxIwYMGLDM8xYXF0dxcfEqrR0AAACAlZO1UKpFixaxySab1Ghr1qxZtGvXLt1+3HHHxciRI6Nt27bRsmXLOOWUU2LAgAGxzTbbZKNkAAAAABpJVhc6X54rr7wy8vLyYsiQIbFkyZIYNGhQXH/99dkuCwAAAICVtFqFUi+88EKN602aNIkxY8bEmDFjslMQAAAAAKtE1hY6B4D/z96dh8lVFujDfqpX0iELSxaQJShhCauAYAYcWQIR0CGAyggOhGGYUaKyiM4vzgAqapDVMIaAAyS4AIoiqJ/AQAyMYkAI+2IIKATMQhDoEFqS6u76/mAsbBNAOp06Tfd9X1dd16lzTp16ivbYzcP7vgUAAPRfSikAAAAAaq5XTd8DAAAAoOfU19fn/e9/f3W7N1FKAQAAAPRR9fX12XvvvYuOsVqm7wEAAABQc0ZKAQAAAPRRlUolS5cuTZIMGzYspVKp4ESvMVIKAAAAoI8ql8uZPn16pk+fnnK5XHScLpRSAAAAANScUgoAAACAmlNKAQAAAFBzSikAAAAAak4pBQAAAEDNKaUAAAAAqLmGogMAAAAAsHbU19dn7Nix1e3eRCkFAAAA0EfV19fngAMOKDrGapm+BwAAAEDNGSkFAAAA0EdVKpW0trYmSYYMGZJSqVRwotcYKQUAAADQR5XL5UydOjVTp05NuVwuOk4XSikAAAAAak4pBQAAAEDNKaUAAAAAqDmlFAAAAAA1p5QCAAAAoOaUUgAAAADUXEPRAQAAAABYO+rq6rLbbrtVt3sTpRQAAABAH9XQ0JCDDz646Bir1bsqMgAAAAD6BSOlAAAAAPqoSqWStra2JElLS0tKpVLBiV5jpBQAAABAH1Uul3Puuefm3HPPTblcLjpOF0opAAAAAGpOKQUAAABAzSmlAAAAAKg5pRQAAAAANaeUAgAAAKDmlFIAAAAA1FxD0QEAAAAAWDvq6uqy0047Vbd7E6UUAAAAQB/V0NCQCRMmFB1jtXpXRQYAAABAv2CkFAAAAEAfValUUi6XkySNjY0plUoFJ3qNkVIAAAAAfVS5XM6UKVMyZcqUajnVWyilAAAAAKg5pRQAAAAANaeUAgAAAKDmlFIAAAAA1JxSCgAAAICaU0oBAAAAUHMNRQcAAAAAYO2oq6vLmDFjqtu9iVIKAAAAoI9qaGjIRz7ykaJjrFbvqsgAAAAA6BeUUgAAAADUnOl7AAAAAH3UypUrM2XKlCTJ5MmT09TUVHCi1xgpBQAAAEDNKaUAAAAAqDmlFAAAAAA1p5QCAAAAoOaUUgAAAADUnFIKAAAAgJprKDoAAAAAAGtHXV1dRo8eXd3uTZRSAAAAAH1UQ0NDjjzyyKJjrFbvqsgAAAAA6BeUUgAAAADUnOl7AAAAAH3UypUrc+655yZJTj311DQ1NRWc6DVKKQAAAIA+rFwuFx1htUzfAwAAAKDmlFIAAAAA1JxSCgAAAICaU0oBAAAAUHNKKQAAAABqzrfvAQAAAPRRpVIpm2++eXW7N1FKAQAAAPRRjY2NmThxYtExVsv0PQAAAABqTikFAAAAQM2ZvgcAAADQR61cuTJTp05Nkpx44olpamoqONFrlFIAAAAAfVhbW1vREVbL9D0AAAAAak4pBQAAAEDNKaUAAAAAqDmlFAAAAAA1p5QCAAAAoOZ8+x4AAABAH1UqlbLxxhtXt3sTpRQAAABAH9XY2Jjjjz++6BirZfoeAAAAADWnlAIAAACg5kzfAwAAAOijyuVypk2bliSZNGlSGhsbC070GqUUAAAAQB9VqVTS2tpa3e5NTN8DAAAAoOaUUgAAAADUnFIKAAAAgJpTSgEAAABQc0opAAAAAGrOt+8BAAAA9FGlUinDhg2rbvcmhY6Umj59enbccccMHjw4gwcPztixY3PDDTdUj7/yyiuZNGlSNthgg6y77ro5/PDDs2TJkgITAwAAALx9NDY25oQTTsgJJ5yQxsbGouN0UWgptckmm+Sss87K3Llzc/fdd2fffffNIYcckocffjhJcvLJJ+enP/1prrnmmtx2221ZuHBhDjvssCIjAwAAANADCp2+96EPfajL869+9auZPn167rjjjmyyySa57LLLcuWVV2bfffdNksyYMSPbbrtt7rjjjrz3ve8tIjIAAAAAPaDXLHTe0dGRq6++Oi+//HLGjh2buXPnplwuZ9y4cdVzttlmm2y22WaZM2fO615nxYoVWbZsWZcHAAAAQH9ULpdz0UUX5aKLLkq5XC46TheFl1IPPvhg1l133TQ3N+cTn/hEfvzjH2fMmDFZvHhxmpqaMnTo0C7njxgxIosXL37d602ZMiVDhgypPjbddNO1/AkAAAAAeqdKpZKlS5dm6dKlqVQqRcfpovBSauutt859992XO++8M5/85CdzzDHH5JFHHun29SZPnpzW1tbq4+mnn+7BtAAAAAD0hELXlEqSpqambLnllkmSXXfdNXfddVemTp2aI444IitXrsyLL77YZbTUkiVLMnLkyNe9XnNzc5qbm9d2bAAAAADWQOEjpf5aZ2dnVqxYkV133TWNjY2ZNWtW9di8efOyYMGCjB07tsCEAAAAAKypQkdKTZ48OQceeGA222yzvPTSS7nyyitz66235qabbsqQIUNy3HHH5ZRTTsn666+fwYMH59Of/nTGjh3rm/cAAAAA3uYKLaWeffbZHH300Vm0aFGGDBmSHXfcMTfddFP233//JMkFF1yQurq6HH744VmxYkXGjx+fiy66qMjIAAAAAPSAQkupyy677A2Pr7POOpk2bVqmTZtWo0QAAAAAfUepVMqQIUOq271J4QudAwAAALB2NDY25qSTTio6xmr1uoXOAQAAAOj7lFIAAAAA1JzpewAAAAB9VLlczsyZM5MkEydOTGNjY7GB/oJSCgAAAKCPqlQqWbhwYXW7NzF9DwAAAICaU0oBAAAAUHNKKQAAAABqTikFAAAAQM0ppQAAAACoOd++BwAAANCHtbS0FB1htZRSAAAAAH1UU1NTPve5zxUdY7VM3wMAAACg5pRSAAAAANSc6XsAAAAAfVS5XM73vve9JMlRRx2VxsbGghO9RikFAAAA0EdVKpU89dRT1e3exPQ9AAAAAGpOKQUAAABAzSmlAAAAAKg5pRQAAAAANaeUAgAAAKDmfPseAAAAQB/W2NhYdITVUkoBAAAA9FFNTU35whe+UHSM1TJ9DwAAAICaU0oBAAAAUHPdKqV+97vf9XQOAAAAAHpYe3t7rrzyylx55ZVpb28vOk4X3Sqlttxyy+yzzz757ne/m1deeaWnMwEAAADQAzo7OzN//vzMnz8/nZ2dRcfpolul1D333JMdd9wxp5xySkaOHJl/+7d/y29+85uezgYAAABAH9WtUmrnnXfO1KlTs3Dhwlx++eVZtGhR9tprr2y//fY5//zzs3Tp0p7OCQAAAEAfskYLnTc0NOSwww7LNddck69//et5/PHHc+qpp2bTTTfN0UcfnUWLFvVUTgAAAAD6kDUqpe6+++6ccMIJ2WijjXL++efn1FNPzRNPPJGbb745CxcuzCGHHNJTOQEAAADoQxq686Lzzz8/M2bMyLx583LQQQfl29/+dg466KDU1b3acW2xxRaZOXNmRo0a1ZNZAQAAAOgjulVKTZ8+Pf/8z/+ciRMnZqONNlrtOcOHD89ll122RuEAAAAA6Ju6VUrNnz//Tc9pamrKMccc053LAwAAANADmpqacsYZZxQdY7W6tabUjBkzcs0116yy/5prrskVV1yxxqEAAAAA6Nu6VUpNmTIlG2644Sr7hw8fnq997WtrHAoAAACAvq1b0/cWLFiQLbbYYpX9m2++eRYsWLDGoQAAAABYc+3t7fnxj3+cJDn00EPT0NCtKmit6NZIqeHDh+eBBx5YZf/999+fDTbYYI1DAQAAALDmOjs788gjj+SRRx5JZ2dn0XG66FYp9bGPfSyf+cxnMnv27HR0dKSjoyO/+MUvcuKJJ+Yf//EfezojAAAAAH1Mt8ZsnXnmmXnyySez3377VYd9dXZ25uijj7amFAAAAABvqlulVFNTU77//e/nzDPPzP33358BAwZkhx12yOabb97T+QAAAADog9ZodautttoqW221VU9lAQAAAKCf6FYp1dHRkZkzZ2bWrFl59tlnV1ko6xe/+EWPhAMAAACgb+pWKXXiiSdm5syZOfjgg7P99tunVCr1dC4AAABgLWltbU1bW1vRMfgrLS0tGTJkSNExaqZbpdTVV1+dH/zgBznooIN6Og8AAACwFrW2tubMc87Mc8ufKzoKf2XDdTfMaZ87rUeLqcbGxkyePLm63Zt0e6HzLbfcsqezAAAAAGtZW1tbnlv+XAbsMCAtQ1uKjsP/aXuxLc89+Fza2tp6tJQqlUppamrqsev1pG6VUp/97GczderUfPOb3zR1DwAAAN6GWoa2ZNAGg4qOwV/4U/5UdISa6lYp9atf/SqzZ8/ODTfckO22226V4V/XXnttj4QDAAAAoPva29vzs5/9LEnywQ9+MA0N3aqC1opuJRk6dGgOPfTQns4CAAAAQA/q7OzM/fffnyS9bm3wbpVSM2bM6OkcAAAAAPQjdd19YXt7e2655ZZccskleemll5IkCxcuzPLly3ssHAAAAAB9U7dGSj311FP5wAc+kAULFmTFihXZf//9M2jQoHz961/PihUrcvHFF/d0TgAAAAD6kG6NlDrxxBOz22675YUXXsiAAQOq+w899NDMmjWrx8IBAAAA0Dd1a6TUL3/5y/z6179OU1NTl/2jRo3KH/7whx4JBgAAAEDf1a2RUp2dneno6Fhl/zPPPJNBgwatcSgAAAAA+rZujZQ64IAD8o1vfCPf+ta3kiSlUinLly/PGWec0eu+XhAAAACgv2psbMypp55a3e5NulVKnXfeeRk/fnzGjBmTV155JUceeWTmz5+fDTfcMFdddVVPZwQAAACgG0qlUgYOHFh0jNXqVim1ySab5P7778/VV1+dBx54IMuXL89xxx2Xo446qsvC5wAAAACwOt0qpZKkoaEhH//4x3syCwAAAAA9qL29PTfddFOSZPz48Wlo6HYV1OO6leTb3/72Gx4/+uijuxUGAAAAgJ7T2dmZu+++O0my//77F5ymq26VUieeeGKX5+VyOW1tbWlqakpLS4tSCgAAAIA3VNedF73wwgtdHsuXL8+8efOy1157WegcAAAAgDfVrVJqdUaPHp2zzjprlVFUAAAAAPDXeqyUSl5d/HzhwoU9eUkAAAAA+qBurSn1k5/8pMvzSqWSRYsW5Zvf/Gb23HPPHgkGAAAAQN/VrVJqwoQJXZ6XSqUMGzYs++67b84777yeyAUAAABAH9atUqqzs7OncwAAAADQwxobG6vrfzc2NhacpqtulVIAAAAA9H6lUilDhw4tOsZqdauUOuWUU/7mc88///zuvAUAAAAAfVi3Sql777039957b8rlcrbeeuskyWOPPZb6+vrssssu1fNKpVLPpAQAAADgLevo6MisWbOSJPvtt1/q6+sLTvSabpVSH/rQhzJo0KBcccUVWW+99ZIkL7zwQo499ti8733vy2c/+9keDQkAAADAW9fR0ZE5c+YkSfbee+9eVUrVdedF5513XqZMmVItpJJkvfXWy1e+8hXfvgcAAADAm+pWKbVs2bIsXbp0lf1Lly7NSy+9tMahAAAAAOjbulVKHXrooTn22GNz7bXX5plnnskzzzyTH/3oRznuuONy2GGH9XRGAAAAAPqYbq0pdfHFF+fUU0/NkUcemXK5/OqFGhpy3HHH5ZxzzunRgAAAAAD0Pd0qpVpaWnLRRRflnHPOyRNPPJEkede73pWBAwf2aDgAAAAA+qZuTd/7s0WLFmXRokUZPXp0Bg4cmEql0lO5AAAAAOjDujVS6o9//GM++tGPZvbs2SmVSpk/f37e+c535rjjjst6663nG/gAAAAAeoHGxsZ88pOfrG73Jt0aKXXyySensbExCxYsSEtLS3X/EUcckRtvvLHHwgEAAADQfaVSKcOHD8/w4cNTKpWKjtNFt0ZK/c///E9uuummbLLJJl32jx49Ok899VSPBAMAAACg7+pWKfXyyy93GSH1Z88//3yam5vXOBQAAAAAa66joyO//OUvkyTve9/7Ul9fX3Ci13Rr+t773ve+fPvb364+L5VK6ezszNlnn5199tmnx8IBAAAA0H0dHR257bbbctttt6Wjo6PoOF10a6TU2Wefnf322y933313Vq5cmc9//vN5+OGH8/zzz+f222/v6YwAAAAA9DHdGim1/fbb57HHHstee+2VQw45JC+//HIOO+yw3HvvvXnXu97V0xkBAAAA6GPe8kipcrmcD3zgA7n44ovzH//xH2sjEwAAAAB93FseKdXY2JgHHnhgbWQBAAAAoJ/o1vS9j3/847nssst6OgsAAAAA/US3Fjpvb2/P5ZdfnltuuSW77rprBg4c2OX4+eef3yPhAAAAAOib3lIp9bvf/S6jRo3KQw89lF122SVJ8thjj3U5p1Qq9Vw6AAAAALqtoaEh//Iv/1Ld7k3eUprRo0dn0aJFmT17dpLkiCOOyIUXXpgRI0aslXAAAAAAdF9dXV3e8Y53FB1jtd7SmlKVSqXL8xtuuCEvv/xyt998ypQpec973pNBgwZl+PDhmTBhQubNm9flnFdeeSWTJk3KBhtskHXXXTeHH354lixZ0u33BAAAAKB43Vro/M/+uqR6q2677bZMmjQpd9xxR26++eaUy+UccMABXYquk08+OT/96U9zzTXX5LbbbsvChQtz2GGHrdH7AgAAAPQHHR0duf3223P77beno6Oj6DhdvKXpe6VSaZU1o9ZkDakbb7yxy/OZM2dm+PDhmTt3bv7+7/8+ra2tueyyy3LllVdm3333TZLMmDEj2267be644468973v7fZ7AwAAAPR1HR0dueWWW5Ik73nPe1JfX19wote8pVKqUqlk4sSJaW5uTvLq1LpPfOITq3z73rXXXtutMK2trUmS9ddfP0kyd+7clMvljBs3rnrONttsk8022yxz5sxRSgEAAAC8Tb2lUuqYY47p8vzjH/94jwXp7OzMSSedlD333DPbb799kmTx4sVpamrK0KFDu5w7YsSILF68eLXXWbFiRVasWFF9vmzZsh7LCAAAAEDPeEul1IwZM9ZWjkyaNCkPPfRQfvWrX63RdaZMmZIvfelLPZQKAAAAgLVhjRY67ymf+tSn8rOf/SyzZ8/OJptsUt0/cuTIrFy5Mi+++GKX85csWZKRI0eu9lqTJ09Oa2tr9fH000+vzegAAAAAdEOhpVSlUsmnPvWp/PjHP84vfvGLbLHFFl2O77rrrmlsbMysWbOq++bNm5cFCxZk7Nixq71mc3NzBg8e3OUBAAAAQO/ylqbv9bRJkyblyiuvzPXXX59BgwZV14kaMmRIBgwYkCFDhuS4447LKaeckvXXXz+DBw/Opz/96YwdO9Yi5wAAAABvY4WWUtOnT0+S7L333l32z5gxIxMnTkySXHDBBamrq8vhhx+eFStWZPz48bnoootqnBQAAADg7aehoaH6xXUNDYXWQKsoNE2lUnnTc9ZZZ51MmzYt06ZNq0EiAAAAgL6jrq4uo0aNKjrGavWKhc4BAAAA6F9617gtAAAAAHpMR0dH5s6dm+TVL5Srr68vONFrlFIAAAAAfVRHR0duuOGGJMnOO++slAIAAKB/aG1tTVtbW9Ex+AtLlizJypUri44BSikAAADWjtbW1px5zpl5bvlzRUfhL7S93JaH5z2c9fdaP4MyqOg49GNKKQAAANaKtra2PLf8uQzYYUBahrYUHYf/0/lkZ1Y8vCLlcrnoKPRzSikAAADWqpahLRm0gRE5vcXyF5YXHQGSJHVFBwAAAACg/1FKAQAAAFBzpu8BAAAA9FENDQ352Mc+Vt3uTXpXGgAAAAB6TF1dXbbaaquiY6yW6XsAAAAA1JyRUgAAAAB9VEdHRx588MEkyQ477JD6+vqCE71GKQUAAADQR3V0dOT6669PkowZM6ZXlVKm7wEAAABQc0opAAAAAGpOKQUAAABAzSmlAAAAAKg5pRQAAAAANaeUAgAAAKDmGooOAAAAAMDa0dDQkA9/+MPV7d6kd6UBAAAAoMfU1dVlu+22KzrGapm+BwAAAEDNGSkFAAAA0Ed1dnbm0UcfTZJsu+22qavrPeOTek8SAAAAAHpUe3t7fvjDH+aHP/xh2tvbi47ThVIKAAAAgJpTSgEAAABQc0opAAAAAGpOKQUAAABAzSmlAAAAAKg5pRQAAAAANddQdAAAAAAA1o76+voccsgh1e3eRCkFAAAA0EfV19dn5513LjrGapm+BwAAAEDNGSkFAAAA0Ed1dnbm8ccfT5JsueWWqavrPeOTek8SAAAAAHpUe3t7rrrqqlx11VVpb28vOk4XSikAAAAAak4pBQAAAEDNKaUAAAAAqDmlFAAAAAA1p5QCAAAAoOaUUgAAAADUXEPRAQAAAABYO+rr63PggQdWt3sTpRQAAABAH1VfX5/dd9+96BirZfoeAAAAADVnpBQAAABAH9XZ2ZkFCxYkSTbbbLPU1fWe8Um9JwkAAAAAPaq9vT1XXHFFrrjiirS3txcdpwulFAAAAAA1p5QCAAAAoOaUUgAAAADUnFIKAAAAgJpTSgEAAABQc0opAAAAAGquoegAAAAAAKwd9fX1GTduXHW7N1FKAQAAAPRR9fX12XPPPYuOsVqm7wEAAABQc0ZKAQAAAPRRnZ2dWbRoUZJko402Sl1d7xmf1HuSAAAAANCj2tvbc+mll+bSSy9Ne3t70XG6UEoBAAAAUHNKKQAAAABqTikFAAAAQM0ppQAAAACoOaUUAAAAADWnlAIAAACg5hqKDgAAAADA2lFfX5/3v//91e3eRCkFAAAA0EfV19dn7733LjrGapm+BwAAAEDNGSkFAAAA0EdVKpUsXbo0STJs2LCUSqWCE73GSCkAAACAPqpcLmf69OmZPn16yuVy0XG6UEoBAAAAUHNKKQAAAABqTikFAAAAQM0ppQAAAACoOaUUAAAAADWnlAIAAACg5hqKDgAAAADA2lFfX5+xY8dWt3sTpRQAAABAH1VfX58DDjig6BirZfoeAAAAADVnpBQAAABAH1WpVNLa2pokGTJkSEqlUsGJXmOkFAAAAEAfVS6XM3Xq1EydOjXlcrnoOF0opQAAAACoOaUUAAAAADWnlAIAAACg5pRSAAAAANScUgoAAACAmlNKAQAAAFBzDUUHAAAAAGDtqKury2677Vbd7k2UUgAAAAB9VENDQw4++OCiY6xW76rIAAAAAOgXjJQCAAAA6KMqlUra2tqSJC0tLSmVSgUneo2RUgAAAAB9VLlczrnnnptzzz035XK56DhdFFpK/e///m8+9KEPZeONN06pVMp1113X5XilUsnpp5+ejTbaKAMGDMi4ceMyf/78YsICAAAA0GMKLaVefvnl7LTTTpk2bdpqj5999tm58MILc/HFF+fOO+/MwIEDM378+Lzyyis1TgoAAABATyp0TakDDzwwBx544GqPVSqVfOMb38h//ud/5pBDDkmSfPvb386IESNy3XXX5R//8R9rGRUAAACAHtRr15T6/e9/n8WLF2fcuHHVfUOGDMkee+yROXPmvO7rVqxYkWXLlnV5AAAAANC79NpSavHixUmSESNGdNk/YsSI6rHVmTJlSoYMGVJ9bLrppms1JwAAAABvXa8tpbpr8uTJaW1trT6efvrpoiMBAAAA8FcKXVPqjYwcOTJJsmTJkmy00UbV/UuWLMnOO+/8uq9rbm5Oc3Pz2o4HAAAA0OvV1dVlp512qm73Jr0rzV/YYostMnLkyMyaNau6b9myZbnzzjszduzYApMBAAAAvD00NDRkwoQJmTBhQhoaetfYpELTLF++PI8//nj1+e9///vcd999WX/99bPZZpvlpJNOyle+8pWMHj06W2yxRU477bRsvPHGmTBhQnGhAQAAAFhjhZZSd999d/bZZ5/q81NOOSVJcswxx2TmzJn5/Oc/n5dffjn/+q//mhdffDF77bVXbrzxxqyzzjpFRQYAAAB426hUKimXy0mSxsbGlEqlghO9ptBSau+9906lUnnd46VSKV/+8pfz5S9/uYapAAAAAPqGcrmcKVOmJHn1y+GampoKTvSaXrumFAAAAAB9l1IKAAAAgJpTSgEAAABQc0opAAAAAGpOKQUAAABAzSmlAAAAAKi5hqIDAAAAALB21NXVZcyYMdXt3kQpBQAAANBHNTQ05CMf+UjRMVard1VkAAAAAPQLSikAAAAAas70PQAAAIA+auXKlZkyZUqSZPLkyWlqaio40WuMlAIAAACg5pRSAAAAANScUgoAAACAmlNKAQAAAFBzSikAAAAAak4pBQAAAEDNNRQdAAAAAIC1o66uLqNHj65u9yZKKQAAAIA+qqGhIUceeWTRMVard1VkAAAAAPQLSikAAAAAas70PQAAAIA+auXKlTn33HOTJKeeemqampoKTvQapRQAAABAH1Yul4uOsFqm7wEAAABQc0opAAAAAGpOKQUAAABAzSmlAAAAAKg5pRQAAAAANefb9wAAAAD6qFKplM0337y63ZsopQAAAAD6qMbGxkycOLHoGKtl+h4AAAAANaeUAgAAAKDmTN8DAAAA6KNWrlyZqVOnJklOPPHENDU1FZzoNUopAAAAgD6sra2t6AirZfoeAAAAADWnlAIAAACg5pRSAAAAANScUgoAAACAmlNKAQAAAFBzvn0PAAAAoI8qlUrZeOONq9u9iVIKAAAAoI9qbGzM8ccfX3SM1TJ9DwAAAICaU0oBAAAAUHOm7wEAAAD0UeVyOdOmTUuSTJo0KY2NjQUneo1SCgAAAKCPqlQqaW1trW73JqbvAQAAAFBzSikAAAAAak4pBQAAAEDNKaUAAAAAqDmlFAAAAAA159v3AAAAAPqoUqmUYcOGVbd7E6UUAAAAQB/V2NiYE044oegYq2X6HgAAAAA1p5QCAAAAoOZM3wMAAADoo8rlcv77v/87SXL88censbGx4ESvUUoBAAAA9FGVSiVLly6tbvcmpu8BAAAAUHNKKQAAAABqTikFAAAAQM0ppQAAAACoOaUUAAAAADXn2/cAAAAA+qhSqZQhQ4ZUt3sTpRQAAABAH9XY2JiTTjqp6BirZfoeAAAAADWnlAIAAACg5kzfAwAAAOijyuVyZs6cmSSZOHFiGhsbiw30F5RSAAAAAH1UpVLJwoULq9u9iel7AAAAANScUgoAAACAmlNKAQAAAFBzSikAAAAAak4pBQAAAEDN+fY9AAAAgD6spaWl6AirpZQCAAAA6KOampryuc99rugYq2X6HgAAAAA1p5QCAAAAoOZM3wMAAADoo8rlcr73ve8lSY466qg0NjYWnOg1SikAAACAPqpSqeSpp56qbvcmpu8BAAAAUHNKKQAAAABqTikFAAAAQM0ppQAAAACoOaUUAAAAADXn2/cAAAAA+rDGxsaiI6yWUgoAAOgTWltb09bWVnQM/sKSJUuycuXKomNAv9bU1JQvfOELRcdYLaUUAADwttfa2pozzzkzzy1/rugo/IW2l9vy8LyHs/5e62dQBhUdB+hllFIAAMDbXltbW55b/lwG7DAgLUNbio7D/+l8sjMrHl6RcrlcdBSgF1JKAQAAfUbL0JYM2sCInN5i+QvLi44A/V57e3t+8IMfJEk++tGPpqGh91RBvScJAAAAAD2qs7Mz8+fPr273JnVFBwAAAACg/3lblFLTpk3LqFGjss4662SPPfbIb37zm6IjAQAAALAGen0p9f3vfz+nnHJKzjjjjNxzzz3ZaaedMn78+Dz77LNFRwMAAACgm3p9KXX++efn+OOPz7HHHpsxY8bk4osvTktLSy6//PKiowEAAADQTb26lFq5cmXmzp2bcePGVffV1dVl3LhxmTNnToHJAAAAAFgTvfrb95577rl0dHRkxIgRXfaPGDEiv/3tb1f7mhUrVmTFihXV562trUmSZcuWrb2gNfLSSy9l5YqVeXHRi1nRtuLNX0BN/Kn1T2lb3pYnnngiL730UtFx+AuVSiWlUqnoGPwVP5feyc+ld/Jz6b38bHqfZ599Nm0vt6V+Ub2/lXuR1iWt6WzvTOuS1jTWNRYdh//j59I7/an1T1m5YmVeeumlDBw4sMeuu3LlyrzyyitJXu1Gmpqaeuzar+fPHUylUnnD83p1KdUdU6ZMyZe+9KVV9m+66aYFpKE/ueaya4qOAAAAvdLv7/p90RFYDT+X3umqi69aa9c+66yz1tq1V+ell17KkCFDXvd4ry6lNtxww9TX12fJkiVd9i9ZsiQjR45c7WsmT56cU045pfq8s7Mzzz//fDbYYIOa/9esZcuWZdNNN83TTz+dwYMH1/S9oS9yT0HPck9Bz3E/Qc9yT0HPqvU9ValU8tJLL2XjjTd+w/N6dSnV1NSUXXfdNbNmzcqECROSvFoyzZo1K5/61KdW+5rm5uY0Nzd32Td06NC1nPSNDR482P+RQg9yT0HPck9Bz3E/Qc9yT0HPquU99UYjpP6sV5dSSXLKKafkmGOOyW677Zbdd9893/jGN/Lyyy/n2GOPLToaAAAAAN3U60upI444IkuXLs3pp5+exYsXZ+edd86NN964yuLnAAAAALx99PpSKkk+9alPve50vd6subk5Z5xxxirTCYHucU9Bz3JPQc9xP0HPck9Bz+qt91Sp8mbfzwcAAAAAPayu6AAAAAAA9D9KKQAAAABqTikFAAAAQM0ppd6iJ598Mscdd1y22GKLDBgwIO9617tyxhlnZOXKlV3OKZVKqzzuuOOOLte65pprss0222SdddbJDjvskJ///OddjlcqlZx++unZaKONMmDAgIwbNy7z58+vyeeEWvlb7qkkeeCBB/K+970v66yzTjbddNOcffbZq1zLPQWv+upXv5q/+7u/S0tLS4YOHbrac1b3e+rqq6/ucs6tt96aXXbZJc3Nzdlyyy0zc+bMVa4zbdq0jBo1Kuuss0722GOP/OY3v1kLnwiK9bfcUwsWLMjBBx+clpaWDB8+PJ/73OfS3t7e5Rz3FKzeqFGjVvmddNZZZ3U5pyf+FoT+rLf+flFKvUW//e1v09nZmUsuuSQPP/xwLrjgglx88cX5whe+sMq5t9xySxYtWlR97LrrrtVjv/71r/Oxj30sxx13XO69995MmDAhEyZMyEMPPVQ95+yzz86FF16Yiy++OHfeeWcGDhyY8ePH55VXXqnJZ4Va+FvuqWXLluWAAw7I5ptvnrlz5+acc87JF7/4xXzrW9+qnuOegtesXLkyH/nIR/LJT37yDc+bMWNGl99TEyZMqB77/e9/n4MPPjj77LNP7rvvvpx00kn5l3/5l9x0003Vc77//e/nlFNOyRlnnJF77rknO+20U8aPH59nn312bX00KMSb3VMdHR05+OCDs3Llyvz617/OFVdckZkzZ+b000+vnuOegjf25S9/ucvvpE9/+tPVYz31tyD0V73690uFNXb22WdXtthii+rz3//+95UklXvvvfd1X/PRj360cvDBB3fZt8cee1T+7d/+rVKpVCqdnZ2VkSNHVs4555zq8RdffLHS3Nxcueqqq3r2A0Av89f31EUXXVRZb731KitWrKju+/d///fK1ltvXX3unoJVzZgxozJkyJDVHktS+fGPf/y6r/385z9f2W677brsO+KIIyrjx4+vPt99990rkyZNqj7v6OiobLzxxpUpU6asUW7orV7vnvr5z39eqaurqyxevLi6b/r06ZXBgwdXf3e5p+D1bb755pULLrjgdY/3xN+C0J/15t8vRkr1gNbW1qy//vqr7P+Hf/iHDB8+PHvttVd+8pOfdDk2Z86cjBs3rsu+8ePHZ86cOUle/a9pixcv7nLOkCFDsscee1TPgb7qr++pOXPm5O///u/T1NRU3Td+/PjMmzcvL7zwQvUc9xS8NZMmTcqGG26Y3XffPZdffnkqlUr12JvdUytXrszcuXO7nFNXV5dx48a5p+h35syZkx122CEjRoyo7hs/fnyWLVuWhx9+uHqOewpe31lnnZUNNtgg7373u3POOed0mf7aE38LQn/V23+/NBQd4O3u8ccfz3/913/l3HPPre5bd911c95552XPPfdMXV1dfvSjH2XChAm57rrr8g//8A9JksWLF3f5wyVJRowYkcWLF1eP/3nf650DfdHq7qnFixdniy226HLen++NxYsXZ7311nNPwVv05S9/Ofvuu29aWlryP//zPznhhBOyfPnyfOYzn0ny+r+nli1blj/96U954YUX0tHRsdpzfvvb39bsc0Bv8Hr3y5+PvdE57ilIPvOZz2SXXXbJ+uuvn1//+teZPHlyFi1alPPPPz9Jz/wtCP3Vc88916t/vxgp9X/+3//7f6td9PUvH3/9A/vDH/6QD3zgA/nIRz6S448/vrp/ww03zCmnnJI99tgj73nPe3LWWWfl4x//eM4555xafywoTE/eU0D37qk3ctppp2XPPffMu9/97vz7v/97Pv/5z/s9Rb/S0/cU0NVbucdOOeWU7L333tlxxx3ziU98Iuedd17+67/+KytWrCj4UwBrm5FS/+ezn/1sJk6c+IbnvPOd76xuL1y4MPvss0/+7u/+rssCe69njz32yM0331x9PnLkyCxZsqTLOUuWLMnIkSOrx/+8b6ONNupyzs477/ym7wdF68l76vXulz8fe6Nz3FP0FW/1nnqr9thjj5x55plZsWJFmpubX/eeGjx4cAYMGJD6+vrU19e/4X0HvVlP3lMjR45c5VuM/tbfU+4p+qo1ucf22GOPtLe358knn8zWW2/dI38LQn+14YYb9urfL0qp/zNs2LAMGzbsbzr3D3/4Q/bZZ5/suuuumTFjRurq3nzA2X333dflX4THjh2bWbNm5aSTTqruu/nmmzN27NgkyRZbbJGRI0dm1qxZ1X9hXrZsWe688843/TYl6A168p4aO3Zs/uM//iPlcjmNjY1JXr1ftt5666y33nrVc9xT9GVv5Z7qjvvuuy/rrbdempubk7x6T/31V2n/5T3V1NSUXXfdNbNmzap+a19nZ2dmzZqVT33qU2stJ/SUnrynxo4dm69+9at59tlnM3z48CSv3i+DBw/OmDFjque4p+hP1uQeu++++1JXV1e9n3rib0Hor3r975eiV1p/u3nmmWcqW265ZWW//farPPPMM5VFixZVH382c+bMypVXXll59NFHK48++mjlq1/9aqWurq5y+eWXV8+5/fbbKw0NDZVzzz238uijj1bOOOOMSmNjY+XBBx+snnPWWWdVhg4dWrn++usrDzzwQOWQQw6pbLHFFpU//elPNf3MsDb9LffUiy++WBkxYkTln/7pnyoPPfRQ5eqrr660tLRULrnkkuo57il4zVNPPVW59957K1/60pcq6667buXee++t3HvvvZWXXnqpUqlUKj/5yU8q//3f/1158MEHK/Pnz69cdNFFlZaWlsrpp59evcbvfve7SktLS+Vzn/tc5dFHH61MmzatUl9fX7nxxhur51x99dWV5ubmysyZMyuPPPJI5V//9V8rQ4cO7fINZNAXvNk91d7eXtl+++0rBxxwQOW+++6r3HjjjZVhw4ZVJk+eXL2GewpW79e//nXlggsuqNx3332VJ554ovLd7363MmzYsMrRRx9dPaen/haE/qo3/35RSr1FM2bMqCRZ7ePPZs6cWdl2220rLS0tlcGDB1d23333yjXXXLPKtX7wgx9Uttpqq0pTU1Nlu+22q/x//9//1+V4Z2dn5bTTTquMGDGi0tzcXNlvv/0q8+bNW+ufEWrpb7mnKpVK5f7776/stddelebm5so73vGOyllnnbXKtdxT8KpjjjlmtffU7NmzK5VKpXLDDTdUdt5558q6665bGThwYGWnnXaqXHzxxZWOjo4u15k9e3Zl5513rjQ1NVXe+c53VmbMmLHKe/3Xf/1XZbPNNqs0NTVVdt9998odd9xRg08ItfVm91SlUqk8+eSTlQMPPLAyYMCAyoYbblj57Gc/WymXy12u456CVc2dO7eyxx57VIYMGVJZZ511Kttuu23la1/7WuWVV17pcl5P/C0I/Vlv/f1SqlT+4vufAQAAAKAGfPseAAAAADWnlAIAAACg5pRSAAAAANScUgoAAACAmlNKAQAAAFBzSikAAAAAak4pBQAAAEDNKaUAAAAAqDmlFAAAAAA1p5QCAHqlUqmU6667rvr8t7/9bd773vdmnXXWyc477/y6+/qa6667LltuuWXq6+tz0kknFR0HAKDHKKUAgJqZOHFiSqVSSqVSGhsbM2LEiOy///65/PLL09nZ2eXcRYsW5cADD6w+P+OMMzJw4MDMmzcvs2bNet19fc2//du/5cMf/nCefvrpnHnmmUXHSZL86U9/yhlnnJGtttoqzc3N2XDDDfORj3wkDz/8cLev+eSTT6ZUKuW+++7ruaAAQK+mlAIAauoDH/hAFi1alCeffDI33HBD9tlnn5x44on54Ac/mPb29up5I0eOTHNzc/X5E088kb322iubb755Nthgg9fd91atXLlyzT7QWrR8+fI8++yzGT9+fDbeeOMMGjRolXM6OjpWKfTWphUrVmTcuHG5/PLL85WvfCWPPfZYfv7zn6e9vT177LFH7rjjjppleT3lcrnoCADA30ApBQDUVHNzc0aOHJl3vOMd2WWXXfKFL3wh119/fW644YbMnDmzet5fTt8rlUqZO3duvvzlL6dUKuWLX/ziavclydNPP52PfvSjGTp0aNZff/0ccsghefLJJ6vXnThxYiZMmJCvfvWr2XjjjbP11lu/pdede+652WijjbLBBhtk0qRJXQqQFStW5N///d+z6aabprm5OVtuuWUuu+yy6vGHHnooBx54YNZdd92MGDEi//RP/5Tnnntutf+cbr311moJte+++6ZUKuXWW2/NzJkzM3To0PzkJz/JmDFj0tzcnAULFuSFF17I0UcfnfXWWy8tLS058MADM3/+/Or1/vy6n/3sZ9l6663T0tKSD3/4w2lra8sVV1yRUaNGZb311stnPvOZdHR0vO7P7xvf+EbmzJmTn/3sZ/noRz+azTffPLvvvnt+9KMfZdttt81xxx2XSqWy2te+8MILOeqoozJs2LAMGDAgo0ePzowZM5IkW2yxRZLk3e9+d0qlUvbee+8kyV133ZX9998/G264YYYMGZL3v//9ueeee7pct1QqZfr06fmHf/iHDBw4MF/96ldfNz8A0HsopQCAwu27777Zaaedcu211672+KJFi7Lddtvls5/9bBYtWpRTTz11tfvK5XLGjx+fQYMG5Ze//GVuv/32rLvuuvnABz7QZUTUrFmzMm/evNx888352c9+9je/bvbs2XniiScye/bsXHHFFZk5c2aXIu3oo4/OVVddlQsvvDCPPvpoLrnkkqy77rpJkhdffDH77rtv3v3ud+fuu+/OjTfemCVLluSjH/3oaj/z3/3d32XevHlJkh/96EdZtGhR/u7v/i5J0tbWlq9//eu59NJL8/DDD2f48OGZOHFi7r777vzkJz/JnDlzUqlUctBBB3Upzdra2nLhhRfm6quvzo033phbb701hx56aH7+85/n5z//eb7zne/kkksuyQ9/+MPX/VldeeWV2X///bPTTjt12V9XV5eTTz45jzzySO6///7Vvva0007LI488khtuuCGPPvpopk+fng033DBJ8pvf/CZJcsstt2TRokXV/y289NJLOeaYY/KrX/0qd9xxR0aPHp2DDjooL730Updrf/GLX8yhhx6aBx98MP/8z//8uvkBgN6joegAAABJss022+SBBx5Y7bGRI0emoaEh6667bkaOHJkkWXfddVfZ993vfjednZ259NJLUyqVkiQzZszI0KFDc+utt+aAAw5IkgwcODCXXnppmpqa3tLr1ltvvXzzm99MfX19ttlmmxx88MGZNWtWjj/++Dz22GP5wQ9+kJtvvjnjxo1Lkrzzne+sfoZvfvObefe7352vfe1r1X2XX355Nt100zz22GPZaqutunzmpqamDB8+PEmy/vrrVz9j8ur0tIsuuqhaDM2fPz8/+clPcvvtt1eLq+9973vZdNNNc9111+UjH/lI9XXTp0/Pu971riTJhz/84XznO9/JkiVLsu6662bMmDHZZ599Mnv27BxxxBGr/Vk89thj2WeffVZ7bNttt62es7qF5xcsWJB3v/vd2W233ZIko0aNqh4bNmxYkmSDDTbo8ln33XffLtf41re+laFDh+a2227LBz/4wer+I488Mscee+xqcwEAvZNSCgDoFSqVSrUQ6q77778/jz/++CprL73yyit54oknqs932GGHaiH1Vl633Xbbpb6+vvp8o402yoMPPpgkue+++1JfX5/3v//9r5tt9uzZ1ZFTf+mJJ55YpZR6I01NTdlxxx2rzx999NE0NDRkjz32qO7bYIMNsvXWW+fRRx+t7mtpaakWUkkyYsSIjBo1qkumESNG5Nlnn33D93+96Xl/mW91PvnJT+bwww/PPffckwMOOCATJkyolmivZ8mSJfnP//zP3HrrrXn22WfT0dGRtra2LFiwoMt5fy66AIC3D6UUANArPProo9V1hbpr+fLl2XXXXfO9731vlWN/HomTvDpSqjuva2xs7HKsVCpVFxkfMGDAm2b70Ic+lK9//eurHNtoo43e8LV/bcCAAd0q8FaX/40+0+qMHj26S9H1l/68//UKtgMPPDBPPfVUfv7zn+fmm2/Ofvvtl0mTJuXcc8993fc75phj8sc//jFTp07N5ptvnubm5owdO3aVBer/+mcKAPR+1pQCAAr3i1/8Ig8++GAOP/zwNbrOLrvskvnz52f48OHZcsstuzyGDBnS46/7SzvssEM6Oztz2223ve57PPzwwxk1atQq77Gmhcq2226b9vb23HnnndV9f/zjHzNv3ryMGTNmja791z72sY/llltuWWXdqM7OzlxwwQXZbbfd3vA9hw0blmOOOSbf/e53841vfCPf+ta3krw2uuqvF1m//fbb85nPfCYHHXRQtttuuzQ3N7/u4vAAwNuLUgoAqKkVK1Zk8eLF+cMf/pB77rknX/va13LIIYfkgx/8YI4++ug1uvZRRx2VDTfcMIccckh++ctf5ve//31uvfXWfOYzn8kzzzzT46/7S6NGjcoxxxyTf/7nf851111XvcYPfvCDJMmkSZPy/PPP52Mf+1juuuuuPPHEE7npppty7LHHvuG33f0tRo8enUMOOSTHH398fvWrX+X+++/Pxz/+8bzjHe/IIYccskbX/msnn3xydt9993zoQx/KNddckwULFuSuu+7K4Ycfnvnz5+eKK6543deefvrpuf766/P444/n4Ycfzs9+9rPqOlTDhw/PgAEDqgvAt7a2Vj/bd77znTz66KO58847c9RRR73pqDQA4O1BKQUA1NSNN96YjTbaKKNGjcoHPvCBzJ49OxdeeGGuv/76Lus1dUdLS0v+93//N5tttlkOO+ywbLvttjnuuOPyyiuvZPDgwT3+ur82ffr0fPjDH84JJ5yQbbbZJscff3xefvnlJMnGG2+c22+/PR0dHTnggAOyww475KSTTsrQoUNTV7fmf5LNmDEju+66az74wQ9m7NixqVQq+fnPf77K9Lw1tc4662TWrFk5+uijM3ny5LzrXe/K7rvvnoceeigPPfTQG46SampqyuTJk7Pjjjvm7//+71NfX5+rr746SdLQ0JALL7wwl1xySTbeeONqmXbZZZflhRdeyC677JJ/+qd/ymc+85nqAvAAwNtbqfJmK1UCAMAbuOGGG3LooYfm3HPPzac+9ami4wAAbxNGSgEAsEYOPPDA3HDDDXn++eet9wQA/M2MlAIAAACg5oyUAgAAAKDmlFIAAAAA1JxSCgAAAICaU0oBAAAAUHNKKQAAAABqTikFAAAAQM0ppQAAAACoOaUUAAAAADWnlAIAAACg5pRSAAAAANScUgoAAACAmlNKAQAAAFBzSikAAAAAak4pBQAAAEDNKaUAAAAAqDmlFADAWjJz5syUSqXcfffda3Sdtra2fPGLX8ytt97aM8EAAHoBpRQAQC/X1taWL33pS0opAKBPUUoBAAAAUHNKKQCAgqxcuTKnn356dt111wwZMiQDBw7M+973vsyePbt6zpNPPplhw4YlSb70pS+lVCqlVCrli1/8YvWc3/72t/nwhz+c9ddfP+uss0522223/OQnP6n1xwEAeEuUUgAABVm2bFkuvfTS7L333vn617+eL37xi1m6dGnGjx+f++67L0kybNiwTJ8+PUly6KGH5jvf+U6+853v5LDDDkuSPPzww3nve9+bRx99NP/v//2/nHfeeRk4cGAmTJiQH//4x0V9NACAN1WqVCqVokMAAPRFM2fOzLHHHpu77roru+222yrHOzo60tHRkaampuq+F198Mdtss00OPvjgXHbZZUmS5557LsOGDcsZZ5zRZYRUkowbNy7PPvts7rrrrjQ3NydJKpVK9tprryxdujSPPfbY2vuAAABrwEgpAICC1NfXVwupzs7OPP/882lvb89uu+2We+65501f//zzz+cXv/hFPvrRj+all17Kc889l+eeey5//OMfM378+MyfPz9/+MMf1vbHAADoloaiAwAA9GdXXHFFzjvvvPz2t79NuVyu7t9iiy3e9LWPP/54KpVKTjvttJx22mmrPefZZ5/NO97xjh7LCwDQU5RSAAAF+e53v5uJEydmwoQJ+dznPpfhw4envr4+U6ZMyRNPPPGmr+/s7EySnHrqqRk/fvxqz9lyyy17NDMAQE9RSgEAFOSHP/xh3vnOd+baa69NqVSq7j/jjDO6nPeXx/7SO9/5ziRJY2Njxo0bt/aCAgCsBdaUAgAoSH19fZJXFyb/szvvvDNz5szpcl5LS0uSVxdB/0vDhw/P3nvvnUsuuSSLFi1a5fpLly7t4cQAAD3HSCkAgLXs8ssvz4033rjK/r333jvXXnttDj300Bx88MH5/e9/n4svvjhjxozJ8uXLq+cNGDAgY8aMyfe///1stdVWWX/99bP99ttn++23z7Rp07LXXntlhx12yPHHH593vvOdWbJkSebMmZNnnnkm999/fy0/KgDA30wpBQCwlk2fPn21+xcsWJDly5fnkksuyU033ZQxY8bku9/9bq655prceuutXc699NJL8+lPfzonn3xyVq5cmTPOOCPbb799xowZk7vvvjtf+tKXMnPmzPzxj3/M8OHD8+53vzunn356DT4dAED3lCp/OV4cAAAAAGrAmlIAAAAA1JxSCgAAAICaU0oBAAAAUHNKKQAAAABqTikFAAAAQM0ppQAAAACouYaiA6xtnZ2dWbhwYQYNGpRSqVR0HAAAAIA+rVKp5KWXXsrGG2+currXHw/V50uphQsXZtNNNy06BgAAAEC/8vTTT2eTTTZ53eN9vpQaNGhQklf/QQwePLjgNAAAAADFWblyZc4777wkyWc/+9k0NTX1+HssW7Ysm266abWTeT19vpT685S9wYMHK6UAAACAfm3lypVZZ511krzalayNUurP3mwZJQudAwAAAFBzSikAAAAAaq7PT98DAAAA4FUNDQ35l3/5l+p2oVkKfXcAAAAAaqauri7veMc7io6RxPQ9AAAAAApgpBQAAABAP9HR0ZE77rgjSfLe97439fX1hWVRSgEAAAD0Ex0dHbnllluSJO95z3sKLaVM3wMAAACg5pRSAAAAANScUgoAAACAmlNKAQAAAFBzSikAAAAAak4pBQAAAEDNNRQdAAAAAIDaaGhoyDHHHFPdLjRLoe8OAAAAQM3U1dVl1KhRRcdIYvoeAAAAAAUwUgoAAACgn+jo6MjcuXOTJLvuumvq6+sLy6KUAgAAAOgnOjo6csMNNyRJdt5550JLKdP3AAAAAKg5I6XeZlpbW9PW1lZ0DP5KS0tLhgwZUnQMAAAAeNtQSr2NtLa25ptnnpnyc88VHYW/0rjhhvnUaacppgAAAOBvpJR6G2lra0v5uedy2IABGdbSUnQc/s/StrZc+9xzaWtrU0oBAADA30gp9TY0rKUlGw0aVHQM/tKf/lR0AgAAAHhbsdA5AAAAADVnpBQAAABAP9HQ0JCPfexj1e1CsxT67gAAAADUTF1dXbbaaquiYyQxfQ8AAACAAhgpBQAAANBPdHR05MEHH0yS7LDDDqmvry8si1IKAAAAoJ/o6OjI9ddfnyQZM2ZMoaWU6XsAAAAA1JxSCgAAAICaU0oBAAAAUHNKKQAAAABqTikFAAAAQM0ppQAAAACouYaiAwAAAABQGw0NDfnwhz9c3S40S6HvDgAAAEDN1NXVZbvttis6RhLT9wAAAAAogJFSAAAAAP1EZ2dnHn300STJtttum7q64sYrGSkFAAAA0E+0t7fnhz/8YX74wx+mvb290CxKKQAAAABqTikFAAAAQM0ppQAAAACoOaUUAAAAADWnlAIAAACg5pRSAAAAANRcQ9EBAAAAAKiN+vr6HHLIIdXtIimlAAAAAPqJ+vr67LzzzkXHSGL6HgAAAAAFMFIKAAAAoJ/o7OzM448/niTZcsstU1dX3HglI6UAAAAA+on29vZcddVVueqqq9Le3l5oFqUUAAAAADWnlAIAAACg5pRSAAAAANScUgoAAACAmlNKAQAAAFBzSikAAAAAaq6h6AAAAAAA1EZ9fX0OPPDA6naRlFIAAAAA/UR9fX123333omMkMX0PAAAAgAIYKQUAAADQT3R2dmbBggVJks022yx1dcWNVzJSCgAAAKCfaG9vzxVXXJErrrgi7e3thWZRSgEAAABQc0opAAAAAGpOKQUAAABAzSmlAAAAAKi5XlNKnXXWWSmVSjnppJOq+1555ZVMmjQpG2ywQdZdd90cfvjhWbJkSXEhAQAAAOgRvaKUuuuuu3LJJZdkxx137LL/5JNPzk9/+tNcc801ue2227Jw4cIcdthhBaUEAAAAoKcUXkotX748Rx11VP77v/876623XnV/a2trLrvsspx//vnZd999s+uuu2bGjBn59a9/nTvuuKPAxAAAAABvT/X19Rk3blzGjRuX+vr6QrMUXkpNmjQpBx98cMaNG9dl/9y5c1Mul7vs32abbbLZZptlzpw5tY4JAAAA8LZXX1+fPffcM3vuuWfhpVRDkW9+9dVX55577sldd921yrHFixenqakpQ4cO7bJ/xIgRWbx48etec8WKFVmxYkX1+bJly3osLwAAAAA9o7CRUk8//XROPPHEfO9738s666zTY9edMmVKhgwZUn1suummPXZtAAAAgLezzs7O/OEPf8gf/vCHdHZ2FpqlsFJq7ty5efbZZ7PLLrukoaEhDQ0Nue2223LhhRemoaEhI0aMyMqVK/Piiy92ed2SJUsycuTI173u5MmT09raWn08/fTTa/mTAAAAALw9tLe359JLL82ll16a9vb2QrMUNn1vv/32y4MPPthl37HHHpttttkm//7v/55NN900jY2NmTVrVg4//PAkybx587JgwYKMHTv2da/b3Nyc5ubmtZodAAAAgDVTWCk1aNCgbL/99l32DRw4MBtssEF1/3HHHZdTTjkl66+/fgYPHpxPf/rTGTt2bN773vcWERkAAACAHlLoQudv5oILLkhdXV0OP/zwrFixIuPHj89FF11UdCwAAAAA1lCvKqVuvfXWLs/XWWedTJs2LdOmTSsmEAAAAABrRWELnQMAAADQfymlAAAAAKi5XjV9DwAAAIC1p76+Pu9///ur20VSSgEAAAD0E/X19dl7772LjpHE9D0AAAAACmCkFAAAAEA/UalUsnTp0iTJsGHDUiqVCstipBQAAABAP1EulzN9+vRMnz495XK50CxKKQAAAABqTikFAAAAQM0ppQAAAACoOaUUAAAAADWnlAIAAACg5pRSAAAAANRcQ9EBAAAAAKiN+vr6jB07trpdJKUUAAAAQD9RX1+fAw44oOgYSUzfAwAAAKAARkoBAAAA9BOVSiWtra1JkiFDhqRUKhWWxUgpAAAAgH6iXC5n6tSpmTp1asrlcqFZlFIAAAAA1JxSCgAAAICaU0oBAAAAUHNKKQAAAABqTikFAAAAQM0ppQAAAACouYaiAwAAAABQG3V1ddltt92q20VSSgEAAAD0Ew0NDTn44IOLjpHE9D0AAAAACmCkFAAAAEA/UalU0tbWliRpaWlJqVQqLIuRUgAAAAD9RLlczrnnnptzzz035XK50CxKKQAAAABqTikFAAAAQM0ppQAAAACoOaUUAAAAADWnlAIAAACg5pRSAAAAANRcQ9EBAAAAAKiNurq67LTTTtXtIimlAAAAAPqJhoaGTJgwoegYSUzfAwAAAKAARkoBAAAA9BOVSiXlcjlJ0tjYmFKpVFgWI6UAAAAA+olyuZwpU6ZkypQp1XKqKEopAAAAAGpOKQUAAABAzSmlAAAAAKg5pRQAAAAANaeUAgAAAKDmlFIAAAAA1FxD0QEAAAAAqI26urqMGTOmul0kpRQAAABAP9HQ0JCPfOQjRcdIYvoeAAAAAAVQSgEAAABQc6bvAQAAAPQTK1euzJQpU5IkkydPTlNTU2FZjJQCAAAAoOaUUgAAAADUnFIKAAAAgJpTSgEAAABQc0opAAAAAGpOKQUAAABAzTUUHQAAAACA2qirq8vo0aOr20VSSgEAAAD0Ew0NDTnyyCOLjpHE9D0AAAAACqCUAgAAAKDmTN8DAAAA6CdWrlyZc889N0ly6qmnpqmpqbAsSikAAACAfqRcLhcdIYnpewAAAAAUQCkFAAAAQM0ppQAAAACoOaUUAAAAADWnlAIAAACg5nz7HgAAAEA/USqVsvnmm1e3i6SUAgAAAOgnGhsbM3HixKJjJDF9DwAAAIACKKUAAAAAqDnT9wAAAAD6iZUrV2bq1KlJkhNPPDFNTU2FZVFKAQAAAPQjbW1tRUdIYvoeAAAAAAVQSgEAAABQc0opAAAAAGpOKQUAAABAzSmlAAAAAKg5374HAAAA0E+USqVsvPHG1e0iKaUAAAAA+onGxsYcf/zxRcdIYvoeAAAAAAVQSgEAAABQc6bvAQAAAPQT5XI506ZNS5JMmjQpjY2NhWVRSgEAAAD0E5VKJa2trdXtIpm+BwAAAEDNKaUAAAAAqDmlFAAAAAA1p5QCAAAAoOaUUgAAAADUnG/fAwAAAOgnSqVShg0bVt0uUqEjpaZPn54dd9wxgwcPzuDBgzN27NjccMMN1eOvvPJKJk2alA022CDrrrtuDj/88CxZsqTAxAAAAABvX42NjTnhhBNywgknpLGxsdAshZZSm2yySc4666zMnTs3d999d/bdd98ccsghefjhh5MkJ598cn7605/mmmuuyW233ZaFCxfmsMMOKzIyAAAAAD2g0Ol7H/rQh7o8/+pXv5rp06fnjjvuyCabbJLLLrssV155Zfbdd98kyYwZM7LtttvmjjvuyHvf+94iIgMAAADQA3rNQucdHR25+uqr8/LLL2fs2LGZO3duyuVyxo0bVz1nm222yWabbZY5c+a87nVWrFiRZcuWdXkAAAAAkJTL5Vx00UW56KKLUi6XC81SeCn14IMPZt11101zc3M+8YlP5Mc//nHGjBmTxYsXp6mpKUOHDu1y/ogRI7J48eLXvd6UKVMyZMiQ6mPTTTddy58AAAAA4O2hUqlk6dKlWbp0aSqVSqFZCi+ltt5669x33325884788lPfjLHHHNMHnnkkW5fb/LkyWltba0+nn766R5MCwAAAEBPKHRNqSRpamrKlltumSTZddddc9ddd2Xq1Kk54ogjsnLlyrz44otdRkstWbIkI0eOfN3rNTc3p7m5eW3HBgAAAGANFD5S6q91dnZmxYoV2XXXXdPY2JhZs2ZVj82bNy8LFizI2LFjC0wIAAAAwJoqdKTU5MmTc+CBB2azzTbLSy+9lCuvvDK33nprbrrppgwZMiTHHXdcTjnllKy//voZPHhwPv3pT2fs2LG+eQ8AAADgba7QUurZZ5/N0UcfnUWLFmXIkCHZcccdc9NNN2X//fdPklxwwQWpq6vL4YcfnhUrVmT8+PG56KKLiowMAAAAQA8otJS67LLL3vD4Ouusk2nTpmXatGk1SgQAAADQd5VKpQwZMqS6XaTCFzoHAAAAoDYaGxtz0kknFR0jSS9c6BwAAACAvk8pBQAAAEDNmb4HAAAA0E+Uy+XMnDkzSTJx4sQ0NjYWlkUpBQAAANBPVCqVLFy4sLpdJNP3AAAAAKg5pRQAAAAANaeUAgAAAKDmlFIAAAAA1JxSCgAAAICa8+17AAAAAP1IS0tL0RGSKKUAAAAA+o2mpqZ87nOfKzpGEtP3AAAAACiAUgoAAACAmjN9DwAAAKCfKJfL+d73vpckOeqoo9LY2FhYFqUUAAAAQD9RqVTy1FNPVbeLZPoeAAAAADWnlAIAAACg5pRSAAAAANScUgoAAACAmlNKAQAAAFBzvn0PAAAAoB9pbGwsOkISpRQAAABAv9HU1JQvfOELRcdIYvoeAAAAAAVQSgEAAABQc90qpX73u9/1dA4AAAAA1rL29vZceeWVufLKK9Pe3l5olm6VUltuuWX22WeffPe7380rr7zS05kAAAAAWAs6Ozszf/78zJ8/P52dnYVm6VYpdc8992THHXfMKaeckpEjR+bf/u3f8pvf/KanswEAAADQR3WrlNp5550zderULFy4MJdffnkWLVqUvfbaK9tvv33OP//8LF26tKdzAgAAANCHrNFC5w0NDTnssMNyzTXX5Otf/3oef/zxnHrqqdl0001z9NFHZ9GiRT2VEwAAAIA+ZI1KqbvvvjsnnHBCNtpoo5x//vk59dRT88QTT+Tmm2/OwoULc8ghh/RUTgAAAAD6kIbuvOj888/PjBkzMm/evBx00EH59re/nYMOOih1da92XFtssUVmzpyZUaNG9WRWAAAAAPqIbpVS06dPzz//8z9n4sSJ2WijjVZ7zvDhw3PZZZetUTgAAAAA+qZulVLz589/03OamppyzDHHdOfyAAAAAKwFTU1NOeOMM4qOkaSba0rNmDEj11xzzSr7r7nmmlxxxRVrHAoAAACAvq1bpdSUKVOy4YYbrrJ/+PDh+drXvrbGoQAAAADo27o1fW/BggXZYostVtm/+eabZ8GCBWscCgAAAICe197enh//+MdJkkMPPTQNDd2qhnpEt0ZKDR8+PA888MAq+++///5ssMEGaxwKAAAAgJ7X2dmZRx55JI888kg6OzsLzdKtUupjH/tYPvOZz2T27Nnp6OhIR0dHfvGLX+TEE0/MP/7jP/Z0RgAAAAD6mG6N0TrzzDPz5JNPZr/99qsO8+rs7MzRRx9tTSkAAAAA3lS3SqmmpqZ8//vfz5lnnpn7778/AwYMyA477JDNN9+8p/MBAAAA0Aet0WpWW221VbbaaqueygIAAABAP9GtUqqjoyMzZ87MrFmz8uyzz66yMNYvfvGLHgkHAAAAQN/UrVLqxBNPzMyZM3PwwQdn++23T6lU6ulcAAAAwFrS2tqatra2omPwV1paWjJkyJCiY9RMt0qpq6++Oj/4wQ9y0EEH9XQeAAAAYC1qbW3NN888M+Xnnis6Cn+lccMN86nTTlurxVRjY2MmT55c3S5Stxc633LLLXs6CwAAALCWtbW1pfzcczlswIAMa2kpOg7/Z2lbW6597rm0tbWt1VKqVCqlqalprV3/rehWKfXZz342U6dOzTe/+U1T9wAAAOBtaFhLSzYaNKjoGPylP/2p6AQ11a1S6le/+lVmz56dG264Idttt90qw72uvfbaHgkHAAAAQM9pb2/Pz372syTJBz/4wTQ0dKsa6hHdeuehQ4fm0EMP7eksAAAAAKxFnZ2duf/++5Ok8LXCu1VKzZgxo6dzAAAAANCP1HX3he3t7bnllltyySWX5KWXXkqSLFy4MMuXL++xcAAAAAD0Td0aKfXUU0/lAx/4QBYsWJAVK1Zk//33z6BBg/L1r389K1asyMUXX9zTOQEAAADoQ7o1UurEE0/MbrvtlhdeeCEDBgyo7j/00EMza9asHgsHAAAAQN/UrZFSv/zlL/PrX/86TU1NXfaPGjUqf/jDH3okGAAAAAB9V7dGSnV2dqajo2OV/c8880wGDRq0xqEAAAAA6Nu6NVLqgAMOyDe+8Y1861vfSpKUSqUsX748Z5xxRuFfJwgAAADA6jU2NubUU0+tbhepW6XUeeedl/Hjx2fMmDF55ZVXcuSRR2b+/PnZcMMNc9VVV/V0RgAAAAB6QKlUysCBA4uOkaSbpdQmm2yS+++/P1dffXUeeOCBLF++PMcdd1yOOuqoLgufAwAAAMDqdKuUSpKGhoZ8/OMf78ksAAAAAKxF7e3tuemmm5Ik48ePT0NDt6uhNdatd/72t7/9hsePPvroboUBAAAAYO3p7OzM3XffnSTZf//9C83SrVLqxBNP7PK8XC6nra0tTU1NaWlpUUoBAAAA8IbquvOiF154octj+fLlmTdvXvbaay8LnQMAAADwprpVSq3O6NGjc9ZZZ60yigoAAAAA/lqPlVLJq4ufL1y4sCcvCQAAAEAf1K01pX7yk590eV6pVLJo0aJ885vfzJ577tkjwQAAAADou7pVSk2YMKHL81KplGHDhmXffffNeeed1xO5AAAAAOjDulVKdXZ29nQOAAAAANayxsbG6nrgjY2NhWbpVikFAAAAwNtPqVTK0KFDi46RpJul1CmnnPI3n3v++ed35y0AAAAA6MO6VUrde++9uffee1Mul7P11lsnSR577LHU19dnl112qZ5XKpV6JiUAAAAAa6yjoyOzZs1Kkuy3336pr68vLEu3SqkPfehDGTRoUK644oqst956SZIXXnghxx57bN73vvfls5/9bI+GBAAAAGDNdXR0ZM6cOUmSvffeu9BSqq47LzrvvPMyZcqUaiGVJOutt16+8pWv+PY9AAAAAN5Ut0qpZcuWZenSpavsX7p0aV566aU1DgUAAABA39atUurQQw/Nsccem2uvvTbPPPNMnnnmmfzoRz/Kcccdl8MOO6ynMwIAAADQx3RrTamLL744p556ao488siUy+VXL9TQkOOOOy7nnHNOjwYEAAAAoO/pVinV0tKSiy66KOecc06eeOKJJMm73vWuDBw4sEfDAQAAANA3dWv63p8tWrQoixYtyujRozNw4MBUKpWeygUAAABAH9atkVJ//OMf89GPfjSzZ89OqVTK/Pnz8853vjPHHXdc1ltvPd/ABwAAANALNTY25pOf/GR1u0jdGil18sknp7GxMQsWLEhLS0t1/xFHHJEbb7yxx8IBAAAA0HNKpVKGDx+e4cOHp1QqFZqlWyOl/ud//ic33XRTNtlkky77R48enaeeeqpHggEAAADQd3WrlHr55Ze7jJD6s+effz7Nzc1rHAoAAACAntfR0ZFf/vKXSZL3ve99qa+vLyxLt6bvve9978u3v/3t6vNSqZTOzs6cffbZ2WeffXosHAAAAAA9p6OjI7fddltuu+22dHR0FJqlWyOlzj777Oy33365++67s3Llynz+85/Pww8/nOeffz633357T2cEAAAAoI/p1kip7bffPo899lj22muvHHLIIXn55Zdz2GGH5d5778273vWuns4IAAAAQB/zlkdKlcvlfOADH8jFF1+c//iP/1gbmQAAAADo497ySKnGxsY88MADayMLAAAAAP1Et6bvffzjH89ll13W01kAAAAA6Ce6tdB5e3t7Lr/88txyyy3ZddddM3DgwC7Hzz///B4JBwAAAEDf9JZKqd/97ncZNWpUHnrooeyyyy5Jkscee6zLOaVSqefSAQAAANBjGhoa8i//8i/V7UKzvJWTR48enUWLFmX27NlJkiOOOCIXXnhhRowYsVbCAQAAANBz6urq8o53vKPoGEne4ppSlUqly/MbbrghL7/8crfffMqUKXnPe96TQYMGZfjw4ZkwYULmzZvX5ZxXXnklkyZNygYbbJB11103hx9+eJYsWdLt9wQAAACgeN1a6PzP/rqkeqtuu+22TJo0KXfccUduvvnmlMvlHHDAAV2KrpNPPjk//elPc8011+S2227LwoULc9hhh63R+wIAAAD0Rx0dHbn99ttz++23p6Ojo9Asb2n6XqlUWmXNqDVZQ+rGG2/s8nzmzJkZPnx45s6dm7//+79Pa2trLrvsslx55ZXZd999kyQzZszItttumzvuuCPvfe97u/3eAAAAAP1NR0dHbrnlliTJe97zntTX1xeW5S2VUpVKJRMnTkxzc3OSV6fWfeITn1jl2/euvfbaboVpbW1Nkqy//vpJkrlz56ZcLmfcuHHVc7bZZptsttlmmTNnjlIKAAAA4G3qLZVSxxxzTJfnH//4x3ssSGdnZ0466aTsueee2X777ZMkixcvTlNTU4YOHdrl3BEjRmTx4sWrvc6KFSuyYsWK6vNly5b1WEYAAAAAesZbKqVmzJixtnJk0qRJeeihh/KrX/1qja4zZcqUfOlLX+qhVAAAAACsDWu00HlP+dSnPpWf/exnmT17djbZZJPq/pEjR2blypV58cUXu5y/ZMmSjBw5crXXmjx5clpbW6uPp59+em1GBwAAAKAbCi2lKpVKPvWpT+XHP/5xfvGLX2SLLbbocnzXXXdNY2NjZs2aVd03b968LFiwIGPHjl3tNZubmzN48OAuDwAAAAB6l7c0fa+nTZo0KVdeeWWuv/76DBo0qLpO1JAhQzJgwIAMGTIkxx13XE455ZSsv/76GTx4cD796U9n7NixFjkHAAAAeBsrtJSaPn16kmTvvffusn/GjBmZOHFikuSCCy5IXV1dDj/88KxYsSLjx4/PRRddVOOkAAAAAG9/DQ0N1S+ya2gotBYqtpSqVCpves4666yTadOmZdq0aTVIBAAAANB31dXVZdSoUUXHSNJLFjoHAAAAoH8pdpwWAAAAADXT0dGRuXPnJnn1C+bq6+sLy6KUAgAAAOgnOjo6csMNNyRJdt55Z6UUAAAAfVNra2va2tqKjsFfWLJkSVauXFl0DFBKAQAAsHa0trbmm2eemfJzzxUdhb/wUltbfvfww3ll/fWTQYOKjkM/ppQCAABgrWhra0v5uedy2IABGdbSUnQc/s8jnZ35rxUr0l4uFx2Ffk4pBQAAwFo1rKUlGxmR02ssWb686AiQJKkrOgAAAAAA/Y9SCgAAAICaM30PAAAAoJ9oaGjIxz72sep2oVkKfXcAAAAAaqauri5bbbVV0TGSmL4HAAAAQAGMlAIAAADoJzo6OvLggw8mSXbYYYfU19cXlkUpBQAAANBPdHR05Prrr0+SjBkzptBSyvQ9AAAAAGpOKQUAAABAzSmlAAAAAKg5pRQAAAAANaeUAgAAAKDmlFIAAAAA1FxD0QEAAAAAqI2GhoZ8+MMfrm4XmqXQdwcAAACgZurq6rLddtsVHSOJ6XsAAAAAFMBIKQAAAIB+orOzM48++miSZNttt01dXXHjlYyUAgAAAOgn2tvb88Mf/jA//OEP097eXmgWpRQAAAAANaeUAgAAAKDmlFIAAAAA1JxSCgAAAICaU0oBAAAAUHNKKQAAAABqrqHoAAAAAADURn19fQ455JDqdpGUUgAAAAD9RH19fXbeeeeiYyQxfQ8AAACAAhgpBQAAANBPdHZ25vHHH0+SbLnllqmrK268kpFSAAAAAP1Ee3t7rrrqqlx11VVpb28vNItSCgAAAICaU0oBAAAAUHNKKQAAAABqTikFAAAAQM0ppQAAAACoOaUUAAAAADXXUHQAAAAAAGqjvr4+Bx54YHW7SEopAAAAgH6ivr4+u+++e9Exkpi+BwAAAEABjJQCAAAA6Cc6OzuzYMGCJMlmm22WurrixisZKQUAAADQT7S3t+eKK67IFVdckfb29kKzKKUAAAAAqDmlFAAAAAA1p5QCAAAAoOaUUgAAAADUnFIKAAAAgJpTSgEAAABQcw1FBwAAAACgNurr6zNu3LjqdpGUUgAAAAD9RH19ffbcc8+iYyQxfQ8AAACAAhgpBQAAANBPdHZ2ZtGiRUmSjTbaKHV1xY1XMlIKAAAAoJ9ob2/PpZdemksvvTTt7e2FZlFKAQAAAFBzSikAAAAAak4pBQAAAEDNKaUAAAAAqDmlFAAAAAA1p5QCAAAAoOYaig4AAAAAQG3U19fn/e9/f3W7SEopAAAAgH6ivr4+e++9d9Exkpi+BwAAAEABjJQCAAAA6CcqlUqWLl2aJBk2bFhKpVJhWYyUAgAAAOgnyuVypk+fnunTp6dcLheaRSkFAAAAQM0ppQAAAACoOaUUAAAAADWnlAIAAACg5pRSAAAAANScUgoAAACAmmsoOgAAAAAAtVFfX5+xY8dWt4uklAIAAADoJ+rr63PAAQcUHSOJ6XsAAAAAFMBIKQAAAIB+olKppLW1NUkyZMiQlEqlwrIYKQUAAADQT5TL5UydOjVTp05NuVwuNItSCgAAAICaU0oBAAAAUHNKKQAAAABqTikFAAAAQM0ppQAAAACoOaUUAAAAADXXUHQAAAAAAGqjrq4uu+22W3W7SEopAAAAgH6ioaEhBx98cNExkpi+BwAAAEABjJQCAAAA6CcqlUra2tqSJC0tLSmVSoVlMVIKAAAAoJ8ol8s599xzc+6556ZcLheapdBS6n//93/zoQ99KBtvvHFKpVKuu+66LscrlUpOP/30bLTRRhkwYEDGjRuX+fPnFxMWAAAAgB5TaCn18ssvZ6eddsq0adNWe/zss8/OhRdemIsvvjh33nlnBg4cmPHjx+eVV16pcVIAAAAAelKha0odeOCBOfDAA1d7rFKp5Bvf+Eb+8z//M4ccckiS5Nvf/nZGjBiR6667Lv/4j/9Yy6gAAAAA9KBeu6bU73//+yxevDjjxo2r7hsyZEj22GOPzJkz53Vft2LFiixbtqzLAwAAAIDepdeWUosXL06SjBgxosv+ESNGVI+tzpQpUzJkyJDqY9NNN12rOQEAAAB463ptKdVdkydPTmtra/Xx9NNPFx0JAAAAgL9S6JpSb2TkyJFJkiVLlmSjjTaq7l+yZEl23nnn131dc3Nzmpub13Y8AAAAgLedurq67LTTTtXtQrMU+u5vYIsttsjIkSMza9as6r5ly5blzjvvzNixYwtMBgAAAPD21NDQkAkTJmTChAlpaCh2rFKh7758+fI8/vjj1ee///3vc99992X99dfPZpttlpNOOilf+cpXMnr06GyxxRY57bTTsvHGG2fChAnFhQYAAABgjRVaSt19993ZZ599qs9POeWUJMkxxxyTmTNn5vOf/3xefvnl/Ou//mtefPHF7LXXXrnxxhuzzjrrFBUZAAAA4G2rUqmkXC4nSRobG1MqlQrLUmgptffee6dSqbzu8VKplC9/+cv58pe/XMNUAAAAAH1TuVzOlClTkrz6ZXFNTU2FZem1a0oBAAAA0HcppQAAAACoOaUUAAAAADWnlAIAAACg5pRSAAAAANScUgoAAACAmmsoOgAAAAAAtVFXV5cxY8ZUt4uklAIAAADoJxoaGvKRj3yk6BhJTN8DAAAAoABKKQAAAABqzvQ9AAAAgH5i5cqVmTJlSpJk8uTJaWpqKiyLkVIAAAAA1JxSCgAAAICaU0oBAAAAUHNKKQAAAABqTikFAAAAQM0ppQAAAACouYaiAwAAAABQG3V1dRk9enR1u0hKKQAAAIB+oqGhIUceeWTRMZKYvgcAAABAAZRSAAAAANSc6XsAAAAA/cTKlStz7rnnJklOPfXUNDU1FZZFKQUAAADQj5TL5aIjJDF9DwAAAIACKKUAAAAAqDmlFAAAAAA1p5QCAAAAoOaUUgAAAADUnG/fAwAAAOgnSqVSNt988+p2kZRSAAAAAP1EY2NjJk6cWHSMJKbvAQAAAFAApRQAAAAANWf6HgAAAEA/sXLlykydOjVJcuKJJ6apqamwLEopAAAAgH6kra2t6AhJTN8D4P9v786joyrvP45/JiEzyRCzQHaKBAXZimw2adCqYCQgKFEBj0VZpKlVKEWsWmwlqMWioFgQARcSjhtibYFDAxbTxCoEVCAIIUBM2dQsohCCgazP7w9+3DIkYQ0zI3m/zplz5j73ufc+1/HLvXy4CwAAAAB4AKEUAAAAAAAA3I5QCgAAAAAAAG5HKAUAAAAAAAC3I5QCAAAAAACA2/H2PQAAAAAAgGbCZrMpJibG+u5JhFIAAAAAAADNhJ+fn1JSUjw9DEncvgcAAAAAAAAPIJQCAAAAAACA23H7HgAAAAAAQDNRXV2tefPmSZLGjx8vPz8/j42FUAoAAAAAAKCZMMaorKzM+u5J3L4HAAAAAAAAtyOUAgAAAAAAgNsRSgEAAAAAAMDtCKUAAAAAAADgdoRSAAAAAAAAcDvevgcAAAAAANBM2Gw2hYeHW989iVAKAAAAAACgmfDz89ODDz7o6WFI4vY9AAAAAAAAeAChFAAAAAAAANyO2/cAAAAAAACaierqar366quSpJSUFPn5+XlsLIRSAAAAAAAAzYQxRt9++6313ZO4fQ8AAAAAAABuRygFAAAAAAAAtyOUAgAAAAAAgNsRSgEAAAAAAMDtCKUAAAAAAADgdrx9DwAAAAAAoJmw2WwKDg62vnsSoRQAAAAAAEAz4efnp0mTJnl6GJK4fQ8AAAAAAAAeQCgFAAAAAAAAt+P2PQAAAAAAgGaiurpa6enpkqQxY8bIz8/PY2MhlAIAAAAAAGgmjDH65ptvrO+exO17AAAAAAAAcDtCKQAAAAAAALgdoRQAAAAAAADcjlAKAAAAAAAAbkcoBQAAAAAAALfj7XsAAAAAAADNiNPp9PQQJBFKAQAAAAAANBt2u12PPPKIp4chidv3AAAAAAAA4AGEUgAAAAAAAHA7bt8DAAAAAABoJqqrq/XWW29JkkaOHCk/Pz+PjYVQCgAAAAAAoJkwxmjv3r3Wd0/i9j0AAAAAAAC4HaEUAAAAAAAA3I5QCgAAAAAAAG5HKAUAAAAAAAC3I5QCAAAAAACA2/H2PQAAAAAAgGbEz8/P00OQRCgFAAAA4BJRVlamiooKTw8DJykpKVFVVZWnhwHgJHa7XY8//rinhyGJUAoAAADAJaCsrEwvPf20qg8c8PRQcJLyigr9Ny9Px1q1ki67zNPDAeBlCKUAAAAA/OhVVFSo+sAB3REQoHCn09PDwf/bXlenuZWVqqmu9vRQAHghQikAAAAAl4xwp1PRXJHjNUqOHPH0EACcoqamRkuXLpUkjRgxQi1aeC4aIpQCAAAAAABoJurq6lRQUGB99yQfj24dAAAAAAAAzdKPIpSaN2+eYmNj5e/vr/j4eH366aeeHhIAAAAAAAAugNeHUu+++64mT56s1NRUbdq0ST169FBSUpJKS0s9PTQAAAAAAACcJ68PpV544QWlpKRo7Nix6tq1qxYsWCCn06lFixZ5emgAAAAAAAA4T14dSlVVVWnjxo1KTEy02nx8fJSYmKicnBwPjgwAAAAAAAAXwqvfvnfgwAHV1tYqMjLSpT0yMlI7duxocJnKykpVVlZa02VlZZKkw4cPX7yBukl5ebkqq6q0+9AhlZ+0j/CsA0eP6nBFhQoLC1VeXu7p4eAkxhjZbDZPDwOn4HfxTvwu3onfxXvx23if0tJSHamo0G5fX86Vvci+sjJV19Vpb1mZjJ+fp4eD/8fv4p0OHD2qyqoqlZeXq2XLlhdtO1VVVTp27Jik41mJ3W5v8m2cyGCMMaftZzNn6uFB33zzjdq0aaN169YpISHBan/00Uf10UcfacOGDfWWmTZtmp588kl3DhMAAAAAAACn2L9/v37yk580Ot+rr5QKCwuTr6+vSkpKXNpLSkoUFRXV4DJTpkzR5MmTrem6ujp9//33at26tUf/Nevw4cNq27at9u/fr6CgII+NA7hUUFNA06KmgKZFTQFNi5oCmtbFriljjMrLyxUTE3Pafl4dStntdvXp00eZmZlKTk6WdDxkyszM1IQJExpcxuFwyOFwuLSFhIRc5JGevaCgIP4QBZoQNQU0LWoKaFrUFNC0qCmgaV3MmgoODj5jH68OpSRp8uTJGj16tK655hrFxcXpxRdf1A8//KCxY8d6emgAAAAAAAA4T14fSt1111369ttvNXXqVBUXF6tnz55avXp1vYefAwAAAAAA4MfD60MpSZowYUKjt+v9WDgcDqWmpta7tRDA+aGmgKZFTQFNi5oCmhY1BTQtb6kpr377HgAAAAAAAC5NPp4eAAAAAAAAAJofQikAAAAAAAC4HaEUAAAAAAAA3I5Q6gLs2bNH48aNU/v27RUQEKArr7xSqampqqqqculjs9nqfdavX++yrvfee0+dO3eWv7+/unfvroyMDJf5xhhNnTpV0dHRCggIUGJiogoKCtyyn4C7nE1NSdIXX3yhX/ziF/L391fbtm313HPP1VsXNQUcN336dPXt21dOp1MhISEN9mnoOLVkyRKXPtnZ2erdu7ccDoc6dOig9PT0euuZN2+eYmNj5e/vr/j4eH366acXYY8Azzqbmtq3b58GDx4sp9OpiIgIPfLII6qpqXHpQ00BjYuNja13XJoxY4ZLn6Y4HwSaM285xhBKXYAdO3aorq5OCxcuVF5enmbPnq0FCxbo8ccfr9f3ww8/VFFRkfXp06ePNW/dunW6++67NW7cOG3evFnJyclKTk7Wtm3brD7PPfec5syZowULFmjDhg1q2bKlkpKSdOzYMbfsK+AOZ1NThw8f1oABA9SuXTtt3LhRM2fO1LRp0/TKK69Yfagp4H+qqqo0fPhwPfDAA6ftl5aW5nKcSk5Otubt3r1bgwcPVr9+/ZSbm6tJkybpV7/6lT744AOrz7vvvqvJkycrNTVVmzZtUo8ePZSUlKTS0tKLtWuAR5yppmprazV48GBVVVVp3bp1Wrx4sdLT0zV16lSrDzUFnNlTTz3lclz67W9/a81rqvNBoLnyqmOMQZN67rnnTPv27a3p3bt3G0lm8+bNjS4zYsQIM3jwYJe2+Ph4c//99xtjjKmrqzNRUVFm5syZ1vxDhw4Zh8Nh3nnnnabdAcDLnFpTL7/8sgkNDTWVlZVW22OPPWY6depkTVNTQH1paWkmODi4wXmSzD/+8Y9Gl3300UdNt27dXNruuusuk5SUZE3HxcWZ8ePHW9O1tbUmJibG/OUvf7mgcQPeqrGaysjIMD4+Pqa4uNhqmz9/vgkKCrKOXdQUcHrt2rUzs2fPbnR+U5wPAs2ZNx1juFKqiZWVlalVq1b12m+77TZFRETouuuu04oVK1zm5eTkKDEx0aUtKSlJOTk5ko7/a1pxcbFLn+DgYMXHx1t9gEvVqTWVk5Oj66+/Xna73WpLSkrSzp07dfDgQasPNQWcm/HjxyssLExxcXFatGiRjDHWvDPVVFVVlTZu3OjSx8fHR4mJidQUmp2cnBx1795dkZGRVltSUpIOHz6svLw8qw81BZzejBkz1Lp1a/Xq1UszZ850uQW2Kc4HgebK244xLdy+xUvYl19+qblz52rWrFlWW2BgoJ5//nlde+218vHx0fvvv6/k5GQtW7ZMt912mySpuLjY5cRFkiIjI1VcXGzNP9HWWB/gUtRQTRUXF6t9+/Yu/U7URnFxsUJDQ6kp4Bw99dRT6t+/v5xOp/71r3/pwQcf1JEjRzRx4kRJjR+nDh8+rKNHj+rgwYOqra1tsM+OHTvcth+AN2isXk7MO10fago4buLEierdu7datWqldevWacqUKSoqKtILL7wgqWnOB4Hm6sCBA151jOFKqQb84Q9/aPChryd/Tv2xvv76aw0cOFDDhw9XSkqK1R4WFqbJkycrPj5eP/vZzzRjxgzdc889mjlzprt3C/CYpqwpAOdXU6fzxBNP6Nprr1WvXr302GOP6dFHH+U4hWalqWsKQH3nUmeTJ0/WjTfeqKuvvlq/+c1v9Pzzz2vu3LmqrKz08F4AaGpcKdWAhx9+WGPGjDltnyuuuML6/s0336hfv37q27evy8P1GhMfH681a9ZY01FRUSopKXHpU1JSoqioKGv+ibbo6GiXPj179jzj9gBPa8qaaqxeTsw7XR9qCpeKc62pcxUfH6+nn35alZWVcjgcjdZUUFCQAgIC5OvrK19f39PWHeDNmrKmoqKi6r3B6GyPU9QULmUXUmfx8fGqqanRnj171KlTpyY5HwSaq7CwMK86xhBKNSA8PFzh4eFn1ffrr79Wv3791KdPH6WlpcnH58wXn+Xm5rr8RTghIUGZmZmaNGmS1bZmzRolJCRIktq3b6+oqChlZmZaf2E+fPiwNmzYcMa3KQHeoClrKiEhQX/84x9VXV0tPz8/ScfrpVOnTgoNDbX6UFO4lJ1LTZ2P3NxchYaGyuFwSDpeU6e+RvvkmrLb7erTp48yMzOtt/bV1dUpMzNTEyZMuGjjBJpKU9ZUQkKCpk+frtLSUkVEREg6Xi9BQUHq2rWr1YeaQnNzIXWWm5srHx8fq6aa4nwQaK687hjj9kerX0K++uor06FDB3PTTTeZr776yhQVFVmfE9LT083bb79t8vPzTX5+vpk+fbrx8fExixYtsvqsXbvWtGjRwsyaNcvk5+eb1NRU4+fnZ7Zu3Wr1mTFjhgkJCTHLly83X3zxhRk6dKhp3769OXr0qFv3GbiYzqamDh06ZCIjI829995rtm3bZpYsWWKcTqdZuHCh1YeaAv5n7969ZvPmzebJJ580gYGBZvPmzWbz5s2mvLzcGGPMihUrzKuvvmq2bt1qCgoKzMsvv2ycTqeZOnWqtY7//ve/xul0mkceecTk5+ebefPmGV9fX7N69Wqrz5IlS4zD4TDp6elm+/bt5te//rUJCQlxeQMZcCk4U03V1NSYn/70p2bAgAEmNzfXrF692oSHh5spU6ZY66CmgMatW7fOzJ492+Tm5prCwkLz5ptvmvDwcDNq1CirT1OdDwLNlTcdYwilLkBaWpqR1ODnhPT0dNOlSxfjdDpNUFCQiYuLM++99169dS1dutRcddVVxm63m27dupl//vOfLvPr6urME088YSIjI43D4TA33XST2blz50XfR8CdzqamjDFmy5Yt5rrrrjMOh8O0adPGzJgxo966qCnguNGjRzdYU1lZWcYYY1atWmV69uxpAgMDTcuWLU2PHj3MggULTG1trct6srKyTM+ePY3dbjdXXHGFSUtLq7etuXPnmssvv9zY7XYTFxdn1q9f74Y9BNzrTDVljDF79uwxgwYNMgEBASYsLMw8/PDDprq62mU91BTQsI0bN5r4+HgTHBxs/P39TZcuXcwzzzxjjh075tKvKc4HgebMW44xNmNOeuczAAAAAAAA4Aa8fQ8AAAAAAABuRygFAAAAAAAAtyOUAgAAAAAAgNsRSgEAAAAAAMDtCKUAAAAAAADgdoRSAAAAAAAAcDtCKQAAAAAAALgdoRQAAAAAAADcjlAKAAAAAAAAbkcoBQAAvJLNZtOyZcus6R07dujnP/+5/P391bNnz0bbLjXLli1Thw4d5Ovrq0mTJnl6OAAAAE2GUAoAALjNmDFjZLPZZLPZ5Ofnp8jISN18881atGiR6urqXPoWFRVp0KBB1nRqaqpatmypnTt3KjMzs9G2S83999+vYcOGaf/+/Xr66ac9PRxJ0tGjR5WamqqrrrpKDodDYWFhGj58uPLy8s57nXv27JHNZlNubm7TDRQAAHg1QikAAOBWAwcOVFFRkfbs2aNVq1apX79++t3vfqchQ4aopqbG6hcVFSWHw2FNFxYW6rrrrlO7du3UunXrRtvOVVVV1YXt0EV05MgRlZaWKikpSTExMbrsssvq9amtra0X6F1MlZWVSkxM1KJFi/TnP/9Zu3btUkZGhmpqahQfH6/169e7bSyNqa6u9vQQAADAWSCUAgAAbuVwOBQVFaU2bdqod+/eevzxx7V8+XKtWrVK6enpVr+Tb9+z2WzauHGjnnrqKdlsNk2bNq3BNknav3+/RowYoZCQELVq1UpDhw7Vnj17rPWOGTNGycnJmj59umJiYtSpU6dzWm7WrFmKjo5W69atNX78eJcApLKyUo899pjatm0rh8OhDh066PXXX7fmb9u2TYMGDVJgYKAiIyN177336sCBAw3+d8rOzrZCqP79+8tmsyk7O1vp6ekKCQnRihUr1LVrVzkcDu3bt08HDx7UqFGjFBoaKqfTqUGDBqmgoMBa34nlVq5cqU6dOsnpdGrYsGGqqKjQ4sWLFRsbq9DQUE2cOFG1tbWN/n4vvviicnJytHLlSo0YMULt2rVTXFyc3n//fXXp0kXjxo2TMabBZQ8ePKiRI0cqPDxcAQEB6tixo9LS0iRJ7du3lyT16tVLNptNN954oyTps88+080336ywsDAFBwfrhhtu0KZNm1zWa7PZNH/+fN12221q2bKlpk+f3uj4AQCA9yCUAgAAHte/f3/16NFDf//73xucX1RUpG7duunhhx9WUVGRfv/73zfYVl1draSkJF122WX6+OOPtXbtWgUGBmrgwIEuV0RlZmZq586dWrNmjVauXHnWy2VlZamwsFBZWVlavHix0tPTXYK0UaNG6Z133tGcOXOUn5+vhQsXKjAwUJJ06NAh9e/fX7169dLnn3+u1atXq6SkRCNGjGhwn/v27audO3dKkt5//30VFRWpb9++kqSKigo9++yzeu2115SXl6eIiAiNGTNGn3/+uVasWKGcnBwZY3TLLbe4hGYVFRWaM2eOlixZotWrVys7O1u33367MjIylJGRoTfeeEMLFy7U3/72t0Z/q7fffls333yzevTo4dLu4+Ojhx56SNu3b9eWLVsaXPaJJ57Q9u3btWrVKuXn52v+/PkKCwuTJH366aeSpA8//FBFRUXW/wvl5eUaPXq0PvnkE61fv14dO3bULbfcovLycpd1T5s2Tbfffru2bt2q++67r9HxAwAA79HC0wMAAACQpM6dO+uLL75ocF5UVJRatGihwMBARUVFSZICAwPrtb355puqq6vTa6+9JpvNJklKS0tTSEiIsrOzNWDAAElSy5Yt9dprr8lut5/TcqGhoXrppZfk6+urzp07a/DgwcrMzFRKSop27dqlpUuXas2aNUpMTJQkXXHFFdY+vPTSS+rVq5eeeeYZq23RokVq27atdu3apauuuspln+12uyIiIiRJrVq1svZROn572ssvv2wFQwUFBVqxYoXWrl1rBVdvvfWW2rZtq2XLlmn48OHWcvPnz9eVV14pSRo2bJjeeOMNlZSUKDAwUF27dlW/fv2UlZWlu+66q8HfYteuXerXr1+D87p06WL1aejB8/v27VOvXr10zTXXSJJiY2OteeHh4ZKk1q1bu+xr//79XdbxyiuvKCQkRB999JGGDBlitf/yl7/U2LFjGxwXAADwToRSAADAKxhjrEDofG3ZskVffvllvWcvHTt2TIWFhdZ09+7drUDqXJbr1q2bfH19reno6Ght3bpVkpSbmytfX1/dcMMNjY4tKyvLunLqZIWFhfVCqdOx2+26+uqrren8/Hy1aNFC8fHxVlvr1q3VqVMn5efnW21Op9MKpCQpMjJSsbGxLmOKjIxUaWnpabff2O15J4+vIQ888IDuvPNObdq0SQMGDFBycrIVojWmpKREf/rTn5Sdna3S0lLV1taqoqJC+/btc+l3IugCAAA/HoRSAADAK+Tn51vPFTpfR44cUZ8+ffTWW2/Vm3fiShzp+JVS57Ocn5+fyzybzWY9ZDwgIOCMY7v11lv17LPP1psXHR192mVPFRAQcF4BXkPjP90+NaRjx44uQdfJTrQ3FrANGjRIe/fuVUZGhtasWaObbrpJ48eP16xZsxrd3ujRo/Xdd9/pr3/9q9q1ayeHw6GEhIR6D6g/9TcFAADej2dKAQAAj/v3v/+trVu36s4777yg9fTu3VsFBQWKiIhQhw4dXD7BwcFNvtzJunfvrrq6On300UeNbiMvL0+xsbH1tnGhgUqXLl1UU1OjDRs2WG3fffeddu7cqa5du17Quk91991368MPP6z33Ki6ujrNnj1b11xzzWm3GR4ertGjR+vNN9/Uiy++qFdeeUXS/66uOvUh62vXrtXEiRN1yy23qFu3bnI4HI0+HB4AAPy4EEoBAAC3qqysVHFxsb7++mtt2rRJzzzzjIYOHaohQ4Zo1KhRF7TukSNHKiwsTEOHDtXHH3+s3bt3Kzs7WxMnTtRXX33V5MudLDY2VqNHj9Z9992nZcuWWetYunSpJGn8+PH6/vvvdffdd+uzzz5TYWGhPvjgA40dO/a0b7s7Gx07dtTQoUOVkpKiTz75RFu2bNE999yjNm3aaOjQoRe07lM99NBDiouL06233qr33ntP+/bt02effaY777xTBQUFWrx4caPLTp06VcuXL9eXX36pvLw8rVy50noOVUREhAICAqwHwJeVlVn79sYbbyg/P18bNmzQyJEjz3hVGgAA+HEglAIAAG61evVqRUdHKzY2VgMHDlRWVpbmzJmj5cuXuzyv6Xw4nU795z//0eWXX6477rhDXbp00bhx43Ts2DEFBQU1+XKnmj9/voYNG6YHH3xQnTt3VkpKin744QdJUkxMjNauXava2loNGDBA3bt316RJkxQSEiIfnws/JUtLS1OfPn00ZMgQJSQkyBijjIyMerfnXSh/f39lZmZq1KhRmjJliq688krFxcVp27Zt2rZt22mvkrLb7ZoyZYquvvpqXX/99fL19dWSJUskSS1atNCcOXO0cOFCxcTEWGHa66+/roMHD6p379669957NXHiROsB8AAA4MfNZs70pEoAAADgNFatWqXbb79ds2bN0oQJEzw9HAAA8CPBlVIAAAC4IIMGDdKqVav0/fff87wnAABw1rhSCgAAAAAAAG7HlVIAAAAAAABwO0IpAAAAAAAAuB2hFAAAAAAAANyOUAoAAAAAAABuRygFAAAAAAAAtyOUAgAAAAAAgNsRSgEAAAAAAMDtCKUAAAAAAADgdoRSAAAAAAAAcLv/A/gOnNuMJlShAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x1800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 繪製直方圖\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 18))\n",
    "\n",
    "# 早期\n",
    "axes[0].hist(early_diff, bins=10, alpha=0.5, color=\"blue\", edgecolor=\"black\")\n",
    "axes[0].axvline(0, color=\"grey\", linestyle=\"--\")\n",
    "axes[0].set_title(\"Early\")\n",
    "axes[0].set_xlabel(\"Difference from Q star\")\n",
    "axes[0].set_ylabel(\"Frequency\")\n",
    "\n",
    "# 中期\n",
    "axes[1].hist(mid_diff, bins=10, alpha=0.5, color=\"green\", edgecolor=\"black\")\n",
    "axes[1].axvline(0, color=\"grey\", linestyle=\"--\")\n",
    "axes[1].set_title(\"Mid\")\n",
    "axes[1].set_xlabel(\"Difference from Q star\")\n",
    "axes[1].set_ylabel(\"Frequency\")\n",
    "\n",
    "# 晚期\n",
    "axes[2].hist(late_diff, bins=10, alpha=0.5, color=\"red\", edgecolor=\"black\")\n",
    "axes[2].axvline(0, color=\"grey\", linestyle=\"--\")\n",
    "axes[2].set_title(\"Late\")\n",
    "axes[2].set_xlabel(\"Difference from Q star\")\n",
    "axes[2].set_ylabel(\"Frequency\")\n",
    "\n",
    "fig.suptitle(\"Histogram of Differences from Q star at Different Times\")\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDilezxfOmIe"
   },
   "source": [
    "# Strategies utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the r and R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gurobipy as gp\n",
    "# from gurobipy import GRB\n",
    "\n",
    "# # 初始化模型\n",
    "# # model = gp.Model(\"Test_r_R_relationship\")\n",
    "# model = gp.Model(env=env)\n",
    "\n",
    "# # 設定參數\n",
    "# K = 4  # 候選數量\n",
    "# i = 0  # 單個 i 的例子\n",
    "\n",
    "# # 定義變數\n",
    "# r_vars = model.addVars(K, lb=0.0, ub=1.0, name=\"r_vars\")  # r_{i,k}\n",
    "# R_vars = model.addVars(K, vtype=GRB.BINARY, name=\"R_vars\")  # R_{i,k}\n",
    "# max_r_helper = model.addVar(lb=0.0, ub=1.0, name=\"max_r_helper\")  # 最大值輔助變數\n",
    "\n",
    "# # 假設 exp_tau_vars 是已知的輸入數值\n",
    "# exp_tau_vars = [0.1, 0.3, 0.5, 0.2]  # 例子數值\n",
    "\n",
    "# # 限制式 1: 定義 r_vars 與 exp_tau_vars 的關係\n",
    "# for k in range(K):\n",
    "#     model.addConstr(\n",
    "#         r_vars[k] * sum(exp_tau_vars) == exp_tau_vars[k],\n",
    "#         name=f\"softmax_relation_{k}\",\n",
    "#     )\n",
    "\n",
    "# # 限制式 2: 確保 r_vars 的加總為 1\n",
    "# model.addConstr(gp.quicksum(r_vars[k] for k in range(K)) == 1, name=\"sum_r_constraint\")\n",
    "\n",
    "# # 限制式 3: 找出 r_vars 中的最大值\n",
    "# model.addGenConstrMax(\n",
    "#     max_r_helper, [r_vars[k] for k in range(K)], name=\"max_r_constraint\"\n",
    "# )\n",
    "\n",
    "# # 限制式 4: 確保 R_vars 對應到最大值\n",
    "# for k in range(K):\n",
    "#     model.addGenConstrIndicator(\n",
    "#         R_vars[k], 1, r_vars[k] == max_r_helper, name=f\"indicator_R_{k}\"\n",
    "#     )\n",
    "\n",
    "# # 限制式 5: 確保僅有一個 R_vars[k] 為 1\n",
    "# model.addConstr(\n",
    "#     gp.quicksum(R_vars[k] for k in range(K)) == 1, name=\"unique_R_constraint\"\n",
    "# )\n",
    "\n",
    "# # 設定目標函數（範例：最大化 max_r_helper）\n",
    "# model.setObjective(max_r_helper, GRB.MAXIMIZE)\n",
    "\n",
    "# # 求解模型\n",
    "# model.optimize()\n",
    "\n",
    "# # 輸出結果\n",
    "# if model.Status == GRB.OPTIMAL:\n",
    "#     print(\"Optimal solution found!\")\n",
    "#     print(f\"max_r_helper: {max_r_helper.X}\")\n",
    "#     print(\"r_vars:\")\n",
    "#     for k in range(K):\n",
    "#         print(f\"  r_vars[{k}]: {r_vars[k].X}\")\n",
    "#     print(\"R_vars:\")\n",
    "#     for k in range(K):\n",
    "#         print(f\"  R_vars[{k}]: {R_vars[k].X}\")\n",
    "# else:\n",
    "#     print(\"No optimal solution found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "檢驗結果：目前的寫法可以成功讓 r 與 R 的關係實現\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8oJyOCv3Oqap"
   },
   "source": [
    "## S0 - One-time Procurement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "iMoKgd_XO05c"
   },
   "outputs": [],
   "source": [
    "def one_time_procurement(Q_star, demand_df, cost, price, salvage_value):\n",
    "\n",
    "    all_losses = []\n",
    "    all_lefts = []\n",
    "    all_operation_profits = []\n",
    "    all_profits = []\n",
    "\n",
    "    for i, row in demand_df.iterrows():\n",
    "        inventory = Q_star\n",
    "        losses = []\n",
    "        lefts = []\n",
    "        daily_operation_profits = []\n",
    "        daily_profits = []\n",
    "        total_sold = 0  # 追蹤總售出量\n",
    "        total_lost = 0  # 追蹤總丟失量\n",
    "\n",
    "        # print(\"=\" * 50)\n",
    "        # print(\n",
    "        #     f\"Processing row {i+1}/{len(demand_df)} with initial inventory Q_star={Q_star}\"\n",
    "        # )\n",
    "        # print(\"=\" * 50)\n",
    "\n",
    "        for day, demand in enumerate(row):\n",
    "            sales = min(inventory, demand)\n",
    "            loss = max(demand - inventory, 0)\n",
    "            left = max(inventory - sales, 0)\n",
    "            total_sold += sales\n",
    "            total_lost += loss\n",
    "\n",
    "            inventory -= sales\n",
    "\n",
    "            # print(\"-\" * 50)\n",
    "            # print(f\"Day {day+1}\")\n",
    "            # print(f\"Demand      : {demand}\")\n",
    "            # print(f\"Sales       : {sales}\")\n",
    "            # print(f\"Loss        : {loss}\")\n",
    "            # print(f\"Left        : {left}\")\n",
    "            # print(f\"Inventory   : {inventory}\")\n",
    "            # print(\"-\" * 50)\n",
    "\n",
    "            if day == len(row) - 1:\n",
    "                left_penalty_cost = (cost - salvage_value) * left\n",
    "                lefts.append(left)\n",
    "                # print(f\"End of period: Left Penalty Cost = {left_penalty_cost}\")\n",
    "                # print(\"-\" * 50)\n",
    "            else:\n",
    "                left_penalty_cost = 0\n",
    "\n",
    "        operation_profit = (price - cost) * total_sold\n",
    "        profit = operation_profit - left_penalty_cost - (price - cost) * total_lost\n",
    "\n",
    "        # print(\"=\" * 50)\n",
    "        # print(f\"Row {i+1} Summary\")\n",
    "        # print(f\"Total Sold         : {total_sold}\")\n",
    "        # print(f\"Total Lost         : {total_lost}\")\n",
    "        # print(f\"Operation Profit   : {operation_profit}\")\n",
    "        # print(f\"Profit             : {profit}\")\n",
    "        # print(\"=\" * 50)\n",
    "\n",
    "        all_losses.append(total_lost)\n",
    "        all_lefts.append(sum(lefts))\n",
    "        all_operation_profits.append(operation_profit)\n",
    "        all_profits.append(profit)\n",
    "\n",
    "    avg_losses = np.mean(all_losses)\n",
    "    avg_lefts = np.mean(all_lefts)\n",
    "    avg_operation_profits = np.mean(all_operation_profits)\n",
    "    avg_profits = np.mean(all_profits)\n",
    "\n",
    "    # print(\"=\" * 50)\n",
    "    # print(\"Overall Summary\")\n",
    "    # print(f\"Average Losses           : {avg_losses}\")\n",
    "    # print(f\"Average Lefts            : {avg_lefts}\")\n",
    "    # print(f\"Average Operation Profits: {avg_operation_profits}\")\n",
    "    # print(f\"Average Profits          : {avg_profits}\")\n",
    "    # print(\"=\" * 50)\n",
    "\n",
    "    stimulation_df = pd.DataFrame(\n",
    "        {\n",
    "            \"losses\": all_losses,\n",
    "            \"lefts\": all_lefts,\n",
    "            \"operation_profits\": all_operation_profits,\n",
    "            \"profits\": all_profits,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return avg_losses, avg_lefts, avg_profits, avg_operation_profits, stimulation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gmHkLPVROtLN"
   },
   "source": [
    "## S1 - Grid for Fixed F & Fixed Rk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "iCm5WosfO_l-"
   },
   "outputs": [],
   "source": [
    "def cal_fixed_F_fixed_R(\n",
    "    Q_star, assigned_F, assigned_R, demand_df, cost, price, salvage_value, Qk_hat_df\n",
    "):\n",
    "    all_losses = []\n",
    "    all_lefts = []\n",
    "    all_left0s = []\n",
    "    all_left1s = []\n",
    "    all_operation_profits = []\n",
    "    all_profits = []\n",
    "    all_q0s = []\n",
    "    all_q1s = []\n",
    "\n",
    "    Q0 = assigned_F * Q_star  # 期初庫存\n",
    "\n",
    "    # print(f\"\\n\")\n",
    "    # print(f\"====\" * 10)\n",
    "    # print(f\"\\n\")\n",
    "\n",
    "    for i, row in demand_df.iterrows():\n",
    "\n",
    "        # 第一階段計算\n",
    "        total_sold_0 = min(Q0, row[: assigned_R + 1].sum())  # 第一階段售出量\n",
    "        left_0 = max(Q0 - total_sold_0, 0)  # 第一階段剩餘\n",
    "        lost_0 = max((row[: assigned_R + 1].sum() - Q0), 0)\n",
    "\n",
    "        # 第二階段開始補貨，根據指定的 R\n",
    "        Qk_hat = Qk_hat_df.iloc[i, assigned_R]\n",
    "        Q1 = max((Qk_hat - Q0), 0)  # 二次訂貨量\n",
    "        total_sold_1 = min(Q1 + left_0, row[assigned_R + 1 :].sum())  # 第二階段售出量\n",
    "        left_1 = max((Q1 + left_0) - total_sold_1, 0)  # 第二階段剩餘\n",
    "        lost_1 = max(row[assigned_R + 1 :].sum() - (Q1 + left_0), 0)\n",
    "\n",
    "        # 統計\n",
    "        total_sold = total_sold_0 + total_sold_1\n",
    "        total_lost = lost_0 + lost_1\n",
    "        total_left = left_0 + left_1\n",
    "\n",
    "        # 計算運營利潤和總利潤\n",
    "        operation_profit = (price - cost) * total_sold\n",
    "\n",
    "        left_penalty_cost = (cost - salvage_value) * left_1\n",
    "        # left_penalty_cost = (cost - salvage_value) * total_left\n",
    "        lost_penalty_cost = (price - cost) * total_lost\n",
    "\n",
    "        profit = operation_profit - left_penalty_cost - lost_penalty_cost\n",
    "\n",
    "        all_losses.append(total_lost)\n",
    "        all_lefts.append(total_left)\n",
    "        all_operation_profits.append(operation_profit)\n",
    "        all_profits.append(profit)\n",
    "        all_q0s.append(Q0)\n",
    "        all_q1s.append(Q1)\n",
    "        all_left0s.append(left_0)\n",
    "        all_left1s.append(left_1)\n",
    "\n",
    "        # print(f\"這是第 {i+1} 筆模擬資料\\n\")\n",
    "        # print(f\"F: {assigned_F}, R: {assigned_R+2}\")\n",
    "        # print(f\"Q_star 為 {Q_star}\")\n",
    "        # print(f\"期初庫存 Q0: {Q0}\")\n",
    "        # print(f\"重新估計量 Qk_hat: {Qk_hat}\")\n",
    "        # print(f\"訂貨量 Q1 為 {Q1}\\n\")\n",
    "\n",
    "        # print(\n",
    "        #     f\"第一階段：期初庫存 Q0: {Q0}，需求量為 {row[:assigned_R + 1].sum()}，Sold_0 為 {total_sold_0}，Left_0 為 {left_0}，Lost_0 為 {lost_0}\"\n",
    "        # )\n",
    "        # print(\n",
    "        #     f\"第二階段：期初庫存 Q1+left_0 為 {Q1+left_0}，需求量為 {row[assigned_R + 1:].sum()}，Sold_1 為 {total_sold_1}，Left_1 為 {left_1}，Lost_1 為 {lost_1}\\n\"\n",
    "        # )\n",
    "        # print(\n",
    "        #     f\"統計結果：Sold 為 {total_sold}, Lost 為 {total_lost} Left_Penalty_Cost 為 {left_penalty_cost}，Lost_Penalty_Cost 為 {lost_penalty_cost}，Profit 為 {profit}\"\n",
    "        # )\n",
    "        # print(\"----\" * 10)\n",
    "\n",
    "    result_df = {\n",
    "        \"R(T)\": assigned_R + 2,\n",
    "        \"F\": assigned_F,\n",
    "        \"Q0\": all_q0s,\n",
    "        \"Q1\": all_q1s,\n",
    "        \"average_profits\": np.mean(all_profits),\n",
    "        \"average_losses\": np.mean(all_losses),\n",
    "        \"average_lefts\": np.mean(all_lefts),\n",
    "        \"average_operation_profits\": np.mean(all_operation_profits),\n",
    "    }\n",
    "\n",
    "    stimulation_result = {\n",
    "        \"R(T)\": assigned_R + 2,\n",
    "        \"F\": assigned_F,\n",
    "        \"profits\": all_profits,\n",
    "        \"losses\": all_losses,\n",
    "        \"lefts\": all_lefts,\n",
    "        \"Left0s\": all_left0s,\n",
    "        \"Left1s\": all_left1s,\n",
    "        \"operation_profits\": all_operation_profits,\n",
    "        \"Q0\": all_q0s,\n",
    "        \"Q1\": all_q1s,\n",
    "    }\n",
    "\n",
    "    return result_df, stimulation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "4OJpJmXYZ3nm"
   },
   "outputs": [],
   "source": [
    "def grid_fixed_F_fixed_R(\n",
    "    assigned_Ts,\n",
    "    assigned_Fs,\n",
    "    cost,\n",
    "    price,\n",
    "    salvage_value,\n",
    "    Qk_hat_df,\n",
    "    demand_df_train,\n",
    "    Q_star,\n",
    "):\n",
    "\n",
    "    results_list = []\n",
    "    max_profit = None\n",
    "    max_profit_stimulation_result = {}\n",
    "\n",
    "    for assigned_T in assigned_Ts:\n",
    "        for assigned_F in assigned_Fs:\n",
    "            assigned_R = assigned_T - 2\n",
    "            mean_result, stimulation_result = cal_fixed_F_fixed_R(\n",
    "                Q_star,\n",
    "                assigned_F,\n",
    "                assigned_R,\n",
    "                demand_df_train,\n",
    "                cost,\n",
    "                price,\n",
    "                salvage_value,\n",
    "                Qk_hat_df,\n",
    "            )\n",
    "            results_list.append(mean_result)\n",
    "\n",
    "            if max_profit is None or max_profit < mean_result[\"average_profits\"]:\n",
    "                # print(\n",
    "                #     f\"max_profit is changed from {max_profit} to {mean_result['average_profits']}\"\n",
    "                # )\n",
    "                max_profit = mean_result[\"average_profits\"]\n",
    "                max_profit_stimulation_result = stimulation_result\n",
    "\n",
    "    results_df_1 = pd.DataFrame(results_list).sort_values(\n",
    "        by=\"average_profits\", ascending=False\n",
    "    )\n",
    "\n",
    "    return results_df_1, pd.DataFrame(max_profit_stimulation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S8 - Grid for Fixed F & Fixed Rk(with holding cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_fixed_F_fixed_R_with_holding_cost(\n",
    "    Q_star,\n",
    "    assigned_F,\n",
    "    assigned_R,\n",
    "    demand_df,\n",
    "    cost,\n",
    "    price,\n",
    "    salvage_value,\n",
    "    Qk_hat_df,\n",
    "    holding_cost,\n",
    "):\n",
    "    all_losses = []\n",
    "    all_lefts = []\n",
    "    all_operation_profits = []\n",
    "    all_profits = []\n",
    "    all_q0s = []\n",
    "    all_q1s = []\n",
    "    all_holding_costs_0 = []\n",
    "    all_holding_costs_1 = []\n",
    "    all_left0s = []\n",
    "    all_left1s = []\n",
    "    all_lost0s = []\n",
    "    all_lost1s = []\n",
    "\n",
    "    Q0 = assigned_F * Q_star  # 期初庫存\n",
    "\n",
    "    # print(f\"\\n\")\n",
    "    # print(f\"====\" * 10)\n",
    "    # print(f\"\\n\")\n",
    "\n",
    "    for i, row in demand_df.iterrows():\n",
    "\n",
    "        # 第一階段計算\n",
    "        total_sold_0 = min(Q0, row[: assigned_R + 1].sum())  # 第一階段售出量\n",
    "        left_0 = max(Q0 - total_sold_0, 0)  # 第一階段剩餘\n",
    "        lost_0 = max(row[: assigned_R + 1].sum() - Q0, 0)\n",
    "\n",
    "        # 第二階段開始補貨，根據指定的 R\n",
    "        Qk_hat = Qk_hat_df.iloc[i, assigned_R]\n",
    "        Q1 = max((Qk_hat - Q0), 0)  # 二次訂貨量\n",
    "        total_sold_1 = min(Q1 + left_0, row[assigned_R + 1 :].sum())  # 第二階段售出量\n",
    "        left_1 = max((Q1 + left_0) - total_sold_1, 0)  # 第二階段剩餘\n",
    "        lost_1 = max(row[assigned_R + 1 :].sum() - (Q1 + left_0), 0)\n",
    "\n",
    "        # 統計\n",
    "        total_sold = total_sold_0 + total_sold_1\n",
    "        total_lost = lost_0 + lost_1\n",
    "\n",
    "        # 計算 holding_cost\n",
    "        \"\"\"\n",
    "        今天 T = 10, 假設 R = 5 (此時 assigned_R=3), 此時:\n",
    "        第一階段是 T=1~4 -> 高為 R-1 = (assigned_R+2) - 1\n",
    "        第二階段是 T=5~10 -> 高為 T - R = T - (assigned_R+2)\n",
    "        \"\"\"\n",
    "\n",
    "        first_holding_cost = (Q0 + left_0 + Q1) * ((assigned_R + 2) - 1) / 2\n",
    "        # T = 1 ~ R+1, R+1 才是代表 R(T)\n",
    "        second_holding_cost = (Q1 + left_0 + left_1) * (T - (assigned_R + 2)) / 2\n",
    "        # T = R+1 ~ T\n",
    "        holding_penalty = holding_cost * (first_holding_cost + second_holding_cost)\n",
    "\n",
    "        # 計算運營利潤和總利潤\n",
    "        operation_profit = (price - cost) * total_sold\n",
    "        left_penalty_cost = (cost - salvage_value) * left_1\n",
    "        lost_penalty_cost = (price - cost) * total_lost\n",
    "        profit = (\n",
    "            operation_profit - left_penalty_cost - lost_penalty_cost - holding_penalty\n",
    "        )\n",
    "\n",
    "        all_losses.append(total_lost)\n",
    "        all_lefts.append(left_1)\n",
    "        all_operation_profits.append(operation_profit)\n",
    "        all_profits.append(profit)\n",
    "        all_q0s.append(Q0)\n",
    "        all_q1s.append(Q1)\n",
    "        all_holding_costs_0.append(first_holding_cost)\n",
    "        all_holding_costs_1.append(second_holding_cost)\n",
    "        all_left0s.append(left_0)\n",
    "        all_left1s.append(left_1)\n",
    "        all_lost0s.append(lost_0)\n",
    "        all_lost1s.append(lost_1)\n",
    "\n",
    "        # print(f\"這是第 {i+1} 筆模擬資料\\n\")\n",
    "        # print(f\"F: {assigned_F}, R: {assigned_R+2}\")\n",
    "        # print(f\"Q_star 為 {Q_star}\")\n",
    "        # print(f\"期初庫存 Q0: {Q0}\")\n",
    "        # print(f\"重新估計量 Qk_hat: {Qk_hat}\")\n",
    "        # print(f\"訂貨量 Q1 為 {Q1}\\n\")\n",
    "\n",
    "        # print(\n",
    "        #     f\"第一階段：期初庫存 Q0: {Q0}，需求量為 {row[:assigned_R + 1].sum()}，Sold_0 為 {total_sold_0}，Left_0 為 {left_0}，Lost_0 為 {lost_0}, first_holding_cost 為 {first_holding_cost}\"\n",
    "        # )\n",
    "        # print(\n",
    "        #     f\"第二階段：期初庫存 Q1+left_0 為 {Q1+left_0}，需求量為 {row[assigned_R + 1:].sum()}，Sold_1 為 {total_sold_1}，Left_1 為 {left_1}，Lost_1 為 {lost_1}, second_holding_cost 為 {second_holding_cost}\\n\"\n",
    "        # )\n",
    "        # print(\n",
    "        #     f\"統計結果：Sold 為 {total_sold}, Lost 為 {total_lost} Left_Penalty_Cost 為 {left_penalty_cost}，Lost_Penalty_Cost 為 {lost_penalty_cost}，holding_penalty 為 {holding_penalty}，Profit 為 {profit}\"\n",
    "        # )\n",
    "        # print(\"----\" * 10)\n",
    "\n",
    "    result_df = {\n",
    "        \"R(T)\": assigned_R + 2,\n",
    "        \"F\": assigned_F,\n",
    "        \"Q0\": all_q0s,\n",
    "        \"Q1\": all_q1s,\n",
    "        \"average_profits\": np.mean(all_profits),\n",
    "        \"average_losses\": np.mean(all_losses),\n",
    "        \"average_lefts\": np.mean(all_lefts),\n",
    "        \"average_operation_profits\": np.mean(all_operation_profits),\n",
    "    }\n",
    "\n",
    "    stimulation_result = {\n",
    "        \"R(T)\": assigned_R + 2,\n",
    "        \"F\": assigned_F,\n",
    "        \"profits\": all_profits,\n",
    "        \"losses\": all_losses,\n",
    "        \"lefts\": all_lefts,\n",
    "        \"operation_profits\": all_operation_profits,\n",
    "        \"Q0\": all_q0s,\n",
    "        \"Q1\": all_q1s,\n",
    "        \"hc0\": all_holding_costs_0,\n",
    "        \"hc1\": all_holding_costs_1,\n",
    "        \"Left0s\": all_left0s,\n",
    "        \"Left1s\": all_left1s,\n",
    "        \"lost0s\": all_lost0s,\n",
    "        \"lost1s\": all_lost1s,\n",
    "    }\n",
    "\n",
    "    return result_df, stimulation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_fixed_F_fixed_R_with_holding_cost(\n",
    "    assigned_Ts,\n",
    "    assigned_Fs,\n",
    "    cost,\n",
    "    price,\n",
    "    salvage_value,\n",
    "    holding_cost,\n",
    "    Qk_hat_df,\n",
    "    demand_df_train,\n",
    "    Q_star,\n",
    "):\n",
    "\n",
    "    results_list = []\n",
    "    max_profit = None\n",
    "    max_profit_stimulation_result = {}\n",
    "\n",
    "    for assigned_T in assigned_Ts:\n",
    "        for assigned_F in assigned_Fs:\n",
    "            assigned_R = assigned_T - 2\n",
    "            mean_result, stimulation_result = cal_fixed_F_fixed_R_with_holding_cost(\n",
    "                Q_star,\n",
    "                assigned_F,\n",
    "                assigned_R,\n",
    "                demand_df_train,\n",
    "                cost,\n",
    "                price,\n",
    "                salvage_value,\n",
    "                Qk_hat_df,\n",
    "                holding_cost,\n",
    "            )\n",
    "            results_list.append(mean_result)\n",
    "\n",
    "            if max_profit is None or max_profit < mean_result[\"average_profits\"]:\n",
    "                # print(\n",
    "                #     f\"max_profit is changed from {max_profit} to {mean_result['average_profits']}\"\n",
    "                # )\n",
    "                max_profit = mean_result[\"average_profits\"]\n",
    "                max_profit_stimulation_result = stimulation_result\n",
    "\n",
    "    results_df_1 = pd.DataFrame(results_list).sort_values(\n",
    "        by=\"average_profits\", ascending=False\n",
    "    )\n",
    "\n",
    "    return results_df_1, pd.DataFrame(max_profit_stimulation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S2 - Grid for Fixed Rk & Flexible F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cal_flexible_F_fixed_R(\n",
    "#     assigned_R,\n",
    "#     salvage_value,\n",
    "#     cost,\n",
    "#     price,\n",
    "#     Q_star,\n",
    "#     demand_df_train,\n",
    "#     Qk_hat_df,\n",
    "#     training_df,\n",
    "# ):\n",
    "#     # print(\n",
    "#     #     f\"+++++++++++++++++++++++++++++++++++++++ THis is R={assigned_R} +++++++++++++++++++++++++++++++++++++++++++++++++\"\n",
    "#     # )\n",
    "#     with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "#         model.setParam(\"OutputFlag\", True)\n",
    "#         model.setParam(\"Threads\", THREADS)\n",
    "#         model.setParam(\"MIPGap\", MIPGAP)\n",
    "#         model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "\n",
    "#         # ======================= Decision Variables =======================\n",
    "#         alphas = model.addVars(\n",
    "#             features_num + 1, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"alphas\"\n",
    "#         )\n",
    "#         Sold_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_0\")\n",
    "#         Sold_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_1\")\n",
    "#         Lost_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_0\")\n",
    "#         Lost_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_1\")\n",
    "#         Left_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_1\")\n",
    "\n",
    "#         f_vars = model.addVars(\n",
    "#             len(demand_df_train), lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"f_var\"\n",
    "#         )\n",
    "#         F_vars = model.addVars(len(demand_df_train), lb=0, ub=1, name=\"Fraction\")\n",
    "\n",
    "#         Q0_vars = model.addVars(\n",
    "#             len(demand_df_train), lb=0.0, ub=(Q_star + 1), name=\"Q0_var\"\n",
    "#         )\n",
    "#         Q1_vars = model.addVars(len(Qk_hat_df), lb=0.0, name=\"Q1_var\")\n",
    "\n",
    "#         profits_vars = model.addVars(\n",
    "#             len(demand_df_train), lb=-GRB.INFINITY, name=\"profits_vars\"\n",
    "#         )\n",
    "\n",
    "#         # ======================= Model Constraints =======================\n",
    "#         for i, row in demand_df_train.iterrows():\n",
    "#             demand_row = demand_df_train.iloc[i]\n",
    "#             Qk_hat_df_row = Qk_hat_df.iloc[i].tolist()\n",
    "#             X_data = training_df.iloc[i].tolist()\n",
    "#             X_data.append(1)\n",
    "\n",
    "#             model.addConstr(F_vars[i] >= 0, name=f\"Fraction_lower_bound_{i}\")\n",
    "#             model.addConstr(F_vars[i] <= 1, name=f\"Fraction_upper_bound_{i}\")\n",
    "\n",
    "#             # Calculate F using logistic regression\n",
    "#             model.addConstr(\n",
    "#                 f_vars[i]\n",
    "#                 == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "#             )\n",
    "#             model.addGenConstrLogistic(xvar=f_vars[i], yvar=F_vars[i])\n",
    "\n",
    "#             # Calculate initial order quantity\n",
    "#             model.addConstr(Q0_vars[i] == F_vars[i] * Q_star)\n",
    "\n",
    "#             # Define demand variables for before and after reorder point\n",
    "#             total_demand_before_R = demand_row[: assigned_R + 1].sum()\n",
    "#             total_demand_after_R = demand_row[assigned_R + 1 :].sum()\n",
    "\n",
    "#             # Calculate first period sales and lost sales\n",
    "#             model.addGenConstrMin(\n",
    "#                 Sold_0s[i],\n",
    "#                 [total_demand_before_R, Q0_vars[i]],\n",
    "#                 name=f\"min_sales_constr_{i}\",\n",
    "#             )\n",
    "\n",
    "#             # Calculate lost sales\n",
    "#             Lost_0_expr = total_demand_before_R - Q0_vars[i]\n",
    "#             Lost_0_var = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_expr_{i}\")\n",
    "#             model.addConstr(Lost_0_var == Lost_0_expr)\n",
    "#             model.addGenConstrMax(\n",
    "#                 Lost_0s[i], [Lost_0_var, 0], name=f\"max_lost_constr_{i}\"\n",
    "#             )\n",
    "\n",
    "#             # Calculate inventory left after first period\n",
    "#             left_0 = Q0_vars[i] - Sold_0s[i]\n",
    "\n",
    "#             # Calculate Q1 based on reorder point estimate\n",
    "#             Q_hat = Qk_hat_df_row[assigned_R]\n",
    "#             Q_hat_adjusted = Q_hat - Q0_vars[i]\n",
    "#             Q_hat_adjusted_var = model.addVar(\n",
    "#                 lb=-GRB.INFINITY, name=f\"Q_hat_adjusted_{i}\"\n",
    "#             )\n",
    "#             model.addConstr(Q_hat_adjusted_var == Q_hat_adjusted)\n",
    "\n",
    "#             model.addGenConstrMax(\n",
    "#                 Q1_vars[i], [Q_hat_adjusted_var, 0], name=f\"max_Q1_constr_{i}\"\n",
    "#             )\n",
    "\n",
    "#             # Calculate second period sales and lost sales\n",
    "#             total_stock_second_period = Q1_vars[i] + left_0\n",
    "#             total_stock_second_period_var = model.addVar(\n",
    "#                 lb=0, name=f\"total_stock_second_period_{i}\"\n",
    "#             )\n",
    "#             model.addConstr(total_stock_second_period_var == total_stock_second_period)\n",
    "\n",
    "#             model.addGenConstrMin(\n",
    "#                 Sold_1s[i],\n",
    "#                 [total_demand_after_R, total_stock_second_period_var],\n",
    "#                 name=f\"min_sales2_constr_{i}\",\n",
    "#             )\n",
    "\n",
    "#             # Calculate second period lost sales\n",
    "#             Lost_1_expr = total_demand_after_R - total_stock_second_period_var\n",
    "#             Lost_1_var = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_1_expr_{i}\")\n",
    "#             model.addConstr(Lost_1_var == Lost_1_expr)\n",
    "\n",
    "#             model.addGenConstrMax(\n",
    "#                 Lost_1s[i], [Lost_1_var, 0], name=f\"max_lost2_constr_{i}\"\n",
    "#             )\n",
    "\n",
    "#             model.addConstr(Left_1s[i] == total_stock_second_period_var - Sold_1s[i])\n",
    "\n",
    "#             # # Calculate holding costs directly in profit equation\n",
    "#             # holding_cost_1 = (\n",
    "#             #     (Q0_vars[i] + total_stock_second_period) * (assigned_R + 2 - 1) / 2\n",
    "#             # )\n",
    "#             # holding_cost_2 = (\n",
    "#             #     (total_stock_second_period + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "#             # )\n",
    "\n",
    "#             # Calculate profit\n",
    "#             model.addConstr(\n",
    "#                 profits_vars[i]\n",
    "#                 == (\n",
    "#                     (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue\n",
    "#                     - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "#                     - (cost - salvage_value) * Left_1s[i]  # Salvage cost\n",
    "#                     # - holding_cost * (holding_cost_1 + holding_cost_2)  # Holding cost\n",
    "#                 )\n",
    "#             )\n",
    "\n",
    "#         # Set objective\n",
    "#         model.setObjective(\n",
    "#             gp.quicksum(profits_vars[i] for i in range(len(demand_df_train))),\n",
    "#             GRB.MAXIMIZE,\n",
    "#         )\n",
    "\n",
    "#         model.write(\"s2_model_debug.lp\")\n",
    "#         model.write(\"s2_model.mps\")\n",
    "\n",
    "#         # Solve model\n",
    "#         try:\n",
    "#             model.optimize()\n",
    "\n",
    "#             if model.status == GRB.OPTIMAL or model.status == GRB.TIME_LIMIT:\n",
    "#                 print(f\"Model status: {model.status}\")\n",
    "\n",
    "#                 # Collect results\n",
    "#                 alpha_values = np.array([alpha.X for alpha in alphas.values()])\n",
    "\n",
    "#                 results = {\n",
    "#                     \"losses\": [],\n",
    "#                     \"lefts\": [],\n",
    "#                     \"profits\": [],\n",
    "#                     \"operation_profits\": [],\n",
    "#                     \"Q0s\": [],\n",
    "#                     \"Q1s\": [],\n",
    "#                     \"Fs\": [],\n",
    "#                 }\n",
    "\n",
    "#                 for i in range(len(demand_df_train)):\n",
    "#                     sold0, sold1 = Sold_0s[i].X, Sold_1s[i].X\n",
    "#                     lost0, lost1 = Lost_0s[i].X, Lost_1s[i].X\n",
    "#                     left1 = Left_1s[i].X\n",
    "#                     left0 = Q0_vars[i].X - Sold_0s[i].X\n",
    "\n",
    "#                     # Record results\n",
    "#                     results[\"losses\"].append(lost0 + lost1)\n",
    "#                     results[\"lefts\"].append(left1)\n",
    "#                     # results[\"lefts\"].append(left0)\n",
    "\n",
    "#                     results[\"operation_profits\"].append(\n",
    "#                         (price - cost) * (sold0 + sold1)\n",
    "#                     )\n",
    "#                     results[\"profits\"].append(profits_vars[i].X)\n",
    "#                     results[\"Q0s\"].append(Q0_vars[i].X)\n",
    "#                     results[\"Q1s\"].append(Q1_vars[i].X)\n",
    "#                     results[\"Fs\"].append(F_vars[i].X)\n",
    "\n",
    "#                     # print(f\"\\nObservation {i+1}:\")\n",
    "#                     # print(f\"Reorder day: {assigned_R}\")\n",
    "#                     # print(f\"Profit: {profits_vars[i].X:.2f}\")\n",
    "\n",
    "#                 return (\n",
    "#                     [assigned_R] * len(demand_df_train),  # Fixed R for all observations\n",
    "#                     results[\"losses\"],\n",
    "#                     results[\"lefts\"],\n",
    "#                     results[\"profits\"],\n",
    "#                     results[\"operation_profits\"],\n",
    "#                     alpha_values,\n",
    "#                     results[\"Fs\"],\n",
    "#                     results[\"Q0s\"],\n",
    "#                     results[\"Q1s\"],\n",
    "#                 )\n",
    "\n",
    "#             else:\n",
    "#                 print(\"===================== 找不到最佳解 ==================\")\n",
    "#                 print(f\"Model is feasible. Status: {model.status}\")\n",
    "#                 model.computeIIS()\n",
    "#                 model.write(\"model.ilp\")\n",
    "\n",
    "#                 for constr in model.getConstrs():\n",
    "#                     if constr.IISConstr:\n",
    "#                         print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "#                 for var in model.getVars():\n",
    "#                     if var.IISLB > 0 or var.IISUB > 0:\n",
    "#                         print(\n",
    "#                             f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "#                         )\n",
    "\n",
    "#                 return None\n",
    "\n",
    "#         except gp.GurobiError as e:\n",
    "#             print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "#             return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def grid_flexible_F_fixed_R(\n",
    "#     assigned_Ts,\n",
    "#     salvage_value,\n",
    "#     cost,\n",
    "#     price,\n",
    "#     Q_star,\n",
    "#     demand_df_train,\n",
    "#     Qk_hat_df_train,\n",
    "#     training_df,\n",
    "# ):\n",
    "#     results_dict = {\n",
    "#         \"R(T)\": [],\n",
    "#         \"R\": [],\n",
    "#         \"average_profits\": [],\n",
    "#         \"average_losses\": [],\n",
    "#         \"average_lefts\": [],\n",
    "#         \"average_operation_profits\": [],\n",
    "#         \"alpha_values\": [],\n",
    "#         \"F_vars\": [],\n",
    "#         \"Q0_vars\": [],\n",
    "#         \"Q1_vars\": [],\n",
    "#     }\n",
    "\n",
    "#     max_profit = None\n",
    "#     max_profit_stimulation_result = {}\n",
    "\n",
    "#     for assigned_T in assigned_Ts:\n",
    "#         assigned_R = assigned_T - 2\n",
    "#         result = cal_flexible_F_fixed_R(\n",
    "#             assigned_R=assigned_R,\n",
    "#             salvage_value=salvage_value,\n",
    "#             cost=cost,\n",
    "#             price=price,\n",
    "#             Q_star=Q_star,\n",
    "#             demand_df_train=demand_df_train,\n",
    "#             Qk_hat_df=Qk_hat_df_train,\n",
    "#             training_df=training_df,\n",
    "#         )\n",
    "\n",
    "#         if result is None:\n",
    "#             print(f\"模型沒有最佳解\")\n",
    "#             continue\n",
    "\n",
    "#         (\n",
    "#             all_Rs,\n",
    "#             losses,\n",
    "#             lefts,\n",
    "#             profits,\n",
    "#             operation_profits,\n",
    "#             alpha_values,\n",
    "#             F_vars,\n",
    "#             Q0_vars,\n",
    "#             Q1_vars,\n",
    "#         ) = result\n",
    "\n",
    "#         # 計算平均值\n",
    "#         average_losses = sum(losses) / len(losses) if losses else 0\n",
    "#         average_lefts = sum(lefts) / len(lefts) if lefts else 0\n",
    "#         average_profits = sum(profits) / len(profits) if profits else 0\n",
    "#         average_operation_profits = (\n",
    "#             sum(operation_profits) / len(operation_profits) if operation_profits else 0\n",
    "#         )\n",
    "\n",
    "#         # 將結果存儲到字典中\n",
    "#         results_dict[\"R(T)\"].append(assigned_T)\n",
    "#         results_dict[\"R\"].append(all_Rs)\n",
    "#         results_dict[\"average_losses\"].append(average_losses)\n",
    "#         results_dict[\"average_lefts\"].append(average_lefts)\n",
    "#         results_dict[\"average_profits\"].append(average_profits)\n",
    "#         results_dict[\"average_operation_profits\"].append(average_operation_profits)\n",
    "#         results_dict[\"alpha_values\"].append(alpha_values)\n",
    "#         results_dict[\"F_vars\"].append(F_vars)\n",
    "#         results_dict[\"Q0_vars\"].append(Q0_vars)\n",
    "#         results_dict[\"Q1_vars\"].append(Q1_vars)\n",
    "\n",
    "#         # print(f\"The average profits is {average_profits}\")\n",
    "\n",
    "#         if max_profit is None or max_profit < average_profits:\n",
    "#             # print(f\"max_profit is changed from {max_profit} to {average_profits}\")\n",
    "#             max_profit = average_profits\n",
    "#             max_profit_stimulation_result = {\n",
    "#                 \"R\": all_Rs,\n",
    "#                 \"F\": F_vars,\n",
    "#                 \"profits\": profits,\n",
    "#                 \"losses\": losses,\n",
    "#                 \"lefts\": lefts,\n",
    "#                 \"operation_profits\": operation_profits,\n",
    "#                 \"Q0\": Q0_vars,\n",
    "#                 \"Q1\": Q1_vars,\n",
    "#             }\n",
    "\n",
    "#     return pd.DataFrame(results_dict).sort_values(\n",
    "#         by=\"average_profits\", ascending=False\n",
    "#     ), pd.DataFrame(max_profit_stimulation_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S17 - Grid for Fixed Rk & Flexible F with lasso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_flexible_F_fixed_R(\n",
    "    assigned_R,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_train,\n",
    "    Qk_hat_df,\n",
    "    training_df,\n",
    "    lambda_alpha,\n",
    "):\n",
    "    print(\n",
    "        f\"+++++++++++++++++++++++++++++++++++++++ THis is R={assigned_R} +++++++++++++++++++++++++++++++++++++++++++++++++\"\n",
    "    )\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "        model.setParam(\"NonConvex\", 2)\n",
    "        model.setParam(\"IntFeasTol\", 1e-9)\n",
    "        model.setParam(\"NumericFocus\", 3)\n",
    "\n",
    "        # ======================= Decision Variables =======================\n",
    "        alphas = model.addVars(\n",
    "            features_num + 1, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"alphas\"\n",
    "        )\n",
    "        abs_alphas = model.addVars(alphas.keys(), lb=0, name=\"abs_alpha\")\n",
    "\n",
    "        # 進行 L1 正則化處理：alphas\n",
    "        for i in alphas.keys():\n",
    "            model.addConstr(abs_alphas[i] >= alphas[i])\n",
    "            model.addConstr(abs_alphas[i] >= -alphas[i])\n",
    "\n",
    "        Sold_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_0\")\n",
    "        Left_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_0\")\n",
    "        Lost_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_0\")\n",
    "\n",
    "        Sold_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_1\")\n",
    "        Left_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_1\")\n",
    "        Lost_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_1\")\n",
    "\n",
    "        f_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"f_var\"\n",
    "        )\n",
    "        F_vars = model.addVars(len(demand_df_train), lb=0, ub=1, name=\"Fraction\")\n",
    "\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, ub=(Q_star + 1), name=\"Q0_var\"\n",
    "        )\n",
    "        Q1_vars = model.addVars(len(Qk_hat_df), lb=0.0, name=\"Q1_var\")\n",
    "\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, name=\"profits_vars\"\n",
    "        )\n",
    "\n",
    "        # ======================= Model Constraints =======================\n",
    "        for i, row in demand_df_train.iterrows():\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i].tolist()\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            model.addConstr(F_vars[i] >= 0, name=f\"Fraction_lower_bound_{i}\")\n",
    "            model.addConstr(F_vars[i] <= 1, name=f\"Fraction_upper_bound_{i}\")\n",
    "\n",
    "            # Calculate F using logistic regression\n",
    "            model.addConstr(\n",
    "                f_vars[i]\n",
    "                == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            )\n",
    "            model.addGenConstrLogistic(\n",
    "                xvar=f_vars[i], yvar=F_vars[i], options=\"FuncNonlinear=1\"\n",
    "            )\n",
    "\n",
    "            # Calculate initial order quantity\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star)\n",
    "\n",
    "            # Define demand variables for before and after reorder point\n",
    "            total_demand_before_R = demand_row[: assigned_R + 1].sum()\n",
    "            total_demand_after_R = demand_row[assigned_R + 1 :].sum()\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Left_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0s[i],\n",
    "                [total_demand_before_R, Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_before_R - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_before_R - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # Calculate Q1 based on reorder point estimate\n",
    "            Q_hat = Qk_hat_df_row[assigned_R]\n",
    "            Q_hat_adjusted = Q_hat - Q0_vars[i]\n",
    "            Q_hat_adjusted_var = model.addVar(\n",
    "                lb=-GRB.INFINITY, name=f\"Q_hat_adjusted_{i}\"\n",
    "            )\n",
    "            model.addConstr(Q_hat_adjusted_var == Q_hat_adjusted)\n",
    "\n",
    "            model.addGenConstrMax(\n",
    "                Q1_vars[i], [Q_hat_adjusted_var, 0], name=f\"max_Q1_constr_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1s[i],\n",
    "                [total_demand_after_R, Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_after_R - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_after_R - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # # Calculate holding costs directly in profit equation\n",
    "            # holding_cost_1 = (\n",
    "            #     (Q0_vars[i] + total_stock_second_period) * (assigned_R + 2 - 1) / 2\n",
    "            # )\n",
    "            # holding_cost_2 = (\n",
    "            #     (total_stock_second_period + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "            # )\n",
    "\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * (Left_1s[i])  # left cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # model.addConstr(\n",
    "            #     profits_vars[i]\n",
    "            #     == (\n",
    "            #         (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "            #         - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "            #         - (cost - salvage_value) * (Left_0s[i] + Left_1s[i])  # left cost\n",
    "            #     ),\n",
    "            #     name=f\"Profit_Constraint_{i}\",\n",
    "            # )\n",
    "\n",
    "        # Set objective\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train)))\n",
    "            - lambda_alpha * gp.quicksum(abs_alphas[i] for i in abs_alphas.keys()),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "\n",
    "        model.write(\"s17_model_debug.lp\")\n",
    "        model.write(\"s17_model.mps\")\n",
    "\n",
    "        # Solve model\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL or model.status == GRB.TIME_LIMIT:\n",
    "                print(f\"Model status: {model.status}\")\n",
    "\n",
    "                # Collect results\n",
    "                alpha_values = np.array([alpha.X for alpha in alphas.values()])\n",
    "\n",
    "                results = {\n",
    "                    \"losses\": [],\n",
    "                    \"lefts\": [],\n",
    "                    \"profits\": [],\n",
    "                    \"operation_profits\": [],\n",
    "                    \"Q0s\": [],\n",
    "                    \"Q1s\": [],\n",
    "                    \"Fs\": [],\n",
    "                    \"fs\": [],\n",
    "                }\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "                    sold0, sold1 = Sold_0s[i].X, Sold_1s[i].X\n",
    "                    lost0, lost1 = Lost_0s[i].X, Lost_1s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    print(\n",
    "                        f\"Lost0: {lost0}, Lost1: {lost1}, Left0: {left0}, Left1: {left1}\"\n",
    "                    )\n",
    "\n",
    "                    # Record results\n",
    "                    results[\"losses\"].append(lost0 + lost1)\n",
    "\n",
    "                    # results[\"lefts\"].append(left1)\n",
    "                    results[\"lefts\"].append(left0 + left1)\n",
    "\n",
    "                    results[\"operation_profits\"].append(\n",
    "                        (price - cost) * (sold0 + sold1)\n",
    "                    )\n",
    "                    results[\"profits\"].append(profits_vars[i].X)\n",
    "                    results[\"Q1s\"].append(Q1_vars[i].X)\n",
    "\n",
    "                    # Check f\n",
    "                    x_data = training_df.iloc[i].tolist()\n",
    "                    x_data.append(1)\n",
    "                    f_train, F_train, Q0_train = compute_f_F_Q(\n",
    "                        x_data, alpha_values, Q_star\n",
    "                    )\n",
    "                    print(\n",
    "                        f\"f_train: {f_train}, F_train: {F_train}, Q0_train: {Q0_train}\"\n",
    "                    )\n",
    "                    if (\n",
    "                        truncate_to_2(f_train) == truncate_to_2(f_vars[i].X)\n",
    "                        and truncate_to_2(F_train) == truncate_to_2(F_vars[i].X)\n",
    "                        and truncate_to_2(Q0_train) == truncate_to_2(Q0_vars[i].X)\n",
    "                    ):\n",
    "                        print(\"f_train, F_train, Q0_train 都相等\")\n",
    "                        results[\"Q0s\"].append(Q0_vars[i].X)\n",
    "                        results[\"Fs\"].append(F_vars[i].X)\n",
    "                        results[\"fs\"].append(f_vars[i].X)\n",
    "                    else:\n",
    "                        print(f\"f_train, F_train, Q0_train 不相等\")\n",
    "                        results[\"Q0s\"].append(-1)\n",
    "                        results[\"Fs\"].append(-1)\n",
    "                        results[\"fs\"].append(-1)\n",
    "                        # results[\"Q0s\"].append(Q0_vars[i].X)\n",
    "                        # results[\"Fs\"].append(F_vars[i].X)\n",
    "                        # results[\"fs\"].append(f_vars[i].X)\n",
    "                return (\n",
    "                    [assigned_R] * len(demand_df_train),  # Fixed R for all observations\n",
    "                    results[\"losses\"],\n",
    "                    results[\"lefts\"],\n",
    "                    results[\"profits\"],\n",
    "                    results[\"operation_profits\"],\n",
    "                    alpha_values,\n",
    "                    results[\"Fs\"],\n",
    "                    results[\"fs\"],\n",
    "                    results[\"Q0s\"],\n",
    "                    results[\"Q1s\"],\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_flexible_F_fixed_R(\n",
    "    assigned_Ts,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_train,\n",
    "    Qk_hat_df_train,\n",
    "    training_df,\n",
    "):\n",
    "    results_dict = {\n",
    "        \"R(T)\": [],\n",
    "        \"R\": [],\n",
    "        \"average_profits\": [],\n",
    "        \"average_losses\": [],\n",
    "        \"average_lefts\": [],\n",
    "        \"average_operation_profits\": [],\n",
    "        \"alpha_values\": [],\n",
    "        \"F_vars\": [],\n",
    "        \"f_vars\": [],\n",
    "        \"Q0_vars\": [],\n",
    "        \"Q1_vars\": [],\n",
    "    }\n",
    "\n",
    "    max_profit = None\n",
    "    max_profit_stimulation_result = {}\n",
    "\n",
    "    for assigned_T in assigned_Ts:\n",
    "        assigned_R = assigned_T - 2\n",
    "        result = cal_flexible_F_fixed_R(\n",
    "            assigned_R=assigned_R,\n",
    "            salvage_value=salvage_value,\n",
    "            cost=cost,\n",
    "            price=price,\n",
    "            Q_star=Q_star,\n",
    "            demand_df_train=demand_df_train,\n",
    "            Qk_hat_df=Qk_hat_df_train,\n",
    "            training_df=training_df,\n",
    "            lambda_alpha=LASSO_ALPHA,\n",
    "        )\n",
    "\n",
    "        if result is None:\n",
    "            print(f\"模型沒有最佳解\")\n",
    "            continue\n",
    "\n",
    "        (\n",
    "            all_Rs,\n",
    "            losses,\n",
    "            lefts,\n",
    "            profits,\n",
    "            operation_profits,\n",
    "            alpha_values,\n",
    "            F_vars,\n",
    "            f_vars,\n",
    "            Q0_vars,\n",
    "            Q1_vars,\n",
    "        ) = result\n",
    "\n",
    "        # 計算平均值\n",
    "        average_losses = sum(losses) / len(losses) if losses else 0\n",
    "        average_lefts = sum(lefts) / len(lefts) if lefts else 0\n",
    "        average_profits = sum(profits) / len(profits) if profits else 0\n",
    "        average_operation_profits = (\n",
    "            sum(operation_profits) / len(operation_profits) if operation_profits else 0\n",
    "        )\n",
    "\n",
    "        # 將結果存儲到字典中\n",
    "        results_dict[\"R(T)\"].append(assigned_T)\n",
    "        results_dict[\"R\"].append(all_Rs)\n",
    "        results_dict[\"average_losses\"].append(average_losses)\n",
    "        results_dict[\"average_lefts\"].append(average_lefts)\n",
    "        results_dict[\"average_profits\"].append(average_profits)\n",
    "        results_dict[\"average_operation_profits\"].append(average_operation_profits)\n",
    "        results_dict[\"alpha_values\"].append(alpha_values)\n",
    "        results_dict[\"F_vars\"].append(F_vars)\n",
    "        results_dict[\"f_vars\"].append(f_vars)\n",
    "        results_dict[\"Q0_vars\"].append(Q0_vars)\n",
    "        results_dict[\"Q1_vars\"].append(Q1_vars)\n",
    "\n",
    "        # print(f\"The average profits is {average_profits}\")\n",
    "\n",
    "        if max_profit is None or max_profit < average_profits:\n",
    "            # print(f\"max_profit is changed from {max_profit} to {average_profits}\")\n",
    "            max_profit = average_profits\n",
    "            max_profit_stimulation_result = {\n",
    "                \"R\": all_Rs,\n",
    "                \"F\": F_vars,\n",
    "                \"f\": f_vars,\n",
    "                \"profits\": profits,\n",
    "                \"losses\": losses,\n",
    "                \"lefts\": lefts,\n",
    "                \"operation_profits\": operation_profits,\n",
    "                \"Q0\": Q0_vars,\n",
    "                \"Q1\": Q1_vars,\n",
    "            }\n",
    "\n",
    "    return pd.DataFrame(results_dict).sort_values(\n",
    "        by=\"average_profits\", ascending=False\n",
    "    ), pd.DataFrame(max_profit_stimulation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S13 - Grid for Fixed Rk & Optimized F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_optimized_F_fixed_R(\n",
    "    assigned_R,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_train,\n",
    "    Qk_hat_df,\n",
    "    training_df,\n",
    "):\n",
    "    print(\n",
    "        f\"+++++++++++++++++++++++++++++++++++++++ THis is R={assigned_R} +++++++++++++++++++++++++++++++++++++++++++++++++\"\n",
    "    )\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "\n",
    "        # ======================= Decision Variables =======================\n",
    "        # alphas = model.addVars(\n",
    "        #     features_num + 1, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"alphas\"\n",
    "        # )\n",
    "        Sold_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_0\")\n",
    "        Sold_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_1\")\n",
    "        Lost_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_0\")\n",
    "        Lost_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_1\")\n",
    "        Left_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_1\")\n",
    "\n",
    "        # f_vars = model.addVars(\n",
    "        #     len(demand_df_train), lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"f_var\"\n",
    "        # )\n",
    "        F_vars = model.addVars(len(demand_df_train), lb=0, ub=1, name=\"Fraction\")\n",
    "\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, ub=(Q_star + 1), name=\"Q0_var\"\n",
    "        )\n",
    "        Q1_vars = model.addVars(len(Qk_hat_df), lb=0.0, name=\"Q1_var\")\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, name=\"profits_vars\"\n",
    "        )\n",
    "\n",
    "        # ======================= Model Constraints =======================\n",
    "        for i, row in demand_df_train.iterrows():\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i].tolist()\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            model.addConstr(F_vars[i] >= 0, name=f\"Fraction_lower_bound_{i}\")\n",
    "            model.addConstr(F_vars[i] <= 1, name=f\"Fraction_upper_bound_{i}\")\n",
    "\n",
    "            # Calculate F using logistic regression\n",
    "            # model.addConstr(\n",
    "            #     f_vars[i]\n",
    "            #     == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            # )\n",
    "            # model.addGenConstrLogistic(xvar=f_vars[i], yvar=F_vars[i])\n",
    "\n",
    "            # Calculate initial order quantity\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star)\n",
    "\n",
    "            # Define demand variables for before and after reorder point\n",
    "            total_demand_before_R = demand_row[: assigned_R + 1].sum()\n",
    "            total_demand_after_R = demand_row[assigned_R + 1 :].sum()\n",
    "\n",
    "            # Calculate first period sales and lost sales\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0s[i],\n",
    "                [total_demand_before_R, Q0_vars[i]],\n",
    "                name=f\"min_sales_constr_{i}\",\n",
    "            )\n",
    "\n",
    "            # Calculate lost sales\n",
    "            Lost_0_expr = total_demand_before_R - Q0_vars[i]\n",
    "            Lost_0_var = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_expr_{i}\")\n",
    "            model.addConstr(Lost_0_var == Lost_0_expr)\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_var, 0], name=f\"max_lost_constr_{i}\"\n",
    "            )\n",
    "\n",
    "            # Calculate inventory left after first period\n",
    "            left_0 = Q0_vars[i] - Sold_0s[i]\n",
    "\n",
    "            # Calculate Q1 based on reorder point estimate\n",
    "            Q_hat = Qk_hat_df_row[assigned_R]\n",
    "            Q_hat_adjusted = Q_hat - Q0_vars[i]\n",
    "            Q_hat_adjusted_var = model.addVar(\n",
    "                lb=-GRB.INFINITY, name=f\"Q_hat_adjusted_{i}\"\n",
    "            )\n",
    "            model.addConstr(Q_hat_adjusted_var == Q_hat_adjusted)\n",
    "\n",
    "            model.addGenConstrMax(\n",
    "                Q1_vars[i], [Q_hat_adjusted_var, 0], name=f\"max_Q1_constr_{i}\"\n",
    "            )\n",
    "\n",
    "            # Calculate second period sales and lost sales\n",
    "            total_stock_second_period = Q1_vars[i] + left_0\n",
    "            total_stock_second_period_var = model.addVar(\n",
    "                lb=0, name=f\"total_stock_second_period_{i}\"\n",
    "            )\n",
    "            model.addConstr(total_stock_second_period_var == total_stock_second_period)\n",
    "\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1s[i],\n",
    "                [total_demand_after_R, total_stock_second_period_var],\n",
    "                name=f\"min_sales2_constr_{i}\",\n",
    "            )\n",
    "\n",
    "            # Calculate second period lost sales\n",
    "            Lost_1_expr = total_demand_after_R - total_stock_second_period_var\n",
    "            Lost_1_var = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_1_expr_{i}\")\n",
    "            model.addConstr(Lost_1_var == Lost_1_expr)\n",
    "\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_var, 0], name=f\"max_lost2_constr_{i}\"\n",
    "            )\n",
    "\n",
    "            model.addConstr(Left_1s[i] == total_stock_second_period_var - Sold_1s[i])\n",
    "\n",
    "            # # Calculate holding costs directly in profit equation\n",
    "            # holding_cost_1 = (\n",
    "            #     (Q0_vars[i] + total_stock_second_period) * (assigned_R + 2 - 1) / 2\n",
    "            # )\n",
    "            # holding_cost_2 = (\n",
    "            #     (total_stock_second_period + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "            # )\n",
    "\n",
    "            # Calculate profit\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "                    - (cost - salvage_value) * Left_1s[i]  # Salvage cost\n",
    "                    # - holding_cost * (holding_cost_1 + holding_cost_2)  # Holding cost\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Set objective\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train))),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "\n",
    "        model.write(\"s2_model_debug.lp\")\n",
    "        model.write(\"s2_model.mps\")\n",
    "\n",
    "        # Solve model\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL or model.status == GRB.TIME_LIMIT:\n",
    "                print(f\"Model status: {model.status}\")\n",
    "\n",
    "                # Collect results\n",
    "                # alpha_values = np.array([alpha.X for alpha in alphas.values()])\n",
    "\n",
    "                results = {\n",
    "                    \"losses\": [],\n",
    "                    \"lefts\": [],\n",
    "                    \"profits\": [],\n",
    "                    \"operation_profits\": [],\n",
    "                    \"Q0s\": [],\n",
    "                    \"Q1s\": [],\n",
    "                    \"Fs\": [],\n",
    "                }\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "                    sold0, sold1 = Sold_0s[i].X, Sold_1s[i].X\n",
    "                    lost0, lost1 = Lost_0s[i].X, Lost_1s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "\n",
    "                    # Record results\n",
    "                    results[\"losses\"].append(lost0 + lost1)\n",
    "                    results[\"lefts\"].append(left1)\n",
    "                    results[\"operation_profits\"].append(\n",
    "                        (price - cost) * (sold0 + sold1)\n",
    "                    )\n",
    "                    results[\"profits\"].append(profits_vars[i].X)\n",
    "                    results[\"Q0s\"].append(Q0_vars[i].X)\n",
    "                    results[\"Q1s\"].append(Q1_vars[i].X)\n",
    "                    results[\"Fs\"].append(F_vars[i].X)\n",
    "\n",
    "                    print(f\"\\nObservation {i+1}:\")\n",
    "                    print(f\"Reorder day: {assigned_R}\")\n",
    "                    print(f\"Profit: {profits_vars[i].X:.2f}\")\n",
    "\n",
    "                return (\n",
    "                    [assigned_R] * len(demand_df_train),  # Fixed R for all observations\n",
    "                    results[\"losses\"],\n",
    "                    results[\"lefts\"],\n",
    "                    results[\"profits\"],\n",
    "                    results[\"operation_profits\"],\n",
    "                    None,\n",
    "                    results[\"Fs\"],\n",
    "                    results[\"Q0s\"],\n",
    "                    results[\"Q1s\"],\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "XHdZiv2bbIfP"
   },
   "outputs": [],
   "source": [
    "def grid_optimized_F_fixed_R(\n",
    "    assigned_Ts,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_train,\n",
    "    Qk_hat_df_train,\n",
    "    training_df,\n",
    "):\n",
    "    results_dict = {\n",
    "        \"R(T)\": [],\n",
    "        \"R\": [],\n",
    "        \"average_profits\": [],\n",
    "        \"average_losses\": [],\n",
    "        \"average_lefts\": [],\n",
    "        \"average_operation_profits\": [],\n",
    "        \"alpha_values\": [],\n",
    "        \"F_vars\": [],\n",
    "        \"Q0_vars\": [],\n",
    "        \"Q1_vars\": [],\n",
    "    }\n",
    "\n",
    "    max_profit = None\n",
    "    max_profit_stimulation_result = {}\n",
    "\n",
    "    for assigned_T in assigned_Ts:\n",
    "        assigned_R = assigned_T - 2\n",
    "        result = cal_optimized_F_fixed_R(\n",
    "            assigned_R=assigned_R,\n",
    "            salvage_value=salvage_value,\n",
    "            cost=cost,\n",
    "            price=price,\n",
    "            Q_star=Q_star,\n",
    "            demand_df_train=demand_df_train,\n",
    "            Qk_hat_df=Qk_hat_df_train,\n",
    "            training_df=training_df,\n",
    "        )\n",
    "\n",
    "        if result is None:\n",
    "            print(f\"模型沒有最佳解\")\n",
    "            results_dict[\"R(T)\"].append(None)\n",
    "            results_dict[\"R\"].append(None)\n",
    "            results_dict[\"average_losses\"].append(None)\n",
    "            results_dict[\"average_lefts\"].append(None)\n",
    "            results_dict[\"average_profits\"].append(None)\n",
    "            results_dict[\"average_operation_profits\"].append(None)\n",
    "            results_dict[\"alpha_values\"].append(None)\n",
    "            results_dict[\"F_vars\"].append(None)\n",
    "            results_dict[\"Q0_vars\"].append(None)\n",
    "            results_dict[\"Q1_vars\"].append(None)\n",
    "\n",
    "            continue\n",
    "\n",
    "        (\n",
    "            all_Rs,\n",
    "            losses,\n",
    "            lefts,\n",
    "            profits,\n",
    "            operation_profits,\n",
    "            alpha_values,\n",
    "            F_vars,\n",
    "            Q0_vars,\n",
    "            Q1_vars,\n",
    "        ) = result\n",
    "\n",
    "        # 計算平均值\n",
    "        average_losses = sum(losses) / len(losses) if losses else 0\n",
    "        average_lefts = sum(lefts) / len(lefts) if lefts else 0\n",
    "        average_profits = sum(profits) / len(profits) if profits else 0\n",
    "        average_operation_profits = (\n",
    "            sum(operation_profits) / len(operation_profits) if operation_profits else 0\n",
    "        )\n",
    "\n",
    "        # 將結果存儲到字典中\n",
    "        results_dict[\"R(T)\"].append(assigned_T)\n",
    "        results_dict[\"R\"].append(all_Rs)\n",
    "        results_dict[\"average_losses\"].append(average_losses)\n",
    "        results_dict[\"average_lefts\"].append(average_lefts)\n",
    "        results_dict[\"average_profits\"].append(average_profits)\n",
    "        results_dict[\"average_operation_profits\"].append(average_operation_profits)\n",
    "        results_dict[\"alpha_values\"].append(alpha_values)\n",
    "        results_dict[\"F_vars\"].append(F_vars)\n",
    "        results_dict[\"Q0_vars\"].append(Q0_vars)\n",
    "        results_dict[\"Q1_vars\"].append(Q1_vars)\n",
    "\n",
    "        print(f\"The average profits is {average_profits}\")\n",
    "\n",
    "        if max_profit is None or max_profit < average_profits:\n",
    "            print(f\"max_profit is changed from {max_profit} to {average_profits}\")\n",
    "            max_profit = average_profits\n",
    "            max_profit_stimulation_result = {\n",
    "                \"R\": all_Rs,\n",
    "                \"F\": F_vars,\n",
    "                \"profits\": profits,\n",
    "                \"losses\": losses,\n",
    "                \"lefts\": lefts,\n",
    "                \"operation_profits\": operation_profits,\n",
    "                \"Q0\": Q0_vars,\n",
    "                \"Q1\": Q1_vars,\n",
    "            }\n",
    "\n",
    "    return pd.DataFrame(results_dict).sort_values(\n",
    "        by=\"average_profits\", ascending=False\n",
    "    ), pd.DataFrame(max_profit_stimulation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HzqGevK3OwNQ"
   },
   "source": [
    "## S3 - Grid for Fixed F & Flexible Rk(with full beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "JEygghprPvw5"
   },
   "outputs": [],
   "source": [
    "def cal_fixed_F_flexible_R(\n",
    "    assigned_F,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_train,\n",
    "    Qk_hat_df,\n",
    "    training_df,\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        betas = model.addVars(\n",
    "            K, features_num + 1, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"betas\"\n",
    "        )  # Beta coefficients\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "        Sold_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Sold_0\",\n",
    "        )\n",
    "        Left_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Left_0\",\n",
    "        )\n",
    "        Lost_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Lost_0\",\n",
    "        )\n",
    "\n",
    "        Sold_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Sold_1\",\n",
    "        )\n",
    "        Left_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Left_1\",\n",
    "        )\n",
    "        Lost_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Lost_1\",\n",
    "        )\n",
    "\n",
    "        Holding_Cost_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Holding_Cost_0\",\n",
    "        )\n",
    "\n",
    "        Holding_Cost_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Holding_Cost_1\",\n",
    "        )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=-GRB.INFINITY,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"profits_vars\",\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Total_Demand_from_k_to_T\",\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=1,\n",
    "            name=\"Fraction_for_second_order_amount\",\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), vtype=GRB.CONTINUOUS, lb=0, ub=Q_star, name=\"Q0_var\"\n",
    "        )\n",
    "\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        tau_vars = model.addVars(\n",
    "            len(demand_df_train), K, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"tau\"\n",
    "        )  # Tau變量\n",
    "        r_vars = model.addVars(\n",
    "            len(demand_df_train), K, vtype=GRB.CONTINUOUS, lb=0.0, ub=1.0, name=\"r\"\n",
    "        )  # but t-1 is different from others\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=demand_df_train.max().max(),\n",
    "            name=\"Q1_var\",\n",
    "        )  # Every stimulation will have there own Q1 vars.\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=(-demand_df_train.max().max() * 100),\n",
    "            ub=demand_df_train.max().max() * 100,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=(-demand_df_train.max().max() * 100),\n",
    "            ub=demand_df_train.max().max() * 100,\n",
    "            name=f\"Q_hat_adjusted\",\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, row in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            model.addConstr(F_vars[i] == assigned_F)\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "            # 用線性回歸計算確定最佳補貨時間\n",
    "            exp_tau_vars = []\n",
    "            for k in range(K):\n",
    "\n",
    "                # 計算 tau_vars 作為 beta 和特徵的線性組合\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, k]\n",
    "                    == gp.quicksum(\n",
    "                        X_data[j] * betas[k, j] for j in range(features_num + 1)\n",
    "                    ),\n",
    "                    name=f\"tau_computation_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "                # 定義指數變數\n",
    "                exp_tau_var = model.addVar(\n",
    "                    vtype=GRB.CONTINUOUS, name=f\"exp_tau_var_{i}_{k}\"\n",
    "                )\n",
    "                neg_tau_var = model.addVar(\n",
    "                    vtype=GRB.CONTINUOUS, name=f\"neg_tau_var_{i}_{k}\"\n",
    "                )\n",
    "\n",
    "                # 設定約束條件\n",
    "                model.addConstr(\n",
    "                    neg_tau_var == -tau_vars[i, k], name=f\"neg_tau_constr_{i}_{k}\"\n",
    "                )\n",
    "                model.addGenConstrExp(xvar=neg_tau_var, yvar=exp_tau_var)\n",
    "\n",
    "                exp_tau_vars.append(exp_tau_var)\n",
    "\n",
    "                model.addConstr(\n",
    "                    r_vars[i, k] * gp.quicksum(exp_tau_vars) == exp_tau_vars[k],\n",
    "                    name=f\"softmax_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "            ### 找到最大 R 以及 r, R 的相關限制式 -> k: 0~7\n",
    "            max_r_helpers = model.addVar(vtype=GRB.CONTINUOUS, name=\"max_r_helper\")\n",
    "            model.addGenConstrMax(\n",
    "                max_r_helpers,\n",
    "                [r_vars[i, k] for k in range(K)],\n",
    "                name=f\"MaxRConstraint_{i}\",\n",
    "            )\n",
    "\n",
    "            ### 指定讓當 r_vars 中的值等於 max_r 時，R_vars 設為 1 -> k: 0~7\n",
    "            for k in range(K):\n",
    "                model.addConstr(\n",
    "                    r_vars[i, k] - max_r_helpers >= (R_vars[i, k] - 1),\n",
    "                    \"link_r_R_{}\".format(k),\n",
    "                )\n",
    "                model.addGenConstrIndicator(\n",
    "                    R_vars[i, k], 1, r_vars[i, k] == max_r_helpers\n",
    "                )\n",
    "\n",
    "            ## 只會有一個 R 為 1\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"Ensure_only_one_R_true_{i}\",\n",
    "            )  # 0~7\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "\n",
    "            ### 將 Q_hats(重新估計的值) 與原先 Q0 值進行比較。如果發現原先估計的比較少，則補足 Q_hat_adjusted，如果不用補充，則為 0\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            # ### 0~k-1 的需求量\n",
    "            total_demand_up_to_k_minus_1_var = model.addVar(\n",
    "                name=f\"Total_Demand_Up_to_K_Minus_1_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_var\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == total_demand_up_to_k_minus_1_var,\n",
    "                name=f\"Calculate_Total_Demand_Up_to_K_minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            total_demand_from_k_to_T_var = model.addVar(\n",
    "                name=f\"Total_Demand_from_K_to_T_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_var\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i] == total_demand_from_k_to_T_var,\n",
    "                name=f\"Calculate_Total_Demand_from_k_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Sold_0_aux = model.addVar(name=f\"Sold_0_aux_{i}\")\n",
    "            Left_0_aux = model.addVar(name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(name=f\"Lost_0_aux_{i}\")\n",
    "            Sold_1_aux = model.addVar(name=f\"Sold_1_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0_aux,\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "            model.addConstr(Sold_0s[i] == Sold_0_aux, name=f\"Constr_Sold_0_eq_aux_{i}\")\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1_aux,\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "            model.addConstr(Sold_1s[i] == Sold_1_aux, name=f\"Constr_Sold_1_eq_aux_{i}\")\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Holding_Cost_0\n",
    "            assigned_R_var = model.addVar(vtype=GRB.INTEGER, name=f\"assigned_R_{i}\")\n",
    "            model.addConstr(\n",
    "                assigned_R_var == gp.quicksum(k * R_vars[i, k] for k in range(K)),\n",
    "                name=f\"Calc_assigned_R_{i}\",\n",
    "            )\n",
    "\n",
    "            model.addConstr(\n",
    "                Holding_Cost_0s[i]\n",
    "                == ((Q0_vars[i] + Q1_plus_lefts[i]) * (assigned_R_var + 2 - 1) / 2),\n",
    "                name=f\"Constr_Holding_Cost_0_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Holding_Cost_1\n",
    "            model.addConstr(\n",
    "                Holding_Cost_1s[i]\n",
    "                == ((Q1_plus_lefts[i] + Left_1s[i]) * (T - (assigned_R_var + 2)) / 2),\n",
    "                name=f\"Constr_Holding_Cost_1_{i}\",\n",
    "            )\n",
    "\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "                    - holding_cost\n",
    "                    * (Holding_Cost_0s[i] + Holding_Cost_1s[i])  # holding cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train))),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                print(\"===================== 找到最佳解 ==================\")\n",
    "                print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                print(\"Beta values:\")\n",
    "                for key, beta in betas.items():\n",
    "                    print(f\"beta{key}: {beta.X}\")\n",
    "\n",
    "                beta_values = np.array(\n",
    "                    [[betas[i, j].X for j in range(1)] for i in range(K)]\n",
    "                )\n",
    "                tau_values = np.array(\n",
    "                    [\n",
    "                        [tau_vars[i, j].X for j in range(K)]\n",
    "                        for i in range(len(demand_df_train))\n",
    "                    ]\n",
    "                )\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                all_holding_costs_0 = []\n",
    "                all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    print(\"----------------------------------------------\")\n",
    "                    print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "                    all_Q0s.append(Q0_vars[i].X)\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    all_Fs.append(F_vars[i].X)\n",
    "                    all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    for k in range(K):\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        print(f\"第 {k+2} 天補貨策略: R_vars = {R_value}\")\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "                    all_Rs.append(reorder_day)\n",
    "\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "                    # print(f\"第一階段需求量: {demand_row[: (reorder_day-1)].sum()}\")\n",
    "                    # print(f\"第二階段需求量: {demand_row[(reorder_day-1): ].sum()}\\n\")\n",
    "\n",
    "                    # print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "                    # print(f\"F_var（重新訂貨量佔總訂貨量比例）: {F_vars[i].X}\")\n",
    "                    # print(f\"Q0_var（期初庫存量）: {Q0_vars[i].X}\\n\")\n",
    "                    # print(f\"Q1_var（二次訂貨量）: {Q1_vars[i].X}\")\n",
    "                    # print(f\"Holding_Cost_0: {Holding_Cost_0}\")\n",
    "                    # print(f\"Holding_Cost_1: {Holding_Cost_1}\\n\")\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    print(check_results_df)\n",
    "\n",
    "                    # for t in range(2):\n",
    "                    #     if t == 0:\n",
    "                    #         print(\n",
    "                    #             f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                    #         )\n",
    "                    #     else:\n",
    "                    #         print(\n",
    "                    #             f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                    #         )\n",
    "\n",
    "                    # print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                print(\"==========================================\")\n",
    "                print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    beta_values,\n",
    "                    tau_values,\n",
    "                    all_holding_costs_0,\n",
    "                    all_holding_costs_1,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "18afnulQbj_B"
   },
   "outputs": [],
   "source": [
    "def grid_fixed_F_flexible_R(\n",
    "    assigned_Fs,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_train,\n",
    "    Qk_hat_df_train,\n",
    "    training_df,\n",
    "):\n",
    "    results_dict = {\n",
    "        \"R(T)\": [],\n",
    "        \"average_losses\": [],\n",
    "        \"average_lefts\": [],\n",
    "        \"average_operation_profits\": [],\n",
    "        \"average_profits\": [],\n",
    "        \"beta_values\": [],\n",
    "        \"F_vars\": [],\n",
    "        \"Q0_vars\": [],\n",
    "        \"Q1_vars\": [],\n",
    "        \"tau_values\": [],\n",
    "    }\n",
    "\n",
    "    max_profit = None\n",
    "    max_profit_stimulation_result = {}\n",
    "\n",
    "    for assigned_F in assigned_Fs:\n",
    "        print(\n",
    "            f\"+++++++++++++++++++++++++++++++++++++++ THis is F={assigned_F} +++++++++++++++++++++++++++++++++++++++++++++++++\"\n",
    "        )\n",
    "        result = cal_fixed_F_flexible_R(\n",
    "            assigned_F=assigned_F,\n",
    "            salvage_value=salvage_value,\n",
    "            cost=cost,\n",
    "            price=price,\n",
    "            Q_star=Q_star,\n",
    "            demand_df_train=demand_df_train,\n",
    "            Qk_hat_df=Qk_hat_df_train,\n",
    "            training_df=training_df,\n",
    "        )\n",
    "\n",
    "        if result is None:\n",
    "            print(f\"模型沒有最佳解\")\n",
    "\n",
    "        else:\n",
    "            (\n",
    "                all_Rs,\n",
    "                losses,\n",
    "                lefts,\n",
    "                profits,\n",
    "                operation_profits,\n",
    "                F_vars,\n",
    "                Q0_vars,\n",
    "                Q1_vars,\n",
    "                beta_values,\n",
    "                tau_values,\n",
    "                holding_costs_0s,\n",
    "                holding_costs_1s,\n",
    "                all_left0s,\n",
    "                all_left1s,\n",
    "                all_lost0s,\n",
    "                all_lost1s,\n",
    "            ) = result\n",
    "\n",
    "            # 计算平均值\n",
    "            average_losses = sum(losses) / len(losses) if losses else 0\n",
    "            average_lefts = sum(lefts) / len(lefts) if lefts else 0\n",
    "            average_profits = sum(profits) / len(profits) if profits else 0\n",
    "            average_operation_profits = (\n",
    "                sum(operation_profits) / len(operation_profits)\n",
    "                if operation_profits\n",
    "                else 0\n",
    "            )\n",
    "\n",
    "            # 将结果存储到字典中\n",
    "            results_dict[\"R(T)\"].append(all_Rs)\n",
    "            results_dict[\"average_losses\"].append(average_losses)\n",
    "            results_dict[\"average_lefts\"].append(average_lefts)\n",
    "            results_dict[\"average_profits\"].append(average_profits)\n",
    "            results_dict[\"average_operation_profits\"].append(average_operation_profits)\n",
    "            results_dict[\"beta_values\"].append(beta_values)\n",
    "            results_dict[\"tau_values\"].append(tau_values)\n",
    "            results_dict[\"F_vars\"].append(F_vars)\n",
    "            results_dict[\"Q0_vars\"].append(Q0_vars)\n",
    "            results_dict[\"Q1_vars\"].append(Q1_vars)\n",
    "\n",
    "            if max_profit is None or max_profit < average_profits:\n",
    "                print(f\"max_profit is changed from {max_profit} to {average_profits}\")\n",
    "                max_profit = average_profits\n",
    "                max_profit_stimulation_result = {\n",
    "                    \"R(T)\": all_Rs,\n",
    "                    \"F\": F_vars,\n",
    "                    \"profits\": profits,\n",
    "                    \"losses\": losses,\n",
    "                    \"lefts\": lefts,\n",
    "                    \"operation_profits\": operation_profits,\n",
    "                    \"Q0\": Q0_vars,\n",
    "                    \"Q1\": Q1_vars,\n",
    "                    \"hc0\": holding_costs_0s,\n",
    "                    \"hc1\": holding_costs_1s,\n",
    "                    \"Left0s\": all_left0s,\n",
    "                    \"Left1s\": all_left1s,\n",
    "                    \"lost0s\": all_lost0s,\n",
    "                    \"lost1s\": all_lost1s,\n",
    "                }\n",
    "\n",
    "            print(f\"beta_values: \\n{beta_values}\")\n",
    "\n",
    "    print(max_profit_stimulation_result)\n",
    "\n",
    "    return pd.DataFrame(results_dict).sort_values(\n",
    "        by=\"average_profits\", ascending=False\n",
    "    ), pd.DataFrame(max_profit_stimulation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4Bnp-M_QC6e"
   },
   "source": [
    "## Fully flexible F & Rk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6BPJ4AakQC6e"
   },
   "source": [
    "### S5 - Simple beta with softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "bdApAjTOQC6e"
   },
   "outputs": [],
   "source": [
    "def __fully_flexible_simple_beta_with_softmax_5(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        alphas = model.addVars(\n",
    "            features_num + 1, name=\"alphas\"\n",
    "        )  # alpha coefficients with intercept\n",
    "        betas = model.addVars(\n",
    "            K, features_num + 1, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"betas\"\n",
    "        )  # Beta coefficients\n",
    "        betas = model.addVars(\n",
    "            K, 1, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"betas_with_ONLY_intercept\"\n",
    "        )  # Beta coefficients with ONLY intercept\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "\n",
    "        #### 1-1. 計算兩階段 Sold, Loss, Left 以及總合的 profit\n",
    "        Sold_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Sold_0\",\n",
    "        )\n",
    "        Left_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Left_0\",\n",
    "        )\n",
    "        Lost_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Lost_0\",\n",
    "        )\n",
    "\n",
    "        Sold_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Sold_1\",\n",
    "        )\n",
    "        Left_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Left_1\",\n",
    "        )\n",
    "        Lost_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Lost_1\",\n",
    "        )\n",
    "\n",
    "        Holding_Cost_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Holding_Cost_0\",\n",
    "        )\n",
    "\n",
    "        Holding_Cost_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Holding_Cost_1\",\n",
    "        )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=-GRB.INFINITY,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"profits_vars\",\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Total_Demand_from_k_to_T\",\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        f_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=-GRB.INFINITY,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"f_var\",\n",
    "        )\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=1,\n",
    "            name=\"Fraction_for_second_order_amount\",\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), vtype=GRB.CONTINUOUS, lb=0, ub=Q_star, name=\"Q0_var\"\n",
    "        )\n",
    "\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        tau_vars = model.addVars(\n",
    "            len(demand_df_train), K, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"tau\"\n",
    "        )  # Tau變量\n",
    "        r_vars = model.addVars(\n",
    "            len(demand_df_train), K, vtype=GRB.CONTINUOUS, lb=0.0, ub=1.0, name=\"r\"\n",
    "        )  # but t-1 is different from others\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=demand_df_train.max().max(),\n",
    "            name=\"Q1_var\",\n",
    "        )  # Every stimulation will have there own Q1 vars.\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=(-demand_df_train.max().max() * 100),\n",
    "            ub=demand_df_train.max().max() * 100,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=(-demand_df_train.max().max() * 100),\n",
    "            ub=demand_df_train.max().max() * 100,\n",
    "            name=f\"Q_hat_adjusted\",\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, row in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            ### 用線性回歸計算F_var\n",
    "            model.addConstr(\n",
    "                f_vars[i]\n",
    "                == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            )\n",
    "            model.addGenConstrLogistic(\n",
    "                xvar=f_vars[i], yvar=F_vars[i], name=f\"logistic_constraint_{i}\"\n",
    "            )\n",
    "\n",
    "            ### Q0_var = F_vars * Q_star\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "            # 用線性回歸計算確定最佳補貨時間\n",
    "\n",
    "            ### 訓練 beta(使用 softmax)\n",
    "            exp_tau_vars = []\n",
    "            for k in range(K):\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, k] == betas[k, 0], name=f\"tau_computation_{i}_{k}\"\n",
    "                )  # 只使用截距項\n",
    "\n",
    "                exp_tau_var = model.addVar(\n",
    "                    vtype=GRB.CONTINUOUS, name=f\"exp_tau_var_{i}_{k}\"\n",
    "                )\n",
    "                neg_tau_var = model.addVar(\n",
    "                    vtype=GRB.CONTINUOUS, name=f\"neg_tau_var_{i}_{k}\"\n",
    "                )\n",
    "\n",
    "                model.addConstr(\n",
    "                    neg_tau_var == -tau_vars[i, k], name=f\"neg_tau_constr_{i}_{k}\"\n",
    "                )\n",
    "                model.addGenConstrExp(xvar=neg_tau_var, yvar=exp_tau_var)\n",
    "\n",
    "                exp_tau_vars.append(exp_tau_var)\n",
    "\n",
    "            for k in range(K):\n",
    "                model.addConstr(\n",
    "                    r_vars[i, k] * gp.quicksum(exp_tau_vars) == exp_tau_vars[k],\n",
    "                    name=f\"softmax_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "            ### 找到最大 R 以及 r, R 的相關限制式 -> k: 0~7\n",
    "            max_r_helpers = model.addVar(vtype=GRB.CONTINUOUS, name=\"max_r_helper\")\n",
    "            model.addGenConstrMax(\n",
    "                max_r_helpers,\n",
    "                [r_vars[i, k] for k in range(K)],\n",
    "                name=f\"MaxRConstraint_{i}\",\n",
    "            )\n",
    "\n",
    "            ### 指定讓當 r_vars 中的值等於 max_r 時，R_vars 設為 1 -> k: 0~7\n",
    "            for k in range(K):\n",
    "                model.addConstr(\n",
    "                    r_vars[i, k] - max_r_helpers >= (R_vars[i, k] - 1),\n",
    "                    \"link_r_R_{}\".format(k),\n",
    "                )\n",
    "                model.addGenConstrIndicator(\n",
    "                    R_vars[i, k], 1, r_vars[i, k] == max_r_helpers\n",
    "                )\n",
    "\n",
    "            ## 只會有一個 R 為 1\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"Ensure_only_one_R_true_{i}\",\n",
    "            )  # 0~7\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "\n",
    "            ### 將 Q_hats(重新估計的值) 與原先 Q0 值進行比較。如果發現原先估計的比較少，則補足 Q_hat_adjusted，如果不用補充，則為 0\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            \"\"\"\n",
    "            計算每一個時間點 k 為界線。Rk = 1 時，代表選到該 k 的 timeline，其他非k則是 R=0。\n",
    "            因此意義上可以理解為，model 2 挑到一個最好的 timeline k 並且將其 R 設為 1, 因此只會計算到該時間線的數值。\n",
    "            \"\"\"\n",
    "            # ### 0~k-1 的需求量\n",
    "            total_demand_up_to_k_minus_1_var = model.addVar(\n",
    "                name=f\"Total_Demand_Up_to_K_Minus_1_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_var\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == total_demand_up_to_k_minus_1_var,\n",
    "                name=f\"Calculate_Total_Demand_Up_to_K_minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            total_demand_from_k_to_T_var = model.addVar(\n",
    "                name=f\"Total_Demand_from_K_to_T_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_var\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i] == total_demand_from_k_to_T_var,\n",
    "                name=f\"Calculate_Total_Demand_from_k_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Sold_0_aux = model.addVar(name=f\"Sold_0_aux_{i}\")\n",
    "            Left_0_aux = model.addVar(name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(name=f\"Lost_0_aux_{i}\")\n",
    "            Sold_1_aux = model.addVar(name=f\"Sold_1_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0_aux,\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "            model.addConstr(Sold_0s[i] == Sold_0_aux, name=f\"Constr_Sold_0_eq_aux_{i}\")\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1_aux,\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "            model.addConstr(Sold_1s[i] == Sold_1_aux, name=f\"Constr_Sold_1_eq_aux_{i}\")\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            assigned_R_var = model.addVar(vtype=GRB.INTEGER, name=f\"assigned_R_{i}\")\n",
    "            model.addConstr(\n",
    "                assigned_R_var == gp.quicksum(k * R_vars[i, k] for k in range(K)),\n",
    "                name=f\"Calc_assigned_R_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Holding_Cost_0\n",
    "            model.addConstr(\n",
    "                Holding_Cost_0s[i]\n",
    "                == ((Q0_vars[i] + Q1_plus_lefts[i]) * (assigned_R_var + 2 - 1) / 2),\n",
    "                name=f\"Constr_Holding_Cost_0_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Holding_Cost_1\n",
    "            model.addConstr(\n",
    "                Holding_Cost_1s[i]\n",
    "                == ((Q1_plus_lefts[i] + Left_1s[i]) * (T - (assigned_R_var + 2)) / 2),\n",
    "                name=f\"Constr_Holding_Cost_1_{i}\",\n",
    "            )\n",
    "\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "                    - holding_cost\n",
    "                    * (Holding_Cost_0s[i] + Holding_Cost_1s[i])  # holding cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train))),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                print(\"===================== 找到最佳解 ==================\")\n",
    "                print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                print(\"Alphas values:\")\n",
    "                for key, alpha in alphas.items():\n",
    "                    print(f\"alpha[{key}]: {alpha.X}\")\n",
    "\n",
    "                print(\"Beta values:\")\n",
    "                for key, beta in betas.items():\n",
    "                    print(f\"beta{key}: {beta.X}\")\n",
    "\n",
    "                alpha_values = np.array([alpha.X for _, alpha in alphas.items()])\n",
    "                beta_values = np.array(\n",
    "                    [[betas[i, j].X for j in range(1)] for i in range(K)]\n",
    "                )\n",
    "                f_values = np.array([f.X for _, f in f_vars.items()])\n",
    "                tau_values = np.array(\n",
    "                    [\n",
    "                        [tau_vars[i, j].X for j in range(K)]\n",
    "                        for i in range(len(demand_df_train))\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                print(f\"------------\")\n",
    "                print(f\"f_values:\\n{f_values}\")\n",
    "                print(f\"tau_values:\\n{tau_values}\")\n",
    "\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                all_holding_costs_0 = []\n",
    "                all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    print(\"----------------------------------------------\")\n",
    "                    print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "                    all_Q0s.append(Q0_vars[i].X)\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    all_Fs.append(F_vars[i].X)\n",
    "                    all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    for k in range(K):\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        print(f\"第 {k+2} 天補貨策略: R_vars = {R_value}\")\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "                    all_Rs.append(reorder_day)\n",
    "\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "                    # print(f\"第一階段需求量: {demand_row[: (reorder_day-1)].sum()}\")\n",
    "                    # print(f\"第二階段需求量: {demand_row[(reorder_day-1): ].sum()}\\n\")\n",
    "\n",
    "                    # print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "                    # print(f\"F_var（重新訂貨量佔總訂貨量比例）: {F_vars[i].X}\")\n",
    "                    # print(f\"Q0_var（期初庫存量）: {Q0_vars[i].X}\\n\")\n",
    "                    # print(f\"Q1_var（二次訂貨量）: {Q1_vars[i].X}\")\n",
    "                    # print(f\"Holding_Cost_0: {Holding_Cost_0}\")\n",
    "                    # print(f\"Holding_Cost_1: {Holding_Cost_1}\\n\")\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    print(check_results_df)\n",
    "\n",
    "                    # for t in range(2):\n",
    "                    #     if t == 0:\n",
    "                    #         print(\n",
    "                    #             f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                    #         )\n",
    "                    #     else:\n",
    "                    #         print(\n",
    "                    #             f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                    #         )\n",
    "\n",
    "                    # print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                print(\"==========================================\")\n",
    "                print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    alpha_values,\n",
    "                    beta_values,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    f_values,\n",
    "                    tau_values,\n",
    "                    all_holding_costs_0,\n",
    "                    all_holding_costs_1,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "rjpIHSWueRBJ"
   },
   "outputs": [],
   "source": [
    "def fully_flexible_simple_beta_with_softmax_5(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    result = __fully_flexible_simple_beta_with_softmax_5(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "\n",
    "    if result is None:\n",
    "        print(f\"找不到最佳解\")\n",
    "        return None, None\n",
    "    else:\n",
    "        (\n",
    "            all_Rs,\n",
    "            all_losses,\n",
    "            all_lefts,\n",
    "            all_profits,\n",
    "            all_operation_profits,\n",
    "            alpha_values,\n",
    "            beta_values,\n",
    "            all_Fs,\n",
    "            all_Q0s,\n",
    "            all_Q1s,\n",
    "            f_values,\n",
    "            tau_values,\n",
    "            holding_costs_0s,\n",
    "            holding_costs_1s,\n",
    "            all_left0s,\n",
    "            all_left1s,\n",
    "            all_lost0s,\n",
    "            all_lost1s,\n",
    "        ) = result\n",
    "        return make_s3_related_strtegies_result(\n",
    "            all_Rs=all_Rs,\n",
    "            losses=all_losses,\n",
    "            lefts=all_lefts,\n",
    "            profits=all_profits,\n",
    "            operation_profits=all_operation_profits,\n",
    "            alpha_values=alpha_values,\n",
    "            beta_values=beta_values,\n",
    "            F_vars=all_Fs,\n",
    "            Q0_vars=all_Q0s,\n",
    "            Q1_vars=all_Q1s,\n",
    "            f_values=f_values,\n",
    "            tau_values=tau_values,\n",
    "            holding_costs_0s=holding_costs_0s,\n",
    "            holding_costs_1s=holding_costs_1s,\n",
    "            all_left0s=all_left0s,\n",
    "            all_left1s=all_left1s,\n",
    "            all_lost0s=all_lost0s,\n",
    "            all_lost1s=all_lost1s,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8HSaPvrQC6f"
   },
   "source": [
    "### S6 - Simple beta and softmax with T is 1 - sum(T-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "FJ6F57YQQC6f"
   },
   "outputs": [],
   "source": [
    "def __fully_flexible_simple_beta_with_softmax_6(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        alphas = model.addVars(features_num + 1, lb=-GRB.INFINITY, name=\"alphas\")\n",
    "        betas = model.addVars(\n",
    "            K, 1, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"betas_with_ONLY_intercept\"\n",
    "        )\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "\n",
    "        #### 1-1. 計算兩階段 Sold, Loss, Left 以及總合的 profit\n",
    "        Sold_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_0\")\n",
    "        Left_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_0\")\n",
    "        Lost_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_0\")\n",
    "\n",
    "        Sold_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_1\")\n",
    "        Left_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_1\")\n",
    "        Lost_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_1\")\n",
    "        Holding_Cost_0s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_0\"\n",
    "        )\n",
    "\n",
    "        Holding_Cost_1s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_1\"\n",
    "        )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, name=\"profits_vars\"\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, name=\"Total_Demand_from_k_to_T\"\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        f_vars = model.addVars(len(demand_df_train), lb=-GRB.INFINITY, name=\"f_var\")\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=1, name=\"Fraction_for_second_order_amount\"\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=(Q_star + 1), name=\"Q0_var\"\n",
    "        )\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        r_vars = model.addVars(len(demand_df_train), K, lb=0.0, ub=1.0, name=\"r\")\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(len(Qk_hat_df), lb=0.0, name=\"Q1_var\")\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            # lb=0.0,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df), lb=-GRB.INFINITY, name=f\"Q_hat_adjusted\"\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, row in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            ### 用線性回歸計算F_var\n",
    "            model.addConstr(\n",
    "                f_vars[i]\n",
    "                == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            )\n",
    "            model.addGenConstrLogistic(\n",
    "                xvar=f_vars[i], yvar=F_vars[i], name=f\"logistic_constraint_{i}\"\n",
    "            )\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "            # 用線性回歸計算確定最佳補貨時間\n",
    "            exp_tau_vars = []\n",
    "            for p in range(K - 1):  # 一直到前一個\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, p] == betas[p, 0], name=f\"tau_computation_{i}_{p}\"\n",
    "                )  # 只使用截距項\n",
    "\n",
    "                # 定義指數變數\n",
    "                exp_tau_var = model.addVar(lb=0, name=f\"exp_tau_var_{i}_{p}\")\n",
    "                neg_tau_var = model.addVar(\n",
    "                    lb=-GRB.INFINITY, ub=0, name=f\"neg_tau_var_{i}_{p}\"\n",
    "                )\n",
    "                model.addConstr(\n",
    "                    neg_tau_var == -tau_vars[i, p], name=f\"neg_tau_constr_{i}_{p}\"\n",
    "                )\n",
    "                model.addGenConstrExp(xvar=neg_tau_var, yvar=exp_tau_var)\n",
    "                exp_tau_vars.append(exp_tau_var)\n",
    "\n",
    "            sum_exp_tau_vars = model.addVar(lb=0, name=f\"sum_exp_tau_vars_{i}\")\n",
    "            model.addConstr(\n",
    "                sum_exp_tau_vars == gp.quicksum(exp_tau_vars),\n",
    "                name=f\"sum_exp_tau_vars_computation_{i}\",\n",
    "            )\n",
    "\n",
    "            # 將 r_vars 的最後一個變量設為 1，其他變量根據 softmax 計算\n",
    "            for p in range(K):\n",
    "                if p == K - 1:  # 最後一個是特別處理\n",
    "                    r_sum_without_last = gp.quicksum(r_vars[i, p] for p in range(K - 1))\n",
    "                    model.addConstr(\n",
    "                        r_vars[i, p] == 1 - r_sum_without_last,\n",
    "                        name=f\"r_var_fixed_{i}_{p}\",\n",
    "                    )\n",
    "                else:\n",
    "                    model.addConstr(\n",
    "                        r_vars[i, p] * (sum_exp_tau_vars + 1) == exp_tau_vars[p],\n",
    "                        name=f\"softmax_{i}_{p}\",\n",
    "                    )\n",
    "\n",
    "            ### 找到最大 R 以及 r, R 的相關限制式 -> k: 0~7\n",
    "            max_r_helpers = model.addVar(lb=0.0, ub=1.0, name=\"max_r_helper\")\n",
    "            model.addGenConstrMax(\n",
    "                max_r_helpers,\n",
    "                [r_vars[i, k] for k in range(K)],\n",
    "                name=f\"MaxRConstraint_{i}\",\n",
    "            )\n",
    "\n",
    "            ### 指定讓當 r_vars 中的值等於 max_r 時，R_vars 設為 1 -> k: 0~7\n",
    "            eps = 1e-10\n",
    "            for k in range(K):\n",
    "                model.addGenConstrIndicator(\n",
    "                    R_vars[i, k], 1, r_vars[i, k] >= max_r_helpers - eps\n",
    "                )\n",
    "\n",
    "            ## 只會有一個 R 為 1\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"Ensure_only_one_R_true_{i}\",\n",
    "            )\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            \"\"\"\n",
    "            計算每一個時間點 k 為界線。Rk = 1 時，代表選到該 k 的 timeline，其他非k則是 R=0。\n",
    "            因此意義上可以理解為，model 2 挑到一個最好的 timeline k 並且將其 R 設為 1, 因此只會計算到該時間線的數值。\n",
    "            \"\"\"\n",
    "            # ### 0~k-1 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Left_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0s[i],\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1s[i],\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # assigned_R_var = model.addVar(vtype=GRB.INTEGER, name=f\"assigned_R_{i}\")\n",
    "            # model.addConstr(\n",
    "            #     assigned_R_var == gp.quicksum(k * R_vars[i, k] for k in range(K)),\n",
    "            #     name=f\"Calc_assigned_R_{i}\",\n",
    "            # )\n",
    "\n",
    "            # # 計算 Holding_Cost_0\n",
    "            # model.addConstr(\n",
    "            #     Holding_Cost_0s[i]\n",
    "            #     == ((Q0_vars[i] + Q1_plus_lefts[i]) * (assigned_R_var + 2 - 1) / 2),\n",
    "            #     name=f\"Constr_Holding_Cost_0_{i}\",\n",
    "            # )\n",
    "\n",
    "            # # 計算 Holding_Cost_1\n",
    "            # model.addConstr(\n",
    "            #     Holding_Cost_1s[i]\n",
    "            #     == ((Q1_plus_lefts[i] + Left_1s[i]) * (T - (assigned_R_var + 2)) / 2),\n",
    "            #     name=f\"Constr_Holding_Cost_1_{i}\",\n",
    "            # )\n",
    "\n",
    "            # model.addConstr(\n",
    "            #     profits_vars[i]\n",
    "            #     == (\n",
    "            #         (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "            #         - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "            #         - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "            #         # - holding_cost\n",
    "            #         # * (Holding_Cost_0s[i] + Holding_Cost_1s[i])  # holding cost\n",
    "            #     ),\n",
    "            #     name=f\"Profit_Constraint_{i}\",\n",
    "            # )\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train))),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "\n",
    "        model.write(\"s6_model_debug.lp\")\n",
    "        model.write(\"s6_model.mps\")\n",
    "\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                print(\"===================== 找到最佳解 ==================\")\n",
    "                print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                print(\"Alphas values:\")\n",
    "                for key, alpha in alphas.items():\n",
    "                    print(f\"alpha[{key}]: {alpha.X}\")\n",
    "\n",
    "                print(\"Beta values:\")\n",
    "                for key, beta in betas.items():\n",
    "                    print(f\"beta{key}: {beta.X}\")\n",
    "\n",
    "                alpha_values = np.array([alpha.X for _, alpha in alphas.items()])\n",
    "                beta_values = np.array(\n",
    "                    [[betas[k, j].X for j in range(features_num + 1)] for k in range(K)]\n",
    "                )\n",
    "                print(f\"beta_values:\\n{beta_values}\")\n",
    "\n",
    "                f_values = np.array([f.X for _, f in f_vars.items()])\n",
    "                tau_values = np.array(\n",
    "                    [\n",
    "                        [tau_vars[i, j].X for j in range(K)]\n",
    "                        for i in range(len(demand_df_train))\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                print(f\"------------\")\n",
    "                print(f\"f_values:\\n{f_values}\")\n",
    "                print(f\"tau_values:\\n{tau_values}\")\n",
    "\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                all_rs = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                all_holding_costs_0 = []\n",
    "                all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    print(\"----------------------------------------------\")\n",
    "                    print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "                    all_Q0s.append(Q0_vars[i].X)\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    all_Fs.append(F_vars[i].X)\n",
    "                    all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    rs = []\n",
    "                    for k in range(K):\n",
    "                        rs.append(r_vars[i, k].X)\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        print(\n",
    "                            f\"第 {k+2} 天補貨策略: R_vars = {R_value}, r_vars = {rs[k]}\"\n",
    "                        )\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "\n",
    "                    all_Rs.append(reorder_day)\n",
    "                    all_rs.append(rs)\n",
    "\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    print(check_results_df)\n",
    "\n",
    "                    for t in range(2):\n",
    "                        if t == 0:\n",
    "                            print(\n",
    "                                f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                            )\n",
    "                        else:\n",
    "                            print(\n",
    "                                f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                            )\n",
    "\n",
    "                    print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                print(\"==========================================\")\n",
    "                print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    alpha_values,\n",
    "                    beta_values,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    f_values,\n",
    "                    tau_values,\n",
    "                    all_holding_costs_0,\n",
    "                    all_holding_costs_1,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "iAQkhleJepdr"
   },
   "outputs": [],
   "source": [
    "def fully_flexible_simple_beta_with_softmax_6(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    result = __fully_flexible_simple_beta_with_softmax_6(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "\n",
    "    if result is None:\n",
    "        print(f\"找不到最佳解\")\n",
    "        return None, None\n",
    "    else:\n",
    "        (\n",
    "            all_Rs,\n",
    "            all_losses,\n",
    "            all_lefts,\n",
    "            all_profits,\n",
    "            all_operation_profits,\n",
    "            alpha_values,\n",
    "            beta_values,\n",
    "            all_Fs,\n",
    "            all_Q0s,\n",
    "            all_Q1s,\n",
    "            f_values,\n",
    "            tau_values,\n",
    "            holding_costs_0s,\n",
    "            holding_costs_1s,\n",
    "            all_left0s,\n",
    "            all_left1s,\n",
    "            all_lost0s,\n",
    "            all_lost1s,\n",
    "        ) = result\n",
    "        return make_s3_related_strtegies_result(\n",
    "            all_Rs=all_Rs,\n",
    "            losses=all_losses,\n",
    "            lefts=all_lefts,\n",
    "            profits=all_profits,\n",
    "            operation_profits=all_operation_profits,\n",
    "            alpha_values=alpha_values,\n",
    "            beta_values=beta_values,\n",
    "            F_vars=all_Fs,\n",
    "            Q0_vars=all_Q0s,\n",
    "            Q1_vars=all_Q1s,\n",
    "            f_values=f_values,\n",
    "            tau_values=tau_values,\n",
    "            holding_costs_0s=holding_costs_0s,\n",
    "            holding_costs_1s=holding_costs_1s,\n",
    "            all_left0s=all_left0s,\n",
    "            all_left1s=all_left1s,\n",
    "            all_lost0s=all_lost0s,\n",
    "            all_lost1s=all_lost1s,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMeeInmeQC6g"
   },
   "source": [
    "### S7 - Simple beat and softmax with T is 1 - sum(T-1) & tau with f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "fCSTKTWSQC6g"
   },
   "outputs": [],
   "source": [
    "def __fully_flexible_simple_beta_with_softmax_7(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        alphas = model.addVars(\n",
    "            features_num + 1, name=\"alphas\"\n",
    "        )  # alpha coefficients with intercept\n",
    "        betas = model.addVars(\n",
    "            K, 1, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"betas_with_ONLY_intercept\"\n",
    "        )  # Beta coefficients with ONLY intercept\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "        Sold_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Sold_0\",\n",
    "        )\n",
    "        Left_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Left_0\",\n",
    "        )\n",
    "        Lost_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Lost_0\",\n",
    "        )\n",
    "\n",
    "        Sold_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Sold_1\",\n",
    "        )\n",
    "        Left_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Left_1\",\n",
    "        )\n",
    "        Lost_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Lost_1\",\n",
    "        )\n",
    "\n",
    "        Holding_Cost_0s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Holding_Cost_0\",\n",
    "        )\n",
    "\n",
    "        Holding_Cost_1s = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0.0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Holding_Cost_1\",\n",
    "        )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=-GRB.INFINITY,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"profits_vars\",\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"Total_Demand_from_k_to_T\",\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        f_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=-GRB.INFINITY,\n",
    "            ub=GRB.INFINITY,\n",
    "            name=\"f_var\",\n",
    "        )\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=1,\n",
    "            name=\"Fraction_for_second_order_amount\",\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), vtype=GRB.CONTINUOUS, lb=0, ub=Q_star, name=\"Q0_var\"\n",
    "        )\n",
    "\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        tau_vars = model.addVars(\n",
    "            len(demand_df_train), K, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"tau\"\n",
    "        )  # Tau變量\n",
    "        r_vars = model.addVars(\n",
    "            len(demand_df_train), K, vtype=GRB.CONTINUOUS, lb=0.0, ub=1.0, name=\"r\"\n",
    "        )  # but t-1 is different from others\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=0,\n",
    "            ub=demand_df_train.max().max(),\n",
    "            name=\"Q1_var\",\n",
    "        )  # Every stimulation will have there own Q1 vars.\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=(-demand_df_train.max().max() * 100),\n",
    "            ub=demand_df_train.max().max() * 100,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            vtype=GRB.CONTINUOUS,\n",
    "            lb=(-demand_df_train.max().max() * 100),\n",
    "            ub=demand_df_train.max().max() * 100,\n",
    "            name=f\"Q_hat_adjusted\",\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, row in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            ### 用線性回歸計算F_var\n",
    "            model.addConstr(\n",
    "                f_vars[i]\n",
    "                == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            )\n",
    "            model.addGenConstrLogistic(\n",
    "                xvar=f_vars[i], yvar=F_vars[i], name=f\"logistic_constraint_{i}\"\n",
    "            )\n",
    "\n",
    "            ### Q0_var = F_vars * Q_star\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "            # 用線性回歸計算確定最佳補貨時間\n",
    "            exp_tau_vars = []\n",
    "            for p in range(K - 1):  # 一直到前一個\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, p] == betas[p, 0] + f_vars[i],\n",
    "                    name=f\"tau_computation_{i}_{p}\",\n",
    "                )  # 只使用截距項\n",
    "                exp_tau_var = model.addVar(\n",
    "                    vtype=GRB.CONTINUOUS, name=f\"exp_tau_var_{i}_{p}\"\n",
    "                )\n",
    "\n",
    "                neg_tau_var = model.addVar(\n",
    "                    vtype=GRB.CONTINUOUS, name=f\"neg_tau_var_{i}_{p}\"\n",
    "                )\n",
    "                model.addConstr(\n",
    "                    neg_tau_var == -tau_vars[i, p], name=f\"neg_tau_constr_{i}_{p}\"\n",
    "                )\n",
    "                model.addGenConstrExp(xvar=neg_tau_var, yvar=exp_tau_var)\n",
    "\n",
    "                exp_tau_vars.append(exp_tau_var)\n",
    "\n",
    "            sum_exp_tau_vars = model.addVar(\n",
    "                vtype=GRB.CONTINUOUS, name=f\"sum_exp_tau_vars_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                sum_exp_tau_vars == gp.quicksum(exp_tau_vars),\n",
    "                name=f\"sum_exp_tau_vars_computation_{i}\",\n",
    "            )\n",
    "\n",
    "            # 將 r_vars 的最後一個變量設為 1，其他變量根據 softmax 計算\n",
    "            for p in range(K):\n",
    "                if p == K - 1:  # 最後一個是特別處理\n",
    "                    r_sum_without_last = gp.quicksum(r_vars[i, p] for p in range(K - 1))\n",
    "                    model.addConstr(\n",
    "                        r_vars[i, p] == 1 - r_sum_without_last,\n",
    "                        name=f\"r_var_fixed_{i}_{p}\",\n",
    "                    )\n",
    "                else:\n",
    "                    model.addConstr(\n",
    "                        r_vars[i, p] * (sum_exp_tau_vars + 1) == exp_tau_vars[p],\n",
    "                        name=f\"softmax_{i}_{p}\",\n",
    "                    )\n",
    "\n",
    "            ### 找到最大 R 以及 r, R 的相關限制式 -> k: 0~7\n",
    "            max_r_helpers = model.addVar(vtype=GRB.CONTINUOUS, name=\"max_r_helper\")\n",
    "            model.addGenConstrMax(\n",
    "                max_r_helpers,\n",
    "                [r_vars[i, k] for k in range(K)],\n",
    "                name=f\"MaxRConstraint_{i}\",\n",
    "            )\n",
    "\n",
    "            ### 指定讓當 r_vars 中的值等於 max_r 時，R_vars 設為 1 -> k: 0~7\n",
    "            for k in range(K):\n",
    "                model.addConstr(\n",
    "                    r_vars[i, k] - max_r_helpers >= (R_vars[i, k] - 1),\n",
    "                    \"link_r_R_{}\".format(k),\n",
    "                )\n",
    "                model.addGenConstrIndicator(\n",
    "                    R_vars[i, k], 1, r_vars[i, k] == max_r_helpers\n",
    "                )\n",
    "\n",
    "            ## 只會有一個 R 為 1\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"Ensure_only_one_R_true_{i}\",\n",
    "            )  # 0~7\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "\n",
    "            ### 將 Q_hats(重新估計的值) 與原先 Q0 值進行比較。如果發現原先估計的比較少，則補足 Q_hat_adjusted，如果不用補充，則為 0\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            # ### 0~k-1 的需求量\n",
    "            total_demand_up_to_k_minus_1_var = model.addVar(\n",
    "                name=f\"Total_Demand_Up_to_K_Minus_1_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_var\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == total_demand_up_to_k_minus_1_var,\n",
    "                name=f\"Calculate_Total_Demand_Up_to_K_minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            total_demand_from_k_to_T_var = model.addVar(\n",
    "                name=f\"Total_Demand_from_K_to_T_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_var\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i] == total_demand_from_k_to_T_var,\n",
    "                name=f\"Calculate_Total_Demand_from_k_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Sold_0_aux = model.addVar(name=f\"Sold_0_aux_{i}\")\n",
    "            Left_0_aux = model.addVar(name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(name=f\"Lost_0_aux_{i}\")\n",
    "            Sold_1_aux = model.addVar(name=f\"Sold_1_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0_aux,\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "            model.addConstr(Sold_0s[i] == Sold_0_aux, name=f\"Constr_Sold_0_eq_aux_{i}\")\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1_aux,\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "            model.addConstr(Sold_1s[i] == Sold_1_aux, name=f\"Constr_Sold_1_eq_aux_{i}\")\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            assigned_R_var = model.addVar(vtype=GRB.INTEGER, name=f\"assigned_R_{i}\")\n",
    "            model.addConstr(\n",
    "                assigned_R_var == gp.quicksum(k * R_vars[i, k] for k in range(K)),\n",
    "                name=f\"Calc_assigned_R_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Holding_Cost_0\n",
    "            model.addConstr(\n",
    "                Holding_Cost_0s[i]\n",
    "                == ((Q0_vars[i] + Q1_plus_lefts[i]) * (assigned_R_var + 2 - 1) / 2),\n",
    "                name=f\"Constr_Holding_Cost_0_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Holding_Cost_1\n",
    "            model.addConstr(\n",
    "                Holding_Cost_1s[i]\n",
    "                == ((Q1_plus_lefts[i] + Left_1s[i]) * (T - (assigned_R_var + 2)) / 2),\n",
    "                name=f\"Constr_Holding_Cost_1_{i}\",\n",
    "            )\n",
    "\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "                    - holding_cost\n",
    "                    * (Holding_Cost_0s[i] + Holding_Cost_1s[i])  # holding cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train))),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                print(\"===================== 找到最佳解 ==================\")\n",
    "                print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                print(\"Alphas values:\")\n",
    "                for key, alpha in alphas.items():\n",
    "                    print(f\"alpha[{key}]: {alpha.X}\")\n",
    "\n",
    "                print(\"Beta values:\")\n",
    "                for key, beta in betas.items():\n",
    "                    print(f\"beta{key}: {beta.X}\")\n",
    "\n",
    "                alpha_values = np.array([alpha.X for _, alpha in alphas.items()])\n",
    "                beta_values = np.array(\n",
    "                    [[betas[i, j].X for j in range(1)] for i in range(K)]\n",
    "                )\n",
    "                f_values = np.array([f.X for _, f in f_vars.items()])\n",
    "                tau_values = np.array(\n",
    "                    [\n",
    "                        [tau_vars[i, j].X for j in range(K)]\n",
    "                        for i in range(len(demand_df_train))\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                print(f\"------------\")\n",
    "                print(f\"f_values:\\n{f_values}\")\n",
    "                print(f\"tau_values:\\n{tau_values}\")\n",
    "\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                all_holding_costs_0 = []\n",
    "                all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    print(\"----------------------------------------------\")\n",
    "                    print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "                    all_Q0s.append(Q0_vars[i].X)\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    all_Fs.append(F_vars[i].X)\n",
    "                    all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    for k in range(K):\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        print(f\"第 {k+2} 天補貨策略: R_vars = {R_value}\")\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "                    all_Rs.append(reorder_day)\n",
    "\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "                    # print(f\"第一階段需求量: {demand_row[: (reorder_day-1)].sum()}\")\n",
    "                    # print(f\"第二階段需求量: {demand_row[(reorder_day-1): ].sum()}\\n\")\n",
    "\n",
    "                    # print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "                    # print(f\"F_var（重新訂貨量佔總訂貨量比例）: {F_vars[i].X}\")\n",
    "                    # print(f\"Q0_var（期初庫存量）: {Q0_vars[i].X}\\n\")\n",
    "                    # print(f\"Q1_var（二次訂貨量）: {Q1_vars[i].X}\")\n",
    "                    # print(f\"Holding_Cost_0: {Holding_Cost_0}\")\n",
    "                    # print(f\"Holding_Cost_1: {Holding_Cost_1}\\n\")\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    print(check_results_df)\n",
    "\n",
    "                    # for t in range(2):\n",
    "                    #     if t == 0:\n",
    "                    #         print(\n",
    "                    #             f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                    #         )\n",
    "                    #     else:\n",
    "                    #         print(\n",
    "                    #             f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                    #         )\n",
    "\n",
    "                    # print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                print(\"==========================================\")\n",
    "                print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    alpha_values,\n",
    "                    beta_values,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    f_values,\n",
    "                    tau_values,\n",
    "                    all_holding_costs_0,\n",
    "                    all_holding_costs_1,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "m0dwZyvzcL4m"
   },
   "outputs": [],
   "source": [
    "def fully_flexible_simple_beta_with_softmax_7(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "    result = __fully_flexible_simple_beta_with_softmax_7(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "\n",
    "    if result is None:\n",
    "        print(f\"找不到最佳解\")\n",
    "        return None, None\n",
    "    else:\n",
    "        (\n",
    "            all_Rs,\n",
    "            all_losses,\n",
    "            all_lefts,\n",
    "            all_profits,\n",
    "            all_operation_profits,\n",
    "            alpha_values,\n",
    "            beta_values,\n",
    "            all_Fs,\n",
    "            all_Q0s,\n",
    "            all_Q1s,\n",
    "            f_values,\n",
    "            tau_values,\n",
    "            holding_costs_0s,\n",
    "            holding_costs_1s,\n",
    "            all_left0s,\n",
    "            all_left1s,\n",
    "            all_lost0s,\n",
    "            all_lost1s,\n",
    "        ) = result\n",
    "        return make_s3_related_strtegies_result(\n",
    "            all_Rs=all_Rs,\n",
    "            losses=all_losses,\n",
    "            lefts=all_lefts,\n",
    "            profits=all_profits,\n",
    "            operation_profits=all_operation_profits,\n",
    "            alpha_values=alpha_values,\n",
    "            beta_values=beta_values,\n",
    "            F_vars=all_Fs,\n",
    "            Q0_vars=all_Q0s,\n",
    "            Q1_vars=all_Q1s,\n",
    "            f_values=f_values,\n",
    "            tau_values=tau_values,\n",
    "            holding_costs_0s=holding_costs_0s,\n",
    "            holding_costs_1s=holding_costs_1s,\n",
    "            all_left0s=all_left0s,\n",
    "            all_left1s=all_left1s,\n",
    "            all_lost0s=all_lost0s,\n",
    "            all_lost1s=all_lost1s,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgQovzuG41d_"
   },
   "source": [
    "### S4 - Beta with softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "tVy2xESR44dH"
   },
   "outputs": [],
   "source": [
    "def __fully_flexible_beta_with_softmax_4(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "        model.setParam(\"IntFeasTol\", 1e-9)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        alphas = model.addVars(features_num + 1, lb=-GRB.INFINITY, name=\"alphas\")\n",
    "        betas = model.addVars(K, features_num + 1, lb=-GRB.INFINITY, name=\"betas\")\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "        Sold_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_0\")\n",
    "        Left_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_0\")\n",
    "        Lost_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_0\")\n",
    "\n",
    "        Sold_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_1\")\n",
    "        Left_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_1\")\n",
    "        Lost_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_1\")\n",
    "\n",
    "        Holding_Cost_0s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_0\"\n",
    "        )\n",
    "\n",
    "        Holding_Cost_1s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_1\"\n",
    "        )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, name=\"profits_vars\"\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, name=\"Total_Demand_from_k_to_T\"\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        f_vars = model.addVars(len(demand_df_train), lb=-GRB.INFINITY, name=\"f_var\")\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=1, name=\"Fraction_for_second_order_amount\"\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=(Q_star + 1), name=\"Q0_var\"\n",
    "        )\n",
    "\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        # tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        r_vars = model.addVars(len(demand_df_train), K, lb=0.0, ub=1.0, name=\"r\")\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(len(Qk_hat_df), lb=0.0, name=\"Q1_var\")\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            lb=0.0,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df), lb=-GRB.INFINITY, name=f\"Q_hat_adjusted\"\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, _ in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            ### 用線性回歸計算F_var\n",
    "            model.addConstr(\n",
    "                f_vars[i]\n",
    "                == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            )\n",
    "            model.addGenConstrLogistic(\n",
    "                xvar=f_vars[i], yvar=F_vars[i], name=f\"logistic_constraint_{i}\"\n",
    "            )\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "            # 用線性回歸計算確定最佳補貨時間\n",
    "            exp_tau_vars = []\n",
    "            for k in range(K):\n",
    "\n",
    "                # 計算 tau_vars 作為 beta 和特徵的線性組合\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, k]\n",
    "                    == gp.quicksum(\n",
    "                        X_data[j] * betas[k, j] for j in range(features_num + 1)\n",
    "                    ),\n",
    "                    name=f\"tau_computation_{i}_{k}\",\n",
    "                )\n",
    "                # model.addConstr(tau_vars[i, k] >= -5, name=f\"tau_lb_{i}_{k}\")\n",
    "\n",
    "                exp_tau_var = model.addVar(lb=1e-6, name=f\"exp_tau_var_{i}_{k}\")\n",
    "                exp_tau_var = model.addVar(\n",
    "                    lb=-GRB.INFINITY, name=f\"exp_tau_var_{i}_{k}\"\n",
    "                )\n",
    "                model.addGenConstrExp(xvar=tau_vars[i, k], yvar=exp_tau_var)\n",
    "                exp_tau_vars.append(exp_tau_var)\n",
    "\n",
    "            ### 找到最大 R 以及 r, R 的相關限制式 -> k: 0~7\n",
    "            for k in range(K):\n",
    "                model.addConstr(\n",
    "                    r_vars[i, k] * gp.quicksum(exp_tau_vars) == exp_tau_vars[k],\n",
    "                    name=f\"softmax_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "            model.addConstr(\n",
    "                gp.quicksum(r_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"sum_r_{i}\",\n",
    "            )\n",
    "\n",
    "            max_r_helpers = model.addVar(lb=0.0, ub=1.0, name=\"max_r_helper\")\n",
    "            model.addGenConstrMax(\n",
    "                max_r_helpers,\n",
    "                [r_vars[i, k] for k in range(K)],\n",
    "                name=f\"MaxRConstraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # 確保 R_vars 的邏輯行為\n",
    "            for k in range(K):\n",
    "                model.addGenConstrIndicator(\n",
    "                    R_vars[i, k], True, r_vars[i, k] == max_r_helpers\n",
    "                )\n",
    "\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"Ensure_only_one_R_true_{i}\",\n",
    "            )\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            # ### 0~k-1 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Left_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0s[i],\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1s[i],\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train))),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "        model.write(\"s4_model_debug.lp\")\n",
    "        model.write(\"s4_model.mps\")\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                print(\"===================== 找到最佳解 ==================\")\n",
    "                print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                print(\"Alphas values:\")\n",
    "                for key, alpha in alphas.items():\n",
    "                    print(f\"alpha[{key}]: {alpha.X}\")\n",
    "\n",
    "                alpha_values = np.array([alpha.X for _, alpha in alphas.items()])\n",
    "                beta_values = np.array(\n",
    "                    [[betas[k, j].X for j in range(features_num + 1)] for k in range(K)]\n",
    "                )\n",
    "                print(f\"beta_values:\\n{beta_values}\")\n",
    "\n",
    "                f_values = np.array([f.X for _, f in f_vars.items()])\n",
    "                tau_values = np.array(\n",
    "                    [\n",
    "                        [tau_vars[i, j].X for j in range(K)]\n",
    "                        for i in range(len(demand_df_train))\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                print(f\"------------\")\n",
    "                print(f\"f_values:\\n{f_values}\")\n",
    "                print(f\"tau_values:\\n{tau_values}\")\n",
    "\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                all_rs = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                all_holding_costs_0 = []\n",
    "                all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    print(\"----------------------------------------------\")\n",
    "                    print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "                    all_Q0s.append(Q0_vars[i].X)\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    all_Fs.append(F_vars[i].X)\n",
    "                    all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    rs = []\n",
    "                    for k in range(K):\n",
    "                        rs.append(r_vars[i, k].X)\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        print(\n",
    "                            f\"第 {k+2} 天補貨策略: R_vars = {R_value}, r_vars = {rs[k]}\"\n",
    "                        )\n",
    "                        # print(\n",
    "                        #     f\"第 {k+2} 天補貨策略: R_vars = {R_value}, tau_vars = {tau_vars[i, k].X}\"\n",
    "                        # )\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "\n",
    "                    all_Rs.append(reorder_day)\n",
    "                    all_rs.append(rs)\n",
    "\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    print(check_results_df)\n",
    "\n",
    "                    for t in range(2):\n",
    "                        if t == 0:\n",
    "                            print(\n",
    "                                f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                            )\n",
    "                        else:\n",
    "                            print(\n",
    "                                f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                            )\n",
    "\n",
    "                    print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                print(\"==========================================\")\n",
    "                print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    alpha_values,\n",
    "                    beta_values,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    f_values,\n",
    "                    tau_values,\n",
    "                    all_holding_costs_0,\n",
    "                    all_holding_costs_1,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "tSxMyuGNeyyb"
   },
   "outputs": [],
   "source": [
    "def fully_flexible_beta_with_softmax_4(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    result = __fully_flexible_beta_with_softmax_4(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "    if result is None:\n",
    "        print(f\"找不到最佳解\")\n",
    "        return None, None\n",
    "    else:\n",
    "        (\n",
    "            all_Rs,\n",
    "            all_losses,\n",
    "            all_lefts,\n",
    "            all_profits,\n",
    "            all_operation_profits,\n",
    "            alpha_values,\n",
    "            beta_values,\n",
    "            all_Fs,\n",
    "            all_Q0s,\n",
    "            all_Q1s,\n",
    "            f_values,\n",
    "            tau_values,\n",
    "            holding_costs_0s,\n",
    "            holding_costs_1s,\n",
    "            all_left0s,\n",
    "            all_left1s,\n",
    "            all_lost0s,\n",
    "            all_lost1s,\n",
    "        ) = result\n",
    "\n",
    "        print(f\"all_Rs: {all_Rs}\")\n",
    "\n",
    "        return make_s3_related_strtegies_result(\n",
    "            all_Rs=all_Rs,\n",
    "            losses=all_losses,\n",
    "            lefts=all_lefts,\n",
    "            profits=all_profits,\n",
    "            operation_profits=all_operation_profits,\n",
    "            alpha_values=alpha_values,\n",
    "            beta_values=beta_values,\n",
    "            F_vars=all_Fs,\n",
    "            Q0_vars=all_Q0s,\n",
    "            Q1_vars=all_Q1s,\n",
    "            f_values=f_values,\n",
    "            tau_values=tau_values,\n",
    "            holding_costs_0s=holding_costs_0s,\n",
    "            holding_costs_1s=holding_costs_1s,\n",
    "            all_left0s=all_left0s,\n",
    "            all_left1s=all_left1s,\n",
    "            all_lost0s=all_lost0s,\n",
    "            all_lost1s=all_lost1s,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S9 - Without beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __fully_flexible_beta_with_softmax_9(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "        model.setParam(\"IntFeasTol\", 1e-9)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        alphas = model.addVars(features_num + 1, lb=-GRB.INFINITY, name=\"alphas\")\n",
    "        # betas = model.addVars(K, features_num + 1, lb=-GRB.INFINITY, name=\"betas\")\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "        Sold_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_0\")\n",
    "        Left_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_0\")\n",
    "        Lost_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_0\")\n",
    "\n",
    "        Sold_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_1\")\n",
    "        Left_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_1\")\n",
    "        Lost_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_1\")\n",
    "\n",
    "        Holding_Cost_0s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_0\"\n",
    "        )\n",
    "\n",
    "        Holding_Cost_1s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_1\"\n",
    "        )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, name=\"profits_vars\"\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, name=\"Total_Demand_from_k_to_T\"\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        f_vars = model.addVars(len(demand_df_train), lb=-GRB.INFINITY, name=\"f_var\")\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=1, name=\"Fraction_for_second_order_amount\"\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=(Q_star + 1), name=\"Q0_var\"\n",
    "        )\n",
    "\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        # tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        # r_vars = model.addVars(len(demand_df_train), K, lb=0.0, ub=1.0, name=\"r\")\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(len(Qk_hat_df), lb=0.0, name=\"Q1_var\")\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            lb=0.0,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df), lb=-GRB.INFINITY, name=f\"Q_hat_adjusted\"\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, _ in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            ### 用線性回歸計算F_var\n",
    "            model.addConstr(\n",
    "                f_vars[i]\n",
    "                == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            )\n",
    "            model.addGenConstrLogistic(\n",
    "                xvar=f_vars[i], yvar=F_vars[i], name=f\"logistic_constraint_{i}\"\n",
    "            )\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"Ensure_only_one_R_true_{i}\",\n",
    "            )\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            # ### 0~k-1 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Left_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0s[i],\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1s[i],\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train))),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "        model.write(\"s4_model_debug.lp\")\n",
    "        model.write(\"s4_model.mps\")\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                print(\"===================== 找到最佳解 ==================\")\n",
    "                print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                print(\"Alphas values:\")\n",
    "                for key, alpha in alphas.items():\n",
    "                    print(f\"alpha[{key}]: {alpha.X}\")\n",
    "\n",
    "                # print(\"Beta values:\")\n",
    "                # for key, beta in betas.items():\n",
    "                #     print(f\"beta{key}: {beta.X}\")\n",
    "\n",
    "                alpha_values = np.array([alpha.X for _, alpha in alphas.items()])\n",
    "                # beta_values = np.array(\n",
    "                #     [[betas[k, j].X for j in range(features_num + 1)] for k in range(K)]\n",
    "                # )\n",
    "                # print(f\"beta_values:\\n{beta_values}\")\n",
    "\n",
    "                f_values = np.array([f.X for _, f in f_vars.items()])\n",
    "                # tau_values = np.array(\n",
    "                #     [\n",
    "                #         [tau_vars[i, j].X for j in range(K)]\n",
    "                #         for i in range(len(demand_df_train))\n",
    "                #     ]\n",
    "                # )\n",
    "\n",
    "                print(f\"------------\")\n",
    "                print(f\"f_values:\\n{f_values}\")\n",
    "                # print(f\"tau_values:\\n{tau_values}\")\n",
    "\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                # all_rs = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                all_holding_costs_0 = []\n",
    "                all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    # print(\"----------------------------------------------\")\n",
    "                    # print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "                    all_Q0s.append(Q0_vars[i].X)\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    all_Fs.append(F_vars[i].X)\n",
    "                    all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    rs = []\n",
    "                    for k in range(K):\n",
    "                        # rs.append(r_vars[i, k].X)\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        # print(\n",
    "                        #     f\"第 {k+2} 天補貨策略: R_vars = {R_value}, r_vars = {rs[k]}\"\n",
    "                        # )\n",
    "                        # print(f\"第 {k+2} 天補貨策略: R_vars = {R_value}\")\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    # print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "\n",
    "                    all_Rs.append(reorder_day)\n",
    "                    # all_rs.append(rs)\n",
    "\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    print(check_results_df)\n",
    "\n",
    "                #     for t in range(2):\n",
    "                #         if t == 0:\n",
    "                #             print(\n",
    "                #                 f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                #             )\n",
    "                #         else:\n",
    "                #             print(\n",
    "                #                 f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                #             )\n",
    "\n",
    "                #     print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                # print(\"==========================================\")\n",
    "                # print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    alpha_values,\n",
    "                    None,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    f_values,\n",
    "                    None,\n",
    "                    all_holding_costs_0,\n",
    "                    all_holding_costs_1,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_flexible_beta_with_softmax_9(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    result = __fully_flexible_beta_with_softmax_9(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "    if result is None:\n",
    "        print(f\"找不到最佳解\")\n",
    "        return None, None\n",
    "    else:\n",
    "        (\n",
    "            all_Rs,\n",
    "            all_losses,\n",
    "            all_lefts,\n",
    "            all_profits,\n",
    "            all_operation_profits,\n",
    "            alpha_values,\n",
    "            beta_values,\n",
    "            all_Fs,\n",
    "            all_Q0s,\n",
    "            all_Q1s,\n",
    "            f_values,\n",
    "            tau_values,\n",
    "            holding_costs_0s,\n",
    "            holding_costs_1s,\n",
    "            all_left0s,\n",
    "            all_left1s,\n",
    "            all_lost0s,\n",
    "            all_lost1s,\n",
    "        ) = result\n",
    "\n",
    "        print(f\"all_Rs: {all_Rs}\")\n",
    "\n",
    "        return make_s3_related_strtegies_result(\n",
    "            all_Rs=all_Rs,\n",
    "            losses=all_losses,\n",
    "            lefts=all_lefts,\n",
    "            profits=all_profits,\n",
    "            operation_profits=all_operation_profits,\n",
    "            alpha_values=alpha_values,\n",
    "            beta_values=beta_values,\n",
    "            F_vars=all_Fs,\n",
    "            Q0_vars=all_Q0s,\n",
    "            Q1_vars=all_Q1s,\n",
    "            f_values=f_values,\n",
    "            tau_values=tau_values,\n",
    "            holding_costs_0s=holding_costs_0s,\n",
    "            holding_costs_1s=holding_costs_1s,\n",
    "            all_left0s=all_left0s,\n",
    "            all_left1s=all_left1s,\n",
    "            all_lost0s=all_lost0s,\n",
    "            all_lost1s=all_lost1s,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S11 - Beta(Beta+Gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __fully_flexible_beta_with_softmax_11(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "        model.setParam(\"IntFeasTol\", 1e-9)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        alphas = model.addVars(features_num + 1, lb=-GRB.INFINITY, name=\"alphas\")\n",
    "        betas = model.addVars(K, lb=-GRB.INFINITY, name=\"betas\")  # for intercept\n",
    "        gammas = model.addVars(\n",
    "            features_num, lb=-GRB.INFINITY, name=\"gammas\"\n",
    "        )  # for features coefficients\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "        Sold_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_0\")\n",
    "        Left_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_0\")\n",
    "        Lost_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_0\")\n",
    "\n",
    "        Sold_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_1\")\n",
    "        Left_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_1\")\n",
    "        Lost_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_1\")\n",
    "\n",
    "        # Holding_Cost_0s = model.addVars(\n",
    "        #     len(demand_df_train), lb=0.0, name=\"Holding_Cost_0\"\n",
    "        # )\n",
    "\n",
    "        # Holding_Cost_1s = model.addVars(\n",
    "        #     len(demand_df_train), lb=0.0, name=\"Holding_Cost_1\"\n",
    "        # )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, name=\"profits_vars\"\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, name=\"Total_Demand_from_k_to_T\"\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        f_vars = model.addVars(len(demand_df_train), lb=-GRB.INFINITY, name=\"f_var\")\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=1, name=\"Fraction_for_second_order_amount\"\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=(Q_star + 1), name=\"Q0_var\"\n",
    "        )\n",
    "\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        r_vars = model.addVars(len(demand_df_train), K, lb=0.0, ub=1.0, name=\"r\")\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(len(Qk_hat_df), lb=0.0, name=\"Q1_var\")\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            lb=0.0,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df), lb=-GRB.INFINITY, name=f\"Q_hat_adjusted\"\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, _ in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            ### 用線性回歸計算F_var\n",
    "            model.addConstr(\n",
    "                f_vars[i]\n",
    "                == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            )\n",
    "            model.addGenConstrLogistic(\n",
    "                xvar=f_vars[i], yvar=F_vars[i], name=f\"logistic_constraint_{i}\"\n",
    "            )\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "            # 用線性回歸計算確定最佳補貨時間\n",
    "            exp_tau_vars = []\n",
    "            for k in range(K):\n",
    "\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, k]\n",
    "                    == gp.quicksum(\n",
    "                        X_data[j] * gammas[j]\n",
    "                        for j in range(features_num)  # features coefficient\n",
    "                    )\n",
    "                    + betas[k],  # intercept\n",
    "                    name=f\"tau_computation_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "                exp_tau_var = model.addVar(lb=0, name=f\"exp_tau_var_{i}_{k}\")\n",
    "                # neg_tau_var = model.addVar(\n",
    "                #     lb=-GRB.INFINITY, ub=0, name=f\"neg_tau_var_{i}_{k}\"\n",
    "                # )\n",
    "\n",
    "                # model.addConstr(\n",
    "                #     neg_tau_var == -tau_vars[i, k], name=f\"neg_tau_constr_{i}_{k}\"\n",
    "                # )\n",
    "                # model.addGenConstrExp(xvar=neg_tau_var, yvar=exp_tau_var)\n",
    "                model.addGenConstrExp(xvar=tau_vars[i, k], yvar=exp_tau_var)\n",
    "\n",
    "                exp_tau_vars.append(exp_tau_var)\n",
    "\n",
    "            ### 找到最大 R 以及 r, R 的相關限制式 -> k: 0~7\n",
    "            for k in range(K):\n",
    "                model.addConstr(\n",
    "                    r_vars[i, k] * gp.quicksum(exp_tau_vars) == exp_tau_vars[k],\n",
    "                    name=f\"softmax_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "            model.addConstr(\n",
    "                gp.quicksum(r_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"sum_r_{i}\",\n",
    "            )\n",
    "\n",
    "            max_r_helpers = model.addVar(lb=0.0, ub=1.0, name=\"max_r_helper\")\n",
    "            model.addGenConstrMax(\n",
    "                max_r_helpers,\n",
    "                [r_vars[i, k] for k in range(K)],\n",
    "                name=f\"MaxRConstraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # 確保 R_vars 的邏輯行為\n",
    "            # for k in range(K):\n",
    "            #     model.addGenConstrIndicator(\n",
    "            #         R_vars[i, k], 1, r_vars[i, k] == max_r_helpers\n",
    "            #     )\n",
    "\n",
    "            epsilon = 1e-3  # 可調整的小正數\n",
    "            for k in range(K):\n",
    "                for k2 in range(K):\n",
    "                    if k != k2:\n",
    "                        model.addGenConstrIndicator(\n",
    "                            R_vars[i, k],\n",
    "                            True,\n",
    "                            r_vars[i, k] >= r_vars[i, k2] + epsilon,\n",
    "                            name=f\"tau_diff_{i}_{k}_{k2}\",\n",
    "                        )\n",
    "\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"Ensure_only_one_R_true_{i}\",\n",
    "            )\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            # ### 0~k-1 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Left_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0s[i],\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1s[i],\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train))),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "        model.write(\"s4_model_debug.lp\")\n",
    "        model.write(\"s4_model.mps\")\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                print(\"===================== 找到最佳解 ==================\")\n",
    "                print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                print(\"Alphas values:\")\n",
    "                for key, alpha in alphas.items():\n",
    "                    print(f\"alpha[{key}]: {alpha.X}\")\n",
    "\n",
    "                # print(\"Beta values:\")\n",
    "                # for key, beta in betas.items():\n",
    "                #     print(f\"beta{key}: {beta.X}\")\n",
    "\n",
    "                alpha_values = np.array([alpha.X for _, alpha in alphas.items()])\n",
    "                beta_values = np.array([betas[k].X for k in range(K)])\n",
    "                print(f\"beta_values:\\n{beta_values}\")\n",
    "\n",
    "                gamma_values = np.array([gammas[j].X for j in range(features_num)])\n",
    "                print(f\"gamma_values:\\n{gamma_values}\")\n",
    "\n",
    "                f_values = np.array([f.X for _, f in f_vars.items()])\n",
    "                tau_values = np.array(\n",
    "                    [\n",
    "                        [tau_vars[i, j].X for j in range(K)]\n",
    "                        for i in range(len(demand_df_train))\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                print(f\"------------\")\n",
    "                print(f\"f_values:\\n{f_values}\")\n",
    "                print(f\"tau_values:\\n{tau_values}\")\n",
    "\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                all_rs = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                # all_holding_costs_0 = []\n",
    "                # all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    print(\"----------------------------------------------\")\n",
    "                    print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    # Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    # Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "                    all_Q0s.append(Q0_vars[i].X)\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    all_Fs.append(F_vars[i].X)\n",
    "                    # all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    # all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    rs = []\n",
    "                    for k in range(K):\n",
    "                        rs.append(r_vars[i, k].X)\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        print(\n",
    "                            f\"第 {k+2} 天補貨策略: R_vars = {R_value}, r_vars = {rs[k]}\"\n",
    "                        )\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "\n",
    "                    all_Rs.append(reorder_day)\n",
    "                    all_rs.append(rs)\n",
    "\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    print(check_results_df)\n",
    "\n",
    "                    # for t in range(2):\n",
    "                    #     if t == 0:\n",
    "                    #         print(\n",
    "                    #             f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                    #         )\n",
    "                    #     else:\n",
    "                    #         print(\n",
    "                    #             f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                    #         )\n",
    "\n",
    "                    # print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                print(\"==========================================\")\n",
    "                print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    alpha_values,\n",
    "                    beta_values,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    f_values,\n",
    "                    tau_values,\n",
    "                    None,\n",
    "                    None,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                    gamma_values,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_flexible_beta_with_softmax_11(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    result = __fully_flexible_beta_with_softmax_11(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "    if result is None:\n",
    "        print(f\"找不到最佳解\")\n",
    "        return None, None\n",
    "    else:\n",
    "        (\n",
    "            all_Rs,\n",
    "            all_losses,\n",
    "            all_lefts,\n",
    "            all_profits,\n",
    "            all_operation_profits,\n",
    "            alpha_values,\n",
    "            beta_values,\n",
    "            all_Fs,\n",
    "            all_Q0s,\n",
    "            all_Q1s,\n",
    "            f_values,\n",
    "            tau_values,\n",
    "            holding_costs_0s,\n",
    "            holding_costs_1s,\n",
    "            all_left0s,\n",
    "            all_left1s,\n",
    "            all_lost0s,\n",
    "            all_lost1s,\n",
    "            gamma_values,\n",
    "        ) = result\n",
    "\n",
    "        print(f\"all_Rs: {all_Rs}\")\n",
    "\n",
    "        return make_s3_related_strtegies_result(\n",
    "            all_Rs=all_Rs,\n",
    "            losses=all_losses,\n",
    "            lefts=all_lefts,\n",
    "            profits=all_profits,\n",
    "            operation_profits=all_operation_profits,\n",
    "            alpha_values=alpha_values,\n",
    "            beta_values=beta_values,\n",
    "            F_vars=all_Fs,\n",
    "            Q0_vars=all_Q0s,\n",
    "            Q1_vars=all_Q1s,\n",
    "            f_values=f_values,\n",
    "            tau_values=tau_values,\n",
    "            holding_costs_0s=holding_costs_0s,\n",
    "            holding_costs_1s=holding_costs_1s,\n",
    "            all_left0s=all_left0s,\n",
    "            all_left1s=all_left1s,\n",
    "            all_lost0s=all_lost0s,\n",
    "            all_lost1s=all_lost1s,\n",
    "            gamma_values=gamma_values,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S12 - Beta without r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __fully_flexible_beta_with_softmax_12(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "        model.setParam(\"IntFeasTol\", 1e-9)\n",
    "        model.setParam(\"NumericFocus\", 3)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        alphas = model.addVars(features_num + 1, lb=-GRB.INFINITY, name=\"alphas\")\n",
    "        betas = model.addVars(K, features_num + 1, lb=-GRB.INFINITY, name=\"betas\")\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "        Sold_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_0\")\n",
    "        Left_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_0\")\n",
    "        Lost_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_0\")\n",
    "\n",
    "        Sold_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_1\")\n",
    "        Left_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_1\")\n",
    "        Lost_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_1\")\n",
    "\n",
    "        Holding_Cost_0s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_0\"\n",
    "        )\n",
    "\n",
    "        Holding_Cost_1s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_1\"\n",
    "        )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, name=\"profits_vars\"\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, name=\"Total_Demand_from_k_to_T\"\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        f_vars = model.addVars(len(demand_df_train), lb=-GRB.INFINITY, name=\"f_var\")\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=1, name=\"Fraction_for_second_order_amount\"\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=(Q_star + 1), name=\"Q0_var\"\n",
    "        )\n",
    "\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        # tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        r_vars = model.addVars(len(demand_df_train), K, lb=0.0, ub=1.0, name=\"r\")\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(len(Qk_hat_df), lb=0.0, name=\"Q1_var\")\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            lb=0.0,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df), lb=-GRB.INFINITY, name=f\"Q_hat_adjusted\"\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, _ in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            ### 用線性回歸計算F_var\n",
    "            model.addConstr(\n",
    "                f_vars[i]\n",
    "                == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            )\n",
    "            model.addGenConstrLogistic(\n",
    "                xvar=f_vars[i],\n",
    "                yvar=F_vars[i],\n",
    "                options=\"FuncNonlinear=1\",\n",
    "                name=f\"logistic_constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model(Alternative Model) ===================\n",
    "\n",
    "            # Step 1: 利用線性回歸計算 tau\n",
    "            for k in range(K):\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, k]\n",
    "                    == gp.quicksum(\n",
    "                        X_data[j] * betas[k, j] for j in range(features_num + 1)\n",
    "                    ),\n",
    "                    name=f\"tau_computation_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "            delta = 1e-3\n",
    "            tau_star = model.addVar(lb=-GRB.INFINITY, name=f\"tau_star_{i}\")\n",
    "\n",
    "            for k in range(K):\n",
    "                # 如果候選 k 被選中 (R_vars[i,k] == 1)，則強制 tau_vars[i,k] 等於 tau_star\n",
    "                model.addGenConstrIndicator(\n",
    "                    R_vars[i, k],\n",
    "                    True,\n",
    "                    tau_vars[i, k] == tau_star,\n",
    "                    name=f\"tau_star_eq_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "                # 如果候選 k 未被選中 (R_vars[i,k] == 0)，則必須有 tau_vars[i,k] <= tau_star - delta\n",
    "                # 利用 Big-M 技巧：當 R_vars[i,k]==0 時，約束變為 tau_vars[i,k] <= tau_star - delta\n",
    "                # 當 R_vars[i,k]==1 時，由於前面的 indicator 約束已強制 tau_vars[i,k] == tau_star，\n",
    "                # 此約束則不會影響模型（因為 tau_star <= tau_star - delta + M 已經成立）\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, k] <= tau_star - delta + M * R_vars[i, k],\n",
    "                    name=f\"tau_gap_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "            # Step 3: 保證只有一個候選被選中 (即 R_vars 為 1 的只有一個)\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"one_R_{i}\",\n",
    "            )\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            # ### 0~k-1 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Left_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0s[i],\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1s[i],\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # model.addConstr(\n",
    "            #     profits_vars[i]\n",
    "            #     == (\n",
    "            #         (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "            #         - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "            #         - (cost - salvage_value) * (Left_0s[i] + Left_1s[i])  # left cost\n",
    "            #     ),\n",
    "            #     name=f\"Profit_Constraint_{i}\",\n",
    "            # )\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * (Left_1s[i])  # left cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train))),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "        model.write(\"s4_model_debug.lp\")\n",
    "        model.write(\"s4_model.mps\")\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                # print(\"===================== 找到最佳解 ==================\")\n",
    "                # print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                # print(\"Alphas values:\")\n",
    "                # for key, alpha in alphas.items():\n",
    "                #     print(f\"alpha[{key}]: {alpha.X}\")\n",
    "\n",
    "                alpha_values = np.array([alpha.X for _, alpha in alphas.items()])\n",
    "                beta_values = np.array(\n",
    "                    [[betas[k, j].X for j in range(features_num + 1)] for k in range(K)]\n",
    "                )\n",
    "                # print(f\"beta_values:\\n{beta_values}\")\n",
    "\n",
    "                f_values = np.array([f.X for _, f in f_vars.items()])\n",
    "                tau_values = np.array(\n",
    "                    [\n",
    "                        [tau_vars[i, j].X for j in range(K)]\n",
    "                        for i in range(len(demand_df_train))\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                # print(f\"------------\")\n",
    "                # print(f\"f_values:\\n{f_values}\")\n",
    "                # print(f\"tau_values:\\n{tau_values}\")\n",
    "\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                all_rs = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                all_holding_costs_0 = []\n",
    "                all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    # print(\"----------------------------------------------\")\n",
    "                    # print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    # all_Fs.append(F_vars[i].X)\n",
    "                    all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    # Check f\n",
    "                    x_data = training_df.iloc[i].tolist()\n",
    "                    x_data.append(1)\n",
    "                    f_train, F_train, Q0_train = compute_f_F_Q(\n",
    "                        x_data, alpha_values, Q_star\n",
    "                    )\n",
    "                    if (\n",
    "                        truncate_to_2(f_train) == truncate_to_2(f_vars[i].X)\n",
    "                        and truncate_to_2(F_train) == truncate_to_2(F_vars[i].X)\n",
    "                        and truncate_to_2(Q0_train) == truncate_to_2(Q0_vars[i].X)\n",
    "                    ):\n",
    "                        print(\"f_train, F_train, Q0_train 都相等\")\n",
    "                        all_Q0s.append(Q0_vars[i].X)\n",
    "                        all_Fs.append(F_vars[i].X)\n",
    "                    else:\n",
    "                        print(f\"f_train, F_train, Q0_train 不相等\")\n",
    "                        all_Q0s.append(-1)\n",
    "                        all_Fs.append(-1)\n",
    "                        # results[\"Q0s\"].append(Q0_vars[i].X)\n",
    "                        # results[\"Fs\"].append(F_vars[i].X)\n",
    "                        # results[\"fs\"].append(f_vars[i].X)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    rs = []\n",
    "                    for k in range(K):\n",
    "                        rs.append(r_vars[i, k].X)\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        print(\n",
    "                            f\"第 {k+2} 天補貨策略: R_vars = {R_value}, tau_vars = {tau_vars[i, k].X}\"\n",
    "                        )\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "\n",
    "                    all_Rs.append(reorder_day)\n",
    "                    all_rs.append(rs)\n",
    "\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    # print(check_results_df)\n",
    "\n",
    "                    # for t in range(2):\n",
    "                    #     if t == 0:\n",
    "                    #         print(\n",
    "                    #             f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                    #         )\n",
    "                    #     else:\n",
    "                    #         print(\n",
    "                    #             f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                    #         )\n",
    "\n",
    "                    # print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                # print(\"==========================================\")\n",
    "                # print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    alpha_values,\n",
    "                    beta_values,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    f_values,\n",
    "                    tau_values,\n",
    "                    all_holding_costs_0,\n",
    "                    all_holding_costs_1,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_flexible_beta_with_softmax_12(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    result = __fully_flexible_beta_with_softmax_12(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "    if result is None:\n",
    "        print(f\"找不到最佳解\")\n",
    "        return None, None\n",
    "    else:\n",
    "        (\n",
    "            all_Rs,\n",
    "            all_losses,\n",
    "            all_lefts,\n",
    "            all_profits,\n",
    "            all_operation_profits,\n",
    "            alpha_values,\n",
    "            beta_values,\n",
    "            all_Fs,\n",
    "            all_Q0s,\n",
    "            all_Q1s,\n",
    "            f_values,\n",
    "            tau_values,\n",
    "            holding_costs_0s,\n",
    "            holding_costs_1s,\n",
    "            all_left0s,\n",
    "            all_left1s,\n",
    "            all_lost0s,\n",
    "            all_lost1s,\n",
    "        ) = result\n",
    "\n",
    "        print(f\"all_Rs: {all_Rs}\")\n",
    "\n",
    "        return make_s3_related_strtegies_result(\n",
    "            all_Rs=all_Rs,\n",
    "            losses=all_losses,\n",
    "            lefts=all_lefts,\n",
    "            profits=all_profits,\n",
    "            operation_profits=all_operation_profits,\n",
    "            alpha_values=alpha_values,\n",
    "            beta_values=beta_values,\n",
    "            F_vars=all_Fs,\n",
    "            Q0_vars=all_Q0s,\n",
    "            Q1_vars=all_Q1s,\n",
    "            f_values=f_values,\n",
    "            tau_values=tau_values,\n",
    "            holding_costs_0s=holding_costs_0s,\n",
    "            holding_costs_1s=holding_costs_1s,\n",
    "            all_left0s=all_left0s,\n",
    "            all_left1s=all_left1s,\n",
    "            all_lost0s=all_lost0s,\n",
    "            all_lost1s=all_lost1s,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S14 - Optimized F & Rk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __cal_optimized_F_R(\n",
    "    salvage_value, cost, price, Q_star, demand_df_train, Qk_hat_df, training_df\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "        model.setParam(\"IntFeasTol\", 1e-9)\n",
    "        model.setParam(\"NumericFocus\", 3)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "        Sold_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_0\")\n",
    "        Left_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_0\")\n",
    "        Lost_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_0\")\n",
    "\n",
    "        Sold_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_1\")\n",
    "        Left_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_1\")\n",
    "        Lost_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_1\")\n",
    "\n",
    "        Holding_Cost_0s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_0\"\n",
    "        )\n",
    "\n",
    "        Holding_Cost_1s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_1\"\n",
    "        )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, name=\"profits_vars\"\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, name=\"Total_Demand_from_k_to_T\"\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=1, name=\"Fraction_for_second_order_amount\"\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=(Q_star + 1), name=\"Q0_var\"\n",
    "        )\n",
    "\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(len(Qk_hat_df), lb=0.0, name=\"Q1_var\")\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            lb=0.0,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df), lb=-GRB.INFINITY, name=f\"Q_hat_adjusted\"\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, _ in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            model.addConstr(F_vars[i] >= 0, name=f\"Fraction_lower_bound_{i}\")\n",
    "            model.addConstr(F_vars[i] <= 1, name=f\"Fraction_upper_bound_{i}\")\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"Ensure_only_one_R_true_{i}\",\n",
    "            )\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            # ### 0~k-1 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Left_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0s[i],\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1s[i],\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # model.addConstr(\n",
    "            #     profits_vars[i]\n",
    "            #     == (\n",
    "            #         (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "            #         - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "            #         - (cost - salvage_value) * (Left_0s[i] + Left_1s[i])  # left cost\n",
    "            #     ),\n",
    "            #     name=f\"Profit_Constraint_{i}\",\n",
    "            # )\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train))),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "        model.write(\"s4_model_debug.lp\")\n",
    "        model.write(\"s4_model.mps\")\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                # print(\"===================== 找到最佳解 ==================\")\n",
    "                # print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                # all_rs = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                all_holding_costs_0 = []\n",
    "                all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    # print(\"----------------------------------------------\")\n",
    "                    # print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "                    all_Q0s.append(Q0_vars[i].X)\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    all_Fs.append(F_vars[i].X)\n",
    "                    all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    rs = []\n",
    "                    for k in range(K):\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        print(f\"第 {k+2} 天補貨策略: R_vars = {R_value}\")\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    # print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "\n",
    "                    all_Rs.append(reorder_day)\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    # print(check_results_df)\n",
    "\n",
    "                #     for t in range(2):\n",
    "                #         if t == 0:\n",
    "                #             print(\n",
    "                #                 f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                #             )\n",
    "                #         else:\n",
    "                #             print(\n",
    "                #                 f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                #             )\n",
    "\n",
    "                #     print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                # print(\"==========================================\")\n",
    "                # print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    all_holding_costs_0,\n",
    "                    all_holding_costs_1,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_optimized_F_R(\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df,\n",
    "    Qk_hat_df,\n",
    "    training_df,\n",
    "):\n",
    "    results_dict = {\n",
    "        \"R(T)\": [],\n",
    "        \"average_profits\": [],\n",
    "        \"average_losses\": [],\n",
    "        \"average_lefts\": [],\n",
    "        \"average_operation_profits\": [],\n",
    "        \"alpha_values\": [],\n",
    "        \"F_vars\": [],\n",
    "        \"Q0_vars\": [],\n",
    "        \"Q1_vars\": [],\n",
    "    }\n",
    "\n",
    "    max_profit = None\n",
    "    max_profit_stimulation_result = {}\n",
    "\n",
    "    (\n",
    "        all_Rs,\n",
    "        losses,\n",
    "        lefts,\n",
    "        profits,\n",
    "        operation_profits,\n",
    "        F_vars,\n",
    "        Q0_vars,\n",
    "        Q1_vars,\n",
    "        all_holding_costs_0,\n",
    "        all_holding_costs_1,\n",
    "        all_left0s,\n",
    "        all_left1s,\n",
    "        all_lost0s,\n",
    "        all_lost1s,\n",
    "    ) = __cal_optimized_F_R(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df,\n",
    "        Qk_hat_df=Qk_hat_df,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "\n",
    "    # 計算平均值\n",
    "    average_losses = sum(losses) / len(losses) if losses else 0\n",
    "    average_lefts = sum(lefts) / len(lefts) if lefts else 0\n",
    "    average_profits = sum(profits) / len(profits) if profits else 0\n",
    "    average_operation_profits = (\n",
    "        sum(operation_profits) / len(operation_profits) if operation_profits else 0\n",
    "    )\n",
    "\n",
    "    # 將結果存儲到字典中\n",
    "    results_dict[\"R(T)\"].append(all_Rs)\n",
    "    results_dict[\"average_losses\"].append(average_losses)\n",
    "    results_dict[\"average_lefts\"].append(average_lefts)\n",
    "    results_dict[\"average_profits\"].append(average_profits)\n",
    "    results_dict[\"average_operation_profits\"].append(average_operation_profits)\n",
    "    results_dict[\"alpha_values\"].append(None)\n",
    "    results_dict[\"F_vars\"].append(F_vars)\n",
    "    results_dict[\"Q0_vars\"].append(Q0_vars)\n",
    "    results_dict[\"Q1_vars\"].append(Q1_vars)\n",
    "\n",
    "    # print(f\"The average profits is {average_profits}\")\n",
    "\n",
    "    if max_profit is None or max_profit < average_profits:\n",
    "        # print(f\"max_profit is changed from {max_profit} to {average_profits}\")\n",
    "        max_profit = average_profits\n",
    "        max_profit_stimulation_result = {\n",
    "            \"R\": all_Rs,\n",
    "            \"F\": F_vars,\n",
    "            \"profits\": profits,\n",
    "            \"losses\": losses,\n",
    "            \"lefts\": lefts,\n",
    "            \"operation_profits\": operation_profits,\n",
    "            \"Q0\": Q0_vars,\n",
    "            \"Q1\": Q1_vars,\n",
    "        }\n",
    "\n",
    "    return pd.DataFrame(results_dict).sort_values(\n",
    "        by=\"average_profits\", ascending=False\n",
    "    ), pd.DataFrame(max_profit_stimulation_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S15 - Beta with Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __fully_flexible_beta_with_lasso_15(\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_train,\n",
    "    Qk_hat_df,\n",
    "    training_df,\n",
    "    lambda_beta,\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "        model.setParam(\"IntFeasTol\", 1e-9)\n",
    "        model.setParam(\"NumericFocus\", 3)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        alphas = model.addVars(features_num + 1, lb=-GRB.INFINITY, name=\"alphas\")\n",
    "        betas = model.addVars(K, features_num + 1, lb=-GRB.INFINITY, name=\"betas\")\n",
    "        abs_betas = model.addVars(betas.keys(), lb=0, name=\"abs_beta\")\n",
    "\n",
    "        # 進行 lasso 處理\n",
    "        for k, j in betas.keys():\n",
    "            model.addConstr(abs_betas[k, j] >= betas[k, j])\n",
    "            model.addConstr(abs_betas[k, j] >= -betas[k, j])\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "        Sold_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_0\")\n",
    "        Left_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_0\")\n",
    "        Lost_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_0\")\n",
    "\n",
    "        Sold_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_1\")\n",
    "        Left_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_1\")\n",
    "        Lost_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_1\")\n",
    "\n",
    "        Holding_Cost_0s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_0\"\n",
    "        )\n",
    "\n",
    "        Holding_Cost_1s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_1\"\n",
    "        )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, name=\"profits_vars\"\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, name=\"Total_Demand_from_k_to_T\"\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        f_vars = model.addVars(len(demand_df_train), lb=-GRB.INFINITY, name=\"f_var\")\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=1, name=\"Fraction_for_second_order_amount\"\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=(Q_star + 1), name=\"Q0_var\"\n",
    "        )\n",
    "\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        # tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        r_vars = model.addVars(len(demand_df_train), K, lb=0.0, ub=1.0, name=\"r\")\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(len(Qk_hat_df), lb=0.0, name=\"Q1_var\")\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            lb=0.0,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df), lb=-GRB.INFINITY, name=f\"Q_hat_adjusted\"\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, _ in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            ### 用線性回歸計算F_var\n",
    "            model.addConstr(\n",
    "                f_vars[i]\n",
    "                == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            )\n",
    "            model.addGenConstrLogistic(\n",
    "                xvar=f_vars[i],\n",
    "                yvar=F_vars[i],\n",
    "                options=\"FuncNonlinear=1\",\n",
    "                name=f\"logistic_constraint_{i}\",\n",
    "            )\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model(Alternative Model) ===================\n",
    "\n",
    "            # Step 1: 利用線性回歸計算 tau\n",
    "            for k in range(K):\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, k]\n",
    "                    == gp.quicksum(\n",
    "                        X_data[j] * betas[k, j] for j in range(features_num + 1)\n",
    "                    ),\n",
    "                    name=f\"tau_computation_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "            delta = 1e-3\n",
    "            tau_star = model.addVar(lb=-GRB.INFINITY, name=f\"tau_star_{i}\")\n",
    "\n",
    "            for k in range(K):\n",
    "                # 如果候選 k 被選中 (R_vars[i,k] == 1)，則強制 tau_vars[i,k] 等於 tau_star\n",
    "                model.addGenConstrIndicator(\n",
    "                    R_vars[i, k],\n",
    "                    True,\n",
    "                    tau_vars[i, k] == tau_star,\n",
    "                    name=f\"tau_star_eq_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, k] <= tau_star - delta + M * R_vars[i, k],\n",
    "                    name=f\"tau_gap_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "            # Step 3: 保證只有一個候選被選中 (即 R_vars 為 1 的只有一個)\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"one_R_{i}\",\n",
    "            )\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            # ### 0~k-1 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Left_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0s[i],\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1s[i],\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train)))\n",
    "            - lambda_beta * gp.quicksum(abs_betas[k, j] for k, j in abs_betas.keys()),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "        model.write(\"s4_model_debug.lp\")\n",
    "        model.write(\"s4_model.mps\")\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                # print(\"===================== 找到最佳解 ==================\")\n",
    "                # print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                # print(\"Alphas values:\")\n",
    "                # for key, alpha in alphas.items():\n",
    "                #     print(f\"alpha[{key}]: {alpha.X}\")\n",
    "\n",
    "                alpha_values = np.array([alpha.X for _, alpha in alphas.items()])\n",
    "                beta_values = np.array(\n",
    "                    [[betas[k, j].X for j in range(features_num + 1)] for k in range(K)]\n",
    "                )\n",
    "                # print(f\"beta_values:\\n{beta_values}\")\n",
    "\n",
    "                f_values = np.array([f.X for _, f in f_vars.items()])\n",
    "                tau_values = np.array(\n",
    "                    [\n",
    "                        [tau_vars[i, j].X for j in range(K)]\n",
    "                        for i in range(len(demand_df_train))\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                # print(f\"------------\")\n",
    "                # print(f\"f_values:\\n{f_values}\")\n",
    "                # print(f\"tau_values:\\n{tau_values}\")\n",
    "\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                all_rs = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                all_holding_costs_0 = []\n",
    "                all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    # print(\"----------------------------------------------\")\n",
    "                    # print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "                    all_Q0s.append(Q0_vars[i].X)\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    all_Fs.append(F_vars[i].X)\n",
    "                    all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    rs = []\n",
    "                    for k in range(K):\n",
    "                        rs.append(r_vars[i, k].X)\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        # print(\n",
    "                        #     f\"第 {k+2} 天補貨策略: R_vars = {R_value}, tau_vars = {tau_vars[i, k].X}\"\n",
    "                        # )\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    # print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "\n",
    "                    all_Rs.append(reorder_day)\n",
    "                    all_rs.append(rs)\n",
    "\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    # print(check_results_df)\n",
    "\n",
    "                #     for t in range(2):\n",
    "                #         if t == 0:\n",
    "                #             print(\n",
    "                #                 f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                #             )\n",
    "                #         else:\n",
    "                #             print(\n",
    "                #                 f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                #             )\n",
    "\n",
    "                #     print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                # print(\"==========================================\")\n",
    "                # print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    alpha_values,\n",
    "                    beta_values,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    f_values,\n",
    "                    tau_values,\n",
    "                    all_holding_costs_0,\n",
    "                    all_holding_costs_1,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_flexible_beta_with_lasso_15(\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_train,\n",
    "    Qk_hat_df,\n",
    "    training_df,\n",
    "    lambda_beta,\n",
    "):\n",
    "\n",
    "    result = __fully_flexible_beta_with_lasso_15(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df,\n",
    "        training_df=training_df,\n",
    "        lambda_beta=lambda_beta,\n",
    "    )\n",
    "    if result is None:\n",
    "        print(f\"找不到最佳解\")\n",
    "        return None, None\n",
    "    else:\n",
    "        (\n",
    "            all_Rs,\n",
    "            all_losses,\n",
    "            all_lefts,\n",
    "            all_profits,\n",
    "            all_operation_profits,\n",
    "            alpha_values,\n",
    "            beta_values,\n",
    "            all_Fs,\n",
    "            all_Q0s,\n",
    "            all_Q1s,\n",
    "            f_values,\n",
    "            tau_values,\n",
    "            holding_costs_0s,\n",
    "            holding_costs_1s,\n",
    "            all_left0s,\n",
    "            all_left1s,\n",
    "            all_lost0s,\n",
    "            all_lost1s,\n",
    "        ) = result\n",
    "\n",
    "        # print(f\"all_Rs: {all_Rs}\")\n",
    "\n",
    "        return make_s3_related_strtegies_result(\n",
    "            all_Rs=all_Rs,\n",
    "            losses=all_losses,\n",
    "            lefts=all_lefts,\n",
    "            profits=all_profits,\n",
    "            operation_profits=all_operation_profits,\n",
    "            alpha_values=alpha_values,\n",
    "            beta_values=beta_values,\n",
    "            F_vars=all_Fs,\n",
    "            Q0_vars=all_Q0s,\n",
    "            Q1_vars=all_Q1s,\n",
    "            f_values=f_values,\n",
    "            tau_values=tau_values,\n",
    "            holding_costs_0s=holding_costs_0s,\n",
    "            holding_costs_1s=holding_costs_1s,\n",
    "            all_left0s=all_left0s,\n",
    "            all_left1s=all_left1s,\n",
    "            all_lost0s=all_lost0s,\n",
    "            all_lost1s=all_lost1s,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S16 - Beta with second Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __fully_flexible_beta_with_second_training_16(\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_train,\n",
    "    Qk_hat_df,\n",
    "    training_df,\n",
    "    lambda_beta,\n",
    "    last_beta_total,\n",
    "):\n",
    "\n",
    "    with gp.Model(\"profit_maximization\", env=env) as model:\n",
    "\n",
    "        model.setParam(\"OutputFlag\", True)\n",
    "        model.setParam(\"Threads\", THREADS)\n",
    "        model.setParam(\"MIPGap\", MIPGAP)\n",
    "        model.setParam(\"TimeLimit\", TIME_LIMIT)\n",
    "        model.setParam(\"IntFeasTol\", 1e-9)\n",
    "        model.setParam(\"NumericFocus\", 3)\n",
    "\n",
    "        # ======================= Global Variables =======================\n",
    "\n",
    "        # Category 1 - Some variables that is important to future work\n",
    "        K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "\n",
    "        alphas = model.addVars(features_num + 1, lb=-GRB.INFINITY, name=\"alphas\")\n",
    "        betas = model.addVars(K, features_num + 1, lb=-GRB.INFINITY, name=\"betas\")\n",
    "        abs_betas = model.addVars(betas.keys(), lb=0, name=\"abs_beta\")\n",
    "\n",
    "        # 進行絕對值處理\n",
    "        for k, j in betas.keys():\n",
    "            model.addConstr(abs_betas[k, j] >= betas[k, j])\n",
    "            model.addConstr(abs_betas[k, j] >= -betas[k, j])\n",
    "\n",
    "        # 設定 beta 的上限\n",
    "        model.addConstr(\n",
    "            gp.quicksum(abs_betas[k, j] for k, j in abs_betas.keys())\n",
    "            <= lambda_beta * last_beta_total,\n",
    "            name=\"beta_limit\",\n",
    "        )\n",
    "\n",
    "        # Category 2 - Variables about this stimulation\n",
    "        ### 1. Variables for Model 1: Maximum Profit Model\n",
    "        Sold_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_0\")\n",
    "        Left_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_0\")\n",
    "        Lost_0s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_0\")\n",
    "\n",
    "        Sold_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Sold_1\")\n",
    "        Left_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Left_1\")\n",
    "        Lost_1s = model.addVars(len(demand_df_train), lb=0.0, name=\"Lost_1\")\n",
    "\n",
    "        Holding_Cost_0s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_0\"\n",
    "        )\n",
    "\n",
    "        Holding_Cost_1s = model.addVars(\n",
    "            len(demand_df_train), lb=0.0, name=\"Holding_Cost_1\"\n",
    "        )\n",
    "\n",
    "        profits_vars = model.addVars(\n",
    "            len(demand_df_train), lb=-GRB.INFINITY, name=\"profits_vars\"\n",
    "        )\n",
    "\n",
    "        #### 1-2. 用於計算 k 時期之前與之後的需求量\n",
    "        total_demand_up_to_k_minus_1_vars = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=\"Total_Demand_Up_to_K_minus_1\",\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, name=\"Total_Demand_from_k_to_T\"\n",
    "        )\n",
    "        Q1_plus_lefts = model.addVars(\n",
    "            len(demand_df_train),\n",
    "            lb=0,\n",
    "            name=f\"Q1_plus_left\",\n",
    "        )  # k 之前的剩餘 + 新進貨的 Q1 量\n",
    "\n",
    "        ### 2. Variables for Model 2: Optimal Fraction Model\n",
    "        f_vars = model.addVars(len(demand_df_train), lb=-GRB.INFINITY, name=\"f_var\")\n",
    "        F_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=1, name=\"Fraction_for_second_order_amount\"\n",
    "        )\n",
    "        Q0_vars = model.addVars(\n",
    "            len(demand_df_train), lb=0, ub=(Q_star + 1), name=\"Q0_var\"\n",
    "        )\n",
    "\n",
    "        ### 3. Variables for Model 3: Optimal Order Time Model\n",
    "        # tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        tau_vars = model.addVars(len(demand_df_train), K, lb=-GRB.INFINITY, name=\"tau\")\n",
    "        r_vars = model.addVars(len(demand_df_train), K, lb=0.0, ub=1.0, name=\"r\")\n",
    "        R_vars = model.addVars(len(demand_df_train), K, vtype=GRB.BINARY, name=\"R\")\n",
    "\n",
    "        ### 4. Variables for Model 4: re-estimate order-up-to-level\n",
    "        Q1_vars = model.addVars(len(Qk_hat_df), lb=0.0, name=\"Q1_var\")\n",
    "        Q_hats = model.addVars(\n",
    "            len(Qk_hat_df),\n",
    "            lb=0.0,\n",
    "            name=\"Q_hat\",\n",
    "        )\n",
    "        Q_hat_adjusteds = model.addVars(\n",
    "            len(Qk_hat_df), lb=-GRB.INFINITY, name=f\"Q_hat_adjusted\"\n",
    "        )\n",
    "\n",
    "        # ======================= Start Stimulation! =======================\n",
    "\n",
    "        for i, _ in demand_df_train.iterrows():\n",
    "\n",
    "            ### Data for this stimulation\n",
    "            demand_row = demand_df_train.iloc[i]\n",
    "            Qk_hat_df_row = Qk_hat_df.iloc[i]\n",
    "            X_data = training_df.iloc[i].tolist()\n",
    "            X_data.append(1)\n",
    "\n",
    "            # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "            ### 用線性回歸計算F_var\n",
    "            model.addConstr(\n",
    "                f_vars[i]\n",
    "                == gp.quicksum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "            )\n",
    "            model.addGenConstrLogistic(\n",
    "                xvar=f_vars[i],\n",
    "                yvar=F_vars[i],\n",
    "                options=\"FuncNonlinear=1\",\n",
    "                name=f\"logistic_constraint_{i}\",\n",
    "            )\n",
    "            model.addConstr(Q0_vars[i] == F_vars[i] * Q_star, f\"Q0_upper_bound_{i}\")\n",
    "\n",
    "            # =================== Model 2: Optimal Order Time Model(Alternative Model) ===================\n",
    "\n",
    "            # Step 1: 利用線性回歸計算 tau\n",
    "            for k in range(K):\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, k]\n",
    "                    == gp.quicksum(\n",
    "                        X_data[j] * betas[k, j] for j in range(features_num + 1)\n",
    "                    ),\n",
    "                    name=f\"tau_computation_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "            delta = 1e-3\n",
    "            tau_star = model.addVar(lb=-GRB.INFINITY, name=f\"tau_star_{i}\")\n",
    "\n",
    "            for k in range(K):\n",
    "                # 如果候選 k 被選中 (R_vars[i,k] == 1)，則強制 tau_vars[i,k] 等於 tau_star\n",
    "                model.addGenConstrIndicator(\n",
    "                    R_vars[i, k],\n",
    "                    True,\n",
    "                    tau_vars[i, k] == tau_star,\n",
    "                    name=f\"tau_star_eq_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "                model.addConstr(\n",
    "                    tau_vars[i, k] <= tau_star - delta + M * R_vars[i, k],\n",
    "                    name=f\"tau_gap_{i}_{k}\",\n",
    "                )\n",
    "\n",
    "            # Step 3: 保證只有一個候選被選中 (即 R_vars 為 1 的只有一個)\n",
    "            model.addConstr(\n",
    "                gp.quicksum(R_vars[i, k] for k in range(K)) == 1,\n",
    "                name=f\"one_R_{i}\",\n",
    "            )\n",
    "\n",
    "            # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "            ### 計算 Q_hat -> k: 2~9 -> k-2: 0~7\n",
    "            model.addConstr(\n",
    "                Q_hats[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Define_Q_hat_{i}\",\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q_hat_adjusteds[i] == Q_hats[i] - Q0_vars[i], name=f\"Adjust_Q_hat_{i}\"\n",
    "            )\n",
    "            model.addConstr(\n",
    "                Q1_vars[i] == max_(Q_hat_adjusteds[i], 0),\n",
    "                name=f\"Max_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "            # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "            # ### 0~k-1 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_up_to_k_minus_1_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_Up_to_K_Minus_1_{i}\",\n",
    "            )\n",
    "\n",
    "            # ### k~T 的需求量\n",
    "            model.addConstr(\n",
    "                total_demand_from_k_to_T_vars[i]\n",
    "                == gp.quicksum(\n",
    "                    R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "                ),\n",
    "                name=f\"Constr_Total_Demand_from_K_to_T_{i}\",\n",
    "            )\n",
    "\n",
    "            # 定義輔助變數\n",
    "            Left_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_0_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "            Left_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Left_0_aux_{i}\")\n",
    "            Lost_1_aux = model.addVar(lb=-GRB.INFINITY, name=f\"Lost_0_aux_{i}\")\n",
    "\n",
    "            # 計算 Sold_0，為 total_demand_up_to_k_minus_1_vars 和 Q0_vars 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_0s[i],\n",
    "                [total_demand_up_to_k_minus_1_vars[i], Q0_vars[i]],\n",
    "                name=f\"Constr_Sold_0_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_0，為 max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_0_aux == Q0_vars[i] - Sold_0s[i],\n",
    "                name=f\"Constr_Left_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_0s[i], [Left_0_aux, 0], name=f\"Constr_Left_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_0，為 max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_0_aux == total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i],\n",
    "                name=f\"Constr_Lost_0_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_0s[i], [Lost_0_aux, 0], name=f\"Constr_Lost_0_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Q1 + left_0\n",
    "            model.addConstr(\n",
    "                Q1_plus_lefts[i] == Q1_vars[i] + Left_0s[i],\n",
    "                name=f\"Constr_Q1_plus_left_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Sold_1，為 total_demand_from_k_to_T_vars 和 Q1_plus_lefts 的最小值\n",
    "            model.addGenConstrMin(\n",
    "                Sold_1s[i],\n",
    "                [total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i]],\n",
    "                name=f\"Constr_Sold_1_min_{i}\",\n",
    "            )\n",
    "\n",
    "            # 計算 Left_1，為 max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "            model.addConstr(\n",
    "                Left_1_aux == Q1_plus_lefts[i] - Sold_1s[i],\n",
    "                name=f\"Constr_Left_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Left_1s[i], [Left_1_aux, 0], name=f\"Constr_Left_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            # 計算 Lost_1，為 max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "            model.addConstr(\n",
    "                Lost_1_aux == total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i],\n",
    "                name=f\"Constr_Lost_1_diff_aux_{i}\",\n",
    "            )\n",
    "            model.addGenConstrMax(\n",
    "                Lost_1s[i], [Lost_1_aux, 0], name=f\"Constr_Lost_1_max_{i}\"\n",
    "            )\n",
    "\n",
    "            model.addConstr(\n",
    "                profits_vars[i]\n",
    "                == (\n",
    "                    (price - cost) * (Sold_0s[i] + Sold_1s[i])  # sold\n",
    "                    - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # lost sales\n",
    "                    - (cost - salvage_value) * Left_1s[i]  # left cost\n",
    "                ),\n",
    "                name=f\"Profit_Constraint_{i}\",\n",
    "            )\n",
    "\n",
    "        #  ======================================= Model optimize =======================================\n",
    "\n",
    "        model.setObjective(\n",
    "            gp.quicksum(profits_vars[i] for i in range(len(demand_df_train)))\n",
    "            - lambda_beta * gp.quicksum(abs_betas[k, j] for k, j in abs_betas.keys()),\n",
    "            GRB.MAXIMIZE,\n",
    "        )\n",
    "        model.write(\"s4_model_debug.lp\")\n",
    "        model.write(\"s4_model.mps\")\n",
    "        try:\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                print(f\"\\nmodel.status is optimal: {model.status == GRB.OPTIMAL}\")\n",
    "                print(f\"model.status is TIME_LIMIT: {model.status == GRB.TIME_LIMIT}\\n\")\n",
    "\n",
    "                # print(\"===================== 找到最佳解 ==================\")\n",
    "                # print(f\"Q0_optimal（最佳總庫存量）: {Q_star}\")\n",
    "\n",
    "                # print(\"Alphas values:\")\n",
    "                # for key, alpha in alphas.items():\n",
    "                #     print(f\"alpha[{key}]: {alpha.X}\")\n",
    "\n",
    "                alpha_values = np.array([alpha.X for _, alpha in alphas.items()])\n",
    "                beta_values = np.array(\n",
    "                    [[betas[k, j].X for j in range(features_num + 1)] for k in range(K)]\n",
    "                )\n",
    "                # print(f\"beta_values:\\n{beta_values}\")\n",
    "\n",
    "                f_values = np.array([f.X for _, f in f_vars.items()])\n",
    "                tau_values = np.array(\n",
    "                    [\n",
    "                        [tau_vars[i, j].X for j in range(K)]\n",
    "                        for i in range(len(demand_df_train))\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                # print(f\"------------\")\n",
    "                # print(f\"f_values:\\n{f_values}\")\n",
    "                # print(f\"tau_values:\\n{tau_values}\")\n",
    "\n",
    "                all_losses = []\n",
    "                all_lefts = []\n",
    "                all_operation_profits = []\n",
    "                all_profits = []\n",
    "                all_rs = []\n",
    "                all_Rs = []\n",
    "                all_Q0s = []\n",
    "                all_Q1s = []\n",
    "                all_Fs = []\n",
    "                all_holding_costs_0 = []\n",
    "                all_holding_costs_1 = []\n",
    "                all_left0s = []\n",
    "                all_left1s = []\n",
    "                all_lost0s = []\n",
    "                all_lost1s = []\n",
    "\n",
    "                for i in range(len(demand_df_train)):\n",
    "\n",
    "                    # print(\"----------------------------------------------\")\n",
    "                    # print(f\"第 {i+1} 筆觀察資料:\")\n",
    "\n",
    "                    sold0 = Sold_0s[i].X\n",
    "                    sold1 = Sold_1s[i].X\n",
    "                    left0 = Left_0s[i].X\n",
    "                    left1 = Left_1s[i].X\n",
    "                    lost0 = Lost_0s[i].X\n",
    "                    lost1 = Lost_1s[i].X\n",
    "                    Holding_Cost_0 = Holding_Cost_0s[i].X\n",
    "                    Holding_Cost_1 = Holding_Cost_1s[i].X\n",
    "\n",
    "                    operation_profit = (price - cost) * (sold0 + sold1)\n",
    "                    daily_profit = profits_vars[i].X\n",
    "\n",
    "                    all_losses.append(lost0 + lost1)\n",
    "                    all_lefts.append(left0 + left1)\n",
    "                    all_operation_profits.append(operation_profit)\n",
    "                    all_profits.append(daily_profit)\n",
    "                    all_Q0s.append(Q0_vars[i].X)\n",
    "                    all_Q1s.append(Q1_vars[i].X)\n",
    "                    all_Fs.append(F_vars[i].X)\n",
    "                    all_holding_costs_0.append(Holding_Cost_0)\n",
    "                    all_holding_costs_1.append(Holding_Cost_1)\n",
    "                    all_left0s.append(left0)\n",
    "                    all_left1s.append(left1)\n",
    "                    all_lost0s.append(lost0)\n",
    "                    all_lost1s.append(lost1)\n",
    "\n",
    "                    reorder_day = None\n",
    "                    rs = []\n",
    "                    for k in range(K):\n",
    "                        rs.append(r_vars[i, k].X)\n",
    "                        R_value = R_vars[i, k].X\n",
    "                        # print(\n",
    "                        #     f\"第 {k+2} 天補貨策略: R_vars = {R_value}, tau_vars = {tau_vars[i, k].X}\"\n",
    "                        # )\n",
    "\n",
    "                        if int(R_value) == 1:\n",
    "                            reorder_day = k + 2\n",
    "                    # print(f\"*** 於第[{reorder_day}]天進貨 ***\\n\")\n",
    "\n",
    "                    all_Rs.append(reorder_day)\n",
    "                    all_rs.append(rs)\n",
    "\n",
    "                    demand_row = demand_df_train.iloc[i]\n",
    "\n",
    "                    total_demand_up = total_demand_up_to_k_minus_1_vars[i].X\n",
    "                    total_demand_down = total_demand_from_k_to_T_vars[i].X\n",
    "\n",
    "                    check_results_df = check_values(\n",
    "                        Q1_vars=Q1_vars,\n",
    "                        Q_hat_adjusteds=Q_hat_adjusteds,\n",
    "                        Q0_vars=Q0_vars,\n",
    "                        Sold_0s=Sold_0s,\n",
    "                        total_demand_up_to_k_minus_1_vars=total_demand_up_to_k_minus_1_vars,\n",
    "                        Sold_1s=Sold_1s,\n",
    "                        total_demand_from_k_to_T_vars=total_demand_from_k_to_T_vars,\n",
    "                        Q1_plus_lefts=Q1_plus_lefts,\n",
    "                        Left_0s=Left_0s,\n",
    "                        Lost_0s=Lost_0s,\n",
    "                        Left_1s=Left_1s,\n",
    "                        Lost_1s=Lost_1s,\n",
    "                    )\n",
    "                    # print(check_results_df)\n",
    "\n",
    "                #     for t in range(2):\n",
    "                #         if t == 0:\n",
    "                #             print(\n",
    "                #                 f\"  第 {t+1} 階段: 本階段期初庫存 = {Q0_vars[i].X}, 第一階段總需求 = {total_demand_up}, 銷售量 = {Sold_0s[i].X}, 本階段期末剩餘庫存 = {Left_0s[i].X}, 本期損失 = {Lost_0s[i].X}, 本期 holding cost = {Holding_Cost_0}\"\n",
    "                #             )\n",
    "                #         else:\n",
    "                #             print(\n",
    "                #                 f\"  第 {t+1} 階段: 本階段期初庫存 = {Q1_plus_lefts[i].X}, 重新預估需求 = {Q_hats[i].X}, 第二階段總需求 = {total_demand_down}, 銷售量 = {Sold_1s[i].X}, 本階段期末剩餘庫存 = {Left_1s[i].X}, 本期損失 = {Lost_1s[i].X}, 本期 holding cost = {Holding_Cost_1}\"\n",
    "                #             )\n",
    "\n",
    "                #     print(f\"  本觀察資料總利潤 = {daily_profit}\\n\")\n",
    "\n",
    "                # print(\"==========================================\")\n",
    "                # print(f\"最佳化模型平均利潤 = {np.mean(all_profits)}\")\n",
    "\n",
    "                return (\n",
    "                    all_Rs,\n",
    "                    all_losses,\n",
    "                    all_lefts,\n",
    "                    all_profits,\n",
    "                    all_operation_profits,\n",
    "                    alpha_values,\n",
    "                    beta_values,\n",
    "                    all_Fs,\n",
    "                    all_Q0s,\n",
    "                    all_Q1s,\n",
    "                    f_values,\n",
    "                    tau_values,\n",
    "                    all_holding_costs_0,\n",
    "                    all_holding_costs_1,\n",
    "                    all_left0s,\n",
    "                    all_left1s,\n",
    "                    all_lost0s,\n",
    "                    all_lost1s,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                print(\"===================== 找不到最佳解 ==================\")\n",
    "                print(f\"Model is feasible. Status: {model.status}\")\n",
    "                model.computeIIS()\n",
    "                model.write(\"model.ilp\")\n",
    "\n",
    "                for constr in model.getConstrs():\n",
    "                    if constr.IISConstr:\n",
    "                        print(f\"導致不可行的約束： {constr.constrName}\")\n",
    "\n",
    "                for var in model.getVars():\n",
    "                    if var.IISLB > 0 or var.IISUB > 0:\n",
    "                        print(\n",
    "                            f\"導致不可行的變量： {var.VarName}, IIS下界： {var.IISLB}, IIS上界： {var.IISUB}\"\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "\n",
    "        except gp.GurobiError as e:\n",
    "            print(f\"Error code {str(e.errno)}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_flexible_beta_with_second_training_16(\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_train,\n",
    "    Qk_hat_df,\n",
    "    training_df,\n",
    "    lambda_beta,\n",
    "    last_beta_total,\n",
    "):\n",
    "\n",
    "    result = __fully_flexible_beta_with_second_training_16(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df,\n",
    "        training_df=training_df,\n",
    "        lambda_beta=lambda_beta,\n",
    "        last_beta_total=last_beta_total,\n",
    "    )\n",
    "    if result is None:\n",
    "        print(f\"找不到最佳解\")\n",
    "        return None, None\n",
    "    else:\n",
    "        (\n",
    "            all_Rs,\n",
    "            all_losses,\n",
    "            all_lefts,\n",
    "            all_profits,\n",
    "            all_operation_profits,\n",
    "            alpha_values,\n",
    "            beta_values,\n",
    "            all_Fs,\n",
    "            all_Q0s,\n",
    "            all_Q1s,\n",
    "            f_values,\n",
    "            tau_values,\n",
    "            holding_costs_0s,\n",
    "            holding_costs_1s,\n",
    "            all_left0s,\n",
    "            all_left1s,\n",
    "            all_lost0s,\n",
    "            all_lost1s,\n",
    "        ) = result\n",
    "\n",
    "        # print(f\"all_Rs: {all_Rs}\")\n",
    "\n",
    "        return make_s3_related_strtegies_result(\n",
    "            all_Rs=all_Rs,\n",
    "            losses=all_losses,\n",
    "            lefts=all_lefts,\n",
    "            profits=all_profits,\n",
    "            operation_profits=all_operation_profits,\n",
    "            alpha_values=alpha_values,\n",
    "            beta_values=beta_values,\n",
    "            F_vars=all_Fs,\n",
    "            Q0_vars=all_Q0s,\n",
    "            Q1_vars=all_Q1s,\n",
    "            f_values=f_values,\n",
    "            tau_values=tau_values,\n",
    "            holding_costs_0s=holding_costs_0s,\n",
    "            holding_costs_1s=holding_costs_1s,\n",
    "            all_left0s=all_left0s,\n",
    "            all_left1s=all_left1s,\n",
    "            all_lost0s=all_lost0s,\n",
    "            all_lost1s=all_lost1s,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S1 - Grid for Fixed F & Fixed Rk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_fixed_F_fixed_R(\n",
    "    assigned_T,\n",
    "    assigned_F,\n",
    "    cost,\n",
    "    price,\n",
    "    salvage_value,\n",
    "    Qk_hat_df_test,\n",
    "    demand_df_test,\n",
    "    Q_star,\n",
    "):\n",
    "    assigned_R = assigned_T - 2\n",
    "    result, stimulation_result = cal_fixed_F_fixed_R(\n",
    "        Q_star,\n",
    "        assigned_F,\n",
    "        assigned_R,\n",
    "        demand_df_test,\n",
    "        cost,\n",
    "        price,\n",
    "        salvage_value,\n",
    "        Qk_hat_df_test,\n",
    "    )\n",
    "\n",
    "    results_df_1 = pd.DataFrame([result]).sort_values(\n",
    "        by=\"average_profits\", ascending=False\n",
    "    )\n",
    "\n",
    "    return results_df_1, pd.DataFrame(stimulation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S8 - Grid for Fixed F & Fixed Rk(with holding cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_fixed_F_fixed_R_with_holding_cost(\n",
    "    assigned_T,\n",
    "    assigned_F,\n",
    "    cost,\n",
    "    price,\n",
    "    salvage_value,\n",
    "    Qk_hat_df_test,\n",
    "    demand_df_test,\n",
    "    Q_star,\n",
    "    holding_cost,\n",
    "):\n",
    "\n",
    "    assigned_R = assigned_T - 2\n",
    "    result, stimulation_result = cal_fixed_F_fixed_R_with_holding_cost(\n",
    "        Q_star,\n",
    "        assigned_F,\n",
    "        assigned_R,\n",
    "        demand_df_test,\n",
    "        cost,\n",
    "        price,\n",
    "        salvage_value,\n",
    "        Qk_hat_df_test,\n",
    "        holding_cost,\n",
    "    )\n",
    "\n",
    "    results_df_1 = pd.DataFrame([result]).sort_values(\n",
    "        by=\"average_profits\", ascending=False\n",
    "    )\n",
    "\n",
    "    return results_df_1, pd.DataFrame(stimulation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S2 - Grid for Fixed Rk & Flexible F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_flexible_F_fixed_R(\n",
    "    assigned_R,\n",
    "    alphas,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_test,\n",
    "    Qk_hat_df_test,\n",
    "    testing_df,\n",
    "):\n",
    "\n",
    "    # ======================= Global Variables =======================\n",
    "\n",
    "    # Category 1 - Some variables that is important to future work\n",
    "    K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "    n = len(demand_df_test)\n",
    "\n",
    "    # Initialize lists or numpy arrays to replace Gurobi variables\n",
    "    Sold_0s = np.zeros(n)\n",
    "    Left_0s = np.zeros(n)\n",
    "    Lost_0s = np.zeros(n)\n",
    "    Sold_1s = np.zeros(n)\n",
    "    Left_1s = np.zeros(n)\n",
    "    Lost_1s = np.zeros(n)\n",
    "    all_holding_costs_0 = np.zeros(n)\n",
    "    all_holding_costs_1 = np.zeros(n)\n",
    "    profits_vars = np.zeros(n)\n",
    "\n",
    "    # 1-2. Arrays for demand calculation up to certain periods\n",
    "    total_demand_up_to_k_minus_1_vars = np.zeros(n)\n",
    "    total_demand_from_k_to_T_vars = np.zeros(n)\n",
    "    Q1_plus_lefts = np.zeros(n)\n",
    "\n",
    "    # 2. Variables for Model 2: Optimal Fraction Model\n",
    "    f_vars = np.zeros(n)\n",
    "    F_vars = np.zeros(n)  # Assuming values will be between 0 and 1\n",
    "    Q0_vars = np.zeros(n)  # Replace Q_star with a specific value as needed\n",
    "\n",
    "    # 3. Variables for Model 3: Optimal Order Time Model (2D array for binary values)\n",
    "    R_vars = np.zeros((n, K), dtype=int)  # Use dtype=int to represent binary 0/1 values\n",
    "\n",
    "    # 4. Variables for Model 4: Re-estimate order-up-to-level\n",
    "    Q1_vars = np.zeros(n)\n",
    "    Q_hats = np.zeros(n)\n",
    "    Q_hat_adjusteds = np.zeros(n)\n",
    "\n",
    "    # ======================= Start Stimulation! =======================\n",
    "\n",
    "    for i, row in demand_df_test.iterrows():\n",
    "\n",
    "        ### Data for this stimulation\n",
    "        demand_row = demand_df_test.iloc[i]\n",
    "        Qk_hat_df_test_row = Qk_hat_df_test.iloc[i]\n",
    "        X_data = testing_df.iloc[i].tolist()\n",
    "        X_data.append(1)\n",
    "\n",
    "        # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "        ### 用線性回歸計算F_var\n",
    "        f_vars[i] = sum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "        F_vars[i] = 1 / (1 + np.exp(-(f_vars[i])))\n",
    "        print(f\"f_vars[i]: {f_vars[i]}, F_vars[i]: {F_vars[i]}\")\n",
    "        Q0_vars[i] = F_vars[i] * Q_star\n",
    "\n",
    "        # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "        # Ensure only one `R` is set to 1 in each row by setting `assigned_R` to 1 and all others to 0\n",
    "        R_vars[i, assigned_R] = 1\n",
    "\n",
    "        # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "        Q_hats[i] = sum(\n",
    "            R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
    "        )\n",
    "        Q_hat_adjusteds[i] = Q_hats[i] - Q0_vars[i]\n",
    "        Q1_vars[i] = max(Q_hat_adjusteds[i], 0)\n",
    "\n",
    "        # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "        # Calculate the demand up to k-1\n",
    "        total_demand_up_to_k_minus_1 = sum(\n",
    "            R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_up_to_k_minus_1_vars[i] = total_demand_up_to_k_minus_1\n",
    "\n",
    "        # Calculate the demand from k to T\n",
    "        total_demand_from_k_to_T = sum(\n",
    "            R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars[i] = total_demand_from_k_to_T\n",
    "\n",
    "        Sold_0s[i] = min(total_demand_up_to_k_minus_1_vars[i], Q0_vars[i])\n",
    "        Left_0s[i] = max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "        Lost_0s[i] = max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "        Q1_plus_lefts[i] = Q1_vars[i] + Left_0s[i]\n",
    "\n",
    "        Sold_1s[i] = min(total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i])\n",
    "        Left_1s[i] = max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "        Lost_1s[i] = max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "\n",
    "        # all_holding_costs_0[i] = (\n",
    "        #     (Q0_vars[i] + Left_0s[i] + Q1_vars[i]) * ((assigned_R + 2) - 1) / 2\n",
    "        # )\n",
    "        # all_holding_costs_1[i] = (\n",
    "        #     (Q1_vars[i] + Left_0s[i] + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "        # )\n",
    "\n",
    "        profits_vars[i] = (\n",
    "            (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue from sales\n",
    "            - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "            - (cost - salvage_value) * Left_1s[i]\n",
    "        )\n",
    "\n",
    "        # profits_vars[i] = (\n",
    "        #     (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue from sales\n",
    "        #     - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "        #     - (cost - salvage_value) * (Left_0s[i] + Left_1s[i])  # 加上 Left_0s[i]\n",
    "        # )\n",
    "\n",
    "    # Calculate the average profit\n",
    "    print(f\"assigned_R: {assigned_R}\")\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"average_profits\": [np.mean(profits_vars)],\n",
    "            \"average_loss_penalty\": [\n",
    "                np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))\n",
    "            ],\n",
    "            \"average_left_penalty\": [\n",
    "                np.mean((cost - salvage_value) * (Left_0s[i] + Left_1s[i]))\n",
    "            ],\n",
    "            \"average_loss\": [np.mean((Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"average_left\": [np.mean((Left_0s[i] + Left_1s[i]))],\n",
    "            \"alpha_values\": [alphas],\n",
    "            \"R(T)\": assigned_R + 2,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    stimulation_result = pd.DataFrame(\n",
    "        {\n",
    "            \"F\": F_vars,\n",
    "            \"R(T)\": assigned_R + 2,\n",
    "            \"Sold_0\": Sold_0s,\n",
    "            \"Left_0\": Left_0s,\n",
    "            \"Lost_0\": Lost_0s,\n",
    "            \"Sold_1\": Sold_1s,\n",
    "            \"Left_1\": Left_1s,\n",
    "            \"Lost_1\": Lost_1s,\n",
    "            \"profits\": profits_vars,\n",
    "            \"Q0\": Q0_vars,\n",
    "            \"Q1\": Q1_vars,\n",
    "            \"hc0\": all_holding_costs_0,\n",
    "            \"hc1\": all_holding_costs_1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return results_df, stimulation_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3 - Grid for Fixed F & Flexible Rk(原s6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_fixed_F_flexible_R(\n",
    "    assigned_F,\n",
    "    betas,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_test,\n",
    "    Qk_hat_df_test,\n",
    "    testing_df,\n",
    "):\n",
    "\n",
    "    # ======================= Global Variables =======================\n",
    "\n",
    "    # Category 1 - Some variables that is important to future work\n",
    "    K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "    n = len(demand_df_test)\n",
    "\n",
    "    # Initialize lists or numpy arrays to replace Gurobi variables\n",
    "    Sold_0s = np.zeros(n)\n",
    "    Left_0s = np.zeros(n)\n",
    "    Lost_0s = np.zeros(n)\n",
    "    Sold_1s = np.zeros(n)\n",
    "    Left_1s = np.zeros(n)\n",
    "    Lost_1s = np.zeros(n)\n",
    "    all_holding_costs_0 = np.zeros(n)\n",
    "    all_holding_costs_1 = np.zeros(n)\n",
    "    profits_vars = np.zeros(n)\n",
    "\n",
    "    # 1-2. Arrays for demand calculation up to certain periods\n",
    "    total_demand_up_to_k_minus_1_vars = np.zeros(n)\n",
    "    total_demand_from_k_to_T_vars = np.zeros(n)\n",
    "    Q1_plus_lefts = np.zeros(n)\n",
    "\n",
    "    # 2. Variables for Model 2: Optimal Fraction Model\n",
    "    f_vars = np.zeros(n)\n",
    "    F_vars = np.zeros(n)  # Assuming values will be between 0 and 1\n",
    "    Q0_vars = np.zeros(n)  # Replace Q_star with a specific value as needed\n",
    "\n",
    "    # 3. Variables for Model 3: Optimal Order Time Model (2D array for binary values)\n",
    "    tau_vars = np.zeros((n, K))\n",
    "    exp_tau_vars = np.zeros((n, K))\n",
    "    r_vars = np.zeros((n, K))\n",
    "    max_r_index = np.zeros(n, dtype=int)\n",
    "    R_vars = np.zeros(\n",
    "        (n, K), dtype=int\n",
    "    )  # Binary array to select one optimal replenishment time\n",
    "\n",
    "    # 4. Variables for Model 4: Re-estimate order-up-to-level\n",
    "    Q1_vars = np.zeros(n)\n",
    "    Q_hats = np.zeros(n)\n",
    "    Q_hat_adjusteds = np.zeros(n)\n",
    "\n",
    "    # ======================= Start Stimulation! =======================\n",
    "\n",
    "    for i, row in demand_df_test.iterrows():\n",
    "\n",
    "        ### Data for this stimulation\n",
    "        demand_row = demand_df_test.iloc[i]\n",
    "        Qk_hat_df_test_row = Qk_hat_df_test.iloc[i]\n",
    "        X_data = testing_df.iloc[i].tolist()\n",
    "        X_data.append(1)\n",
    "\n",
    "        # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "        F_vars[i] = assigned_F\n",
    "        Q0_vars[i] = F_vars[i] * Q_star\n",
    "\n",
    "        # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "        for k in range(K):\n",
    "            tau_vars[i, k] = betas[k, 0]\n",
    "            exp_tau_vars[i, k] = np.exp(-tau_vars[i, k])  # Calculate exp(-tau_vars)\n",
    "\n",
    "        sum_exp_tau_vars = np.sum(\n",
    "            exp_tau_vars[i]\n",
    "        )  # Sum of all exp_tau_vars for normalization\n",
    "\n",
    "        for k in range(K):\n",
    "            r_vars[i, k] = exp_tau_vars[i, k] / sum_exp_tau_vars\n",
    "\n",
    "        max_r_index[i] = np.argmax(\n",
    "            r_vars[i]\n",
    "        )  # Find index of the maximum value in r_vars\n",
    "        R_vars[i, max_r_index[i]] = (\n",
    "            1  # Set only this R_vars element to 1, ensuring only one is set\n",
    "        )\n",
    "\n",
    "        # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "        Q_hats[i] = sum(\n",
    "            R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
    "        )\n",
    "        Q_hat_adjusteds[i] = Q_hats[i] - Q0_vars[i]\n",
    "        Q1_vars[i] = max(Q_hat_adjusteds[i], 0)\n",
    "\n",
    "        # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "        # Calculate the demand up to k-1\n",
    "        total_demand_up_to_k_minus_1 = sum(\n",
    "            R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_up_to_k_minus_1_vars[i] = total_demand_up_to_k_minus_1\n",
    "\n",
    "        # Calculate the demand from k to T\n",
    "        total_demand_from_k_to_T = sum(\n",
    "            R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars[i] = total_demand_from_k_to_T\n",
    "\n",
    "        Sold_0s[i] = min(total_demand_up_to_k_minus_1_vars[i], Q0_vars[i])\n",
    "        Left_0s[i] = max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "        Lost_0s[i] = max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "        Q1_plus_lefts[i] = Q1_vars[i] + Left_0s[i]\n",
    "\n",
    "        Sold_1s[i] = min(total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i])\n",
    "        Left_1s[i] = max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "        Lost_1s[i] = max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "\n",
    "        assigned_R = max_r_index[i]\n",
    "\n",
    "        all_holding_costs_0[i] = (\n",
    "            (Q0_vars[i] + Left_0s[i] + Q1_vars[i]) * ((assigned_R + 2) - 1) / 2\n",
    "        )\n",
    "        all_holding_costs_1[i] = (\n",
    "            (Q1_vars[i] + Left_0s[i] + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "        )\n",
    "\n",
    "        profits_vars[i] = (\n",
    "            (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue from sales\n",
    "            - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "            - (cost - salvage_value) * Left_1s[i]\n",
    "            - holding_cost * (all_holding_costs_0[i] + all_holding_costs_1[i])\n",
    "        )\n",
    "\n",
    "    # Calculate the average profit\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"average_profits\": [np.mean(profits_vars)],\n",
    "            \"average_loss\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"average_left\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"beta_balues\": [betas],\n",
    "            \"F\": [assigned_F],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    stimulation_result = pd.DataFrame(\n",
    "        {\n",
    "            \"F\": F_vars,\n",
    "            \"R(T)\": [x + 2 for x in max_r_index],\n",
    "            \"Sold_0\": Sold_0s,\n",
    "            \"Left_0\": Left_0s,\n",
    "            \"Lost_0\": Lost_0s,\n",
    "            \"Sold_1\": Sold_1s,\n",
    "            \"Left_1\": Left_1s,\n",
    "            \"Lost_1\": Lost_1s,\n",
    "            \"profits\": profits_vars,\n",
    "            \"Q0\": Q0_vars,\n",
    "            \"Q1\": Q1_vars,\n",
    "            \"hc0\": all_holding_costs_0,\n",
    "            \"hc1\": all_holding_costs_1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return results_df, stimulation_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully flexible F & Rk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S5 - Simple beta with softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_fully_flexible_simple_beta_with_softmax_5(\n",
    "    alphas,\n",
    "    betas,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_test,\n",
    "    Qk_hat_df_test,\n",
    "    testing_df,\n",
    "):\n",
    "\n",
    "    # ======================= Global Variables =======================\n",
    "\n",
    "    # Category 1 - Some variables that is important to future work\n",
    "    K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "    n = len(demand_df_test)\n",
    "\n",
    "    # Initialize lists or numpy arrays to replace Gurobi variables\n",
    "    Sold_0s = np.zeros(n)\n",
    "    Left_0s = np.zeros(n)\n",
    "    Lost_0s = np.zeros(n)\n",
    "    Sold_1s = np.zeros(n)\n",
    "    Left_1s = np.zeros(n)\n",
    "    Lost_1s = np.zeros(n)\n",
    "    all_holding_costs_0 = np.zeros(n)\n",
    "    all_holding_costs_1 = np.zeros(n)\n",
    "    profits_vars = np.zeros(n)\n",
    "\n",
    "    # 1-2. Arrays for demand calculation up to certain periods\n",
    "    total_demand_up_to_k_minus_1_vars = np.zeros(n)\n",
    "    total_demand_from_k_to_T_vars = np.zeros(n)\n",
    "    Q1_plus_lefts = np.zeros(n)\n",
    "\n",
    "    # 2. Variables for Model 2: Optimal Fraction Model\n",
    "    f_vars = np.zeros(n)\n",
    "    F_vars = np.zeros(n)  # Assuming values will be between 0 and 1\n",
    "    Q0_vars = np.zeros(n)  # Replace Q_star with a specific value as needed\n",
    "\n",
    "    # 3. Variables for Model 3: Optimal Order Time Model (2D array for binary values)\n",
    "    tau_vars = np.zeros((n, K))\n",
    "    exp_tau_vars = np.zeros((n, K))\n",
    "    r_vars = np.zeros((n, K))\n",
    "    max_r_index = np.zeros(n, dtype=int)\n",
    "    R_vars = np.zeros(\n",
    "        (n, K), dtype=int\n",
    "    )  # Binary array to select one optimal replenishment time\n",
    "\n",
    "    # 4. Variables for Model 4: Re-estimate order-up-to-level\n",
    "    Q1_vars = np.zeros(n)\n",
    "    Q_hats = np.zeros(n)\n",
    "    Q_hat_adjusteds = np.zeros(n)\n",
    "\n",
    "    # ======================= Start Stimulation! =======================\n",
    "\n",
    "    for i, row in demand_df_test.iterrows():\n",
    "\n",
    "        ### Data for this stimulation\n",
    "        demand_row = demand_df_test.iloc[i]\n",
    "        Qk_hat_df_test_row = Qk_hat_df_test.iloc[i]\n",
    "        X_data = testing_df.iloc[i].tolist()\n",
    "        X_data.append(1)\n",
    "\n",
    "        # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "        ### 用線性回歸計算F_var\n",
    "        f_vars[i] = sum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "        F_vars[i] = 1 / (1 + np.exp(-(f_vars[i])))\n",
    "        Q0_vars[i] = F_vars[i] * Q_star\n",
    "\n",
    "        # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "        for k in range(K):\n",
    "            tau_vars[i, k] = betas[k, 0]\n",
    "            exp_tau_vars[i, k] = np.exp(-tau_vars[i, k])  # Calculate exp(-tau_vars)\n",
    "\n",
    "        sum_exp_tau_vars = np.sum(\n",
    "            exp_tau_vars[i]\n",
    "        )  # Sum of all exp_tau_vars for normalization\n",
    "\n",
    "        for k in range(K):\n",
    "            r_vars[i, k] = exp_tau_vars[i, k] / sum_exp_tau_vars\n",
    "\n",
    "        max_r_index[i] = np.argmax(\n",
    "            r_vars[i]\n",
    "        )  # Find index of the maximum value in r_vars\n",
    "        R_vars[i, max_r_index[i]] = (\n",
    "            1  # Set only this R_vars element to 1, ensuring only one is set\n",
    "        )\n",
    "\n",
    "        # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "        Q_hats[i] = sum(\n",
    "            R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
    "        )\n",
    "        Q_hat_adjusteds[i] = Q_hats[i] - Q0_vars[i]\n",
    "        Q1_vars[i] = max(Q_hat_adjusteds[i], 0)\n",
    "\n",
    "        # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "        # Calculate the demand up to k-1\n",
    "        total_demand_up_to_k_minus_1 = sum(\n",
    "            R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_up_to_k_minus_1_vars[i] = total_demand_up_to_k_minus_1\n",
    "\n",
    "        # Calculate the demand from k to T\n",
    "        total_demand_from_k_to_T = sum(\n",
    "            R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars[i] = total_demand_from_k_to_T\n",
    "\n",
    "        Sold_0s[i] = min(total_demand_up_to_k_minus_1_vars[i], Q0_vars[i])\n",
    "        Left_0s[i] = max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "        Lost_0s[i] = max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "        Q1_plus_lefts[i] = Q1_vars[i] + Left_0s[i]\n",
    "\n",
    "        Sold_1s[i] = min(total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i])\n",
    "        Left_1s[i] = max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "        Lost_1s[i] = max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "\n",
    "        assigned_R = max_r_index[i]\n",
    "\n",
    "        all_holding_costs_0[i] = (\n",
    "            (Q0_vars[i] + Left_0s[i] + Q1_vars[i]) * ((assigned_R + 2) - 1) / 2\n",
    "        )\n",
    "        all_holding_costs_1[i] = (\n",
    "            (Q1_vars[i] + Left_0s[i] + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "        )\n",
    "\n",
    "        profits_vars[i] = (\n",
    "            (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue from sales\n",
    "            - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "            - (cost - salvage_value) * Left_1s[i]\n",
    "            - holding_cost * (all_holding_costs_0[i] + all_holding_costs_1[i])\n",
    "        )\n",
    "\n",
    "    # Calculate the average profit\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"average_profits\": [np.mean(profits_vars)],\n",
    "            \"average_loss\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"average_left\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"alpha_values\": [alphas],\n",
    "            \"beta_balues\": [betas],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    stimulation_result = pd.DataFrame(\n",
    "        {\n",
    "            \"F\": F_vars,\n",
    "            \"R(T)\": [x + 2 for x in max_r_index],\n",
    "            \"Sold_0\": Sold_0s,\n",
    "            \"Left_0\": Left_0s,\n",
    "            \"Lost_0\": Lost_0s,\n",
    "            \"Sold_1\": Sold_1s,\n",
    "            \"Left_1\": Left_1s,\n",
    "            \"Lost_1\": Lost_1s,\n",
    "            \"profits\": profits_vars,\n",
    "            \"Q0\": Q0_vars,\n",
    "            \"Q1\": Q1_vars,\n",
    "            \"hc0\": all_holding_costs_0,\n",
    "            \"hc1\": all_holding_costs_1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return results_df, stimulation_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S6 - Simple beta and softmax with T is 1 - sum(T-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_fully_flexible_simple_beta_with_softmax_6(\n",
    "    alphas,\n",
    "    betas,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_test,\n",
    "    Qk_hat_df_test,\n",
    "    testing_df,\n",
    "):\n",
    "\n",
    "    # ======================= Global Variables =======================\n",
    "\n",
    "    # Category 1 - Some variables that is important to future work\n",
    "    K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "    n = len(demand_df_test)\n",
    "\n",
    "    # Initialize lists or numpy arrays to replace Gurobi variables\n",
    "    Sold_0s = np.zeros(n)\n",
    "    Left_0s = np.zeros(n)\n",
    "    Lost_0s = np.zeros(n)\n",
    "    Sold_1s = np.zeros(n)\n",
    "    Left_1s = np.zeros(n)\n",
    "    Lost_1s = np.zeros(n)\n",
    "    all_holding_costs_0 = np.zeros(n)\n",
    "    all_holding_costs_1 = np.zeros(n)\n",
    "    profits_vars = np.zeros(n)\n",
    "\n",
    "    # 1-2. Arrays for demand calculation up to certain periods\n",
    "    total_demand_up_to_k_minus_1_vars = np.zeros(n)\n",
    "    total_demand_from_k_to_T_vars = np.zeros(n)\n",
    "    Q1_plus_lefts = np.zeros(n)\n",
    "\n",
    "    # 2. Variables for Model 2: Optimal Fraction Model\n",
    "    f_vars = np.zeros(n)\n",
    "    F_vars = np.zeros(n)  # Assuming values will be between 0 and 1\n",
    "    Q0_vars = np.zeros(n)  # Replace Q_star with a specific value as needed\n",
    "\n",
    "    # 3. Variables for Model 3: Optimal Order Time Model (2D array for binary values)\n",
    "    tau_vars = np.zeros((n, K - 1))\n",
    "    exp_tau_vars = np.zeros((n, K - 1))\n",
    "    r_vars = np.zeros((n, K))\n",
    "    max_r_index = np.zeros(n, dtype=int)\n",
    "    R_vars = np.zeros(\n",
    "        (n, K), dtype=int\n",
    "    )  # Binary array to select one optimal replenishment time\n",
    "\n",
    "    # 4. Variables for Model 4: Re-estimate order-up-to-level\n",
    "    Q1_vars = np.zeros(n)\n",
    "    Q_hats = np.zeros(n)\n",
    "    Q_hat_adjusteds = np.zeros(n)\n",
    "\n",
    "    # ======================= Start Stimulation! =======================\n",
    "\n",
    "    for i, row in demand_df_test.iterrows():\n",
    "\n",
    "        ### Data for this stimulation\n",
    "        demand_row = demand_df_test.iloc[i]\n",
    "        Qk_hat_df_test_row = Qk_hat_df_test.iloc[i]\n",
    "        X_data = testing_df.iloc[i].tolist()\n",
    "        X_data.append(1)\n",
    "\n",
    "        # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "        ### 用線性回歸計算F_var\n",
    "        f_vars[i] = sum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "        F_vars[i] = 1 / (1 + np.exp(-(f_vars[i])))\n",
    "        Q0_vars[i] = F_vars[i] * Q_star\n",
    "\n",
    "        # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "        # Step 1: Calculate tau_vars based on betas\n",
    "        for p in range(K - 1):\n",
    "            tau_vars[i, p] = betas[p, 0]  # Only intercept term is used\n",
    "            exp_tau_vars[i, p] = np.exp(-tau_vars[i, p])  # Calculate exp(-tau_vars)\n",
    "\n",
    "        # Step 2: Calculate softmax-normalized r_vars\n",
    "        sum_exp_tau_vars = (\n",
    "            np.sum(exp_tau_vars[i]) + 1\n",
    "        )  # Adding 1 as in the softmax denominator for the last element\n",
    "\n",
    "        for p in range(K):\n",
    "            if p == K - 1:\n",
    "                # Set the last r_vars element to ensure the sum of all r_vars elements is 1\n",
    "                r_vars[i, p] = 1 - np.sum(r_vars[i, : K - 1])\n",
    "            else:\n",
    "                r_vars[i, p] = exp_tau_vars[i, p] / sum_exp_tau_vars\n",
    "\n",
    "        # Step 3: Find the maximum r_vars element and set corresponding R_vars to 1\n",
    "        max_r_index[i] = np.argmax(\n",
    "            r_vars[i]\n",
    "        )  # Find index of the maximum value in r_vars\n",
    "        R_vars[i, max_r_index[i]] = (\n",
    "            1  # Set only this R_vars element to 1, ensuring only one is set\n",
    "        )\n",
    "\n",
    "        # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "        Q_hats[i] = sum(\n",
    "            R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
    "        )\n",
    "        Q_hat_adjusteds[i] = Q_hats[i] - Q0_vars[i]\n",
    "        Q1_vars[i] = max(Q_hat_adjusteds[i], 0)\n",
    "\n",
    "        # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "        # Calculate the demand up to k-1\n",
    "        total_demand_up_to_k_minus_1 = sum(\n",
    "            R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_up_to_k_minus_1_vars[i] = total_demand_up_to_k_minus_1\n",
    "\n",
    "        # Calculate the demand from k to T\n",
    "        total_demand_from_k_to_T = sum(\n",
    "            R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars[i] = total_demand_from_k_to_T\n",
    "\n",
    "        Sold_0s[i] = min(total_demand_up_to_k_minus_1_vars[i], Q0_vars[i])\n",
    "        Left_0s[i] = max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "        Lost_0s[i] = max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "        Q1_plus_lefts[i] = Q1_vars[i] + Left_0s[i]\n",
    "\n",
    "        Sold_1s[i] = min(total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i])\n",
    "        Left_1s[i] = max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "        Lost_1s[i] = max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "\n",
    "        assigned_R = max_r_index[i]\n",
    "\n",
    "        # all_holding_costs_0[i] = (\n",
    "        #     (Q0_vars[i] + Left_0s[i] + Q1_vars[i]) * ((assigned_R + 2) - 1) / 2\n",
    "        # )\n",
    "        # all_holding_costs_1[i] = (\n",
    "        #     (Q1_vars[i] + Left_0s[i] + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "        # )\n",
    "\n",
    "        profits_vars[i] = (\n",
    "            (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue from sales\n",
    "            - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "            - (cost - salvage_value) * Left_1s[i]\n",
    "            # - holding_cost * (all_holding_costs_0[i] + all_holding_costs_1[i])\n",
    "        )\n",
    "\n",
    "    # Calculate the average profit\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"average_profits\": [np.mean(profits_vars)],\n",
    "            \"average_loss\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"average_left\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"alpha_values\": [alphas],\n",
    "            \"beta_balues\": [betas],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    stimulation_result = pd.DataFrame(\n",
    "        {\n",
    "            \"F\": F_vars,\n",
    "            \"R(T)\": [x + 2 for x in max_r_index],\n",
    "            \"Sold_0\": Sold_0s,\n",
    "            \"Left_0\": Left_0s,\n",
    "            \"Lost_0\": Lost_0s,\n",
    "            \"Sold_1\": Sold_1s,\n",
    "            \"Left_1\": Left_1s,\n",
    "            \"Lost_1\": Lost_1s,\n",
    "            \"profits\": profits_vars,\n",
    "            \"Q0\": Q0_vars,\n",
    "            \"Q1\": Q1_vars,\n",
    "            \"hc0\": all_holding_costs_0,\n",
    "            \"hc1\": all_holding_costs_1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return results_df, stimulation_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S7 - Simple beat and softmax with T is 1 - sum(T-1) & tau with f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_fully_flexible_simple_beta_with_softmax_7(\n",
    "    alphas,\n",
    "    betas,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_test,\n",
    "    Qk_hat_df_test,\n",
    "    testing_df,\n",
    "):\n",
    "\n",
    "    # ======================= Global Variables =======================\n",
    "\n",
    "    # Category 1 - Some variables that is important to future work\n",
    "    K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "    n = len(demand_df_test)\n",
    "\n",
    "    # Initialize lists or numpy arrays to replace Gurobi variables\n",
    "    Sold_0s = np.zeros(n)\n",
    "    Left_0s = np.zeros(n)\n",
    "    Lost_0s = np.zeros(n)\n",
    "    Sold_1s = np.zeros(n)\n",
    "    Left_1s = np.zeros(n)\n",
    "    Lost_1s = np.zeros(n)\n",
    "    all_holding_costs_0 = np.zeros(n)\n",
    "    all_holding_costs_1 = np.zeros(n)\n",
    "    profits_vars = np.zeros(n)\n",
    "\n",
    "    # 1-2. Arrays for demand calculation up to certain periods\n",
    "    total_demand_up_to_k_minus_1_vars = np.zeros(n)\n",
    "    total_demand_from_k_to_T_vars = np.zeros(n)\n",
    "    Q1_plus_lefts = np.zeros(n)\n",
    "\n",
    "    # 2. Variables for Model 2: Optimal Fraction Model\n",
    "    f_vars = np.zeros(n)\n",
    "    F_vars = np.zeros(n)  # Assuming values will be between 0 and 1\n",
    "    Q0_vars = np.zeros(n)  # Replace Q_star with a specific value as needed\n",
    "\n",
    "    # 3. Variables for Model 3: Optimal Order Time Model (2D array for binary values)\n",
    "    tau_vars = np.zeros((n, K - 1))\n",
    "    exp_tau_vars = np.zeros((n, K - 1))\n",
    "    r_vars = np.zeros((n, K))\n",
    "    max_r_index = np.zeros(n, dtype=int)\n",
    "    R_vars = np.zeros(\n",
    "        (n, K), dtype=int\n",
    "    )  # Binary array to select one optimal replenishment time\n",
    "\n",
    "    # 4. Variables for Model 4: Re-estimate order-up-to-level\n",
    "    Q1_vars = np.zeros(n)\n",
    "    Q_hats = np.zeros(n)\n",
    "    Q_hat_adjusteds = np.zeros(n)\n",
    "\n",
    "    # ======================= Start Stimulation! =======================\n",
    "\n",
    "    for i, row in demand_df_test.iterrows():\n",
    "\n",
    "        ### Data for this stimulation\n",
    "        demand_row = demand_df_test.iloc[i]\n",
    "        Qk_hat_df_test_row = Qk_hat_df_test.iloc[i]\n",
    "        X_data = testing_df.iloc[i].tolist()\n",
    "        X_data.append(1)\n",
    "\n",
    "        # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "        ### 用線性回歸計算F_var\n",
    "        f_vars[i] = sum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "        F_vars[i] = 1 / (1 + np.exp(-(f_vars[i])))\n",
    "        Q0_vars[i] = F_vars[i] * Q_star\n",
    "\n",
    "        # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "        # Step 1: Calculate tau_vars based on betas and f_vars\n",
    "        for p in range(K - 1):\n",
    "            tau_vars[i, p] = betas[p, 0] + f_vars[i]\n",
    "            exp_tau_vars[i, p] = np.exp(-tau_vars[i, p])  # Calculate exp(-tau_vars)\n",
    "\n",
    "        # Step 2: Calculate the sum of exp_tau_vars for softmax normalization\n",
    "        sum_exp_tau_vars = np.sum(exp_tau_vars[i]) + 1  # Adding 1 for the last r_var\n",
    "\n",
    "        # Step 3: Calculate r_vars with softmax normalization\n",
    "        for p in range(K):\n",
    "            if p == K - 1:\n",
    "                # Last r_var element ensures all r_vars sum to 1\n",
    "                r_vars[i, p] = 1 - np.sum(r_vars[i, : K - 1])\n",
    "            else:\n",
    "                r_vars[i, p] = exp_tau_vars[i, p] / sum_exp_tau_vars\n",
    "\n",
    "        # Step 4: Find the index of the maximum r_vars and set corresponding R_vars to 1\n",
    "        max_r_index[i] = np.argmax(\n",
    "            r_vars[i]\n",
    "        )  # Find index of the maximum value in r_vars\n",
    "        R_vars[i, max_r_index[i]] = (\n",
    "            1  # Set only this R_vars element to 1, ensuring only one is set\n",
    "        )\n",
    "\n",
    "        # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "        Q_hats[i] = sum(\n",
    "            R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
    "        )\n",
    "        Q_hat_adjusteds[i] = Q_hats[i] - Q0_vars[i]\n",
    "        Q1_vars[i] = max(Q_hat_adjusteds[i], 0)\n",
    "\n",
    "        # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "        # Calculate the demand up to k-1\n",
    "        total_demand_up_to_k_minus_1 = sum(\n",
    "            R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_up_to_k_minus_1_vars[i] = total_demand_up_to_k_minus_1\n",
    "\n",
    "        # Calculate the demand from k to T\n",
    "        total_demand_from_k_to_T = sum(\n",
    "            R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars[i] = total_demand_from_k_to_T\n",
    "\n",
    "        Sold_0s[i] = min(total_demand_up_to_k_minus_1_vars[i], Q0_vars[i])\n",
    "        Left_0s[i] = max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "        Lost_0s[i] = max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "        Q1_plus_lefts[i] = Q1_vars[i] + Left_0s[i]\n",
    "\n",
    "        Sold_1s[i] = min(total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i])\n",
    "        Left_1s[i] = max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "        Lost_1s[i] = max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "\n",
    "        assigned_R = max_r_index[i]\n",
    "\n",
    "        all_holding_costs_0[i] = (\n",
    "            (Q0_vars[i] + Left_0s[i] + Q1_vars[i]) * ((assigned_R + 2) - 1) / 2\n",
    "        )\n",
    "        all_holding_costs_1[i] = (\n",
    "            (Q1_vars[i] + Left_0s[i] + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "        )\n",
    "\n",
    "        profits_vars[i] = (\n",
    "            (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue from sales\n",
    "            - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "            - (cost - salvage_value) * Left_1s[i]\n",
    "            - holding_cost * (all_holding_costs_0[i] + all_holding_costs_1[i])\n",
    "        )\n",
    "\n",
    "    # Calculate the average profit\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"average_profits\": [np.mean(profits_vars)],\n",
    "            \"average_loss\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"average_left\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"alpha_values\": [alphas],\n",
    "            \"beta_balues\": [betas],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    stimulation_result = pd.DataFrame(\n",
    "        {\n",
    "            \"F\": F_vars,\n",
    "            \"R(T)\": [x + 2 for x in max_r_index],\n",
    "            \"Sold_0\": Sold_0s,\n",
    "            \"Left_0\": Left_0s,\n",
    "            \"Lost_0\": Lost_0s,\n",
    "            \"Sold_1\": Sold_1s,\n",
    "            \"Left_1\": Left_1s,\n",
    "            \"Lost_1\": Lost_1s,\n",
    "            \"profits\": profits_vars,\n",
    "            \"Q0\": Q0_vars,\n",
    "            \"Q1\": Q1_vars,\n",
    "            \"hc0\": all_holding_costs_0,\n",
    "            \"hc1\": all_holding_costs_1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return results_df, stimulation_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S4 - Beta with softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_fully_flexible_beta_with_softmax_4(\n",
    "    alphas,\n",
    "    betas,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_test,\n",
    "    Qk_hat_df_test,\n",
    "    testing_df,\n",
    "):\n",
    "\n",
    "    # ======================= Global Variables =======================\n",
    "\n",
    "    # Category 1 - Some variables that is important to future work\n",
    "    K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "    n = len(demand_df_test)\n",
    "\n",
    "    # Initialize lists or numpy arrays to replace Gurobi variables\n",
    "    Sold_0s = np.zeros(n)\n",
    "    Left_0s = np.zeros(n)\n",
    "    Lost_0s = np.zeros(n)\n",
    "    Sold_1s = np.zeros(n)\n",
    "    Left_1s = np.zeros(n)\n",
    "    Lost_1s = np.zeros(n)\n",
    "    all_holding_costs_0 = np.zeros(n)\n",
    "    all_holding_costs_1 = np.zeros(n)\n",
    "    profits_vars = np.zeros(n)\n",
    "\n",
    "    # 1-2. Arrays for demand calculation up to certain periods\n",
    "    total_demand_up_to_k_minus_1_vars = np.zeros(n)\n",
    "    total_demand_from_k_to_T_vars = np.zeros(n)\n",
    "    Q1_plus_lefts = np.zeros(n)\n",
    "\n",
    "    # 2. Variables for Model 2: Optimal Fraction Model\n",
    "    f_vars = np.zeros(n)\n",
    "    F_vars = np.zeros(n)  # Assuming values will be between 0 and 1\n",
    "    Q0_vars = np.zeros(n)  # Replace Q_star with a specific value as needed\n",
    "\n",
    "    # 3. Variables for Model 3: Optimal Order Time Model (2D array for binary values)\n",
    "    tau_vars = np.zeros((n, K))\n",
    "    exp_tau_vars = np.zeros((n, K))\n",
    "    r_vars = np.zeros((n, K))\n",
    "    max_r_index = np.zeros(n, dtype=int)\n",
    "    R_vars = np.zeros(\n",
    "        (n, K), dtype=int\n",
    "    )  # Binary array to select one optimal replenishment time\n",
    "\n",
    "    # 4. Variables for Model 4: Re-estimate order-up-to-level\n",
    "    Q1_vars = np.zeros(n)\n",
    "    Q_hats = np.zeros(n)\n",
    "    Q_hat_adjusteds = np.zeros(n)\n",
    "\n",
    "    # ======================= Start Stimulation! =======================\n",
    "\n",
    "    for i, row in demand_df_test.iterrows():\n",
    "\n",
    "        ### Data for this stimulation\n",
    "        demand_row = demand_df_test.iloc[i]\n",
    "        Qk_hat_df_test_row = Qk_hat_df_test.iloc[i]\n",
    "        X_data = testing_df.iloc[i].tolist()\n",
    "        X_data.append(1)\n",
    "\n",
    "        # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "        ### 用線性回歸計算F_var\n",
    "        f_vars[i] = sum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "        F_vars[i] = 1 / (1 + np.exp(-(f_vars[i])))\n",
    "        Q0_vars[i] = F_vars[i] * Q_star\n",
    "\n",
    "        # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "        # Step 1: Calculate tau_vars as a linear combination of X_data and betas\n",
    "        for k in range(K):\n",
    "            tau_vars[i, k] = sum(\n",
    "                X_data[j] * betas[k, j] for j in range(features_num + 1)\n",
    "            )\n",
    "\n",
    "        # Step 2: Calculate the exponentials of tau_vars\n",
    "        exp_tau_vars[i] = np.exp(tau_vars[i])\n",
    "\n",
    "        # Step 3: Softmax normalization\n",
    "        sum_exp_tau = np.sum(exp_tau_vars[i])  # Sum of exponentials for normalization\n",
    "        r_vars[i] = exp_tau_vars[i] / sum_exp_tau  # Normalize to get softmax\n",
    "\n",
    "        max_r_index[i] = np.argmax(r_vars[i])\n",
    "        R_vars[i, max_r_index[i]] = 1\n",
    "\n",
    "        # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "        Q_hats[i] = sum(\n",
    "            R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
    "        )\n",
    "        Q_hat_adjusteds[i] = Q_hats[i] - Q0_vars[i]\n",
    "        Q1_vars[i] = max(Q_hat_adjusteds[i], 0)\n",
    "\n",
    "        # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "        # Calculate the demand up to k-1\n",
    "        total_demand_up_to_k_minus_1 = sum(\n",
    "            R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_up_to_k_minus_1_vars[i] = total_demand_up_to_k_minus_1\n",
    "\n",
    "        # Calculate the demand from k to T\n",
    "        total_demand_from_k_to_T = sum(\n",
    "            R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars[i] = total_demand_from_k_to_T\n",
    "\n",
    "        Sold_0s[i] = min(total_demand_up_to_k_minus_1_vars[i], Q0_vars[i])\n",
    "        Left_0s[i] = max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "        Lost_0s[i] = max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "        Q1_plus_lefts[i] = Q1_vars[i] + Left_0s[i]\n",
    "\n",
    "        Sold_1s[i] = min(total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i])\n",
    "        Left_1s[i] = max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "        Lost_1s[i] = max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "\n",
    "        # assigned_R = max_r_index[i]\n",
    "\n",
    "        # all_holding_costs_0[i] = (\n",
    "        #     (Q0_vars[i] + Left_0s[i] + Q1_vars[i]) * ((assigned_R + 2) - 1) / 2\n",
    "        # )\n",
    "        # all_holding_costs_1[i] = (\n",
    "        #     (Q1_vars[i] + Left_0s[i] + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "        # )\n",
    "\n",
    "        profits_vars[i] = (\n",
    "            (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue from sales\n",
    "            - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "            - (cost - salvage_value) * Left_1s[i]\n",
    "            # - holding_cost * (all_holding_costs_0[i] + all_holding_costs_1[i])\n",
    "        )\n",
    "\n",
    "    # Calculate the average profit\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"average_profits\": [np.mean(profits_vars)],\n",
    "            \"average_loss\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"average_left\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"alpha_values\": [alphas],\n",
    "            \"beta_balues\": [betas],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    stimulation_result = pd.DataFrame(\n",
    "        {\n",
    "            \"F\": F_vars,\n",
    "            \"R(T)\": [x + 2 for x in max_r_index],\n",
    "            \"Sold_0\": Sold_0s,\n",
    "            \"Left_0\": Left_0s,\n",
    "            \"Lost_0\": Lost_0s,\n",
    "            \"Sold_1\": Sold_1s,\n",
    "            \"Left_1\": Left_1s,\n",
    "            \"Lost_1\": Lost_1s,\n",
    "            \"profits\": profits_vars,\n",
    "            \"Q0\": Q0_vars,\n",
    "            \"Q1\": Q1_vars,\n",
    "            \"hc0\": all_holding_costs_0,\n",
    "            \"hc1\": all_holding_costs_1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return results_df, stimulation_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S12 - Beta without r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_fully_flexible_beta_with_softmax_12(\n",
    "    alphas,\n",
    "    betas,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_test,\n",
    "    Qk_hat_df_test,\n",
    "    testing_df,\n",
    "):\n",
    "\n",
    "    # ======================= Global Variables =======================\n",
    "\n",
    "    # Category 1 - Some variables that is important to future work\n",
    "    K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "    n = len(demand_df_test)\n",
    "\n",
    "    # Initialize lists or numpy arrays to replace Gurobi variables\n",
    "    Sold_0s = np.zeros(n)\n",
    "    Left_0s = np.zeros(n)\n",
    "    Lost_0s = np.zeros(n)\n",
    "    Sold_1s = np.zeros(n)\n",
    "    Left_1s = np.zeros(n)\n",
    "    Lost_1s = np.zeros(n)\n",
    "    all_holding_costs_0 = np.zeros(n)\n",
    "    all_holding_costs_1 = np.zeros(n)\n",
    "    profits_vars = np.zeros(n)\n",
    "\n",
    "    # 1-2. Arrays for demand calculation up to certain periods\n",
    "    total_demand_up_to_k_minus_1_vars = np.zeros(n)\n",
    "    total_demand_from_k_to_T_vars = np.zeros(n)\n",
    "    Q1_plus_lefts = np.zeros(n)\n",
    "\n",
    "    # 2. Variables for Model 2: Optimal Fraction Model\n",
    "    f_vars = np.zeros(n)\n",
    "    F_vars = np.zeros(n)  # Assuming values will be between 0 and 1\n",
    "    Q0_vars = np.zeros(n)  # Replace Q_star with a specific value as needed\n",
    "\n",
    "    # 3. Variables for Model 3: Optimal Order Time Model (2D array for binary values)\n",
    "    tau_vars = np.zeros((n, K))\n",
    "    exp_tau_vars = np.zeros((n, K))\n",
    "    r_vars = np.zeros((n, K))\n",
    "    max_r_index = np.zeros(n, dtype=int)\n",
    "    R_vars = np.zeros(\n",
    "        (n, K), dtype=int\n",
    "    )  # Binary array to select one optimal replenishment time\n",
    "\n",
    "    # 4. Variables for Model 4: Re-estimate order-up-to-level\n",
    "    Q1_vars = np.zeros(n)\n",
    "    Q_hats = np.zeros(n)\n",
    "    Q_hat_adjusteds = np.zeros(n)\n",
    "\n",
    "    # ======================= Start Stimulation! =======================\n",
    "\n",
    "    for i, row in demand_df_test.iterrows():\n",
    "\n",
    "        ### Data for this stimulation\n",
    "        demand_row = demand_df_test.iloc[i]\n",
    "        Qk_hat_df_test_row = Qk_hat_df_test.iloc[i]\n",
    "        X_data = testing_df.iloc[i].tolist()\n",
    "        X_data.append(1)\n",
    "\n",
    "        # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "        ### 用線性回歸計算F_var\n",
    "        f_vars[i] = sum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "        F_vars[i] = 1 / (1 + np.exp(-(f_vars[i])))\n",
    "        Q0_vars[i] = F_vars[i] * Q_star\n",
    "\n",
    "        # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "        # Step 1: Calculate tau_vars as a linear combination of X_data and betas\n",
    "        for k in range(K):\n",
    "            tau_vars[i, k] = sum(\n",
    "                X_data[j] * betas[k, j] for j in range(features_num + 1)\n",
    "            )\n",
    "\n",
    "        max_r_index[i] = np.argmax(tau_vars[i])\n",
    "        R_vars[i, max_r_index[i]] = 1\n",
    "\n",
    "        print(f\"tau: {tau_vars[i]}\")\n",
    "        print(f\"R: {R_vars[i]}\")\n",
    "        print(f\"max_r_index: {max_r_index[i]}\")\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "        # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "        Q_hats[i] = sum(\n",
    "            R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
    "        )\n",
    "        Q_hat_adjusteds[i] = Q_hats[i] - Q0_vars[i]\n",
    "        Q1_vars[i] = max(Q_hat_adjusteds[i], 0)\n",
    "\n",
    "        # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "        # Calculate the demand up to k-1\n",
    "        total_demand_up_to_k_minus_1 = sum(\n",
    "            R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_up_to_k_minus_1_vars[i] = total_demand_up_to_k_minus_1\n",
    "\n",
    "        # Calculate the demand from k to T\n",
    "        total_demand_from_k_to_T = sum(\n",
    "            R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars[i] = total_demand_from_k_to_T\n",
    "\n",
    "        Sold_0s[i] = min(total_demand_up_to_k_minus_1_vars[i], Q0_vars[i])\n",
    "        Left_0s[i] = max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "        Lost_0s[i] = max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "        Q1_plus_lefts[i] = Q1_vars[i] + Left_0s[i]\n",
    "\n",
    "        Sold_1s[i] = min(total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i])\n",
    "        Left_1s[i] = max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "        Lost_1s[i] = max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "\n",
    "        # assigned_R = max_r_index[i]\n",
    "\n",
    "        # all_holding_costs_0[i] = (\n",
    "        #     (Q0_vars[i] + Left_0s[i] + Q1_vars[i]) * ((assigned_R + 2) - 1) / 2\n",
    "        # )\n",
    "        # all_holding_costs_1[i] = (\n",
    "        #     (Q1_vars[i] + Left_0s[i] + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "        # )\n",
    "\n",
    "        # profits_vars[i] = (\n",
    "        #     (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue from sales\n",
    "        #     - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "        #     - (cost - salvage_value) * (Left_0s[i] + Left_1s[i])\n",
    "        # )\n",
    "\n",
    "        profits_vars[i] = (\n",
    "            (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue from sales\n",
    "            - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "            - (cost - salvage_value) * (Left_1s[i])\n",
    "        )\n",
    "\n",
    "    # Calculate the average profit\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"average_profits\": [np.mean(profits_vars)],\n",
    "            \"average_loss\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"average_left\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"alpha_values\": [alphas],\n",
    "            \"beta_balues\": [betas],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    stimulation_result = pd.DataFrame(\n",
    "        {\n",
    "            \"F\": F_vars,\n",
    "            \"R(T)\": [x + 2 for x in max_r_index],\n",
    "            \"Sold_0\": Sold_0s,\n",
    "            \"Left_0\": Left_0s,\n",
    "            \"Lost_0\": Lost_0s,\n",
    "            \"Sold_1\": Sold_1s,\n",
    "            \"Left_1\": Left_1s,\n",
    "            \"Lost_1\": Lost_1s,\n",
    "            \"profits\": profits_vars,\n",
    "            \"Q0\": Q0_vars,\n",
    "            \"Q1\": Q1_vars,\n",
    "            \"hc0\": all_holding_costs_0,\n",
    "            \"hc1\": all_holding_costs_1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return results_df, stimulation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S15 - Beta with Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_fully_flexible_beta_with_lasso_15(\n",
    "    alphas,\n",
    "    betas,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_test,\n",
    "    Qk_hat_df_test,\n",
    "    testing_df,\n",
    "):\n",
    "\n",
    "    # ======================= Global Variables =======================\n",
    "\n",
    "    # Category 1 - Some variables that is important to future work\n",
    "    K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "    n = len(demand_df_test)\n",
    "\n",
    "    # Initialize lists or numpy arrays to replace Gurobi variables\n",
    "    Sold_0s = np.zeros(n)\n",
    "    Left_0s = np.zeros(n)\n",
    "    Lost_0s = np.zeros(n)\n",
    "    Sold_1s = np.zeros(n)\n",
    "    Left_1s = np.zeros(n)\n",
    "    Lost_1s = np.zeros(n)\n",
    "    all_holding_costs_0 = np.zeros(n)\n",
    "    all_holding_costs_1 = np.zeros(n)\n",
    "    profits_vars = np.zeros(n)\n",
    "\n",
    "    # 1-2. Arrays for demand calculation up to certain periods\n",
    "    total_demand_up_to_k_minus_1_vars = np.zeros(n)\n",
    "    total_demand_from_k_to_T_vars = np.zeros(n)\n",
    "    Q1_plus_lefts = np.zeros(n)\n",
    "\n",
    "    # 2. Variables for Model 2: Optimal Fraction Model\n",
    "    f_vars = np.zeros(n)\n",
    "    F_vars = np.zeros(n)  # Assuming values will be between 0 and 1\n",
    "    Q0_vars = np.zeros(n)  # Replace Q_star with a specific value as needed\n",
    "\n",
    "    # 3. Variables for Model 3: Optimal Order Time Model (2D array for binary values)\n",
    "    tau_vars = np.zeros((n, K))\n",
    "    exp_tau_vars = np.zeros((n, K))\n",
    "    r_vars = np.zeros((n, K))\n",
    "    max_r_index = np.zeros(n, dtype=int)\n",
    "    R_vars = np.zeros(\n",
    "        (n, K), dtype=int\n",
    "    )  # Binary array to select one optimal replenishment time\n",
    "\n",
    "    # 4. Variables for Model 4: Re-estimate order-up-to-level\n",
    "    Q1_vars = np.zeros(n)\n",
    "    Q_hats = np.zeros(n)\n",
    "    Q_hat_adjusteds = np.zeros(n)\n",
    "\n",
    "    # ======================= Start Stimulation! =======================\n",
    "\n",
    "    for i, row in demand_df_test.iterrows():\n",
    "\n",
    "        ### Data for this stimulation\n",
    "        demand_row = demand_df_test.iloc[i]\n",
    "        Qk_hat_df_test_row = Qk_hat_df_test.iloc[i]\n",
    "        X_data = testing_df.iloc[i].tolist()\n",
    "        X_data.append(1)\n",
    "\n",
    "        # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "        ### 用線性回歸計算F_var\n",
    "        f_vars[i] = sum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "        F_vars[i] = 1 / (1 + np.exp(-(f_vars[i])))\n",
    "        Q0_vars[i] = F_vars[i] * Q_star\n",
    "\n",
    "        # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "        # Step 1: Calculate tau_vars as a linear combination of X_data and betas\n",
    "        for k in range(K):\n",
    "            tau_vars[i, k] = sum(\n",
    "                X_data[j] * betas[k, j] for j in range(features_num + 1)\n",
    "            )\n",
    "\n",
    "        max_r_index[i] = np.argmax(tau_vars[i])\n",
    "        R_vars[i, max_r_index[i]] = 1\n",
    "\n",
    "        print(f\"tau: {tau_vars[i]}\")\n",
    "        print(f\"R: {R_vars[i]}\")\n",
    "        print(f\"max_r_index: {max_r_index[i]}\")\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "        # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "        Q_hats[i] = sum(\n",
    "            R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
    "        )\n",
    "        Q_hat_adjusteds[i] = Q_hats[i] - Q0_vars[i]\n",
    "        Q1_vars[i] = max(Q_hat_adjusteds[i], 0)\n",
    "\n",
    "        # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "        # Calculate the demand up to k-1\n",
    "        total_demand_up_to_k_minus_1 = sum(\n",
    "            R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_up_to_k_minus_1_vars[i] = total_demand_up_to_k_minus_1\n",
    "\n",
    "        # Calculate the demand from k to T\n",
    "        total_demand_from_k_to_T = sum(\n",
    "            R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars[i] = total_demand_from_k_to_T\n",
    "\n",
    "        Sold_0s[i] = min(total_demand_up_to_k_minus_1_vars[i], Q0_vars[i])\n",
    "        Left_0s[i] = max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "        Lost_0s[i] = max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "        Q1_plus_lefts[i] = Q1_vars[i] + Left_0s[i]\n",
    "\n",
    "        Sold_1s[i] = min(total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i])\n",
    "        Left_1s[i] = max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "        Lost_1s[i] = max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "\n",
    "        # assigned_R = max_r_index[i]\n",
    "\n",
    "        # all_holding_costs_0[i] = (\n",
    "        #     (Q0_vars[i] + Left_0s[i] + Q1_vars[i]) * ((assigned_R + 2) - 1) / 2\n",
    "        # )\n",
    "        # all_holding_costs_1[i] = (\n",
    "        #     (Q1_vars[i] + Left_0s[i] + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "        # )\n",
    "\n",
    "        profits_vars[i] = (\n",
    "            (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue from sales\n",
    "            - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "            - (cost - salvage_value) * Left_1s[i]\n",
    "            # - holding_cost * (all_holding_costs_0[i] + all_holding_costs_1[i])\n",
    "        )\n",
    "\n",
    "    # Calculate the average profit\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"average_profits\": [np.mean(profits_vars)],\n",
    "            \"average_loss\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"average_left\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"alpha_values\": [alphas],\n",
    "            \"beta_balues\": [betas],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    stimulation_result = pd.DataFrame(\n",
    "        {\n",
    "            \"F\": F_vars,\n",
    "            \"R(T)\": [x + 2 for x in max_r_index],\n",
    "            \"Sold_0\": Sold_0s,\n",
    "            \"Left_0\": Left_0s,\n",
    "            \"Lost_0\": Lost_0s,\n",
    "            \"Sold_1\": Sold_1s,\n",
    "            \"Left_1\": Left_1s,\n",
    "            \"Lost_1\": Lost_1s,\n",
    "            \"profits\": profits_vars,\n",
    "            \"Q0\": Q0_vars,\n",
    "            \"Q1\": Q1_vars,\n",
    "            \"hc0\": all_holding_costs_0,\n",
    "            \"hc1\": all_holding_costs_1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return results_df, stimulation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S16 - Beta with second Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_fully_flexible_beta_with_second_training_16(\n",
    "    alphas,\n",
    "    betas,\n",
    "    salvage_value,\n",
    "    cost,\n",
    "    price,\n",
    "    Q_star,\n",
    "    demand_df_test,\n",
    "    Qk_hat_df_test,\n",
    "    testing_df,\n",
    "):\n",
    "\n",
    "    # ======================= Global Variables =======================\n",
    "\n",
    "    # Category 1 - Some variables that is important to future work\n",
    "    K = T - 2  # this is for k=2~T-1. => if T = 10(1~10), K will be 8. (0~7)\n",
    "    n = len(demand_df_test)\n",
    "\n",
    "    # Initialize lists or numpy arrays to replace Gurobi variables\n",
    "    Sold_0s = np.zeros(n)\n",
    "    Left_0s = np.zeros(n)\n",
    "    Lost_0s = np.zeros(n)\n",
    "    Sold_1s = np.zeros(n)\n",
    "    Left_1s = np.zeros(n)\n",
    "    Lost_1s = np.zeros(n)\n",
    "    all_holding_costs_0 = np.zeros(n)\n",
    "    all_holding_costs_1 = np.zeros(n)\n",
    "    profits_vars = np.zeros(n)\n",
    "\n",
    "    # 1-2. Arrays for demand calculation up to certain periods\n",
    "    total_demand_up_to_k_minus_1_vars = np.zeros(n)\n",
    "    total_demand_from_k_to_T_vars = np.zeros(n)\n",
    "    Q1_plus_lefts = np.zeros(n)\n",
    "\n",
    "    # 2. Variables for Model 2: Optimal Fraction Model\n",
    "    f_vars = np.zeros(n)\n",
    "    F_vars = np.zeros(n)  # Assuming values will be between 0 and 1\n",
    "    Q0_vars = np.zeros(n)  # Replace Q_star with a specific value as needed\n",
    "\n",
    "    # 3. Variables for Model 3: Optimal Order Time Model (2D array for binary values)\n",
    "    tau_vars = np.zeros((n, K))\n",
    "    exp_tau_vars = np.zeros((n, K))\n",
    "    r_vars = np.zeros((n, K))\n",
    "    max_r_index = np.zeros(n, dtype=int)\n",
    "    R_vars = np.zeros(\n",
    "        (n, K), dtype=int\n",
    "    )  # Binary array to select one optimal replenishment time\n",
    "\n",
    "    # 4. Variables for Model 4: Re-estimate order-up-to-level\n",
    "    Q1_vars = np.zeros(n)\n",
    "    Q_hats = np.zeros(n)\n",
    "    Q_hat_adjusteds = np.zeros(n)\n",
    "\n",
    "    # ======================= Start Stimulation! =======================\n",
    "\n",
    "    for i, row in demand_df_test.iterrows():\n",
    "\n",
    "        ### Data for this stimulation\n",
    "        demand_row = demand_df_test.iloc[i]\n",
    "        Qk_hat_df_test_row = Qk_hat_df_test.iloc[i]\n",
    "        X_data = testing_df.iloc[i].tolist()\n",
    "        X_data.append(1)\n",
    "\n",
    "        # =================== Model 1: Optimal Fraction Model ===================\n",
    "\n",
    "        ### 用線性回歸計算F_var\n",
    "        f_vars[i] = sum(X_data[j] * alphas[j] for j in range(features_num + 1))\n",
    "        F_vars[i] = 1 / (1 + np.exp(-(f_vars[i])))\n",
    "        Q0_vars[i] = F_vars[i] * Q_star\n",
    "\n",
    "        # =================== Model 2: Optimal Order Time Model ===================\n",
    "\n",
    "        # Step 1: Calculate tau_vars as a linear combination of X_data and betas\n",
    "        for k in range(K):\n",
    "            tau_vars[i, k] = sum(\n",
    "                X_data[j] * betas[k, j] for j in range(features_num + 1)\n",
    "            )\n",
    "\n",
    "        max_r_index[i] = np.argmax(tau_vars[i])\n",
    "        R_vars[i, max_r_index[i]] = 1\n",
    "\n",
    "        print(f\"tau: {tau_vars[i]}\")\n",
    "        print(f\"R: {R_vars[i]}\")\n",
    "        print(f\"max_r_index: {max_r_index[i]}\")\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "        # ============ Model 3: re-estimate order-up-to-level =================\n",
    "\n",
    "        Q_hats[i] = sum(\n",
    "            R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
    "        )\n",
    "        Q_hat_adjusteds[i] = Q_hats[i] - Q0_vars[i]\n",
    "        Q1_vars[i] = max(Q_hat_adjusteds[i], 0)\n",
    "\n",
    "        # =================== Model 4: Maximum Profit Model ===================\n",
    "\n",
    "        # Calculate the demand up to k-1\n",
    "        total_demand_up_to_k_minus_1 = sum(\n",
    "            R_vars[i, k - 2] * demand_row[: k - 1].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_up_to_k_minus_1_vars[i] = total_demand_up_to_k_minus_1\n",
    "\n",
    "        # Calculate the demand from k to T\n",
    "        total_demand_from_k_to_T = sum(\n",
    "            R_vars[i, k - 2] * demand_row[k - 1 :].sum() for k in range(2, T)\n",
    "        )\n",
    "        total_demand_from_k_to_T_vars[i] = total_demand_from_k_to_T\n",
    "\n",
    "        Sold_0s[i] = min(total_demand_up_to_k_minus_1_vars[i], Q0_vars[i])\n",
    "        Left_0s[i] = max(Q0_vars[i] - Sold_0s[i], 0)\n",
    "        Lost_0s[i] = max(total_demand_up_to_k_minus_1_vars[i] - Q0_vars[i], 0)\n",
    "        Q1_plus_lefts[i] = Q1_vars[i] + Left_0s[i]\n",
    "\n",
    "        Sold_1s[i] = min(total_demand_from_k_to_T_vars[i], Q1_plus_lefts[i])\n",
    "        Left_1s[i] = max(Q1_plus_lefts[i] - Sold_1s[i], 0)\n",
    "        Lost_1s[i] = max(total_demand_from_k_to_T_vars[i] - Q1_plus_lefts[i], 0)\n",
    "\n",
    "        # assigned_R = max_r_index[i]\n",
    "\n",
    "        # all_holding_costs_0[i] = (\n",
    "        #     (Q0_vars[i] + Left_0s[i] + Q1_vars[i]) * ((assigned_R + 2) - 1) / 2\n",
    "        # )\n",
    "        # all_holding_costs_1[i] = (\n",
    "        #     (Q1_vars[i] + Left_0s[i] + Left_1s[i]) * (T - (assigned_R + 2)) / 2\n",
    "        # )\n",
    "\n",
    "        profits_vars[i] = (\n",
    "            (price - cost) * (Sold_0s[i] + Sold_1s[i])  # Revenue from sales\n",
    "            - (price - cost) * (Lost_0s[i] + Lost_1s[i])  # Lost sales cost\n",
    "            - (cost - salvage_value) * Left_1s[i]\n",
    "            # - holding_cost * (all_holding_costs_0[i] + all_holding_costs_1[i])\n",
    "        )\n",
    "\n",
    "    # Calculate the average profit\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"average_profits\": [np.mean(profits_vars)],\n",
    "            \"average_loss\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"average_left\": [np.mean((price - cost) * (Lost_0s[i] + Lost_1s[i]))],\n",
    "            \"alpha_values\": [alphas],\n",
    "            \"beta_balues\": [betas],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    stimulation_result = pd.DataFrame(\n",
    "        {\n",
    "            \"F\": F_vars,\n",
    "            \"R(T)\": [x + 2 for x in max_r_index],\n",
    "            \"Sold_0\": Sold_0s,\n",
    "            \"Left_0\": Left_0s,\n",
    "            \"Lost_0\": Lost_0s,\n",
    "            \"Sold_1\": Sold_1s,\n",
    "            \"Left_1\": Left_1s,\n",
    "            \"Lost_1\": Lost_1s,\n",
    "            \"profits\": profits_vars,\n",
    "            \"Q0\": Q0_vars,\n",
    "            \"Q1\": Q1_vars,\n",
    "            \"hc0\": all_holding_costs_0,\n",
    "            \"hc1\": all_holding_costs_1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return results_df, stimulation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting reasonable parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202504101622"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CURRENT_TIMESTAMP = int(datetime.now().strftime(\"%Y%m%d%H%M\"))\n",
    "CURRENT_TIMESTAMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service_lv: 0.6\n"
     ]
    }
   ],
   "source": [
    "status = \"train\"\n",
    "\n",
    "service_lv = calculate_service_level(\n",
    "    salvage_value=salvage_value, cost=cost, price=price\n",
    ")\n",
    "print(f\"service_lv: {service_lv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_df, testing_df = training_data_folds[0]\n",
    "# demand_df_train, demand_df_test = demand_folds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>251.794016</td>\n",
       "      <td>254.356464</td>\n",
       "      <td>247.741536</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>261.523870</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.087872</td>\n",
       "      <td>252.716034</td>\n",
       "      <td>254.356465</td>\n",
       "      <td>254.356465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251.056784</td>\n",
       "      <td>251.010919</td>\n",
       "      <td>248.192143</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>250.249903</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>252.054546</td>\n",
       "      <td>246.842220</td>\n",
       "      <td>251.010920</td>\n",
       "      <td>251.010920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>297.528249</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>294.250464</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>283.569719</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>285.767294</td>\n",
       "      <td>287.835884</td>\n",
       "      <td>291.630992</td>\n",
       "      <td>291.630992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>289.066894</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.355508</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>285.816090</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>292.681865</td>\n",
       "      <td>290.851589</td>\n",
       "      <td>288.907838</td>\n",
       "      <td>288.907838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298.072424</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>299.903104</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>296.615372</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>290.943971</td>\n",
       "      <td>295.944768</td>\n",
       "      <td>293.500607</td>\n",
       "      <td>293.500607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>301.401948</td>\n",
       "      <td>298.930917</td>\n",
       "      <td>300.714683</td>\n",
       "      <td>298.930917</td>\n",
       "      <td>294.785980</td>\n",
       "      <td>298.930917</td>\n",
       "      <td>299.484772</td>\n",
       "      <td>298.727945</td>\n",
       "      <td>298.930917</td>\n",
       "      <td>298.930917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>291.672619</td>\n",
       "      <td>289.957928</td>\n",
       "      <td>291.788015</td>\n",
       "      <td>289.957928</td>\n",
       "      <td>285.872455</td>\n",
       "      <td>289.957928</td>\n",
       "      <td>290.444897</td>\n",
       "      <td>292.664979</td>\n",
       "      <td>289.957928</td>\n",
       "      <td>289.957928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>269.341662</td>\n",
       "      <td>273.073968</td>\n",
       "      <td>269.572013</td>\n",
       "      <td>273.073968</td>\n",
       "      <td>271.669642</td>\n",
       "      <td>273.073968</td>\n",
       "      <td>273.459253</td>\n",
       "      <td>273.376911</td>\n",
       "      <td>273.073968</td>\n",
       "      <td>273.073968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>291.803572</td>\n",
       "      <td>289.026459</td>\n",
       "      <td>288.668454</td>\n",
       "      <td>289.026459</td>\n",
       "      <td>282.672846</td>\n",
       "      <td>289.026459</td>\n",
       "      <td>287.717318</td>\n",
       "      <td>286.983188</td>\n",
       "      <td>289.026459</td>\n",
       "      <td>289.026459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>258.259455</td>\n",
       "      <td>255.913721</td>\n",
       "      <td>255.439341</td>\n",
       "      <td>255.913721</td>\n",
       "      <td>255.976937</td>\n",
       "      <td>255.913721</td>\n",
       "      <td>255.911150</td>\n",
       "      <td>251.612160</td>\n",
       "      <td>255.913721</td>\n",
       "      <td>255.913721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>278.551022</td>\n",
       "      <td>281.996051</td>\n",
       "      <td>281.029925</td>\n",
       "      <td>281.996051</td>\n",
       "      <td>289.535263</td>\n",
       "      <td>281.996051</td>\n",
       "      <td>285.332026</td>\n",
       "      <td>287.403702</td>\n",
       "      <td>281.996051</td>\n",
       "      <td>281.996051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>256.151738</td>\n",
       "      <td>257.167663</td>\n",
       "      <td>252.945792</td>\n",
       "      <td>257.167664</td>\n",
       "      <td>264.788247</td>\n",
       "      <td>257.167664</td>\n",
       "      <td>262.220107</td>\n",
       "      <td>256.201799</td>\n",
       "      <td>257.167664</td>\n",
       "      <td>257.167664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>295.186828</td>\n",
       "      <td>297.233446</td>\n",
       "      <td>298.436136</td>\n",
       "      <td>297.233446</td>\n",
       "      <td>301.105487</td>\n",
       "      <td>297.233446</td>\n",
       "      <td>295.272601</td>\n",
       "      <td>298.475322</td>\n",
       "      <td>297.233446</td>\n",
       "      <td>297.233446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>278.898077</td>\n",
       "      <td>276.092416</td>\n",
       "      <td>278.517826</td>\n",
       "      <td>276.092416</td>\n",
       "      <td>274.536813</td>\n",
       "      <td>276.092416</td>\n",
       "      <td>276.925605</td>\n",
       "      <td>274.583612</td>\n",
       "      <td>276.092416</td>\n",
       "      <td>276.092416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>276.126061</td>\n",
       "      <td>270.733097</td>\n",
       "      <td>271.699824</td>\n",
       "      <td>270.733097</td>\n",
       "      <td>268.070512</td>\n",
       "      <td>270.733097</td>\n",
       "      <td>266.551512</td>\n",
       "      <td>268.201901</td>\n",
       "      <td>270.733097</td>\n",
       "      <td>270.733097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "0   251.794016  254.356464  247.741536  254.356465  261.523870  254.356465   \n",
       "1   251.056784  251.010919  248.192143  251.010920  250.249903  251.010920   \n",
       "2   297.528249  291.630992  294.250464  291.630992  283.569719  291.630992   \n",
       "3   289.066894  288.907838  288.355508  288.907838  285.816090  288.907838   \n",
       "4   298.072424  293.500607  299.903104  293.500607  296.615372  293.500607   \n",
       "5   301.401948  298.930917  300.714683  298.930917  294.785980  298.930917   \n",
       "6   291.672619  289.957928  291.788015  289.957928  285.872455  289.957928   \n",
       "7   269.341662  273.073968  269.572013  273.073968  271.669642  273.073968   \n",
       "8   291.803572  289.026459  288.668454  289.026459  282.672846  289.026459   \n",
       "9   258.259455  255.913721  255.439341  255.913721  255.976937  255.913721   \n",
       "10  278.551022  281.996051  281.029925  281.996051  289.535263  281.996051   \n",
       "11  256.151738  257.167663  252.945792  257.167664  264.788247  257.167664   \n",
       "12  295.186828  297.233446  298.436136  297.233446  301.105487  297.233446   \n",
       "13  278.898077  276.092416  278.517826  276.092416  274.536813  276.092416   \n",
       "14  276.126061  270.733097  271.699824  270.733097  268.070512  270.733097   \n",
       "\n",
       "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "0   254.087872  252.716034  254.356465  254.356465  \n",
       "1   252.054546  246.842220  251.010920  251.010920  \n",
       "2   285.767294  287.835884  291.630992  291.630992  \n",
       "3   292.681865  290.851589  288.907838  288.907838  \n",
       "4   290.943971  295.944768  293.500607  293.500607  \n",
       "5   299.484772  298.727945  298.930917  298.930917  \n",
       "6   290.444897  292.664979  289.957928  289.957928  \n",
       "7   273.459253  273.376911  273.073968  273.073968  \n",
       "8   287.717318  286.983188  289.026459  289.026459  \n",
       "9   255.911150  251.612160  255.913721  255.913721  \n",
       "10  285.332026  287.403702  281.996051  281.996051  \n",
       "11  262.220107  256.201799  257.167664  257.167664  \n",
       "12  295.272601  298.475322  297.233446  297.233446  \n",
       "13  276.925605  274.583612  276.092416  276.092416  \n",
       "14  266.551512  268.201901  270.733097  270.733097  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of sum: 2779.8596331748327\n",
      "std of sum: 169.30737789635148\n",
      "60.0 percentile of sum: 2822.7531669043915\n",
      "Q_star: 2822.7531669043915\n"
     ]
    }
   ],
   "source": [
    "Q_star = calculate_Q_star(demand_df_train, service_level=service_lv)\n",
    "print(f\"Q_star: {Q_star}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Qk_hat_k2</th>\n",
       "      <th>Qk_hat_k3</th>\n",
       "      <th>Qk_hat_k4</th>\n",
       "      <th>Qk_hat_k5</th>\n",
       "      <th>Qk_hat_k6</th>\n",
       "      <th>Qk_hat_k7</th>\n",
       "      <th>Qk_hat_k8</th>\n",
       "      <th>Qk_hat_k9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2534.081315</td>\n",
       "      <td>2543.948337</td>\n",
       "      <td>2538.169538</td>\n",
       "      <td>2538.169539</td>\n",
       "      <td>2543.228824</td>\n",
       "      <td>2543.228823</td>\n",
       "      <td>2539.412604</td>\n",
       "      <td>2539.645653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2527.210887</td>\n",
       "      <td>2508.922414</td>\n",
       "      <td>2510.804283</td>\n",
       "      <td>2510.804283</td>\n",
       "      <td>2504.954162</td>\n",
       "      <td>2504.954163</td>\n",
       "      <td>2504.391943</td>\n",
       "      <td>2503.450194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2960.288461</td>\n",
       "      <td>2917.779397</td>\n",
       "      <td>2913.227722</td>\n",
       "      <td>2913.227722</td>\n",
       "      <td>2911.802544</td>\n",
       "      <td>2911.802544</td>\n",
       "      <td>2907.898303</td>\n",
       "      <td>2907.106573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2881.435279</td>\n",
       "      <td>2892.708128</td>\n",
       "      <td>2889.196078</td>\n",
       "      <td>2889.196078</td>\n",
       "      <td>2886.719816</td>\n",
       "      <td>2886.719816</td>\n",
       "      <td>2891.092232</td>\n",
       "      <td>2891.311134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2965.359748</td>\n",
       "      <td>2937.295369</td>\n",
       "      <td>2945.103421</td>\n",
       "      <td>2945.103421</td>\n",
       "      <td>2949.918090</td>\n",
       "      <td>2949.918090</td>\n",
       "      <td>2948.619230</td>\n",
       "      <td>2948.982677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2996.388296</td>\n",
       "      <td>2993.214630</td>\n",
       "      <td>2989.552936</td>\n",
       "      <td>2989.552937</td>\n",
       "      <td>2989.334267</td>\n",
       "      <td>2989.334267</td>\n",
       "      <td>2991.437954</td>\n",
       "      <td>2989.769915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2905.718591</td>\n",
       "      <td>2902.663421</td>\n",
       "      <td>2903.119411</td>\n",
       "      <td>2903.119411</td>\n",
       "      <td>2899.280034</td>\n",
       "      <td>2899.280034</td>\n",
       "      <td>2900.342555</td>\n",
       "      <td>2902.232607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2697.611597</td>\n",
       "      <td>2734.038448</td>\n",
       "      <td>2733.262880</td>\n",
       "      <td>2733.262878</td>\n",
       "      <td>2725.743234</td>\n",
       "      <td>2725.743234</td>\n",
       "      <td>2722.432589</td>\n",
       "      <td>2722.789323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2906.938973</td>\n",
       "      <td>2892.764411</td>\n",
       "      <td>2885.548336</td>\n",
       "      <td>2885.548336</td>\n",
       "      <td>2883.835781</td>\n",
       "      <td>2883.835781</td>\n",
       "      <td>2883.681181</td>\n",
       "      <td>2882.977674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2594.334133</td>\n",
       "      <td>2557.573980</td>\n",
       "      <td>2560.927624</td>\n",
       "      <td>2560.927623</td>\n",
       "      <td>2558.351789</td>\n",
       "      <td>2558.351789</td>\n",
       "      <td>2558.077087</td>\n",
       "      <td>2556.767651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2783.435609</td>\n",
       "      <td>2824.279231</td>\n",
       "      <td>2827.528743</td>\n",
       "      <td>2827.528743</td>\n",
       "      <td>2830.080320</td>\n",
       "      <td>2830.080320</td>\n",
       "      <td>2830.650460</td>\n",
       "      <td>2831.832195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2574.691858</td>\n",
       "      <td>2571.744830</td>\n",
       "      <td>2569.436321</td>\n",
       "      <td>2569.436323</td>\n",
       "      <td>2575.298932</td>\n",
       "      <td>2575.298932</td>\n",
       "      <td>2579.362663</td>\n",
       "      <td>2578.146004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2938.468259</td>\n",
       "      <td>2977.998016</td>\n",
       "      <td>2980.486511</td>\n",
       "      <td>2980.486512</td>\n",
       "      <td>2981.857422</td>\n",
       "      <td>2981.857422</td>\n",
       "      <td>2977.059368</td>\n",
       "      <td>2974.643605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2786.669883</td>\n",
       "      <td>2761.750741</td>\n",
       "      <td>2766.420356</td>\n",
       "      <td>2766.420355</td>\n",
       "      <td>2763.544241</td>\n",
       "      <td>2763.544241</td>\n",
       "      <td>2765.192205</td>\n",
       "      <td>2763.924015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2760.836871</td>\n",
       "      <td>2706.337694</td>\n",
       "      <td>2704.322900</td>\n",
       "      <td>2704.322898</td>\n",
       "      <td>2705.797118</td>\n",
       "      <td>2705.797118</td>\n",
       "      <td>2702.924363</td>\n",
       "      <td>2704.315296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Qk_hat_k2    Qk_hat_k3    Qk_hat_k4    Qk_hat_k5    Qk_hat_k6  \\\n",
       "0   2534.081315  2543.948337  2538.169538  2538.169539  2543.228824   \n",
       "1   2527.210887  2508.922414  2510.804283  2510.804283  2504.954162   \n",
       "2   2960.288461  2917.779397  2913.227722  2913.227722  2911.802544   \n",
       "3   2881.435279  2892.708128  2889.196078  2889.196078  2886.719816   \n",
       "4   2965.359748  2937.295369  2945.103421  2945.103421  2949.918090   \n",
       "5   2996.388296  2993.214630  2989.552936  2989.552937  2989.334267   \n",
       "6   2905.718591  2902.663421  2903.119411  2903.119411  2899.280034   \n",
       "7   2697.611597  2734.038448  2733.262880  2733.262878  2725.743234   \n",
       "8   2906.938973  2892.764411  2885.548336  2885.548336  2883.835781   \n",
       "9   2594.334133  2557.573980  2560.927624  2560.927623  2558.351789   \n",
       "10  2783.435609  2824.279231  2827.528743  2827.528743  2830.080320   \n",
       "11  2574.691858  2571.744830  2569.436321  2569.436323  2575.298932   \n",
       "12  2938.468259  2977.998016  2980.486511  2980.486512  2981.857422   \n",
       "13  2786.669883  2761.750741  2766.420356  2766.420355  2763.544241   \n",
       "14  2760.836871  2706.337694  2704.322900  2704.322898  2705.797118   \n",
       "\n",
       "      Qk_hat_k7    Qk_hat_k8    Qk_hat_k9  \n",
       "0   2543.228823  2539.412604  2539.645653  \n",
       "1   2504.954163  2504.391943  2503.450194  \n",
       "2   2911.802544  2907.898303  2907.106573  \n",
       "3   2886.719816  2891.092232  2891.311134  \n",
       "4   2949.918090  2948.619230  2948.982677  \n",
       "5   2989.334267  2991.437954  2989.769915  \n",
       "6   2899.280034  2900.342555  2902.232607  \n",
       "7   2725.743234  2722.432589  2722.789323  \n",
       "8   2883.835781  2883.681181  2882.977674  \n",
       "9   2558.351789  2558.077087  2556.767651  \n",
       "10  2830.080320  2830.650460  2831.832195  \n",
       "11  2575.298932  2579.362663  2578.146004  \n",
       "12  2981.857422  2977.059368  2974.643605  \n",
       "13  2763.544241  2765.192205  2763.924015  \n",
       "14  2705.797118  2702.924363  2704.315296  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_matrix, covariance_matrix = cal_mu_and_cov_matrix(demand_df_train)\n",
    "Qk_hat_df_train = make_Qk_hat_df(\n",
    "    demand_df_train, T, service_lv, mu_matrix, covariance_matrix\n",
    ")\n",
    "Qk_hat_df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-folds training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data_folds), len(demand_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Testing Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for single fold training.\n",
    "def perform_fold_training(\n",
    "    training_df, demand_df_train, Qk_hat_df_train, Q_star\n",
    ") -> dict[str, float]:\n",
    "\n",
    "    # 1. Baseline model\n",
    "    (\n",
    "        baseline_avg_losses,\n",
    "        baseline_avg_lefts,\n",
    "        baseline_avg_profits,\n",
    "        baseline_avg_operation_profits,\n",
    "        baseline_stimulation_df,\n",
    "    ) = one_time_procurement(\n",
    "        Q_star=Q_star,\n",
    "        demand_df=demand_df_train,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        salvage_value=salvage_value,\n",
    "    )\n",
    "\n",
    "    # 2. S1 - Grid F & Grid R\n",
    "\n",
    "    results_df_1, stimulation_results_df_1 = None, None\n",
    "\n",
    "    results_df_1, stimulation_results_df_1 = grid_fixed_F_fixed_R(\n",
    "        assigned_Ts=ASSIGNED_TS,\n",
    "        assigned_Fs=ASSIGNED_FS,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        salvage_value=salvage_value,\n",
    "        Qk_hat_df=Qk_hat_df_train,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Q_star=Q_star,\n",
    "    )\n",
    "\n",
    "    S1_profit_training = results_df_1.iloc[0][\"average_profits\"]\n",
    "\n",
    "    # 3. S2 - Grid R & Flexible F\n",
    "\n",
    "    results_df_2, stimulation_results_df_2 = None, None\n",
    "    results_df_2, stimulation_results_df_2 = grid_flexible_F_fixed_R(\n",
    "        assigned_Ts=ASSIGNED_TS,\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df_train=Qk_hat_df_train,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "\n",
    "    S2_profit_training = results_df_2.iloc[0][\"average_profits\"]\n",
    "\n",
    "    # 5. S14 - Optimized F & Rk\n",
    "    results_df_14, stimulation_results_df_14 = None, None\n",
    "    results_df_14, stimulation_results_df_14 = cal_optimized_F_R(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df_train,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "    S14_profit_training = results_df_14.iloc[0][\"average_profits\"]\n",
    "\n",
    "    # 4. S12 - Beta without r\n",
    "\n",
    "    results_df_12, stimulation_results_df_12 = None, None\n",
    "    results_df_12, stimulation_results_df_12 = fully_flexible_beta_with_softmax_12(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df_train=demand_df_train,\n",
    "        Qk_hat_df=Qk_hat_df_train,\n",
    "        training_df=training_df,\n",
    "    )\n",
    "    if results_df_12 is not None:\n",
    "        S12_profit_training = results_df_12.iloc[0][\"average_profits\"]\n",
    "    else:\n",
    "        S12_profit_training = None\n",
    "\n",
    "    # # 6. S15 - Beta with Lasso\n",
    "    # results_df_15, stimulation_results_df_15 = None, None\n",
    "    # results_df_15, stimulation_results_df_15 = fully_flexible_beta_with_lasso_15(\n",
    "    #     salvage_value=salvage_value,\n",
    "    #     cost=cost,\n",
    "    #     price=price,\n",
    "    #     Q_star=Q_star,\n",
    "    #     demand_df_train=demand_df_train,\n",
    "    #     Qk_hat_df=Qk_hat_df_train,\n",
    "    #     training_df=training_df,\n",
    "    #     lambda_beta=LASSO_BETA,\n",
    "    # )\n",
    "    # if results_df_15 is not None:\n",
    "    #     S15_profit_training = results_df_15.iloc[0][\"average_profits\"]\n",
    "    # else:\n",
    "    #     S15_profit_training = None\n",
    "\n",
    "    # # 7. S16 - Beta with Second Training\n",
    "    # results_df_16, stimulation_results_df_16 = None, None\n",
    "    # if results_df_12 is not None:\n",
    "    #     last_beta_total = np.sum(np.abs(results_df_12.iloc[0][\"beta_values\"]))\n",
    "    #     results_df_16, stimulation_results_df_16 = (\n",
    "    #         fully_flexible_beta_with_second_training_16(\n",
    "    #             salvage_value=salvage_value,\n",
    "    #             cost=cost,\n",
    "    #             price=price,\n",
    "    #             Q_star=Q_star,\n",
    "    #             demand_df_train=demand_df_train,\n",
    "    #             Qk_hat_df=Qk_hat_df_train,\n",
    "    #             training_df=training_df,\n",
    "    #             lambda_beta=LASSO_BETA_SECOND_TRAIN,\n",
    "    #             last_beta_total=last_beta_total,\n",
    "    #         )\n",
    "    #     )\n",
    "    # if results_df_16 is not None:\n",
    "    #     S16_profit_training = results_df_16.iloc[0][\"average_profits\"]\n",
    "    # else:\n",
    "    #     S16_profit_training = None\n",
    "\n",
    "    # print(f\"baseline_profit: {baseline_avg_profits}\")\n",
    "    # print(f\"S1_profit_training: {S1_profit_training}\")\n",
    "    # print(f\"S2_profit_training: {S2_profit_training}\")\n",
    "    # print(f\"S12_profit_training: {S12_profit_training}\")\n",
    "    # print(f\"S14_profit_training: {S14_profit_training}\")\n",
    "    # print(f\"S15_profit_training: {S15_profit_training}\")\n",
    "    # print(f\"S16_profit_training: {S16_profit_training}\")\n",
    "\n",
    "    # 整理利潤結果\n",
    "    training_profits = {\n",
    "        \"baseline\": baseline_avg_profits,\n",
    "        \"S1\": S1_profit_training,\n",
    "        \"S2\": S2_profit_training,\n",
    "        \"S12\": S12_profit_training,\n",
    "        # \"S15\": S15_profit_training,\n",
    "        # \"S16\": S16_profit_training,\n",
    "        # \"S12\": None,\n",
    "        \"S15\": None,\n",
    "        \"S16\": None,\n",
    "        \"S14\": S14_profit_training,\n",
    "    }\n",
    "\n",
    "    training_results = {\n",
    "        \"S1\": results_df_1,\n",
    "        \"S2\": results_df_2,\n",
    "        \"S12\": results_df_12,\n",
    "        # \"S15\": results_df_15,\n",
    "        # \"S16\": results_df_16,\n",
    "        # \"S12\": None,\n",
    "        \"S15\": None,\n",
    "        \"S16\": None,\n",
    "        \"S14\": results_df_14,\n",
    "    }\n",
    "\n",
    "    training_stimulation_results = {\n",
    "        \"baseline\": baseline_stimulation_df,\n",
    "        \"S1\": stimulation_results_df_1,\n",
    "        \"S2\": stimulation_results_df_2,\n",
    "        \"S12\": stimulation_results_df_12,\n",
    "        # \"S15\": stimulation_results_df_15,\n",
    "        # \"S16\": stimulation_results_df_16,\n",
    "        # \"S12\": None,\n",
    "        \"S15\": None,\n",
    "        \"S16\": None,\n",
    "        \"S14\": stimulation_results_df_14,\n",
    "    }\n",
    "\n",
    "    return training_profits, training_results, training_stimulation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for single fold testing.\n",
    "\n",
    "\n",
    "def perform_fold_testing(\n",
    "    results_df_1,\n",
    "    results_df_2,\n",
    "    results_df_12,\n",
    "    results_df_15,\n",
    "    results_df_16,\n",
    "    demand_df_test,\n",
    "    Qk_hat_df_test,\n",
    "    Q_star,\n",
    "    testing_df,\n",
    ") -> dict[str, float]:\n",
    "\n",
    "    # 1. Baseline model\n",
    "\n",
    "    (\n",
    "        test_baseline_avg_loss,\n",
    "        test_baseline_avg_lefts,\n",
    "        test_baseline_avg_profits,\n",
    "        test_baseline_avg_operation_profits,\n",
    "        test_stimulation_df_baseline,\n",
    "    ) = one_time_procurement(\n",
    "        Q_star=Q_star,\n",
    "        demand_df=demand_df_test,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        salvage_value=salvage_value,\n",
    "    )\n",
    "\n",
    "    print(f\"baseline_profit: {test_baseline_avg_profits}\")\n",
    "\n",
    "    # 2. S1 - Grid F & Grid R\n",
    "    if results_df_1 is not None:\n",
    "        assigned_T = results_df_1.iloc[0][\"R(T)\"]\n",
    "        assigned_F = results_df_1.iloc[0][\"F\"]\n",
    "\n",
    "        test_results_df_1, test_stimulation_results_df_1 = cal_test_fixed_F_fixed_R(\n",
    "            assigned_T=int(assigned_T),\n",
    "            assigned_F=assigned_F,\n",
    "            salvage_value=salvage_value,\n",
    "            cost=cost,\n",
    "            price=price,\n",
    "            Q_star=Q_star,\n",
    "            demand_df_test=demand_df_test,\n",
    "            Qk_hat_df_test=Qk_hat_df_test,\n",
    "        )\n",
    "\n",
    "    S1_profit_testing = test_results_df_1.iloc[0][\"average_profits\"]\n",
    "\n",
    "    # 3. S2 - Grid R & Flexible F\n",
    "\n",
    "    if results_df_2 is not None and len(results_df_2) > 0:\n",
    "        assigned_R = results_df_2.iloc[0][\"R\"]\n",
    "        alphas = results_df_2.iloc[0][\"alpha_values\"]\n",
    "\n",
    "        test_results_df_2, test_stimulation_results_df_2 = cal_test_flexible_F_fixed_R(\n",
    "            assigned_R=assigned_R[0],\n",
    "            alphas=alphas,\n",
    "            salvage_value=salvage_value,\n",
    "            cost=cost,\n",
    "            price=price,\n",
    "            Q_star=Q_star,\n",
    "            demand_df_test=demand_df_test,\n",
    "            Qk_hat_df_test=Qk_hat_df_test,\n",
    "            testing_df=testing_df,\n",
    "        )\n",
    "\n",
    "    S2_profit_testing = test_results_df_2.iloc[0][\"average_profits\"]\n",
    "\n",
    "    # 5. S14 - Optimized F & Rk\n",
    "    test_results_df_14, test_stimulation_results_df_14 = cal_optimized_F_R(\n",
    "        salvage_value=salvage_value,\n",
    "        cost=cost,\n",
    "        price=price,\n",
    "        Q_star=Q_star,\n",
    "        demand_df=demand_df_test,\n",
    "        Qk_hat_df=Qk_hat_df_test,\n",
    "        training_df=testing_df,\n",
    "    )\n",
    "\n",
    "    S14_profit_testing = test_results_df_14.iloc[0][\"average_profits\"]\n",
    "\n",
    "    # 4. S12 - Beta without r\n",
    "    test_results_df_12, test_stimulation_results_df_12 = None, None\n",
    "    if results_df_12 is not None:\n",
    "        alphas = results_df_12.iloc[0][\"alpha_values\"]\n",
    "        betas = results_df_12.iloc[0][\"beta_values\"]\n",
    "\n",
    "        test_results_df_12, test_stimulation_results_df_12 = (\n",
    "            cal_test_fully_flexible_beta_with_softmax_12(\n",
    "                alphas=alphas,\n",
    "                betas=betas,\n",
    "                salvage_value=salvage_value,\n",
    "                cost=cost,\n",
    "                price=price,\n",
    "                Q_star=Q_star,\n",
    "                demand_df_test=demand_df_test,\n",
    "                Qk_hat_df_test=Qk_hat_df_test,\n",
    "                testing_df=testing_df,\n",
    "            )\n",
    "        )\n",
    "        S12_profit_testing = test_results_df_12.iloc[0][\"average_profits\"]\n",
    "    else:\n",
    "        S12_profit_testing = None\n",
    "\n",
    "    # # 6. S15 - Beta with Lasso\n",
    "    # test_results_df_15, test_stimulation_results_df_15 = None, None\n",
    "    # if results_df_15 is not None:\n",
    "    #     alphas = results_df_15.iloc[0][\"alpha_values\"]\n",
    "    #     betas = results_df_15.iloc[0][\"beta_values\"]\n",
    "\n",
    "    #     test_results_df_15, test_stimulation_results_df_15 = (\n",
    "    #         cal_test_fully_flexible_beta_with_lasso_15(\n",
    "    #             alphas=alphas,\n",
    "    #             betas=betas,\n",
    "    #             salvage_value=salvage_value,\n",
    "    #             cost=cost,\n",
    "    #             price=price,\n",
    "    #             Q_star=Q_star,\n",
    "    #             demand_df_test=demand_df_test,\n",
    "    #             Qk_hat_df_test=Qk_hat_df_test,\n",
    "    #             testing_df=testing_df,\n",
    "    #         )\n",
    "    #     )\n",
    "    #     S15_profit_testing = test_results_df_15.iloc[0][\"average_profits\"]\n",
    "    # else:\n",
    "    #     S15_profit_testing = None\n",
    "\n",
    "    # # 7. S16 - Beta with Second Training\n",
    "    # test_results_df_16, test_stimulation_results_df_16 = None, None\n",
    "    # if results_df_16 is not None:\n",
    "    #     alphas = results_df_16.iloc[0][\"alpha_values\"]\n",
    "    #     betas = results_df_16.iloc[0][\"beta_values\"]\n",
    "\n",
    "    #     test_results_df_16, test_stimulation_results_df_16 = (\n",
    "    #         cal_test_fully_flexible_beta_with_second_training_16(\n",
    "    #             alphas=alphas,\n",
    "    #             betas=betas,\n",
    "    #             salvage_value=salvage_value,\n",
    "    #             cost=cost,\n",
    "    #             price=price,\n",
    "    #             Q_star=Q_star,\n",
    "    #             demand_df_test=demand_df_test,\n",
    "    #             Qk_hat_df_test=Qk_hat_df_test,\n",
    "    #             testing_df=testing_df,\n",
    "    #         )\n",
    "    #     )\n",
    "    #     S16_profit_testing = test_results_df_16.iloc[0][\"average_profits\"]\n",
    "    # else:\n",
    "    #     S16_profit_testing = None\n",
    "\n",
    "    # print(f\"baseline_profit: {test_baseline_avg_profits}\")\n",
    "    # print(f\"S1_profit_testing: {S1_profit_testing}\")\n",
    "    # print(f\"S2_profit_testing: {S2_profit_testing}\")\n",
    "    # print(f\"S12_profit_testing: {S12_profit_testing}\")\n",
    "    # print(f\"S14_profit_testing: {S14_profit_testing}\")\n",
    "    # print(f\"S15_profit_testing: {S15_profit_testing}\")\n",
    "    # print(f\"S16_profit_testing: {S16_profit_testing}\")\n",
    "\n",
    "    # 整理利潤結果\n",
    "    testing_profits = {\n",
    "        \"baseline\": test_baseline_avg_profits,\n",
    "        \"S1\": S1_profit_testing,\n",
    "        \"S2\": S2_profit_testing,\n",
    "        \"S12\": S12_profit_testing,\n",
    "        # \"S15\": S15_profit_testing,\n",
    "        # \"S16\": S16_profit_testing,\n",
    "        # \"S12\": None,\n",
    "        \"S15\": None,\n",
    "        \"S16\": None,\n",
    "        \"S14\": S14_profit_testing,\n",
    "    }\n",
    "\n",
    "    testing_stimulation_results = {\n",
    "        \"baseline\": test_stimulation_df_baseline,\n",
    "        \"S1\": test_stimulation_results_df_1,\n",
    "        \"S2\": test_stimulation_results_df_2,\n",
    "        \"S12\": test_stimulation_results_df_12,\n",
    "        # \"S15\": test_stimulation_results_df_15,\n",
    "        # \"S16\": test_stimulation_results_df_16,\n",
    "        # \"S12\": None,\n",
    "        \"S15\": None,\n",
    "        \"S16\": None,\n",
    "        \"S14\": test_stimulation_results_df_14,\n",
    "    }\n",
    "\n",
    "    return testing_profits, testing_stimulation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Processing Fold 1 =====\n",
      "training_df: \n",
      "           X1   X2          X3\n",
      "0   17.744068  0.0  254.356465\n",
      "1   18.575947  0.0  251.010920\n",
      "2   18.013817  0.0  291.630992\n",
      "3   17.724416  0.0  288.907838\n",
      "4   17.118274  0.0  293.500607\n",
      "5   18.229471  0.0  298.930917\n",
      "6   17.187936  0.0  289.957928\n",
      "7   19.458865  0.0  273.073968\n",
      "8   19.818314  0.0  289.026459\n",
      "9   16.917208  0.0  255.913721\n",
      "10  18.958625  0.0  281.996051\n",
      "11  17.644475  0.0  257.167664\n",
      "12  17.840223  0.0  297.233446\n",
      "13  19.627983  0.0  276.092416\n",
      "14  15.355180  0.0  270.733097\n",
      "demand_df_train: \n",
      "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
      "0   251.794016  254.356464  247.741536  254.356465  261.523870  254.356465   \n",
      "1   251.056784  251.010919  248.192143  251.010920  250.249903  251.010920   \n",
      "2   297.528249  291.630992  294.250464  291.630992  283.569719  291.630992   \n",
      "3   289.066894  288.907838  288.355508  288.907838  285.816090  288.907838   \n",
      "4   298.072424  293.500607  299.903104  293.500607  296.615372  293.500607   \n",
      "5   301.401948  298.930917  300.714683  298.930917  294.785980  298.930917   \n",
      "6   291.672619  289.957928  291.788015  289.957928  285.872455  289.957928   \n",
      "7   269.341662  273.073968  269.572013  273.073968  271.669642  273.073968   \n",
      "8   291.803572  289.026459  288.668454  289.026459  282.672846  289.026459   \n",
      "9   258.259455  255.913721  255.439341  255.913721  255.976937  255.913721   \n",
      "10  278.551022  281.996051  281.029925  281.996051  289.535263  281.996051   \n",
      "11  256.151738  257.167663  252.945792  257.167664  264.788247  257.167664   \n",
      "12  295.186828  297.233446  298.436136  297.233446  301.105487  297.233446   \n",
      "13  278.898077  276.092416  278.517826  276.092416  274.536813  276.092416   \n",
      "14  276.126061  270.733097  271.699824  270.733097  268.070512  270.733097   \n",
      "\n",
      "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
      "0   254.087872  252.716034  254.356465  254.356465  \n",
      "1   252.054546  246.842220  251.010920  251.010920  \n",
      "2   285.767294  287.835884  291.630992  291.630992  \n",
      "3   292.681865  290.851589  288.907838  288.907838  \n",
      "4   290.943971  295.944768  293.500607  293.500607  \n",
      "5   299.484772  298.727945  298.930917  298.930917  \n",
      "6   290.444897  292.664979  289.957928  289.957928  \n",
      "7   273.459253  273.376911  273.073968  273.073968  \n",
      "8   287.717318  286.983188  289.026459  289.026459  \n",
      "9   255.911150  251.612160  255.913721  255.913721  \n",
      "10  285.332026  287.403702  281.996051  281.996051  \n",
      "11  262.220107  256.201799  257.167664  257.167664  \n",
      "12  295.272601  298.475322  297.233446  297.233446  \n",
      "13  276.925605  274.583612  276.092416  276.092416  \n",
      "14  266.551512  268.201901  270.733097  270.733097  \n",
      "testing_df: \n",
      "           X1   X2         X3\n",
      "0   16.322778  1.0  66.706379\n",
      "1   18.871168  1.0  62.103826\n",
      "2   17.280752  1.0  61.289263\n",
      "3   17.842170  1.0  63.154284\n",
      "4   15.093949  1.0  63.637108\n",
      "5   18.088177  1.0  65.701968\n",
      "6   18.060479  1.0  64.386015\n",
      "7   18.084670  1.0  69.883738\n",
      "8   19.718740  1.0  61.020448\n",
      "9   18.409101  1.0  62.088768\n",
      "10  16.797540  1.0  61.613095\n",
      "11  17.185160  1.0  66.531083\n",
      "12  18.488156  1.0  62.532916\n",
      "13  15.301127  1.0  64.663108\n",
      "14  18.333834  1.0  62.444256\n",
      "demand_df_test: \n",
      "    demand_t1  demand_t2  demand_t3  demand_t4  demand_t5  demand_t6  \\\n",
      "0   69.049446  66.984864  65.276090  66.706379  64.399509  66.706379   \n",
      "1   62.472855  61.379065  62.263812  62.103826  59.547465  62.103826   \n",
      "2   57.026718  60.339037  58.994137  61.289263  61.559450  61.289263   \n",
      "3   62.944633  65.536993  64.153686  63.154284  59.520451  63.154284   \n",
      "4   66.458142  64.430325  65.691033  63.637108  58.415305  63.637108   \n",
      "5   65.340264  66.665934  65.624076  65.701968  65.763430  65.701968   \n",
      "6   60.459442  64.184997  61.973620  64.386015  65.111260  64.386015   \n",
      "7   71.557122  70.563024  74.662817  69.883738  69.277905  69.883738   \n",
      "8   63.840751  62.306341  66.968545  61.020448  59.275984  61.020448   \n",
      "9   62.969099  64.263725  64.029270  62.088768  60.721711  62.088768   \n",
      "10  60.057707  60.871552  60.104051  61.613095  62.302393  61.613095   \n",
      "11  68.193840  67.527301  72.362407  66.531083  64.621767  66.531083   \n",
      "12  55.740736  63.143807  63.924512  62.532916  65.056794  62.532916   \n",
      "13  67.989985  63.983761  64.570792  64.663108  66.958315  64.663108   \n",
      "14  58.797450  62.278203  63.120200  62.444256  58.121198  62.444256   \n",
      "\n",
      "    demand_t7  demand_t8  demand_t9  demand_t10  \n",
      "0   71.005184  64.088969  66.706381   66.706379  \n",
      "1   63.271804  55.331312  62.103825   62.103826  \n",
      "2   63.232738  60.581985  61.289264   61.289263  \n",
      "3   62.573906  68.894022  63.154284   63.154283  \n",
      "4   62.211406  62.929656  63.637111   63.637108  \n",
      "5   62.072328  64.226544  65.701970   65.701968  \n",
      "6   66.214844  63.597722  64.386018   64.386015  \n",
      "7   68.924536  69.361419  69.883738   69.883738  \n",
      "8   59.005480  60.829499  61.020442   61.020448  \n",
      "9   60.879685  62.634618  62.088772   62.088768  \n",
      "10  61.283812  63.885645  61.613092   61.613095  \n",
      "11  65.714526  66.642278  66.531082   66.531083  \n",
      "12  56.151613  66.725960  62.532920   62.532916  \n",
      "13  65.885875  61.730881  64.663100   64.663108  \n",
      "14  57.806186  61.151295  62.444260   62.444256  \n",
      "===== Processing Fold 2 =====\n",
      "training_df: \n",
      "           X1   X2          X3\n",
      "0   15.794848  0.0  251.959390\n",
      "1   15.551876  0.0  264.140348\n",
      "2   18.281648  0.0  256.009828\n",
      "3   15.690915  0.0  264.807010\n",
      "4   15.982912  0.0  255.936386\n",
      "5   16.843626  0.0  265.899159\n",
      "6   19.104966  0.0  270.713150\n",
      "7   15.485506  0.0  253.207375\n",
      "8   19.189725  0.0  284.623606\n",
      "9   15.480492  0.0  278.330073\n",
      "10  19.882297  0.0  263.269475\n",
      "11  17.343256  0.0  276.162403\n",
      "12  19.883805  0.0  254.697026\n",
      "13  18.024228  0.0  278.797325\n",
      "14  18.696318  0.0  296.464810\n",
      "demand_df_train: \n",
      "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
      "0   256.519623  251.959390  252.619473  251.959390  246.815799  251.959390   \n",
      "1   266.557046  264.140348  264.160430  264.140348  262.456134  264.140348   \n",
      "2   255.104623  256.009829  259.397400  256.009828  253.201453  256.009828   \n",
      "3   258.328805  264.807010  266.027383  264.807010  264.784493  264.807010   \n",
      "4   253.416118  255.936386  254.214539  255.936386  256.695107  255.936386   \n",
      "5   263.215996  265.899159  268.949097  265.899159  263.130433  265.899159   \n",
      "6   267.820993  270.713150  268.501904  270.713150  272.402984  270.713150   \n",
      "7   250.255196  253.207375  252.917631  253.207375  253.511599  253.207375   \n",
      "8   291.872275  284.623606  289.498687  284.623606  279.906507  284.623606   \n",
      "9   276.428735  278.330073  277.122965  278.330073  276.905217  278.330073   \n",
      "10  261.244738  263.269475  267.407733  263.269475  263.036084  263.269475   \n",
      "11  281.624515  276.162403  277.291903  276.162403  272.064668  276.162403   \n",
      "12  256.640801  254.697025  253.216210  254.697026  257.734949  254.697026   \n",
      "13  276.596581  278.797325  282.033169  278.797325  278.763871  278.797325   \n",
      "14  297.215013  296.464810  297.943972  296.464810  296.618148  296.464810   \n",
      "\n",
      "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
      "0   252.404141  247.642667  251.959390  251.959390  \n",
      "1   268.037060  263.302797  264.140348  264.140348  \n",
      "2   254.294350  257.262525  256.009828  256.009828  \n",
      "3   265.545294  267.617149  264.807010  264.807010  \n",
      "4   259.314176  259.850532  255.936386  255.936386  \n",
      "5   261.011138  267.280099  265.899159  265.899159  \n",
      "6   270.361907  270.006558  270.713150  270.713150  \n",
      "7   251.010061  255.083055  253.207375  253.207375  \n",
      "8   286.218363  285.561041  284.623606  284.623606  \n",
      "9   280.820443  281.184906  278.330073  278.330073  \n",
      "10  260.086461  263.477115  263.269475  263.269475  \n",
      "11  274.337136  273.932259  276.162403  276.162403  \n",
      "12  260.510507  256.621323  254.697026  254.697026  \n",
      "13  274.790903  280.071033  278.797325  278.797325  \n",
      "14  293.376616  299.036274  296.464810  296.464810  \n",
      "testing_df: \n",
      "           X1   X2         X3\n",
      "0   16.592845  1.0  65.761573\n",
      "1   18.337052  1.0  65.920419\n",
      "2   15.658989  1.0  65.722519\n",
      "3   18.581636  1.0  62.230816\n",
      "4   16.447030  1.0  69.527490\n",
      "5   15.915957  1.0  64.471254\n",
      "6   17.932565  1.0  68.464087\n",
      "7   15.100538  1.0  66.994793\n",
      "8   19.144700  1.0  62.974370\n",
      "9   15.023477  1.0  68.137978\n",
      "10  18.389083  1.0  63.965057\n",
      "11  16.350040  1.0  68.811032\n",
      "12  18.675970  1.0  65.812729\n",
      "13  19.810943  1.0  68.817354\n",
      "14  16.243766  1.0  66.925316\n",
      "demand_df_test: \n",
      "    demand_t1  demand_t2  demand_t3  demand_t4  demand_t5  demand_t6  \\\n",
      "0   68.370121  64.894454  67.199076  65.761573  63.053747  65.761573   \n",
      "1   66.587610  64.979976  69.411094  65.920419  65.768066  65.920419   \n",
      "2   70.933664  66.187890  69.618863  65.722519  60.188051  65.722519   \n",
      "3   63.476652  63.427189  58.172863  62.230816  63.207280  62.230816   \n",
      "4   72.298368  69.469709  69.557802  69.527490  69.049027  69.527490   \n",
      "5   61.418697  64.596306  63.090749  64.471254  64.412447  64.471254   \n",
      "6   68.349991  68.233833  65.527941  68.464087  66.683151  68.464087   \n",
      "7   69.173899  67.791676  68.980601  66.994793  66.269833  66.994793   \n",
      "8   65.242553  65.421038  68.671875  62.974370  57.570268  62.974370   \n",
      "9   67.587048  68.232925  69.938504  68.137978  72.345359  68.137978   \n",
      "10  61.458167  62.971443  63.673554  63.965057  63.243366  63.965057   \n",
      "11  62.593521  68.252412  63.791590  68.811032  69.928345  68.811032   \n",
      "12  64.041609  65.899146  66.197404  65.812729  69.316660  65.812729   \n",
      "13  74.367057  70.734412  75.902168  68.817354  67.054075  68.817354   \n",
      "14  66.151275  66.585163  64.513272  66.925316  65.898617  66.925316   \n",
      "\n",
      "    demand_t7  demand_t8  demand_t9  demand_t10  \n",
      "0   63.984974  62.127812  65.761570   65.761573  \n",
      "1   64.382597  68.059276  65.920415   65.920419  \n",
      "2   61.025759  66.547948  65.722519   65.722519  \n",
      "3   66.306121  62.062609  62.230823   62.230816  \n",
      "4   62.861684  67.820569  69.527490   69.527490  \n",
      "5   63.799314  63.693119  64.471254   64.471254  \n",
      "6   76.051808  69.090667  68.464087   68.464087  \n",
      "7   68.198098  71.791799  66.994793   66.994793  \n",
      "8   58.224097  57.855352  62.974371   62.974369  \n",
      "9   66.220593  70.069887  68.137978   68.137978  \n",
      "10  63.568947  62.804834  63.965054   63.965057  \n",
      "11  73.798658  71.999444  68.811034   68.811032  \n",
      "12  62.910571  70.182959  65.812727   65.812729  \n",
      "13  65.788339  68.993258  68.817352   68.817354  \n",
      "14  69.469320  67.743843  66.925316   66.925316  \n",
      "===== Processing Fold 3 =====\n",
      "training_df: \n",
      "           X1   X2          X3\n",
      "0   18.626271  0.0  279.543638\n",
      "1   17.506622  0.0  278.716262\n",
      "2   19.780418  0.0  282.660041\n",
      "3   18.219951  0.0  282.605164\n",
      "4   17.119275  0.0  271.570922\n",
      "5   18.031966  0.0  294.827330\n",
      "6   15.095966  0.0  268.378094\n",
      "7   16.507874  0.0  271.793246\n",
      "8   18.300868  0.0  294.596168\n",
      "9   16.450388  0.0  290.309699\n",
      "10  18.090077  0.0  285.194429\n",
      "11  17.143844  0.0  255.011344\n",
      "12  15.677370  0.0  295.974131\n",
      "13  16.491412  0.0  285.712065\n",
      "14  17.849825  0.0  299.942350\n",
      "demand_df_train: \n",
      "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
      "0   283.936601  279.543638  285.077369  279.543638  276.931626  279.543638   \n",
      "1   280.752154  278.716263  284.554707  278.716262  277.019908  278.716262   \n",
      "2   280.810270  282.660041  281.793406  282.660041  283.966752  282.660041   \n",
      "3   282.690695  282.605164  284.501807  282.605163  280.263205  282.605164   \n",
      "4   269.794746  271.570922  270.571046  271.570922  268.258034  271.570922   \n",
      "5   292.141287  294.827330  296.363870  294.827330  297.636415  294.827330   \n",
      "6   268.295270  268.378094  272.289189  268.378094  267.061530  268.378094   \n",
      "7   274.284449  271.793246  275.891790  271.793246  271.007436  271.793246   \n",
      "8   295.561676  294.596168  295.346168  294.596168  293.901419  294.596168   \n",
      "9   291.572767  290.309699  289.337801  290.309699  287.979840  290.309699   \n",
      "10  289.359045  285.194429  290.753028  285.194429  285.165963  285.194429   \n",
      "11  259.085891  255.011345  255.041535  255.011344  252.753361  255.011344   \n",
      "12  294.703610  295.974131  298.873793  295.974131  294.749160  295.974131   \n",
      "13  288.208942  285.712065  285.303854  285.712065  283.167061  285.712065   \n",
      "14  297.971527  299.942350  303.764967  299.942350  296.928688  299.942350   \n",
      "\n",
      "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
      "0   279.497137  277.402834  279.543638  279.543638  \n",
      "1   272.022711  278.462176  278.716262  278.716262  \n",
      "2   284.073037  284.669504  282.660041  282.660041  \n",
      "3   280.973891  281.791857  282.605164  282.605164  \n",
      "4   273.396903  267.461509  271.570922  271.570922  \n",
      "5   290.725323  299.869873  294.827330  294.827330  \n",
      "6   264.194145  269.637850  268.378094  268.378094  \n",
      "7   271.264363  278.902212  271.793246  271.793246  \n",
      "8   293.952546  289.434761  294.596168  294.596168  \n",
      "9   296.220290  291.572601  290.309699  290.309699  \n",
      "10  280.959832  286.639870  285.194429  285.194429  \n",
      "11  255.233465  254.206041  255.011344  255.011344  \n",
      "12  295.417869  296.365897  295.974131  295.974131  \n",
      "13  283.449034  289.498190  285.712065  285.712065  \n",
      "14  293.866069  299.198634  299.942350  299.942350  \n",
      "testing_df: \n",
      "           X1   X2         X3\n",
      "0   15.747242  1.0  68.558033\n",
      "1   19.340630  1.0  60.117141\n",
      "2   15.812465  1.0  63.599781\n",
      "3   18.077798  1.0  67.299906\n",
      "4   15.619100  1.0  61.716297\n",
      "5   19.240041  1.0  65.210366\n",
      "6   19.036595  1.0  60.543380\n",
      "7   17.845504  1.0  61.999965\n",
      "8   17.035916  1.0  60.185218\n",
      "9   15.345835  1.0  67.936977\n",
      "10  18.487144  1.0  62.239247\n",
      "11  17.267713  1.0  63.453517\n",
      "12  18.610278  1.0  69.280813\n",
      "13  19.331912  1.0  67.044144\n",
      "14  19.877608  1.0  60.318389\n",
      "demand_df_test: \n",
      "    demand_t1  demand_t2  demand_t3  demand_t4  demand_t5  demand_t6  \\\n",
      "0   65.625929  67.884966  68.750730  68.558033  74.175914  68.558033   \n",
      "1   60.770111  61.058111  59.574148  60.117141  58.717761  60.117141   \n",
      "2   66.073532  64.930685  65.683239  63.599781  63.459309  63.599781   \n",
      "3   63.121389  66.381203  61.668540  67.299906  67.404706  67.299906   \n",
      "4   64.915095  62.604395  65.471782  61.716297  63.127936  61.716297   \n",
      "5   63.427651  63.458016  59.857699  65.210366  66.962546  65.210366   \n",
      "6   60.438469  59.245399  60.450320  60.543380  56.855468  60.543380   \n",
      "7   62.564427  62.207089  62.998637  61.999965  61.345170  61.999965   \n",
      "8   60.300860  59.014437  58.383848  60.185218  60.029247  60.185218   \n",
      "9   66.947411  67.567002  67.449213  67.936977  72.133012  67.936977   \n",
      "10  65.746933  65.853934  70.574162  62.239247  55.130102  62.239247   \n",
      "11  61.329502  63.260741  60.017189  63.453517  66.141381  63.453517   \n",
      "12  66.822772  69.549069  66.237491  69.280813  70.547457  69.280813   \n",
      "13  62.577572  67.210049  65.172995  67.044144  70.357863  67.044144   \n",
      "14  59.277409  59.472203  62.933669  60.318389  57.697020  60.318389   \n",
      "\n",
      "    demand_t7  demand_t8  demand_t9  demand_t10  \n",
      "0   65.559446  71.308420  68.558033   68.558033  \n",
      "1   57.979551  58.390955  60.117144   60.117141  \n",
      "2   64.215938  63.806809  63.599781   63.599781  \n",
      "3   70.525694  68.097560  67.299908   67.299906  \n",
      "4   61.250627  60.709187  61.716291   61.716297  \n",
      "5   68.788190  65.421392  65.210367   65.210366  \n",
      "6   59.175878  58.100125  60.543382   60.543380  \n",
      "7   64.147963  63.211996  61.999964   61.999965  \n",
      "8   62.275329  58.171283  60.185214   60.185218  \n",
      "9   64.609175  66.191955  67.936978   67.936977  \n",
      "10  57.888206  63.679955  62.239243   62.239247  \n",
      "11  65.584679  64.101433  63.453519   63.453517  \n",
      "12  70.842404  73.111604  69.280814   69.280813  \n",
      "13  68.535449  70.440907  67.044145   67.044144  \n",
      "14  59.467526  57.168997  60.318390   60.318390  \n"
     ]
    }
   ],
   "source": [
    "for fold_idx in range(len(training_data_folds)):\n",
    "    print(f\"===== Processing Fold {fold_idx + 1} =====\")\n",
    "    # 取出該 fold 的訓練資料與需求資料\n",
    "    training_df, testing_df = training_data_folds[fold_idx]\n",
    "    demand_df_train, demand_df_test = demand_folds[fold_idx]\n",
    "\n",
    "    print(f\"training_df: \\n{training_df}\")\n",
    "    print(f\"demand_df_train: \\n{demand_df_train}\")\n",
    "    print(f\"testing_df: \\n{testing_df}\")\n",
    "    print(f\"demand_df_test: \\n{demand_df_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Processing Fold 1 =====\n",
      "mean of sum: 2779.8596331748327\n",
      "std of sum: 169.30737789635148\n",
      "60.0 percentile of sum: 2822.7531669043915\n",
      "Fold 1 Q_star: 2822.7531669043915\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=0 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0xa1a45b52\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [3e+02, 3e+03]\n",
      "Presolve removed 67 rows and 106 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 226 rows, 158 columns, 596 nonzeros\n",
      "Presolved model has 37 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 121 continuous, 37 integer (37 binary)\n",
      "\n",
      "Root relaxation: objective 2.488797e+07, 85 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.4888e+07    0   20          - 2.4888e+07      -     -    0s\n",
      "H    0     0                    2.476668e+07 2.4888e+07  0.49%     -    0s\n",
      "\n",
      "Explored 1 nodes (85 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.47667e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.476667621138e+07, best bound 2.488797086334e+07, gap 0.4897%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 5.564336473899402, Left0: 1159.5825673712181, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1160.3197998221744, Left1: 23.760693792225993\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1113.8483348291797, Left1: 53.181889321544986\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 9.875853938779528, Left0: 1122.30968934702, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1113.3041594698097, Left1: 16.377072023945175\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1109.974635658498, Left1: 6.6183828149018495\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1119.7039643040362, Left1: 3.4859851168245086\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 25.177724302188835, Left0: 1142.034921755577, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1119.5730109608608, Left1: 23.96129995241847\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1153.11712820828, Left1: 37.56648328068286\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 48.39658474516273, Left0: 1132.8255611372374, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.454145403235998, Left0: 1155.2248459379507, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 36.17534411758777, Left0: 1116.1897553744734, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1132.4785067945745, Left1: 22.745868728340156\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1135.2505226863407, Left1: 56.52157602011266\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=1 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0x476fe42d\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [5e+02, 2e+03]\n",
      "Presolve removed 66 rows and 101 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 227 rows, 163 columns, 603 nonzeros\n",
      "Presolved model has 40 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 123 continuous, 40 integer (40 binary)\n",
      "\n",
      "Root relaxation: objective 2.498602e+07, 80 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.4986e+07    0   22          - 2.4986e+07      -     -    0s\n",
      "H    0     0                    2.496418e+07 2.4986e+07  0.09%     -    0s\n",
      "\n",
      "Explored 1 nodes (80 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.49642e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.496418333370e+07, best bound 2.498601683110e+07, gap 0.0875%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 905.2261032640715, Left1: 4.302685597263462\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 909.3088807413448, Left1: 5.472220752648809\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 822.2173425060043, Left1: 10.672825485723024\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 833.4018517860536, Left1: 1.39699497511333\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 11.687306927434292, Left0: 819.8035520246931, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 811.0437185347139, Left1: 3.444716451027034\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 829.7460360471362, Left1: 0.43081525038223845\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 868.960953619797, Left1: 11.249126627081296\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 830.5465521921219, Left1: 9.786737602076528\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 897.2034073005101, Left1: 0.8063302783602921\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 7.552962579032737, Left0: 850.8295102629437, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 6.401172858177688, Left0: 898.0571826600205, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 818.9563095260683, Left1: 3.354412452252973\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 2.1732735539844725, Left0: 856.3860907020392, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 864.517425727407, Left1: 2.0223989622195404\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=2 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0xa54db082\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [8e+02, 2e+03]\n",
      "Presolve removed 60 rows and 91 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 233 rows, 173 columns, 619 nonzeros\n",
      "Presolved model has 44 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 129 continuous, 44 integer (44 binary)\n",
      "\n",
      "Root relaxation: objective 2.499646e+07, 87 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.4996e+07    0   24          - 2.4996e+07      -     -    0s\n",
      "H    0     0                    2.497793e+07 2.4996e+07  0.07%     -    0s\n",
      "\n",
      "Explored 1 nodes (87 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.49779e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.497793082074e+07, best bound 2.499646261769e+07, gap 0.0742%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 1.476113014911789, Left0: 657.4845676466084, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 661.1167381092084, Left1: 7.354089155754082\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 527.9668781654559, Left1: 6.12115003931126\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 2.1150548445386903, Left0: 545.0463440792619, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.879255108934899, Left0: 519.9004479532431, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.21697727737409878, Left0: 510.32903549266507, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 537.9580212258243, Left1: 0.8868056303670073\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 599.3889407625729, Left1: 10.473558427818261\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 541.8780982793046, Left1: 2.57066278415914\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 641.7640659048361, Left1: 4.159975133068656\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.303450596604307, Left0: 569.7995848866215, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 8.709682201584883, Left0: 645.1113905326058, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 520.5201732408443, Left1: 5.842907600725994\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 577.8682642088975, Left1: 2.4963418012598595\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 592.8176016323464, Left1: 0.0076048891141908825\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=3 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0xe9e53f69\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 2e+03]\n",
      "Presolve removed 56 rows and 72 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 237 rows, 192 columns, 635 nonzeros\n",
      "Presolved model has 59 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 133 continuous, 59 integer (59 binary)\n",
      "\n",
      "Root relaxation: objective 2.499646e+07, 96 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.4996e+07    0   26          - 2.4996e+07      -     -    0s\n",
      "H    0     0                    2.497793e+07 2.4996e+07  0.07%     -    0s\n",
      "\n",
      "Explored 1 nodes (96 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.49779e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.497793082625e+07, best bound 2.499646262005e+07, gap 0.0742%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 1.4761125007100873, Left0: 403.12810265364556, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 410.1058182234974, Left1: 7.35408941647438\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 236.3358859092407, Left1: 6.121149948623497\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 2.115055277489091, Left0: 256.1385065358834, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.879254585053104, Left0: 226.3998405345344, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.21697672108075494, Left0: 211.39811838456694, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 248.00009301150703, Left1: 0.8868053879048148\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 326.3149726404886, Left1: 10.473556520839793\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 252.8516394537478, Left1: 2.570662756265847\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 385.85034461187047, Left1: 4.159974101592979\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.303450648993021, Left0: 287.8035338099992, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 8.70968038076171, Left0: 387.94372617552585, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 223.2867273916172, Left1: 5.842907979584652\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 301.77584811314523, Left1: 2.4963408004773555\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 322.0845046384377, Left1: 0.007603554817706026\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1411.3766\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1411.3765834521957\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=4 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0x9d32845a\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 1e+03]\n",
      "Presolve removed 56 rows and 72 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 237 rows, 192 columns, 635 nonzeros\n",
      "Presolved model has 59 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 133 continuous, 59 integer (59 binary)\n",
      "\n",
      "Root relaxation: objective 2.500297e+07, 98 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5003e+07    0   26          - 2.5003e+07      -     -    0s\n",
      "H    0     0                    2.440439e+07 2.5003e+07  2.45%     -    0s\n",
      "     0     2 2.5003e+07    0   28 2.4404e+07 2.5003e+07  2.45%     -    0s\n",
      "H   67    46                    2.499668e+07 2.4997e+07  0.00%   8.1    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Cover: 1\n",
      "  Implied bound: 8\n",
      "\n",
      "Explored 90 nodes (767 simplex iterations) in 0.03 seconds (0.03 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 2.49967e+07 2.44044e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.499667796090e+07, best bound 2.499713487456e+07, gap 0.0018%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1273.4564729184842, Left1: 3.5831722201371576\n",
      "f_vars[i]: 2.2081, F_vars[i]: 0.9010, Q0_vars[i]: 2543.2288\n",
      "f_train: 2.2081003584967025, F_train: 0.9009745710098171, Q0_train: 2543.2288236182867\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1249.7148870964752, Left1: 1.5039689853688287\n",
      "f_vars[i]: 2.0515, F_vars[i]: 0.8861, Q0_vars[i]: 2501.2356\n",
      "f_train: 2.0514877896940806, F_train: 0.8860978652895151, Q0_train: 2501.2355554331994\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1322.4073365114957, Left1: 4.695972773454059\n",
      "f_vars[i]: 4.1992, F_vars[i]: 0.9852, Q0_vars[i]: 2781.0178\n",
      "f_train: 4.19922222376303, F_train: 0.9852146429091334, Q0_train: 2781.0177533523356\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.591316957642675, Left0: 1333.209604851686, Left1: 0.0\n",
      "f_vars[i]: 4.0468, F_vars[i]: 0.9828, Q0_vars[i]: 2774.2638\n",
      "f_train: 4.046795557603144, F_train: 0.9828219498159371, Q0_train: 2774.2637713460854\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1302.453520541058, Left1: 0.9354141000890195\n",
      "f_vars[i]: 4.2756, F_vars[i]: 0.9863, Q0_vars[i]: 2784.0456\n",
      "f_train: 4.275626233403964, F_train: 0.9862873128844136, Q0_train: 2784.045635922101\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.4356465371465674, Left0: 1299.7122770511435, Left1: 0.0\n",
      "f_vars[i]: 4.5934, F_vars[i]: 0.9900, Q0_vars[i]: 2794.4767\n",
      "f_train: 4.59337102410395, F_train: 0.9899826717777305, Q0_train: 2794.4767219410596\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 2.952571835949584, Left0: 1326.9785620284413, Left1: 0.0\n",
      "f_vars[i]: 4.0888, F_vars[i]: 0.9835, Q0_vars[i]: 2776.2275\n",
      "f_train: 4.088844288100001, F_train: 0.9835176308020639, Q0_train: 2776.22750705283\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1360.5270455356203, Left1: 2.9539123810645833\n",
      "f_vars[i]: 3.2487, F_vars[i]: 0.9626, Q0_vars[i]: 2717.2583\n",
      "f_train: 3.2487163625784756, F_train: 0.9626269595497963, Q0_train: 2717.258298616733\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1335.8605043913678, Left1: 0.8581076172540634\n",
      "f_vars[i]: 4.1072, F_vars[i]: 0.9838, Q0_vars[i]: 2777.0583\n",
      "f_train: 4.107161389825302, F_train: 0.9838119489564741, Q0_train: 2777.0582945552687\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1276.848613702851, Left1: 1.5841401060731641\n",
      "f_vars[i]: 2.2697, F_vars[i]: 0.9063, Q0_vars[i]: 2558.3518\n",
      "f_train: 2.2696501798983455, F_train: 0.9063320942754172, Q0_train: 2558.3517893830235\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.7518734516529548, Left0: 1342.2500084339522, Left1: 0.0\n",
      "f_vars[i]: 3.7107, F_vars[i]: 0.9761, Q0_vars[i]: 2755.3583\n",
      "f_train: 3.710734237256995, F_train: 0.9761244283602997, Q0_train: 2755.358321446775\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1289.9248992403645, Left1: 0.0\n",
      "f_vars[i]: 2.3552, F_vars[i]: 0.9133, Q0_vars[i]: 2578.1460\n",
      "f_train: 2.3551723062813554, F_train: 0.9133444728731404, Q0_train: 2578.146003277279\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1302.3278714305934, Left1: 7.213818778245468\n",
      "f_vars[i]: 4.4930, F_vars[i]: 0.9889, Q0_vars[i]: 2791.5232\n",
      "f_train: 4.492965038899486, F_train: 0.9889363502956162, Q0_train: 2791.5232146638214\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.3797734929269154, Left0: 1348.6593139799234, Left1: 0.0\n",
      "f_vars[i]: 3.4138, F_vars[i]: 0.9681, Q0_vars[i]: 2732.7969\n",
      "f_train: 3.4137568112030845, F_train: 0.9681317143393448, Q0_train: 2732.796862631963\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1333.8181405312314, Left1: 1.4818232456436817\n",
      "f_vars[i]: 3.0182, F_vars[i]: 0.9534, Q0_vars[i]: 2691.1807\n",
      "f_train: 3.0181777725645134, F_train: 0.9533886148193296, Q0_train: 2691.1807317718535\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=5 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0x213047c9\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 2e+03]\n",
      "Presolve removed 56 rows and 73 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 237 rows, 191 columns, 635 nonzeros\n",
      "Presolved model has 58 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 133 continuous, 58 integer (58 binary)\n",
      "\n",
      "Root relaxation: objective 2.500297e+07, 97 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5003e+07    0   25          - 2.5003e+07      -     -    0s\n",
      "H    0     0                    1.884295e+07 2.5003e+07  32.7%     -    0s\n",
      "     0     2 2.5003e+07    0   24 1.8843e+07 2.5003e+07  32.7%     -    0s\n",
      "H    9     8                    2.215039e+07 2.5000e+07  12.9%   2.3    0s\n",
      "H   93    92                    2.482025e+07 2.4997e+07  0.71%   3.6    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 8\n",
      "\n",
      "Explored 117 nodes (625 simplex iterations) in 0.03 seconds (0.03 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 3: 2.48203e+07 2.21504e+07 1.88429e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.482025138395e+07, best bound 2.499739384674e+07, gap 0.7137%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1.675655941160141, Left1: 3.5831720840326398\n",
      "f_vars[i]: 0.1625, F_vars[i]: 0.5405, Q0_vars[i]: 1525.8045\n",
      "f_train: 0.16250744524878646, F_train: 0.5405376883517355, Q0_train: 1525.8044716260406\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1.1449189121076315, Left1: 1.5039693350270227\n",
      "f_vars[i]: 0.1310, F_vars[i]: 0.5327, Q0_vars[i]: 1503.6765\n",
      "f_train: 0.13098112237242754, F_train: 0.5326985457853114, Q0_train: 1503.6765071208517\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 11.487563529229647, Lost1: 0.0, Left0: 0.0, Left1: 16.183536389836583\n",
      "f_vars[i]: 0.4725, F_vars[i]: 0.6160, Q0_vars[i]: 1738.7538\n",
      "f_train: 0.4725113990261218, F_train: 0.615977998351105, Q0_train: 1738.7538455890096\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 5.58693911973387, Lost1: 0.0, Left0: 0.0, Left1: 0.9956221363238976\n",
      "f_vars[i]: 0.4510, F_vars[i]: 0.6109, Q0_vars[i]: 1724.3749\n",
      "f_train: 0.45102981988912205, F_train: 0.6108840549387865, Q0_train: 1724.3749006898558\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 23.36005474831677, Lost1: 0.0, Left0: 0.0, Left1: 24.295468845721945\n",
      "f_vars[i]: 0.4920, F_vars[i]: 0.6206, Q0_vars[i]: 1751.7316\n",
      "f_train: 0.49199186373393555, F_train: 0.6205755521512637, Q0_train: 1751.731605138421\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 15.161967937318423, Lost1: 0.0, Left0: 0.0, Left1: 14.726321550381297\n",
      "f_vars[i]: 0.5325, F_vars[i]: 0.6301, Q0_vars[i]: 1778.5334\n",
      "f_train: 0.5325191110737251, F_train: 0.6300704627371605, Q0_train: 1778.5333940642352\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 7.401687176284138, Lost1: 0.0, Left0: 0.0, Left1: 4.449115449725166\n",
      "f_vars[i]: 0.4621, F_vars[i]: 0.6135, Q0_vars[i]: 1731.8044\n",
      "f_train: 0.46211606405222927, F_train: 0.6135160451437721, Q0_train: 1731.8043593762404\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.47259032513420607, Lost1: 0.0, Left0: 0.0, Left1: 3.426502476066844\n",
      "f_vars[i]: 0.3113, F_vars[i]: 0.5772, Q0_vars[i]: 1629.3326\n",
      "f_train: 0.31134688170049607, F_train: 0.5772139855860764, Q0_train: 1629.3326057946028\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 11.26371259048344, Lost1: 0.0, Left0: 0.0, Left1: 12.121820207070844\n",
      "f_vars[i]: 0.4430, F_vars[i]: 0.6090, Q0_vars[i]: 1718.9587\n",
      "f_train: 0.44296500512162584, F_train: 0.6089653048909468, Q0_train: 1718.9587429158184\n",
      "f_train, F_train, Q0_train 不相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 1.584140004002279\n",
      "f_vars[i]: 0.1791, F_vars[i]: 0.5447, Q0_vars[i]: 1537.4169\n",
      "f_train: 0.17908329571411885, F_train: 0.5446515533129832, Q0_train: 1537.4168969736193\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 13.308479469113081, Lost1: 0.0, Left0: 0.0, Left1: 11.556605874232543\n",
      "f_vars[i]: 0.3880, F_vars[i]: 0.5958, Q0_vars[i]: 1681.7944\n",
      "f_train: 0.3879923743206466, F_train: 0.5957993110096848, Q0_train: 1681.7943919920422\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.8470709792941307, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 0.1864, F_vars[i]: 0.5465, Q0_vars[i]: 1542.5417\n",
      "f_train: 0.18640623398617073, F_train: 0.546467085933595, Q0_train: 1542.5416974280697\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 16.124455445854593, Lost1: 0.0, Left0: 0.0, Left1: 23.338274277267075\n",
      "f_vars[i]: 0.5200, F_vars[i]: 0.6272, Q0_vars[i]: 1770.3043\n",
      "f_train: 0.5200318007981077, F_train: 0.6271552023733199, Q0_train: 1770.3043336398532\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 14.075662626078067, Lost1: 0.0, Left0: 0.0, Left1: 13.695889027263547\n",
      "f_vars[i]: 0.3358, F_vars[i]: 0.5832, Q0_vars[i]: 1646.1542\n",
      "f_train: 0.3358137540788335, F_train: 0.583173276716081, Q0_train: 1646.1542137043286\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 1.4818228512135647\n",
      "f_vars[i]: 0.3096, F_vars[i]: 0.5768, Q0_vars[i]: 1628.0957\n",
      "f_train: 0.30955152684861886, F_train: 0.5767757901501639, Q0_train: 1628.0956882401579\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=6 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0x2bdf8ff6\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [7e+02, 2e+03]\n",
      "Presolve removed 60 rows and 98 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 233 rows, 166 columns, 619 nonzeros\n",
      "Presolved model has 37 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 129 continuous, 37 integer (37 binary)\n",
      "\n",
      "Root relaxation: objective 2.501242e+07, 84 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5012e+07    0   20          - 2.5012e+07      -     -    0s\n",
      "H    0     0                    1.217565e+07 2.5012e+07   105%     -    0s\n",
      "     0     2 2.5012e+07    0   20 1.2176e+07 2.5012e+07   105%     -    0s\n",
      "H   64    76                    2.479122e+07 2.5010e+07  0.88%   4.9    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Cover: 1\n",
      "  Implied bound: 1\n",
      "\n",
      "Explored 87 nodes (463 simplex iterations) in 0.03 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 2.47912e+07 1.21757e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.479122397620e+07, best bound 2.501022570907e+07, gap 0.8834%\n",
      "Model status: 2\n",
      "Lost0: 14.209587073226203, Lost1: 0.0, Left0: 0.0, Left1: 13.976539407804466\n",
      "f_vars[i]: 0.5105, F_vars[i]: 0.6249, Q0_vars[i]: 1764.0066\n",
      "f_train: 0.5105019461630644, F_train: 0.624924134993001, Q0_train: 1764.006581126481\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 18.552708866471676, Lost1: 0.0, Left0: 0.0, Left1: 19.494458856846677\n",
      "f_vars[i]: 0.4684, F_vars[i]: 0.6150, Q0_vars[i]: 1736.0329\n",
      "f_train: 0.4684383480033749, F_train: 0.6150140677684764, Q0_train: 1736.0329074842189\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 0.7917310883983646\n",
      "f_vars[i]: 0.9508, F_vars[i]: 0.7213, Q0_vars[i]: 2036.0082\n",
      "f_train: 0.9508422533266385, F_train: 0.7212845304212585, Q0_train: 2036.0081924857543\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 4.559134472093547, Lost1: 0.0, Left0: 0.0, Left1: 4.340233343308749\n",
      "f_vars[i]: 0.9195, F_vars[i]: 0.7149, Q0_vars[i]: 2018.0842\n",
      "f_train: 0.9194729910212169, F_train: 0.7149347118206396, Q0_train: 2018.084221921589\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 16.040717497612015, Lost1: 0.0, Left0: 0.0, Left1: 15.67727161053458\n",
      "f_vars[i]: 0.9756, F_vars[i]: 0.7262, Q0_vars[i]: 2049.9955\n",
      "f_train: 0.9756273173090464, F_train: 0.7262397194205501, Q0_train: 2049.9954679261145\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 9.44386721023361, Lost1: 0.0, Left0: 0.0, Left1: 11.11190723176637\n",
      "f_vars[i]: 1.0366, F_vars[i]: 0.7382, Q0_vars[i]: 2083.7358\n",
      "f_train: 1.0365961317703647, F_train: 0.7381926936435838, Q0_train: 2083.7357637681093\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 3.5257676609176087, Lost1: 0.0, Left0: 0.0, Left1: 1.6357173939780443\n",
      "f_vars[i]: 0.9335, F_vars[i]: 0.7178, Q0_vars[i]: 2026.1255\n",
      "f_train: 0.9334932102360458, F_train: 0.7177834444089062, Q0_train: 2026.125490856782\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.3567327174587236, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 0.7269, F_vars[i]: 0.6741, Q0_vars[i]: 1902.9072\n",
      "f_train: 0.726931902411069, F_train: 0.6741316389305955, Q0_train: 1902.9072187017862\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.6277538459441985, Lost1: 0.0, Left0: 0.0, Left1: 3.3312611953686067\n",
      "f_vars[i]: 0.9147, F_vars[i]: 0.7140, Q0_vars[i]: 2015.3133\n",
      "f_train: 0.9146613611520973, F_train: 0.7139530735803609, Q0_train: 2015.3132994700877\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 15.539495798049302, Lost1: 0.0, Left0: 0.0, Left1: 16.84893363204708\n",
      "f_vars[i]: 0.5314, F_vars[i]: 0.6298, Q0_vars[i]: 1777.7880\n",
      "f_train: 0.5313863908698848, F_train: 0.6298064075391286, Q0_train: 1777.7880314177532\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 12.406910981351075, Lost1: 0.0, Left0: 0.0, Left1: 11.225177877835783\n",
      "f_vars[i]: 0.8340, F_vars[i]: 0.6972, Q0_vars[i]: 1968.0290\n",
      "f_train: 0.8340089417709509, F_train: 0.6972019316069917, Q0_train: 1968.0289604154948\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 21.48812679546856, Lost1: 0.0, Left0: 0.0, Left1: 22.704786022889493\n",
      "f_vars[i]: 0.5441, F_vars[i]: 0.6328, Q0_vars[i]: 1786.1202\n",
      "f_train: 0.5440678949638071, F_train: 0.6327582053465525, Q0_train: 1786.1202280267203\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 8.340805392327551, Lost1: 0.0, Left0: 0.0, Left1: 10.756569387858603\n",
      "f_vars[i]: 1.0177, F_vars[i]: 0.7345, Q0_vars[i]: 2073.3601\n",
      "f_train: 1.017662134830184, F_train: 0.7345169615822393, Q0_train: 2073.360079451257\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 12.542698287750454, Lost1: 0.0, Left0: 0.0, Left1: 13.810889226548738\n",
      "f_vars[i]: 0.7622, F_vars[i]: 0.6818, Q0_vars[i]: 1924.6124\n",
      "f_train: 0.7621529825342019, F_train: 0.6818209869792873, Q0_train: 1924.612350257661\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.390931458805582, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 0.7114, F_vars[i]: 0.6707, Q0_vars[i]: 1893.2557\n",
      "f_train: 0.7114092130195306, F_train: 0.6707124695652229, Q0_train: 1893.2557475474982\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=7 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0x42877812\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [5e+02, 2e+03]\n",
      "Presolve removed 56 rows and 94 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 237 rows, 170 columns, 630 nonzeros\n",
      "Presolved model has 37 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 133 continuous, 37 integer (37 binary)\n",
      "Found heuristic solution: objective 2.467104e+07\n",
      "\n",
      "Root relaxation: objective 2.501874e+07, 98 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5019e+07    0   15 2.4671e+07 2.5019e+07  1.41%     -    0s\n",
      "H    0     0                    2.487084e+07 2.5019e+07  0.59%     -    0s\n",
      "\n",
      "Explored 1 nodes (98 simplex iterations) in 0.01 seconds (0.01 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 2.48708e+07 2.4671e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.487083915210e+07, best bound 2.501873669152e+07, gap 0.5947%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 64.44095730982379, Left1: 1.164057167102328e-06\n",
      "f_vars[i]: 1.0580, F_vars[i]: 0.7423, Q0_vars[i]: 2095.3737\n",
      "f_train: 1.0580388500709144, F_train: 0.7423155886618803, Q0_train: 2095.3736787378202\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 67.35337793457802, Left1: 0.0\n",
      "f_vars[i]: 1.0094, F_vars[i]: 0.7329, Q0_vars[i]: 2068.7817\n",
      "f_train: 1.0093606944787687, F_train: 0.7328950174822901, Q0_train: 2068.781731606584\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 1.082469680113718e-06\n",
      "f_vars[i]: 1.5386, F_vars[i]: 0.8233, Q0_vars[i]: 2323.8446\n",
      "f_train: 1.5385553703076873, F_train: 0.8232546204342092, Q0_train: 2323.8445869993366\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 3.4994333374455784, Lost1: 0.0, Left0: 0.0, Left1: 3.4994345527055777\n",
      "f_vars[i]: 1.5052, F_vars[i]: 0.8183, Q0_vars[i]: 2309.9960\n",
      "f_train: 1.5051987558998854, F_train: 0.8183485724210103, Q0_train: 2309.9960244330946\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 25.936278819056042, Lost1: 0.0, Left0: 0.0, Left1: 25.93627992966341\n",
      "f_vars[i]: 1.5686, F_vars[i]: 0.8276, Q0_vars[i]: 2336.0452\n",
      "f_train: 1.568550363395286, F_train: 0.8275768528999287, Q0_train: 2336.0451823800436\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 30.98719521755811, Lost1: 0.0, Left0: 0.0, Left1: 30.987196379202153\n",
      "f_vars[i]: 1.6316, F_vars[i]: 0.8364, Q0_vars[i]: 2360.9209\n",
      "f_train: 1.6316052259405258, F_train: 0.8363894199891024, Q0_train: 2360.920884039566\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 5.199237914336663, Lost1: 0.0, Left0: 0.0, Left1: 5.199238949413221\n",
      "f_vars[i]: 1.5223, F_vars[i]: 0.8209, Q0_vars[i]: 2317.1175\n",
      "f_train: 1.522262878633514, F_train: 0.8208714593076845, Q0_train: 2317.1175113821955\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 36.37916031278928, Left1: 1.2226390708747203e-06\n",
      "f_vars[i]: 1.2891, F_vars[i]: 0.7840, Q0_vars[i]: 2213.0205\n",
      "f_train: 1.2890930886337286, F_train: 0.7839936454625195, Q0_train: 2213.0205455622454\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 1.1779846364828953e-06\n",
      "f_vars[i]: 1.4932, F_vars[i]: 0.8166, Q0_vars[i]: 2304.9248\n",
      "f_train: 1.4931593758646997, F_train: 0.8165520041349572, Q0_train: 2304.924755614078\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 64.12125089623912, Left1: 1.2460991314355852e-06\n",
      "f_vars[i]: 1.0835, F_vars[i]: 0.7472, Q0_vars[i]: 2109.0615\n",
      "f_train: 1.0835472312537027, F_train: 0.7471646767822874, Q0_train: 2109.061457586298\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 1.187523908626577e-06\n",
      "f_vars[i]: 1.4078, F_vars[i]: 0.8034, Q0_vars[i]: 2267.8401\n",
      "f_train: 1.4077716751713494, F_train: 0.8034142403933066, Q0_train: 2267.8400914062922\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 51.37048287711832, Left1: 1.0969015420414507e-06\n",
      "f_vars[i]: 1.0951, F_vars[i]: 0.7493, Q0_vars[i]: 2115.1812\n",
      "f_train: 1.0950563368984199, F_train: 0.7493326664949346, Q0_train: 2115.1811574134886\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 26.813683582917747, Lost1: 0.0, Left0: 0.0, Left1: 26.813684734118443\n",
      "f_vars[i]: 1.6122, F_vars[i]: 0.8337, Q0_vars[i]: 2353.3630\n",
      "f_train: 1.612166385151601, F_train: 0.8337119433002268, Q0_train: 2353.36302823673\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 19.23015006352922, Left1: 1.2717766821879195e-06\n",
      "f_vars[i]: 1.3271, F_vars[i]: 0.7904, Q0_vars[i]: 2230.9693\n",
      "f_train: 1.3270500235548868, F_train: 0.7903522554318386, Q0_train: 2230.9693319902512\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 48.40871040159494, Left1: 1.264536429346208e-06\n",
      "f_vars[i]: 1.2854, F_vars[i]: 0.7834, Q0_vars[i]: 2211.2578\n",
      "f_train: 1.285409417631758, F_train: 0.7833691720047614, Q0_train: 2211.257811131711\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 210 rows, 435 columns and 945 nonzeros\n",
      "Model fingerprint: 0x44027cd4\n",
      "Model has 105 general constraints\n",
      "Variable types: 315 continuous, 120 integer (120 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Presolve removed 177 rows and 361 columns\n",
      "Presolve time: 0.02s\n",
      "Presolved: 33 rows, 74 columns, 178 nonzeros\n",
      "Presolved model has 17 SOS constraint(s)\n",
      "Variable types: 33 continuous, 41 integer (41 binary)\n",
      "Found heuristic solution: objective 2.501235e+07\n",
      "\n",
      "Root relaxation: interrupted, 29 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0          -    0      2.5012e+07 2.5019e+07  0.03%     -    0s\n",
      "\n",
      "Explored 1 nodes (29 simplex iterations) in 0.02 seconds (0.01 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.50123e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.501234612928e+07, best bound 2.501873669540e+07, gap 0.0255%\n",
      "\n",
      "model.status is optimal: True\n",
      "model.status is TIME_LIMIT: False\n",
      "\n",
      "第 2 天補貨策略: R_vars = 1.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = -0.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 1.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = 1.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = -0.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = 1.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = -0.0\n",
      "第 2 天補貨策略: R_vars = 1.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = 1.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = -0.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = 1.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = -0.0\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 667 and 669 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 667 and 669 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 435 rows, 741 columns and 1815 nonzeros\n",
      "Model fingerprint: 0x054e8f16\n",
      "Model has 240 general constraints\n",
      "Variable types: 621 continuous, 120 integer (120 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 5e+06]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e-03, 1e+00]\n",
      "  GenCon coe range [1e+00, 1e+00]\n",
      "Presolve removed 21 rows and 213 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 534 rows, 529 columns, 2037 nonzeros\n",
      "Presolved model has 195 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 333 continuous, 196 integer (196 binary)\n",
      "\n",
      "Root relaxation: objective 2.501874e+07, 239 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5019e+07    0   52          - 2.5019e+07      -     -    0s\n",
      "H    0     0                    -9929711.723 2.5019e+07   352%     -    0s\n",
      "     0     2 2.5019e+07    0   52 -9929711.7 2.5019e+07   352%     -    0s\n",
      "H   64    84                    2.467105e+07 2.5019e+07  1.41%   4.0    0s\n",
      "H 1079   797                    2.500024e+07 2.5019e+07  0.07%   4.3    0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27336/4060423289.py:107: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27336/3170868990.py:156: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 4\n",
      "\n",
      "Explored 1211 nodes (5424 simplex iterations) in 0.15 seconds (0.22 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 3: 2.50002e+07 2.4671e+07 -9.92971e+06 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.500023850191e+07, best bound 2.501873669543e+07, gap 0.0740%\n",
      "\n",
      "model.status is optimal: True\n",
      "model.status is TIME_LIMIT: False\n",
      "\n",
      "f_vars[i]: -0.2276, F_vars[i]: 0.4433, Q0_vars[i]: 1251.4289\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 1.0, tau_vars = -0.006995763027339992\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.014225314440783867\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.015706897990525645\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.015466106215654779\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.009536130483036887\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.009870534157421213\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.016378212031051456\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.045376381079234224\n",
      "*** 於第[2]天進貨 ***\n",
      "\n",
      "f_vars[i]: -0.2275, F_vars[i]: 0.4434, Q0_vars[i]: 1251.5207\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = 0.013646829825415943\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.006769850059089968\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.008847017356687742\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.008308433707888864\n",
      "第 6 天補貨策略: R_vars = 1.0, tau_vars = 0.014646829825415942\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = 0.013646829825415943\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.010153556090440734\n",
      "第 9 天補貨策略: R_vars = -0.0, tau_vars = -0.036944906613580804\n",
      "*** 於第[6]天進貨 ***\n",
      "\n",
      "f_vars[i]: 5.1084, F_vars[i]: 0.9940, Q0_vars[i]: 2805.7906\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.10934097222248289\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.015017181789646755\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.014296597606867132\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.015156889698256959\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.06356564490689642\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.06006271746095008\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.016040012819084654\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = -0.009287444557908893\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 4.5677, F_vars[i]: 0.9897, Q0_vars[i]: 2793.7484\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.10547316229719048\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.017285633413073664\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.016600572606537658\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.01744310300980567\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.06570908020218846\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.06238531440149436\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.018035235026146193\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = -0.015600572606537657\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 4.8674, F_vars[i]: 0.9924, Q0_vars[i]: 2801.2018\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.12664012447549994\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.022898303260292772\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.021644705365444574\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.022771504312868673\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.08680577608563213\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.08276931860839294\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.02266517606988673\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = -0.01987018549893785\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 6.2446, F_vars[i]: 0.9981, Q0_vars[i]: 2817.2850\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.12720546119857526\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.013767777727936298\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.012691601080434314\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.013729689404185313\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.07046972342988017\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.06627637193442966\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.014784098186484684\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 4.4135, F_vars[i]: 0.9880, Q0_vars[i]: 2788.9725\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.11563758339394933\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.0220010129314573\n",
      "第 4 天補貨策略: R_vars = 1.0, tau_vars = -0.0210010129314573\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.0220010129314573\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.07951844341759329\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.07588245069052338\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0220010129314573\n",
      "第 9 天補貨策略: R_vars = -0.0, tau_vars = -0.0220010129314573\n",
      "*** 於第[4]天進貨 ***\n",
      "\n",
      "f_vars[i]: 3.3357, F_vars[i]: 0.9656, Q0_vars[i]: 2725.7432\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.03725304267166296\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.002109872651935834\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.0020549363259678988\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 7 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.004668947218159192\n",
      "第 9 天補貨策略: R_vars = -0.0, tau_vars = -0.005723927390575963\n",
      "*** 於第[7]天進貨 ***\n",
      "\n",
      "f_vars[i]: 5.7559, F_vars[i]: 0.9968, Q0_vars[i]: 2813.8502\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.07778863789725046\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = 0.0007658052478969214\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = 0.00048498268234101194\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = 0.00012539396511898615\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.018612703813711308\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.0160619725905747\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0027414005708593075\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.013047525405683944\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: -0.4737, F_vars[i]: 0.3837, Q0_vars[i]: 1083.1941\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.022487862262215344\n",
      "第 3 天補貨策略: R_vars = 1.0, tau_vars = -0.021487862262215343\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.022487862262215344\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.022487862262215344\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.03072134002673496\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.030580986206828708\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.022487862262215344\n",
      "第 9 天補貨策略: R_vars = -0.0, tau_vars = -0.05529441287692453\n",
      "*** 於第[3]天進貨 ***\n",
      "\n",
      "f_vars[i]: 4.2969, F_vars[i]: 0.9866, Q0_vars[i]: 2784.8482\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.06930910349759395\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.006061409288379895\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.006381632900935923\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.006721521094657901\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.026687951635415905\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.024557543695957737\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.008714751314275154\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = -0.004785336125861454\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.1077, F_vars[i]: 0.5269, Q0_vars[i]: 1487.2991\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.016319579079198097\n",
      "第 3 天補貨策略: R_vars = 1.0, tau_vars = -0.015319579079198098\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.016579328387008017\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.016449453733103088\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.016319579079198097\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.016319579079198097\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.017229023818558932\n",
      "第 9 天補貨策略: R_vars = -0.0, tau_vars = -0.04428963353209455\n",
      "*** 於第[3]天進貨 ***\n",
      "\n",
      "f_vars[i]: 5.7906, F_vars[i]: 0.9970, Q0_vars[i]: 2814.1529\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.12758942553774\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.016983295061965713\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.015832183468654094\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.016907739265309918\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.07652241813286671\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.07236239207710292\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.017553776920961106\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = -0.006782414145225996\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 3.8502, F_vars[i]: 0.9792, Q0_vars[i]: 2763.9492\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.04356993329257502\n",
      "第 3 天補貨策略: R_vars = 1.0, tau_vars = 0.00020622053748232908\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.000793779462517671\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.000793779462517671\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.002049269169941843\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.000793779462517671\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.003565503745547497\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.000793779462517671\n",
      "*** 於第[3]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.7136, F_vars[i]: 0.6712, Q0_vars[i]: 1894.6472\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.08551677603022968\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.03620135509223127\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.035549915705613194\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.036375635398922274\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.08990020622814807\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.08760796845913926\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = -0.03454991570561319\n",
      "第 9 天補貨策略: R_vars = -0.0, tau_vars = -0.06370266736114041\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "all_Rs: [2, 6, 9, 9, 9, 9, 4, 7, 9, 3, 9, 3, 9, 3, 8]\n",
      "Fold 1 Q_star: 2822.7531669043915\n",
      "baseline_profit: -491661.27713878395\n",
      "f_vars[i]: -7.81738144255929, F_vars[i]: 0.00040251264870798923\n",
      "f_vars[i]: -7.996596030591622, F_vars[i]: 0.0003364932123415421\n",
      "f_vars[i]: -8.081010712925034, F_vars[i]: 0.0003092625321163005\n",
      "f_vars[i]: -7.9672415460181005, F_vars[i]: 0.0003465137284418792\n",
      "f_vars[i]: -8.01248243723833, F_vars[i]: 0.0003311915385509576\n",
      "f_vars[i]: -7.8252754886299725, F_vars[i]: 0.0003993489677782629\n",
      "f_vars[i]: -7.896039911520304, F_vars[i]: 0.00037207613639872526\n",
      "f_vars[i]: -7.6027663931306, F_vars[i]: 0.0004988199557012481\n",
      "f_vars[i]: -8.032386175271316, F_vars[i]: 0.0003246668770915584\n",
      "f_vars[i]: -8.009325299371111, F_vars[i]: 0.0003322384602728266\n",
      "f_vars[i]: -8.076246369306642, F_vars[i]: 0.0003107390216934254\n",
      "f_vars[i]: -7.804451217269175, F_vars[i]: 0.00040774888568442645\n",
      "f_vars[i]: -7.983642154972749, F_vars[i]: 0.00034087896260993466\n",
      "f_vars[i]: -7.9525194132614505, F_vars[i]: 0.00035165107922459\n",
      "f_vars[i]: -7.992345268017712, F_vars[i]: 0.0003379261250696673\n",
      "assigned_R: 4\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 210 rows, 435 columns and 945 nonzeros\n",
      "Model fingerprint: 0xb9a4cefb\n",
      "Model has 105 general constraints\n",
      "Variable types: 315 continuous, 120 integer (120 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Presolve removed 144 rows and 303 columns\n",
      "Presolve time: 0.02s\n",
      "Presolved: 66 rows, 132 columns, 354 nonzeros\n",
      "Presolved model has 18 SOS constraint(s)\n",
      "Variable types: 66 continuous, 66 integer (66 binary)\n",
      "\n",
      "Root relaxation: objective 5.736960e+06, 35 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5736959.91    0   10          - 5736959.91      -     -    0s\n",
      "H    0     0                    5736959.9066 5736959.91 -0.00%     -    0s\n",
      "     0     0 5736959.91    0   10 5736959.91 5736959.91 -0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (38 simplex iterations) in 0.03 seconds (0.01 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 5.73696e+06 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Warning: max constraint violation (3.6339e-06) exceeds tolerance\n",
      "Best objective 5.736959906607e+06, best bound 5.736959906607e+06, gap 0.0000%\n",
      "\n",
      "model.status is optimal: True\n",
      "model.status is TIME_LIMIT: False\n",
      "\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 1.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 1.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 1.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 1.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 1.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "tau: [ 0.50739071 -0.01078483 -0.0233233  -0.01755407  0.26103361  0.24140479\n",
      " -0.01854328 -0.22792079]\n",
      "R: [1 0 0 0 0 0 0 0]\n",
      "max_r_index: 0\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 5.54577734e-01  1.15819378e-02 -2.42848188e-03  4.07672797e-03\n",
      "  3.26009008e-01  3.04937786e-01  2.78091743e-04 -1.97182082e-01]\n",
      "R: [1 0 0 0 0 0 0 0]\n",
      "max_r_index: 0\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 0.53560933 -0.00206839 -0.01539041 -0.0092294   0.29140554  0.27084493\n",
      " -0.01130658 -0.21957165]\n",
      "R: [1 0 0 0 0 0 0 0]\n",
      "max_r_index: 0\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 0.53782111  0.0026182  -0.01084832 -0.00461506  0.30107621  0.28050204\n",
      " -0.00728628 -0.21029644]\n",
      "R: [1 0 0 0 0 0 0 0]\n",
      "max_r_index: 0\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 0.49967042 -0.02112756 -0.0332865  -0.02770703  0.23823279  0.21874068\n",
      " -0.02738726 -0.24734158]\n",
      "R: [1 0 0 0 0 0 0 0]\n",
      "max_r_index: 0\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 0.53387137  0.00452704 -0.00889475 -0.00268386  0.3025227   0.28212542\n",
      " -0.00560043 -0.20472745]\n",
      "R: [1 0 0 0 0 0 0 0]\n",
      "max_r_index: 0\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 0.53724136  0.00439822 -0.00909287 -0.00284733  0.30401971  0.28349377\n",
      " -0.00574517 -0.20624932]\n",
      "R: [1 0 0 0 0 0 0 0]\n",
      "max_r_index: 0\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 0.52193749  0.00414691 -0.00901213 -0.00293261  0.29569856  0.27574446\n",
      " -0.00580923 -0.20113906]\n",
      "R: [1 0 0 0 0 0 0 0]\n",
      "max_r_index: 0\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 0.56899998  0.01898349  0.00451145  0.01124747  0.34689763  0.32539395\n",
      "  0.00651832 -0.18656964]\n",
      "R: [1 0 0 0 0 0 0 0]\n",
      "max_r_index: 0\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 5.48436899e-01  7.59754052e-03 -6.19904042e-03  1.99250052e-04\n",
      "  3.15598171e-01  2.94698711e-01 -3.09733323e-03 -2.03494279e-01]\n",
      "R: [1 0 0 0 0 0 0 0]\n",
      "max_r_index: 0\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 0.5282222  -0.00626353 -0.01934073 -0.01330213  0.27997056  0.25962545\n",
      " -0.01485135 -0.22587743]\n",
      "R: [1 0 0 0 0 0 0 0]\n",
      "max_r_index: 0\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 0.51942987 -0.00333151 -0.01628178 -0.01030664  0.28079202  0.26082113\n",
      " -0.01223463 -0.21631684]\n",
      "R: [1 0 0 0 0 0 0 0]\n",
      "max_r_index: 0\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 0.54823233  0.00824228 -0.00556331  0.00083948  0.31666712  0.29578493\n",
      " -0.00253918 -0.20203037]\n",
      "R: [1 0 0 0 0 0 0 0]\n",
      "max_r_index: 0\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 0.49952653 -0.01942634 -0.03161752 -0.02602193  0.24125675  0.22179532\n",
      " -0.02591846 -0.24362509]\n",
      "R: [1 0 0 0 0 0 0 0]\n",
      "max_r_index: 0\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 5.46419124e-01  6.91855837e-03 -6.82083841e-03 -4.51140017e-04\n",
      "  3.13324972e-01  2.92491313e-01 -3.66284834e-03 -2.04211255e-01]\n",
      "R: [1 0 0 0 0 0 0 0]\n",
      "max_r_index: 0\n",
      "\n",
      "\n",
      "\n",
      "===== Processing Fold 2 =====\n",
      "mean of sum: 2677.1537131644673\n",
      "std of sum: 131.02183264368077\n",
      "60.0 percentile of sum: 2710.3477149122873\n",
      "Fold 2 Q_star: 2710.3477149122873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27336/2267964258.py:74: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27336/4060423289.py:107: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27336/3802425588.py:90: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++++++++++++++++++++++ THis is R=0 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0x0df5c610\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [3e+02, 3e+03]\n",
      "Presolve removed 54 rows and 84 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 239 rows, 180 columns, 635 nonzeros\n",
      "Presolved model has 45 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 135 continuous, 45 integer (45 binary)\n",
      "\n",
      "Root relaxation: objective 2.396047e+07, 91 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.3960e+07    0   20          - 2.3960e+07      -     -    0s\n",
      "H    0     0                    2.384284e+07 2.3960e+07  0.49%     -    0s\n",
      "\n",
      "Explored 1 nodes (91 simplex iterations) in 0.03 seconds (0.00 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.38428e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.384283505795e+07, best bound 2.396046990178e+07, gap 0.4934%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1098.6542343561578, Left1: 71.71421213211943\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1088.6168113467866, Left1: 31.415909298843417\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1100.0692340638057, Left1: 15.640155773277911\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 42.76230857296787, Left0: 1096.8450524035147, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.214316463461273, Left0: 1101.7577395841893, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 6.115287128978252, Left0: 1091.9578616499316, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 14.806900740366473, Left0: 1087.3528643859954, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1104.9186619471704, Left1: 3.079108040627034\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1063.3015821634494, Left1: 45.21997853758967\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 19.83474965502768, Left0: 1078.745122939923, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 2.1342387119789237, Left0: 1093.9291192787284, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1073.5493421654114, Left1: 50.34663672781198\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1098.533056482922, Left1: 30.37983650566639\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 20.474055491699346, Left0: 1078.5772759573501, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 17.683164671576833, Left0: 1057.9588444048225, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=1 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0x8afa0d53\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [5e+02, 2e+03]\n",
      "Presolve removed 51 rows and 77 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 242 rows, 187 columns, 649 nonzeros\n",
      "Presolved model has 49 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 138 continuous, 49 integer (49 binary)\n",
      "\n",
      "Root relaxation: objective 2.407849e+07, 85 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.4078e+07    0   23          - 2.4078e+07      -     -    0s\n",
      "H    0     0                    2.405983e+07 2.4078e+07  0.08%     -    0s\n",
      "\n",
      "Explored 1 nodes (85 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.40598e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.405982750988e+07, best bound 2.407849481834e+07, gap 0.0776%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 846.6948443452608, Left1: 8.119835493842857\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.6822831063664125, Left0: 824.4764631980116, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 844.0594052708284, Left1: 1.7709542264219635\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.6431226119379971, Left0: 832.0380425267922, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.8279680729106076, Left0: 845.8213536092852, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 826.058702406895, Left1: 5.897539158196196\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 816.6397148255444, Left1: 4.383006954691609\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 851.7112872598171, Left1: 2.9424476021226837\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.5914080168836335, Left0: 778.6779759899082, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.20309270121970258, Left0: 800.4150501882264, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 830.6596444967108, Left1: 1.4630103645872623\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 797.3869394862235, Left1: 6.709455202000186\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 8.505466228663181, Left0: 843.83603147936, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 799.7799511406002, Left1: 2.1594540194884075\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 761.49403451745, Left1: 0.5840462602900516\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=2 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0x58b5f4eb\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [8e+02, 2e+03]\n",
      "Presolve removed 54 rows and 82 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 239 rows, 182 columns, 641 nonzeros\n",
      "Presolved model has 47 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 135 continuous, 47 integer (47 binary)\n",
      "\n",
      "Root relaxation: objective 2.407856e+07, 80 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.4079e+07    0   22          - 2.4079e+07      -     -    0s\n",
      "H    0     0                    2.406140e+07 2.4079e+07  0.07%     -    0s\n",
      "\n",
      "Explored 1 nodes (80 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.40614e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.406139967440e+07, best bound 2.407855813597e+07, gap 0.0713%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 594.075371084953, Left1: 8.159642937715489\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.2831075042940938, Left0: 560.3160328755401, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 584.6620051278201, Left1: 0.6990556698556247\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.9647407740139897, Left0: 566.010659869886, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.0865625910842027, Left0: 591.6068148563461, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 557.1096054634634, Left1: 5.049646681429294\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 548.1378108896093, Left1: 5.528809714223371\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 598.7936561085303, Left1: 3.102251790905939\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.478272960508093, Left0: 489.17928852582645, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 523.2920853155714, Left1: 0.7308317860582747\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 563.2519112414673, Left1: 0.19666637942009402\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 520.0950365157764, Left1: 6.9967725079911816\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 7.725170624074508, Left0: 590.6198218546648, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 517.7467825937509, Left1: 1.4670091471256228\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 463.5500622057124, Left1: 0.9151102134118219\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=3 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0xe371fe12\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 2e+03]\n",
      "Presolve removed 50 rows and 63 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 243 rows, 201 columns, 657 nonzeros\n",
      "Presolved model has 62 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 139 continuous, 62 integer (62 binary)\n",
      "\n",
      "Root relaxation: objective 2.407856e+07, 92 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.4079e+07    0   26          - 2.4079e+07      -     -    0s\n",
      "H    0     0                    2.406140e+07 2.4079e+07  0.07%     -    0s\n",
      "\n",
      "Explored 1 nodes (92 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.40614e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.406139967825e+07, best bound 2.407855813757e+07, gap 0.0713%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 342.11598147111806, Left1: 8.15964146594888\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.2831076883367132, Left0: 296.17568474692484, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 328.6521770659547, Left1: 0.6990535358336274\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.9647403060596389, Left0: 301.2036499800065, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.08656321950275, Left0: 335.67042890596144, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 291.2104464722179, Left1: 5.0496465064934455\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 277.42466116168407, Left1: 5.528809453145186\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 345.58628128530904, Left1: 3.1022525623420734\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.4782727554527355, Left0: 204.55568255766798, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 244.9620125911631, Left1: 0.7308307558857905\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 299.98243670240595, Left1: 0.1966667266378863\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 243.93263383768817, Left1: 6.996772510504115\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 7.725168515735049, Left0: 335.92279633398334, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 238.94945780785656, Left1: 1.4670097816861016\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 167.08525232257853, Left1: 0.9151098335701136\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1355.1739\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1355.1738574561437\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=4 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0x6642f991\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 1e+03]\n",
      "Presolve removed 48 rows and 59 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 245 rows, 205 columns, 660 nonzeros\n",
      "Presolved model has 64 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 141 continuous, 64 integer (64 binary)\n",
      "\n",
      "Root relaxation: objective 2.407845e+07, 99 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.4078e+07    0   27          - 2.4078e+07      -     -    0s\n",
      "H    0     0                    2.358825e+07 2.4078e+07  2.08%     -    0s\n",
      "     0     2 2.4078e+07    0   34 2.3588e+07 2.4078e+07  2.08%     -    0s\n",
      "H   67    58                    2.404213e+07 2.4075e+07  0.14%   8.0    0s\n",
      "H   71    58                    2.404214e+07 2.4075e+07  0.14%   7.8    0s\n",
      "H   73    58                    2.404214e+07 2.4075e+07  0.14%   7.7    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Cover: 3\n",
      "  Implied bound: 9\n",
      "\n",
      "Explored 90 nodes (770 simplex iterations) in 0.05 seconds (0.03 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 4: 2.40421e+07 2.40421e+07 2.40421e+07 2.35883e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.404213718703e+07, best bound 2.407389624541e+07, gap 0.1321%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 8.841736851502551, Left1: 4.041094337791492\n",
      "f_vars[i]: -0.1278, F_vars[i]: 0.4681, Q0_vars[i]: 1268.7154\n",
      "f_train: -0.12777111366409666, F_train: 0.4681006074618422, Q0_train: 1268.7154117832574\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.7358470262345236, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -0.0498, F_vars[i]: 0.4876, Q0_vars[i]: 1321.4540\n",
      "f_train: -0.04977495562585532, F_train: 0.4875588296186854, Q0_train: 1321.4539597423131\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.5066964442826247, Left0: 15.73762986009896, Left1: 0.0\n",
      "f_vars[i]: -0.0882, F_vars[i]: 0.4780, Q0_vars[i]: 1295.4608\n",
      "f_train: -0.08818320118339429, F_train: 0.4779684747909802, Q0_train: 1295.4607634498443\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 2.7342735757758874, Left0: 6.138616670105044, Left1: 0.0\n",
      "f_vars[i]: -0.0447, F_vars[i]: 0.4888, Q0_vars[i]: 1324.8933\n",
      "f_train: -0.04469623058912675, F_train: 0.48882780223178707, Q0_train: 1324.8933167645196\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.274832303137373, Left0: 10.675466331382685, Left1: 0.0\n",
      "f_vars[i]: -0.1009, F_vars[i]: 0.4748, Q0_vars[i]: 1286.8740\n",
      "f_train: -0.10088413723762413, F_train: 0.47480033476137445, Q0_train: 1286.8740023600803\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 6.7662331238231195, Left1: 2.2055258115133256\n",
      "f_vars[i]: -0.0315, F_vars[i]: 0.4921, Q0_vars[i]: 1333.8601\n",
      "f_train: -0.03145801211629107, F_train: 0.49213614547037837, Q0_train: 1333.8600773013811\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 13.085668005552199, Left1: 5.711003209398768\n",
      "f_vars[i]: 0.0119, F_vars[i]: 0.5030, Q0_vars[i]: 1363.2378\n",
      "f_train: 0.011901183291378015, F_train: 0.5029752607053888, Q0_train: 1363.2378485102624\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.98902294520027, Left1: 3.1677729957327756\n",
      "f_vars[i]: -0.1213, F_vars[i]: 0.4697, Q0_vars[i]: 1273.0882\n",
      "f_train: -0.12129258618172911, F_train: 0.4697139747464809, Q0_train: 1273.0881981164923\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 5.690224535855723, Lost1: 0.0, Left0: 0.0, Left1: 1.454074967570623\n",
      "f_vars[i]: 0.1029, F_vars[i]: 0.5257, Q0_vars[i]: 1424.8345\n",
      "f_train: 0.10289757550789447, F_train: 0.525701720583447, Q0_train: 1424.8344571088032\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 3.3471801874914036, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 0.0422, F_vars[i]: 0.5106, Q0_vars[i]: 1383.7699\n",
      "f_train: 0.04220900367376168, F_train: 0.510550684539994, Q0_train: 1383.7698811898767\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 14.982383364520288, Left1: 3.0682110041029773\n",
      "f_vars[i]: -0.0324, F_vars[i]: 0.4919, Q0_vars[i]: 1333.2099\n",
      "f_train: -0.032417823257039347, F_train: 0.4918962538691858, Q0_train: 1333.209887648262\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.3841404899535306, Lost1: 0.0, Left0: 0.0, Left1: 6.953238331670924\n",
      "f_vars[i]: 0.0380, F_vars[i]: 0.5095, Q0_vars[i]: 1380.9218\n",
      "f_train: 0.038003969018207906, F_train: 0.5094998488947794, Q0_train: 1380.921751200121\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.1969896941770912, Left0: 18.457003092586223, Left1: 0.0\n",
      "f_vars[i]: -0.0882, F_vars[i]: 0.4780, Q0_vars[i]: 1295.4430\n",
      "f_train: -0.08820944846417222, F_train: 0.47796192571469104, Q0_train: 1295.4430131758893\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 3.2018765307875583\n",
      "f_vars[i]: 0.0588, F_vars[i]: 0.5147, Q0_vars[i]: 1394.9883\n",
      "f_train: 0.05877603705156975, F_train: 0.5146897805357956, Q0_train: 1394.9882705639002\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 9.674601153264119, Lost1: 0.0, Left0: 0.0, Left1: 12.17795930773559\n",
      "f_vars[i]: 0.1774, F_vars[i]: 0.5442, Q0_vars[i]: 1475.0303\n",
      "f_train: 0.1773505932731798, F_train: 0.5442217991560312, Q0_train: 1475.030309748003\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=5 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0x2c816c54\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 2e+03]\n",
      "Presolve removed 51 rows and 66 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 242 rows, 198 columns, 648 nonzeros\n",
      "Presolved model has 60 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 138 continuous, 60 integer (60 binary)\n",
      "\n",
      "Root relaxation: objective 2.407845e+07, 95 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.4078e+07    0   26          - 2.4078e+07      -     -    0s\n",
      "H    0     0                    1.807402e+07 2.4078e+07  33.2%     -    0s\n",
      "     0     2 2.4078e+07    0   24 1.8074e+07 2.4078e+07  33.2%     -    0s\n",
      "H   67    76                    2.393919e+07 2.4074e+07  0.56%   5.3    0s\n",
      "H   69    76                    2.393919e+07 2.4074e+07  0.56%   5.3    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 12\n",
      "\n",
      "Explored 91 nodes (538 simplex iterations) in 0.06 seconds (0.03 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 3: 2.39392e+07 2.39392e+07 1.8074e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.393919044569e+07, best bound 2.407389624572e+07, gap 0.5627%\n",
      "Model status: 2\n",
      "Lost0: 6.957389509627319, Lost1: 0.0, Left0: 0.0, Left1: 10.998483790633372\n",
      "f_vars[i]: 0.2218, F_vars[i]: 0.5552, Q0_vars[i]: 1504.8752\n",
      "f_train: 0.2218384168885401, F_train: 0.5552332768199416, Q0_train: 1504.8752430721902\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 8.976966818734809, Lost1: 0.0, Left0: 0.0, Left1: 8.241119787932575\n",
      "f_vars[i]: 0.3298, F_vars[i]: 0.5817, Q0_vars[i]: 1576.6172\n",
      "f_train: 0.3297679622744316, F_train: 0.5817029174179741, Q0_train: 1576.617172981617\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.5911733732352786, Lost1: 0.0, Left0: 0.0, Left1: 2.0844765669419303\n",
      "f_vars[i]: 0.2642, F_vars[i]: 0.5657, Q0_vars[i]: 1533.1414\n",
      "f_train: 0.26417466143571255, F_train: 0.5656622377260266, Q0_train: 1533.1413534329074\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.798799700300151, Lost1: 0.0, Left0: 0.0, Left1: 0.06452633147205233\n",
      "f_vars[i]: 0.3361, F_vars[i]: 0.5832, Q0_vars[i]: 1580.7629\n",
      "f_train: 0.33605744861970743, F_train: 0.5832325133217242, Q0_train: 1580.7629097440854\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 3.274832446106656, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 0.2577, F_vars[i]: 0.5641, Q0_vars[i]: 1528.8601\n",
      "f_train: 0.25774807426227264, F_train: 0.5640826382233324, Q0_train: 1528.8600895303034\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 3.918630487283963, Lost1: 0.0, Left0: 0.0, Left1: 6.124156429767027\n",
      "f_vars[i]: 0.3487, F_vars[i]: 0.5863, Q0_vars[i]: 1589.0723\n",
      "f_train: 0.348683634088486, F_train: 0.586298327257781, Q0_train: 1589.072331540023\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 5.7110031163338135\n",
      "f_vars[i]: 0.3973, F_vars[i]: 0.5980, Q0_vars[i]: 1620.8653\n",
      "f_train: 0.39725745408497115, F_train: 0.5980285560086903, Q0_train: 1620.8653302304485\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 4.5104091661683015, Lost1: 0.0, Left0: 0.0, Left1: 7.678182328320986\n",
      "f_vars[i]: 0.2322, F_vars[i]: 0.5578, Q0_vars[i]: 1511.7943\n",
      "f_train: 0.23218195134716302, F_train: 0.5577861240395322, Q0_train: 1511.7943467003277\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 14.459008516881113, Lost1: 0.0, Left0: 0.0, Left1: 10.222859031820027\n",
      "f_vars[i]: 0.5214, F_vars[i]: 0.6275, Q0_vars[i]: 1700.6888\n",
      "f_train: 0.5214208008742718, F_train: 0.6274799370139602, Q0_train: 1700.688813439093\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 6.519020246438231, Lost1: 0.0, Left0: 0.0, Left1: 3.17184004105007\n",
      "f_vars[i]: 0.4560, F_vars[i]: 0.6121, Q0_vars[i]: 1658.9263\n",
      "f_train: 0.4560276817105833, F_train: 0.6120714098317879, Q0_train: 1658.9263470007284\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.8258067022581894, Lost1: 0.0, Left0: 0.0, Left1: 5.894017673855842\n",
      "f_vars[i]: 0.3329, F_vars[i]: 0.5825, Q0_vars[i]: 1578.6702\n",
      "f_train: 0.33288173379819597, F_train: 0.5824603814180882, Q0_train: 1578.6701638034547\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 9.976592853445707, Lost1: 0.0, Left0: 0.0, Left1: 14.545690852758979\n",
      "f_vars[i]: 0.4414, F_vars[i]: 0.6086, Q0_vars[i]: 1649.4910\n",
      "f_train: 0.4413898789911066, F_train: 0.6085901612103642, Q0_train: 1649.4909527546113\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 3.6543068736859823, Lost1: 0.0, Left0: 0.0, Left1: 2.4573172797427105\n",
      "f_vars[i]: 0.2565, F_vars[i]: 0.5638, Q0_vars[i]: 1528.0281\n",
      "f_train: 0.25649985328262925, F_train: 0.5637756843902102, Q0_train: 1528.028137910117\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 8.077316086339351, Lost1: 0.0, Left0: 0.0, Left1: 11.279192670158226\n",
      "f_vars[i]: 0.4666, F_vars[i]: 0.6146, Q0_vars[i]: 1665.7082\n",
      "f_train: 0.4665785506131148, F_train: 0.6145736261745351, Q0_train: 1665.7082233475096\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 15.346232793422814, Lost1: 0.0, Left0: 0.0, Left1: 17.849590764086877\n",
      "f_vars[i]: 0.6257, F_vars[i]: 0.6515, Q0_vars[i]: 1765.8253\n",
      "f_train: 0.6256940827256714, F_train: 0.6515124685325435, Q0_train: 1765.8253303240429\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=6 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0x0a76c0b0\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [8e+02, 2e+03]\n",
      "Presolve removed 48 rows and 85 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 245 rows, 179 columns, 661 nonzeros\n",
      "Presolved model has 38 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 141 continuous, 38 integer (38 binary)\n",
      "\n",
      "Root relaxation: objective 2.408936e+07, 88 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.4089e+07    0   18          - 2.4089e+07      -     -    0s\n",
      "H    0     0                    1.165763e+07 2.4089e+07   107%     -    0s\n",
      "     0     2 2.4089e+07    0   18 1.1658e+07 2.4089e+07   107%     -    0s\n",
      "H  620   424                    1.719426e+07 2.4089e+07  40.1%   3.3    0s\n",
      "H  691   424                    2.406404e+07 2.4089e+07  0.10%   3.1    0s\n",
      "\n",
      "Explored 867 nodes (2579 simplex iterations) in 0.05 seconds (0.05 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 3: 2.4064e+07 1.71943e+07 1.16576e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Warning: max constraint violation (2.5861e-06) exceeds tolerance\n",
      "Best objective 2.406404247064e+07, best bound 2.408860025762e+07, gap 0.1021%\n",
      "Model status: 2\n",
      "Lost0: 5.140183017407708, Lost1: 0.0, Left0: 0.0, Left1: 6.862704687890983\n",
      "f_vars[i]: 0.6148, F_vars[i]: 0.6490, Q0_vars[i]: 1759.0979\n",
      "f_train: 0.6147797651384774, F_train: 0.6490303586027145, Q0_train: 1759.0979493475697\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 5.743518922215344, Lost1: 0.0, Left0: 0.0, Left1: 7.524528319533831\n",
      "f_vars[i]: 0.7620, F_vars[i]: 0.6818, Q0_vars[i]: 1847.8887\n",
      "f_train: 0.7620113147309411, F_train: 0.6817902526145384, Q0_train: 1847.8886532232852\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.566274771305757, Left0: 9.907104652383444, Left1: 0.0\n",
      "f_vars[i]: 0.6816, F_vars[i]: 0.6641, Q0_vars[i]: 1799.9356\n",
      "f_train: 0.6816088716832391, F_train: 0.6640976862469862, Q0_train: 1799.9356463980562\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.133972675428555, Left1: 1.4382656001663088\n",
      "f_vars[i]: 0.7711, F_vars[i]: 0.6838, Q0_vars[i]: 1853.2414\n",
      "f_train: 0.7711295902136928, F_train: 0.683765196112782, Q0_train: 1853.2414368208306\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.758132825399116, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 0.6647, F_vars[i]: 0.6603, Q0_vars[i]: 1789.6910\n",
      "f_train: 0.6647109656632684, F_train: 0.6603178462055207, Q0_train: 1789.6909655789361\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.7010169271543418, Left0: 11.714635342655795, Left1: 0.0\n",
      "f_vars[i]: 0.7925, F_vars[i]: 0.6884, Q0_vars[i]: 1865.7194\n",
      "f_train: 0.7925053297390874, F_train: 0.6883690201524145, Q0_train: 1865.7194007865069\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 17.241471334954863, Left1: 2.5424970926858355\n",
      "f_vars[i]: 0.8671, F_vars[i]: 0.7041, Q0_vars[i]: 1908.4696\n",
      "f_train: 0.8671002425542444, F_train: 0.7041419607675344, Q0_train: 1908.4695543401444\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.1447427313883054, Lost1: 1.24070004348755, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 0.6279, F_vars[i]: 0.6520, Q0_vars[i]: 1767.1727\n",
      "f_train: 0.6278843344027654, F_train: 0.652009586805078, Q0_train: 1767.1726936980479\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.4088471842567287, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 1.0378, F_vars[i]: 0.7384, Q0_vars[i]: 2001.3671\n",
      "f_train: 1.0377575136014774, F_train: 0.7384170851220957, Q0_train: 2001.367059312864\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.254357611523119, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 0.9350, F_vars[i]: 0.7181, Q0_vars[i]: 1946.2676\n",
      "f_train: 0.9349960783637172, F_train: 0.7180877812969224, Q0_train: 1946.2675771445479\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 17.725965632703893, Left1: 1.7558315113152503\n",
      "f_vars[i]: 0.7815, F_vars[i]: 0.6860, Q0_vars[i]: 1859.3106\n",
      "f_train: 0.7815053933327434, F_train: 0.686004469942108, Q0_train: 1859.3106475272073\n",
      "f_train, F_train, Q0_train 不相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.012932736834024, Left1: 0.3421921285339522\n",
      "f_vars[i]: 0.9215, F_vars[i]: 0.7153, Q0_vars[i]: 1938.8187\n",
      "f_train: 0.9214599359962903, F_train: 0.7153394843090922, Q0_train: 1938.8187366836821\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.049027721631659915, Left0: 4.776477194261404, Left1: 0.0\n",
      "f_vars[i]: 0.6767, F_vars[i]: 0.6630, Q0_vars[i]: 1796.9716\n",
      "f_train: 0.6767103090259159, F_train: 0.6630040774231816, Q0_train: 1796.9715862214493\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 10.473637530696955, Left1: 1.096953886306892\n",
      "f_vars[i]: 0.9584, F_vars[i]: 0.7228, Q0_vars[i]: 1959.0505\n",
      "f_train: 0.958413932891923, F_train: 0.7228041357131385, Q0_train: 1959.0505375592556\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.716170011255599, Lost1: 0.0, Left0: 0.0, Left1: 1.1198323872628402\n",
      "f_vars[i]: 1.1791, F_vars[i]: 0.7648, Q0_vars[i]: 2072.8320\n",
      "f_train: 1.1790921583694165, F_train: 0.7647845321619541, Q0_train: 2072.8320091454148\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=7 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0x4e64c58d\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [5e+02, 2e+03]\n",
      "Presolve removed 47 rows and 82 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 246 rows, 182 columns, 657 nonzeros\n",
      "Presolved model has 40 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 142 continuous, 40 integer (40 binary)\n",
      "Found heuristic solution: objective 2.380724e+07\n",
      "\n",
      "Root relaxation: objective 2.409438e+07, 79 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.4094e+07    0   15 2.3807e+07 2.4094e+07  1.21%     -    0s\n",
      "H    0     0                    2.398130e+07 2.4094e+07  0.47%     -    0s\n",
      "\n",
      "Explored 1 nodes (79 simplex iterations) in 0.02 seconds (0.01 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 2.39813e+07 2.38072e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.398130298759e+07, best bound 2.409438341750e+07, gap 0.4715%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.680247279764665, Left1: 0.0\n",
      "f_vars[i]: 1.0689, F_vars[i]: 0.7444, Q0_vars[i]: 2017.5601\n",
      "f_train: 1.0689207468289377, F_train: 0.7443916175418961, Q0_train: 2017.5601196045393\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 1.2718, F_vars[i]: 0.7811, Q0_vars[i]: 2116.9345\n",
      "f_train: 1.2718333771617658, F_train: 0.781056430306411, Q0_train: 2116.934511098529\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.3986642522031, Left1: 1.03897843395373e-06\n",
      "f_vars[i]: 1.1463, F_vars[i]: 0.7588, Q0_vars[i]: 2056.6885\n",
      "f_train: 1.1462663088160019, F_train: 0.7588282823714428, Q0_train: 2056.688501136256\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.611258058476764, Left1: 0.0\n",
      "f_vars[i]: 1.2835, F_vars[i]: 0.7830, Q0_vars[i]: 2122.3354\n",
      "f_train: 1.2835244986607863, F_train: 0.7830491268004248, Q0_train: 2122.3354114875933\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.38204398466454853, Left1: 0.0\n",
      "f_vars[i]: 1.1362, F_vars[i]: 0.7570, Q0_vars[i]: 2051.6817\n",
      "f_train: 1.1361984252502877, F_train: 0.7569809817487846, Q0_train: 2051.681674114878\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 11.440253256994186, Left1: 0.0\n",
      "f_vars[i]: 1.3062, F_vars[i]: 0.7869, Q0_vars[i]: 2132.7245\n",
      "f_train: 1.3062337562540138, F_train: 0.7868822445833483, Q0_train: 2132.7244935115295\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 11.02127421925841, Left1: 0.0\n",
      "f_vars[i]: 1.3955, F_vars[i]: 0.8015, Q0_vars[i]: 2172.2551\n",
      "f_train: 1.3954903624049964, F_train: 0.8014673018722859, Q0_train: 2172.2550702064664\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.26851389667718, Left1: 0.0\n",
      "f_vars[i]: 1.0886, F_vars[i]: 0.7481, Q0_vars[i]: 2027.6682\n",
      "f_train: 1.088616184625793, F_train: 0.7481210505943158, Q0_train: 2027.6681799560833\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 21.135013497896125, Lost1: 0.0, Left0: 0.0, Left1: 21.135014271055308\n",
      "f_vars[i]: 1.6286, F_vars[i]: 0.8360, Q0_vars[i]: 2265.7927\n",
      "f_train: 1.628606082119667, F_train: 0.8359785965123954, Q0_train: 2265.7926787729516\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 7.904675394782262, Lost1: 0.0, Left0: 0.0, Left1: 7.9046762282472995\n",
      "f_vars[i]: 1.5090, F_vars[i]: 0.8189, Q0_vars[i]: 2219.5478\n",
      "f_train: 1.5090222393616823, F_train: 0.8189162575661542, Q0_train: 2219.547807398948\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 12.836005615373235, Left1: 0.0\n",
      "f_vars[i]: 1.2739, F_vars[i]: 0.7814, Q0_vars[i]: 2117.8966\n",
      "f_train: 1.273910256676201, F_train: 0.7814113845076816, Q0_train: 2117.896560406841\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 1.4799, F_vars[i]: 0.8146, Q0_vars[i]: 2207.7377\n",
      "f_train: 1.4799090293840012, F_train: 0.8145588397397601, Q0_train: 2207.737689950263\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 1.1305, F_vars[i]: 0.7559, Q0_vars[i]: 2048.8149\n",
      "f_train: 1.1304571497697289, F_train: 0.7559232545980336, Q0_train: 2048.8148657488396\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.0654091159963173, Lost1: 0.0, Left0: 0.0, Left1: 2.0654099111676256\n",
      "f_vars[i]: 1.5266, F_vars[i]: 0.8215, Q0_vars[i]: 2226.5821\n",
      "f_train: 1.5266225291630056, F_train: 0.8215116123737973, Q0_train: 2226.58212137123\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 39.56996840147758, Lost1: 0.0, Left0: 0.0, Left1: 39.56996932989895\n",
      "f_vars[i]: 1.8249, F_vars[i]: 0.8611, Q0_vars[i]: 2334.0145\n",
      "f_train: 1.8248700179197046, F_train: 0.8611494650866478, Q0_train: 2334.014484895534\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 210 rows, 435 columns and 945 nonzeros\n",
      "Model fingerprint: 0xc60699ae\n",
      "Model has 105 general constraints\n",
      "Variable types: 315 continuous, 120 integer (120 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Presolve removed 198 rows and 409 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 12 rows, 26 columns, 61 nonzeros\n",
      "Presolved model has 6 SOS constraint(s)\n",
      "Variable types: 12 continuous, 14 integer (14 binary)\n",
      "Found heuristic solution: objective 2.409410e+07\n",
      "\n",
      "Root relaxation: interrupted, 11 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0          -    0      2.4094e+07 2.4094e+07  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (11 simplex iterations) in 0.02 seconds (0.00 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.40941e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.409410376409e+07, best bound 2.409438341750e+07, gap 0.0012%\n",
      "\n",
      "model.status is optimal: True\n",
      "model.status is TIME_LIMIT: False\n",
      "\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 1.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 1.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 1.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 667 and 669 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 667 and 669 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 435 rows, 741 columns and 1815 nonzeros\n",
      "Model fingerprint: 0x2d3ace57\n",
      "Model has 240 general constraints\n",
      "Variable types: 621 continuous, 120 integer (120 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 5e+06]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e-03, 1e+00]\n",
      "  GenCon coe range [1e+00, 1e+00]\n",
      "Presolve removed 20 rows and 207 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 535 rows, 535 columns, 2039 nonzeros\n",
      "Presolved model has 200 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 335 continuous, 200 integer (200 binary)\n",
      "\n",
      "Root relaxation: objective 2.409438e+07, 254 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.4094e+07    0   53          - 2.4094e+07      -     -    0s\n",
      "     0     2 2.4094e+07    0   53          - 2.4094e+07      -     -    0s\n",
      "* 1383  1027              73    1.337608e+07 2.4094e+07  80.1%   4.5    0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27336/4060423289.py:107: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27336/3170868990.py:156: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H 1655  1177                    2.239780e+07 2.4094e+07  7.57%   4.4    0s\n",
      "* 1661  1177              77    2.239781e+07 2.4094e+07  7.57%   4.3    0s\n",
      "* 2191  1394              76    2.385352e+07 2.4094e+07  1.01%   3.9    0s\n",
      "H 2293  1517                    2.397856e+07 2.4094e+07  0.48%   3.8    0s\n",
      "H 2333  1517                    2.397856e+07 2.4094e+07  0.48%   3.8    0s\n",
      "H 2375  1517                    2.397856e+07 2.4094e+07  0.48%   3.8    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 3\n",
      "\n",
      "Explored 2565 nodes (9848 simplex iterations) in 0.22 seconds (0.28 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 7: 2.39786e+07 2.39786e+07 2.39786e+07 ... 1.33761e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.397856459402e+07, best bound 2.409438341685e+07, gap 0.4830%\n",
      "\n",
      "model.status is optimal: True\n",
      "model.status is TIME_LIMIT: False\n",
      "\n",
      "f_vars[i]: 2.3919, F_vars[i]: 0.9162, Q0_vars[i]: 2483.2453\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.25151177546639836\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -49.638923565957896\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.08578602066524987\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -15.794847918227598\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -15.794847918227598\n",
      "第 7 天補貨策略: R_vars = 1.0, tau_vars = -0.08478602066524987\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.24255680290502335\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.09977210986088234\n",
      "*** 於第[7]天進貨 ***\n",
      "\n",
      "f_vars[i]: 4.6967, F_vars[i]: 0.9910, Q0_vars[i]: 2685.8377\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.2808662354511041\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -64.9321786679433\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.08593397819048393\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -15.551875705821526\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -15.551875705821526\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.105796120350788\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.2707146447447232\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = -0.04820936250664765\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 3.1040, F_vars[i]: 0.9571, Q0_vars[i]: 2593.9579\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.1019530329894387\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -21.83526987846855\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.14221602546111328\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -18.281647947326366\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -18.281647947326366\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.10195303298943859\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = -0.1009530329894388\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.2264578594453233\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "f_vars[i]: 4.8196, F_vars[i]: 0.9920, Q0_vars[i]: 2688.6499\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.27302026326105144\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -63.81785172025931\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.08928718301638389\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -15.69091475674307\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -15.69091475674307\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.10755002586495377\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.26329876292857657\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = -0.053920952048710794\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 3.1387, F_vars[i]: 0.9585, Q0_vars[i]: 2597.7683\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.2445040290610262\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -51.20695882052536\n",
      "第 4 天補貨策略: R_vars = 1.0, tau_vars = -0.09170589917232397\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -15.982911808400267\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -15.982911808400267\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.09270589917232397\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.23602824855647087\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.09791604205634762\n",
      "*** 於第[4]天進貨 ***\n",
      "\n",
      "f_vars[i]: 5.0014, F_vars[i]: 0.9933, Q0_vars[i]: 2692.2328\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.2027744557324802\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -50.14461355079874\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.11509075818206338\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -16.84362585330482\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -16.84362585330482\n",
      "第 7 天補貨策略: R_vars = 1.0, tau_vars = -0.11409075818206342\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.19676652714304776\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.1150907581820634\n",
      "*** 於第[7]天進貨 ***\n",
      "\n",
      "f_vars[i]: 5.8624, F_vars[i]: 0.9972, Q0_vars[i]: 2702.6601\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 1.0, tau_vars = -0.06810054140471455\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -25.992486688450356\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.16691369420678265\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -19.104966149239676\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -19.104966149239676\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.1317411958200151\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.06928866042010862\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.2267677187197699\n",
      "*** 於第[2]天進貨 ***\n",
      "\n",
      "f_vars[i]: 2.6341, F_vars[i]: 0.9330, Q0_vars[i]: 2528.8144\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.2721693189030798\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -54.84934796067435\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.07955509222451462\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -15.485506378965306\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -15.485506378965306\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.08581072799571476\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.262166384015853\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = -0.07855509222451466\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 8.4867, F_vars[i]: 0.9998, Q0_vars[i]: 2709.7890\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 1.0, tau_vars = -0.07914648648123779\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -38.81724988106819\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.17503670047752456\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -19.18972453749402\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -19.18972453749402\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.15717064966714311\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.0801464864812379\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.18817523421817503\n",
      "*** 於第[2]天進貨 ***\n",
      "\n",
      "f_vars[i]: 7.3770, F_vars[i]: 0.9994, Q0_vars[i]: 2708.6535\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.301928175263965\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -80.03627588027237\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.09075403430320717\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -15.480492039469816\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -15.480492039469816\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.13111023836139157\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.2910711930890244\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 4.4407, F_vars[i]: 0.9883, Q0_vars[i]: 2678.7703\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 1.0, tau_vars = -0.01114182455942596\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -8.591766872079091\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.18063202125999672\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -19.88229732506698\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -19.88229732506698\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.12139555749181807\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.015106965733983402\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.29350435311153605\n",
      "*** 於第[2]天進貨 ***\n",
      "\n",
      "f_vars[i]: 6.9284, F_vars[i]: 0.9990, Q0_vars[i]: 2707.6953\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.18380241542922593\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -54.00795987520516\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.1306819720852635\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -17.34325600823851\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -17.34325600823851\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.13458591998643343\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.17907764420231376\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = -0.11110210152051367\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 2.8223, F_vars[i]: 0.9439, Q0_vars[i]: 2558.2089\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.0010000000000000009\n",
      "第 3 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.1768062264169174\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -19.883805440951686\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -19.883805440951686\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.10593750616013897\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.005255901927645912\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.320297812502624\n",
      "*** 於第[3]天進貨 ***\n",
      "\n",
      "f_vars[i]: 7.4114, F_vars[i]: 0.9994, Q0_vars[i]: 2708.7108\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.14463651803179556\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -47.92013325394555\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.14682128360297458\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -18.02422759872523\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -18.02422759872523\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.14203921457885516\n",
      "第 8 天補貨策略: R_vars = 0.0, tau_vars = -0.14203921457885538\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = -0.14103921457885515\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 10.7326, F_vars[i]: 1.0000, Q0_vars[i]: 2710.2886\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 0.0, tau_vars = -0.12364221234005202\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -56.978632496095315\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.1695325228992695\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -18.69631789699151\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -18.69631789699151\n",
      "第 7 天補貨策略: R_vars = 0.0, tau_vars = -0.17657486840935732\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = -0.12264221234005213\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.12364221234005211\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "all_Rs: [7, 9, 8, 9, 4, 7, 2, 9, 2, 9, 2, 9, 3, 9, 8]\n",
      "Fold 2 Q_star: 2710.3477149122873\n",
      "baseline_profit: -420569.42922120873\n",
      "f_vars[i]: -1.656094761734997, F_vars[i]: 0.16028692552435955\n",
      "f_vars[i]: -1.6420124370213, F_vars[i]: 0.162191415912825\n",
      "f_vars[i]: -1.663072196784406, F_vars[i]: 0.15935002203296658\n",
      "f_vars[i]: -1.6854186235520516, F_vars[i]: 0.15637928628463543\n",
      "f_vars[i]: -1.6110681006352754, F_vars[i]: 0.16644037465502934\n",
      "f_vars[i]: -1.6765814094631244, F_vars[i]: 0.15754867745204193\n",
      "f_vars[i]: -1.613729282957963, F_vars[i]: 0.16607149526318524\n",
      "f_vars[i]: -1.6514045733757479, F_vars[i]: 0.1609192078212376\n",
      "f_vars[i]: -1.6724089201647572, F_vars[i]: 0.15810327146232103\n",
      "f_vars[i]: -1.6379645127007354, F_vars[i]: 0.16274222200159472\n",
      "f_vars[i]: -1.6655562698705528, F_vars[i]: 0.15901754309718152\n",
      "f_vars[i]: -1.6205025079777309, F_vars[i]: 0.1651355798579787\n",
      "f_vars[i]: -1.6409700572308479, F_vars[i]: 0.16233310994760583\n",
      "f_vars[i]: -1.5963361179798445, F_vars[i]: 0.16849431602561893\n",
      "f_vars[i]: -1.6442967185162907, F_vars[i]: 0.16188125496888323\n",
      "assigned_R: 6\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 210 rows, 435 columns and 945 nonzeros\n",
      "Model fingerprint: 0xe6d3a85c\n",
      "Model has 105 general constraints\n",
      "Variable types: 315 continuous, 120 integer (120 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Presolve removed 199 rows and 413 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 11 rows, 22 columns, 59 nonzeros\n",
      "Presolved model has 3 SOS constraint(s)\n",
      "Variable types: 11 continuous, 11 integer (11 binary)\n",
      "\n",
      "Root relaxation: objective 5.972127e+06, 4 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0    5972126.9107 5972126.91 -0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (4 simplex iterations) in 0.02 seconds (0.01 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 5.97213e+06 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 5.972126910693e+06, best bound 5.972126910693e+06, gap 0.0000%\n",
      "\n",
      "model.status is optimal: True\n",
      "model.status is TIME_LIMIT: False\n",
      "\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 1.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 1.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = 1.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = -0.0\n",
      "第 2 天補貨策略: R_vars = 1.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "tau: [ 1.62569500e-02  1.46780649e+02 -1.94914797e-02 -1.65928448e+01\n",
      " -1.65928448e+01  2.47936241e-01  1.64069838e-02 -7.24606467e-01]\n",
      "R: [0 1 0 0 0 0 0 0]\n",
      "max_r_index: 1\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 1.24299193e-01  1.68963823e+02 -5.78633609e-02 -1.83370519e+01\n",
      " -1.83370519e+01  2.40733792e-01  1.18780284e-01 -8.21818578e-01]\n",
      "R: [0 1 0 0 0 0 0 0]\n",
      "max_r_index: 1\n",
      "\n",
      "\n",
      "\n",
      "tau: [-4.16432079e-02  1.34857697e+02  1.03227469e-03 -1.56589893e+01\n",
      " -1.56589893e+01  2.51709494e-01 -3.84564655e-02 -6.72415417e-01]\n",
      "R: [0 1 0 0 0 0 0 0]\n",
      "max_r_index: 1\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 1.43800481e-01  1.75786370e+02 -6.15732052e-02 -1.85816360e+01\n",
      " -1.85816360e+01  2.46419755e-01  1.37362860e-01 -8.47015305e-01]\n",
      "R: [0 1 0 0 0 0 0 0]\n",
      "max_r_index: 1\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 2.79489970e-03  1.41146958e+02 -1.79848370e-02 -1.64470305e+01\n",
      " -1.64470305e+01  2.41720984e-01  3.54487266e-03 -7.04704861e-01]\n",
      "R: [0 1 0 0 0 0 0 0]\n",
      "max_r_index: 1\n",
      "\n",
      "\n",
      "\n",
      "tau: [-2.42316404e-02  1.39400529e+02 -4.04711572e-03 -1.59159568e+01\n",
      " -1.59159568e+01  2.52947785e-01 -2.19225869e-02 -6.90708764e-01]\n",
      "R: [0 1 0 0 0 0 0 0]\n",
      "max_r_index: 1\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 9.62190977e-02  1.61238970e+02 -5.01264196e-02 -1.79325647e+01\n",
      " -1.79325647e+01  2.37749034e-01  9.21008830e-02 -7.91234762e-01]\n",
      "R: [0 1 0 0 0 0 0 0]\n",
      "max_r_index: 1\n",
      "\n",
      "\n",
      "\n",
      "tau: [-7.77865539e-02  1.26432067e+02  1.27223816e-02 -1.51005377e+01\n",
      " -1.51005377e+01  2.51628711e-01 -7.27406366e-02 -6.37168074e-01]\n",
      "R: [0 1 0 0 0 0 0 0]\n",
      "max_r_index: 1\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 1.77867173e-01  1.82255257e+02 -7.42720271e-02 -1.91447001e+01\n",
      " -1.91447001e+01  2.42845855e-01  1.69622591e-01 -8.76240369e-01]\n",
      "R: [0 1 0 0 0 0 0 0]\n",
      "max_r_index: 1\n",
      "\n",
      "\n",
      "\n",
      "tau: [-8.39081570e-02  1.24301795e+02  1.38999123e-02 -1.50234774e+01\n",
      " -1.50234774e+01  2.49872043e-01 -7.85734271e-02 -6.29289510e-01]\n",
      "R: [0 1 0 0 0 0 0 0]\n",
      "max_r_index: 1\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 1.29819704e-01  1.71585661e+02 -5.81256736e-02 -1.83890827e+01\n",
      " -1.83890827e+01  2.44054807e-01  1.24066325e-01 -8.30825515e-01]\n",
      "R: [0 1 0 0 0 0 0 0]\n",
      "max_r_index: 1\n",
      "\n",
      "\n",
      "\n",
      "tau: [-2.38358767e-03  1.40621037e+02 -1.55325421e-02 -1.63500399e+01\n",
      " -1.63500399e+01  2.43397993e-01 -1.34197652e-03 -7.01503891e-01]\n",
      "R: [0 1 0 0 0 0 0 0]\n",
      "max_r_index: 1\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 1.45455373e-01  1.73412808e+02 -6.52570589e-02 -1.86759701e+01\n",
      " -1.86759701e+01  2.39584223e-01  1.38830306e-01 -8.41139633e-01]\n",
      "R: [0 1 0 0 0 0 0 0]\n",
      "max_r_index: 1\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 2.12358784e-01  1.84946354e+02 -9.15320276e-02 -1.98109427e+01\n",
      " -1.98109427e+01  2.29663867e-01  2.02141625e-01 -8.95357109e-01]\n",
      "R: [0 1 0 0 0 0 0 0]\n",
      "max_r_index: 1\n",
      "\n",
      "\n",
      "\n",
      "tau: [-6.76756890e-03  1.41145459e+02 -1.23500486e-02 -1.62437657e+01\n",
      " -1.62437657e+01  2.47221063e-01 -5.44310814e-03 -7.01425906e-01]\n",
      "R: [0 1 0 0 0 0 0 0]\n",
      "max_r_index: 1\n",
      "\n",
      "\n",
      "\n",
      "===== Processing Fold 3 =====\n",
      "mean of sum: 2825.330566520376\n",
      "std of sum: 120.7948325515889\n",
      "60.0 percentile of sum: 2855.933587421095\n",
      "Fold 3 Q_star: 2855.933587421095\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=0 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0x7c7e00e0\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [3e+02, 3e+03]\n",
      "Presolve removed 62 rows and 97 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 231 rows, 167 columns, 612 nonzeros\n",
      "Presolved model has 41 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 126 continuous, 41 integer (41 binary)\n",
      "\n",
      "Root relaxation: objective 2.533262e+07, 85 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5333e+07    0   21          - 2.5333e+07      -     -    0s\n",
      "H    0     0                    2.524373e+07 2.5333e+07  0.35%     -    0s\n",
      "\n",
      "Explored 1 nodes (85 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.52437e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.524373243406e+07, best bound 2.533261583285e+07, gap 0.3521%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1144.0301924086202, Left1: 36.98013902744424\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1147.2146401786881, Left1: 17.658839232383343\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 23.95013703959512, Left0: 1147.1565240677305, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1145.2760988103475, Left1: 1.1929361545380743\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 18.528398860166362, Left0: 1158.1720475343188, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 27.037615877432472, Left0: 1135.8255066678205, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 10.330585983076162, Left0: 1159.671523872997, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1153.6823448104933, Left1: 5.711934684320568\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1132.405117791089, Left1: 18.63196479163662\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1136.3940269564055, Left1: 9.624653434906463\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1138.6077483185654, Left1: 35.72398762633202\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1168.8809024505395, Left1: 24.802197373810486\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 9.196225102519747, Left0: 1133.2631837868332, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1139.7578512715843, Left1: 24.290380924166584\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 6.286913241360708, Left0: 1129.9952670164112, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=1 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27336/2267964258.py:74: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27336/4060423289.py:107: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27336/3802425588.py:90: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27336/3639980328.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sd_Y = np.sqrt(var_Y)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27336/3639980328.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sd_Y = np.sqrt(var_Y)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27336/3639980328.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sd_Y = np.sqrt(var_Y)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27336/3639980328.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sd_Y = np.sqrt(var_Y)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27336/3639980328.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sd_Y = np.sqrt(var_Y)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27336/3639980328.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sd_Y = np.sqrt(var_Y)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27336/3639980328.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sd_Y = np.sqrt(var_Y)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27336/3639980328.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sd_Y = np.sqrt(var_Y)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27336/3639980328.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sd_Y = np.sqrt(var_Y)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27336/3639980328.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sd_Y = np.sqrt(var_Y)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27336/3639980328.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sd_Y = np.sqrt(var_Y)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27336/3639980328.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sd_Y = np.sqrt(var_Y)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27336/3639980328.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sd_Y = np.sqrt(var_Y)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27336/3639980328.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sd_Y = np.sqrt(var_Y)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27336/3639980328.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sd_Y = np.sqrt(var_Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0x3d42e3d0\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [5e+02, 2e+03]\n",
      "Presolve removed 55 rows and 83 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 238 rows, 181 columns, 635 nonzeros\n",
      "Presolved model has 47 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 134 continuous, 47 integer (47 binary)\n",
      "\n",
      "Root relaxation: objective 2.540762e+07, 89 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5408e+07    0   25          - 2.5408e+07      -     -    0s\n",
      "H    0     0                    2.538804e+07 2.5408e+07  0.08%     -    0s\n",
      "\n",
      "Explored 1 nodes (89 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.5388e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.538804436055e+07, best bound 2.540761695120e+07, gap 0.0771%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 864.4865541859278, Left1: 1.3320266561004246\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 868.4983776614915, Left1: 4.179683795642177\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.494361096698867, Left0: 864.4964830017955, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 862.6709352896246, Left1: 3.807774725669333\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 886.6011257255556, Left1: 6.702636206273837\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.845951177695952, Left0: 840.99817687566, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 891.2934302117237, Left1: 0.8369143515910764\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 8.565508626538758, Left0: 881.8890984342389, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 837.8089499887839, Left1: 7.223925849980674\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 2.422123780279776, Left0: 846.0843275265487, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.5955094169944459, Left0: 853.4133191802168, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 913.8695579373602, Left1: 4.161348693608943\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.6376606011212971, Left0: 837.2890530897555, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 854.0457861906891, Left1: 3.1138721000688747\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 830.0529166697116, Left1: 6.785318866206467\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=2 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0x9b436c22\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [8e+02, 2e+03]\n",
      "Presolve removed 55 rows and 83 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 238 rows, 181 columns, 635 nonzeros\n",
      "Presolved model has 47 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 134 continuous, 47 integer (47 binary)\n",
      "\n",
      "Root relaxation: objective 2.540750e+07, 88 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5407e+07    0   25          - 2.5407e+07      -     -    0s\n",
      "H    0     0                    2.538780e+07 2.5407e+07  0.08%     -    0s\n",
      "\n",
      "Explored 1 nodes (88 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.53878e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.538779517723e+07, best bound 2.540749947467e+07, gap 0.0776%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 579.4091854544656, Left1: 1.68947841768113\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 583.9436705857113, Left1: 4.8213623977098905\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.8577910975725445, Left0: 582.7030768508378, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 578.1691287192477, Left1: 3.813188306363827\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 616.030079611496, Left1: 6.410200259288558\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.772083398577934, Left0: 544.6343068433034, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 619.0042413332005, Left1: 1.3892546520169162\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 8.244358266108293, Left0: 605.9973084332223, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 542.4627819542546, Left1: 6.809544179941099\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.163746740711872, Left0: 556.746526959222, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.26522495544145386, Left0: 562.6602909033318, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 658.8280233034043, Left1: 3.6910013991214328\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.43514190700898325, Left0: 538.4152603818297, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 568.7419324855722, Left1: 2.413551467104867\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 526.2879501025548, Left1: 7.197183447751286\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=3 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0xc60b9deb\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 2e+03]\n",
      "Presolve removed 52 rows and 65 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 241 rows, 199 columns, 647 nonzeros\n",
      "Presolved model has 62 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 137 continuous, 62 integer (62 binary)\n",
      "\n",
      "Root relaxation: objective 2.540750e+07, 97 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5407e+07    0   27          - 2.5407e+07      -     -    0s\n",
      "H    0     0                    2.538780e+07 2.5407e+07  0.08%     -    0s\n",
      "\n",
      "Explored 1 nodes (97 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.53878e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.538779517814e+07, best bound 2.540749947535e+07, gap 0.0776%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 299.86554739244843, Left1: 1.6894780642987826\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 305.227408142747, Left1: 4.821362451086316\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.8577912144401125, Left0: 300.0430358585686, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 295.5639652290297, Left1: 3.8131884187764626\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 344.45915784976887, Left1: 6.410200437845106\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.7720833550229145, Left0: 249.8069770529553, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 350.6261478289755, Left1: 1.3892544946247654\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 8.24435831686128, Left0: 334.2040621734052, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 247.86661418351878, Left1: 6.8095440614731615\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.1637465616656755, Left0: 266.4368275001914, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.26522452100493865, Left0: 277.46586172172465, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 403.81667892813675, Left1: 3.691001444572521\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.43514184545324497, Left0: 242.44112968216905, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 283.02986749600404, Left1: 2.413551206114107\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 226.34559978329753, Left1: 7.197183336380476\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=4 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0xa5ed6f9b\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 1e+03]\n",
      "Presolve removed 56 rows and 73 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 237 rows, 191 columns, 639 nonzeros\n",
      "Presolved model has 58 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 133 continuous, 58 integer (58 binary)\n",
      "\n",
      "Root relaxation: objective 2.541313e+07, 91 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5413e+07    0   25          - 2.5413e+07      -     -    0s\n",
      "H    0     0                    2.501788e+07 2.5413e+07  1.58%     -    0s\n",
      "     0     2 2.5413e+07    0   27 2.5018e+07 2.5413e+07  1.58%     -    0s\n",
      "H   36    22                    2.540086e+07 2.5409e+07  0.03%  10.6    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Cover: 1\n",
      "  Implied bound: 9\n",
      "\n",
      "Explored 47 nodes (519 simplex iterations) in 0.03 seconds (0.03 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 2.54009e+07 2.50179e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.540086165798e+07, best bound 2.540907229301e+07, gap 0.0323%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0442706266182995, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -0.0321, F_vars[i]: 0.4920, Q0_vars[i]: 1405.0329\n",
      "f_train: -0.032123847918444026, F_train: 0.49196972857277776, Q0_train: 1405.0328718254357\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.081484115484246, Left1: 3.9735896354927718\n",
      "f_vars[i]: -0.0268, F_vars[i]: 0.4933, Q0_vars[i]: 1408.8408\n",
      "f_train: -0.026789362055680055, F_train: 0.49330305999732205, Q0_train: 1408.8407778239557\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 0.2542948950626851\n",
      "f_vars[i]: -0.0225, F_vars[i]: 0.4944, Q0_vars[i]: 1411.8905\n",
      "f_train: -0.02251727824615979, F_train: 0.4943709182782028, Q0_train: 1411.8905101549287\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.764879186039707, Left1: 1.4142064545967514\n",
      "f_vars[i]: -0.0078, F_vars[i]: 0.4981, Q0_vars[i]: 1422.4309\n",
      "f_train: -0.007753553922643652, F_train: 0.4980616212302191, Q0_train: 1422.4309126767862\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 25.73120573232177, Left1: 2.2199238035420876\n",
      "f_vars[i]: -0.0707, F_vars[i]: 0.4823, Q0_vars[i]: 1377.4969\n",
      "f_train: -0.07071726002291134, F_train: 0.48232804906424753, Q0_train: 1377.4968754778745\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 6.14495849748483, Left1: 1.208751934558677\n",
      "f_vars[i]: 0.0756, F_vars[i]: 0.5189, Q0_vars[i]: 1481.9412\n",
      "f_train: 0.07563218315967224, F_train: 0.5188990377496455, Q0_train: 1481.9411903896994\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 31.890054445462813, Left1: 1.0641162352530955\n",
      "f_vars[i]: -0.0724, F_vars[i]: 0.4819, Q0_vars[i]: 1376.2922\n",
      "f_train: -0.07240663864936203, F_train: 0.4819062446900743, Q0_train: 1376.292230198352\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 6.797781953293452, Left0: 18.0125701842548, Left1: 0.0\n",
      "f_vars[i]: -0.0633, F_vars[i]: 0.4842, Q0_vars[i]: 1382.7827\n",
      "f_train: -0.06330559620413179, F_train: 0.48417888431938677, Q0_train: 1382.7827380478097\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.980679405658884, Left1: 7.57986390964993\n",
      "f_vars[i]: 0.0715, F_vars[i]: 0.5179, Q0_vars[i]: 1478.9823\n",
      "f_train: 0.07148234237746265, F_train: 0.5178629799986897, Q0_train: 1478.9822782602366\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 5.026929325021456, Left0: 21.867347607356802, Left1: 0.0\n",
      "f_vars[i]: 0.0608, F_vars[i]: 0.5152, Q0_vars[i]: 1471.3772\n",
      "f_train: 0.0608189783600086, F_train: 0.5152000595261795, Q0_train: 1471.3771542421637\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 2.601641160733152\n",
      "f_vars[i]: 0.0108, F_vars[i]: 0.5027, Q0_vars[i]: 1435.6669\n",
      "f_train: 0.010784810222653318, F_train: 0.5026961764225452, Q0_train: 1435.6668945133072\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 21.85560591878084, Left1: 3.9287458972503373\n",
      "f_vars[i]: -0.1815, F_vars[i]: 0.4548, Q0_vars[i]: 1298.7591\n",
      "f_train: -0.18146370864474792, F_train: 0.4547581524499312, Q0_train: 1298.7590817353212\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.7437060145430223, Left0: 23.385195898975805, Left1: 0.0\n",
      "f_vars[i]: 0.1061, F_vars[i]: 0.5265, Q0_vars[i]: 1503.6600\n",
      "f_train: 0.10611484966197593, F_train: 0.5265038468407276, Q0_train: 1503.660020098846\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 21.09474529472054, Left1: 0.6543544472428948\n",
      "f_vars[i]: 0.0297, F_vars[i]: 0.5074, Q0_vars[i]: 1449.1987\n",
      "f_train: 0.02973949199711834, F_train: 0.5074343250744378, Q0_train: 1449.1987323904411\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 8.966909915220242, Left1: 2.0456162854748072\n",
      "f_vars[i]: 0.1115, F_vars[i]: 0.5279, Q0_vars[i]: 1507.5168\n",
      "f_train: 0.11153262776633999, F_train: 0.5278542884117062, Q0_train: 1507.5167915392535\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=5 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0x29cda3b0\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 2e+03]\n",
      "Presolve removed 56 rows and 73 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 237 rows, 191 columns, 639 nonzeros\n",
      "Presolved model has 58 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 133 continuous, 58 integer (58 binary)\n",
      "\n",
      "Root relaxation: objective 2.541313e+07, 91 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5413e+07    0   25          - 2.5413e+07      -     -    0s\n",
      "H    0     0                    1.898036e+07 2.5413e+07  33.9%     -    0s\n",
      "     0     2 2.5413e+07    0   23 1.8980e+07 2.5413e+07  33.9%     -    0s\n",
      "H   11     8                    2.540086e+07 2.5410e+07  0.04%   3.9    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 7\n",
      "\n",
      "Explored 15 nodes (154 simplex iterations) in 0.02 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 2.54009e+07 1.89804e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.540086165029e+07, best bound 2.540907229446e+07, gap 0.0323%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.04427070108886255, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 0.3634, F_vars[i]: 0.5899, Q0_vars[i]: 1684.5765\n",
      "f_train: 0.363351188895233, F_train: 0.5898514196403374, Q0_train: 1684.5764809388545\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.126535630824947, Left1: 3.973589645122729\n",
      "f_vars[i]: 0.3677, F_vars[i]: 0.5909, Q0_vars[i]: 1687.6021\n",
      "f_train: 0.3677319411655908, F_train: 0.5909108219858813, Q0_train: 1687.602063680086\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 0.25429486149232616\n",
      "f_vars[i]: 0.3778, F_vars[i]: 0.5933, Q0_vars[i]: 1694.5505\n",
      "f_train: 0.37780593320713596, F_train: 0.5933438118998666, Q0_train: 1694.5505212932935\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.81405485966502, Left1: 1.414206508322195\n",
      "f_vars[i]: 0.3931, F_vars[i]: 0.5970, Q0_vars[i]: 1705.0852\n",
      "f_train: 0.3931157152912994, F_train: 0.5970325187783241, Q0_train: 1705.0852231616313\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 25.437526863424935, Left1: 2.2199238678498006\n",
      "f_vars[i]: 0.3118, F_vars[i]: 0.5773, Q0_vars[i]: 1648.7741\n",
      "f_train: 0.311761959967491, F_train: 0.5773152772085405, Q0_train: 1648.774090711191\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.365821076855861, Left1: 1.2087519381427683\n",
      "f_vars[i]: 0.4974, F_vars[i]: 0.6219, Q0_vars[i]: 1775.9894\n",
      "f_train: 0.4974482463139913, F_train: 0.6218594724910351, Q0_train: 1775.9893541431118\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 31.593009645905795, Left1: 1.0641161758576345\n",
      "f_vars[i]: 0.3055, F_vars[i]: 0.5758, Q0_vars[i]: 1644.3733\n",
      "f_train: 0.30545024867741066, F_train: 0.5757743317472364, Q0_train: 1644.3732528118685\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 6.797781960631028, Left0: 17.811721518430204, Left1: 0.0\n",
      "f_vars[i]: 0.3198, F_vars[i]: 0.5793, Q0_vars[i]: 1654.3751\n",
      "f_train: 0.31980391286927423, F_train: 0.5792764634691976, Q0_train: 1654.3751084241903\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.263806064464848, Left1: 7.579863854253517\n",
      "f_vars[i]: 0.4928, F_vars[i]: 0.6208, Q0_vars[i]: 1772.8615\n",
      "f_train: 0.49279344455638396, F_train: 0.620764275352724, Q0_train: 1772.8615438509617\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 5.026929269582297, Left0: 21.437976405605806, Left1: 0.0\n",
      "f_vars[i]: 0.4756, F_vars[i]: 0.6167, Q0_vars[i]: 1761.2575\n",
      "f_train: 0.4755694670540622, F_train: 0.6167011245690621, Q0_train: 1761.2574550571453\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 2.6016412696092175\n",
      "f_vars[i]: 0.4161, F_vars[i]: 0.6026, Q0_vars[i]: 1720.8613\n",
      "f_train: 0.4161285758318165, F_train: 0.6025564819327652, Q0_train: 1720.8612950700765\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 19.072250252164167, Left1: 3.928745897847307\n",
      "f_vars[i]: 0.1727, F_vars[i]: 0.5431, Q0_vars[i]: 1550.9870\n",
      "f_train: 0.1727294527929859, F_train: 0.5430753187392917, Q0_train: 1550.98704328696\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.7437060246500096, Left0: 22.08212219576034, Left1: 0.0\n",
      "f_vars[i]: 0.5309, F_vars[i]: 0.6297, Q0_vars[i]: 1798.3311\n",
      "f_train: 0.5308544513260709, F_train: 0.6296823771154634, Q0_train: 1798.3310502112083\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 21.032144819721783, Left1: 0.654354382480733\n",
      "f_vars[i]: 0.4366, F_vars[i]: 0.6075, Q0_vars[i]: 1734.8482\n",
      "f_train: 0.4366225599781739, F_train: 0.607453960798842, Q0_train: 1734.84816945739\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.355003091592702, Left1: 2.045616279306614\n",
      "f_vars[i]: 0.5422, F_vars[i]: 0.6323, Q0_vars[i]: 1805.8472\n",
      "f_train: 0.5421574199379702, F_train: 0.6323141457254511, Q0_train: 1805.8472065787926\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=6 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0x61b0fa0c\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [8e+02, 2e+03]\n",
      "Presolve removed 53 rows and 91 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 240 rows, 173 columns, 650 nonzeros\n",
      "Presolved model has 37 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 136 continuous, 37 integer (37 binary)\n",
      "\n",
      "Root relaxation: objective 2.541692e+07, 87 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5417e+07    0   21          - 2.5417e+07      -     -    0s\n",
      "H    0     0                    1.223711e+07 2.5416e+07   108%     -    0s\n",
      "     0     2 2.5416e+07    0   21 1.2237e+07 2.5416e+07   108%     -    0s\n",
      "H   63    74                    2.527288e+07 2.5414e+07  0.56%   4.3    0s\n",
      "\n",
      "Explored 87 nodes (445 simplex iterations) in 0.04 seconds (0.03 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 2.52729e+07 1.22371e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.527288392557e+07, best bound 2.541428588554e+07, gap 0.5595%\n",
      "Model status: 2\n",
      "Lost0: 8.78183542565577, Lost1: 0.0, Left0: 0.0, Left1: 11.536860989102479\n",
      "f_vars[i]: 0.7752, F_vars[i]: 0.6846, Q0_vars[i]: 1955.2907\n",
      "f_train: 0.7751852996363833, F_train: 0.6846415092758438, Q0_train: 1955.2906816835534\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.8845924019144604, Lost1: 0.0, Left0: 0.0, Left1: 4.644939883719871\n",
      "f_vars[i]: 0.7628, F_vars[i]: 0.6820, Q0_vars[i]: 1947.6109\n",
      "f_train: 0.7627590178826651, F_train: 0.6819524464822724, Q0_train: 1947.6108969327086\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 1.303397792219016\n",
      "f_vars[i]: 0.8133, F_vars[i]: 0.6928, Q0_vars[i]: 1978.6236\n",
      "f_train: 0.813296317509729, F_train: 0.6928114844147251, Q0_train: 1978.62358809108\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.6891160780118687, Lost1: 0.0, Left0: 0.0, Left1: 1.6097578430203612\n",
      "f_vars[i]: 0.8083, F_vars[i]: 0.6917, Q0_vars[i]: 1975.5558\n",
      "f_train: 0.8082538933002419, F_train: 0.6917372947875802, Q0_train: 1975.5557738556574\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 2.9510728650883493\n",
      "f_vars[i]: 0.6818, F_vars[i]: 0.6641, Q0_vars[i]: 1896.7335\n",
      "f_train: 0.6817887720292481, F_train: 0.6641378157830808, Q0_train: 1896.7334947713846\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 5.146342113285126, Lost1: 0.0, Left0: 0.0, Left1: 4.862354013043213\n",
      "f_vars[i]: 0.9443, F_vars[i]: 0.7200, Q0_vars[i]: 2056.2022\n",
      "f_train: 0.9443401292512692, F_train: 0.7199755090602376, Q0_train: 2056.202238445733\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 6.810647606232111, Lost1: 0.0, Left0: 0.0, Left1: 7.191006168422973\n",
      "f_vars[i]: 0.6404, F_vars[i]: 0.6548, Q0_vars[i]: 1870.1626\n",
      "f_train: 0.6403565655308845, F_train: 0.654834058283584, Q0_train: 1870.1625812393504\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 10.61396159246895, Lost1: 0.0, Left0: 0.0, Left1: 5.846958419859675\n",
      "f_vars[i]: 0.6825, F_vars[i]: 0.6643, Q0_vars[i]: 1897.2111\n",
      "f_train: 0.6825386110466161, F_train: 0.6643050533666385, Q0_train: 1897.211114203346\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 7.396487331963272, Lost1: 0.0, Left0: 0.0, Left1: 14.118112711865733\n",
      "f_vars[i]: 0.9425, F_vars[i]: 0.7196, Q0_vars[i]: 2055.1535\n",
      "f_train: 0.9425194032043285, F_train: 0.7196082840923861, Q0_train: 2055.153468325907\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 11.876938585234939, Lost1: 0.0, Left0: 0.0, Left1: 10.309527911012866\n",
      "f_vars[i]: 0.8894, F_vars[i]: 0.7088, Q0_vars[i]: 2024.1619\n",
      "f_train: 0.889352986021664, F_train: 0.7087566335501074, Q0_train: 2024.1618750632567\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 8.958240683067713, Lost1: 0.0, Left0: 0.0, Left1: 10.777832411609749\n",
      "f_vars[i]: 0.8368, F_vars[i]: 0.6978, Q0_vars[i]: 1992.8612\n",
      "f_train: 0.8368281769654811, F_train: 0.6977967731893838, Q0_train: 1992.861241745621\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 11.623493588401653, Lost1: 0.0, Left0: 0.0, Left1: 13.717002711491432\n",
      "f_vars[i]: 0.4968, F_vars[i]: 0.6217, Q0_vars[i]: 1775.5237\n",
      "f_train: 0.4967549911813749, F_train: 0.621696439593698, Q0_train: 1775.5237430157522\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 11.935993664469091, Lost1: 0.0, Left0: 0.0, Left1: 12.268455059634956\n",
      "f_vars[i]: 0.9505, F_vars[i]: 0.7212, Q0_vars[i]: 2059.7305\n",
      "f_train: 0.9504761680072242, F_train: 0.7212109291723702, Q0_train: 2059.7305162385487\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 3.651982704205693, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 0.8381, F_vars[i]: 0.6981, Q0_vars[i]: 1993.6131\n",
      "f_train: 0.8380769089811597, F_train: 0.6980600362880919, Q0_train: 1993.61310367155\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 3.9426418490852484, Lost1: 0.0, Left0: 0.0, Left1: 3.6532290150513202\n",
      "f_vars[i]: 1.0010, F_vars[i]: 0.7313, Q0_vars[i]: 2088.4156\n",
      "f_train: 1.0009990365699997, F_train: 0.7312549557941651, Q0_train: 2088.415589220684\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=7 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0x7dc4f434\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [5e+02, 2e+03]\n",
      "Presolve removed 53 rows and 90 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 240 rows, 174 columns, 639 nonzeros\n",
      "Presolved model has 38 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 136 continuous, 38 integer (38 binary)\n",
      "Found heuristic solution: objective 2.524514e+07\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.52451e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.524514127959e+07, best bound 2.542797509868e+07, gap 0.7242%\n",
      "Model status: 2\n",
      "Lost0: 10.014793751860907, Lost1: 0.0, Left0: 0.0, Left1: 10.014794055471384\n",
      "f_vars[i]: 1.2735, F_vars[i]: 0.7813, Q0_vars[i]: 2231.4617\n",
      "f_train: 1.2735057752192374, F_train: 0.7813422881235575, Q0_train: 2231.4616839245186\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.19434734856668, Lost1: 0.0, Left0: 0.0, Left1: 2.194347591066048\n",
      "f_vars[i]: 1.2639, F_vars[i]: 0.7797, Q0_vars[i]: 2226.7661\n",
      "f_train: 1.2639080959099358, F_train: 0.7796981310568509, Q0_train: 2226.7660805347155\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 8.019705899363451, Lost1: 0.0, Left0: 0.0, Left1: 8.019706174674411\n",
      "f_vars[i]: 1.3230, F_vars[i]: 0.7897, Q0_vars[i]: 2255.2734\n",
      "f_train: 1.3229970866771303, F_train: 0.7896799114746096, Q0_train: 2255.2733824920547\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.2548893336885874e-06, Lost1: 0.0, Left0: 0.0, Left1: 1.4747593013453297e-06\n",
      "f_vars[i]: 1.3288, F_vars[i]: 0.7906, Q0_vars[i]: 2258.0369\n",
      "f_train: 1.3288332138194239, F_train: 0.7906475691772322, Q0_train: 2258.036948626101\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.8983678273798432e-06, Lost1: 0.0, Left0: 0.0, Left1: 2.1154513092369598e-06\n",
      "f_vars[i]: 1.1406, F_vars[i]: 0.7578, Q0_vars[i]: 2164.1950\n",
      "f_train: 1.1405956301493223, F_train: 0.7577889806308682, Q0_train: 2164.19500196129\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 8.02143225400214, Lost1: 0.0, Left0: 0.0, Left1: 8.021432500755328\n",
      "f_vars[i]: 1.5435, F_vars[i]: 0.8240, Q0_vars[i]: 2353.1973\n",
      "f_train: 1.5434645320255003, F_train: 0.8239678019434487, Q0_train: 2353.197320523828\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 7.374830386837213, Lost1: 0.0, Left0: 0.0, Left1: 7.374830675329463\n",
      "f_vars[i]: 1.0936, F_vars[i]: 0.7491, Q0_vars[i]: 2139.2374\n",
      "f_train: 1.0935527217199956, F_train: 0.7490501317430419, Q0_train: 2139.23742990715\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 19.10624018125054, Lost1: 0.0, Left0: 0.0, Left1: 19.10624044143026\n",
      "f_vars[i]: 1.1471, F_vars[i]: 0.7590, Q0_vars[i]: 2167.6237\n",
      "f_train: 1.1471477127000993, F_train: 0.7589895494625019, Q0_train: 2167.6237468115637\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.9516384752103686, Lost1: 0.0, Left0: 0.0, Left1: 0.951638760791705\n",
      "f_vars[i]: 1.5382, F_vars[i]: 0.8232, Q0_vars[i]: 2351.0334\n",
      "f_train: 1.5382495004756453, F_train: 0.8232101100001037, Q0_train: 2351.0334026539103\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 5.00089999272268, Lost1: 0.0, Left0: 0.0, Left1: 5.00090021878683\n",
      "f_vars[i]: 1.4713, F_vars[i]: 0.8133, Q0_vars[i]: 2322.6115\n",
      "f_train: 1.471321922405397, F_train: 0.81325822857909, Q0_train: 2322.6114902456056\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 9.03290474494483, Lost1: 0.0, Left0: 0.0, Left1: 9.032904927264866\n",
      "f_vars[i]: 1.3747, F_vars[i]: 0.7981, Q0_vars[i]: 2279.4281\n",
      "f_train: 1.374695036554698, F_train: 0.7981376483438661, Q0_train: 2279.428117290534\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 40.103057717502644, Lost1: 0.0, Left0: 0.0, Left1: 40.10305796655007\n",
      "f_vars[i]: 0.8508, F_vars[i]: 0.7007, Q0_vars[i]: 2001.2513\n",
      "f_train: 0.8507980533747093, F_train: 0.7007345255812077, Q0_train: 2001.2512674729578\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.40013623403623, Lost1: 0.0, Left0: 0.0, Left1: 2.400136497735579\n",
      "f_vars[i]: 1.5738, F_vars[i]: 0.8283, Q0_vars[i]: 2365.6326\n",
      "f_train: 1.573781215115587, F_train: 0.8283219824623304, Q0_train: 2365.6325709133966\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.0887470125453547e-06, Lost1: 0.0, Left0: 0.0, Left1: 1.3741884004048188e-06\n",
      "f_vars[i]: 1.3907, F_vars[i]: 0.8007, Q0_vars[i]: 2286.7633\n",
      "f_train: 1.3907129803011866, F_train: 0.8007060420010472, Q0_train: 2286.763279001797\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.0509214115930603, Lost1: 0.0, Left0: 0.0, Left1: 2.0509216658473064\n",
      "f_vars[i]: 1.6337, F_vars[i]: 0.8367, Q0_vars[i]: 2389.5060\n",
      "f_train: 1.6337391391027172, F_train: 0.8366812196993645, Q0_train: 2389.5059973038633\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 210 rows, 435 columns and 945 nonzeros\n",
      "Model fingerprint: 0x854a9da7\n",
      "Model has 105 general constraints\n",
      "Variable types: 315 continuous, 120 integer (120 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Presolve removed 199 rows and 410 columns\n",
      "Presolve time: 0.02s\n",
      "Presolved: 11 rows, 25 columns, 59 nonzeros\n",
      "Presolved model has 6 SOS constraint(s)\n",
      "Variable types: 11 continuous, 14 integer (14 binary)\n",
      "Found heuristic solution: objective 2.541808e+07\n",
      "\n",
      "Root relaxation: interrupted, 7 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0          -    0      2.5418e+07 2.5428e+07  0.04%     -    0s\n",
      "\n",
      "Explored 1 nodes (7 simplex iterations) in 0.03 seconds (0.01 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.54181e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.541808183591e+07, best bound 2.542797509789e+07, gap 0.0389%\n",
      "\n",
      "model.status is optimal: True\n",
      "model.status is TIME_LIMIT: False\n",
      "\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = 1.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = -0.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = -0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = -0.0\n",
      "第 3 天補貨策略: R_vars = -0.0\n",
      "第 4 天補貨策略: R_vars = -0.0\n",
      "第 5 天補貨策略: R_vars = -0.0\n",
      "第 6 天補貨策略: R_vars = -0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = -0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 667 and 669 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 667 and 669 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 435 rows, 741 columns and 1815 nonzeros\n",
      "Model fingerprint: 0x9d5538e7\n",
      "Model has 240 general constraints\n",
      "Variable types: 621 continuous, 120 integer (120 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 5e+06]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e-03, 1e+00]\n",
      "  GenCon coe range [1e+00, 1e+00]\n",
      "Presolve removed 20 rows and 210 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 535 rows, 532 columns, 2040 nonzeros\n",
      "Presolved model has 197 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 334 continuous, 198 integer (198 binary)\n",
      "\n",
      "Root relaxation: objective 2.542798e+07, 263 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5428e+07    0   58          - 2.5428e+07      -     -    0s\n",
      "     0     2 2.5428e+07    0   55          - 2.5428e+07      -     -    0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27336/4060423289.py:107: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27336/3170868990.py:156: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H 2345  1409                    2.327139e+07 2.5428e+07  9.27%   3.6    0s\n",
      "H 2348  1409                    2.329046e+07 2.5428e+07  9.18%   3.6    0s\n",
      "* 2354  1409              93    2.329046e+07 2.5428e+07  9.18%   3.6    0s\n",
      "* 2637  1482             109    2.540179e+07 2.5428e+07  0.10%   3.5    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 4\n",
      "\n",
      "Explored 2972 nodes (10351 simplex iterations) in 0.19 seconds (0.30 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 4: 2.54018e+07 2.32905e+07 2.32905e+07 2.32714e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.540179007870e+07, best bound 2.542797509809e+07, gap 0.1031%\n",
      "\n",
      "model.status is optimal: True\n",
      "model.status is TIME_LIMIT: False\n",
      "\n",
      "f_vars[i]: 3.9833, F_vars[i]: 0.9817, Q0_vars[i]: 2803.7191\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.028796827374656386\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.001\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.012833639438671551\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.01699473984396882\n",
      "第 7 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.0036343982074568426\n",
      "第 9 天補貨策略: R_vars = -0.0, tau_vars = -0.07353817826798781\n",
      "*** 於第[7]天進貨 ***\n",
      "\n",
      "f_vars[i]: 4.0589, F_vars[i]: 0.9830, Q0_vars[i]: 2807.4548\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.016105728371737627\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.03092405726216818\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.0310310195045978\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.016105728371737627\n",
      "第 6 天補貨策略: R_vars = 1.0, tau_vars = -0.015105728371737626\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.029817095019738466\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.03307035604105724\n",
      "第 9 天補貨策略: R_vars = -0.0, tau_vars = -0.04292269801984738\n",
      "*** 於第[6]天進貨 ***\n",
      "\n",
      "f_vars[i]: 4.2957, F_vars[i]: 0.9866, Q0_vars[i]: 2817.5391\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.0461214446430005\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = 0.02250705653084835\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = 0.02250705653084835\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.014534541189790695\n",
      "第 6 天補貨策略: R_vars = 0.0, tau_vars = -0.023757672911077554\n",
      "第 7 天補貨策略: R_vars = 1.0, tau_vars = 0.02350705653084835\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = 0.02250705653084835\n",
      "第 9 天補貨策略: R_vars = -0.0, tau_vars = -0.1059600511796036\n",
      "*** 於第[7]天進貨 ***\n",
      "\n",
      "f_vars[i]: 4.5904, F_vars[i]: 0.9900, Q0_vars[i]: 2827.2397\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.030492143706521202\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.022759215918625304\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.022961786305122873\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.021556645532127567\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.0234614767017417\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.021556645532127567\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = -0.020556645532127566\n",
      "第 9 天補貨策略: R_vars = -0.0, tau_vars = -0.0637097070072441\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "f_vars[i]: 2.9025, F_vars[i]: 0.9480, Q0_vars[i]: 2707.3341\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 1.0, tau_vars = 0.0011406792245581832\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.01903733586560863\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.018847191829213072\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.001862751055087597\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = 0.00014067922455818314\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.018227479902004042\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.03052233552229143\n",
      "第 9 天補貨策略: R_vars = 0.0, tau_vars = -0.02971572843930359\n",
      "*** 於第[2]天進貨 ***\n",
      "\n",
      "f_vars[i]: 6.7342, F_vars[i]: 0.9988, Q0_vars[i]: 2852.5406\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.051529462198198206\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.06786126727879332\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.0686839100494539\n",
      "第 5 天補貨策略: R_vars = 0.0, tau_vars = -0.04981387990909236\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.04944278032735175\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.06603862450813285\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = -0.04844278032735175\n",
      "第 9 天補貨策略: R_vars = -0.0, tau_vars = -0.06328286981283826\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "f_vars[i]: 2.7463, F_vars[i]: 0.9397, Q0_vars[i]: 2683.7358\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 1.0, tau_vars = 0.027256592336475594\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.06760850376450356\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.06752895530780989\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.0039702863254906795\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = 0.007166156641701171\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.06668805222119718\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.08056466141790754\n",
      "第 9 天補貨策略: R_vars = -0.0, tau_vars = 0.026256592336475593\n",
      "*** 於第[2]天進貨 ***\n",
      "\n",
      "f_vars[i]: 3.0600, F_vars[i]: 0.9552, Q0_vars[i]: 2728.0175\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 1.0, tau_vars = 0.006807343126969179\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.03756350335414377\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.03746460457722045\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.005160602639873502\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.00026201389728952584\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.03666240213106711\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.047847549232769376\n",
      "第 9 天補貨策略: R_vars = -0.0, tau_vars = -0.013254742511663808\n",
      "*** 於第[2]天進貨 ***\n",
      "\n",
      "f_vars[i]: 6.6420, F_vars[i]: 0.9987, Q0_vars[i]: 2852.2131\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.05377173621755216\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.059280778083597774\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.06005679303516792\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.048064465897169506\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.048981899997990186\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.05750476313202756\n",
      "第 8 天補貨策略: R_vars = 1.0, tau_vars = -0.04057536753739447\n",
      "第 9 天補貨策略: R_vars = -0.0, tau_vars = -0.07047175095966729\n",
      "*** 於第[8]天進貨 ***\n",
      "\n",
      "f_vars[i]: 6.2636, F_vars[i]: 0.9981, Q0_vars[i]: 2850.5052\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.027325669080289994\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.09927289943122397\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.10008350650664688\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.046929205103870664\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.03964955422462513\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.09746229235580096\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.08380693614062676\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = -0.018759536640111096\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 5.0621, F_vars[i]: 0.9937, Q0_vars[i]: 2837.9629\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.03405292089701373\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.034936514641451526\n",
      "第 4 天補貨策略: R_vars = 0.0, tau_vars = -0.03528229125309051\n",
      "第 5 天補貨策略: R_vars = 1.0, tau_vars = -0.027955260284527432\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.028955260284527433\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.03359073802981243\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.028955260284527433\n",
      "第 9 天補貨策略: R_vars = -0.0, tau_vars = -0.06118236555137868\n",
      "*** 於第[5]天進貨 ***\n",
      "\n",
      "f_vars[i]: 0.0426, F_vars[i]: 0.5107, Q0_vars[i]: 1458.3943\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = 0.031933488820151235\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = 0.03536870972454831\n",
      "第 4 天補貨策略: R_vars = 1.0, tau_vars = 0.03636870972454831\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = 0.03536870972454831\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = 0.03536870972454831\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = 0.03536870972454831\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = 0.0008942372841568916\n",
      "第 9 天補貨策略: R_vars = -0.0, tau_vars = -0.02406628566453073\n",
      "*** 於第[4]天進貨 ***\n",
      "\n",
      "f_vars[i]: 7.3909, F_vars[i]: 0.9994, Q0_vars[i]: 2854.1730\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.03025096538864802\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.14015045350534439\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.14133865027726555\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.06316577528537293\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.05161186121764216\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.13796225673342316\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.11570411461487617\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = 0.0\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 5.4629, F_vars[i]: 0.9958, Q0_vars[i]: 2843.8723\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = -0.0, tau_vars = -0.019116600854400367\n",
      "第 3 天補貨策略: R_vars = -0.0, tau_vars = -0.0831714465237629\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.08375270501676668\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.03643558018820858\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.02987270582092616\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.08159018803075901\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.07413827013806623\n",
      "第 9 天補貨策略: R_vars = 1.0, tau_vars = -0.018116600854400366\n",
      "*** 於第[9]天進貨 ***\n",
      "\n",
      "f_vars[i]: 7.6516, F_vars[i]: 0.9995, Q0_vars[i]: 2854.5769\n",
      "f_train, F_train, Q0_train 都相等\n",
      "第 2 天補貨策略: R_vars = 1.0, tau_vars = -0.05930415105322917\n",
      "第 3 天補貨策略: R_vars = 0.0, tau_vars = -0.08974988473233392\n",
      "第 4 天補貨策略: R_vars = -0.0, tau_vars = -0.09084563900721276\n",
      "第 5 天補貨策略: R_vars = -0.0, tau_vars = -0.0621134017736098\n",
      "第 6 天補貨策略: R_vars = -0.0, tau_vars = -0.06030415105322917\n",
      "第 7 天補貨策略: R_vars = -0.0, tau_vars = -0.08765413045745497\n",
      "第 8 天補貨策略: R_vars = -0.0, tau_vars = -0.06297538628981343\n",
      "第 9 天補貨策略: R_vars = -0.0, tau_vars = -0.06030415105322917\n",
      "*** 於第[2]天進貨 ***\n",
      "\n",
      "all_Rs: [7, 6, 7, 8, 2, 8, 2, 2, 8, 9, 5, 4, 9, 9, 2]\n",
      "Fold 3 Q_star: 2855.933587421095\n",
      "baseline_profit: -503059.0186827384\n",
      "f_vars[i]: -1.4121950968685657, F_vars[i]: 0.19588806281098134\n",
      "f_vars[i]: -1.5033650206717974, F_vars[i]: 0.1819241791443945\n",
      "f_vars[i]: -1.445915757272681, F_vars[i]: 0.19063093090613548\n",
      "f_vars[i]: -1.4431876081878832, F_vars[i]: 0.19105221445800322\n",
      "f_vars[i]: -1.4566101264341809, F_vars[i]: 0.18898634515405724\n",
      "f_vars[i]: -1.4684007380294364, F_vars[i]: 0.1871858156177802\n",
      "f_vars[i]: -1.4975727080225756, F_vars[i]: 0.1827878248933817\n",
      "f_vars[i]: -1.4763038161527953, F_vars[i]: 0.1859863552727172\n",
      "f_vars[i]: -1.4805647248925629, F_vars[i]: 0.18534213608722544\n",
      "f_vars[i]: -1.4124476894488982, F_vars[i]: 0.19584827851216413\n",
      "f_vars[i]: -1.4809282007750266, F_vars[i]: 0.18528726098461773\n",
      "f_vars[i]: -1.4610015982204345, F_vars[i]: 0.18831418117605536\n",
      "f_vars[i]: -1.4351310836405848, F_vars[i]: 0.19230046071471907\n",
      "f_vars[i]: -1.4570540090859727, F_vars[i]: 0.1889183204273638\n",
      "f_vars[i]: -1.5072284263769433, F_vars[i]: 0.18134990349658292\n",
      "assigned_R: 4\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 375 and 377 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 210 rows, 435 columns and 945 nonzeros\n",
      "Model fingerprint: 0x52b90c6c\n",
      "Model has 105 general constraints\n",
      "Variable types: 315 continuous, 120 integer (120 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Presolve removed 166 rows and 347 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 44 rows, 88 columns, 236 nonzeros\n",
      "Presolved model has 12 SOS constraint(s)\n",
      "Variable types: 44 continuous, 44 integer (44 binary)\n",
      "\n",
      "Root relaxation: objective 5.753830e+06, 25 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5753829.75    0    8          - 5753829.75      -     -    0s\n",
      "H    0     0                    5753829.7434 5753829.75  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (25 simplex iterations) in 0.01 seconds (0.01 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 5.75383e+06 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 5.753829743390e+06, best bound 5.753829746571e+06, gap 0.0000%\n",
      "\n",
      "model.status is optimal: True\n",
      "model.status is TIME_LIMIT: False\n",
      "\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 1.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 1.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "第 2 天補貨策略: R_vars = 1.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 1.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 0.0\n",
      "第 2 天補貨策略: R_vars = 0.0\n",
      "第 3 天補貨策略: R_vars = 0.0\n",
      "第 4 天補貨策略: R_vars = 0.0\n",
      "第 5 天補貨策略: R_vars = 0.0\n",
      "第 6 天補貨策略: R_vars = 0.0\n",
      "第 7 天補貨策略: R_vars = 0.0\n",
      "第 8 天補貨策略: R_vars = 0.0\n",
      "第 9 天補貨策略: R_vars = 1.0\n",
      "tau: [0.39529494 0.59922796 0.60912649 0.44691659 0.43221272 0.59032942\n",
      " 0.30834577 0.08482487]\n",
      "R: [0 0 1 0 0 0 0 0]\n",
      "max_r_index: 2\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 0.37536177  0.73124288  0.74202521  0.48229071  0.44975769  0.72146056\n",
      "  0.42341342 -0.00920096]\n",
      "R: [0 0 1 0 0 0 0 0]\n",
      "max_r_index: 2\n",
      "\n",
      "\n",
      "\n",
      "tau: [0.40393912 0.61720338 0.62735201 0.45832936 0.44275401 0.60805474\n",
      " 0.31935321 0.08495042]\n",
      "R: [0 0 1 0 0 0 0 0]\n",
      "max_r_index: 2\n",
      "\n",
      "\n",
      "\n",
      "tau: [0.37446429 0.67117802 0.68144437 0.46040796 0.43462142 0.66191167\n",
      " 0.37514877 0.022235  ]\n",
      "R: [0 0 1 0 0 0 0 0]\n",
      "max_r_index: 2\n",
      "\n",
      "\n",
      "\n",
      "tau: [0.40939325 0.61767893 0.62789388 0.46166589 0.4467834  0.60846399\n",
      " 0.31750038 0.09090145]\n",
      "R: [0 0 1 0 0 0 0 0]\n",
      "max_r_index: 2\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 0.3668165   0.71179991  0.72232091  0.47041346  0.43893331  0.70227892\n",
      "  0.41117717 -0.00842091]\n",
      "R: [0 0 1 0 0 0 0 0]\n",
      "max_r_index: 2\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 0.37758799  0.72100673  0.7317283   0.47994316  0.44888582  0.71128516\n",
      "  0.41421205 -0.00113567]\n",
      "R: [0 0 1 0 0 0 0 0]\n",
      "max_r_index: 2\n",
      "\n",
      "\n",
      "\n",
      "tau: [0.38670915 0.68159692 0.69209088 0.47122436 0.44592387 0.67210297\n",
      " 0.37856052 0.03054227]\n",
      "R: [0 0 1 0 0 0 0 0]\n",
      "max_r_index: 2\n",
      "\n",
      "\n",
      "\n",
      "tau: [0.39816578 0.66390388 0.67437975 0.47158522 0.44987788 0.654428\n",
      " 0.35953419 0.05314332]\n",
      "R: [0 0 1 0 0 0 0 0]\n",
      "max_r_index: 2\n",
      "\n",
      "\n",
      "\n",
      "tau: [0.40045291 0.58955176 0.59942775 0.44647074 0.43358019 0.58067577\n",
      " 0.29839486 0.09592456]\n",
      "R: [0 0 1 0 0 0 0 0]\n",
      "max_r_index: 2\n",
      "\n",
      "\n",
      "\n",
      "tau: [0.37987643 0.69950707 0.71007376 0.47362596 0.44534101 0.68994037\n",
      " 0.39586539 0.01308694]\n",
      "R: [0 0 1 0 0 0 0 0]\n",
      "max_r_index: 2\n",
      "\n",
      "\n",
      "\n",
      "tau: [0.38973373 0.66005761 0.67040477 0.46532056 0.44289785 0.65071045\n",
      " 0.35987971 0.0456242 ]\n",
      "R: [0 0 1 0 0 0 0 0]\n",
      "max_r_index: 2\n",
      "\n",
      "\n",
      "\n",
      "tau: [0.36545341 0.68026237 0.69050226 0.45840581 0.43034576 0.67102247\n",
      " 0.38620136 0.00706967]\n",
      "R: [0 0 1 0 0 0 0 0]\n",
      "max_r_index: 2\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 0.36246539  0.70852979  0.71897354  0.46672363  0.43502134  0.69908603\n",
      "  0.41031473 -0.01160635]\n",
      "R: [0 0 1 0 0 0 0 0]\n",
      "max_r_index: 2\n",
      "\n",
      "\n",
      "\n",
      "tau: [ 0.36964172  0.74622833  0.75707147  0.48429834  0.44926778  0.73638518\n",
      "  0.43789371 -0.0238094 ]\n",
      "R: [0 0 1 0 0 0 0 0]\n",
      "max_r_index: 2\n",
      "\n",
      "\n",
      "\n",
      "All train fold profits:\n",
      "       baseline            S1            S2           S12   S15   S16  \\\n",
      "0  1.571096e+06  1.667190e+06  1.666445e+06  1.666683e+06  None  None   \n",
      "1  1.528869e+06  1.606292e+06  1.604270e+06  1.598571e+06  None  None   \n",
      "2  1.632055e+06  1.694693e+06  1.693391e+06  1.693453e+06  None  None   \n",
      "\n",
      "            S14  \n",
      "0  1.667490e+06  \n",
      "1  1.606274e+06  \n",
      "2  1.694539e+06  \n",
      "All test fold profits:\n",
      "        baseline             S1             S2            S12   S15   S16  \\\n",
      "0 -491661.277139 -265841.023786 -127054.888034  279316.953171  None  None   \n",
      "1 -420569.429221 -312155.520625  356784.467359  183840.906132  None  None   \n",
      "2 -503059.018683 -388821.675186  382424.840717   77095.369821  None  None   \n",
      "\n",
      "             S14  \n",
      "0  382463.993774  \n",
      "1  398141.794046  \n",
      "2  383588.649559  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27336/2267964258.py:74: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27336/4060423289.py:107: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_row[k - 2] for k in range(2, T)\n",
      "/var/folders/ky/18rg_26d0nx_dq3q0413qtv80000gr/T/ipykernel_27336/3802425588.py:90: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R_vars[i, k - 2] * Qk_hat_df_test_row[k - 2] for k in range(2, T)\n"
     ]
    }
   ],
   "source": [
    "train_all_fold_profits = []\n",
    "train_all_fold_stimulation_results = []\n",
    "test_all_fold_profits = []\n",
    "test_all_fold_stimulation_results = []\n",
    "beta_records = {\"S12\": [], \"S15\": [], \"S16\": []}\n",
    "\n",
    "# 迴圈遍歷所有 fold\n",
    "for fold_idx in range(len(training_data_folds)):\n",
    "    print(f\"===== Processing Fold {fold_idx + 1} =====\")\n",
    "    # 取出該 fold 的訓練資料與需求資料\n",
    "    training_df, testing_df = training_data_folds[fold_idx]\n",
    "    demand_df_train, demand_df_test = demand_folds[fold_idx]\n",
    "\n",
    "    Q_star = calculate_Q_star(demand_df_train, service_level=service_lv)\n",
    "    print(f\"Fold {fold_idx + 1} Q_star: {Q_star}\")\n",
    "\n",
    "    # ====訓練階段====\n",
    "\n",
    "    mu_matrix, covariance_matrix = cal_mu_and_cov_matrix(demand_df_train)\n",
    "    Qk_hat_df_train = make_Qk_hat_df(\n",
    "        demand_df_train, T, service_lv, mu_matrix, covariance_matrix\n",
    "    )\n",
    "    training_profits, training_results, training_stimulation_results = (\n",
    "        perform_fold_training(training_df, demand_df_train, Qk_hat_df_train, Q_star)\n",
    "    )\n",
    "    train_all_fold_profits.append(training_profits)\n",
    "    train_all_fold_stimulation_results.append(training_stimulation_results)\n",
    "\n",
    "    if training_results[\"S12\"] is not None:\n",
    "        beta_records[\"S12\"].append(training_results[\"S12\"].iloc[0][\"beta_values\"])\n",
    "    else:\n",
    "        beta_records[\"S12\"].append(None)\n",
    "\n",
    "    if training_results[\"S15\"] is not None:\n",
    "        beta_records[\"S15\"].append(training_results[\"S15\"].iloc[0][\"beta_values\"])\n",
    "    else:\n",
    "        beta_records[\"S15\"].append(None)\n",
    "\n",
    "    if training_results[\"S16\"] is not None:\n",
    "        beta_records[\"S16\"].append(training_results[\"S16\"].iloc[0][\"beta_values\"])\n",
    "    else:\n",
    "        beta_records[\"S16\"].append(None)\n",
    "\n",
    "    # ====測試階段====\n",
    "    print(f\"Fold {fold_idx + 1} Q_star: {Q_star}\")\n",
    "\n",
    "    mu_matrix, covariance_matrix = cal_mu_and_cov_matrix(demand_df_test)\n",
    "    Qk_hat_df_test = make_Qk_hat_df(\n",
    "        demand_df_test, T, service_lv, mu_matrix, covariance_matrix\n",
    "    )\n",
    "    testing_profits, testing_stimulation_results = perform_fold_testing(\n",
    "        training_results[\"S1\"],\n",
    "        training_results[\"S2\"],\n",
    "        training_results[\"S12\"],\n",
    "        training_results[\"S15\"],\n",
    "        training_results[\"S16\"],\n",
    "        demand_df_test,\n",
    "        Qk_hat_df_test,\n",
    "        Q_star,\n",
    "        testing_df,\n",
    "    )\n",
    "\n",
    "    test_all_fold_profits.append(testing_profits)\n",
    "    test_all_fold_stimulation_results.append(testing_stimulation_results)\n",
    "\n",
    "\n",
    "# 將所有 fold 的結果轉換為 DataFrame 便於檢查與保存\n",
    "train_all_fold_profit_df = pd.DataFrame(train_all_fold_profits)\n",
    "print(\"All train fold profits:\")\n",
    "print(train_all_fold_profit_df)\n",
    "\n",
    "test_all_fold_profit_df = pd.DataFrame(test_all_fold_profits)\n",
    "print(\"All test fold profits:\")\n",
    "print(test_all_fold_profit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S12</th>\n",
       "      <th>S15</th>\n",
       "      <th>S16</th>\n",
       "      <th>S14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.571096e+06</td>\n",
       "      <td>1.667190e+06</td>\n",
       "      <td>1.666445e+06</td>\n",
       "      <td>1.666683e+06</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.667490e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.528869e+06</td>\n",
       "      <td>1.606292e+06</td>\n",
       "      <td>1.604270e+06</td>\n",
       "      <td>1.598571e+06</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.606274e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.632055e+06</td>\n",
       "      <td>1.694693e+06</td>\n",
       "      <td>1.693391e+06</td>\n",
       "      <td>1.693453e+06</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.694539e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       baseline            S1            S2           S12   S15   S16  \\\n",
       "0  1.571096e+06  1.667190e+06  1.666445e+06  1.666683e+06  None  None   \n",
       "1  1.528869e+06  1.606292e+06  1.604270e+06  1.598571e+06  None  None   \n",
       "2  1.632055e+06  1.694693e+06  1.693391e+06  1.693453e+06  None  None   \n",
       "\n",
       "            S14  \n",
       "0  1.667490e+06  \n",
       "1  1.606274e+06  \n",
       "2  1.694539e+06  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all_fold_profit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S12</th>\n",
       "      <th>S15</th>\n",
       "      <th>S16</th>\n",
       "      <th>S14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-491661.277139</td>\n",
       "      <td>-265841.023786</td>\n",
       "      <td>-127054.888034</td>\n",
       "      <td>279316.953171</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>382463.993774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-420569.429221</td>\n",
       "      <td>-312155.520625</td>\n",
       "      <td>356784.467359</td>\n",
       "      <td>183840.906132</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>398141.794046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-503059.018683</td>\n",
       "      <td>-388821.675186</td>\n",
       "      <td>382424.840717</td>\n",
       "      <td>77095.369821</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>383588.649559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        baseline             S1             S2            S12   S15   S16  \\\n",
       "0 -491661.277139 -265841.023786 -127054.888034  279316.953171  None  None   \n",
       "1 -420569.429221 -312155.520625  356784.467359  183840.906132  None  None   \n",
       "2 -503059.018683 -388821.675186  382424.840717   77095.369821  None  None   \n",
       "\n",
       "             S14  \n",
       "0  382463.993774  \n",
       "1  398141.794046  \n",
       "2  383588.649559  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_all_fold_profit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S12': [array([[ 1.33825593e-02,  0.00000000e+00, -2.84256176e-03,\n",
       "           4.78567162e-01],\n",
       "         [ 8.62571353e-03,  0.00000000e+00, -8.36670050e-05,\n",
       "          -1.45999314e-01],\n",
       "         [ 8.16089120e-03,  0.00000000e+00, -2.12234697e-05,\n",
       "          -1.55115976e-01],\n",
       "         [ 8.39330237e-03,  0.00000000e+00, -5.24452373e-05,\n",
       "          -1.51057645e-01],\n",
       "         [ 2.25835773e-02,  0.00000000e+00, -1.61293581e-03,\n",
       "           0.00000000e+00],\n",
       "         [ 2.22084070e-02,  0.00000000e+00, -1.50727295e-03,\n",
       "          -2.05533864e-02],\n",
       "         [ 7.30648350e-03,  0.00000000e+00, -4.38025687e-05,\n",
       "          -1.34883482e-01],\n",
       "         [ 1.36324472e-02,  0.00000000e+00,  8.69537321e-04,\n",
       "          -5.08443884e-01]]),\n",
       "  array([[ 6.20502194e-02,  0.00000000e+00, -1.17215578e-03,\n",
       "          -9.36249899e-01],\n",
       "         [ 1.28092696e+01,  0.00000000e+00, -1.00000000e+00,\n",
       "           0.00000000e+00],\n",
       "         [-2.19586169e-02,  0.00000000e+00, -4.50152690e-04,\n",
       "           3.74467190e-01],\n",
       "         [-1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00],\n",
       "         [-1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00],\n",
       "         [-3.96507011e-03,  0.00000000e+00, -1.80392220e-03,\n",
       "           4.32356796e-01],\n",
       "         [ 5.87970276e-02,  0.00000000e+00, -1.13881005e-03,\n",
       "          -8.84313027e-01],\n",
       "         [-5.60180166e-02,  0.00000000e+00,  3.11567648e-03,\n",
       "           0.00000000e+00]]),\n",
       "  array([[-9.94986979e-03,  0.00000000e+00, -1.87427854e-03,\n",
       "           6.80474790e-01],\n",
       "         [ 2.91221761e-02,  0.00000000e+00, -3.24226658e-03,\n",
       "           3.62917439e-01],\n",
       "         [ 2.92537030e-02,  0.00000000e+00, -3.29097703e-03,\n",
       "           3.74084280e-01],\n",
       "         [ 4.57883035e-03,  0.00000000e+00, -2.24154071e-03,\n",
       "           5.28488268e-01],\n",
       "         [-1.14993234e-04,  0.00000000e+00, -2.12752142e-03,\n",
       "           5.79882234e-01],\n",
       "         [ 2.89906491e-02,  0.00000000e+00, -3.19355612e-03,\n",
       "           3.52750597e-01],\n",
       "         [ 2.76619484e-02,  0.00000000e+00, -1.85614440e-03,\n",
       "           0.00000000e+00],\n",
       "         [-2.70620360e-02,  0.00000000e+00, -3.81308641e-04,\n",
       "           5.37119053e-01]])],\n",
       " 'S15': [None, None, None],\n",
       " 'S16': [None, None, None]}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABdYAAAN6CAYAAACDghtkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAADFlUlEQVR4nOzdd3xO9///8eeVkIREQhqRIATxMWO3Zq1oid1aNUootUdblKqiNWprjWpLrVK0Rs3am5Yi9p61dwYhkZzfH365vr0kIUcTCR732+263VznvM85r/e1Pc8772MxDMMQAAAAAAAAAABIFLuULgAAAAAAAAAAgBcJwToAAAAAAAAAACYQrAMAAAAAAAAAYALBOgAAAAAAAAAAJhCsAwAAAAAAAABgAsE6AAAAAAAAAAAmEKwDAAAAAAAAAGACwToAAAAAAAAAACYQrAMAAAAAAAAAYALBOgAASNCuXbtUrlw5OTs7y2KxKDg4WAMHDpTFYvnP+965c6ccHBx07ty5JKg08SwWiwYOHPhcj/kii4qKko+PjyZNmpTSpaQ4i8WiLl26pHQZSEbTp0+XxWLR2bNnrcsqV66sypUrp1hNSens2bOyWCwaNWpUSpcCAADwwiNYBwCkSpMmTZLFYlHp0qVTupRUx9fXVxaLxXrz9PTUm2++qUWLFiXpcaKiotSoUSPdunVLY8eO1axZs5QzZ8542w4dOlSLFy82tf9+/fqpadOmypkzpzXMetrN19f3v3fsBfG8H5Pt27dr4MCBunPnjs3ytGnT6uOPP9aQIUN0//79JDnWs7hz546aN2+uTJkyKXfu3Jo6dWqcNn///bfSp0+vM2fOmNr3qVOn1L59e+XOnVtOTk5ydXVV+fLl9c033ygiIiKpugDF/fxycnJS3rx51atXL926dSuly0u1GjRooJo1a8a77vHHNKHb9OnTn2/Rz0nsyYJ/31xdXVWsWDFNmDBB0dHRyXbsSZMmvbSPKwAAeLo0KV0AAADxmT17tnx9fbVz506dPHlSfn5+KV1SqlKsWDF98sknkqRLly7p+++/17vvvqvvvvtOHTp0SJJjnDp1SufOndOPP/6otm3bWpd//vnn6tOnj03boUOHqmHDhqpfv36i9h0cHKy1a9dq+/btkqSKFStq1qxZNm3atm2rN954Qx9++KF1mYuLyzP25v9EREQoTZrU/xPoeT4m0qNgfdCgQQoKClLGjBlt1rVu3Vp9+vTRnDlz1KZNmyQ5nlk9e/bUxo0bNWjQIJ08eVLt2rVTgQIFVK5cOUmSYRjq1q2bevTooVy5ciV6v8uXL1ejRo3k6Oioli1bqnDhwoqMjNTWrVvVq1cvHTp0SD/88ENydeuV9O/Pr/v372v37t0aN26cNm3apJ07d6ZwdXGtXr06RY8fFRWlNWvWaNiwYfGuHzdunMLDw633V6xYoV9++UVjx46Vh4eHdXnse+Vl1bRpU+vJh5CQEK1YsUJdu3bVuXPnNHLkyGQ55qRJk+Th4aGgoKBk2T8AAEjdUv//KgEAr5wzZ85o+/btWrhwodq3b6/Zs2drwIABz7WGmJgYRUZGysnJ6bkeN7GyZcumFi1aWO+3bNlSfn5+Gjt2bILB+sOHDxUTEyMHB4dEHePatWuSFCdkTZMmzX8OpqdNm6YcOXKoTJkykqTcuXMrd+7cNm06dOig3Llz2/TzcWb7JCnVPqePe9bHJDlkzJhRb7/9tqZPn55iwfqyZcs0YsQItWzZUpK0f/9+LV261BoWzp49W+fOndNnn32W6H2eOXNG7733nnLmzKn169fL29vbuq5z5846efKkli9fnrQdQZzPr7Zt28rFxUWjRo3SiRMnlDdv3hSsLi4zny/JYcuWLQoLC1OtWrXiXf/4Cc0rV67ol19+Uf369eP8Rcu/p7hJDe7fvy8HBwfZ2f33P6QuUaKEzeuqU6dOKl26tObMmZNswToAAHi1MRUMACDVmT17tjJlyqRatWqpYcOGmj17tnVdVFSU3N3d1bp16zjbhYaGysnJST179rQue/DggQYMGCA/Pz85OjrKx8dHvXv31oMHD2y2jZ07efbs2SpUqJAcHR31xx9/SJJGjRqlcuXK6bXXXlO6dOlUsmRJ/fbbb3GOHxERoW7dusnDw0MZMmRQ3bp1dfHixXjn9L548aLatGmjLFmyyNHRUYUKFdJPP/30zI+Zl5eXChQoYJ0C49/z6I4bN0558uSRo6OjDh8+LElav3693nzzTTk7OytjxoyqV6+ejhw5Yt1fUFCQKlWqJElq1KiRLBaLdY7hx+dYt1gsunv3rmbMmGH9M/ynjd5bvHixqlatamqu9if1KTIyUl988YVKliwpNzc3OTs7680339SGDRvi7Ofx5yO2PydPnrSO1nZzc1Pr1q117969J9bUpUsXubi4xNuuadOm8vLysk5D8Pfff6t69ery8PBQunTplCtXriQJqRP7Who/frwKFSqk9OnTK1OmTCpVqpTmzJljfQx69eolScqVK5f1efx3CPfWW29p69atKTZdR0REhDJlymS97+7ubn3c7969qz59+mjYsGGmRvCPGDFC4eHhmjp1qk2oHsvPz0/du3ePs3zx4sUqXLiw9fGO/ayIde7cOXXq1En58uVTunTp9Nprr6lRo0ZxQs3Y6X62bdumjz/+WJkzZ5azs7PeeecdXb9+3aZtTEyMBg4cqKxZsyp9+vSqUqWKDh8+LF9f3zjvtzt37qhHjx7y8fGRo6Oj/Pz8NHz4cMXExDzx8ahdu3ackzmxypYtq1KlSlnvr1mzRhUqVFDGjBnl4uKifPnymTqp8TgvLy9Jsjlpt3//fgUFBVmn6PHy8lKbNm108+ZNm23DwsLUo0cP+fr6ytHRUZ6ennrrrbe0Z88em3Z//fWXatSoITc3N6VPn16VKlXStm3bnlrb43Osb9y4URaLRfPnz9eQIUOUPXt2OTk5KSAgQCdPnoyz/bMeN9by5ctVsGDBJJ8K64cffrB+jr7++uvatWtXnDZHjx5Vw4YN5e7uLicnJ5UqVUpLliyJ0+706dNq1KiR3N3dlT59epUpUybOSanYx23u3Ln6/PPPlS1bNqVPn17BwcGyWCwaO3ZsnP1u375dFotFv/zyi+n+WSwWZcmSJd4TwStXrrR+B2bIkEG1atXSoUOHbNpcuXJFrVu3Vvbs2eXo6Chvb2/Vq1fP+j729fXVoUOHtGnTJutn5ssyFz8AAEgcRqwDAFKd2bNn691335WDg4OaNm2q7777Trt27dLrr7+utGnT6p133tHChQv1/fff24wkXLx4sR48eKD33ntP0qMgqm7dutq6das+/PBDFShQQAcOHNDYsWN1/PjxOHOCr1+/XvPnz1eXLl3k4eFhDTG++eYb1a1bV82bN1dkZKTmzp2rRo0aadmyZTYjCIOCgjR//ny9//77KlOmjDZt2hTvCMOrV6+qTJky1jA/c+bMWrlypT744AOFhoaqR48eph+zqKgo/fPPP3rttddslk+bNk3379/Xhx9+KEdHR7m7u2vt2rUKDAxU7ty5NXDgQEVERGj8+PEqX7689uzZI19fX7Vv317ZsmXT0KFD1a1bN73++uvKkiVLvMeeNWtWnClK8uTJk2CtFy9e1Pnz51WiRAnT/UyoT6GhoZoyZYqaNm2qdu3aKSwsTFOnTlX16tW1c+dOFStW7Kn7bdy4sXLlyqVhw4Zpz549mjJlijw9PTV8+PAEt2nSpIkmTpxonU4k1r1797R06VIFBQXJ3t5e165d09tvv63MmTOrT58+ypgxo86ePauFCxc+02MQK7GvpR9//FHdunVTw4YN1b17d92/f1/79+/XX3/9pWbNmundd9/V8ePH40wfkTlzZuuxSpYsKcMwtH37dtWuXfs/1f0sXn/9dY0ZM0b58+fX6dOn9ccff+jHH3+U9GgqomzZsun99983tc+lS5cqd+7cpqbI2Lp1qxYuXKhOnTopQ4YM+vbbb9WgQQOdP3/e+v7btWuXtm/frvfee0/Zs2fX2bNn9d1336ly5co6fPiw0qdPb7PPrl27KlOmTBowYIDOnj2rcePGqUuXLpo3b561Td++fTVixAjVqVNH1atX1759+1S9evU4897fu3dPlSpV0sWLF9W+fXvlyJFD27dvV9++fXX58mWNGzcuwb41adJELVu2tH7exjp37pz+/PNP66jfQ4cOqXbt2ipSpIi+/PJLOTo66uTJk4kOi6OionTjxg1Jj0Ys7927V2PGjFHFihVtpvFZs2aNTp8+rdatW8vLy8s6Lc+hQ4f0559/Wk/MdejQQb/99pu6dOmiggUL6ubNm9q6dauOHDli/ZxZv369AgMDVbJkSQ0YMEB2dnaaNm2aqlatqi1btuiNN95IVO3/9vXXX8vOzk49e/ZUSEiIRowYoebNm+uvv/6ytkmK465YsSLJ33Nz5sxRWFiY2rdvL4vFohEjRujdd9/V6dOnlTZtWkmPnufy5csrW7Zs6tOnj5ydnTV//nzVr19fCxYs0DvvvCPp0edQuXLldO/ePXXr1k2vvfaaZsyYobp16+q3336ztov11VdfycHBQT179tSDBw+UP39+lS9fXrNnz9ZHH31k03b27NnKkCGD6tWr99Q+3bt3z/q6Cg0N1cqVK/XHH3+ob9++Nu1mzZqlVq1aqXr16ho+fLju3bun7777ThUqVNDevXut3/0NGjTQoUOH1LVrV/n6+uratWtas2aNzp8/L19fX40bN05du3aVi4uL+vXrJ0kJfk8CAICXlAEAQCry999/G5KMNWvWGIZhGDExMUb27NmN7t27W9usWrXKkGQsXbrUZtuaNWsauXPntt6fNWuWYWdnZ2zZssWm3eTJkw1JxrZt26zLJBl2dnbGoUOH4tR07949m/uRkZFG4cKFjapVq1qX7d6925Bk9OjRw6ZtUFCQIckYMGCAddkHH3xgeHt7Gzdu3LBp+9577xlubm5xjve4nDlzGm+//bZx/fp14/r168a+ffuM9957z5BkdO3a1TAMwzhz5owhyXB1dTWuXbtms32xYsUMT09P4+bNm9Zl+/btM+zs7IyWLVtal23YsMGQZPz666822w8YMMB4/CeEs7Oz0apVqyfWHWvt2rXxPn+Pe3yfT+rTw4cPjQcPHtgsu337tpElSxajTZs2Nssffz5i+/N4u3feecd47bXXnlhjTEyMkS1bNqNBgwY2y+fPn29IMjZv3mwYhmEsWrTIkGTs2rXrift7mscfk8S+lurVq2cUKlToifseOXKkIck4c+ZMvOsvXbpkSDKGDx/+n/rwrPbv329kz57dkGRIMho0aGBER0cbp0+fNtKlS2fs2LHD1P5CQkIMSUa9evUSvY0kw8HBwTh58qR12b59+wxJxvjx463L4nsP79ixw5BkzJw507ps2rRphiSjWrVqRkxMjHX5Rx99ZNjb2xt37twxDMMwrly5YqRJk8aoX7++zT4HDhxoSLJ5TXz11VeGs7Ozcfz4cZu2ffr0Mezt7Y3z588n2L+QkBDD0dHR+OSTT2yWjxgxwrBYLMa5c+cMwzCMsWPHGpKM69evJ7ivhOTMmdP6HP77Vr58+Tiv4/gex19++cXmvWUYhuHm5mZ07tw5wWPGxMQYefPmNapXr27zON+7d8/IlSuX8dZbb1mXxT4n/34fVKpUyahUqZL1fuxnY4ECBWw+d7755htDknHgwAHTx03I6dOnDUnGhg0bnto21pPey7Gfo6+99ppx69Yt6/Lff/89zudyQECA4e/vb9y/f9+6LCYmxihXrpyRN29e67IePXoYkmy+a8PCwoxcuXIZvr6+RnR0tGEY//e45c6dO85z+/333xuSjCNHjliXRUZGGh4eHk/9bontU3y3jh072jz2YWFhRsaMGY127drZ7OPKlSuGm5ubdfnt27cNScbIkSOfeOxChQrZvDYAAMCrhalgAACpyuzZs5UlSxZVqVJF0qM/5W7SpInmzp1rnVKjatWq8vDwsBnNefv2ba1Zs0ZNmjSxLvv1119VoEAB5c+fXzdu3LDeqlatKklxpgmpVKmSChYsGKemdOnS2RwnJCREb775ps00A7FTQXTq1Mlm265du9rcNwxDCxYsUJ06dWQYhk1d1atXV0hISJzpC+KzevVqZc6cWZkzZ1bRokX166+/6v33348zurpBgwY2o44vX76s4OBgBQUFyd3d3bq8SJEieuutt7RixYqnHvu/ip3G4d/TepjxeJ8kyd7e3vrXCzExMbp165YePnyoUqVKJerxlBRnbvo333xTN2/eVGhoaILbWCwWNWrUSCtWrLC5eOC8efOULVs2VahQQdL/zVO/bNkyRUVFJaqepzHzWsqYMaMuXLgQ71QPiRX7fMWOCH3e/P39deLECe3atUsnTpzQb7/9Jjs7O33yySdq0KCBypQpo4ULF6po0aLKlSuXvvzySxmGkeD+Yp/XDBkymKqjWrVqNn+RUaRIEbm6uur06dPWZf/+zIiKitLNmzfl5+enjBkzxvt6/PDDD22mRXrzzTcVHR2tc+fOSZLWrVunhw8fPvXzRXr0uffmm28qU6ZMNq+JatWqKTo6Wps3b06wb66urgoMDNT8+fNtHrt58+apTJkyypEjh6T/ez3//vvvT51eJj6lS5fWmjVrtGbNGi1btkxDhgzRoUOHVLduXUVERFjb/ftxvH//vm7cuGG9LsO/H8eMGTPqr7/+0qVLl+I9XnBwsE6cOKFmzZrp5s2b1sfk7t27CggI0ObNm5+pH61bt7b5q6k333xTkqyvhaQ47vLly+Xm5mb9LEkqTZo0sfkMfrz2W7duaf369WrcuLHCwsKstd+8eVPVq1fXiRMndPHiRUmPRtS/8cYbNjW6uLjoww8/1NmzZ61TkMVq1aqVzXMrPfqLIScnJ5up31atWqUbN24k+poSH374ofV1tWDBAnXu3Fnff/+9Pv74Y2ubNWvW6M6dO2ratKnN+8Pe3l6lS5e2/i5Ily6dHBwctHHjRt2+fTtRxwcAAK8epoJJpM2bN2vkyJHavXu3Ll++rEWLFsW5UNDTGIah0aNH64cfftC5c+fk4eGhTp06Wf90EABeddHR0Zo7d66qVKlinStcehTCjB49WuvWrdPbb7+tNGnSqEGDBpozZ44ePHggR0dHLVy4UFFRUTbB+okTJ3TkyJE4IWys2Itzxvr3FAT/tmzZMg0ePFjBwcE2c7P/Owg7d+6c7Ozs4uzDz8/P5v7169d1584d/fDDD/rhhx8SVVd8SpcurcGDB8tisSh9+vQqUKBAnIuMxten2KAuX758cdoWKFBAq1at0t27d+Xs7PzUGv6rJ4WeT5LQ8zRjxgyNHj1aR48etQmvE2r/uNjQMFZs6HT79m25uromuF2TJk00btw4LVmyRM2aNVN4eLhWrFhhnWJBenTSpkGDBho0aJDGjh2rypUrq379+mrWrJkcHR0TVd/jzLyWPv30U61du1ZvvPGG/Pz89Pbbb6tZs2YqX758oo8X+3w9bV78K1euJHqfj4udZzshsXM8x1q/fr1Wr16tY8eO6dixY3rvvff0/fffy9fXV02bNpWPj0+812OQZH1Ow8LCTNX4+OtEevRa+Xf4FhERoWHDhmnatGm6ePGizWs9JCTkqfv892tP+r/37eOfJ+7u7nFOUJ04cUL79+9P9Ofe45o0aaLFixdrx44dKleunE6dOqXdu3fbTCHTpEkTTZkyRW3btlWfPn0UEBCgd999Vw0bNkzURSg9PDxUrVo16/1atWopX758atiwoaZMmWI9YXDr1i0NGjRIc+fOjVP3vx/HESNGqFWrVvLx8VHJkiVVs2ZNtWzZ0jpf/IkTJyQ9CnQTEhISYvpk39Oet6Q47vLly63fe0npabWfPHlShmGof//+6t+/f7z7uHbtmrJly6Zz586pdOnScdYXKFBA0qPXb+HCha3L4/tMzpgxo+rUqaM5c+boq6++kvToRHu2bNmsJ8OfJm/evDavq3fffVcWi0Xjxo1TmzZtrCfnJCW4z9jPBUdHRw0fPlyffPKJsmTJojJlyqh27dpq2bLlUz+nAADAq4NgPZHu3r2rokWLqk2bNnr33XefaR/du3fX6tWrNWrUKPn7++vWrVspdgEwAEiN1q9fr8uXL2vu3LmaO3dunPWzZ8/W22+/LUnWAG3lypWqX7++5s+fr/z586to0aLW9jExMfL399eYMWPiPZ6Pj4/N/cdH0EnSli1bVLduXVWsWFGTJk2St7e30qZNq2nTplkv/GhG7OjEFi1aJBi2FClS5Kn7eTyYSkh8fUppsfNQP+sowPj69PPPPysoKEj169dXr1695OnpKXt7ew0bNkynTp1K1H7t7e3jXf60EwBlypSRr6+v5s+fr2bNmmnp0qWKiIiwOcljsVj022+/6c8//9TSpUu1atUqtWnTRqNHj9aff/5p6oKbscy8lgoUKKBjx45p2bJl+uOPP7RgwQJNmjRJX3zxhQYNGpSo48U+X7HzryckvouAJpaZky3R0dHq3r27+vTpo2zZsumrr75SuXLlrEF6+/btNXv27CcG61mzZtXBgwdN1ZiY10nXrl01bdo09ejRQ2XLlpWbm5ssFovee++9eEcoP+trLz4xMTF666231Lt373jX/+9//3vi9nXq1FH69Ok1f/58lStXTvPnz5ednZ3NNQTSpUunzZs3a8OGDVq+fLn++OMPzZs3T1WrVtXq1asT7M+TBAQESHo0mCU2WG/cuLG2b9+uXr16qVixYnJxcVFMTIxq1Khh8zg2btxYb775phYtWqTVq1dr5MiRGj58uBYuXKjAwEBr25EjRyZ4vYVneQ8+7Xn7r8e9d++eNm7cqO+++850bU+T2Np79uyp6tWrx9v28RM9iZXQ91LLli3166+/avv27fL399eSJUvUqVOnRJ2sSUhAQIAmTJigzZs3y9/f39qvWbNmxRuQ//sERo8ePVSnTh0tXrxYq1atUv/+/TVs2DCtX79exYsXf+aaAADAy4NgPZECAwMVGBiY4PoHDx6oX79++uWXX3Tnzh0VLlxYw4cPt14Z/siRI/ruu+908OBB6yjBxI6gA4BXxezZs+Xp6amJEyfGWbdw4UItWrRIkydPVrp06VSxYkV5e3tr3rx5qlChgtavXx/nL4Dy5Mmjffv2KSAg4KmjbBOyYMECOTk5adWqVTYji6dNm2bTLmfOnIqJidGZM2eUN29e6/KTJ0/atMucObMyZMig6OjoRAXjSS1nzpySpGPHjsVZd/ToUXl4eDzTaHUzj2/+/PklyeavEv6r3377Tblz59bChQttahkwYECSHeNJGjdurG+++UahoaGaN2+efH19rVNW/FuZMmVUpkwZDRkyRHPmzFHz5s01d+5ctW3b1vQxzb6WnJ2d1aRJEzVp0kSRkZF69913NWTIEPXt21dOTk5PfQ5jn6/YUagJWbNmTeI78R989913CgsLU8+ePSVJly5dUtasWa3rs2bNap2qIiG1a9fWDz/8oB07dqhs2bJJVttvv/2mVq1aafTo0dZl9+/f1507d55pf7Hv25MnT9r8frx582acE1R58uRReHj4M3++ODs7q3bt2vr11181ZswYzZs3T2+++abNYytJdnZ2CggIUEBAgMaMGaOhQ4eqX79+2rBhwzMd++HDh5JknVLp9u3bWrdunQYNGqQvvvjC2i52xPHjvL291alTJ3Xq1EnXrl1TiRIlNGTIEAUGBlqn7nF1dX2un7v/9bjr16/XgwcPnvh/kOQSO9o/bdq0T609Z86cCX6nxK5PjBo1aihz5syaPXu2SpcurXv37pm+IPHjHn9dxT4nnp6eiXpO8uTJo08++USffPKJTpw4oWLFimn06NH6+eefJZn77gMAAC8f5lhPIl26dNGOHTs0d+5c7d+/X40aNVKNGjWsP/6XLl2q3Llza9myZcqVK5d8fX3Vtm1bRqwDwP8XERGhhQsXqnbt2mrYsGGcW5cuXRQWFqYlS5ZIehTqNGzYUEuXLtWsWbP08OFDmxHC0qOw8+LFi/rxxx/jPd7du3efWpe9vb0sFot1fndJOnv2rBYvXmzTLnZE36RJk2yWjx8/Ps7+GjRooAULFsQ7Uvb69etPrem/8Pb2VrFixTRjxgybkO/gwYNavXq1atas+Uz7dXZ2TnRomC1bNvn4+Ojvv/9+pmPFJ3b05b9H+P7111/asWNHkh3jSZo0aaIHDx5oxowZ+uOPP9S4cWOb9bdv344z+jh2BOu/pxcyw8xrKXZe+1gODg4qWLCgDMOwTpsTe0Iloedx9+7dslgsTw2gq1Wr9sy3xLp165YGDBigkSNHysnJSZKUJUsWa5AnPRrU8LQpG3r37i1nZ2e1bdtWV69ejbP+1KlT+uabbxJdVyx7e/s4z/f48eNtPkfMCAgIUJo0aeKMXJ4wYUKcto0bN9aOHTu0atWqOOvu3LljDRqfpEmTJrp06ZKmTJmiffv2xflsje/36399PS9dulSSrH91FN97WpLNlDTSo79ceHx6HU9PT2XNmtVaS8mSJZUnTx6NGjXK5loIsZLrc/e/HnfFihUqVaqUsmTJkiz1PYmnp6cqV66s77//XpcvX46z/t+116xZUzt37rT5vL17965++OEH+fr6xnvtkvikSZNGTZs21fz58zV9+nT5+/sn6i+4nuTx11X16tXl6uqqoUOHxnu9i9h+3bt3T/fv37dZlydPHmXIkMHmNW7muw8AALx8GLGeBM6fP69p06bp/Pnz1tE8PXv21B9//KFp06Zp6NChOn36tM6dO6dff/1VM2fOVHR0tD766CM1bNhQ69evT+EeAEDKW7JkicLCwlS3bt1415cpU8Y6ki025GnSpInGjx+vAQMGyN/fP85I2vfff1/z589Xhw4dtGHDBpUvX17R0dE6evSo5s+fr1WrVtnM1xyfWrVqacyYMapRo4aaNWuma9euaeLEifLz89P+/fut7UqWLKkGDRpo3LhxunnzpsqUKaNNmzbp+PHjkmxHtX399dfasGGDSpcurXbt2qlgwYK6deuW9uzZo7Vr1yb7SdeRI0cqMDBQZcuW1QcffKCIiAiNHz9ebm5uGjhw4DPts2TJklq7dq3GjBmjrFmzKleuXPHOuRurXr16WrRokQzDSJIRf7Vr19bChQv1zjvvqFatWjpz5owmT56sggULxhtoJbUSJUrIz89P/fr104MHD+IEkTNmzNCkSZP0zjvvKE+ePAoLC9OPP/4oV1fXZz6ZISX+tfT222/Ly8tL5cuXV5YsWXTkyBFNmDBBtWrVsl68s2TJkpKkfv366b333lPatGlVp04da+C+Zs0alS9f3jqVT0rq37+//P39baYnadCggb788kt17NhROXPm1Pfff5/gNFCx8uTJozlz5qhJkyYqUKCAWrZsqcKFCysyMlLbt2/Xr7/+qqCgINP11a5dW7NmzZKbm5sKFiyoHTt2aO3atc/82GXJkkXdu3fX6NGjVbduXdWoUUP79u3TypUr5eHhYfMe6tWrl5YsWaLatWsrKChIJUuW1N27d3XgwAH99ttvOnv27FOn86lZs6YyZMignj17Wk/g/NuXX36pzZs3q1atWsqZM6euXbumSZMmKXv27Im6yObFixetI34jIyO1b98+ff/99/Lw8LBOA+Pq6qqKFStqxIgRioqKUrZs2bR69eo4f+kSFham7Nmzq2HDhipatKhcXFy0du1a7dq1y/oXA3Z2dpoyZYoCAwNVqFAhtW7dWtmyZdPFixe1YcMGubq6WgPYpPRfj7tixYoEpzJ6HiZOnKgKFSrI399f7dq1U+7cuXX16lXt2LFDFy5c0L59+yRJffr00S+//KLAwEB169ZN7u7umjFjhs6cOaMFCxaYmsqlZcuW+vbbb7Vhw4Y4F+N+mj179lhfV2FhYVq3bp0WLFigcuXKWaeRc3V11Xfffaf3339fJUqU0HvvvafMmTPr/PnzWr58ucqXL68JEybo+PHjCggIUOPGjVWwYEGlSZNGixYt0tWrV/Xee+9Zj1myZEl99913Gjx4sPz8/OTp6ZnoOeEBAMBLwIBpkoxFixZZ7y9btsyQZDg7O9vc0qRJYzRu3NgwDMNo166dIck4duyYdbvdu3cbkoyjR48+7y4AQKpTp04dw8nJybh7926CbYKCgoy0adMaN27cMAzDMGJiYgwfHx9DkjF48OB4t4mMjDSGDx9uFCpUyHB0dDQyZcpklCxZ0hg0aJAREhJibSfJ6Ny5c7z7mDp1qpE3b17D0dHRyJ8/vzFt2jRjwIABxuNfo3fv3jU6d+5suLu7Gy4uLkb9+vWNY8eOGZKMr7/+2qbt1atXjc6dOxs+Pj5G2rRpDS8vLyMgIMD44YcfnvpY5cyZ06hVq9YT25w5c8aQZIwcOTLe9WvXrjXKly9vpEuXznB1dTXq1KljHD582KbNhg0bDEnGr7/+arM8vr4fPXrUqFixopEuXTpDktGqVasn1rdnzx5DkrFly5YE2zg7O9vs50l9iomJMYYOHWrkzJnTcHR0NIoXL24sW7bMaNWqlZEzZ06btpKMAQMGxOnP9evXbdpNmzbNkGScOXPmiX2J1a9fP0OS4efnF29/mzZtauTIkcNwdHQ0PD09jdq1axt///13ovYd6/HHxDAS91r6/vvvjYoVKxqvvfaa4ejoaOTJk8fo1auXzXvAMAzjq6++MrJly2bY2dnZ9P3OnTuGg4ODMWXKFFP1Jof9+/cbDg4Oxt69e+Osmz59uuHr62u89tprxscff2w8fPgwUfs8fvy40a5dO8PX19dwcHAwMmTIYJQvX94YP368cf/+fWu7hD4ncubMafO83L5922jdurXh4eFhuLi4GNWrVzeOHj0ap13sa2zXrl02+4t9723YsMG67OHDh0b//v0NLy8vI126dEbVqlWNI0eOGK+99prRoUMHm+3DwsKMvn37Gn5+foaDg4Ph4eFhlCtXzhg1apQRGRmZqMekefPmhiSjWrVqcdatW7fOqFevnpE1a1bDwcHByJo1q9G0aVPj+PHjT91vzpw5DUnWm52dneHp6Wk0bdrUOHnypE3bCxcuGO+8846RMWNGw83NzWjUqJFx6dIlm/fwgwcPjF69ehlFixY1MmTIYDg7OxtFixY1Jk2aFOfYe/fuNd59913r+yBnzpxG48aNjXXr1lnbxPe+r1SpklGpUiXr/YQ+G2M/o6ZNm2b6uI87ePCgIcnYuXPnUx7RuEaOHJngZ9eTPkcf/2w0DMM4deqU0bJlS8PLy8tImzatkS1bNqN27drGb7/9Fqddw4YNjYwZMxpOTk7GG2+8YSxbtsymTUKP2+MKFSpk2NnZGRcuXEhUf2P79O9bmjRpjNy5cxu9evUywsLC4myzYcMGo3r16oabm5vh5ORk5MmTxwgKCrJ+Jt+4ccPo3LmzkT9/fsPZ2dlwc3MzSpcubcyfP99mP1euXDFq1aplZMiQwZBk8zoBAAAvP4thPMNVkV5xFotFixYtUv369SVJ8+bNU/PmzXXo0KE4FwJycXGRl5eXBgwYEOdPDiMiIpQ+fXqtXr1ab7311vPsAgDgOQkODlbx4sX1888/q3nz5ildTqoSEBCgrFmzatasWSldCp5i3LhxGjFihE6dOpUqL4j7qrpz544yZcqkwYMHx7nGBF5sI0aM0JgxY3T58uVXbh7v4sWLy93dXevWrUvpUgAAAJ6IOdaTQPHixRUdHa1r167Jz8/P5hY7t2f58uX18OFDnTp1yrpd7PQAib2gDwAgdYuIiIizbNy4cbKzs1PFihVToKLUbejQoZo3b57OnTuX0qXgCaKiojRmzBh9/vnnhOopKKHPF0mqXLny8y0Gyc7X11djx4595UL1v//+W8HBwWrZsmVKlwIAAPBUjFhPpPDwcJ08eVLSoyB9zJgxqlKlitzd3ZUjRw61aNFC27Zt0+jRo1W8eHFdv35d69atU5EiRVSrVi3FxMTo9ddfl4uLi8aNG6eYmBh17txZrq6uWr16dQr3DgCQFAYNGqTdu3erSpUqSpMmjVauXKmVK1fqww8/1Pfff5/S5QF4gU2fPl3Tp09XzZo15eLioq1bt+qXX37R22+/He+FSoEXycGDB7V7926NHj1aN27c0OnTp60XJgYAAEitCNYTaePGjapSpUqc5a1atdL06dMVFRWlwYMHa+bMmbp48aI8PDxUpkwZDRo0SP7+/pKkS5cuqWvXrlq9erWcnZ0VGBio0aNHy93d/Xl3BwCQDNasWaNBgwbp8OHDCg8PV44cOfT++++rX79+SpOG64UDeHZ79uxR7969FRwcrNDQUGXJkkUNGjTQ4MGD5eLiktLlAf/JwIED9eWXXypfvnyaPHmyKlWqlNIlAQAAPBXBOgAAAAAAAAAAJjDHOgAAAAAAAAAAJhCsAwAAAAAAAABgAhO+PkVMTIwuXbqkDBkyyGKxpHQ5AAAAAAAAwCvJMAyFhYUpa9assrNjvDBSFsH6U1y6dEk+Pj4pXQYAAAAAAAAASf/884+yZ8+e0mXgFUew/hQZMmSQ9OgN6+rqmsLVAAAAAAAAAK+m0NBQ+fj4WPM6ICURrD9F7PQvrq6uBOsAXjpBQUGaM2eOHBwcrMvWrFmjsmXLxts+KipKH330kWbPni2LxaLmzZtr7NixSpPm0dfJuHHjNHToULm6uuqnn35SxYoVJUl37txR+fLltXHjRmXOnDn5OwbgiSIiIuTv768bN27ozp078bbZvXu3unfvrv3798vDw0MDBw5Uy5YtJUnR0dEKCgrS0qVLVbhwYc2fP19Zs2aVJG3fvl2fffaZNmzYwDR6AAAkI37L41XG70ykBkxGBACvuE6dOik8PNx6S+iHuCQNHjxYW7du1eHDh3Xo0CFt2bJFQ4cOlSRduXJFgwcP1r59+zRmzBh17tzZut2nn36qnj178kMcSCW++OIL5cyZM8H1d+7cUc2aNdWiRQvdvn1bv/zyi7p27aqtW7dKkhYuXKizZ8/q6tWrKl26tIYNGybp0X/Yu3btqsmTJ/OfHSAViIiIkJ+fnzJmzJhgm8OHDysgIECZMmWSl5eXPvzwQ927d8+6vlevXnJ3d1fRokV1+PBh6/LTp0+rWLFiun//fnJ2AcBT8FseAFIOwToAINF++uknff755/L29pa3t7f69eunqVOnSpLOnTunvHnzytvbW2+//bZOnTolSdq2bZtOnDih1q1bp2TpAP6/3bt3648//tCnn36aYJvt27fL0dFRHTp0kL29vUqXLq13331XU6ZMkfQoUKtQoYIcHR311ltvWd/vI0eOVJ06dZQ/f/7n0hcAT/a0k2iS1KxZM+XLl09Xr17VgQMHtG/fPn311VeSpF27dmnx4sU6e/asPvjgA5vPjU6dOmnMmDFycnJK1j4ASDr8lgeApEWwDgCvuJkzZ8rd3V2FChXS6NGjFRMTE2+727dv68KFCypWrJh1WbFixXT+/HmFhIQob968OnPmjC5cuKA1a9bI399fUVFR6tatmyZPnvycegPgSR4+fKh27dpp4sSJNn82/riYmBgZhhFn2f79+yVJ/v7+2rJliyIiIrRu3Tr5+/vr5MmT+vXXX9W3b99k7QOAxEnMSTTp0YmyFi1ayMHBQZkzZ1bdunV14MAB67pSpUrJ1dXVJmibM2eOvLy8VLVq1WTvB4An47c8AKQc5lgHgFdYt27dNHLkSLm7u2vXrl1q3Lix7Ozs9NFHH8VpGx4eLkk2f04e+++wsDBlz55d48ePV/369eXq6qopU6Zo+PDhql+/vqKiohQYGKiIiAh1795d77zzzvPoHoDHjBw5UsWLF1fFihW1cePGBNuVLVtWd+/e1YQJE9S+fXvt3LlTixYtkqenpySpZs2a2r59u0qXLq3ChQtr4sSJatKkib755hstW7ZM48ePV7p06TRmzBgVKFDgOfUOQKx/n0RLKGSL1bNnT82cOVPFixdXSEiIFi1apHbt2kmSChcurM8//1x37tzR2rVr5e/vr9u3b2vo0KHatGnT8+gKgCfgtzyA+ERHRysqKiqly3hhpU2bVvb29olqazEeH44EG6GhoXJzc1NISAgXLwXw0ps0aZJmzpypP//8M86627dvy93dXSdPnlSePHkkSSdPnlTevHl1584dubm52bQ/ceKEmjRpoj///FMVK1bUiBEj5O/vryJFimj//v3KlCnTc+kTgEdOnjypgIAA7d27V+7u7tq4caPq16+f4MVLt23bpl69eunYsWMqWLCgSpQooT///FN//fVXnLazZs3Spk2bNGLECBUpUsQ6nUTfvn21Y8eOZO4ZgMcNGzZMJ0+e1NSpU5/6Xt+1a5dat26to0ePKjo6WvXr19f8+fOVNm1aSdKECRM0ZcoU+fj4aNKkSRo0aJAqVaokX19fDRgwQBaLRYMGDVKFChWeYw8BxIff8ngVkNMlzDAMXblyJcHvfCRexowZ5eXl9dTrRjFiHQBgZWeX8AxhmTJlUvbs2RUcHGz9MR4cHCwfH584P8QlqWPHjvr222/l4OCgffv2qXTp0nJ0dFT27Nl14sQJvfHGG8nWDwBxbd26VVevXtX//vc/SY8uNBoWFiYPDw8tX75cpUuXtmlfvnx5bd++3Xq/SZMmqlSpUpz93rx5U8OHD9eWLVt0/Phx+fj4KFOmTCpbtqz27duXvJ0CEMfJkyc1efJk7d2796ltb9++rWrVqunLL79Ux44ddffuXXXt2lUtWrTQvHnzJEldunRRly5dJEmbN2/W+fPn1bx5c+XMmVObNm2SYRiqWrWqzp49y0WLgRTGb3ng1RYbqnt6eip9+vR8Lz8DwzB07949Xbt2TZLk7e39xPYE6wDwCps/f75q1KihDBkyaPfu3fr666/VuXPnBNu3bt1aQ4YMUfny5SVJQ4cOVdu2beO0mzFjhvLkyWMdvZY7d26tWbNGJUqU0IkTJ556ITUASa9x48aqVq2a9f6OHTvUtm1bBQcHW6d4+be9e/eqYMGCiomJ0c8//6yNGzfGG9T17NlT/fr1U6ZMmZQzZ04dP35cFy9e1N69e63/cQfw/Jg5iXbq1ClFRESoW7duslgscnBwUPv27RUYGBhnv5GRkerRo4fmz5+v69ev6+HDh8qdO7d13fXr1+P9LAGQfPgtDyBWdHS0NVR/7bXXUrqcF1q6dOkkSdeuXZOnp+cTp4UhWAeAV9iECRP04Ycf6uHDh8qWLZs6deqkTz75xLq+Q4cOkmS9YFH//v118+ZN65zJLVq00GeffWazzxs3bmjkyJHaunWrddnEiRPVpk0bhYeHa8CAAcqSJUtydw3AY9KnT6/06dNb72fOnFkWi0XZs2eXJAUGBurNN9+0vqe//fZbLVq0SA8fPlS5cuW0fv16Zc2a1WafGzdu1JUrV9S0aVNJkpeXl/r3769ixYrJ1dVV06ZNe069AxDLzEm0/Pnzy8XFRZMmTVL79u0VERGhH3/8UcWLF4+z32HDhqlRo0by8/NTdHS0Hjx4oH379slisSgyMpL/xAMpgN/yAGLFzqn+79/7eHaxj2NUVNQTg3XmWH8K5m4CAAAA8KJ6fI71x0+ibdu2TZ9++qkOHjwoe3t7lS9fXuPGjbOORpekY8eOqXnz5tqxY4d17vV58+bpo48+ksVi0TfffKOGDRs+974BAF495HTxu3//vs6cOaNcuXLJyckppct54SX28SRYfwresAAAAAAAAEDKI6eLH8F60krs45nwlS0AAAAAAAAAAEAcBOsAAAAAAAAA8AoLCgqSxWKRxWJR2rRplSVLFr311lv66aefFBMTk+j9TJ8+XRkzZky+QhMQFBSk+vXrP9djEqwDAAAAAAAAwCuuRo0aunz5ss6ePauVK1eqSpUq6t69u2rXrq2HDx+mdHmpDsE6ALwC5s6dq8aNG6d0GfGaPXu2mjdvntJlAC+N1Px+HzJkiPr165fSZQAA8EJKLd/x0dHR8vf315EjR1K6FABJzNHRUV5eXsqWLZtKlCihzz77TL///rtWrlyp6dOnS5LGjBkjf39/OTs7y8fHR506dVJ4eLikRxdNb926tUJCQqyj3wcOHChJmjVrlkqVKqUMGTLIy8tLzZo107Vr16zHvn37tpo3b67MmTMrXbp0yps3r6ZNm2Zd/88//6hx48bKmDGj3N3dVa9ePZ09e1aSNHDgQM2YMUO///679bgbN25M9seLYB0AXnIxMTH67LPP1L9//wTbLF68WHnz5lX69OlVoUIFHT169In7fFL7gwcPqkiRInJ3d1efPn1stuvQoYOmTp1qs6xp06bauXOn9u7d+wy9A/BvSf1+P3jwoKpXry4PDw9ZLBbduXPHZv3GjRuVJ08eeXp6avz48TbrAgMDtW7dOptl3bt315QpU3TlyhXznQMQR2oJ2eLDiTQgaT3+HR8aGqpmzZrJ1dVVWbJk0VdfffXE7Z/WvlevXnJ3d1fRokV1+PBh6/LTp0+rWLFiun//vnWZvb29evbsqc8++ywJewggtapataqKFi2qhQsXSpLs7Oz07bff6tChQ5oxY4bWr1+v3r17S5LKlSuncePGydXVVZcvX9bly5fVs2dPSVJUVJS++uor7du3T4sXL9bZs2cVFBRkPU7//v11+PBhrVy5UkeOHNF3330nDw8P67bVq1dXhgwZtGXLFm3btk0uLi6qUaOGIiMj1bNnTzVu3Ng64v7y5csqV65c8j84Bp4oJCTEkGSEhISkdCkA8EyWLl1qlCxZMsH1R48eNdKnT28sXbrUiIiIMPr372/873//M6Kiop6pfc2aNY1JkyYZd+7cMXLlymX8/fffhmEYxtatW40qVaoYMTExcfY5YMAAo23btknQW+DVlhzv9ylTphhLly41JBm3b9+2WV+wYEFjxYoVxj///GO4u7sbV65cMQzDMObMmWO0bNky3n22atXKGDx48LN1EIBVdHS0kStXLmP//v0Jtlm0aJHh5+dnpEuXzihfvrxx5MiRBNtOnz7deP311w1XV1fDy8vLaNOmjc17fsOGDUbu3LmNzJkzG99++63NtjVq1DDWrl1rsywsLMzw9PQ0Ll++/GwdBGDj8e/4li1bGtWrVzdu375tHDt2zPDx8TFmzJiR4PZPar9z507Dz8/PCAkJMb755hujdu3a1u2qV69urFu3Ls7+wsPDjQwZMhjnzp1Lwl4CT0dOF7+IiAjj8OHDRkRExDPvo1WrVka9evXiXdekSROjQIEC8a779ddfjddee816f9q0aYabm9tTj7dr1y5DkhEWFmYYhmHUqVPHaN26dbxtZ82aZeTLl88mT3jw4IGRLl06Y9WqVU+t36zEPp6MWAeAl9ySJUtUtWrVBNf//PPPqlKlimrXri0nJyf1799f165d05YtW56p/enTp1W1alW5ubnpjTfe0KlTpxQVFaVu3brpu+++k8ViibPPgIAALV26NGk6DLzCkvr9ni9fPn3wwQcqXLhwvOtj3+/Zs2dX3rx5de7cOd2+fVuDBw/W6NGj490mICBAS5YsMd85ADZWrFghd3d3+fv7x7v+2LFjat68ucaOHatbt26patWqqlevXoLzo967d08jRozQ1atXdejQIV2+fFmdOnWyru/cubMmTJigPXv2aODAgbp69aok6ZdffpGnp6cCAgJs9ufi4qLAwMA4f6kG4Nn8+zv+3r17mjt3rgYPHqyMGTPqf//7n7p27Zrg++1p7U+fPq1SpUrJ1dVVb7/9tk6dOiVJmjNnjry8vOL9beHs7KzXX39dy5cvT6YeA0hNDMOw/l9+7dq1CggIULZs2ZQhQwa9//77unnzpu7du/fEfezevVt16tRRjhw5lCFDBlWqVEmSdP78eUlSx44dNXfuXBUrVky9e/fW9u3brdvu27dPJ0+eVIYMGeTi4iIXFxe5u7vr/v371s+slECwDgAvueDgYOXPnz/B9fv371exYsWs99OmTauCBQtq//79z9Te399fa9as0Z07d7R7924VLlxYI0aMUN26dZUvX75491mwYEFdvXpVly9fNt9BAFZJ/X5/Gn9/f61evVoXLlzQuXPn5Ofnp969e6t3797WP9t8XMGCBRUcHPxMxwPwf5L6RFrHjh1VuXJlOTk5yd3dXR06dNDWrVut6zmRBqSsf3/HHzt2TJGRkTbf6cWKFUvw+/xp7QsXLqy///5bd+7c0dq1a+Xv76/bt29r6NChCb6/Jb7TgVfJkSNHlCtXLp09e1a1a9dWkSJFtGDBAu3evVsTJ06UJEVGRia4/d27d1W9enW5urpq9uzZ2rVrlxYtWmSzXWBgoM6dO6ePPvpIly5dUkBAgHUamfDwcJUsWVLBwcE2t+PHj6tZs2bJ3PuEEawDwEvu9u3bcnV1TXB9eHi4MmbMaLMsY8aMCgsLe6b2o0eP1qpVq1S5cmV1795dDg4OWrBggT755BN16dJFFStWVNeuXRUVFWXdPra+27dvP0MPAcRK6vf700ydOlVjx45V/fr1rfMsnj17VvXq1dP777+vihUratCgQTbbuLq6KjIy8qkjWgA8WXKfSNu0aZOKFClivc+JNCBl/fs7Pjw8XM7OzkqTJo11/dN+vz+pfaFChdS9e3dVrlxZq1at0qhRo9SrVy99+umnOnz4sKpWraqAgACbk23So+90fr8DL7/169frwIEDatCggXbv3q2YmBiNHj1aZcqU0f/+9z9dunTJpr2Dg4Oio6Ntlh09elQ3b97U119/rTfffFP58+e3uXBprMyZM6tVq1b6+eefNW7cOP3www+SpBIlSujEiRPy9PSUn5+fzc3NzS3B4yY3gnUAeMllypRJoaGhkqShQ4da/2wqMDBQ0qM/1Q4JCbHZJiQkRBkyZIh3f09r7+Pjo6VLlyo4OFhdunRRx44d9c033+jnn3/WvXv3tHnzZoWFhemnn36ybh9bX6ZMmZKm08ArKqnf70/j7++v9evX6++//1a9evXUvXt3TZo0SV9//bXy5s2rjRs3atOmTVq1apV1m9DQUDk4OCh9+vTP2EsAUvKeSFu5cqWmTJmiYcOGWZdxIg1IWf/+jndxcdG9e/dspnZ62u/3p7Xv0qWLgoODtXTpUp05c0bnz59X8+bN1axZM02ZMkU//PCDmjdvLsMwrNuEhoby+x14yTx48EBXrlzRxYsXtWfPHg0dOlT16tVT7dq11bJlS/n5+SkqKkrjx4/X6dOnNWvWLE2ePNlmH76+vgoPD9e6det048YN3bt3Tzly5JCDg4N1uyVLlsS5iPIXX3yh33//XSdPntShQ4e0bNkyFShQQJLUvHlzeXh4qF69etqyZYvOnDmjjRs3qlu3brpw4YL1uPv379exY8d048YNm8F8yYVgHQBecsWKFdPRo0clSZ999pnCw8MVHh6ulStXSpKKFCliM5osKipKhw8fTnDOVjPtZ86cKV9fX7355pvat2+fSpcuLUkqW7as9u3bZ213+PBhZcmSRd7e3v+1u8ArLanf72Z8/fXXatCggfLmzWt9v9vZ2al06dJx3u//HkUL4Nkk14m09evXq0WLFlq4cKHNZwMn0oCU9e/v+Hz58ilt2rQ236/BwcEJfp+baR8ZGakePXpo0qRJun79uh4+fKjcuXMrT548ioyM1PXr161t+U4HXj5//PGHvL295evrqxo1amjDhg369ttv9fvvv8ve3l5FixbVmDFjNHz4cBUuXFizZ8+2OREvSeXKlVOHDh3UpEkTZc6cWSNGjFDmzJk1ffp0/frrrypYsKC+/vprjRo1ymY7BwcH9e3bV0WKFFHFihVlb2+vuXPnSpLSp0+vzZs3K0eOHHr33XdVoEABffDBB7p//751oEG7du2UL18+lSpVSpkzZ9a2bduS/wFLkkulvsS42jCAF92SJUuMUqVKJbj+6NGjRvr06Y3ly5cb9+/fNwYMGGDkzZvXiIqK+k/tb9y4YRQqVMi4deuWYRiGMWLECKNx48ZGZGSk0bhxY2PUqFHWtgMHDjTatGmTBL0FXm1J/X6PiYkxIiIijKNHjxqSjCtXrhgRERFGTEyMTbtjx44ZJUuWNCIjIw3DMIxOnToZPXv2NO7fv2+UK1fO+O2336xtg4KCjC+//DIJegu82tq1a2f06tUrwfWff/65Ubt2bev9yMhII1OmTMa6desS3GbdunVGpkyZjD/++OOJxx40aJAxePBgwzAMo0aNGtb2ffr0MYYPH25tN3PmTOONN95IVH8APNnj3/Hvv/++ERgYaNy5c8c4fvy4kSNHDmPGjBkJbp/Y9gMHDjSGDh1qGIZhPHz40MiUKZMRHBxs7Nu3z3B3dzcePnxoGIZh3L1718iQIYNx9uzZJO4p8GTkdPGLiIgwDh8+bERERKR0KS+FxD6eBOtPwRsWwIvu4cOHhq+vr3HgwIEE2yxcuNDw8/MznJycjHLlyhlHjhyxrtu8ebPh7Oyc6PaxWrVqZfzyyy/W+yEhIUZgYKDh6upq1KpVywgLCzMMwzCio6ONvHnzGrt37/6vXQVeeUn9fj9z5owhKc7tzJkzNvusWrWqsW3bNuv9f/75xyhXrpzh5uZmtGzZ0vqf8PDwcMPT09O4dOlSEvUYeHUl9Ym0DRs2GBkzZjSWLVv2xONyIg1IGY9/x4eEhBjvvfee4eLiYmTOnNkYNGiQTfsaNWoYQ4YMsd5/WnvDePS58e/3t2EYxty5cw1vb28ja9asxq+//mpdPnPmTKNu3bpJ3U3gqcjp4kewnrQS+3haDONfE2QhjtDQULm5uSkkJOSJcxgCQGr2yy+/aPHixZo3b15KlxLHnDlztHz5cs2ePTulSwFeCqn5/T506FDdvXtXQ4YMSelSgBdedHS0/Pz8tHTpUhUuXDjeNosWLVLv3r114cIFlShRQlOnTrVe8HTLli0KDAxUeHi4JKlKlSravHmz0qVLZ7OP2PWxAgIC9NVXX6lcuXKSpAsXLqhJkyY6dOiQ6tWrp59++kn29va6e/eucufOreDgYKZ6A5JIavmOj4mJUbFixTR37lwVLFgwRWvBq4ecLn7379/XmTNnlCtXLjk5OaV0OS+8xD6eBOtPwRsWAAAAQGqUWkK2+HAiDQCQHMjp4kewnrQS+3hy8VLEKyoqSl26dFGmTJnk7u6url272lxB3EzbcePGydPTU35+ftq8ebN1+Z07d1SoUCGbi58AAAAASJymTZumylBdenQBZUJ1AADwMiNYR7wGDx6srVu36vDhwzp06JC2bNmioUOHmm575coVDR48WPv27dOYMWPUuXNn63affvqpevbsqcyZMz+XPgEAAAAAAABAUiBYR7x++uknff755/L29pa3t7f69eunqVOnmm577tw55c2bV97e3nr77bd16tQpSdK2bdt04sQJtW7d+rn1CQAAAAAAAACSQpqULgCpz+3bt3XhwgUVK1bMuqxYsWI6f/68QkJC5Obmlui2efPm1ZkzZ3ThwgXt3btX/v7+ioqKUrdu3fTLL788x14BAAAAAAAAQNIgWEcc4eHhkqSMGTNal8X+OywszCZYf1rb7Nmza/z48apfv75cXV01ZcoUDR8+XPXr11dUVJQCAwMVERGh7t2765133knWfgEAAAAAAABAUiBYRxwuLi6SpJCQEHl4eFj/LUkZMmQw3bZRo0Zq1KiRJOnEiRNauHCh/vzzT1WsWFEjRoyQv7+/ihQposqVKytTpkzJ3DsAAAAAAAAA+G+YYx1xZMqUSdmzZ1dwcLB1WXBwsHx8fGxGq5ttK0kdO3bUt99+KwcHB+3bt0+lS5e27uPEiRPJ1SUAAAAAAAAArwBfX1+NGzcu2Y/DiHXEq3Xr1hoyZIjKly8vSRo6dKjatm37n9rOmDFDefLkUYUKFSRJuXPn1po1a1SiRAmdOHFCOXPmTKbeAAAAAAAAAK+ekr1mPtfj7R7ZMtFtLRbLE9cPGDBAAwcONF3Drl275OzsbHo7swjWEa/+/fvr5s2bKlCggCSpRYsW+uyzzyRJHTp0kCRNnjz5qW1j3bhxQyNHjtTWrVutyyZOnKg2bdooPDxcAwYMUJYsWZK9X0Bq8Ly/1PBkZr70ATN4r6c+vN8BAP8V3++pD9/vwIvr8uXL1n/PmzdPX3zxhY4dO2ZdFjsFtSQZhqHo6GilSfP0ODtz5sxJW2gCCNYRr7Rp02rixImaOHFinHWxgXpi2sby8PDQwYMHbZZVrlxZp0+fTpqCAQAAgBRC0Jb6ELQBAJD6eXl5Wf/t5uYmi8ViXbZx40ZVqVJFK1as0Oeff64DBw5o9erV8vHx0ccff6w///xTd+/eVYECBTRs2DBVq1bNui9fX1/16NFDPXr0kPRoZPyPP/6o5cuXa9WqVcqWLZtGjx6tunXr/qf6mWMdAAAAAAAAAJDq9OnTR19//bWOHDmiIkWKKDw8XDVr1tS6deu0d+9e1ahRQ3Xq1NH58+efuJ9BgwapcePG2r9/v2rWrKnmzZvr1q1b/6k2gnUAAAAAAAAAQKrz5Zdf6q233lKePHnk7u6uokWLqn379ipcuLDy5s2rr776Snny5NGSJUueuJ+goCA1bdpUfn5+Gjp0qMLDw7Vz587/VBvBOgAAAAAAAAAg1SlVqpTN/fDwcPXs2VMFChRQxowZ5eLioiNHjjx1xHqRIkWs/3Z2dparq6uuXbv2n2pjjnUAAAAAAAAAQKrj7Oxsc79nz55as2aNRo0aJT8/P6VLl04NGzZUZGTkE/eTNm1am/sWi0UxMTH/qTZGrL/C5s6dq8aNG6d0GfEaMmSI+vXrl9JlAAAAAAAAAEgltm3bpqCgIL3zzjvy9/eXl5eXzp49myK1EKy/omJiYvTZZ5+pf//+T2372WefyWKxaPHixQm2efjwoXr06KGsWbPKzc1NFSpU0O7du63rN27cqDx58sjT01Pjx4+32TYwMFDr1q2zWda9e3dNmTJFV65cMdcxAAAAAAAAAC+lvHnzauHChQoODta+ffvUrFmz/zzy/FkRrL+iVqxYIXd3d/n7+z+x3b59+7R06VJ5e3s/sd2ECRO0dOlS7dixQ7du3VKNGjVUt25dGYYhSercubMmTJigPXv2aODAgbp69aok6ZdffpGnp6cCAgJs9ufi4qLAwEBNnTr1P/QSAAAAAAAAwMtizJgxypQpk8qVK6c6deqoevXqKlGiRIrUwhzrr6glS5aoatWqT2wTHR2ttm3basKECWrVqtUT254+fVoBAQHKmTOnJKl169bq37+/bt68KQ8PD50+fVpVq1aVo6Oj8ubNq3PnzsnBwUGDBw/Wpk2b4t1nQECAJkyYwJQwAAAAAAAAwDPYPbJlSpeQKEFBQQoKCrLer1y5snXA7r/5+vpq/fr1Nss6d+5sc//xqWHi28+dO3eeudZYjFh/RQUHByt//vxPbDN27FgVKVJElSpVeur+PvjgA+3evVunTp1SVFSUpkyZorJly8rDw0OS5O/vr9WrV+vChQs6d+6c/Pz81Lt3b/Xu3dva5nEFCxZUcHCw6b4BAAAAAAAAQHJixPor6vbt23J1dU1w/enTp61TtyRG7ty5VaxYMfn5+cne3l5ZsmTRypUrreunTp2q7t27KzQ0VN9++60OHTqks2fPauTIkXr//fd17tw5BQQEaMCAAdZtXF1dFRkZqXv37il9+vTP3lkAAAAAAAAASEKMWH9FZcqUSaGhoZKkoUOHysXFxTqvuSR9+OGHGjx4sNzd3RO1v06dOuncuXO6dOmS7t+/r2+++UZVq1bVpUuXJD0asb5+/Xr9/fffqlevnrp3765Jkybp66+/Vt68ebVx40Zt2rRJq1atsu4zNDRUDg4OhOoAAAAAAAAAUhWC9VdUsWLFdPToUUnSZ599pvDwcIWHh1tHma9bt049evSQh4eHPDw89M8//6hly5b66KOP4t3f3r17FRQUJG9vb6VJk0YNGzaUm5ubtm/fHqft119/rQYNGihv3rzat2+fSpcuLTs7O5UuXVr79u2ztjt8+LCKFSuW9J0HAAAAAAAAgP+AYP0VVadOHW3YsCHB9f/884+Cg4Ott6xZs2rs2LH64osv4m1ftmxZzZw5U9evX1dMTIwWLVqkCxcuyN/f36bd8ePHtWTJEvXu3VvSoylk1q5dqwcPHmjz5s3KkyePte369etVu3btJOgtAAAAAAAAACQdgvVXVM2aNXXjxg0dPHgw3vXZs2e3udnb2+u1115TpkyZJEmzZ89WoUKFrO1HjRolHx8fFSlSRBkzZtSAAQM0c+ZM5cuXz2a/HTt21Lfffqu0adNKkvr27avt27crS5Ys8vPzU/369SVJd+/e1YoVK9S2bdtk6D0AAAAAAAAAPDsuXvqKsre319ChQ/XVV19p3rx5T21/9uxZm/vNmzdX8+bNrffd3Nw0derUp+5n3bp1NvezZ8+ubdu2xWn3zTffqG3btvL29n7qPgEAAAAAAADgeSJYf4U1bdpUTZs2Teky4vXZZ5+ldAkAAAAAAAAAEC+mggEAAAAAAAAAwASCdQAAAAAAAAAATGAqGAAAAAAAAAB4CZ3/0v+5Hi/HFwcS3dZisTxx/YABAzRw4MBnqsNisWjRokWqX7/+M22fGATrAAAAAAAAAIDn6vLly9Z/z5s3T1988YWOHTtmXebi4pISZSUaU8EAAAAAAAAAAJ4rLy8v683NzU0Wi8Vm2dy5c1WgQAE5OTkpf/78mjRpknXbyMhIdenSRd7e3nJyclLOnDk1bNgwSZKvr68k6Z133pHFYrHeT2qMWAcAAAAAAAAApBqzZ8/WF198oQkTJqh48eLau3ev2rVrJ2dnZ7Vq1UrffvutlixZovnz5ytHjhz6559/9M8//0iSdu3aJU9PT02bNk01atSQvb19stRIsA4AAAAAAAAASDUGDBig0aNH691335Uk5cqVS4cPH9b333+vVq1a6fz588qbN68qVKggi8WinDlzWrfNnDmzJCljxozy8vJKthoJ1gEAAAAAAAAAqcLdu3d16tQpffDBB2rXrp11+cOHD+Xm5iZJCgoK0ltvvaV8+fKpRo0aql27tt5+++3nWifBeipRstfMlC4Bj9k9smVKlwAAAAAAAAC8UsLDwyVJP/74o0qXLm2zLnZalxIlSujMmTNauXKl1q5dq8aNG6tatWr67bffnludBOsAAAAAAAAAgFQhS5Ysypo1q06fPq3mzZsn2M7V1VVNmjRRkyZN1LBhQ9WoUUO3bt2Su7u70qZNq+jo6GStk2AdAAAAAAAAAJBqDBo0SN26dZObm5tq1KihBw8e6O+//9bt27f18ccfa8yYMfL29lbx4sVlZ2enX3/9VV5eXsqYMaMkydfXV+vWrVP58uXl6OioTJkyJXmNdkm+RwAAAAAAAAAAnlHbtm01ZcoUTZs2Tf7+/qpUqZKmT5+uXLlySZIyZMigESNGqFSpUnr99dd19uxZrVixQnZ2j+Lu0aNHa82aNfLx8VHx4sWTpUZGrAMAAAAAAADASyjHFwdSuoRECQoKUlBQkM2yZs2aqVmzZvG2b9eunc2FTR9Xp04d1alTJylLjIMR6wAAAAAAAAAAmECwDgAAAAAAAACACQTrAAAAAAAAAACYQLAOAAAAAAAAAIAJBOsAAAAAAAAAAJhAsA4AAAAAAAAAL7iYmJiULuGlkNjHMU0y1wEAAAAAAAAASCYODg6ys7PTpUuXlDlzZjk4OMhisaR0WS8cwzAUGRmp69evy87OTg4ODk9sT7AOAAAAAAAAAC8oOzs75cqVS5cvX9alS5dSupwXXvr06ZUjRw7Z2T15sheCdQAAAAAAAAB4gTk4OChHjhx6+PChoqOjU7qcF5a9vb3SpEmTqBH/BOsAAAAAAAAA8IKzWCxKmzat0qZNm9KlvBK4eCkAAAAAAAAAACYQrAMAAAAAAAAAYALBOgAAAAAAAAAAJhCsAwAAAAAAAABgAsE6AAAAAAAAAAAmEKwDAAAAAAAAAGDCCxWsb968WXXq1FHWrFllsVi0ePHiJ7bfuHGjLBZLnNuVK1eeT8EAAAAAAAAAgJfOCxWs3717V0WLFtXEiRNNbXfs2DFdvnzZevP09EymCgEAAAAAAAAAL7s0KV2AGYGBgQoMDDS9naenpzJmzJj0BQEAAAAAAAAAXjkv1Ij1Z1WsWDF5e3vrrbfe0rZt257Y9sGDBwoNDbW5AQAAAAAAAAAQ66UO1r29vTV58mQtWLBACxYskI+PjypXrqw9e/YkuM2wYcPk5uZmvfn4+DzHigEAAAAAAAAAqd0LNRWMWfny5VO+fPms98uVK6dTp05p7NixmjVrVrzb9O3bVx9//LH1fmhoKOE6AAAAAAAAAMDqpQ7W4/PGG29o69atCa53dHSUo6Pjc6wIAAAAAAAAAPAieamngolPcHCwvL29U7oMAAAAAAAAAMAL6oUasR4eHq6TJ09a7585c0bBwcFyd3dXjhw51LdvX128eFEzZ86UJI0bN065cuVSoUKFdP/+fU2ZMkXr16/X6tWrU6oLAAAAAAAAAIAX3AsVrP/999+qUqWK9X7sXOitWrXS9OnTdfnyZZ0/f966PjIyUp988okuXryo9OnTq0iRIlq7dq3NPgAAAAAAAAAAMOOFCtYrV64swzASXD99+nSb+71791bv3r2TuSoAAAAAAAAAwKvklZtjHQAAAAAAAACA/4JgHQAAAAAAAAAAEwjWAQAAAAAAAAAwgWAdAAAAAAAAAAATCNYBAAAAAAAAADCBYB0AAAAAAAAAABMI1gEAAAAAAAAAMIFgHQAAAAAAAAAAEwjWAQAAAAAAAAAwgWAdAAAAAAAAAAATCNYBAAAAAAAAADCBYB0AAAAAAAAAABMI1gEAAAAAAAAAMIFgHQAAAAAAAAAAEwjWAQAAAAAAAAAwgWAdAAAAAAAAAAATCNYBAAAAAAAAADCBYB0AAAAAAAAAABMI1gEAAAAAAAAAMIFgHQAAAAAAAAAAEwjWAQAAAAAAAAAwgWAdAAAAAAAAAAATCNYBAAAAAAAAADCBYB0AAAAAAAAAABMI1gEAAAAAAAAAMIFgHQAAAAAAAAAAEwjWAQAAAAAAAAAwgWAdAAAAAAAAAAATCNYBAAAAAAAAADCBYB0AAAAAAAAAABMI1gEAAAAAAAAAMIFgHQAAAAAAAAAAEwjWAQAAAAAAAAAwgWAdAAAAAAAAAAATCNYBAAAAAAAAADCBYB0AAAAAAAAAABMI1gEAAAAAAAAAMIFgHQAAAAAAAAAAEwjWAQAAAAAAAAAwgWAdAAAAAAAAAAATCNYBAAAAAAAAADCBYB0AAAAAAAAAABMI1gEAAAAAAAAAMIFgHQAAAAAAAAAAEwjWAQAAAAAAAAAwgWAdAAAAAAAAAAATCNYBAAAAAAAAADCBYB0AAAAAAAAAABMI1gEAAAAAAAAAMIFgHQAAAAAAAAAAEwjWAQAAAAAAAAAwgWAdAAAAAAAAAAATCNYBAAAAAAAAADCBYB0AAAAAAAAAABMI1gEAAAAAAAAAMIFgHQAAAAAAAAAAEwjWAQAAAAAAAAAwgWAdAAAAAAAAAAATCNYBAAAAAAAAADCBYB0AAAAAAAAAABMI1gEAAAAAAAAAMIFgHQAAAAAAAAAAEwjWAQAAAAAAAAAwgWAdAAAAAAAAAAATCNYBAAAAAAAAADCBYB0AAAAAAAAAABMI1gEAAAAAAAAAMIFgHQAAAAAAAAAAEwjWAQAAAAAAAAAwgWAdAAAAAAAAAAATCNYBAAAAAAAAADCBYB0AAAAAAAAAABMI1gEAAAAAAAAAMIFgHQAAAAAAAAAAEwjWAQAAAAAAAAAwgWAdAAAAAAAAAAATCNYBAAAAAAAAADCBYB0AAAAAAAAAABMI1gEAAAAAAAAAMIFgHQAAAAAAAAAAEwjWAQAAAAAAAAAwgWAdAAAAAAAAAAATCNYBAAAAAAAAADCBYB0AAAAAAAAAABMI1gEAAAAAAAAAMIFgHQAAAAAAAAAAEwjWAQAAAAAAAAAwgWAdAAAAAAAAAAATCNYBAAAAAAAAADCBYB0AAAAAAAAAABMI1gEAAAAAAAAAMIFgHQAAAAAAAAAAEwjWAQAAAAAAAAAwgWAdAAAAAAAAAAATCNYBAAAAAAAAADCBYB0AAAAAAAAAABMI1gEAAAAAAAAAMIFgHQAAAAAAAAAAEwjWAQAAAAAAAAAwgWAdAAAAAAAAAAATCNYBAAAAAAAAADCBYB0AAAAAAAAAABMI1gEAAAAAAAAAMIFgHQAAAAAAAAAAEwjWAQAAAAAAAAAwgWAdAAAAAAAAAAATCNYBAAAAAAAAADCBYB0AAAAAAAAAABMI1gEAAAAAAAAAMIFgHQAAAAAAAAAAEwjWAQAAAAAAAAAwgWAdAAAAAAAAAAATCNYBAAAAAAAAADCBYB0AAAAAAAAAABMI1gEAAAAAAAAAMIFgHQAAAAAAAAAAEwjWAQAAAAAAAAAwgWAdAAAAAAAAAAATCNYBAAAAAAAAADCBYB0AAAAAAAAAABMI1gEAAAAAAAAAMIFgHQAAAAAAAAAAEwjWAQAAAAAAAAAwgWAdAAAAAAAAAAATCNYBAAAAAAAAADCBYB0AAAAAAAAAABMI1gEAAAAAAAAAMIFgHQAAAAAAAAAAEwjWAQAAAAAAAAAwgWAdAAAAAAAAAAATCNYBAAAAAAAAADCBYB0AAAAAAAAAABMI1gEAAAAAAAAAMIFgHQAAAAAAAAAAEwjWAQAAAAAAAAAwgWAdAAAAAAAAAAATCNYBAAAAAAAAADCBYB0AAAAAAAAAABMI1gEAAAAAAAAAMIFgHQAAAAAAAAAAEwjWAQAAAAAAAAAwgWAdAAAAAAAAAAATCNYBAAAAAAAAADCBYB0AAAAAAAAAABMI1gEAAAAAAAAAMIFgHQAAAAAAAAAAEwjWAQAAAAAAAAAwgWAdAAAAAAAAAAATCNYBAAAAAAAAADCBYB0AAAAAAAAAABMI1gEAAAAAAAAAMIFgHQAAAAAAAAAAEwjWAQAAAAAAAAAwgWAdAAAAAAAAAAATCNYBAAAAAAAAADDhhQrWN2/erDp16ihr1qyyWCxavHjxU7fZuHGjSpQoIUdHR/n5+Wn69OnJXicAAAAAAAAA4OX1QgXrd+/eVdGiRTVx4sREtT9z5oxq1aqlKlWqKDg4WD169FDbtm21atWqZK4UAAAAAAAAAPCySpPSBZgRGBiowMDARLefPHmycuXKpdGjR0uSChQooK1bt2rs2LGqXr16cpUJAAAAAAAAAHiJvVAj1s3asWOHqlWrZrOsevXq2rFjRwpVBAAAAAAAAAB40b1QI9bNunLlirJkyWKzLEuWLAoNDVVERITSpUsXZ5sHDx7owYMH1vuhoaHJXicAAAAAAAAA4MXxUo9YfxbDhg2Tm5ub9ebj45PSJQEAAAAAAAAAUpGXOlj38vLS1atXbZZdvXpVrq6u8Y5Wl6S+ffsqJCTEevvnn3+eR6kAAAAAAAAAgBfESz0VTNmyZbVixQqbZWvWrFHZsmUT3MbR0VGOjo7JXRoAAAAAAAAA4AX1Qo1YDw8PV3BwsIKDgyVJZ86cUXBwsM6fPy/p0Wjzli1bWtt36NBBp0+fVu/evXX06FFNmjRJ8+fP10cffZQS5QMAAAAAAAAAXgIvVLD+999/q3jx4ipevLgk6eOPP1bx4sX1xRdfSJIuX75sDdklKVeuXFq+fLnWrFmjokWLavTo0ZoyZYqqV6+eIvUDAAAAAAAAAF58L9RUMJUrV5ZhGAmunz59erzb7N27NxmrAgAAAAAAAAC8Sl6oEesAAAAAAAAAAKQ0gnUAAAAAAAAAAEwgWAcAAAAAAAAAwASCdQAAAAAAAAAATCBYBwAAAAAAAADABIJ1AAAAAAAAAABMIFgHAAAAAAAAAMAEgnUAAAAAAAAAAEwgWAcAAAAAAAAAwASCdQAAAAAAAAAATCBYBwAAAAAAAADABIJ1AAAAAAAAAABMIFgHAAAAAAAAAMAEgnUAAAAAAAAAAEwgWAcAAAAAAAAAwASCdQAAAAAAAAAATCBYBwAAAAAAAADABIJ1AAAAAAAAAABMIFgHAAAAAAAAAMAEgnUAAAAAAAAAAEwgWAcAAAAAAAAAwASCdQAAAAAAAAAATCBYBwAAAAAAAADABIJ1AAAAAAAAAABMIFgHAAAAAAAAAMAEgnUAAAAAAAAAAEwgWAcAAAAAAAAAwASCdQAAAAAAAAAATCBYBwAAAAAAAADABIJ1AAAAAAAAAABMIFgHAAAAAAAAAMAEgnUAAAAAAAAAAEwgWAcAAAAAAAAAwASCdQAAAAAAAAAATCBYBwAAAAAAAADABIJ1AAAAAAAAAABMIFgHAAAAAAAAAMAEgnUAAAAAAAAAAEwgWAcAAAAAAAAAwASCdQAAAAAAAAAATCBYBwAAAAAAAADABIJ1AAAAAAAAAABMIFgHAAAAAAAAAMAEgnUAAAAAAAAAAEwgWAcAAAAAAAAAwASCdQAAAAAAAAAATCBYBwAAAAAAAADABIJ1AAAAAAAAAABMIFgHAAAAAAAAAMAEgnUAAAAAAAAAAEwgWAcAAAAAAAAAwASCdQAAAAAAAAAATCBYBwAAAAAAAADABIJ1AAAAAAAAAABMIFgHAAAAAAAAAMAEgnUAAAAAAAAAAEwgWAcAAAAAAAAAwASCdQAAAAAAAAAATCBYBwAAAAAAAADABIJ1AAAAAAAAAABMIFgHAAAAAAAAAMAEgnUAAAAAAAAAAEwgWAcAAAAAAAAAwASCdQAAAAAAAAAATCBYBwAAAAAAAADABIJ1AAAAAAAAAABMIFgHAAAAAAAAAMAEgnUAAAAAAAAAAEwgWAcAAAAAAAAAwASCdQAAAAAAAAAATCBYBwAAAAAAAADABIJ1AAAAAAAAAABMIFgHAAAAAAAAAMAEgnUAAAAAAAAAAEwgWAcAAAAAAAAAwASCdQAAAAAAAAAATCBYBwAAAAAAAADABIJ1AAAAAAAAAABMIFgHAAAAAAAAAMAEgnUAAAAAAAAAAEwgWAcAAAAAAAAAwATTwXrVqlV1586dOMtDQ0NVtWrVpKgJAAAAAAAAAIBUy3SwvnHjRkVGRsZZfv/+fW3ZsiVJigIAAAAAAAAAILVKk9iG+/fvt/778OHDunLlivV+dHS0/vjjD2XLli1pqwMAAAAAAAAAIJVJdLBerFgxWSwWWSyWeKd8SZcuncaPH5+kxQEAAAAAAAAAkNokOlg/c+aMDMNQ7ty5tXPnTmXOnNm6zsHBQZ6enrK3t0+WIgEAAAAAAAAASC0SHaznzJlTkhQTE5NsxQAAAAAAAAAAkNolKlhfsmSJAgMDlTZtWi1ZsuSJbevWrZskhQEAAAAAAAAAkBolKlivX7++rly5Ik9PT9WvXz/BdhaLRdHR0UlVGwAAAAAAAAAAqU6igvV/T//CVDAAAAAAAAAAgFeZXWIaubu768aNG5KkNm3aKCwsLFmLAgAAAAAAAAAgtUpUsB4ZGanQ0FBJ0owZM3T//v1kLQoAAAAAAAAAgNQqUVPBlC1bVvXr11fJkiVlGIa6deumdOnSxdv2p59+StICAQAAAAAAAABITRIVrP/8888aO3asTp06JYvFopCQEEatAwAAAAAAAABeSYkK1rNkyaKvv/5akpQrVy7NmjVLr732WrIWBgAAAAAAAABAapSoYP3fzpw5kxx1AAAAAAAAAADwQkjUxUsft2nTJtWpU0d+fn7y8/NT3bp1tWXLlqSuDQAAAAAAAACAVMd0sP7zzz+rWrVqSp8+vbp162a9kGlAQIDmzJmTHDUCAAAAAAAAAJBqmJ4KZsiQIRoxYoQ++ugj67Ju3bppzJgx+uqrr9SsWbMkLRAAAAAAAAAAgNTE9Ij106dPq06dOnGW161bl/nXAQAAAAAAAAAvPdPBuo+Pj9atWxdn+dq1a+Xj45MkRQEAAAAAAAAAkFqZngrmk08+Ubdu3RQcHKxy5cpJkrZt26bp06frm2++SfICAQAAAAAAAABITUwH6x07dpSXl5dGjx6t+fPnS5IKFCigefPmqV69ekleIAAAAAAAAAAAqYmpYP3hw4caOnSo2rRpo61btyZXTQAAAAAAAAAApFqm5lhPkyaNRowYoYcPHyZXPQAAAAAAAAAApGqmL14aEBCgTZs2JUctAAAAAAAAAACkeqbnWA8MDFSfPn104MABlSxZUs7Ozjbr69atm2TFAQAAAAAAAACQ2pgO1jt16iRJGjNmTJx1FotF0dHR/70qAAAAAAAAAABSKdPBekxMTHLUAQAAAAAAAADAC8FUsH727FmtWbNGUVFRqlSpkgoVKpRcdQEAAAAAAAAAkColOljfsGGDateurYiIiEcbpkmjn376SS1atEi24gAAAAAAAAAASG3sEtuwf//+euutt3Tx4kXdvHlT7dq1U+/evZOzNgAAAAAAAAAAUp1EB+sHDx7U0KFD5e3trUyZMmnkyJG6du2abt68mZz1AQAAAAAAAACQqiQ6WA8NDZWHh4f1fvr06ZUuXTqFhIQkS2EAAAAAAAAAAKRGpi5eumrVKrm5uVnvx8TEaN26dTp48KB1Wd26dZOuOgAAAAAAAAAAUhlTwXqrVq3iLGvfvr313xaLRdHR0f+9KgAAAAAAAAAAUqlEB+sxMTHJWQcAAAAAAAAAAC+ERM+xDgAAAAAAAAAACNYBAAAAAAAAADCFYB0AAAAAAAAAABMI1gEAAAAAAAAAMIFgHQAAAAAAAAAAE54pWL9z546mTJmivn376tatW5KkPXv26OLFi0laHAAAAAAAAAAAqU0asxvs379f1apVk5ubm86ePat27drJ3d1dCxcu1Pnz5zVz5szkqBMAAAAAAAAAgFTB9Ij1jz/+WEFBQTpx4oScnJysy2vWrKnNmzcnaXEAAAAAAAAAAKQ2poP1Xbt2qX379nGWZ8uWTVeuXEmSogAAAAAAAAAASK1MB+uOjo4KDQ2Ns/z48ePKnDlzkhQFAAAAAAAAAEBqZTpYr1u3rr788ktFRUVJkiwWi86fP69PP/1UDRo0SPICAQAAAAAAAABITUwH66NHj1Z4eLg8PT0VERGhSpUqyc/PTxkyZNCQIUOSo0YAAAAAAAAAAFKNNGY3cHNz05o1a7R161bt379f4eHhKlGihKpVq5Yc9QEAAAAAAAAAkKqYDtZjVahQQRUqVEjKWgAAAAAAAAAASPVMB+vffvttvMstFoucnJzk5+enihUryt7e/j8XBwAAAAAAAABAamM6WB87dqyuX7+ue/fuKVOmTJKk27dvK3369HJxcdG1a9eUO3dubdiwQT4+PkleMAAAAAAAAAAAKcn0xUuHDh2q119/XSdOnNDNmzd18+ZNHT9+XKVLl9Y333yj8+fPy8vLSx999FFy1AsAAAAAAAAAQIoyPWL9888/14IFC5QnTx7rMj8/P40aNUoNGjTQ6dOnNWLECDVo0CBJCwUAAAAAAAAAIDUwPWL98uXLevjwYZzlDx8+1JUrVyRJWbNmVVhY2H+vDgAAAAAAAACAVMZ0sF6lShW1b99ee/futS7bu3evOnbsqKpVq0qSDhw4oFy5ciVdlQAAAAAAAAAApBKmg/WpU6fK3d1dJUuWlKOjoxwdHVWqVCm5u7tr6tSpkiQXFxeNHj06yYsFAAAAAAAAACClmZ5j3cvLS2vWrNHRo0d1/PhxSVK+fPmUL18+a5sqVaokXYUAAAAAAAAAAKQipoP1WPnz51f+/PmTshYAAAAAAAAAAFK9ZwrWL1y4oCVLluj8+fOKjIy0WTdmzJgkKQwAAAAAAAAAgNTIdLC+bt061a1bV7lz59bRo0dVuHBhnT17VoZhqESJEslRIwAAAAAAAAAAqYbpi5f27dtXPXv21IEDB+Tk5KQFCxbon3/+UaVKldSoUaPkqBEAAAAAAAAAgFTDdLB+5MgRtWzZUpKUJk0aRUREyMXFRV9++aWGDx+e5AUCAAAAAAAAAJCamA7WnZ2drfOqe3t769SpU9Z1N27cSLrKAAAAAAAAAABIhUzPsV6mTBlt3bpVBQoUUM2aNfXJJ5/owIEDWrhwocqUKZMcNQIAAAAAAAAAkGqYDtbHjBmj8PBwSdKgQYMUHh6uefPmKW/evBozZkySFwgAAAAAAAAAQGpiKliPjo7WhQsXVKRIEUmPpoWZPHlyshQGAAAAAAAAAEBqZGqOdXt7e7399tu6fft2ctUDAAAAAAAAAECqZvripYULF9bp06eToxYAAAAAAAAAAFI908H64MGD1bNnTy1btkyXL19WaGiozQ0AAAAAAAAAgJeZ6YuX1qxZU5JUt25dWSwW63LDMGSxWBQdHZ101QEAAAAAAAAAkMqYDtY3bNiQHHUAAAAAAAAAAPBCMB2sV6pUKTnqAAAAAAAAAADghWB6jnVJ2rJli1q0aKFy5crp4sWLkqRZs2Zp69atSVocAAAAAAAAAACpjelgfcGCBapevbrSpUunPXv26MGDB5KkkJAQDR06NMkLfNzEiRPl6+srJycnlS5dWjt37kyw7fTp02WxWGxuTk5OyV4jAAAAAAAAAODlZTpYHzx4sCZPnqwff/xRadOmtS4vX7689uzZk6TFPW7evHn6+OOPNWDAAO3Zs0dFixZV9erVde3atQS3cXV11eXLl623c+fOJWuNAAAAAAAAAICXm+lg/dixY6pYsWKc5W5ubrpz505S1JSgMWPGqF27dmrdurUKFiyoyZMnK3369Prpp58S3MZiscjLy8t6y5IlS7LWCAAAAAAAAAB4uZkO1r28vHTy5Mk4y7du3arcuXMnSVHxiYyM1O7du1WtWjXrMjs7O1WrVk07duxIcLvw8HDlzJlTPj4+qlevng4dOpRsNQIAAAAAAAAAXn6mg/V27dqpe/fu+uuvv2SxWHTp0iXNnj1bPXv2VMeOHZOjRknSjRs3FB0dHWfEeZYsWXTlypV4t8mXL59++ukn/f777/r5558VExOjcuXK6cKFCwke58GDBwoNDbW5AQAAAAAAAAAQK43ZDfr06aOYmBgFBATo3r17qlixohwdHdWzZ0917do1OWp8ZmXLllXZsmWt98uVK6cCBQro+++/11dffRXvNsOGDdOgQYOeV4kAAAAAAAAAgBeM6RHrFotF/fr1061bt3Tw4EH9+eefun79eoJBdVLx8PCQvb29rl69arP86tWr8vLyStQ+0qZNq+LFi8c7lU2svn37KiQkxHr7559//lPdAAAAAAAAAICXi+lg/eeff9a9e/fk4OCgggUL6o033pCLi0ty1GbDwcFBJUuW1Lp166zLYmJitG7dOptR6U8SHR2tAwcOyNvbO8E2jo6OcnV1tbkBAAAAAAAAABDLdLD+0UcfydPTU82aNdOKFSsUHR2dHHXF6+OPP9aPP/6oGTNm6MiRI+rYsaPu3r2r1q1bS5Jatmypvn37Wtt/+eWXWr16tU6fPq09e/aoRYsWOnfunNq2bfvcagYAAAAAAMDL4fLly6pbt66yZs0qi8Wi4ODgOG2GDBminDlzytXVVcWLF9fq1aut62bMmKE33nhDbm5u8vb21gcffKA7d+4keLxp06YpX758cnNzk4eHh959912dP3/eun7evHnKli2bsmXLpt9++826PCoqSqVKldKRI0eSpN8A4jIdrF++fFlz586VxWJR48aN5e3trc6dO2v79u3JUZ+NJk2aaNSoUfriiy9UrFgxBQcH648//rBe0PT8+fO6fPmytf3t27fVrl07FShQQDVr1lRoaKi2b9+uggULJnutAAAAAAAAeLnY2dmpRo0aWrx4cbzrFy9erFGjRmnZsmUKCQnRxx9/rHfeeUe3bt2SJN27d08jRozQ1atXdejQIV2+fFmdOnVK8HhVq1bVtm3bFBISogsXLihPnjxq06aNpEczM3Ts2FGrVq3S8uXL1b59e+sA2FGjRqlWrVoqUKBA0j4AAKxMX7w0TZo0ql27tmrXrq179+5p0aJFmjNnjqpUqaLs2bPr1KlTyVGnVZcuXdSlS5d4123cuNHm/tixYzV27NhkrQcAAAAAAACvhixZsjwxCD99+rRef/11+fv7S5Lef/99ffDBBzp9+rTc3d3VsWNHa1snJyd16NAhwZxLknLmzGn9t2EYsrOz04kTJyRJN27ckKOjowoXLizp0bUFb968qbCwMM2fP19//vnnf+orgCczHaz/W/r06VW9enXdvn1b586d489LAAAAAAAA8Mpq0qSJpk+frr1796pIkSKaOXOmsmfPbg2/H7dp0yYVKVLkifvcunWrateurZCQEKVJk0YTJ06UJGXOnFl2dnbat2+fJMne3l4eHh5q0aKFxo4dK0dHx6TtHAAbzxSsx45Unz17ttatWycfHx81bdrUZi4nAAAAAAAA4FXi6empWrVqqVSpUrJYLHJ2dtbChQvl5OQUp+3KlSs1ZcoUbd269Yn7rFChgu7cuaMbN25oypQp1imO7ezsNHv2bOso+NmzZ2vOnDny8fGRn5+fdQqapk2bqkOHDknfWeAVZzpYf++997Rs2TKlT59ejRs3Vv/+/VW2bNnkqA0AAAAAAABIMbNnz1b79u0lPZqW5dChQ09s/+WXX2rFihU6fvy4cuXKpc2bN6thw4Zau3atihUrZm23fv16tWjRQgsXLrROG/M0Hh4e+uCDD5Q3b15dvHhRzs7Oqly5svW6h7du3VKXLl20efNmderUSe+8844aN26sEiVKqFKlSsy3DiQx0xcvtbe31/z583X58mVNmDDBJlQ/ePBgkhYHAAAAAAAApJTmzZsrPDxc4eHhTw3VJWnv3r1q1KiR8uTJIzs7O1WuXFlFixbV2rVrrW3Wr1+vhg0bas6cOQoICDBVT1RUlEJCQnTt2rU463r27Km+ffvK3d1d+/btU+nSpeXk5KSiRYvqwIEDpo4D4OlMB+uzZ89WzZo1ZW9vL0kKCwvTDz/8oDfeeENFixZN8gIBAAAAAACA1OL+/fu6f/++JCkyMlL3799XTEyMJKls2bL67bffdO7cORmGoW3btmnnzp3W0eobN25UgwYNNGvWLFWvXv2px5o2bZouXLggwzB05coVdevWTf/73//k6+tr027jxo26dOmSmjdvLknKnTu31qxZo9DQUO3cuVN58uRJugcAgKRnCNZjbd68Wa1atZK3t7dGjRqlqlWrcrVhAAAAAAAAvNTSpUundOnSSZJKly6tdOnSafPmzZKk3r17KyAgQBUqVJCrq6tat26toUOHqlq1apKkQf+vvfuOsrI63wZ8zwwwIDADSK+KBQRBxEJMjCJqFLvGRkzsDSWxBKNijSb2xIbGmhgTbCkaGyom9t5AI0hsCEpRpAyItJn5/uDnfCGCehQcynWtNUvOu/f7nmcf16bcs2fvX/4yFRUV2W+//dKoUaOar88MGzYs3bt3r3k9cuTI9OnTJ40aNUrv3r1Tt27dDB8+PEVFRTV95s2blxNPPDFXX311zbULL7ww1157bdZaa63ss88+2WSTTZbrZwKro4L2WJ88eXJuuumm3HjjjamoqMi+++6befPm5a677qo5OAEAAAAAVlXV1dVLbatbt25+85vf5De/+c0S2x955JEvfPYBBxxQs+o8SS6//PJcfvnlX3hPaWlpXn755cWubbjhhrZ/geXsK69Y33XXXdOlS5e8+uqrueyyyzJx4sRceeWVy7M2AAAAAABY4XzlFevDhw/Pz372swwcODDrrbfe8qwJAAAAAABWWF95xfqTTz6ZWbNmZZNNNkmfPn0ydOjQTJ06dXnWBgAAAAAAK5yvHKx/5zvfyfXXX59JkyblqKOOym233Za2bdumqqoqI0aMyKxZs5ZnnQAAAAAAsEL4ysH6Zxo2bJhDDz00Tz75ZF577bX8/Oc/zwUXXJCWLVtmt912Wx41AgAAAMAK5bbbbsu+++5b22WksrIyPXr0yJgxY2q7FFitFBys/7cuXbrkoosuyvvvv59bb711WdUEAAAAACusqqqqDBkyJGeccUaSpKKiIj/60Y9SVlaWVq1a5dxzz/3C+7+s/0knnZRmzZplo402yujRo2uuv/POO+nVq1fmzp1bc62kpCSDBw/OkCFDluEIgS/zjYL1z5SUlGSPPfbI3XffvSweBwAAAAArrPvvvz/NmjVLjx49kiQ//elPM23atIwfPz5PPPFErr/++tx8881Lvf+L+r/wwgu56667Mm7cuBx22GE5+eSTa+475phj8tvf/jb169df7Hl77713/vnPf2b8+PHLYbTAkiyTYB0AAAAAVhd33313+vXrlySZM2dObrvttvzqV79KkyZNsv766+enP/1pbrzxxiXe+2X933nnnWy66aYpKyvLD37wg7z99ttJkltuuSWtW7eued//1rBhw2y22Wa57777ltOIgf8lWAcAAACAAowcOTJdu3ZNkowdOzbz589Pr169atp79eqVV199dYn3fln/DTfcMC+++GJmzJiRhx9+OD169Mj06dNz3nnn5Te/+c1Sa+rWrVtGjhz5jccGfDWCdQAAAAAowPTp01NWVpYkmT17dho2bJg6derUtDdp0iSzZs1a4r1f1r979+457rjj0rdv3zz44IO55JJLctJJJ+Xkk0/O6NGj069fv2y77bZ58sknF3tuWVlZpk+fvqyHCixFnS/vAgAAAAB8pmnTpqmoqEiSNGrUKHPmzMnChQtrwvKZM2emcePGS7z3q/QfNGhQBg0alCR5/PHHM378+BxwwAHp1KlTHnvssVRXV6dfv34ZN25cioqKkiw6ELVp06bLbczA4qxYBwAAAIAC9OrVK2+88UaSpEuXLqlbt25GjRpV0z5y5Miag03/VyH958+fn+OPPz5XX311PvrooyxcuDCdO3fOOuusk/nz5+ejjz6q6Tt69OjFtpcBli/BOgAAAAAUYNddd80jjzySJFljjTWy33775YwzzsjMmTPz5ptv5sorr8zhhx++xHsL6X/++ednn332ybrrrpvmzZtn3rx5GTVqVF599dXMnz8/a665ZpJFB6K+8MIL2WmnnZbfoIHFCNYBAAAAoAA77bRTpk6dmn//+99JkqFDh6a8vDzt27fP9773vRx22GE58MADa/r3798/5513Xs3rL+ufLDrk9J577sngwYOTJCUlJfnd736X/v37p3///rn22mtTUlKSJPnb3/6WbbbZJp06dVreQwf+jz3WAQAAAKAAJSUlOe+883Luuefm9ttvT1lZWW699dal9h8+fPhir7+sf7Joy5gXX3xxsWv77bdf9ttvv8WuVVVV5eKLL85tt91W4CiAb0KwDgAAAAAFGjBgQAYMGFDbZaS4uDivvvpqbZcBqx1bwQAAAAAAQAEE6wAAAAAAUADBOgAAAAAAFECwDgAAAAAABRCsAwAAAABAAQTrAAAAAABQAME6AAAAAAAUQLAOAAAAAAAFqFPbBQAAAADA1zH+nB61XQL/peOZr9V2CfCtsWIdAAAAAAAKIFgHAAAAAIACCNYBAAAAAKAAgnUAAAAAACiAYB0AAAAAAAogWAcAAAAAgAII1gEAAAAAoACCdQAAAAAAKIBgHQAAAAAACiBYBwAAAACAAgjWAQAAAACgAIJ1AAAAAAAogGAdAAAAAAAKIFgHAAAAAIACCNYBAAAAAKAAgnUAAAAAACiAYB0AAAAAAAogWAcAAAAAgAII1gEAAAAAoACCdQAAAAAAKIBgHQAAAAAACiBYBwAAAACAAgjWAQAAAACgAIJ1AAAAAAAogGAdAAAAAAAKIFgHAAAAAIACCNYBAGA5mTRpUnbbbbe0bds2RUVFGTly5FL7DhkyJEVFRbnrrrtqrv3hD39Ily5dUl5enubNm2evvfbK+PHjl/qM888/P507d05ZWVlat26dgw8+ODNmzKhpv+yyy9KyZcusu+66efzxx2uuz5gxI927d89HH330TYYLAACrDcE6AAAsJ8XFxdlxxx0XC8uXZNSoUbnnnnvSpk2bxa7369cvTz31VGbOnJn3338/66yzTg499NClPmfvvffOK6+8koqKivznP//J/PnzM3jw4CTJ5MmT86tf/SqjRo3Kb3/72xx77LE195188skZPHhwWrRo8fUHCwAAqxHBOgAALCetWrXKMccck80333ypfSorK3P44Ydn6NChqVev3mJtnTp1SvPmzZMk1dXVKS4uzptvvrnUZ6233nopLy+vef3f/d97772st956adOmTX7wgx/k7bffTpI89dRTefPNN3PIIYd87XECAMDqpk5tFwAAAKuzSy+9ND179szWW2+9xPYnn3wyu+yyS2bOnJk6derkqquu+sLn3XLLLTn66KMza9asrLHGGrn99tuTLArd33333bz//vt55ZVX0qNHjyxYsCA/+9nPcuutty7zcQEAwKpMsA4AALXknXfeydChQ/Pyyy8vtc+WW26ZGTNmZOrUqbnhhhvSrVu3L3zmj370o/zoRz/K+PHjc+ONN6Zz585JkmbNmuXKK6/MHnvskbKystxwww258MILs8cee2TBggXp379/Pv300xx33HHZc889l+k4AQBgVSNYBwCAZWTYsGE56qijkizaxuX111//wv5HHnlkfvWrX6VZs2Zf+uzmzZvnsMMOy3rrrZcPPvggDRs2/ML+HTt2zC677JLddtstb731VpJkn332yT777JMkefPNN/P3v/89zz77bLbaaqtcdNFF6dGjR3r27Jm+ffumadOmX2XIAACwWrLHOgAALCMHHHBAZs+endmzZ39pqJ4k//znP3P88cenefPmad68eSZMmJADDzwwJ5xwwhL7L1iwIDNnzsyHH374lepZsGBBxo0blwULFnyubeDAgbniiitSr169jBo1Kn369EnTpk3Tvn37L9zHHQAAEKwDAMByNXfu3MydOzdJMn/+/MydOzdVVVVJkgkTJmTkyJE1X23bts2ll16aM888M0nyhz/8Ie+//36qq6szefLk/OxnP8v666+ftdZaa4nvdc0119SE7u+8805OOeWU9OvXL3Xr1l2s3x//+Mess8462XLLLZMknTt3zogRIzJx4sS8+eab6dSp0/L4KAAAYJUhWAcAgOWoQYMGadCgQZKkT58+adCgQR5//PEkSfv27Rf7KikpyZprrlmzDcvIkSPTp0+fNGrUKL17907dunUzfPjwFBUVJUnOO++89O/fv+a9/vnPf2bDDTdMw4YNs/XWW2eDDTbIsGHDFqtn6tSpufjii3PhhRfWXLvqqqvys5/9LL169cpZZ52VVq1aLdfPBFZFkyZNym677Za2bdumqKgoI0eOXKx9+PDh6dGjR5o2bZpmzZpl++23z2uvvVbTvnDhwhx//PFp27ZtysvLs+WWW+all15a6vtdcskl6dmzZ8rKytK+ffsMHjw48+fPr2m//fbb065du7Rr1y5//etfa64vWLAgm266acaMGbPsBg8AqyF7rAMAwHJUXV39lfuOGzdusdeXX355Lr/88qX2HzJkyGKv//KXv3zpezRv3jz//ve/F7vWt2/fvPPOO1+5TuDziouLs+OOO+b0009Pnz59Ptfeq1evPPTQQ2nTpk0WLlyYoUOHZs8996w5A2Ho0KG555578swzz6R9+/Y5//zzs9tuu+X999+v+Wbaf6usrMyNN96YXr16ZcqUKdljjz1y9tln57zzzktlZWUGDhyYxx9/PAsXLsy2226bPffcMyUlJbnkkkuy8847Z4MNNljunwkArMoE6wAAAPANtWrVKsccc8xS29u0aVPz6+rq6pSUlNScgVC3bt2888472XbbbWu2YjrkkENyxhln5OOPP07z5s0/97yTTz655tft27fPgQceWLMyferUqSktLc2GG26YJKlbt24+/vjjzJo1K3fccUeeffbZZTJmAFidCdYBAADgWzB+/Pj07Nkzs2bNSnV1dU477bSaMxAOO+ywHHrooXn77bfTsWPH3HDDDdliiy2WGKovyWOPPZaePXsmSVq0aJHi4uKMGjUqSVJSUpLmzZvnxz/+cS699NKUlpYunwECwGpEsA4AAADfgo4dO2bGjBmZNWtW/vjHP6ZDhw41bZ07d06vXr2y7rrrpqSkJK1atcrw4cO/0nOvv/76PPXUU3nllVeSLNqWZtiwYRk4cGCSZNiwYbnlllvSoUOHrLvuutlzzz0zbdq0DBgwIEcfffSyHygArAYE6wAAAFCgYcOG5aijjkqSdOrUKa+//vpXvrdx48Y55phj0rx587z00ktZe+21c8wxx2TSpEmZOHFiWrRokbvuuiv9+vXLq6++mrZt235hHaeffnpGjBix2HYzffv2zdNPP50kmTZtWgYNGpTHH388xxxzTPbcc8/su+++6d27d81BxwBAYYpruwAAAFiV3Hbbbdl3331ru4yv5Ygjjsj1119f22XASuGAAw7I7NmzM3v27IJC9c9UV1dn7ty5NYcWv/LKKzn44IPTpk2b1KlTJ3vvvXfKy8trwvElGTZsWI4//vg88MADNdvALMngwYNz6qmnplmzZhk1alT69OmT+vXrZ6ONNsprr71WcO0AgGAdAACWmaqqqgwZMiRnnHHGl/YdMmRIioqKctddd9Vc69+/fxo1alTzVb9+/RQXF2fq1Klf+rwf/ehHKSoqysiRI2uu3X777WnXrl3atWtXc6hhkixYsCCbbrppxowZs9gzTjvttJx11lmZN2/elw8W+Jy5c+dm7ty5SZL58+dn7ty5qaqqSrLom25vvfVWqqqqMmPGjBx33HFp2LBhevfunSTZYostcvPNN+ejjz5KVVVV7rzzzrz//vvp0aPHEt/r1ltvzc9+9rMMHz48G2+88VJrevTRRzNx4sQccMABSRZtOTNixIhUVFTk+eefzzrrrLMsPwIAWG0I1gEAYBm5//7706xZs6UGYZ8ZNWpU7rnnnsW2bUiS4cOH16yAnT17do444ohst912X3p44X333ZcpU6Ysdq2ysjIDBw7Mgw8+mPvuuy9HHXVUKisrkySXXHJJdt55589t/7DWWmtl/fXXXyyEB766Bg0apEGDBkmSPn36pEGDBnn88ceTJOPGjcv222+fxo0bZ/3118+4ceMyYsSIlJeXJ1k0Lzt06JCePXumSZMmOeuss3LzzTenS5cuSRatTu/evXvNew0ZMiQVFRXp27dvzTfj/rs9SebNm5cTTzwxV199dc21Cy+8MNdee23WWmut7LPPPtlkk02W62cCAKsqe6wDAMAycvfdd6dfv35f2KeysjKHH354hg4dmoMOOmip/ebOnZthw4bld7/73Rc+b9asWTnhhBNy3333Zf3116+5PnXq1JSWlmbDDTdMktStWzcff/xxZs2alTvuuCPPPvvsEp+37bbb5u67765Z3Qp8ddXV1UttO+WUU3LKKacstb28vDw33njjUtsPOOCAxeblu++++6X1lJaW5uWXX17s2oYbbmj7FwBYBqxYBwCAZWTkyJHp2rXrF/a59NJL07Nnz2y99dZf2O/OO+9McXFx9txzzy/sd+qpp+YnP/lJ1ltvvcWut2jRIsXFxRk1alRGjRqVkpKSNG/ePAMHDsyll16a0tLSJT6vW7dui20nAwAAfJ4V6wAAsIxMnz49ZWVlS21/5513MnTo0M+tIF2SG264IT/5yU9Sr169pfZ5+umn8+ijjy7xecXFxRk2bFgGDhyYZNE2Erfccks6dOiQddddN3vuuWemTZuWAQMG5Oijj665r6ysLNOnT//S+gAAYHVmxToAACwjTZs2TUVFRZLkvPPOq9n3uH///kmSI488Mr/61a/SrFmzL3zOu+++m0ceeSSHHXbYUvvMnz8/Rx55ZH73u98tNXzv27dvnn766Tz99NPp2bNnLrjgglx88cUZPHhw9txzzzz44IO54oorFjvEtKKiIk2bNi106AAAsFoRrAMAwDLSq1evvPHGG0kWHSz42SGkw4cPT5L885//zPHHH5/mzZunefPmmTBhQg488MCccMIJiz3nxhtvzOabb16zP/qSTJw4MWPGjMmee+5Z87wk2WabbfLb3/72c/0HDx6cU089Nc2aNcuoUaPSp0+f1K9fPxtttNFi+y2PHj06vXr1+qYfBQAArNIE6wAAsIzsuuuueeSRR5baPmHChIwcObLmq23btrn00ktz5pln1vSprKzMTTfd9IWr1ZOkQ4cOee+99xZ7XpLcfvvtOeKIIxbr++ijj2bixIk1Bx927tw5I0aMSEVFRZ5//vmss846NX3/9a9/ZZdddil06LDaue2227LvvvvWdhlfyxFHHJHrr7++tssAgJWaYB0AAJaRnXbaKVOnTs2///3vJba3b99+sa+SkpKsueaai2298uCDD2bGjBnZf//9P3f/sGHD0r179yRJSUnJ556XJC1btkzjxo1r7pk3b15OPPHEXH311TXXLrzwwlx77bVZa621ss8++2STTTZJkrz33nt54403ss8++3zzDwNWYVVVVRkyZEjOOOOMJbY/+uijKSoqqtkOqlGjRhk0aFBN+/Dhw9OjR480bdo0zZo1y/bbb7/YT44syejRo7PDDjukcePGadas2WLffLv99tvTrl27tGvXLn/9619rri9YsCCbbrrpYts9Jclpp52Ws846K/Pmzfs6wwcA4vBSAABYZkpKSnLeeefl3HPPze233/6l/ceNG/e5azvttFNmz569xP4HHHBAzarzJamurv7ctdLS0s8dbrrhhhsuMcT79a9/nXPOOSf169f/ksph9Xb//fenWbNm6dGjx1L7lJeXZ8aMGUts69WrVx566KG0adMmCxcuzNChQ7PnnnvmrbfeWmL/iRMnpl+/fvn1r3+du+66K8XFxXn99deTLPopl4EDB+bxxx/PwoULs+2222bPPfdMSUlJLrnkkuy8887ZYIMNFnveWmutlfXXXz9//etfv/D3FABg6QTrAACwDA0YMCADBgyo7TK+luuuu662S4CVwt13351+/fp97fvbtGlT8+vq6uqUlJRk3LhxWbBgQerWrfu5/pdeemn69eu32Cr13r17J0mmTp2a0tLSmjMZ6tatm48//jizZs3KHXfckWeffXaJNWy77ba5++67BesA8DXZCgYAAAAKMHLkyHTt2vUL+8yePTtt27ZN+/btc8ABB+SDDz5YrH38+PFp0qRJ6tevn+OOOy6nnnrqEkP1JHnsscfSqFGjfO9738uaa66Z73//+3nuueeSJC1atEhxcXFGjRqVUaNGpaSkJM2bN8/AgQNz6aWXprS0dInP7NatW83ZDABA4QTrAAAAUIDp06enrKxsqe1du3bNyJEjM2HChLz44ouprq7Orrvumqqqqpo+HTt2zIwZMzJjxoxcccUV2XTTTZf6vGnTpuXWW2/NRRddlEmTJmW//fbLLrvskunTp6e4uDjDhg3LwIEDM3DgwAwbNiy33HJLOnTokHXXXTd77rlntt5661xzzTWLPbOsrCzTp0//5h8GAKymBOsAAABQgKZNm6aioiJJct5559UcUNq/f/8kSevWrbPhhhumpKQkrVu3znXXXZdRo0blP//5z+ee1bhx4xxzzDE55JBD8u677y7x/Ro1apQ99tgj3/ve91KvXr0MGjQo9evXzzPPPJMk6du3b55++uk8/fTT6dmzZy644IJcfPHFGTx4cPbcc888+OCDueKKKxY7xLSiomKxg5MBgMII1gEAAKAAvXr1yhtvvJEkGTJkSGbPnp3Zs2dn+PDhS+xfVFT0hc+rrq7O3Llzl3igcZJstNFGX7m2wYMH59RTT02zZs0yatSo9OnTJ/Xr189GG2202KHFo0ePTq9evb7ycwGAxQnWAQAAoAC77rprHnnkkaW2P/LII3n33XdTXV2djz/+OAMHDkz37t2z3nrrJUluu+22vPXWW6mqqsqMGTNy3HHHpWHDhjUHkv6vI444Iv/4xz/y3HPPpbKyMtdcc03mzZuX7373u4v1e/TRRzNx4sSaA0k7d+6cESNGpKKiIs8//3zWWWedmr7/+te/sssuu3zTjwIAVluCdQAAACjATjvtlKlTp+bf//73EttfeeWVbLXVVmnUqFE23HDDLFy4MPfee29KSkqSJOPGjcv222+fxo0bZ/3118+4ceMyYsSIlJeXJ0mGDRuW7t271zxvyy23zJVXXpn9998/TZo0yc0335z77rsvTZo0qekzb968nHjiibn66qtrrl144YW59tprs9Zaa2WfffbJJptskiR577338sYbb2SfffZZ1h8NAKw2iqqrq6tru4gVWUVFRcrLyzNz5swvPJzmm9rkpJuX27P5el66+MDaLoFVlPm+YjHXWV7M9RWP+c7yYr6veL6N+X7rrbfmrrvuyu23377c32tZO/LII7PZZpvliCOOqO1SVjrm+4rnzsYX13YJ/JeOZ7725Z2+gW8rp4Ovok5tFwAAAAArmwEDBmTAgAG1XcbXct1119V2CQCw0hOsAwCwWhh/To/aLoH/sbxXtQEAwPJij3UAAAAAACiAYB0AAAAAAAogWAcAAAAAgAII1gEAAAAAoACCdQAAAAAAKIBgHQAAAAAACiBYBwAAAACAAtSp7QIAAABgWRp/To/aLoH/0fHM12q7BABYpqxYBwAAAACAAgjWAQAAAACgAIJ1AAAAAAAogGAdAAAAAAAKIFgHAAAAAIACCNYBAAAAAKAAgnUAAAAAACiAYB0AAAAAAAogWAcAAAAAgAII1gEAAAAAoACCdQAAAAAAKIBgHQAAAAAACiBYBwAAAACAAgjWAQAAAACgAIJ1AAAAAAAogGAdAAAAAAAKIFgHAAAAAIACCNYBAAAAAKAAgnUAAAAAACiAYB0AAAAAAAogWAcAAAAAgAII1gEAAAAAoACCdQAAAAAAKIBgHQAAAAAACiBYBwAAAACAAgjWAQAAAACgAIJ1AAAAAAAogGAdAAAAAAAKIFgHAAAAAIACCNYBAAAAAKAAgnUAAAAAACiAYB0AAAAAAAogWAcAAAAAgAII1gEAAAAAoACCdQAAAAAAKIBgHQAAAAAACiBYBwAAAACAAgjWAQAAAACgAIJ1AAAAAAAogGAdAAAAAAAKIFgHAAAAAIACCNYBAAAAAKAAgnUAAAAAACiAYB0AAAAAAAogWAcAAAAAgAII1gEAAAAAoACCdQAAAAAAKIBgHQAAAAAACiBYBwAAAACAAgjWAQAAAACgAIJ1AAAAAAAogGAdAAAAAAAKIFgHAAAAAIACCNYBAAAAAKAAK12wftVVV2WttdZK/fr106dPnzz//PNf2P8vf/lLunbtmvr166dHjx65//77v6VKAQAAAABYFa1Uwfrtt9+eE088MWeddVZefvnlbLTRRtlhhx3y4YcfLrH/008/nQEDBuSwww7LK6+8kj322CN77LFH/v3vf3/LlQMAAAAAsKpYqYL13/72tzniiCNyyCGHpFu3brnmmmuyxhpr5Pe///0S+19++eXZcccdc9JJJ2WDDTbIueeem969e2fo0KHfcuUAAAAAAKwqVppgff78+XnppZey3Xbb1VwrLi7Odtttl2eeeWaJ9zzzzDOL9U+SHXbYYan9AQAAAADgy9Sp7QK+qqlTp6aysjKtWrVa7HqrVq3yxhtvLPGeyZMnL7H/5MmTl/o+8+bNy7x582peV1RUfIOqAQAAAABY1aw0wfq35fzzz88vf/nLb/19X7r4wG/9Pfli48/pUdsl8F86nvlabZewzJjvKxZzfcWzqsx3c31F5P8Jy4f5viLy/4Tlw3xfEfl/AtSOlWYrmObNm6ekpCRTpkxZ7PqUKVPSunXrJd7TunXrgvonyamnnpqZM2fWfE2YMOGbFw8AAAAAwCpjpQnW69Wrl0022ST//Oc/a65VVVXln//8Z7bYYosl3rPFFlss1j9JRowYsdT+SVJaWpqysrLFvgAAAAAA4DMr1VYwJ554Yg466KBsuumm2XzzzXPZZZflk08+ySGHHJIkOfDAA9OuXbucf/75SZLjjjsuW2+9dX7zm99k5513zm233ZYXX3wx1113XW0OAwAAAACAldhKFazvt99++eijj3LmmWdm8uTJ6dWrVx544IGaA0rHjx+f4uL/vwj/u9/9bm655ZacfvrpGTJkSNZbb73cdddd2XDDDWtrCAAAAAAArOSKqqurq2u7iBVZRUVFysvLM3PmTNvCrGYcaLhiWVUOM2TFY66veMx3AABgSeR0rEhWmj3WAQAAAABgRSBYBwAAAACAAgjWAQAAAACgAIJ1AAAAAAAogGAdAAAAAAAKIFgHAAAAAIACCNYBAAAAAKAAgnUAAAAAACiAYB0AAAAAAAogWAcAAAAAgAII1gEAAAAAoACCdQAAAAAAKIBgHQAAAAAACiBYBwAAAACAAgjWAQAAAACgAIJ1AAAAAAAogGAdAAAAAAAKIFgHAAAAAIACCNYBAAAAAKAAgnUAAAAAACiAYB0AAAAAAAogWAcAAAAAgAII1gEAAAAAoACCdQAAAAAAKIBgHQAAAAAACiBYBwAAAACAAgjWAQAAAACgAIJ1AAAAAAAogGAdAAAAAAAKIFgHAAAAAIACCNYBAAAAAKAAgnUAAAAAACiAYB0AAAAAAAogWAcAAAAAgAII1gEAAAAAoACCdQAAAAAAKIBgHQAAAAAACiBYBwAAAACAAgjWAQAAAACgAIJ1AAAAAAAogGAdAAAAAAAKIFgHAAAAAIACCNYBAAAAAKAAgnUAAAAAACiAYB0AAAAAAAogWAcAAAAAgAII1gEAAAAAoACCdQAAAAAAKIBgHQAAAAAACiBYBwAAAACAAgjWAQAAAACgAIJ1AAAAAAAogGAdAAAAAAAKIFgHAAAAAIACCNYBAAAAAKAAgnUAAAAAACiAYB0AAAAAAAogWAcAAAAAgAII1gEAAAAAoACCdQAAAAAAKIBgHQAAAAAACiBYBwAAAACAAgjWAQAAAACgAIJ1AAAAAAAogGAdAAAAAAAKIFgHAAAAAIACCNYBAAAAAKAAdWq7AABY3b028dOccvcHmTBjQaqrq7Nui9Kcsl3r9FmrYZJk7JS5+dWDk/PapE8zfU5lXj1lg5Q3KFnq8w7807i8MH5OzevKqurMr6zOyyd1TbOGdfLMu7Pzi398kE/mV+WnW7XMId9Zc7F7j/xe82zZudHyGzAAAACs5ATrAFDL2jepm2v375h25XWTJA+Mqcghw97Ly7/omvp1i1OnpCg7dy/LwX2a5dBbxn/p827+yVqLvT7zvol55+N5adZw0R/7Z9w3Kefs3DZdW9bPjr97K7tsWJ4WjerkH6/NSPOGdYTqAAAA8CUE6wBQy5quUSdN11j066qq6pQUF+WT+VX5cPbCdGxaL+s0L806zUszYfr8gp89d0FV7nptZn69S9uaa+Onz893126Y0jrFWXvNevlgxvzUKynKlY99lDsOWXtZDQsAAABWWYJ1AFhB9Dh/dD6ZX5XKquSHGzVJx6b1vvEzH3yjIsVFyQ5dG9dc69qqfp54e3a6t26Q92csyFrN6uW8hybn6C2b16xqBwAAAJbOv54BYAXx2qndMndBVe4fXZF5C6uWyTNve2l69urZJPXq/P/zyi/avV3OHj4ps+dV5pc7tcl/PpqX92fMz5AftM7xf5uQD2YuyPfWbpTjt2m5TGoAAACAVY1gHQC+ZXe+OiND7pmYJGlXXjcPD1qvpq1+3eLstVGTbDf0zazbvDSbdWr4td9n/PT5eWbcJzm7f5vFrndtVT+3Hbxoy5f5C6uyxw3v5Kp9OuR3T36UtdcszW/3bJ8f3Twuj701K1uv23hJjwYAAIDVmmAdAL5le/Zskj17NvnCPgurqvPutPnfKFi//eXp6dWuQbq0qr/UPr97cmr6b1CWtdcszejJc3PYFmumuLgoG7drkDGT5wrWAQAAYAmKv7wLALA8/XNsRcZMnpuFldX5dH5Vhj7+YSZVLEifTotONK2urs7cBVWZX1mdJJlfueh1dXX1Up9ZWVWdv46cnv02brrUPu9MnZcRYyty9JYtkiQdm9bLk29/knkLq/Lce3PSsdk33+MdAAAAVkVWrANALZs2pzK/enB8Js9amNI6RenSsn7+cECndGpWmiR5f8aCbHnZf2r6b3rxG0mSJ49fPx2a1sudr87IVY9/tNiWMo+9NTsVc6uya4/ypb7vafdOzNn926ZuSVGS5Njvt8ixf5mQTS9+I9t3KcsOXcuWx3ABAABgpVdU/UXL3UhFRUXKy8szc+bMlJUJGFYn48/pUdsl8F86nvlabZfAKspcX/GY7wAAwJLI6ViR2AoGAAAAAAAKIFgHAAAAAIACCNYBAAAAAKAAgnUAAAAAACiAYB0AloO7X5uRY+4YX9tlLBcn/+OD3PritNouAwAAAGpNndouAABWNVVV1bnon1Nyw4BOS2wfO2VufvXg5Lw26dNMn1OZV0/ZIOUNSmraF1ZW59cPTc69r8/Mp/Or0qVV/Zzdv016tG2QJLnjlen53RMf5aPZC1OnpCibd2qYs3ZsnXZN6i21psse+TB/euHjzF1YnW3Xb5zzd22bhqWL3vOef8/MuQ9MSpKc1b9Ndu5eniRZUFmdPW94O5fu1T7rtahf86xBW7XIXje+k716NUlpHd+jBwAAYPXjX8MAsIw98uasNGlQkq6t6i+xvU5JUXbuXpbf7NFuie1/fP7jPDy2Ince3jmjTtkgW6/bKIfd8l6qq6uTJN9du2H+dljn/HtItzx7Ypd0alovJ/3jg6XWc8cr03P7K9Pzl0M75+kTumTGp5U5a/iiIL2yqjqn3Tsxf/rJWvnDAZ0y5J6Jqaxa9D7XPTU1/dZrvFioniQdmtZL5zXr5f7RFQV/NgAAALAqEKwDwDI2YuysfHftRkttX6d5afbfpFnWb7nk4H389Pn5XudGad+kXkqKi7Lvxk0zZdbCTJ9TmSRp36RemjX8/z90VlyUjPt4/lLf746Xp+fgPmumc/PSlDcoyc/7tczdr83M3AVVmTanMvVKitKlVf10b9MgdUuKMn1OZd6bNi/3vj4zx27VYonP/O7ajfLwG4J1AAAAVk+CdQBYxkZPnpt1mpd+7fv36900r038NO9Nm5cFldW57aXp6d2hwWJh+gvvfZIe549Ol1+Nzg3PTM2gpQTgSfLGlLnp3vr/h/jdWjfIvIXVeefjeVlzjZIUFyWjJ3+a0ZM/TXFR0myNkpx278ScuWPrpW71sl7L0oyePPdrjxEAAABWZvZYB4BlbOanlWlU+vW/d92xab10a10/W13+ZkqKk+YN6+SPP15rsT6bdWqY107tlmmfLMxtL0/Pei2WHuR/Mr8qZfX//x7udUuK0qBuUT6ZV5Xi4qJc/sP2Oe3eiUmSy3/YPne9NjNtyupmrWalOfLW9zLj08rs1qNJfrxZs5pnNC4tycy5lV97jAAAALAyE6wDwDJW3qAks+dVJUmGPv5hrnpiapJks45r5OafrPWl959+78R8OHthnh/cJWuuUScPvlGRAX98Nw8OXDetyuou1rdZwzrZr3fT9L3iP3nu512zRr3PB/oN6xWnYt7/D8EXVlbn0wXVafh/4f8WazfKnYcv2rpmxpyFOfP+d/OXQ9bO6fdNyg4blGXn7uXZ+dq302etNWr2W581rzLl/xXWAwAAwOrEVjAAsIx1a10/b0+dlyQZtFXLjDmtW8ac1u0rhepJ8vrkudm7V9O0alz3/w46LU/j0uK8OGHOEvsvrKxOxdyqTP1k4RLbu7aqn9GT/v+2LaMnz01pnaJ0XvPzq9x/9dDkHPP9FmmyRp2Mnjw3vdqvkfp1i9OtVf2MnTKvpt+bH85Lt9ZL3iMeAAAAVnWCdQBYxrbr0jjPvPvJUturq6szd0FV5ldWJ0nmVy56XV296HXv9mvk76Om5+NPFqaqqjoPjKnI5IqF6dpqUZB9xyvTM2nmglRXV+fDWQty1vBJ6bxmvXRoUneJ77fPxk1z03Mf592P56VibmV+88iU7NajPPXrLv7XgGfenZ0PZy3Mnj2bJEk6Nq2bJ96enVlzKzPygznp1KxeTd+n3/0k23Zp/LU/IwAAAFiZ2QoGAJaxbdZrnLPun5SxU+amS6vPr+p+f8aCbHnZf2peb3rxG0mSJ49fPx2a1stpO7TOuQ9Myg5Xv5VPF1SlfZO6+e1e7WsORB09aW4u+eeUVMytTOP6JflOp4b544/XSlFRUZJF2888/96cmhXy+/Vumokz5+eHN76TuQuqs22Xxjm7f5vFapq3sCrnPjg51+zbsebaqdu3zk//OiG/feTD/GiTpunRtsH/1T8/b0+dl526lS+7Dw0AAABWIkXVny2PY4kqKipSXl6emTNnpqysrLbL4Vs0/pwetV0C/6Xjma/VdgmsopbXXP/HazPy0JiKXPVfQfWq4pS7P8hGbRtkwKbNvrzz12C+AwAASyKnY0VixToALAe792iS3Xs0qe0ylosLdmtX2yUAAABArbLHOgAAAAAAFECwDgAAAAAABRCsAwAAAABAAQTrAAAAAABQAME6AAAAAAAUQLAOAAAAAAAFEKwDAAAAAEABBOsAAAAAAFCAOrVdAADUpo5nvlbbJQAAAAArGSvWAQAAAACgAIJ1AAAAAAAogGAdAAAAAAAKIFgHAAAAAIACCNYBAAAAAKAAgnUAAAAAACiAYB0AAAAAAAogWAcAAAAAgAII1gEAAAAAoACCdQAAAAAAKIBgHQAAAAAACiBYBwAAAACAAgjWAQAAAACgAIJ1AAAAAAAoQJ3aLgD46l4Y/0nOuHdS3p02L53XLM2vdmmbTTqs8bX6T65YkGPumJA3P5qb7buU5ZI92qW4uChJcvUTH2XO/KoM3rbVtzIuAAAAAFiZWLEOK4kZcxbm0GHv5aDNm+XVUzbIgZs1y6HD3svMTyu/Vv+hj3+UzTutkRcGd8270+blgTcqkiTjp83PPf+emZ9u3eJbGxsAAAAArEwE67CSeGBMRVqX1c2ATZultE5xBmzaLC0a1cmD/xeIF9p//PT52WLthqlftzh9OjXM+GnzkySn3TsxZ+zYOqV1/PYAAAAAAEsiOYOVxBtT5qVb6/qLXevWun7emDz3a/Xv2qp+nnz7k8xdUJXn35uTLq3q585XZ6RV4zr57tqNls8gAAAAAGAVIFiHlcQn8ytTVr9ksWtl9Usye37V1+p/7PdbZMqsBdn9+rfz3bUbZuN2DXL1Ex/ltB1a57f/mpJ9fv9OTvj7+5k1d8lbzQAAAADA6srhpbCCuvPVGRlyz8QkSbvyutmyc6PM+HThYn1mzavMmmsseRo3rFfyhf3LG5Tkir071LSddNf7Gbhli4z64NO8OGFObj947Vz+2Ie5+omPcvL2rZfl0AAAAABgpWbFOqyg9uzZJGNO65Yxp3XLw4PWS9dWpRn9P9u+jJ48N11a1V/i/YX0f3bcJ5lcsTB7bdQkYybPzUZtG6S4uCi9O6yR0VOWvNUMAAAAAKyuBOuwkthxg7JMqliQ216alvkLq3LbS9Py4ayF2XGDsm/Uf97CqpzzwKT8epe2SZKOzerluffmZN7Cqjz59ifp1LTech8bAAAAAKxMBOuwkmiyRp38/ked8ofnPs6G54/JTc9Ny40/6pTyBov2Uf9gxvxs8OvR+WDG/K/U/zNXP/FRduleno7NFgXoO25Qlg5N62aTi97Iy+/PybHfb/HtDhQAAAAAVnBF1dXV1bVdxIqsoqIi5eXlmTlzZsrKlrwymFXT+HN61HYJ/JeOZ75W2yUAAAAAtUhOx4rEinUAAAAAACiAYB0AAAAAAAogWAcAAAAAgAII1gEAAAAAoACCdfgW3f3ajBxzx/jaLmOZq6yqzg+uejNvfjS3tksBAAAAgOWuTm0XAKuLqqrqXPTPKblhQKcltv915PTc/Py0vDN1XurXLc426zXK6Tu0SXmDkiTJtU9Nzd9HTc/7MxakUWlxdt2wPL/YtlXq1Vn0/bF7/z0zNz47NaMnz03nNUszfOC6X1rTiDcq8ttHPsy7H89L4/olOW7rlvnxZs2SJL9+cHJuf2V62pbVzRV7t8/6LesnScZPm5+jbh+fOw/vnPp1F713SXFRjvxe81z88JRct5TxAQAAAMCqwop1+JY88uasNGlQkq6t6i+x/dP5VTl1+1Z58aSuefjYdfPh7IU5/b6JNe1VVdW5aPd2GXnyBrnr8HXy7LhPctmjH9a0N2lQksO+0zyDvt/iK9Xz6Juzcvp9E3Pmjq3z+pBuefjY9fKdtRomSUZ9MCcPvVGRp45fP/v1bpoLRkypue/0+ybm9B1a14Tqn9mpW3meeveTfDBj/lf+TAAAAABgZSRYh2/JiLGz8t21Gy21/Sebr5kt1m6U+nWL02SNOvnxps3y4vg5Ne0Dv98iG7VbI3VLitKmvG5+uFHTvPBf7Vuu0yi7bFie1mV1v1I9v/nXhzlu65bZYu1GKSkuSnmDkqzbojRJMn76gvRs2yCN65fk++s0ynvTF4Xld706Iy0a1cn3On9+HGvUK07Ptg3yr//M+krvDwAAAAArK8E6fEtGT56bdZqXfuX+z477ZKmr279K+xeZM78qr036NJMrFqTvFf/Jphe/kYG3j8+UWQuSJF1alubViZ9m5qeVefKd2enasjQzP63MVU98lNN3aL3U567XojSjJ9tnHQAAAIBVm2AdviUzP61Mo9KvNuUeeXNWbn95ek7ertUS2299cVpemjAng7b6atu+LKmW6urkoTdm5c8HrpXHfrZe6tUpyvF/ez9Jsn7L+jnkO2tm/5vezeNvzc5pO7TOrx+anIFbNs+bH83L/je9mwE3vZsX3vtksec2Ki3JzLmVX6smAAAAAFhZOLwUviXlDUoye15VkmTo4x/mqiemJkk267hGbv7JWjX9nnpndo7/2/u5Zv+OS1yRfuerM3LJv6bkzweunVaNv9q2L/9rjXqLAv6D+zRL+yb1kiQnbtMyW1/xZubMr8oa9YpzcJ81c3CfNZMkz437JBNnzs8ePdrmu5eOzR2HdE51qjPgpnF56oT1U1RUlCSZPa8y5fVLvlZNAAAAALCyEKzDt6Rb6/p5e+q8JMmgrVpm0FYtP9fnqXdmZ+AdE3Ll3u2z5RL2Mb/z1Rk5Z/ik/OnAtbJB66+3DUyyKORvV77kUL66unqx1/MXVuWXD0zK1ft0yMdzKrOwKunYbFEYP7+yOh9/UpnmjRb9VvLmR/OyU7eyr10XAAAAAKwMbAUD35LtujTOM+9+stT2Z96dnaNvH59L92qfrddt/Ln2f7w2I2ffPyl//PFa2bBNg8+1V1ZVZ+6CqiysrE51dTJ3QVXmLaxa6vsN2KRp/vj8tEyuWJC5C6py+aMf5XtrN0zD0sVXnF/9xNTs3K08a61ZmmZrlGR+ZXVGT/40YybPzYLK6jRdY1H/T+dX5dWJn2ab9T9fOwAAAACsSqxYh2/JNus1zln3T8rYKXPTZQlbvFz26EeZPa8qg/4yYbHrY07rliS56OEpmT2vMvvd9G5NW7vyunl40HpJkr+PmpHBd31Q09blV6PTvkndPHVClyTJkHsWtZ23a7skyTHfb5EZn1Zmx9+9lSTZYq2GuXSv9ou999tT5+Xh/1TkzsPXSZKUFBfl17u0zUF/fi9FSc7btW1KihdtAzN8zMxssVbDmq1lAAAAAGBVVVT9v/s+sJiKioqUl5dn5syZKSuzxcXqZPw5PZb5M//x2ow8NKYiV+3bcZk/uzZVVVWn/zVv5cq9O2T9ll9/i5ov0vHM15bLcwEAAICVg5yOFYkV6/At2r1Hk+zeo0ltl7HMFRcX5cFj1qvtMgAAAADgW2GPdQAAAAAAKIBgHQAAAAAACiBYBwAAAACAAgjWAQAAAACgAIJ1AAAAAAAogGAdAAAAAAAKIFgHAAAAAIACCNYBAAAAAKAAdWq7AFhRdTzztdouAQAAAABYAVmxDgAAAAAABRCsAwAAAABAAQTrAAAAAABQAME6AAAAAAAUYKUJ1qdNm5YDDjggZWVladKkSQ477LDMnj37C+/p27dvioqKFvs6+uijv6WKAQAAAABYFdWp7QK+qgMOOCCTJk3KiBEjsmDBghxyyCE58sgjc8stt3zhfUcccUTOOeecmtdrrLHG8i4VAAAAAIBV2EoRrI8ZMyYPPPBAXnjhhWy66aZJkiuvvDI77bRTLrnkkrRt23ap966xxhpp3br1t1UqAAAAAACruJViK5hnnnkmTZo0qQnVk2S77bZLcXFxnnvuuS+8d9iwYWnevHk23HDDnHrqqZkzZ87yLhcAAAAAgFXYSrFiffLkyWnZsuVi1+rUqZNmzZpl8uTJS73vRz/6UTp16pS2bdvm1Vdfzcknn5yxY8fm73//+1LvmTdvXubNm1fzuqKi4psPAAAAAACAVUatBuunnHJKLrzwwi/sM2bMmK/9/COPPLLm1z169EibNm2y7bbb5u23384666yzxHvOP//8/PKXv/za7wkAAAAAwKqtVoP1n//85zn44IO/sE/nzp3TunXrfPjhh4tdX7hwYaZNm1bQ/ul9+vRJkrz11ltLDdZPPfXUnHjiiTWvKyoq0qFDh6/8HgAAAAAArNpqNVhv0aJFWrRo8aX9tthii8yYMSMvvfRSNtlkkyTJv/71r1RVVdWE5V/FyJEjkyRt2rRZap/S0tKUlpZ+5WcCAAAAALB6WSkOL91ggw2y44475ogjjsjzzz+fp556KoMGDcr++++ftm3bJkk++OCDdO3aNc8//3yS5O233865556bl156KePGjcvdd9+dAw88MFtttVV69uxZm8MBAAAAAGAltlIE60kybNiwdO3aNdtuu2122mmnbLnllrnuuutq2hcsWJCxY8dmzpw5SZJ69erl4Ycfzg9+8IN07do1P//5z/PDH/4w99xzT20NAQAAAACAVUBRdXV1dW0XsSKrqKhIeXl5Zs6cmbKystouBwAAAABWS3I6ViQrzYp1AAAAAABYEQjWAQAAAACgAIJ1AAAAAAAogGAdAAAAAAAKIFgHAAAAAIACCNYBAAAAAKAAgnUAAAAAACiAYB0AAAAAAAogWAcAAAAAgAII1gEAAAAAoACCdQAAAAAAKIBgHQAAAAAACiBYBwAAAACAAgjWAQAAAACgAIJ1AAAAAAAogGAdAAAAAAAKIFgHAAAAAIACCNYBAAAAAKAAgnUAAAAAAChAndouYEVXXV2dJKmoqKjlSgAAAABg9fVZPvdZXge1SbD+JWbNmpUk6dChQy1XAgAAAADMmjUr5eXltV0Gq7miat/i+UJVVVWZOHFiGjdunKKiotouh29JRUVFOnTokAkTJqSsrKy2ywGWE3MdVh/mO6w+zHdYfZjvq5/q6urMmjUrbdu2TXGxHa6pXVasf4ni4uK0b9++tsuglpSVlfnDGVYD5jqsPsx3WH2Y77D6MN9XL1aqs6LwrR0AAAAAACiAYB0AAAAAAAogWIclKC0tzVlnnZXS0tLaLgVYjsx1WH2Y77D6MN9h9WG+A7XJ4aUAAAAAAFAAK9YBAAAAAKAAgnUAAAAAACiAYB0AAAAAAAogWAcAAAAAgAII1gEAAABYZcybN6+2SwBWA4J1APg/1dXVtV0CsJxNnDixtksAasHNN9+cv/71r3n99ddruxRgOfns7/JDhgxJ3759M2nSpFquCFjVCdZhOaqsrFzideEdrDj+9re/pUuXLhkzZkyKiorMT1hF3Xrrrdl0003zwx/+MDvvvHPuvffeJElVVVUtVwYsT8OGDUvLli3zu9/9LieffHL22muvXHfddUnMf1jVFBUVZd68ebn99tvz3HPP5Y9//GNtlwSs4oqqJQiwXFRXV6eoqChJcu+996akpCQdO3ZM9+7da7kyIElmz56diy++ODfddFMmT56c7bbbLvfdd19tlwUsY9OmTctJJ52UBx54IKecckoaNWqU+++/PyNGjMjUqVNTp06d2i4RWA6qqqry+9//PpdddlmOO+64HHbYYXnjjTfy5z//OXfddVdeeOGFNGzYsLbLBJaxUaNG5bzzzsvmm2+eM844I6+88kq6dOlS22UBqygr1mE5KSoqysiRI9OzZ8/89Kc/zS9/+ctsueWW+cMf/pBPPvmktsuD1VZlZWWqq6vz8ccfZ+LEiTnttNNy55135sEHH8w999yTxAo2WBVUVlamsrIyr7zySl577bX84x//yE9/+tMccsghufTSS9OyZcvceuuttV0msJxUVlamoqIiu+yySw466KAUFxenW7du6dGjR+rVq5ePPvqotksEloP69etn7NixOeqoo7LOOuvk7LPPru2SgFWYJTqwnFRWVuass87Kd77znZofNz377LNz7LHHpmXLltl5551ruUJY/Vx77bV54YUXss8++2SHHXbIwIED06tXrxQVFeWggw7KCSeckF133TXFxb7vDCuzz+b63nvvnc6dO+e4447LxhtvXNNer169zJ07Ny1atKjFKoHloaqqKsXFxalbt2722muvdOzYMcXFxTU/TdqyZcvMnDkzrVq1qu1SgW/ov39K/DMvv/xyOnTokEaNGuX888/P7rvvnoEDB+Y///lP+vTpkx49etRStcCqSHIA39DS9lF/5plnMmbMmAwdOjRJctZZZ+Xyyy/P7rvvnt69e3+bJcJqb8SIEVl77bUzdOjQlJeXZ+7cuVm4cGF69+5dE6KfeOKJmTZtWi666KIkS5/bwIrrv+d6WVlZFi5cmE6dOuWAAw5ISUlJkkVz+9NPP011dXVatmxZyxUDy8J/n5dSXFxc85Nna621Vs3rz8K34cOHp3v37mnQoEEWLFhQm2UDX8PSzkf67L9FRUVp1qxZkmSXXXZJ7969s8022+Tqq6/+XAgP8E1ZsQ7fQHV1dc0/1MeOHZvy8vK0bt06SdK4ceMkiw5MOvfcc1NeXp5bb701O+64Y5Jk7ty5qV+/fu0UDquRxx57LCeeeGKOOuqoHH/88SkqKkppaWlN+2cr2zbYYIMMHjw45557bg4//PCav5ADK4f/netJFvtz9rN/cJeUlOTll19OWVmZb3TDSu5/z0sZPHhw7rvvvs/95FlxcXEqKytTUlKSF154If3790+S1K1bt6bPZ38fAFZMS5vvn4Xln/339ddfT9euXTNp0qTstttuGTt2bIqLi3PooYdmww03rM0hAKsgf3OAr+jDDz+s+fVnK1mLiory5ptvZpNNNskOO+yQLbfcMnfeeWcWLlyY0tLSNGnSJAMHDswpp5yS5557riZUv/XWW/OnP/2pVsYBq5v7778/bdq0ydFHH5369esvFqonqflHdHFxcQ4++OB06NAhP//5z5Mkr7zySp544ok45xtWfP871//3m9dFRUU1/+i+++67s9lmm9W0TZ48ObNmzfpW6wW+vq9zXkpxcXFmz56dcePGZZtttkmS/Oc//8lPfvKTmnZgxfNV5/t/r1j/5S9/mQ4dOqR79+558803c9JJJ+W8887LxIkTa3MowCrI3x7gK7j00ktzyCGHZMKECUkWrXabM2dOnn/++fzmN7/JNttskzvuuCObb755zXfOu3Tpku9+97tZd91106dPn9SrVy9JMnLkyNx444154403Mm/evNocFqwWXn311TRr1ixNmjRJkjzwwAO57LLLcuKJJ+biiy/O2LFjkyxazdq2bdv88pe/zJ///Ofstdde2WSTTfL0008L1mEl8FXnekVFRZ577rnssssuqaqqymmnnZa2bdvm3nvvrcXqga/q2muvzVFHHZWHHnoonTp1ysCBA3P44Yenf//+NeelJJ8PyouKivLEE0+kRYsW6dKlS44//vj07NkzEydOzPz58/1ZDyugrzPfO3funJ/85Cd5/PHHc9NNN6VVq1Y56aSTav79DrAsFVX7GwQs1fvvv5/27dtn5MiRadasWTp27FjTdtBBB+Wuu+5K796985e//CXNmzdPkvTr1y/NmjXLVVddlRkzZmTIkCF56KGHsv3226d+/fq58847c/DBB+fSSy+1FQx8Cx566KHsuOOO2XrrrTNu3LiUlpamY8eOmTJlSubMmZPi4uKawO2TTz7JpZdemjPPPDN9+vTJBRdckK233rqWRwB8FV91rk+YMCH9+vXLgAEDcvPNN6dBgwa5+uqra1awAiumESNG5Mgjj0yjRo3ygx/8IFtttVV23nnn1KmzaHfT6urqjB49Ot///vdz6qmn5qSTTqrZ/uUzxxxzTK655pqUl5enbdu2ufnmm7PJJpvU1pCApfg6833BggWpW7duqqurU1lZWdP3MzNmzKj55jvAsiJYhyWYNWtWTjjhhHz00Ue58847a74D/vzzz2fOnDnp27dvxo0bl759+6Zdu3Z56KGH0rBhwySLfhT9+OOPz6BBg/Kzn/0sSXL55Zfn448/ztSpU3P00UenZ8+etTY2WB3dc889efLJJ9O0adNstdVWadWqVdZZZ508/vjjGTBgQC666KIccMABOemkkzJ06NBcccUVOeKII2q7bKBAS5vrTzzxRPbff/9ceeWVKS4uzl577ZVWrVrltNNOy6BBg2q7bOBLPPbYYxk0aFAOOOCALzwvpaqqKhdccEHOP//8vPfeezXnpVRXV6eoqChHHXVU7r777lx55ZXZe++9a2s4wBf4pvMd4NskWIelOOecc/Lggw9m0KBBGTBgQCZNmpTtttsuvXv3zm9+85u0bNmyZsuIoUOHZocddqi598ADD8yUKVNy+umn5/vf/34tjgL4Io8++mj23nvv/OlPf0r//v3z0ksvWbkGq6BHH300P/zhD/PnP/85HTp0yIgRI2p+fBxY8Z188sl55ZVXcscdd3zpitOJEydm++23z+abb54//OEPefnllzNnzpxsueWWefvtt7POOut8O0UDX8s3me+vvPJKZs+enS233LLmXBWA5cke6/A/Pjvo6NBDD02bNm1y6623ZvLkyWnTpk0OPfTQvPXWWzX7sA4ZMiSlpaX529/+lkmTJtU845RTTslLL72Uhx9+OAsXLqyVcQBfbM6cObnvvvvSu3fvbLzxxkkiVIdV0H/P9c022ywbbrihUB1WMoWel3L22WfXnJey6aab5sknn0x1dbVQHVYC32S+Ox8J+LbV+fIusHr47EfKiouLU11dnfbt22f33XfP1VdfnT/84Q859dRTM3DgwDz88MMZPnx4tthii2ywwQb5xS9+kTPOOCP9+vXL/vvvnyTp1q1bbrjhhmy77baf29sNqD3vvvtunn766cyePTuXXHJJSktL8/vf/z6tW7eu7dKAZWhpc/2z81CAlcsJJ5yQHXfcMVOmTFniGQo33HBDxo4dm6KionzyyScZO3ZsKisrM2nSpDzyyCPOS4GViPkOrExsBcNqr7q6OlVVVTUHG1VUVKSsrCzJor3WTzzxxLz11lu57LLLstFGG+WOO+7IBRdckP333z+/+MUvkiQ77LBDFi5cmCuuuCLdu3evtbEAX+yee+7Jr3/965SUlGTAgAH2VoZVlLkOqx7npcDqw3wHVhaCdfg/EyZMyM9//vNMnTo1rVq1ymGHHZbtttsujz76aM4444z07t07l19+eZL/v4f6GWeckS233DKPPPJIBg8enNtuuy3rrbdeLY8E+CJjxozJeuut56dJYBVnrsPqwXkpsPow34EVjT3WIcnw4cOz+eabp7S0NAcddFBatWqV/fffP3fffXf69u2brbbaKi+88ELuv//+JMmxxx6bjz/+OMOGDcucOXOyzTbb5KWXXhKqw0pggw02ELTBasBch1Wf81Jg9WG+Aysi/9pgtVJVVZWioqLPnRA+fPjw7LPPPrniiiuSJC1atMgVV1yRkSNHZrfddsuAAQPyyiuv5NZbb02/fv3Sp0+ffO9730uTJk1SUlKS6upqp44DAMBy5rwUWH2Y78CKzlYwrDYqKytr9lF/6623Mn/+/HTr1i3V1dVZf/318+c//znNmjXL3nvvnenTp+e0007LkUceWROYX3nllbnuuuty+OGH57jjjsuCBQtSt27d2hwSAACsVpyhAKsP8x1Y0VmxzmqjpKQkU6dOzdFHH52XXnopxx57bNZcc800b948G220UX74wx9m1qxZOfzww3PqqaemefPmmT9/fp5++un07ds3e+21V0aNGpVu3boliVAdAAC+ZbvuumvWXXddZyjAasB8B1Z0fmditfHMM8/kJz/5SXr27Jk77rgjbdq0SatWrVJVVZXevXvnxRdfzOWXX56DDz44n/0gx+OPP57LLrssnTp1ytprr53rr7/eli8AAFCLNthgg9ouAfiWmO/Aikywzirnf/dR/2z/85EjR6Z169b5+9//niRZuHBhkqS4uDi77757Hn300Vx66aXp0KFDmjdvnoceeihXXHFFfvjDH6ZFixZJIlQHAAAAAATrrFr+ex/1Tz75JA0bNqwJw998880UFxfnlltuydtvv51p06blySefTI8ePXLVVVflmmuuyZFHHpnDDz88a6yxRhYsWJArr7wye+yxRy2OCAAAAABY0Ti8lFXO7Nmzc8opp2Ts2LHp3r17dtppp/zgBz/IM888k+uvvz533HFH+vfvn7XXXjt16tTJnXfeme9///u57rrrMn/+/Hz66ad56623sskmm9T2UAAAAACAFZBgnVXK3/72twwaNCgbbbRRttpqq4wePTr/+Mc/8sYbb6Rdu3aZM2dOFixYkEaNGtWsbN9jjz2y/vrr58ILL0xVVVXNdQAAAACAJSmu7QKgEB999FGSRVu+VFZWLtY2ZcqUPP300znttNPywAMPZMiQIfnxj3+cTz75JKeeemrmz5+fNdZYI+Xl5ZkzZ04+/fTTXHfddfn3v/+dbbbZJkVFRUJ1AAAAAOBLWbHOSuNXv/pVXnrppfz2t7/N2muvnST54IMP8sEHH6R3796pU6dO/vWvf+U73/lOpk2bloEDB+a5557L7rvvnt///vf529/+lj322CPPPfdchg0blqeffjoTJ07M5Zdfnn322aeWRwcAAAAArCysWGel0b9//4wfPz4PPPBAkuT444/Peuutl3322Sfbb7997rjjjvTr1y9JcsQRR6RBgwZ59tlnc/3112fzzTfPZZddllmzZmXjjTdO586dc9RRR2XixIlCdQAAAACgIHVquwD4qjbZZJN85zvfySOPPJJZs2blnXfeyb/+9a/MmjUrt912W4488sh07tw5lZWVeeWVV3L//fenc+fOmThxYmbPnp3nnnsul19+eU4//fT87Gc/S3Gx7ysBAAAAAIWzFQwrlQ8//DA77bRTpk+fnmOPPTYnnnhikkX7qx911FGZNm1abrrppqy77rp5/PHHs9lmm+Xmm2/OO++8k+7du6d79+7ZeOONa3kUAAAAAMDKzIp1ViotW7bMEUcckWOOOSYNGjSoud6iRYv89Kc/zb777ps33ngjP/7xj7PLLrvUHFR64403ZrfddqvFygEAAACAVYW9MFjpHHLIIdl0003z1FNP5cMPP0ySFBcXp3Xr1mnWrFmKiopy/fXX55ZbbsnZZ5+djz76SKgOAAAAACwzgnVWOvXq1cu5556b119/PbfcckvN9blz52b27Nlp3rx5SktLs9NOO+WQQw6pxUoBAAAAgFWRPdZZKVVXV2fvvffOiBEjsv/++6dbt2655JJL0qtXr/zpT39K06ZNa7tEAAAAAGAVJVhnpfXuu+9miy22SJcuXdK7d++su+66OfbYY2u7LAAAAABgFSdYZ6V23HHHZYsttsi+++6b4mI7GwEAAAAAy59gnZVaVVWVQB0AAAAA+FYJ1gEAAAAAoACW+gIAAAAAQAEE6wAAAAAAUADBOgAAAAAAFECwDgAAAAAABRCsAwAAAABAAQTrAAAAAABQAME6AACrhb59++b4449f5s89++yz06tXr2X+XAAAYMUlWAcAoNYdfPDBKSoqytFHH/25tmOPPTZFRUU5+OCDv9KzHn300RQVFWXGjBnLtkgAAID/I1gHAGCF0KFDh9x222359NNPa67NnTs3t9xySzp27FiLlQEAACxOsA4AwAqhd+/e6dChQ/7+97/XXPv73/+ejh07ZuONN665VlVVlfPPPz9rr712GjRokI022ih//etfkyTjxo3LNttskyRp2rTp51a6V1VV5Re/+EWaNWuW1q1b5+yzz16shvHjx2f33XdPo0aNUlZWln333TdTpkxZrM8FF1yQVq1apXHjxjnssMMyd+7cZfxJAAAAKzrBOgAAK4xDDz00f/jDH2pe//73v88hhxyyWJ/zzz8/N998c6655pq8/vrrOeGEE/LjH/84jz32WDp06JC//e1vSZKxY8dm0qRJufzyy2vu/eMf/5iGDRvmueeey0UXXZRzzjknI0aMSLIodN99990zbdq0PPbYYxkxYkTeeeed7LfffjX333HHHTn77LNz3nnn5cUXX0ybNm1y9dVXL8+PBAAAWAEVVVdXV9d2EQAArN4OPvjgzJgxI9dff306dOiQsWPHJkm6du2aCRMm5PDDD0+TJk1y7bXXplmzZnn44YezxRZb1Nx/+OGHZ86cObnlllvy6KOPZptttsn06dPTpEmTmj59+/ZNZWVlnnjiiZprm2++efr165cLLrggI0aMSP/+/fPuu++mQ4cOSZLRo0ene/fuef7557PZZpvlu9/9bjbeeONcddVVNc/4zne+k7lz52bkyJHL90MCAABWGHVquwAAAPhMixYtsvPOO+emm25KdXV1dt555zRv3rym/a233sqcOXOy/fbbL3bf/PnzF9suZml69uy52Os2bdrkww8/TJKMGTMmHTp0qAnVk6Rbt25p0qRJxowZk8022yxjxoz53AGrW2yxRR555JGCxwoAAKy8BOsAAKxQDj300AwaNChJFlsZniSzZ89Oktx3331p167dYm2lpaVf+uy6desu9rqoqChVVVXfpFwAAGA1ZI91AABWKDvuuGPmz5+fBQsWZIcddlisrVu3biktLc348eOz7rrrLvb12UrzevXqJUkqKysLet8NNtggEyZMyIQJE2qujR49OjNmzEi3bt1q+jz33HOL3ffss88WPEYAAGDlZsU6AAArlJKSkowZM6bm1/+tcePGGTx4cE444YRUVVVlyy23zMyZM/PUU0+lrKwsBx10UDp16pSioqLce++92WmnndKgQYM0atToS993u+22S48ePXLAAQfksssuy8KFC3PMMcdk6623zqabbpokOe6443LwwQdn0003zfe+970MGzYsr7/+ejp37rzsPwgAAGCFZcU6AAArnLKyspSVlS2x7dxzz80ZZ5yR888/PxtssEF23HHH3HfffVl77bWTJO3atcsvf/nLnHLKKWnVqlXNtjJfpqioKP/4xz/StGnTbLXVVtluu+3SuXPn3H777TV99ttvv5xxxhn5xS9+kU022STvvfdeBg4c+M0HDAAArFSKqqurq2u7CAAAAAAAWFlYsQ4AAAAAAAUQrAMAAAAAQAEE6wAAAAAAUADBOgAAAAAAFECwDgAAAAAABRCsAwAAAABAAQTrAAAAAABQAME6AAAAAAAUQLAOAAAAAAAFEKwDAAAAAEABBOsAAAAAAFAAwToAAAAAABTg/wEAdVkj5CKligAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1500x900 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# train_all_fold_profit_df = train_all_fold_profit_df.drop(columns=[\"S12\", \"S15\", \"S16\"])\n",
    "# test_all_fold_profit_df = test_all_fold_profit_df.drop(columns=[\"S12\", \"S15\", \"S16\"])\n",
    "\n",
    "train_all_fold_profit_df = train_all_fold_profit_df.drop(columns=[\"S15\", \"S16\"])\n",
    "test_all_fold_profit_df = test_all_fold_profit_df.drop(columns=[\"S15\", \"S16\"])\n",
    "\n",
    "# 1️⃣ 計算平均 profit\n",
    "train_means = train_all_fold_profit_df.mean()\n",
    "test_means = test_all_fold_profit_df.mean()\n",
    "\n",
    "# 2️⃣ 定義 baseline & theory best\n",
    "baseline_train = train_means[\"baseline\"]\n",
    "baseline_test = test_means[\"baseline\"]\n",
    "theory_best_train = train_means[\"S14\"]\n",
    "theory_best_test = test_means[\"S14\"]\n",
    "\n",
    "# 3️⃣ 計算百分比變化：baseline & theory\n",
    "train_pct_base = (train_means - baseline_train) / baseline_train * 100\n",
    "test_pct_base = (test_means - baseline_test) / baseline_test * 100\n",
    "train_pct_theory = (train_means - theory_best_train) / theory_best_train * 100\n",
    "test_pct_theory = (test_means - theory_best_test) / theory_best_test * 100\n",
    "\n",
    "# 4️⃣ 建 DataFrame\n",
    "avg_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Method\": train_means.index,\n",
    "        \"Train\": train_means.values,\n",
    "        \"Test\": test_means.values,\n",
    "        \"Train_%_Base\": train_pct_base.values,\n",
    "        \"Test_%_Base\": test_pct_base.values,\n",
    "        \"Train_%_Theory\": train_pct_theory.values,\n",
    "        \"Test_%_Theory\": test_pct_theory.values,\n",
    "    }\n",
    ")\n",
    "\n",
    "avg_df_melted = avg_df.melt(\n",
    "    id_vars=[\n",
    "        \"Method\",\n",
    "        \"Train_%_Base\",\n",
    "        \"Test_%_Base\",\n",
    "        \"Train_%_Theory\",\n",
    "        \"Test_%_Theory\",\n",
    "    ],\n",
    "    value_vars=[\"Train\", \"Test\"],\n",
    "    var_name=\"Dataset\",\n",
    "    value_name=\"Average Profit\",\n",
    ")\n",
    "\n",
    "# 5️⃣ 畫圖\n",
    "plt.figure(figsize=(15, 9))\n",
    "ax = sns.barplot(x=\"Method\", y=\"Average Profit\", hue=\"Dataset\", data=avg_df_melted)\n",
    "\n",
    "# 6️⃣ 標註：baseline (%) 在第一行、theory (%) 括號內第二行\n",
    "for patch, (method, ds) in zip(\n",
    "    ax.patches, zip(avg_df_melted[\"Method\"], avg_df_melted[\"Dataset\"])\n",
    "):\n",
    "    if ds == \"Train\":\n",
    "        pct_base = avg_df.loc[avg_df.Method == method, \"Train_%_Base\"].values[0]\n",
    "        pct_theory = avg_df.loc[avg_df.Method == method, \"Train_%_Theory\"].values[0]\n",
    "    else:\n",
    "        pct_base = avg_df.loc[avg_df.Method == method, \"Test_%_Base\"].values[0]\n",
    "        pct_theory = avg_df.loc[avg_df.Method == method, \"Test_%_Theory\"].values[0]\n",
    "\n",
    "    ax.annotate(\n",
    "        f\"{pct_base:.1f}%\\n({pct_theory:.1f}%)\",\n",
    "        (patch.get_x() + patch.get_width() / 2, patch.get_height()),\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=9,\n",
    "        xytext=(0, 5),\n",
    "        textcoords=\"offset points\",\n",
    "    )\n",
    "\n",
    "plt.title(\"Average Profit (Train vs Test) — % Change vs Baseline / Theory Best\")\n",
    "plt.ylabel(\"Average Profit\")\n",
    "plt.xlabel(\"Method\")\n",
    "plt.xticks(rotation=30)\n",
    "plt.legend(title=\"Dataset\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 計算 baseline（訓練與測試）\n",
    "baseline_train = train_all_fold_profit_df[\"baseline\"].to_numpy().reshape(-1, 1)\n",
    "baseline_test = test_all_fold_profit_df[\"baseline\"].to_numpy().reshape(-1, 1)\n",
    "\n",
    "# # 計算百分比變化\n",
    "# train_relative = (\n",
    "#     (train_all_fold_profit_df.to_numpy() - baseline_train) / baseline_train * 100\n",
    "# )\n",
    "# test_relative = (\n",
    "#     (test_all_fold_profit_df.to_numpy() - baseline_test) / baseline_test * 100\n",
    "# )\n",
    "\n",
    "train_relative = (\n",
    "    (train_all_fold_profit_df.to_numpy() - baseline_train)\n",
    "    / np.abs(baseline_train)\n",
    "    * 100\n",
    ")\n",
    "test_relative = (\n",
    "    (test_all_fold_profit_df.to_numpy() - baseline_test) / np.abs(baseline_test) * 100\n",
    ")\n",
    "\n",
    "# 轉回 DataFrame，並保留 column names\n",
    "train_relative = pd.DataFrame(\n",
    "    train_relative,\n",
    "    columns=train_all_fold_profit_df.columns,\n",
    "    index=train_all_fold_profit_df.index,\n",
    ")\n",
    "test_relative = pd.DataFrame(\n",
    "    test_relative,\n",
    "    columns=test_all_fold_profit_df.columns,\n",
    "    index=test_all_fold_profit_df.index,\n",
    ")\n",
    "\n",
    "# 加入 fold 編號\n",
    "train_relative[\"Fold\"] = train_relative.index + 1\n",
    "test_relative[\"Fold\"] = test_relative.index + 1\n",
    "\n",
    "# 轉換成長格式\n",
    "train_long = train_relative.melt(\n",
    "    id_vars=\"Fold\", var_name=\"Method\", value_name=\"Relative Profit (%)\"\n",
    ")\n",
    "train_long[\"Dataset\"] = \"Train\"\n",
    "\n",
    "test_long = test_relative.melt(\n",
    "    id_vars=\"Fold\", var_name=\"Method\", value_name=\"Relative Profit (%)\"\n",
    ")\n",
    "test_long[\"Dataset\"] = \"Test\"\n",
    "\n",
    "# 合併數據\n",
    "fold_long = pd.concat([train_long, test_long], axis=0)\n",
    "\n",
    "# # === 1. 使用線圖 (Line Plot) 觀察不同 Fold 上的變化趨勢 ===\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.lineplot(\n",
    "#     data=fold_long,\n",
    "#     x=\"Fold\",\n",
    "#     y=\"Relative Profit (%)\",\n",
    "#     hue=\"Method\",\n",
    "#     style=\"Dataset\",\n",
    "#     markers=True,\n",
    "#     dashes=False,\n",
    "# )\n",
    "# plt.axhline(0, color=\"gray\", linestyle=\"--\", linewidth=1)  # 基準線\n",
    "# plt.title(\"Strategy Performance Across Folds (Relative to Baseline)\")\n",
    "# plt.legend(title=\"Method & Dataset\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "# plt.show()\n",
    "\n",
    "# # === 2. 使用箱型圖 (Box Plot) 查看策略穩定性 ===\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.boxplot(data=fold_long, x=\"Method\", y=\"Relative Profit (%)\", hue=\"Dataset\")\n",
    "# plt.axhline(0, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "# plt.title(\"Strategy Performance Distribution Across Folds\")\n",
    "# plt.xticks(rotation=30)\n",
    "# plt.legend(title=\"Dataset\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "# plt.show()\n",
    "\n",
    "# 3️⃣ Heatmap：同時顯示 vs Baseline & vs Theory Best（每 Fold 的 S14）\n",
    "theory_best_train = train_all_fold_profit_df[\"S14\"].to_numpy().reshape(-1, 1)\n",
    "theory_best_test = test_all_fold_profit_df[\"S14\"].to_numpy().reshape(-1, 1)\n",
    "\n",
    "# vs Theory (%) 計算\n",
    "# train_theory_rel = (\n",
    "#     (train_all_fold_profit_df.to_numpy() - theory_best_train) / theory_best_train * 100\n",
    "# )\n",
    "# test_theory_rel = (\n",
    "#     (test_all_fold_profit_df.to_numpy() - theory_best_test) / theory_best_test * 100\n",
    "# )\n",
    "train_theory_rel = (\n",
    "    (train_all_fold_profit_df.to_numpy() - theory_best_train)\n",
    "    / np.abs(theory_best_train)\n",
    "    * 100\n",
    ")\n",
    "test_theory_rel = (\n",
    "    (test_all_fold_profit_df.to_numpy() - theory_best_test)\n",
    "    / np.abs(theory_best_test)\n",
    "    * 100\n",
    ")\n",
    "\n",
    "# 回 DataFrame 並 melt\n",
    "train_theory_rel = pd.DataFrame(\n",
    "    train_theory_rel,\n",
    "    columns=train_all_fold_profit_df.columns,\n",
    "    index=train_all_fold_profit_df.index,\n",
    ")\n",
    "train_theory_rel[\"Fold\"] = train_theory_rel.index + 1\n",
    "train_theory_long = train_theory_rel.melt(\n",
    "    id_vars=\"Fold\", var_name=\"Method\", value_name=\"Relative vs Theory (%)\"\n",
    ")\n",
    "train_theory_long[\"Dataset\"] = \"Train\"\n",
    "\n",
    "test_theory_rel = pd.DataFrame(\n",
    "    test_theory_rel,\n",
    "    columns=test_all_fold_profit_df.columns,\n",
    "    index=test_all_fold_profit_df.index,\n",
    ")\n",
    "test_theory_rel[\"Fold\"] = test_theory_rel.index + 1\n",
    "test_theory_long = test_theory_rel.melt(\n",
    "    id_vars=\"Fold\", var_name=\"Method\", value_name=\"Relative vs Theory (%)\"\n",
    ")\n",
    "test_theory_long[\"Dataset\"] = \"Test\"\n",
    "\n",
    "# 合併 baseline (%) 與 theory (%) 資料\n",
    "merged = fold_long.merge(\n",
    "    pd.concat([train_theory_long, test_theory_long], axis=0),\n",
    "    on=[\"Fold\", \"Method\", \"Dataset\"],\n",
    ")\n",
    "\n",
    "# Pivot heatmap values + annotations\n",
    "heatmap_data = merged.pivot(\n",
    "    index=\"Fold\", columns=[\"Method\", \"Dataset\"], values=\"Relative Profit (%)\"\n",
    ")\n",
    "annot = merged.assign(\n",
    "    annot=merged[\"Relative Profit (%)\"].round(1).astype(str)\n",
    "    + \"\\n(\"\n",
    "    + merged[\"Relative vs Theory (%)\"].round(1).astype(str)\n",
    "    + \"%)\"\n",
    ").pivot(index=\"Fold\", columns=[\"Method\", \"Dataset\"], values=\"annot\")\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.heatmap(heatmap_data, annot=annot, fmt=\"\", cmap=\"coolwarm\", linewidths=0.5)\n",
    "plt.title(\"Relative Profit (%) Across Folds\\n(vs Baseline / (vs Theory Best))\")\n",
    "plt.ylabel(\"Fold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved as plots/plot_strategies_profits_scatter_train_med_with_holding_cost_0.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 訓練階段分佈\n",
    "\n",
    "baseline_data = []\n",
    "S1_data = []\n",
    "S2_data = []\n",
    "S12_data = []\n",
    "S14_data = []\n",
    "S15_data = []\n",
    "\n",
    "for result in train_all_fold_stimulation_results:\n",
    "    baseline_data.append(result[\"baseline\"])\n",
    "    S1_data.append(result[\"S1\"])\n",
    "    S2_data.append(result[\"S2\"])\n",
    "    # S12_data.append(result[\"S12\"])\n",
    "    # S14_data.append(result[\"S14\"])\n",
    "    # S15_data.append(result[\"S15\"])\n",
    "\n",
    "# 合併數據\n",
    "baseline_df = pd.concat(baseline_data, ignore_index=True)\n",
    "S1_df = pd.concat(S1_data, ignore_index=True)\n",
    "S2_df = pd.concat(S2_data, ignore_index=True)\n",
    "# S12_df = pd.concat(S12_data, ignore_index=True)\n",
    "# S14_df = pd.concat(S14_data, ignore_index=True)\n",
    "# S15_df = pd.concat(S15_data, ignore_index=True)\n",
    "\n",
    "\n",
    "dfs = {\n",
    "    \"baseline\": baseline_df,\n",
    "    \"S1\": S1_df,\n",
    "    \"S2\": S2_df,\n",
    "    # \"S12\": S12_df,\n",
    "    # \"S15\": S15_df,\n",
    "    # \"S14\": S14_df,\n",
    "}\n",
    "\n",
    "# 調用繪圖函數\n",
    "plot_strategies_profits_scatter(f\"{status}_{model_prefix}\", dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved as plots/plot_strategies_profits_scatter_train_med_with_holding_cost_0.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 測試結果分布圖\n",
    "\n",
    "baseline_data = []\n",
    "S1_data = []\n",
    "S2_data = []\n",
    "S12_data = []\n",
    "S14_data = []\n",
    "S15_data = []\n",
    "\n",
    "for result in test_all_fold_stimulation_results:\n",
    "    baseline_data.append(result[\"baseline\"])\n",
    "    S1_data.append(result[\"S1\"])\n",
    "    S2_data.append(result[\"S2\"])\n",
    "    # S12_data.append(result[\"S12\"])\n",
    "    # S14_data.append(result[\"S14\"])\n",
    "    # S15_data.append(result[\"S15\"])\n",
    "# 合併數據\n",
    "baseline_df = pd.concat(baseline_data, ignore_index=True)\n",
    "S1_df = pd.concat(S1_data, ignore_index=True)\n",
    "S2_df = pd.concat(S2_data, ignore_index=True)\n",
    "# S12_df = pd.concat(S12_data, ignore_index=True)\n",
    "# S14_df = pd.concat(S14_data, ignore_index=True)\n",
    "# S15_df = pd.concat(S15_data, ignore_index=True)\n",
    "\n",
    "dfs = {\n",
    "    \"baseline\": baseline_df,\n",
    "    \"S1\": S1_df,\n",
    "    \"S2\": S2_df,\n",
    "    # \"S12\": S12_df,\n",
    "    # \"S15\": S15_df,\n",
    "    # \"S14\": S14_df,\n",
    "}\n",
    "\n",
    "# 調用繪圖函數\n",
    "plot_strategies_profits_scatter(f\"{status}_{model_prefix}\", dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ast\n",
    "\n",
    "# summary_df = pd.read_csv(\n",
    "#     \"/Users/hanyuan/Github/Two-Phase-Newsvendor/results/summary.csv\"\n",
    "# )\n",
    "\n",
    "# records_str = summary_df.loc[0, \"train_df\"]\n",
    "# records = ast.literal_eval(records_str)\n",
    "\n",
    "# df_reconstructed = pd.DataFrame(records)\n",
    "# df_reconstructed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Processing Fold 1 =====\n",
      "training_df: \n",
      "           X1   X2          X3\n",
      "0   17.744068  0.0  254.356465\n",
      "1   18.575947  0.0  251.010920\n",
      "2   18.013817  0.0  291.630992\n",
      "3   17.724416  0.0  288.907838\n",
      "4   17.118274  0.0  293.500607\n",
      "5   18.229471  0.0  298.930917\n",
      "6   17.187936  0.0  289.957928\n",
      "7   19.458865  0.0  273.073968\n",
      "8   19.818314  0.0  289.026459\n",
      "9   16.917208  0.0  255.913721\n",
      "10  18.958625  0.0  281.996051\n",
      "11  17.644475  0.0  257.167664\n",
      "12  17.840223  0.0  297.233446\n",
      "13  19.627983  0.0  276.092416\n",
      "14  15.355180  0.0  270.733097\n",
      "demand_df_train: \n",
      "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
      "0   251.794016  254.356464  247.741536  254.356465  261.523870  254.356465   \n",
      "1   251.056784  251.010919  248.192143  251.010920  250.249903  251.010920   \n",
      "2   297.528249  291.630992  294.250464  291.630992  283.569719  291.630992   \n",
      "3   289.066894  288.907838  288.355508  288.907838  285.816090  288.907838   \n",
      "4   298.072424  293.500607  299.903104  293.500607  296.615372  293.500607   \n",
      "5   301.401948  298.930917  300.714683  298.930917  294.785980  298.930917   \n",
      "6   291.672619  289.957928  291.788015  289.957928  285.872455  289.957928   \n",
      "7   269.341662  273.073968  269.572013  273.073968  271.669642  273.073968   \n",
      "8   291.803572  289.026459  288.668454  289.026459  282.672846  289.026459   \n",
      "9   258.259455  255.913721  255.439341  255.913721  255.976937  255.913721   \n",
      "10  278.551022  281.996051  281.029925  281.996051  289.535263  281.996051   \n",
      "11  256.151738  257.167663  252.945792  257.167664  264.788247  257.167664   \n",
      "12  295.186828  297.233446  298.436136  297.233446  301.105487  297.233446   \n",
      "13  278.898077  276.092416  278.517826  276.092416  274.536813  276.092416   \n",
      "14  276.126061  270.733097  271.699824  270.733097  268.070512  270.733097   \n",
      "\n",
      "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
      "0   254.087872  252.716034  254.356465  254.356465  \n",
      "1   252.054546  246.842220  251.010920  251.010920  \n",
      "2   285.767294  287.835884  291.630992  291.630992  \n",
      "3   292.681865  290.851589  288.907838  288.907838  \n",
      "4   290.943971  295.944768  293.500607  293.500607  \n",
      "5   299.484772  298.727945  298.930917  298.930917  \n",
      "6   290.444897  292.664979  289.957928  289.957928  \n",
      "7   273.459253  273.376911  273.073968  273.073968  \n",
      "8   287.717318  286.983188  289.026459  289.026459  \n",
      "9   255.911150  251.612160  255.913721  255.913721  \n",
      "10  285.332026  287.403702  281.996051  281.996051  \n",
      "11  262.220107  256.201799  257.167664  257.167664  \n",
      "12  295.272601  298.475322  297.233446  297.233446  \n",
      "13  276.925605  274.583612  276.092416  276.092416  \n",
      "14  266.551512  268.201901  270.733097  270.733097  \n",
      "testing_df: \n",
      "           X1   X2         X3\n",
      "0   16.322778  1.0  66.706379\n",
      "1   18.871168  1.0  62.103826\n",
      "2   17.280752  1.0  61.289263\n",
      "3   17.842170  1.0  63.154284\n",
      "4   15.093949  1.0  63.637108\n",
      "5   18.088177  1.0  65.701968\n",
      "6   18.060479  1.0  64.386015\n",
      "7   18.084670  1.0  69.883738\n",
      "8   19.718740  1.0  61.020448\n",
      "9   18.409101  1.0  62.088768\n",
      "10  16.797540  1.0  61.613095\n",
      "11  17.185160  1.0  66.531083\n",
      "12  18.488156  1.0  62.532916\n",
      "13  15.301127  1.0  64.663108\n",
      "14  18.333834  1.0  62.444256\n",
      "demand_df_test: \n",
      "    demand_t1  demand_t2  demand_t3  demand_t4  demand_t5  demand_t6  \\\n",
      "0   69.049446  66.984864  65.276090  66.706379  64.399509  66.706379   \n",
      "1   62.472855  61.379065  62.263812  62.103826  59.547465  62.103826   \n",
      "2   57.026718  60.339037  58.994137  61.289263  61.559450  61.289263   \n",
      "3   62.944633  65.536993  64.153686  63.154284  59.520451  63.154284   \n",
      "4   66.458142  64.430325  65.691033  63.637108  58.415305  63.637108   \n",
      "5   65.340264  66.665934  65.624076  65.701968  65.763430  65.701968   \n",
      "6   60.459442  64.184997  61.973620  64.386015  65.111260  64.386015   \n",
      "7   71.557122  70.563024  74.662817  69.883738  69.277905  69.883738   \n",
      "8   63.840751  62.306341  66.968545  61.020448  59.275984  61.020448   \n",
      "9   62.969099  64.263725  64.029270  62.088768  60.721711  62.088768   \n",
      "10  60.057707  60.871552  60.104051  61.613095  62.302393  61.613095   \n",
      "11  68.193840  67.527301  72.362407  66.531083  64.621767  66.531083   \n",
      "12  55.740736  63.143807  63.924512  62.532916  65.056794  62.532916   \n",
      "13  67.989985  63.983761  64.570792  64.663108  66.958315  64.663108   \n",
      "14  58.797450  62.278203  63.120200  62.444256  58.121198  62.444256   \n",
      "\n",
      "    demand_t7  demand_t8  demand_t9  demand_t10  \n",
      "0   71.005184  64.088969  66.706381   66.706379  \n",
      "1   63.271804  55.331312  62.103825   62.103826  \n",
      "2   63.232738  60.581985  61.289264   61.289263  \n",
      "3   62.573906  68.894022  63.154284   63.154283  \n",
      "4   62.211406  62.929656  63.637111   63.637108  \n",
      "5   62.072328  64.226544  65.701970   65.701968  \n",
      "6   66.214844  63.597722  64.386018   64.386015  \n",
      "7   68.924536  69.361419  69.883738   69.883738  \n",
      "8   59.005480  60.829499  61.020442   61.020448  \n",
      "9   60.879685  62.634618  62.088772   62.088768  \n",
      "10  61.283812  63.885645  61.613092   61.613095  \n",
      "11  65.714526  66.642278  66.531082   66.531083  \n",
      "12  56.151613  66.725960  62.532920   62.532916  \n",
      "13  65.885875  61.730881  64.663100   64.663108  \n",
      "14  57.806186  61.151295  62.444260   62.444256  \n",
      "===== Processing Fold 2 =====\n",
      "training_df: \n",
      "           X1   X2          X3\n",
      "0   15.794848  0.0  251.959390\n",
      "1   15.551876  0.0  264.140348\n",
      "2   18.281648  0.0  256.009828\n",
      "3   15.690915  0.0  264.807010\n",
      "4   15.982912  0.0  255.936386\n",
      "5   16.843626  0.0  265.899159\n",
      "6   19.104966  0.0  270.713150\n",
      "7   15.485506  0.0  253.207375\n",
      "8   19.189725  0.0  284.623606\n",
      "9   15.480492  0.0  278.330073\n",
      "10  19.882297  0.0  263.269475\n",
      "11  17.343256  0.0  276.162403\n",
      "12  19.883805  0.0  254.697026\n",
      "13  18.024228  0.0  278.797325\n",
      "14  18.696318  0.0  296.464810\n",
      "demand_df_train: \n",
      "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
      "0   256.519623  251.959390  252.619473  251.959390  246.815799  251.959390   \n",
      "1   266.557046  264.140348  264.160430  264.140348  262.456134  264.140348   \n",
      "2   255.104623  256.009829  259.397400  256.009828  253.201453  256.009828   \n",
      "3   258.328805  264.807010  266.027383  264.807010  264.784493  264.807010   \n",
      "4   253.416118  255.936386  254.214539  255.936386  256.695107  255.936386   \n",
      "5   263.215996  265.899159  268.949097  265.899159  263.130433  265.899159   \n",
      "6   267.820993  270.713150  268.501904  270.713150  272.402984  270.713150   \n",
      "7   250.255196  253.207375  252.917631  253.207375  253.511599  253.207375   \n",
      "8   291.872275  284.623606  289.498687  284.623606  279.906507  284.623606   \n",
      "9   276.428735  278.330073  277.122965  278.330073  276.905217  278.330073   \n",
      "10  261.244738  263.269475  267.407733  263.269475  263.036084  263.269475   \n",
      "11  281.624515  276.162403  277.291903  276.162403  272.064668  276.162403   \n",
      "12  256.640801  254.697025  253.216210  254.697026  257.734949  254.697026   \n",
      "13  276.596581  278.797325  282.033169  278.797325  278.763871  278.797325   \n",
      "14  297.215013  296.464810  297.943972  296.464810  296.618148  296.464810   \n",
      "\n",
      "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
      "0   252.404141  247.642667  251.959390  251.959390  \n",
      "1   268.037060  263.302797  264.140348  264.140348  \n",
      "2   254.294350  257.262525  256.009828  256.009828  \n",
      "3   265.545294  267.617149  264.807010  264.807010  \n",
      "4   259.314176  259.850532  255.936386  255.936386  \n",
      "5   261.011138  267.280099  265.899159  265.899159  \n",
      "6   270.361907  270.006558  270.713150  270.713150  \n",
      "7   251.010061  255.083055  253.207375  253.207375  \n",
      "8   286.218363  285.561041  284.623606  284.623606  \n",
      "9   280.820443  281.184906  278.330073  278.330073  \n",
      "10  260.086461  263.477115  263.269475  263.269475  \n",
      "11  274.337136  273.932259  276.162403  276.162403  \n",
      "12  260.510507  256.621323  254.697026  254.697026  \n",
      "13  274.790903  280.071033  278.797325  278.797325  \n",
      "14  293.376616  299.036274  296.464810  296.464810  \n",
      "testing_df: \n",
      "           X1   X2         X3\n",
      "0   16.592845  1.0  65.761573\n",
      "1   18.337052  1.0  65.920419\n",
      "2   15.658989  1.0  65.722519\n",
      "3   18.581636  1.0  62.230816\n",
      "4   16.447030  1.0  69.527490\n",
      "5   15.915957  1.0  64.471254\n",
      "6   17.932565  1.0  68.464087\n",
      "7   15.100538  1.0  66.994793\n",
      "8   19.144700  1.0  62.974370\n",
      "9   15.023477  1.0  68.137978\n",
      "10  18.389083  1.0  63.965057\n",
      "11  16.350040  1.0  68.811032\n",
      "12  18.675970  1.0  65.812729\n",
      "13  19.810943  1.0  68.817354\n",
      "14  16.243766  1.0  66.925316\n",
      "demand_df_test: \n",
      "    demand_t1  demand_t2  demand_t3  demand_t4  demand_t5  demand_t6  \\\n",
      "0   68.370121  64.894454  67.199076  65.761573  63.053747  65.761573   \n",
      "1   66.587610  64.979976  69.411094  65.920419  65.768066  65.920419   \n",
      "2   70.933664  66.187890  69.618863  65.722519  60.188051  65.722519   \n",
      "3   63.476652  63.427189  58.172863  62.230816  63.207280  62.230816   \n",
      "4   72.298368  69.469709  69.557802  69.527490  69.049027  69.527490   \n",
      "5   61.418697  64.596306  63.090749  64.471254  64.412447  64.471254   \n",
      "6   68.349991  68.233833  65.527941  68.464087  66.683151  68.464087   \n",
      "7   69.173899  67.791676  68.980601  66.994793  66.269833  66.994793   \n",
      "8   65.242553  65.421038  68.671875  62.974370  57.570268  62.974370   \n",
      "9   67.587048  68.232925  69.938504  68.137978  72.345359  68.137978   \n",
      "10  61.458167  62.971443  63.673554  63.965057  63.243366  63.965057   \n",
      "11  62.593521  68.252412  63.791590  68.811032  69.928345  68.811032   \n",
      "12  64.041609  65.899146  66.197404  65.812729  69.316660  65.812729   \n",
      "13  74.367057  70.734412  75.902168  68.817354  67.054075  68.817354   \n",
      "14  66.151275  66.585163  64.513272  66.925316  65.898617  66.925316   \n",
      "\n",
      "    demand_t7  demand_t8  demand_t9  demand_t10  \n",
      "0   63.984974  62.127812  65.761570   65.761573  \n",
      "1   64.382597  68.059276  65.920415   65.920419  \n",
      "2   61.025759  66.547948  65.722519   65.722519  \n",
      "3   66.306121  62.062609  62.230823   62.230816  \n",
      "4   62.861684  67.820569  69.527490   69.527490  \n",
      "5   63.799314  63.693119  64.471254   64.471254  \n",
      "6   76.051808  69.090667  68.464087   68.464087  \n",
      "7   68.198098  71.791799  66.994793   66.994793  \n",
      "8   58.224097  57.855352  62.974371   62.974369  \n",
      "9   66.220593  70.069887  68.137978   68.137978  \n",
      "10  63.568947  62.804834  63.965054   63.965057  \n",
      "11  73.798658  71.999444  68.811034   68.811032  \n",
      "12  62.910571  70.182959  65.812727   65.812729  \n",
      "13  65.788339  68.993258  68.817352   68.817354  \n",
      "14  69.469320  67.743843  66.925316   66.925316  \n",
      "===== Processing Fold 3 =====\n",
      "training_df: \n",
      "           X1   X2          X3\n",
      "0   18.626271  0.0  279.543638\n",
      "1   17.506622  0.0  278.716262\n",
      "2   19.780418  0.0  282.660041\n",
      "3   18.219951  0.0  282.605164\n",
      "4   17.119275  0.0  271.570922\n",
      "5   18.031966  0.0  294.827330\n",
      "6   15.095966  0.0  268.378094\n",
      "7   16.507874  0.0  271.793246\n",
      "8   18.300868  0.0  294.596168\n",
      "9   16.450388  0.0  290.309699\n",
      "10  18.090077  0.0  285.194429\n",
      "11  17.143844  0.0  255.011344\n",
      "12  15.677370  0.0  295.974131\n",
      "13  16.491412  0.0  285.712065\n",
      "14  17.849825  0.0  299.942350\n",
      "demand_df_train: \n",
      "     demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
      "0   283.936601  279.543638  285.077369  279.543638  276.931626  279.543638   \n",
      "1   280.752154  278.716263  284.554707  278.716262  277.019908  278.716262   \n",
      "2   280.810270  282.660041  281.793406  282.660041  283.966752  282.660041   \n",
      "3   282.690695  282.605164  284.501807  282.605163  280.263205  282.605164   \n",
      "4   269.794746  271.570922  270.571046  271.570922  268.258034  271.570922   \n",
      "5   292.141287  294.827330  296.363870  294.827330  297.636415  294.827330   \n",
      "6   268.295270  268.378094  272.289189  268.378094  267.061530  268.378094   \n",
      "7   274.284449  271.793246  275.891790  271.793246  271.007436  271.793246   \n",
      "8   295.561676  294.596168  295.346168  294.596168  293.901419  294.596168   \n",
      "9   291.572767  290.309699  289.337801  290.309699  287.979840  290.309699   \n",
      "10  289.359045  285.194429  290.753028  285.194429  285.165963  285.194429   \n",
      "11  259.085891  255.011345  255.041535  255.011344  252.753361  255.011344   \n",
      "12  294.703610  295.974131  298.873793  295.974131  294.749160  295.974131   \n",
      "13  288.208942  285.712065  285.303854  285.712065  283.167061  285.712065   \n",
      "14  297.971527  299.942350  303.764967  299.942350  296.928688  299.942350   \n",
      "\n",
      "     demand_t7   demand_t8   demand_t9  demand_t10  \n",
      "0   279.497137  277.402834  279.543638  279.543638  \n",
      "1   272.022711  278.462176  278.716262  278.716262  \n",
      "2   284.073037  284.669504  282.660041  282.660041  \n",
      "3   280.973891  281.791857  282.605164  282.605164  \n",
      "4   273.396903  267.461509  271.570922  271.570922  \n",
      "5   290.725323  299.869873  294.827330  294.827330  \n",
      "6   264.194145  269.637850  268.378094  268.378094  \n",
      "7   271.264363  278.902212  271.793246  271.793246  \n",
      "8   293.952546  289.434761  294.596168  294.596168  \n",
      "9   296.220290  291.572601  290.309699  290.309699  \n",
      "10  280.959832  286.639870  285.194429  285.194429  \n",
      "11  255.233465  254.206041  255.011344  255.011344  \n",
      "12  295.417869  296.365897  295.974131  295.974131  \n",
      "13  283.449034  289.498190  285.712065  285.712065  \n",
      "14  293.866069  299.198634  299.942350  299.942350  \n",
      "testing_df: \n",
      "           X1   X2         X3\n",
      "0   15.747242  1.0  68.558033\n",
      "1   19.340630  1.0  60.117141\n",
      "2   15.812465  1.0  63.599781\n",
      "3   18.077798  1.0  67.299906\n",
      "4   15.619100  1.0  61.716297\n",
      "5   19.240041  1.0  65.210366\n",
      "6   19.036595  1.0  60.543380\n",
      "7   17.845504  1.0  61.999965\n",
      "8   17.035916  1.0  60.185218\n",
      "9   15.345835  1.0  67.936977\n",
      "10  18.487144  1.0  62.239247\n",
      "11  17.267713  1.0  63.453517\n",
      "12  18.610278  1.0  69.280813\n",
      "13  19.331912  1.0  67.044144\n",
      "14  19.877608  1.0  60.318389\n",
      "demand_df_test: \n",
      "    demand_t1  demand_t2  demand_t3  demand_t4  demand_t5  demand_t6  \\\n",
      "0   65.625929  67.884966  68.750730  68.558033  74.175914  68.558033   \n",
      "1   60.770111  61.058111  59.574148  60.117141  58.717761  60.117141   \n",
      "2   66.073532  64.930685  65.683239  63.599781  63.459309  63.599781   \n",
      "3   63.121389  66.381203  61.668540  67.299906  67.404706  67.299906   \n",
      "4   64.915095  62.604395  65.471782  61.716297  63.127936  61.716297   \n",
      "5   63.427651  63.458016  59.857699  65.210366  66.962546  65.210366   \n",
      "6   60.438469  59.245399  60.450320  60.543380  56.855468  60.543380   \n",
      "7   62.564427  62.207089  62.998637  61.999965  61.345170  61.999965   \n",
      "8   60.300860  59.014437  58.383848  60.185218  60.029247  60.185218   \n",
      "9   66.947411  67.567002  67.449213  67.936977  72.133012  67.936977   \n",
      "10  65.746933  65.853934  70.574162  62.239247  55.130102  62.239247   \n",
      "11  61.329502  63.260741  60.017189  63.453517  66.141381  63.453517   \n",
      "12  66.822772  69.549069  66.237491  69.280813  70.547457  69.280813   \n",
      "13  62.577572  67.210049  65.172995  67.044144  70.357863  67.044144   \n",
      "14  59.277409  59.472203  62.933669  60.318389  57.697020  60.318389   \n",
      "\n",
      "    demand_t7  demand_t8  demand_t9  demand_t10  \n",
      "0   65.559446  71.308420  68.558033   68.558033  \n",
      "1   57.979551  58.390955  60.117144   60.117141  \n",
      "2   64.215938  63.806809  63.599781   63.599781  \n",
      "3   70.525694  68.097560  67.299908   67.299906  \n",
      "4   61.250627  60.709187  61.716291   61.716297  \n",
      "5   68.788190  65.421392  65.210367   65.210366  \n",
      "6   59.175878  58.100125  60.543382   60.543380  \n",
      "7   64.147963  63.211996  61.999964   61.999965  \n",
      "8   62.275329  58.171283  60.185214   60.185218  \n",
      "9   64.609175  66.191955  67.936978   67.936977  \n",
      "10  57.888206  63.679955  62.239243   62.239247  \n",
      "11  65.584679  64.101433  63.453519   63.453517  \n",
      "12  70.842404  73.111604  69.280814   69.280813  \n",
      "13  68.535449  70.440907  67.044145   67.044144  \n",
      "14  59.467526  57.168997  60.318390   60.318390  \n"
     ]
    }
   ],
   "source": [
    "for fold_idx in range(len(training_data_folds)):\n",
    "    print(f\"===== Processing Fold {fold_idx + 1} =====\")\n",
    "    # 取出該 fold 的訓練資料與需求資料\n",
    "    training_df, testing_df = training_data_folds[fold_idx]\n",
    "    demand_df_train, demand_df_test = demand_folds[fold_idx]\n",
    "\n",
    "    print(f\"training_df: \\n{training_df}\")\n",
    "    print(f\"demand_df_train: \\n{demand_df_train}\")\n",
    "    print(f\"testing_df: \\n{testing_df}\")\n",
    "    print(f\"demand_df_test: \\n{demand_df_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>283.936601</td>\n",
       "      <td>279.543638</td>\n",
       "      <td>285.077369</td>\n",
       "      <td>279.543638</td>\n",
       "      <td>276.931626</td>\n",
       "      <td>279.543638</td>\n",
       "      <td>279.497137</td>\n",
       "      <td>277.402834</td>\n",
       "      <td>279.543638</td>\n",
       "      <td>279.543638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>280.752154</td>\n",
       "      <td>278.716263</td>\n",
       "      <td>284.554707</td>\n",
       "      <td>278.716262</td>\n",
       "      <td>277.019908</td>\n",
       "      <td>278.716262</td>\n",
       "      <td>272.022711</td>\n",
       "      <td>278.462176</td>\n",
       "      <td>278.716262</td>\n",
       "      <td>278.716262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>280.810270</td>\n",
       "      <td>282.660041</td>\n",
       "      <td>281.793406</td>\n",
       "      <td>282.660041</td>\n",
       "      <td>283.966752</td>\n",
       "      <td>282.660041</td>\n",
       "      <td>284.073037</td>\n",
       "      <td>284.669504</td>\n",
       "      <td>282.660041</td>\n",
       "      <td>282.660041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>282.690695</td>\n",
       "      <td>282.605164</td>\n",
       "      <td>284.501807</td>\n",
       "      <td>282.605163</td>\n",
       "      <td>280.263205</td>\n",
       "      <td>282.605164</td>\n",
       "      <td>280.973891</td>\n",
       "      <td>281.791857</td>\n",
       "      <td>282.605164</td>\n",
       "      <td>282.605164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>269.794746</td>\n",
       "      <td>271.570922</td>\n",
       "      <td>270.571046</td>\n",
       "      <td>271.570922</td>\n",
       "      <td>268.258034</td>\n",
       "      <td>271.570922</td>\n",
       "      <td>273.396903</td>\n",
       "      <td>267.461509</td>\n",
       "      <td>271.570922</td>\n",
       "      <td>271.570922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "0  283.936601  279.543638  285.077369  279.543638  276.931626  279.543638   \n",
       "1  280.752154  278.716263  284.554707  278.716262  277.019908  278.716262   \n",
       "2  280.810270  282.660041  281.793406  282.660041  283.966752  282.660041   \n",
       "3  282.690695  282.605164  284.501807  282.605163  280.263205  282.605164   \n",
       "4  269.794746  271.570922  270.571046  271.570922  268.258034  271.570922   \n",
       "\n",
       "    demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "0  279.497137  277.402834  279.543638  279.543638  \n",
       "1  272.022711  278.462176  278.716262  278.716262  \n",
       "2  284.073037  284.669504  282.660041  282.660041  \n",
       "3  280.973891  281.791857  282.605164  282.605164  \n",
       "4  273.396903  267.461509  271.570922  271.570922  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.625929</td>\n",
       "      <td>67.884966</td>\n",
       "      <td>68.750730</td>\n",
       "      <td>68.558033</td>\n",
       "      <td>74.175914</td>\n",
       "      <td>68.558033</td>\n",
       "      <td>65.559446</td>\n",
       "      <td>71.308420</td>\n",
       "      <td>68.558033</td>\n",
       "      <td>68.558033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60.770111</td>\n",
       "      <td>61.058111</td>\n",
       "      <td>59.574148</td>\n",
       "      <td>60.117141</td>\n",
       "      <td>58.717761</td>\n",
       "      <td>60.117141</td>\n",
       "      <td>57.979551</td>\n",
       "      <td>58.390955</td>\n",
       "      <td>60.117144</td>\n",
       "      <td>60.117141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.073532</td>\n",
       "      <td>64.930685</td>\n",
       "      <td>65.683239</td>\n",
       "      <td>63.599781</td>\n",
       "      <td>63.459309</td>\n",
       "      <td>63.599781</td>\n",
       "      <td>64.215938</td>\n",
       "      <td>63.806809</td>\n",
       "      <td>63.599781</td>\n",
       "      <td>63.599781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63.121389</td>\n",
       "      <td>66.381203</td>\n",
       "      <td>61.668540</td>\n",
       "      <td>67.299906</td>\n",
       "      <td>67.404706</td>\n",
       "      <td>67.299906</td>\n",
       "      <td>70.525694</td>\n",
       "      <td>68.097560</td>\n",
       "      <td>67.299908</td>\n",
       "      <td>67.299906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64.915095</td>\n",
       "      <td>62.604395</td>\n",
       "      <td>65.471782</td>\n",
       "      <td>61.716297</td>\n",
       "      <td>63.127936</td>\n",
       "      <td>61.716297</td>\n",
       "      <td>61.250627</td>\n",
       "      <td>60.709187</td>\n",
       "      <td>61.716291</td>\n",
       "      <td>61.716297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   demand_t1  demand_t2  demand_t3  demand_t4  demand_t5  demand_t6  \\\n",
       "0  65.625929  67.884966  68.750730  68.558033  74.175914  68.558033   \n",
       "1  60.770111  61.058111  59.574148  60.117141  58.717761  60.117141   \n",
       "2  66.073532  64.930685  65.683239  63.599781  63.459309  63.599781   \n",
       "3  63.121389  66.381203  61.668540  67.299906  67.404706  67.299906   \n",
       "4  64.915095  62.604395  65.471782  61.716297  63.127936  61.716297   \n",
       "\n",
       "   demand_t7  demand_t8  demand_t9  demand_t10  \n",
       "0  65.559446  71.308420  68.558033   68.558033  \n",
       "1  57.979551  58.390955  60.117144   60.117141  \n",
       "2  64.215938  63.806809  63.599781   63.599781  \n",
       "3  70.525694  68.097560  67.299908   67.299906  \n",
       "4  61.250627  60.709187  61.716291   61.716297  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Qk_hat_k2</th>\n",
       "      <th>Qk_hat_k3</th>\n",
       "      <th>Qk_hat_k4</th>\n",
       "      <th>Qk_hat_k5</th>\n",
       "      <th>Qk_hat_k6</th>\n",
       "      <th>Qk_hat_k7</th>\n",
       "      <th>Qk_hat_k8</th>\n",
       "      <th>Qk_hat_k9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>667.825323</td>\n",
       "      <td>679.441327</td>\n",
       "      <td>674.336130</td>\n",
       "      <td>686.341734</td>\n",
       "      <td>688.364627</td>\n",
       "      <td>688.364627</td>\n",
       "      <td>686.123725</td>\n",
       "      <td>687.537538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>619.725973</td>\n",
       "      <td>615.200743</td>\n",
       "      <td>617.411438</td>\n",
       "      <td>601.269391</td>\n",
       "      <td>602.480994</td>\n",
       "      <td>602.480994</td>\n",
       "      <td>597.018099</td>\n",
       "      <td>596.959203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>672.259056</td>\n",
       "      <td>647.406803</td>\n",
       "      <td>648.811197</td>\n",
       "      <td>641.621708</td>\n",
       "      <td>641.893589</td>\n",
       "      <td>641.893589</td>\n",
       "      <td>643.407440</td>\n",
       "      <td>642.568633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>643.016582</td>\n",
       "      <td>667.674964</td>\n",
       "      <td>672.068531</td>\n",
       "      <td>670.587870</td>\n",
       "      <td>667.499784</td>\n",
       "      <td>667.499784</td>\n",
       "      <td>667.856550</td>\n",
       "      <td>666.398720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>660.784144</td>\n",
       "      <td>624.692052</td>\n",
       "      <td>623.360680</td>\n",
       "      <td>621.516161</td>\n",
       "      <td>624.134902</td>\n",
       "      <td>624.134902</td>\n",
       "      <td>625.562706</td>\n",
       "      <td>624.944206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Qk_hat_k2   Qk_hat_k3   Qk_hat_k4   Qk_hat_k5   Qk_hat_k6   Qk_hat_k7  \\\n",
       "0  667.825323  679.441327  674.336130  686.341734  688.364627  688.364627   \n",
       "1  619.725973  615.200743  617.411438  601.269391  602.480994  602.480994   \n",
       "2  672.259056  647.406803  648.811197  641.621708  641.893589  641.893589   \n",
       "3  643.016582  667.674964  672.068531  670.587870  667.499784  667.499784   \n",
       "4  660.784144  624.692052  623.360680  621.516161  624.134902  624.134902   \n",
       "\n",
       "    Qk_hat_k8   Qk_hat_k9  \n",
       "0  686.123725  687.537538  \n",
       "1  597.018099  596.959203  \n",
       "2  643.407440  642.568633  \n",
       "3  667.856550  666.398720  \n",
       "4  625.562706  624.944206  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_matrix, covariance_matrix = cal_mu_and_cov_matrix(demand_df_test)\n",
    "Qk_hat_df_test = make_Qk_hat_df(\n",
    "    demand_df_test, T, service_lv, mu_matrix, covariance_matrix\n",
    ")\n",
    "Qk_hat_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2855.933587421095)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2855.933587421095)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R(T)</th>\n",
       "      <th>F</th>\n",
       "      <th>Q0</th>\n",
       "      <th>Q1</th>\n",
       "      <th>average_profits</th>\n",
       "      <th>average_losses</th>\n",
       "      <th>average_lefts</th>\n",
       "      <th>average_operation_profits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[2570.3402286789856, 2570.3402286789856, 2570....</td>\n",
       "      <td>[230.22352875709203, 216.05273980283528, 258.2...</td>\n",
       "      <td>1.694693e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>311.185194</td>\n",
       "      <td>1.695198e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>[2284.746869936876, 2284.746869936876, 2284.74...</td>\n",
       "      <td>[518.5719127590378, 503.406445784251, 545.1697...</td>\n",
       "      <td>1.693793e+06</td>\n",
       "      <td>0.703986</td>\n",
       "      <td>308.737744</td>\n",
       "      <td>1.694776e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>[1999.1535111947667, 1999.1535111947667, 1999....</td>\n",
       "      <td>[801.3659753110853, 791.2130466800479, 829.713...</td>\n",
       "      <td>1.693391e+06</td>\n",
       "      <td>0.907513</td>\n",
       "      <td>587.010290</td>\n",
       "      <td>1.694654e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>[1713.5601524526573, 1713.5601524526573, 1713....</td>\n",
       "      <td>[1086.9593340531947, 1076.8064054221572, 1115....</td>\n",
       "      <td>1.693391e+06</td>\n",
       "      <td>0.907513</td>\n",
       "      <td>301.416931</td>\n",
       "      <td>1.694654e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>[2284.746869936876, 2284.746869936876, 2284.74...</td>\n",
       "      <td>[515.772616568976, 505.6196879379386, 544.1205...</td>\n",
       "      <td>1.693391e+06</td>\n",
       "      <td>0.907513</td>\n",
       "      <td>872.603649</td>\n",
       "      <td>1.694654e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[571.186717484219, 571.186717484219, 571.18671...</td>\n",
       "      <td>[2232.1320652116947, 2216.966598236908, 2258.7...</td>\n",
       "      <td>-5.550410e+05</td>\n",
       "      <td>1406.224944</td>\n",
       "      <td>1406.923493</td>\n",
       "      <td>8.514634e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[285.5933587421095, 285.5933587421095, 285.593...</td>\n",
       "      <td>[2514.926127689273, 2504.7731991423348, 2543.2...</td>\n",
       "      <td>-5.624402e+05</td>\n",
       "      <td>1410.801862</td>\n",
       "      <td>1411.690689</td>\n",
       "      <td>8.487172e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[571.186717484219, 571.186717484219, 571.18671...</td>\n",
       "      <td>[2229.3770399518585, 2215.2062509976017, 2257....</td>\n",
       "      <td>-1.007574e+06</td>\n",
       "      <td>1689.232531</td>\n",
       "      <td>1689.232532</td>\n",
       "      <td>6.816588e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[285.5933587421095, 285.5933587421095, 285.593...</td>\n",
       "      <td>[2517.7254239538042, 2502.5599569790174, 2544....</td>\n",
       "      <td>-1.011990e+06</td>\n",
       "      <td>1691.818303</td>\n",
       "      <td>1692.516852</td>\n",
       "      <td>6.801074e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[285.5933587421095, 285.5933587421095, 285.593...</td>\n",
       "      <td>[2514.970398693968, 2500.7996097397113, 2543.0...</td>\n",
       "      <td>-1.464523e+06</td>\n",
       "      <td>1974.825890</td>\n",
       "      <td>1974.825890</td>\n",
       "      <td>5.103028e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    R(T)    F                                                 Q0  \\\n",
       "71     9  0.9  [2570.3402286789856, 2570.3402286789856, 2570....   \n",
       "61     8  0.8  [2284.746869936876, 2284.746869936876, 2284.74...   \n",
       "42     6  0.7  [1999.1535111947667, 1999.1535111947667, 1999....   \n",
       "41     6  0.6  [1713.5601524526573, 1713.5601524526573, 1713....   \n",
       "43     6  0.8  [2284.746869936876, 2284.746869936876, 2284.74...   \n",
       "..   ...  ...                                                ...   \n",
       "55     8  0.2  [571.186717484219, 571.186717484219, 571.18671...   \n",
       "45     7  0.1  [285.5933587421095, 285.5933587421095, 285.593...   \n",
       "64     9  0.2  [571.186717484219, 571.186717484219, 571.18671...   \n",
       "54     8  0.1  [285.5933587421095, 285.5933587421095, 285.593...   \n",
       "63     9  0.1  [285.5933587421095, 285.5933587421095, 285.593...   \n",
       "\n",
       "                                                   Q1  average_profits  \\\n",
       "71  [230.22352875709203, 216.05273980283528, 258.2...     1.694693e+06   \n",
       "61  [518.5719127590378, 503.406445784251, 545.1697...     1.693793e+06   \n",
       "42  [801.3659753110853, 791.2130466800479, 829.713...     1.693391e+06   \n",
       "41  [1086.9593340531947, 1076.8064054221572, 1115....     1.693391e+06   \n",
       "43  [515.772616568976, 505.6196879379386, 544.1205...     1.693391e+06   \n",
       "..                                                ...              ...   \n",
       "55  [2232.1320652116947, 2216.966598236908, 2258.7...    -5.550410e+05   \n",
       "45  [2514.926127689273, 2504.7731991423348, 2543.2...    -5.624402e+05   \n",
       "64  [2229.3770399518585, 2215.2062509976017, 2257....    -1.007574e+06   \n",
       "54  [2517.7254239538042, 2502.5599569790174, 2544....    -1.011990e+06   \n",
       "63  [2514.970398693968, 2500.7996097397113, 2543.0...    -1.464523e+06   \n",
       "\n",
       "    average_losses  average_lefts  average_operation_profits  \n",
       "71        0.000000     311.185194               1.695198e+06  \n",
       "61        0.703986     308.737744               1.694776e+06  \n",
       "42        0.907513     587.010290               1.694654e+06  \n",
       "41        0.907513     301.416931               1.694654e+06  \n",
       "43        0.907513     872.603649               1.694654e+06  \n",
       "..             ...            ...                        ...  \n",
       "55     1406.224944    1406.923493               8.514634e+05  \n",
       "45     1410.801862    1411.690689               8.487172e+05  \n",
       "64     1689.232531    1689.232532               6.816588e+05  \n",
       "54     1691.818303    1692.516852               6.801074e+05  \n",
       "63     1974.825890    1974.825890               5.103028e+05  \n",
       "\n",
       "[72 rows x 8 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_1, stimulation_results_df_1 = None, None\n",
    "\n",
    "results_df_1, stimulation_results_df_1 = grid_fixed_F_fixed_R(\n",
    "    assigned_Ts=ASSIGNED_TS,\n",
    "    assigned_Fs=ASSIGNED_FS,\n",
    "    cost=cost,\n",
    "    price=price,\n",
    "    salvage_value=salvage_value,\n",
    "    Qk_hat_df=Qk_hat_df_train,\n",
    "    demand_df_train=demand_df_train,\n",
    "    Q_star=Q_star,\n",
    ")\n",
    "\n",
    "results_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R: 9, F: 0.9\n",
      "R: 8, F: 0.8\n",
      "R: 6, F: 0.7000000000000001\n",
      "R: 6, F: 0.6000000000000001\n",
      "R: 6, F: 0.8\n",
      "R: 7, F: 0.7000000000000001\n",
      "R: 7, F: 0.8\n",
      "R: 8, F: 0.9\n",
      "R: 6, F: 0.9\n",
      "R: 7, F: 0.9\n",
      "R: 3, F: 0.7000000000000001\n",
      "R: 3, F: 0.4\n",
      "R: 3, F: 0.5\n",
      "R: 3, F: 0.6000000000000001\n",
      "R: 3, F: 0.8\n",
      "R: 3, F: 0.30000000000000004\n",
      "R: 5, F: 0.6000000000000001\n",
      "R: 5, F: 0.8\n",
      "R: 5, F: 0.7000000000000001\n",
      "R: 5, F: 0.5\n",
      "R: 4, F: 0.4\n",
      "R: 4, F: 0.5\n",
      "R: 4, F: 0.6000000000000001\n",
      "R: 4, F: 0.7000000000000001\n",
      "R: 4, F: 0.8\n",
      "R: 3, F: 0.9\n",
      "R: 5, F: 0.9\n",
      "R: 4, F: 0.9\n",
      "R: 3, F: 0.2\n",
      "R: 2, F: 0.30000000000000004\n",
      "R: 2, F: 0.4\n",
      "R: 2, F: 0.9\n",
      "R: 2, F: 0.8\n",
      "R: 2, F: 0.7000000000000001\n",
      "R: 2, F: 0.6000000000000001\n",
      "R: 2, F: 0.5\n",
      "R: 2, F: 0.2\n",
      "R: 2, F: 0.1\n",
      "R: 4, F: 0.30000000000000004\n",
      "R: 5, F: 0.4\n",
      "R: 6, F: 0.5\n",
      "R: 7, F: 0.6000000000000001\n",
      "R: 8, F: 0.7000000000000001\n",
      "R: 9, F: 0.8\n",
      "R: 9, F: 0.7000000000000001\n",
      "R: 8, F: 0.6000000000000001\n",
      "R: 7, F: 0.5\n",
      "R: 6, F: 0.4\n",
      "R: 5, F: 0.30000000000000004\n",
      "R: 4, F: 0.2\n",
      "R: 3, F: 0.1\n",
      "R: 9, F: 0.6000000000000001\n",
      "R: 8, F: 0.5\n",
      "R: 7, F: 0.4\n",
      "R: 6, F: 0.30000000000000004\n",
      "R: 5, F: 0.2\n",
      "R: 4, F: 0.1\n",
      "R: 9, F: 0.5\n",
      "R: 8, F: 0.4\n",
      "R: 7, F: 0.30000000000000004\n",
      "R: 6, F: 0.2\n",
      "R: 5, F: 0.1\n",
      "R: 9, F: 0.4\n",
      "R: 8, F: 0.30000000000000004\n",
      "R: 7, F: 0.2\n",
      "R: 6, F: 0.1\n",
      "R: 9, F: 0.30000000000000004\n",
      "R: 8, F: 0.2\n",
      "R: 7, F: 0.1\n",
      "R: 9, F: 0.2\n",
      "R: 8, F: 0.1\n",
      "R: 9, F: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "result = results_df_1.iloc[:, 0:2]\n",
    "for i in range(len(result)):\n",
    "    print(f\"R: {result.iloc[i, 0]}, F: {result.iloc[i, 1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R(T)</th>\n",
       "      <th>F</th>\n",
       "      <th>Q0</th>\n",
       "      <th>Q1</th>\n",
       "      <th>average_profits</th>\n",
       "      <th>average_losses</th>\n",
       "      <th>average_lefts</th>\n",
       "      <th>average_operation_profits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[571.186717484219, 571.186717484219, 571.18671...</td>\n",
       "      <td>[116.35082099292742, 25.77248565647926, 71.381...</td>\n",
       "      <td>383588.648994</td>\n",
       "      <td>3.843170e-07</td>\n",
       "      <td>59.806058</td>\n",
       "      <td>383588.649541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[571.186717484219, 571.186717484219, 571.18671...</td>\n",
       "      <td>[114.93700720959157, 25.831381486595205, 72.22...</td>\n",
       "      <td>383107.206564</td>\n",
       "      <td>2.412024e-01</td>\n",
       "      <td>124.413564</td>\n",
       "      <td>383443.928345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[571.186717484219, 571.186717484219, 571.18671...</td>\n",
       "      <td>[117.1779092164719, 31.29427690402497, 70.7068...</td>\n",
       "      <td>382424.840720</td>\n",
       "      <td>5.677644e-01</td>\n",
       "      <td>189.196196</td>\n",
       "      <td>383247.991105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[571.186717484219, 571.186717484219, 571.18671...</td>\n",
       "      <td>[117.17790923666837, 31.29427695241725, 70.706...</td>\n",
       "      <td>382424.840717</td>\n",
       "      <td>5.677644e-01</td>\n",
       "      <td>253.163074</td>\n",
       "      <td>383247.991104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[571.186717484219, 571.186717484219, 571.18671...</td>\n",
       "      <td>[115.15501626276262, 30.08267380128484, 70.434...</td>\n",
       "      <td>381653.701958</td>\n",
       "      <td>1.002283e+00</td>\n",
       "      <td>318.059693</td>\n",
       "      <td>382987.280229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[2570.3402286789856, 2570.3402286789856, 2570....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>-388821.675186</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4054.112887</td>\n",
       "      <td>383588.649771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[2570.3402286789856, 2570.3402286789856, 2570....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>-388821.675186</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4438.036770</td>\n",
       "      <td>383588.649771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[2570.3402286789856, 2570.3402286789856, 2570....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>-388821.675186</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4118.169290</td>\n",
       "      <td>383588.649771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[2570.3402286789856, 2570.3402286789856, 2570....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>-388821.675186</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3989.985381</td>\n",
       "      <td>383588.649771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[2570.3402286789856, 2570.3402286789856, 2570....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>-388821.675186</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4374.056950</td>\n",
       "      <td>383588.649771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    R(T)    F                                                 Q0  \\\n",
       "64     9  0.2  [571.186717484219, 571.186717484219, 571.18671...   \n",
       "55     8  0.2  [571.186717484219, 571.186717484219, 571.18671...   \n",
       "46     7  0.2  [571.186717484219, 571.186717484219, 571.18671...   \n",
       "37     6  0.2  [571.186717484219, 571.186717484219, 571.18671...   \n",
       "28     5  0.2  [571.186717484219, 571.186717484219, 571.18671...   \n",
       "..   ...  ...                                                ...   \n",
       "62     8  0.9  [2570.3402286789856, 2570.3402286789856, 2570....   \n",
       "8      2  0.9  [2570.3402286789856, 2570.3402286789856, 2570....   \n",
       "53     7  0.9  [2570.3402286789856, 2570.3402286789856, 2570....   \n",
       "71     9  0.9  [2570.3402286789856, 2570.3402286789856, 2570....   \n",
       "17     3  0.9  [2570.3402286789856, 2570.3402286789856, 2570....   \n",
       "\n",
       "                                                   Q1  average_profits  \\\n",
       "64  [116.35082099292742, 25.77248565647926, 71.381...    383588.648994   \n",
       "55  [114.93700720959157, 25.831381486595205, 72.22...    383107.206564   \n",
       "46  [117.1779092164719, 31.29427690402497, 70.7068...    382424.840720   \n",
       "37  [117.17790923666837, 31.29427695241725, 70.706...    382424.840717   \n",
       "28  [115.15501626276262, 30.08267380128484, 70.434...    381653.701958   \n",
       "..                                                ...              ...   \n",
       "62      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   -388821.675186   \n",
       "8       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   -388821.675186   \n",
       "53      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   -388821.675186   \n",
       "71      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   -388821.675186   \n",
       "17      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   -388821.675186   \n",
       "\n",
       "    average_losses  average_lefts  average_operation_profits  \n",
       "64    3.843170e-07      59.806058              383588.649541  \n",
       "55    2.412024e-01     124.413564              383443.928345  \n",
       "46    5.677644e-01     189.196196              383247.991105  \n",
       "37    5.677644e-01     253.163074              383247.991104  \n",
       "28    1.002283e+00     318.059693              382987.280229  \n",
       "..             ...            ...                        ...  \n",
       "62    0.000000e+00    4054.112887              383588.649771  \n",
       "8     0.000000e+00    4438.036770              383588.649771  \n",
       "53    0.000000e+00    4118.169290              383588.649771  \n",
       "71    0.000000e+00    3989.985381              383588.649771  \n",
       "17    0.000000e+00    4374.056950              383588.649771  \n",
       "\n",
       "[72 rows x 8 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_1, stimulation_results_df_1 = None, None\n",
    "\n",
    "results_df_1, stimulation_results_df_1 = grid_fixed_F_fixed_R(\n",
    "    assigned_Ts=ASSIGNED_TS,\n",
    "    assigned_Fs=ASSIGNED_FS,\n",
    "    cost=cost,\n",
    "    price=price,\n",
    "    salvage_value=salvage_value,\n",
    "    Qk_hat_df=Qk_hat_df_test,\n",
    "    demand_df_train=demand_df_test,\n",
    "    Q_star=Q_star,\n",
    ")\n",
    "\n",
    "results_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R: 9, F: 0.2\n",
      "R: 8, F: 0.2\n",
      "R: 7, F: 0.2\n",
      "R: 6, F: 0.2\n",
      "R: 5, F: 0.2\n",
      "R: 5, F: 0.1\n",
      "R: 3, F: 0.1\n",
      "R: 3, F: 0.2\n",
      "R: 4, F: 0.1\n",
      "R: 4, F: 0.2\n",
      "R: 2, F: 0.1\n",
      "R: 2, F: 0.2\n",
      "R: 6, F: 0.1\n",
      "R: 4, F: 0.30000000000000004\n",
      "R: 7, F: 0.30000000000000004\n",
      "R: 9, F: 0.30000000000000004\n",
      "R: 6, F: 0.30000000000000004\n",
      "R: 8, F: 0.30000000000000004\n",
      "R: 3, F: 0.30000000000000004\n",
      "R: 5, F: 0.30000000000000004\n",
      "R: 2, F: 0.30000000000000004\n",
      "R: 7, F: 0.1\n",
      "R: 6, F: 0.4\n",
      "R: 7, F: 0.4\n",
      "R: 5, F: 0.4\n",
      "R: 9, F: 0.4\n",
      "R: 4, F: 0.4\n",
      "R: 3, F: 0.4\n",
      "R: 8, F: 0.4\n",
      "R: 2, F: 0.4\n",
      "R: 8, F: 0.1\n",
      "R: 6, F: 0.5\n",
      "R: 7, F: 0.5\n",
      "R: 3, F: 0.5\n",
      "R: 5, F: 0.5\n",
      "R: 4, F: 0.5\n",
      "R: 9, F: 0.5\n",
      "R: 8, F: 0.5\n",
      "R: 2, F: 0.5\n",
      "R: 9, F: 0.1\n",
      "R: 7, F: 0.6000000000000001\n",
      "R: 9, F: 0.6000000000000001\n",
      "R: 6, F: 0.6000000000000001\n",
      "R: 8, F: 0.6000000000000001\n",
      "R: 5, F: 0.6000000000000001\n",
      "R: 4, F: 0.6000000000000001\n",
      "R: 2, F: 0.6000000000000001\n",
      "R: 3, F: 0.6000000000000001\n",
      "R: 6, F: 0.7000000000000001\n",
      "R: 5, F: 0.7000000000000001\n",
      "R: 2, F: 0.7000000000000001\n",
      "R: 3, F: 0.7000000000000001\n",
      "R: 9, F: 0.7000000000000001\n",
      "R: 8, F: 0.7000000000000001\n",
      "R: 7, F: 0.7000000000000001\n",
      "R: 4, F: 0.7000000000000001\n",
      "R: 2, F: 0.8\n",
      "R: 7, F: 0.8\n",
      "R: 8, F: 0.8\n",
      "R: 9, F: 0.8\n",
      "R: 5, F: 0.8\n",
      "R: 3, F: 0.8\n",
      "R: 6, F: 0.8\n",
      "R: 4, F: 0.8\n",
      "R: 5, F: 0.9\n",
      "R: 4, F: 0.9\n",
      "R: 6, F: 0.9\n",
      "R: 8, F: 0.9\n",
      "R: 2, F: 0.9\n",
      "R: 7, F: 0.9\n",
      "R: 9, F: 0.9\n",
      "R: 3, F: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "result = results_df_1.iloc[:, 0:2]\n",
    "for i in range(len(result)):\n",
    "    print(f\"R: {result.iloc[i, 0]}, F: {result.iloc[i, 1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.626271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>279.543638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.506622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>278.716262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.780418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282.660041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.219951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282.605164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.119275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>271.570922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X1   X2          X3\n",
       "0  18.626271  0.0  279.543638\n",
       "1  17.506622  0.0  278.716262\n",
       "2  19.780418  0.0  282.660041\n",
       "3  18.219951  0.0  282.605164\n",
       "4  17.119275  0.0  271.570922"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>283.936601</td>\n",
       "      <td>279.543638</td>\n",
       "      <td>285.077369</td>\n",
       "      <td>279.543638</td>\n",
       "      <td>276.931626</td>\n",
       "      <td>279.543638</td>\n",
       "      <td>279.497137</td>\n",
       "      <td>277.402834</td>\n",
       "      <td>279.543638</td>\n",
       "      <td>279.543638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>280.752154</td>\n",
       "      <td>278.716263</td>\n",
       "      <td>284.554707</td>\n",
       "      <td>278.716262</td>\n",
       "      <td>277.019908</td>\n",
       "      <td>278.716262</td>\n",
       "      <td>272.022711</td>\n",
       "      <td>278.462176</td>\n",
       "      <td>278.716262</td>\n",
       "      <td>278.716262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>280.810270</td>\n",
       "      <td>282.660041</td>\n",
       "      <td>281.793406</td>\n",
       "      <td>282.660041</td>\n",
       "      <td>283.966752</td>\n",
       "      <td>282.660041</td>\n",
       "      <td>284.073037</td>\n",
       "      <td>284.669504</td>\n",
       "      <td>282.660041</td>\n",
       "      <td>282.660041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>282.690695</td>\n",
       "      <td>282.605164</td>\n",
       "      <td>284.501807</td>\n",
       "      <td>282.605163</td>\n",
       "      <td>280.263205</td>\n",
       "      <td>282.605164</td>\n",
       "      <td>280.973891</td>\n",
       "      <td>281.791857</td>\n",
       "      <td>282.605164</td>\n",
       "      <td>282.605164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>269.794746</td>\n",
       "      <td>271.570922</td>\n",
       "      <td>270.571046</td>\n",
       "      <td>271.570922</td>\n",
       "      <td>268.258034</td>\n",
       "      <td>271.570922</td>\n",
       "      <td>273.396903</td>\n",
       "      <td>267.461509</td>\n",
       "      <td>271.570922</td>\n",
       "      <td>271.570922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    demand_t1   demand_t2   demand_t3   demand_t4   demand_t5   demand_t6  \\\n",
       "0  283.936601  279.543638  285.077369  279.543638  276.931626  279.543638   \n",
       "1  280.752154  278.716263  284.554707  278.716262  277.019908  278.716262   \n",
       "2  280.810270  282.660041  281.793406  282.660041  283.966752  282.660041   \n",
       "3  282.690695  282.605164  284.501807  282.605163  280.263205  282.605164   \n",
       "4  269.794746  271.570922  270.571046  271.570922  268.258034  271.570922   \n",
       "\n",
       "    demand_t7   demand_t8   demand_t9  demand_t10  \n",
       "0  279.497137  277.402834  279.543638  279.543638  \n",
       "1  272.022711  278.462176  278.716262  278.716262  \n",
       "2  284.073037  284.669504  282.660041  282.660041  \n",
       "3  280.973891  281.791857  282.605164  282.605164  \n",
       "4  273.396903  267.461509  271.570922  271.570922  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.625929</td>\n",
       "      <td>67.884966</td>\n",
       "      <td>68.750730</td>\n",
       "      <td>68.558033</td>\n",
       "      <td>74.175914</td>\n",
       "      <td>68.558033</td>\n",
       "      <td>65.559446</td>\n",
       "      <td>71.308420</td>\n",
       "      <td>68.558033</td>\n",
       "      <td>68.558033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60.770111</td>\n",
       "      <td>61.058111</td>\n",
       "      <td>59.574148</td>\n",
       "      <td>60.117141</td>\n",
       "      <td>58.717761</td>\n",
       "      <td>60.117141</td>\n",
       "      <td>57.979551</td>\n",
       "      <td>58.390955</td>\n",
       "      <td>60.117144</td>\n",
       "      <td>60.117141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.073532</td>\n",
       "      <td>64.930685</td>\n",
       "      <td>65.683239</td>\n",
       "      <td>63.599781</td>\n",
       "      <td>63.459309</td>\n",
       "      <td>63.599781</td>\n",
       "      <td>64.215938</td>\n",
       "      <td>63.806809</td>\n",
       "      <td>63.599781</td>\n",
       "      <td>63.599781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63.121389</td>\n",
       "      <td>66.381203</td>\n",
       "      <td>61.668540</td>\n",
       "      <td>67.299906</td>\n",
       "      <td>67.404706</td>\n",
       "      <td>67.299906</td>\n",
       "      <td>70.525694</td>\n",
       "      <td>68.097560</td>\n",
       "      <td>67.299908</td>\n",
       "      <td>67.299906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64.915095</td>\n",
       "      <td>62.604395</td>\n",
       "      <td>65.471782</td>\n",
       "      <td>61.716297</td>\n",
       "      <td>63.127936</td>\n",
       "      <td>61.716297</td>\n",
       "      <td>61.250627</td>\n",
       "      <td>60.709187</td>\n",
       "      <td>61.716291</td>\n",
       "      <td>61.716297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   demand_t1  demand_t2  demand_t3  demand_t4  demand_t5  demand_t6  \\\n",
       "0  65.625929  67.884966  68.750730  68.558033  74.175914  68.558033   \n",
       "1  60.770111  61.058111  59.574148  60.117141  58.717761  60.117141   \n",
       "2  66.073532  64.930685  65.683239  63.599781  63.459309  63.599781   \n",
       "3  63.121389  66.381203  61.668540  67.299906  67.404706  67.299906   \n",
       "4  64.915095  62.604395  65.471782  61.716297  63.127936  61.716297   \n",
       "\n",
       "   demand_t7  demand_t8  demand_t9  demand_t10  \n",
       "0  65.559446  71.308420  68.558033   68.558033  \n",
       "1  57.979551  58.390955  60.117144   60.117141  \n",
       "2  64.215938  63.806809  63.599781   63.599781  \n",
       "3  70.525694  68.097560  67.299908   67.299906  \n",
       "4  61.250627  60.709187  61.716291   61.716297  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Qk_hat_k2</th>\n",
       "      <th>Qk_hat_k3</th>\n",
       "      <th>Qk_hat_k4</th>\n",
       "      <th>Qk_hat_k5</th>\n",
       "      <th>Qk_hat_k6</th>\n",
       "      <th>Qk_hat_k7</th>\n",
       "      <th>Qk_hat_k8</th>\n",
       "      <th>Qk_hat_k9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2837.543896</td>\n",
       "      <td>2801.895784</td>\n",
       "      <td>2802.253236</td>\n",
       "      <td>2802.253235</td>\n",
       "      <td>2800.519487</td>\n",
       "      <td>2800.519486</td>\n",
       "      <td>2803.318783</td>\n",
       "      <td>2800.563757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2804.051807</td>\n",
       "      <td>2790.572652</td>\n",
       "      <td>2791.214331</td>\n",
       "      <td>2791.214331</td>\n",
       "      <td>2790.366558</td>\n",
       "      <td>2790.366558</td>\n",
       "      <td>2788.153316</td>\n",
       "      <td>2786.392968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804.663037</td>\n",
       "      <td>2825.118813</td>\n",
       "      <td>2824.755383</td>\n",
       "      <td>2824.755383</td>\n",
       "      <td>2828.867469</td>\n",
       "      <td>2828.867469</td>\n",
       "      <td>2829.916572</td>\n",
       "      <td>2828.613175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2824.440209</td>\n",
       "      <td>2827.055047</td>\n",
       "      <td>2827.060461</td>\n",
       "      <td>2827.060461</td>\n",
       "      <td>2824.661479</td>\n",
       "      <td>2824.661479</td>\n",
       "      <td>2824.167915</td>\n",
       "      <td>2823.247273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2688.808448</td>\n",
       "      <td>2714.039483</td>\n",
       "      <td>2713.747047</td>\n",
       "      <td>2713.747047</td>\n",
       "      <td>2709.556771</td>\n",
       "      <td>2709.556771</td>\n",
       "      <td>2710.287920</td>\n",
       "      <td>2707.336847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Qk_hat_k2    Qk_hat_k3    Qk_hat_k4    Qk_hat_k5    Qk_hat_k6  \\\n",
       "0  2837.543896  2801.895784  2802.253236  2802.253235  2800.519487   \n",
       "1  2804.051807  2790.572652  2791.214331  2791.214331  2790.366558   \n",
       "2  2804.663037  2825.118813  2824.755383  2824.755383  2828.867469   \n",
       "3  2824.440209  2827.055047  2827.060461  2827.060461  2824.661479   \n",
       "4  2688.808448  2714.039483  2713.747047  2713.747047  2709.556771   \n",
       "\n",
       "     Qk_hat_k7    Qk_hat_k8    Qk_hat_k9  \n",
       "0  2800.519486  2803.318783  2800.563757  \n",
       "1  2790.366558  2788.153316  2786.392968  \n",
       "2  2828.867469  2829.916572  2828.613175  \n",
       "3  2824.661479  2824.167915  2823.247273  \n",
       "4  2709.556771  2710.287920  2707.336847  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qk_hat_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Qk_hat_k2</th>\n",
       "      <th>Qk_hat_k3</th>\n",
       "      <th>Qk_hat_k4</th>\n",
       "      <th>Qk_hat_k5</th>\n",
       "      <th>Qk_hat_k6</th>\n",
       "      <th>Qk_hat_k7</th>\n",
       "      <th>Qk_hat_k8</th>\n",
       "      <th>Qk_hat_k9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>667.825323</td>\n",
       "      <td>679.441327</td>\n",
       "      <td>674.336130</td>\n",
       "      <td>686.341734</td>\n",
       "      <td>688.364627</td>\n",
       "      <td>688.364627</td>\n",
       "      <td>686.123725</td>\n",
       "      <td>687.537538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>619.725973</td>\n",
       "      <td>615.200743</td>\n",
       "      <td>617.411438</td>\n",
       "      <td>601.269391</td>\n",
       "      <td>602.480994</td>\n",
       "      <td>602.480994</td>\n",
       "      <td>597.018099</td>\n",
       "      <td>596.959203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>672.259056</td>\n",
       "      <td>647.406803</td>\n",
       "      <td>648.811197</td>\n",
       "      <td>641.621708</td>\n",
       "      <td>641.893589</td>\n",
       "      <td>641.893589</td>\n",
       "      <td>643.407440</td>\n",
       "      <td>642.568633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>643.016582</td>\n",
       "      <td>667.674964</td>\n",
       "      <td>672.068531</td>\n",
       "      <td>670.587870</td>\n",
       "      <td>667.499784</td>\n",
       "      <td>667.499784</td>\n",
       "      <td>667.856550</td>\n",
       "      <td>666.398720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>660.784144</td>\n",
       "      <td>624.692052</td>\n",
       "      <td>623.360680</td>\n",
       "      <td>621.516161</td>\n",
       "      <td>624.134902</td>\n",
       "      <td>624.134902</td>\n",
       "      <td>625.562706</td>\n",
       "      <td>624.944206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Qk_hat_k2   Qk_hat_k3   Qk_hat_k4   Qk_hat_k5   Qk_hat_k6   Qk_hat_k7  \\\n",
       "0  667.825323  679.441327  674.336130  686.341734  688.364627  688.364627   \n",
       "1  619.725973  615.200743  617.411438  601.269391  602.480994  602.480994   \n",
       "2  672.259056  647.406803  648.811197  641.621708  641.893589  641.893589   \n",
       "3  643.016582  667.674964  672.068531  670.587870  667.499784  667.499784   \n",
       "4  660.784144  624.692052  623.360680  621.516161  624.134902  624.134902   \n",
       "\n",
       "    Qk_hat_k8   Qk_hat_k9  \n",
       "0  686.123725  687.537538  \n",
       "1  597.018099  596.959203  \n",
       "2  643.407440  642.568633  \n",
       "3  667.856550  666.398720  \n",
       "4  625.562706  624.944206  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qk_hat_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++++++++++++++++++++++ THis is R=0 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0x7c7e00e0\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [3e+02, 3e+03]\n",
      "Presolve removed 62 rows and 97 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 231 rows, 167 columns, 612 nonzeros\n",
      "Presolved model has 41 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 126 continuous, 41 integer (41 binary)\n",
      "\n",
      "Root relaxation: objective 2.533262e+07, 85 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5333e+07    0   21          - 2.5333e+07      -     -    0s\n",
      "H    0     0                    2.524373e+07 2.5333e+07  0.35%     -    0s\n",
      "\n",
      "Explored 1 nodes (85 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.52437e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.524373243406e+07, best bound 2.533261583285e+07, gap 0.3521%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1144.0301924086202, Left1: 36.98013902744424\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1147.2146401786881, Left1: 17.658839232383343\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 23.95013703959512, Left0: 1147.1565240677305, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1145.2760988103475, Left1: 1.1929361545380743\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 18.528398860166362, Left0: 1158.1720475343188, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 27.037615877432472, Left0: 1135.8255066678205, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 10.330585983076162, Left0: 1159.671523872997, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1153.6823448104933, Left1: 5.711934684320568\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1132.405117791089, Left1: 18.63196479163662\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1136.3940269564055, Left1: 9.624653434906463\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1138.6077483185654, Left1: 35.72398762633202\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1168.8809024505395, Left1: 24.802197373810486\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 9.196225102519747, Left0: 1133.2631837868332, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1139.7578512715843, Left1: 24.290380924166584\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 6.286913241360708, Left0: 1129.9952670164112, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=1 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0x3d42e3d0\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [5e+02, 2e+03]\n",
      "Presolve removed 55 rows and 83 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 238 rows, 181 columns, 635 nonzeros\n",
      "Presolved model has 47 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 134 continuous, 47 integer (47 binary)\n",
      "\n",
      "Root relaxation: objective 2.540762e+07, 89 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5408e+07    0   25          - 2.5408e+07      -     -    0s\n",
      "H    0     0                    2.538804e+07 2.5408e+07  0.08%     -    0s\n",
      "\n",
      "Explored 1 nodes (89 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.5388e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.538804436055e+07, best bound 2.540761695120e+07, gap 0.0771%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 864.4865541859278, Left1: 1.3320266561004246\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 868.4983776614915, Left1: 4.179683795642177\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.494361096698867, Left0: 864.4964830017955, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 862.6709352896246, Left1: 3.807774725669333\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 886.6011257255556, Left1: 6.702636206273837\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.845951177695952, Left0: 840.99817687566, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 891.2934302117237, Left1: 0.8369143515910764\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 8.565508626538758, Left0: 881.8890984342389, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 837.8089499887839, Left1: 7.223925849980674\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 2.422123780279776, Left0: 846.0843275265487, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.5955094169944459, Left0: 853.4133191802168, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 913.8695579373602, Left1: 4.161348693608943\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.6376606011212971, Left0: 837.2890530897555, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 854.0457861906891, Left1: 3.1138721000688747\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 830.0529166697116, Left1: 6.785318866206467\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=2 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0x9b436c22\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [8e+02, 2e+03]\n",
      "Presolve removed 55 rows and 83 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 238 rows, 181 columns, 635 nonzeros\n",
      "Presolved model has 47 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 134 continuous, 47 integer (47 binary)\n",
      "\n",
      "Root relaxation: objective 2.540750e+07, 88 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5407e+07    0   25          - 2.5407e+07      -     -    0s\n",
      "H    0     0                    2.538780e+07 2.5407e+07  0.08%     -    0s\n",
      "\n",
      "Explored 1 nodes (88 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.53878e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.538779517723e+07, best bound 2.540749947467e+07, gap 0.0776%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 579.4091854544656, Left1: 1.68947841768113\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 583.9436705857113, Left1: 4.8213623977098905\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.8577910975725445, Left0: 582.7030768508378, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 578.1691287192477, Left1: 3.813188306363827\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 616.030079611496, Left1: 6.410200259288558\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.772083398577934, Left0: 544.6343068433034, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 619.0042413332005, Left1: 1.3892546520169162\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 8.244358266108293, Left0: 605.9973084332223, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 542.4627819542546, Left1: 6.809544179941099\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.163746740711872, Left0: 556.746526959222, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.26522495544145386, Left0: 562.6602909033318, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 658.8280233034043, Left1: 3.6910013991214328\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.43514190700898325, Left0: 538.4152603818297, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 568.7419324855722, Left1: 2.413551467104867\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 526.2879501025548, Left1: 7.197183447751286\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=3 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0xc60b9deb\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 2e+03]\n",
      "Presolve removed 52 rows and 65 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 241 rows, 199 columns, 647 nonzeros\n",
      "Presolved model has 62 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 137 continuous, 62 integer (62 binary)\n",
      "\n",
      "Root relaxation: objective 2.540750e+07, 97 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5407e+07    0   27          - 2.5407e+07      -     -    0s\n",
      "H    0     0                    2.538780e+07 2.5407e+07  0.08%     -    0s\n",
      "\n",
      "Explored 1 nodes (97 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.53878e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.538779517814e+07, best bound 2.540749947535e+07, gap 0.0776%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 299.86554739244843, Left1: 1.6894780642987826\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 305.227408142747, Left1: 4.821362451086316\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.8577912144401125, Left0: 300.0430358585686, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 295.5639652290297, Left1: 3.8131884187764626\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 344.45915784976887, Left1: 6.410200437845106\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.7720833550229145, Left0: 249.8069770529553, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 350.6261478289755, Left1: 1.3892544946247654\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 8.24435831686128, Left0: 334.2040621734052, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 247.86661418351878, Left1: 6.8095440614731615\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.1637465616656755, Left0: 266.4368275001914, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.26522452100493865, Left0: 277.46586172172465, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 403.81667892813675, Left1: 3.691001444572521\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.43514184545324497, Left0: 242.44112968216905, Left1: 0.0\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 283.02986749600404, Left1: 2.413551206114107\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 226.34559978329753, Left1: 7.197183336380476\n",
      "f_vars[i]: 0.0000, F_vars[i]: 0.5000, Q0_vars[i]: 1427.9668\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=4 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0xa5ed6f9b\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 1e+03]\n",
      "Presolve removed 56 rows and 73 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 237 rows, 191 columns, 639 nonzeros\n",
      "Presolved model has 58 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 133 continuous, 58 integer (58 binary)\n",
      "\n",
      "Root relaxation: objective 2.541313e+07, 91 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5413e+07    0   25          - 2.5413e+07      -     -    0s\n",
      "H    0     0                    2.501788e+07 2.5413e+07  1.58%     -    0s\n",
      "     0     2 2.5413e+07    0   27 2.5018e+07 2.5413e+07  1.58%     -    0s\n",
      "H   36    22                    2.540086e+07 2.5409e+07  0.03%  10.6    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Cover: 1\n",
      "  Implied bound: 9\n",
      "\n",
      "Explored 47 nodes (519 simplex iterations) in 0.03 seconds (0.03 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 2.54009e+07 2.50179e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.540086165798e+07, best bound 2.540907229301e+07, gap 0.0323%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0442706266182995, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -0.0321, F_vars[i]: 0.4920, Q0_vars[i]: 1405.0329\n",
      "f_train: -0.032123847918444026, F_train: 0.49196972857277776, Q0_train: 1405.0328718254357\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.081484115484246, Left1: 3.9735896354927718\n",
      "f_vars[i]: -0.0268, F_vars[i]: 0.4933, Q0_vars[i]: 1408.8408\n",
      "f_train: -0.026789362055680055, F_train: 0.49330305999732205, Q0_train: 1408.8407778239557\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 0.2542948950626851\n",
      "f_vars[i]: -0.0225, F_vars[i]: 0.4944, Q0_vars[i]: 1411.8905\n",
      "f_train: -0.02251727824615979, F_train: 0.4943709182782028, Q0_train: 1411.8905101549287\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.764879186039707, Left1: 1.4142064545967514\n",
      "f_vars[i]: -0.0078, F_vars[i]: 0.4981, Q0_vars[i]: 1422.4309\n",
      "f_train: -0.007753553922643652, F_train: 0.4980616212302191, Q0_train: 1422.4309126767862\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 25.73120573232177, Left1: 2.2199238035420876\n",
      "f_vars[i]: -0.0707, F_vars[i]: 0.4823, Q0_vars[i]: 1377.4969\n",
      "f_train: -0.07071726002291134, F_train: 0.48232804906424753, Q0_train: 1377.4968754778745\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 6.14495849748483, Left1: 1.208751934558677\n",
      "f_vars[i]: 0.0756, F_vars[i]: 0.5189, Q0_vars[i]: 1481.9412\n",
      "f_train: 0.07563218315967224, F_train: 0.5188990377496455, Q0_train: 1481.9411903896994\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 31.890054445462813, Left1: 1.0641162352530955\n",
      "f_vars[i]: -0.0724, F_vars[i]: 0.4819, Q0_vars[i]: 1376.2922\n",
      "f_train: -0.07240663864936203, F_train: 0.4819062446900743, Q0_train: 1376.292230198352\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 6.797781953293452, Left0: 18.0125701842548, Left1: 0.0\n",
      "f_vars[i]: -0.0633, F_vars[i]: 0.4842, Q0_vars[i]: 1382.7827\n",
      "f_train: -0.06330559620413179, F_train: 0.48417888431938677, Q0_train: 1382.7827380478097\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.980679405658884, Left1: 7.57986390964993\n",
      "f_vars[i]: 0.0715, F_vars[i]: 0.5179, Q0_vars[i]: 1478.9823\n",
      "f_train: 0.07148234237746265, F_train: 0.5178629799986897, Q0_train: 1478.9822782602366\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 5.026929325021456, Left0: 21.867347607356802, Left1: 0.0\n",
      "f_vars[i]: 0.0608, F_vars[i]: 0.5152, Q0_vars[i]: 1471.3772\n",
      "f_train: 0.0608189783600086, F_train: 0.5152000595261795, Q0_train: 1471.3771542421637\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 2.601641160733152\n",
      "f_vars[i]: 0.0108, F_vars[i]: 0.5027, Q0_vars[i]: 1435.6669\n",
      "f_train: 0.010784810222653318, F_train: 0.5026961764225452, Q0_train: 1435.6668945133072\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 21.85560591878084, Left1: 3.9287458972503373\n",
      "f_vars[i]: -0.1815, F_vars[i]: 0.4548, Q0_vars[i]: 1298.7591\n",
      "f_train: -0.18146370864474792, F_train: 0.4547581524499312, Q0_train: 1298.7590817353212\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.7437060145430223, Left0: 23.385195898975805, Left1: 0.0\n",
      "f_vars[i]: 0.1061, F_vars[i]: 0.5265, Q0_vars[i]: 1503.6600\n",
      "f_train: 0.10611484966197593, F_train: 0.5265038468407276, Q0_train: 1503.660020098846\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 21.09474529472054, Left1: 0.6543544472428948\n",
      "f_vars[i]: 0.0297, F_vars[i]: 0.5074, Q0_vars[i]: 1449.1987\n",
      "f_train: 0.02973949199711834, F_train: 0.5074343250744378, Q0_train: 1449.1987323904411\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 8.966909915220242, Left1: 2.0456162854748072\n",
      "f_vars[i]: 0.1115, F_vars[i]: 0.5279, Q0_vars[i]: 1507.5168\n",
      "f_train: 0.11153262776633999, F_train: 0.5278542884117062, Q0_train: 1507.5167915392535\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=5 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0x29cda3b0\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 2e+03]\n",
      "Presolve removed 56 rows and 73 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 237 rows, 191 columns, 639 nonzeros\n",
      "Presolved model has 58 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 133 continuous, 58 integer (58 binary)\n",
      "\n",
      "Root relaxation: objective 2.541313e+07, 91 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5413e+07    0   25          - 2.5413e+07      -     -    0s\n",
      "H    0     0                    1.898036e+07 2.5413e+07  33.9%     -    0s\n",
      "     0     2 2.5413e+07    0   23 1.8980e+07 2.5413e+07  33.9%     -    0s\n",
      "H   11     8                    2.540086e+07 2.5410e+07  0.04%   3.9    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 7\n",
      "\n",
      "Explored 15 nodes (154 simplex iterations) in 0.02 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 2.54009e+07 1.89804e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.540086165029e+07, best bound 2.540907229446e+07, gap 0.0323%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.04427070108886255, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 0.3634, F_vars[i]: 0.5899, Q0_vars[i]: 1684.5765\n",
      "f_train: 0.363351188895233, F_train: 0.5898514196403374, Q0_train: 1684.5764809388545\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.126535630824947, Left1: 3.973589645122729\n",
      "f_vars[i]: 0.3677, F_vars[i]: 0.5909, Q0_vars[i]: 1687.6021\n",
      "f_train: 0.3677319411655908, F_train: 0.5909108219858813, Q0_train: 1687.602063680086\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 0.25429486149232616\n",
      "f_vars[i]: 0.3778, F_vars[i]: 0.5933, Q0_vars[i]: 1694.5505\n",
      "f_train: 0.37780593320713596, F_train: 0.5933438118998666, Q0_train: 1694.5505212932935\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.81405485966502, Left1: 1.414206508322195\n",
      "f_vars[i]: 0.3931, F_vars[i]: 0.5970, Q0_vars[i]: 1705.0852\n",
      "f_train: 0.3931157152912994, F_train: 0.5970325187783241, Q0_train: 1705.0852231616313\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 25.437526863424935, Left1: 2.2199238678498006\n",
      "f_vars[i]: 0.3118, F_vars[i]: 0.5773, Q0_vars[i]: 1648.7741\n",
      "f_train: 0.311761959967491, F_train: 0.5773152772085405, Q0_train: 1648.774090711191\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.365821076855861, Left1: 1.2087519381427683\n",
      "f_vars[i]: 0.4974, F_vars[i]: 0.6219, Q0_vars[i]: 1775.9894\n",
      "f_train: 0.4974482463139913, F_train: 0.6218594724910351, Q0_train: 1775.9893541431118\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 31.593009645905795, Left1: 1.0641161758576345\n",
      "f_vars[i]: 0.3055, F_vars[i]: 0.5758, Q0_vars[i]: 1644.3733\n",
      "f_train: 0.30545024867741066, F_train: 0.5757743317472364, Q0_train: 1644.3732528118685\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 6.797781960631028, Left0: 17.811721518430204, Left1: 0.0\n",
      "f_vars[i]: 0.3198, F_vars[i]: 0.5793, Q0_vars[i]: 1654.3751\n",
      "f_train: 0.31980391286927423, F_train: 0.5792764634691976, Q0_train: 1654.3751084241903\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.263806064464848, Left1: 7.579863854253517\n",
      "f_vars[i]: 0.4928, F_vars[i]: 0.6208, Q0_vars[i]: 1772.8615\n",
      "f_train: 0.49279344455638396, F_train: 0.620764275352724, Q0_train: 1772.8615438509617\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 5.026929269582297, Left0: 21.437976405605806, Left1: 0.0\n",
      "f_vars[i]: 0.4756, F_vars[i]: 0.6167, Q0_vars[i]: 1761.2575\n",
      "f_train: 0.4755694670540622, F_train: 0.6167011245690621, Q0_train: 1761.2574550571453\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 2.6016412696092175\n",
      "f_vars[i]: 0.4161, F_vars[i]: 0.6026, Q0_vars[i]: 1720.8613\n",
      "f_train: 0.4161285758318165, F_train: 0.6025564819327652, Q0_train: 1720.8612950700765\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 19.072250252164167, Left1: 3.928745897847307\n",
      "f_vars[i]: 0.1727, F_vars[i]: 0.5431, Q0_vars[i]: 1550.9870\n",
      "f_train: 0.1727294527929859, F_train: 0.5430753187392917, Q0_train: 1550.98704328696\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.7437060246500096, Left0: 22.08212219576034, Left1: 0.0\n",
      "f_vars[i]: 0.5309, F_vars[i]: 0.6297, Q0_vars[i]: 1798.3311\n",
      "f_train: 0.5308544513260709, F_train: 0.6296823771154634, Q0_train: 1798.3310502112083\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 21.032144819721783, Left1: 0.654354382480733\n",
      "f_vars[i]: 0.4366, F_vars[i]: 0.6075, Q0_vars[i]: 1734.8482\n",
      "f_train: 0.4366225599781739, F_train: 0.607453960798842, Q0_train: 1734.84816945739\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.355003091592702, Left1: 2.045616279306614\n",
      "f_vars[i]: 0.5422, F_vars[i]: 0.6323, Q0_vars[i]: 1805.8472\n",
      "f_train: 0.5421574199379702, F_train: 0.6323141457254511, Q0_train: 1805.8472065787926\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=6 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0x61b0fa0c\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [8e+02, 2e+03]\n",
      "Presolve removed 53 rows and 91 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 240 rows, 173 columns, 650 nonzeros\n",
      "Presolved model has 37 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 136 continuous, 37 integer (37 binary)\n",
      "\n",
      "Root relaxation: objective 2.541692e+07, 87 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5417e+07    0   21          - 2.5417e+07      -     -    0s\n",
      "H    0     0                    1.223711e+07 2.5416e+07   108%     -    0s\n",
      "     0     2 2.5416e+07    0   21 1.2237e+07 2.5416e+07   108%     -    0s\n",
      "H   63    74                    2.527288e+07 2.5414e+07  0.56%   4.3    0s\n",
      "\n",
      "Explored 87 nodes (445 simplex iterations) in 0.03 seconds (0.03 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 2.52729e+07 1.22371e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.527288392557e+07, best bound 2.541428588554e+07, gap 0.5595%\n",
      "Model status: 2\n",
      "Lost0: 8.78183542565577, Lost1: 0.0, Left0: 0.0, Left1: 11.536860989102479\n",
      "f_vars[i]: 0.7752, F_vars[i]: 0.6846, Q0_vars[i]: 1955.2907\n",
      "f_train: 0.7751852996363833, F_train: 0.6846415092758438, Q0_train: 1955.2906816835534\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.8845924019144604, Lost1: 0.0, Left0: 0.0, Left1: 4.644939883719871\n",
      "f_vars[i]: 0.7628, F_vars[i]: 0.6820, Q0_vars[i]: 1947.6109\n",
      "f_train: 0.7627590178826651, F_train: 0.6819524464822724, Q0_train: 1947.6108969327086\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 1.303397792219016\n",
      "f_vars[i]: 0.8133, F_vars[i]: 0.6928, Q0_vars[i]: 1978.6236\n",
      "f_train: 0.813296317509729, F_train: 0.6928114844147251, Q0_train: 1978.62358809108\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.6891160780118687, Lost1: 0.0, Left0: 0.0, Left1: 1.6097578430203612\n",
      "f_vars[i]: 0.8083, F_vars[i]: 0.6917, Q0_vars[i]: 1975.5558\n",
      "f_train: 0.8082538933002419, F_train: 0.6917372947875802, Q0_train: 1975.5557738556574\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 2.9510728650883493\n",
      "f_vars[i]: 0.6818, F_vars[i]: 0.6641, Q0_vars[i]: 1896.7335\n",
      "f_train: 0.6817887720292481, F_train: 0.6641378157830808, Q0_train: 1896.7334947713846\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 5.146342113285126, Lost1: 0.0, Left0: 0.0, Left1: 4.862354013043213\n",
      "f_vars[i]: 0.9443, F_vars[i]: 0.7200, Q0_vars[i]: 2056.2022\n",
      "f_train: 0.9443401292512692, F_train: 0.7199755090602376, Q0_train: 2056.202238445733\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 6.810647606232111, Lost1: 0.0, Left0: 0.0, Left1: 7.191006168422973\n",
      "f_vars[i]: 0.6404, F_vars[i]: 0.6548, Q0_vars[i]: 1870.1626\n",
      "f_train: 0.6403565655308845, F_train: 0.654834058283584, Q0_train: 1870.1625812393504\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 10.61396159246895, Lost1: 0.0, Left0: 0.0, Left1: 5.846958419859675\n",
      "f_vars[i]: 0.6825, F_vars[i]: 0.6643, Q0_vars[i]: 1897.2111\n",
      "f_train: 0.6825386110466161, F_train: 0.6643050533666385, Q0_train: 1897.211114203346\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 7.396487331963272, Lost1: 0.0, Left0: 0.0, Left1: 14.118112711865733\n",
      "f_vars[i]: 0.9425, F_vars[i]: 0.7196, Q0_vars[i]: 2055.1535\n",
      "f_train: 0.9425194032043285, F_train: 0.7196082840923861, Q0_train: 2055.153468325907\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 11.876938585234939, Lost1: 0.0, Left0: 0.0, Left1: 10.309527911012866\n",
      "f_vars[i]: 0.8894, F_vars[i]: 0.7088, Q0_vars[i]: 2024.1619\n",
      "f_train: 0.889352986021664, F_train: 0.7087566335501074, Q0_train: 2024.1618750632567\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 8.958240683067713, Lost1: 0.0, Left0: 0.0, Left1: 10.777832411609749\n",
      "f_vars[i]: 0.8368, F_vars[i]: 0.6978, Q0_vars[i]: 1992.8612\n",
      "f_train: 0.8368281769654811, F_train: 0.6977967731893838, Q0_train: 1992.861241745621\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 11.623493588401653, Lost1: 0.0, Left0: 0.0, Left1: 13.717002711491432\n",
      "f_vars[i]: 0.4968, F_vars[i]: 0.6217, Q0_vars[i]: 1775.5237\n",
      "f_train: 0.4967549911813749, F_train: 0.621696439593698, Q0_train: 1775.5237430157522\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 11.935993664469091, Lost1: 0.0, Left0: 0.0, Left1: 12.268455059634956\n",
      "f_vars[i]: 0.9505, F_vars[i]: 0.7212, Q0_vars[i]: 2059.7305\n",
      "f_train: 0.9504761680072242, F_train: 0.7212109291723702, Q0_train: 2059.7305162385487\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 3.651982704205693, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: 0.8381, F_vars[i]: 0.6981, Q0_vars[i]: 1993.6131\n",
      "f_train: 0.8380769089811597, F_train: 0.6980600362880919, Q0_train: 1993.61310367155\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 3.9426418490852484, Lost1: 0.0, Left0: 0.0, Left1: 3.6532290150513202\n",
      "f_vars[i]: 1.0010, F_vars[i]: 0.7313, Q0_vars[i]: 2088.4156\n",
      "f_train: 1.0009990365699997, F_train: 0.7312549557941651, Q0_train: 2088.415589220684\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=7 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0x7dc4f434\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [5e+02, 2e+03]\n",
      "Presolve removed 53 rows and 90 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 240 rows, 174 columns, 639 nonzeros\n",
      "Presolved model has 38 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 136 continuous, 38 integer (38 binary)\n",
      "Found heuristic solution: objective 2.524514e+07\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.52451e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.524514127959e+07, best bound 2.542797509868e+07, gap 0.7242%\n",
      "Model status: 2\n",
      "Lost0: 10.014793751860907, Lost1: 0.0, Left0: 0.0, Left1: 10.014794055471384\n",
      "f_vars[i]: 1.2735, F_vars[i]: 0.7813, Q0_vars[i]: 2231.4617\n",
      "f_train: 1.2735057752192374, F_train: 0.7813422881235575, Q0_train: 2231.4616839245186\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.19434734856668, Lost1: 0.0, Left0: 0.0, Left1: 2.194347591066048\n",
      "f_vars[i]: 1.2639, F_vars[i]: 0.7797, Q0_vars[i]: 2226.7661\n",
      "f_train: 1.2639080959099358, F_train: 0.7796981310568509, Q0_train: 2226.7660805347155\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 8.019705899363451, Lost1: 0.0, Left0: 0.0, Left1: 8.019706174674411\n",
      "f_vars[i]: 1.3230, F_vars[i]: 0.7897, Q0_vars[i]: 2255.2734\n",
      "f_train: 1.3229970866771303, F_train: 0.7896799114746096, Q0_train: 2255.2733824920547\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.2548893336885874e-06, Lost1: 0.0, Left0: 0.0, Left1: 1.4747593013453297e-06\n",
      "f_vars[i]: 1.3288, F_vars[i]: 0.7906, Q0_vars[i]: 2258.0369\n",
      "f_train: 1.3288332138194239, F_train: 0.7906475691772322, Q0_train: 2258.036948626101\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.8983678273798432e-06, Lost1: 0.0, Left0: 0.0, Left1: 2.1154513092369598e-06\n",
      "f_vars[i]: 1.1406, F_vars[i]: 0.7578, Q0_vars[i]: 2164.1950\n",
      "f_train: 1.1405956301493223, F_train: 0.7577889806308682, Q0_train: 2164.19500196129\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 8.02143225400214, Lost1: 0.0, Left0: 0.0, Left1: 8.021432500755328\n",
      "f_vars[i]: 1.5435, F_vars[i]: 0.8240, Q0_vars[i]: 2353.1973\n",
      "f_train: 1.5434645320255003, F_train: 0.8239678019434487, Q0_train: 2353.197320523828\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 7.374830386837213, Lost1: 0.0, Left0: 0.0, Left1: 7.374830675329463\n",
      "f_vars[i]: 1.0936, F_vars[i]: 0.7491, Q0_vars[i]: 2139.2374\n",
      "f_train: 1.0935527217199956, F_train: 0.7490501317430419, Q0_train: 2139.23742990715\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 19.10624018125054, Lost1: 0.0, Left0: 0.0, Left1: 19.10624044143026\n",
      "f_vars[i]: 1.1471, F_vars[i]: 0.7590, Q0_vars[i]: 2167.6237\n",
      "f_train: 1.1471477127000993, F_train: 0.7589895494625019, Q0_train: 2167.6237468115637\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.9516384752103686, Lost1: 0.0, Left0: 0.0, Left1: 0.951638760791705\n",
      "f_vars[i]: 1.5382, F_vars[i]: 0.8232, Q0_vars[i]: 2351.0334\n",
      "f_train: 1.5382495004756453, F_train: 0.8232101100001037, Q0_train: 2351.0334026539103\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 5.00089999272268, Lost1: 0.0, Left0: 0.0, Left1: 5.00090021878683\n",
      "f_vars[i]: 1.4713, F_vars[i]: 0.8133, Q0_vars[i]: 2322.6115\n",
      "f_train: 1.471321922405397, F_train: 0.81325822857909, Q0_train: 2322.6114902456056\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 9.03290474494483, Lost1: 0.0, Left0: 0.0, Left1: 9.032904927264866\n",
      "f_vars[i]: 1.3747, F_vars[i]: 0.7981, Q0_vars[i]: 2279.4281\n",
      "f_train: 1.374695036554698, F_train: 0.7981376483438661, Q0_train: 2279.428117290534\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 40.103057717502644, Lost1: 0.0, Left0: 0.0, Left1: 40.10305796655007\n",
      "f_vars[i]: 0.8508, F_vars[i]: 0.7007, Q0_vars[i]: 2001.2513\n",
      "f_train: 0.8507980533747093, F_train: 0.7007345255812077, Q0_train: 2001.2512674729578\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.40013623403623, Lost1: 0.0, Left0: 0.0, Left1: 2.400136497735579\n",
      "f_vars[i]: 1.5738, F_vars[i]: 0.8283, Q0_vars[i]: 2365.6326\n",
      "f_train: 1.573781215115587, F_train: 0.8283219824623304, Q0_train: 2365.6325709133966\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.0887470125453547e-06, Lost1: 0.0, Left0: 0.0, Left1: 1.3741884004048188e-06\n",
      "f_vars[i]: 1.3907, F_vars[i]: 0.8007, Q0_vars[i]: 2286.7633\n",
      "f_train: 1.3907129803011866, F_train: 0.8007060420010472, Q0_train: 2286.763279001797\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.0509214115930603, Lost1: 0.0, Left0: 0.0, Left1: 2.0509216658473064\n",
      "f_vars[i]: 1.6337, F_vars[i]: 0.8367, Q0_vars[i]: 2389.5060\n",
      "f_train: 1.6337391391027172, F_train: 0.8366812196993645, Q0_train: 2389.5059973038633\n",
      "f_train, F_train, Q0_train 都相等\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R(T)</th>\n",
       "      <th>R</th>\n",
       "      <th>average_profits</th>\n",
       "      <th>average_losses</th>\n",
       "      <th>average_lefts</th>\n",
       "      <th>average_operation_profits</th>\n",
       "      <th>alpha_values</th>\n",
       "      <th>F_vars</th>\n",
       "      <th>f_vars</th>\n",
       "      <th>Q0_vars</th>\n",
       "      <th>Q1_vars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]</td>\n",
       "      <td>1.693391e+06</td>\n",
       "      <td>0.907513</td>\n",
       "      <td>15.314716</td>\n",
       "      <td>1.694654e+06</td>\n",
       "      <td>[-0.009695777349282883, 0.0, 0.006673373209610...</td>\n",
       "      <td>[0.49196972857277843, 0.4933030599973235, 0.49...</td>\n",
       "      <td>[-0.032123847918444026, -0.026789362055680055,...</td>\n",
       "      <td>[1405.0328718254375, 1408.8407778239598, 1411....</td>\n",
       "      <td>[1395.4866146804145, 1381.5257800508548, 1416....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]</td>\n",
       "      <td>1.693391e+06</td>\n",
       "      <td>0.907513</td>\n",
       "      <td>14.755805</td>\n",
       "      <td>1.694654e+06</td>\n",
       "      <td>[-0.010105758905410767, 0.0, 0.008380903862416...</td>\n",
       "      <td>[0.5898514297767751, 0.5909108318256385, 0.593...</td>\n",
       "      <td>[0.36335123079402654, 0.36773198187027467, 0.3...</td>\n",
       "      <td>[1684.5765098878474, 1687.6020917817793, 1694....</td>\n",
       "      <td>[1115.9429765435352, 1102.764466102665, 1134.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1.692536e+06</td>\n",
       "      <td>1.370741</td>\n",
       "      <td>864.776106</td>\n",
       "      <td>1.694376e+06</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1427.9667937105476, 1427.9667937105476, 1427....</td>\n",
       "      <td>[1373.9289900780263, 1362.6058583244226, 1397....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]</td>\n",
       "      <td>1.692520e+06</td>\n",
       "      <td>1.382556</td>\n",
       "      <td>297.695576</td>\n",
       "      <td>1.694369e+06</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1427.9667937105476, 1427.9667937105476, 1427....</td>\n",
       "      <td>[1374.2864414862242, 1363.2475369798672, 1396....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>1.692520e+06</td>\n",
       "      <td>1.382556</td>\n",
       "      <td>580.151235</td>\n",
       "      <td>1.694369e+06</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1427.9667937105476, 1427.9667937105476, 1427....</td>\n",
       "      <td>[1374.286441839607, 1363.2475369264903, 1396.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]</td>\n",
       "      <td>1.684859e+06</td>\n",
       "      <td>6.287485</td>\n",
       "      <td>6.986034</td>\n",
       "      <td>1.691426e+06</td>\n",
       "      <td>[0.0028382537089700513, 0.0, 0.011178033549360...</td>\n",
       "      <td>[0.6846419048130468, 0.6819534192526179, 0.692...</td>\n",
       "      <td>[0.7751852996363833, 0.7627590178826651, 0.813...</td>\n",
       "      <td>[1955.2918113115365, 1947.6136751002111, 1978....</td>\n",
       "      <td>[848.0269713843772, 840.5396406209159, 851.292...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]</td>\n",
       "      <td>1.683009e+06</td>\n",
       "      <td>7.618061</td>\n",
       "      <td>7.618061</td>\n",
       "      <td>1.690628e+06</td>\n",
       "      <td>[-0.004355199039511223, 0.0, 0.017493838761694...</td>\n",
       "      <td>[0.7813422892899958, 0.7796981364740222, 0.789...</td>\n",
       "      <td>[1.273505775505294, 1.2639080976497397, 1.3229...</td>\n",
       "      <td>[2231.461687255789, 2226.766096005797, 2255.27...</td>\n",
       "      <td>[569.1020701802887, 559.6268724760239, 573.339...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>1.682915e+06</td>\n",
       "      <td>6.355325</td>\n",
       "      <td>1156.330001</td>\n",
       "      <td>1.691385e+06</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1427.9667937105476, 1427.9667937105476, 1427....</td>\n",
       "      <td>[1409.577102449364, 1376.0850137611637, 1376.6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R(T)                                              R  average_profits  \\\n",
       "4     6  [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]     1.693391e+06   \n",
       "5     7  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]     1.693391e+06   \n",
       "1     3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]     1.692536e+06   \n",
       "3     5  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]     1.692520e+06   \n",
       "2     4  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]     1.692520e+06   \n",
       "6     8  [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]     1.684859e+06   \n",
       "7     9  [7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]     1.683009e+06   \n",
       "0     2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]     1.682915e+06   \n",
       "\n",
       "   average_losses  average_lefts  average_operation_profits  \\\n",
       "4        0.907513      15.314716               1.694654e+06   \n",
       "5        0.907513      14.755805               1.694654e+06   \n",
       "1        1.370741     864.776106               1.694376e+06   \n",
       "3        1.382556     297.695576               1.694369e+06   \n",
       "2        1.382556     580.151235               1.694369e+06   \n",
       "6        6.287485       6.986034               1.691426e+06   \n",
       "7        7.618061       7.618061               1.690628e+06   \n",
       "0        6.355325    1156.330001               1.691385e+06   \n",
       "\n",
       "                                        alpha_values  \\\n",
       "4  [-0.009695777349282883, 0.0, 0.006673373209610...   \n",
       "5  [-0.010105758905410767, 0.0, 0.008380903862416...   \n",
       "1                               [0.0, 0.0, 0.0, 0.0]   \n",
       "3                               [0.0, 0.0, 0.0, 0.0]   \n",
       "2                               [0.0, 0.0, 0.0, 0.0]   \n",
       "6  [0.0028382537089700513, 0.0, 0.011178033549360...   \n",
       "7  [-0.004355199039511223, 0.0, 0.017493838761694...   \n",
       "0                               [0.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                              F_vars  \\\n",
       "4  [0.49196972857277843, 0.4933030599973235, 0.49...   \n",
       "5  [0.5898514297767751, 0.5909108318256385, 0.593...   \n",
       "1  [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, ...   \n",
       "3  [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, ...   \n",
       "2  [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, ...   \n",
       "6  [0.6846419048130468, 0.6819534192526179, 0.692...   \n",
       "7  [0.7813422892899958, 0.7796981364740222, 0.789...   \n",
       "0  [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, ...   \n",
       "\n",
       "                                              f_vars  \\\n",
       "4  [-0.032123847918444026, -0.026789362055680055,...   \n",
       "5  [0.36335123079402654, 0.36773198187027467, 0.3...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6  [0.7751852996363833, 0.7627590178826651, 0.813...   \n",
       "7  [1.273505775505294, 1.2639080976497397, 1.3229...   \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                             Q0_vars  \\\n",
       "4  [1405.0328718254375, 1408.8407778239598, 1411....   \n",
       "5  [1684.5765098878474, 1687.6020917817793, 1694....   \n",
       "1  [1427.9667937105476, 1427.9667937105476, 1427....   \n",
       "3  [1427.9667937105476, 1427.9667937105476, 1427....   \n",
       "2  [1427.9667937105476, 1427.9667937105476, 1427....   \n",
       "6  [1955.2918113115365, 1947.6136751002111, 1978....   \n",
       "7  [2231.461687255789, 2226.766096005797, 2255.27...   \n",
       "0  [1427.9667937105476, 1427.9667937105476, 1427....   \n",
       "\n",
       "                                             Q1_vars  \n",
       "4  [1395.4866146804145, 1381.5257800508548, 1416....  \n",
       "5  [1115.9429765435352, 1102.764466102665, 1134.3...  \n",
       "1  [1373.9289900780263, 1362.6058583244226, 1397....  \n",
       "3  [1374.2864414862242, 1363.2475369798672, 1396....  \n",
       "2  [1374.286441839607, 1363.2475369264903, 1396.7...  \n",
       "6  [848.0269713843772, 840.5396406209159, 851.292...  \n",
       "7  [569.1020701802887, 559.6268724760239, 573.339...  \n",
       "0  [1409.577102449364, 1376.0850137611637, 1376.6...  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_2, stimulation_results_df_2 = None, None\n",
    "results_df_2, stimulation_results_df_2 = grid_flexible_F_fixed_R(\n",
    "    assigned_Ts=ASSIGNED_TS,\n",
    "    salvage_value=salvage_value,\n",
    "    cost=cost,\n",
    "    price=price,\n",
    "    Q_star=Q_star,\n",
    "    demand_df_train=demand_df_train,\n",
    "    Qk_hat_df_train=Qk_hat_df_train,\n",
    "    training_df=training_df,\n",
    ")\n",
    "\n",
    "results_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++++++++++++++++++++++ THis is R=0 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x43b19ce0\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 7e+02]\n",
      "  GenCon const rng [6e+01, 6e+02]\n",
      "Presolve removed 46 rows and 84 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 247 rows, 180 columns, 675 nonzeros\n",
      "Presolved model has 37 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 143 continuous, 37 integer (37 binary)\n",
      "Found heuristic solution: objective 5541046.9003\n",
      "\n",
      "Root relaxation: objective 5.677591e+06, 53 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5677590.52    0   15 5541046.90 5677590.52  2.46%     -    0s\n",
      "H    0     0                    5610213.2929 5677590.52  1.20%     -    0s\n",
      "     0     2 5677590.52    0   15 5610213.29 5677590.52  1.20%     -    0s\n",
      "H   40    12                    5610441.6764 5677590.52  1.20%   3.0    0s\n",
      "* 2201   398              74    5647797.5342 5677590.51  0.53%   3.1    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Cover: 2\n",
      "  Implied bound: 5\n",
      "\n",
      "Explored 2811 nodes (8916 simplex iterations) in 0.09 seconds (0.12 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 4: 5.6478e+06 5.61044e+06 5.61021e+06 5.54105e+06 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 5.647797534185e+06, best bound 5.677590512069e+06, gap 0.5275%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 621.911608523198, Left1: 0.0\n",
      "f_vars[i]: -1.1486, F_vars[i]: 0.2407, Q0_vars[i]: 687.5368\n",
      "f_train: -1.1486279599724267, F_train: 0.24073978098933588, Q0_train: 687.5368263558428\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 441.11603245295373, Left1: 22.766769280235053\n",
      "f_vars[i]: -1.5455, F_vars[i]: 0.1757, Q0_vars[i]: 501.8861\n",
      "f_train: -1.545518140939647, F_train: 0.1757345307759164, Q0_train: 501.88614891262574\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 493.8833560119264, Left1: 29.690421215899278\n",
      "f_vars[i]: -1.4111, F_vars[i]: 0.1961, Q0_vars[i]: 559.9566\n",
      "f_train: -1.4110544672054806, F_train: 0.19606779247773715, Q0_train: 559.9565939486787\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 607.1010393300334, Left1: 3.8237107044307095\n",
      "f_vars[i]: -1.1821, F_vars[i]: 0.2347, Q0_vars[i]: 670.2241\n",
      "f_train: -1.182083613302328, F_train: 0.23467776385979375, Q0_train: 670.2241080280614\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 450.2003016210471, Left1: 35.83994015892563\n",
      "f_vars[i]: -1.5139, F_vars[i]: 0.1804, Q0_vars[i]: 515.1151\n",
      "f_train: -1.513865515399588, F_train: 0.1803666303589834, Q0_train: 515.1151176921861\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 2.7067011329625075, Left0: 559.6195225774447, Left1: 0.0\n",
      "f_vars[i]: -1.2764, F_vars[i]: 0.2182, Q0_vars[i]: 623.0468\n",
      "f_train: -1.27642889046595, F_train: 0.21815871854340063, Q0_train: 623.0468116768432\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 449.0577521997412, Left1: 20.001707302584236\n",
      "f_vars[i]: -1.5272, F_vars[i]: 0.1784, Q0_vars[i]: 509.4960\n",
      "f_train: -1.5272316026736483, F_train: 0.1783990964930288, Q0_train: 509.49597164001784\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 472.6689069538564, Left1: 13.024443359858878\n",
      "f_vars[i]: -1.4669, F_vars[i]: 0.1874, Q0_vars[i]: 535.2344\n",
      "f_train: -1.4669191102465113, F_train: 0.18741134575002463, Q0_train: 535.2343569912831\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 429.54486860306855, Left1: 16.161930412874653\n",
      "f_vars[i]: -1.5749, F_vars[i]: 0.1715, Q0_vars[i]: 489.8457\n",
      "f_train: -1.5749026766997316, F_train: 0.17151859917126708, Q0_train: 489.84572824063764\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 600.5725058853362, Left1: 4.269590143892856\n",
      "f_vars[i]: -1.1874, F_vars[i]: 0.2337, Q0_vars[i]: 667.5197\n",
      "f_train: -1.1873633406918946, F_train: 0.23373083180525833, Q0_train: 667.519732968508\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 479.07615401927984, Left1: 41.193652477815135\n",
      "f_vars[i]: -1.4450, F_vars[i]: 0.1908, Q0_vars[i]: 544.8232\n",
      "f_train: -1.4450220814638746, F_train: 0.19076885496639343, Q0_train: 544.8231803323865\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 8.9819671828987, Left0: 504.5332146179648, Left1: 0.0\n",
      "f_vars[i]: -1.3980, F_vars[i]: 0.1981, Q0_vars[i]: 565.8629\n",
      "f_train: -1.397986093946089, F_train: 0.19813588241207883, Q0_train: 565.8629214539726\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 663.002754231117, Left1: 35.591476160026446\n",
      "f_vars[i]: -1.0692, F_vars[i]: 0.2555, Q0_vars[i]: 729.8259\n",
      "f_train: -1.069242174144081, F_train: 0.25554722840744704, Q0_train: 729.8259127811982\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 609.8938411160198, Left1: 0.0\n",
      "f_vars[i]: -1.1777, F_vars[i]: 0.2355, Q0_vars[i]: 672.4694\n",
      "f_train: -1.1777112656276407, F_train: 0.2354639662829595, Q0_train: 672.4694499348924\n",
      "f_train, F_train, Q0_train 不相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 450.2567345737114, Left1: 7.649614041557925\n",
      "f_vars[i]: -1.5271, F_vars[i]: 0.1784, Q0_vars[i]: 509.5344\n",
      "f_train: -1.5271399025032952, F_train: 0.1784125376455374, Q0_train: 509.53435867892085\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=1 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xfec69995\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 7e+02]\n",
      "  GenCon const rng [1e+02, 6e+02]\n",
      "Presolve removed 34 rows and 67 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 259 rows, 197 columns, 723 nonzeros\n",
      "Presolved model has 43 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 154 continuous, 43 integer (43 binary)\n",
      "Found heuristic solution: objective 5593848.9858\n",
      "\n",
      "Root relaxation: objective 5.727013e+06, 62 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5727012.92    0   15 5593848.99 5727012.92  2.38%     -    0s\n",
      "     0     0 5727012.92    0   15 5593848.99 5727012.92  2.38%     -    0s\n",
      "H    0     0                    5678260.8230 5727012.92  0.86%     -    0s\n",
      "\n",
      "Explored 1 nodes (64 simplex iterations) in 0.01 seconds (0.01 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 5.67826e+06 5.59385e+06 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 5.678260823048e+06, best bound 5.727012924416e+06, gap 0.8586%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 559.5757384883864, Left1: 5.549095652609367\n",
      "f_vars[i]: -1.1380, F_vars[i]: 0.2427, Q0_vars[i]: 693.0866\n",
      "f_train: -1.1380256634828878, F_train: 0.24268303594897198, Q0_train: 693.0866334639901\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 493.37252151569453, Left1: 18.241539618839283\n",
      "f_vars[i]: -1.2926, F_vars[i]: 0.2154, Q0_vars[i]: 615.2007\n",
      "f_train: -1.29260962763571, F_train: 0.2154114318117179, Q0_train: 615.2007432255541\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 516.4025860034773, Left1: 4.838167979299726\n",
      "f_vars[i]: -1.2271, F_vars[i]: 0.2267, Q0_vars[i]: 647.4068\n",
      "f_train: -1.2271061092713351, F_train: 0.22668832560572105, Q0_train: 647.4068029736283\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 550.7778903044591, Left1: 13.881765157352675\n",
      "f_vars[i]: -1.1626, F_vars[i]: 0.2382, Q0_vars[i]: 680.2805\n",
      "f_train: -1.1625789878731732, F_train: 0.23819898549976468, Q0_train: 680.2804831784083\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 503.1931364139721, Left1: 5.768422369790301\n",
      "f_vars[i]: -1.2608, F_vars[i]: 0.2208, Q0_vars[i]: 630.7126\n",
      "f_train: -1.2607611655234376, F_train: 0.22084288964343812, Q0_train: 630.7126260758253\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 533.6456938452558, Left1: 11.774401406813581\n",
      "f_vars[i]: -1.2011, F_vars[i]: 0.2313, Q0_vars[i]: 660.5314\n",
      "f_train: -1.2010759521327457, F_train: 0.23128386590160444, Q0_train: 660.5313608569886\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 499.343121934415, Left1: 22.587809588029245\n",
      "f_vars[i]: -1.2847, F_vars[i]: 0.2168, Q0_vars[i]: 619.0270\n",
      "f_train: -1.2847003333565128, F_train: 0.21675118513140249, Q0_train: 619.0269897301002\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 507.5236389090808, Left1: 7.8200121646847265\n",
      "f_vars[i]: -1.2575, F_vars[i]: 0.2214, Q0_vars[i]: 632.2952\n",
      "f_train: -1.2575437638781717, F_train: 0.22139700936251952, Q0_train: 632.2951551930022\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 497.41410468862813, Left1: 17.813530517905576\n",
      "f_vars[i]: -1.2894, F_vars[i]: 0.2159, Q0_vars[i]: 616.7294\n",
      "f_train: -1.2894454523748555, F_train: 0.21594668855164034, Q0_train: 616.7294009269922\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 552.9124975799116, Left1: 10.781232981241374\n",
      "f_vars[i]: -1.1488, F_vars[i]: 0.2407, Q0_vars[i]: 687.4269\n",
      "f_train: -1.1488385314424274, F_train: 0.2407012939657846, Q0_train: 687.4269099726029\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 502.54517338728925, Left1: 29.897919396847897\n",
      "f_vars[i]: -1.2538, F_vars[i]: 0.2220, Q0_vars[i]: 634.1460\n",
      "f_train: -1.2537880768009613, F_train: 0.22204509346224416, Q0_train: 634.1460403408793\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 520.8899490255891, Left1: 11.231197865485171\n",
      "f_vars[i]: -1.2310, F_vars[i]: 0.2260, Q0_vars[i]: 645.4802\n",
      "f_train: -1.2309584066265307, F_train: 0.22601372617747262, Q0_train: 645.4801918084385\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 562.2754112633238, Left1: 4.4132021431007615\n",
      "f_vars[i]: -1.1275, F_vars[i]: 0.2446, Q0_vars[i]: 698.6473\n",
      "f_train: -1.1274604162161617, F_train: 0.24463007654939492, Q0_train: 698.6472521108105\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 547.5697345901516, Left1: 4.88594292891878\n",
      "f_vars[i]: -1.1682, F_vars[i]: 0.2372, Q0_vars[i]: 677.3574\n",
      "f_train: -1.168227851622961, F_train: 0.2371754577858162, Q0_train: 677.3573560024865\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 497.97824666477436, Left1: 19.43747540728026\n",
      "f_vars[i]: -1.2894, F_vars[i]: 0.2159, Q0_vars[i]: 616.7279\n",
      "f_train: -1.2894486423917586, F_train: 0.21594614843851298, Q0_train: 616.7278583997706\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=2 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x701b3cbf\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 7e+02]\n",
      "  GenCon const rng [2e+02, 5e+02]\n",
      "Presolve removed 40 rows and 75 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 253 rows, 189 columns, 695 nonzeros\n",
      "Presolved model has 40 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 149 continuous, 40 integer (40 binary)\n",
      "Found heuristic solution: objective 5634649.4203\n",
      "\n",
      "Root relaxation: objective 5.728064e+06, 53 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5728064.04    0   15 5634649.42 5728064.04  1.66%     -    0s\n",
      "     0     0 5728064.04    0   15 5634649.42 5728064.04  1.66%     -    0s\n",
      "     0     2 5728064.04    0   15 5634649.42 5728064.04  1.66%     -    0s\n",
      "H   27    38                    5634650.6025 5728064.04  1.66%   3.0    0s\n",
      "H  375   200                    5634650.6866 5728064.04  1.66%   4.2    0s\n",
      "H  658   402                    5704503.6143 5728064.04  0.41%   4.1    0s\n",
      "H  742   402                    5713170.4337 5728064.04  0.26%   3.9    0s\n",
      "\n",
      "Explored 903 nodes (3381 simplex iterations) in 0.05 seconds (0.06 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 4: 5.71317e+06 5.7045e+06 5.63465e+06 5.63465e+06 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 5.713170433699e+06, best bound 5.728064036501e+06, gap 0.2607%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 488.7166404152845, Left1: 3.4407273081079524\n",
      "f_vars[i]: -1.1420, F_vars[i]: 0.2419, Q0_vars[i]: 690.9783\n",
      "f_train: -1.1420466344698068, F_train: 0.24194479464001092, Q0_train: 690.9782653141066\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 411.96611051408445, Left1: 20.452234257136013\n",
      "f_vars[i]: -1.3384, F_vars[i]: 0.2078, Q0_vars[i]: 593.3685\n",
      "f_train: -1.3384388621316403, F_train: 0.2077669043389714, Q0_train: 593.3684804561741\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 438.79650715740485, Left1: 6.24256189131836\n",
      "f_vars[i]: -1.2511, F_vars[i]: 0.2225, Q0_vars[i]: 635.4840\n",
      "f_train: -1.2510781314150783, F_train: 0.22251356491362267, Q0_train: 635.4839636936191\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 481.7285900419445, Left1: 6.501005346176328\n",
      "f_vars[i]: -1.1769, F_vars[i]: 0.2356, Q0_vars[i]: 672.8997\n",
      "f_train: -1.1768745496278203, F_train: 0.23561462581037926, Q0_train: 672.8997235395154\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.5835241690942325, Left0: 422.59039610684016, Left1: 0.0\n",
      "f_vars[i]: -1.2918, F_vars[i]: 0.2155, Q0_vars[i]: 615.5817\n",
      "f_train: -1.2918206164709127, F_train: 0.2155448120160889, Q0_train: 615.5816682311143\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.9642080304506067, Left0: 461.04938589302554, Left1: 0.0\n",
      "f_vars[i]: -1.2263, F_vars[i]: 0.2268, Q0_vars[i]: 647.7928\n",
      "f_train: -1.226335372337499, F_train: 0.22682346481238566, Q0_train: 647.7927515729191\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 418.08914011739733, Left1: 1.7841479956750845\n",
      "f_vars[i]: -1.3281, F_vars[i]: 0.2095, Q0_vars[i]: 598.2233\n",
      "f_train: -1.3281422761337052, F_train: 0.2094668205528379, Q0_train: 598.2233282671572\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.1161977063889026, Left0: 427.49074566753063, Left1: 0.0\n",
      "f_vars[i]: -1.2925, F_vars[i]: 0.2154, Q0_vars[i]: 615.2609\n",
      "f_train: -1.292485002033812, F_train: 0.21543249545033358, Q0_train: 615.2608995785499\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.4815979240240154, Left0: 419.73512827837374, Left1: 0.0\n",
      "f_vars[i]: -1.3298, F_vars[i]: 0.2092, Q0_vars[i]: 597.4343\n",
      "f_train: -1.329811577927577, F_train: 0.20919053414111022, Q0_train: 597.4342726241559\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 482.5458724766595, Left1: 7.863820780529977\n",
      "f_vars[i]: -1.1544, F_vars[i]: 0.2397, Q0_vars[i]: 684.5095\n",
      "f_train: -1.1544359733071834, F_train: 0.23967976740783467, Q0_train: 684.509497965311\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 414.6639626698766, Left1: 20.441659666366547\n",
      "f_vars[i]: -1.2892, F_vars[i]: 0.2160, Q0_vars[i]: 616.8390\n",
      "f_train: -1.2892188285939745, F_train: 0.21598506153620206, Q0_train: 616.8389916224515\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 447.07318916158636, Left1: 6.5179098701804605\n",
      "f_vars[i]: -1.2588, F_vars[i]: 0.2212, Q0_vars[i]: 631.6806\n",
      "f_train: -1.258792472343748, F_train: 0.22118183141775344, Q0_train: 631.6806212732724\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 492.04392772621947, Left1: 4.177866941414322\n",
      "f_vars[i]: -1.1350, F_vars[i]: 0.2432, Q0_vars[i]: 694.6533\n",
      "f_train: -1.1350432550067475, F_train: 0.24323158734343542, Q0_train: 694.653259815865\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 473.0674627235357, Left1: 0.9122229907707151\n",
      "f_vars[i]: -1.1864, F_vars[i]: 0.2339, Q0_vars[i]: 668.0281\n",
      "f_train: -1.186369768932467, F_train: 0.23390882830841916, Q0_train: 668.0280791603285\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 2.625628618438327, Left0: 412.981473999489, Left1: 0.0\n",
      "f_vars[i]: -1.3357, F_vars[i]: 0.2082, Q0_vars[i]: 594.6648\n",
      "f_train: -1.33568355628484, F_train: 0.20822079235899182, Q0_train: 594.6647544974785\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=3 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xb985c37b\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 7e+02]\n",
      "  GenCon const rng [2e+02, 4e+02]\n",
      "Presolve removed 40 rows and 75 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 253 rows, 189 columns, 697 nonzeros\n",
      "Presolved model has 40 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 149 continuous, 40 integer (40 binary)\n",
      "Found heuristic solution: objective 5705493.5252\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.01 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 5.70549e+06 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 5.705493525206e+06, best bound 5.753829746571e+06, gap 0.8472%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 417.1665013919164, Left1: 0.44862171162628783\n",
      "f_vars[i]: -1.1478, F_vars[i]: 0.2409, Q0_vars[i]: 687.9863\n",
      "f_train: -1.1477672116476456, F_train: 0.2408971472384276, Q0_train: 687.9862539121502\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 372.2963068672689, Left1: 16.856613938078283\n",
      "f_vars[i]: -1.2955, F_vars[i]: 0.2149, Q0_vars[i]: 613.8158\n",
      "f_train: -1.295481213997685, F_train: 0.21492650350289355, Q0_train: 613.8158201808914\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 382.68924434864687, Left1: 0.4078463720131822\n",
      "f_vars[i]: -1.2360, F_vars[i]: 0.2251, Q0_vars[i]: 642.9766\n",
      "f_train: -1.2359766172070528, F_train: 0.22513709010895816, Q0_train: 642.9765774164232\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 418.7354684633455, Left1: 10.807789397080057\n",
      "f_vars[i]: -1.1685, F_vars[i]: 0.2371, Q0_vars[i]: 677.2065\n",
      "f_train: -1.1685198075231278, F_train: 0.23712264022581314, Q0_train: 677.2065125588682\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 371.6534309224232, Left1: 1.4167959386145412\n",
      "f_vars[i]: -1.2696, F_vars[i]: 0.2193, Q0_vars[i]: 626.3610\n",
      "f_train: -1.2696382511205675, F_train: 0.21931918381961937, Q0_train: 626.3610234362321\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 406.64083017424696, Left1: 9.837602311993464\n",
      "f_vars[i]: -1.2049, F_vars[i]: 0.2306, Q0_vars[i]: 658.5946\n",
      "f_train: -1.2048942536085794, F_train: 0.23060570047123072, Q0_train: 658.5945654265564\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 376.6985772313158, Left1: 20.936965002437148\n",
      "f_vars[i]: -1.2881, F_vars[i]: 0.2162, Q0_vars[i]: 617.3761\n",
      "f_train: -1.288108460335411, F_train: 0.2161731456118954, Q0_train: 617.3761472514832\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 379.83280013019163, Left1: 5.127776137607327\n",
      "f_vars[i]: -1.2630, F_vars[i]: 0.2205, Q0_vars[i]: 629.6029\n",
      "f_train: -1.2630207220313372, F_train: 0.22045433005775786, Q0_train: 629.6029257043666\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 375.73306787763994, Left1: 14.701559627236122\n",
      "f_vars[i]: -1.2959, F_vars[i]: 0.2149, Q0_vars[i]: 613.6174\n",
      "f_train: -1.2958929446938612, F_train: 0.21485703905977266, Q0_train: 613.6174343446509\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 412.1821235536494, Left1: 5.437048897996306\n",
      "f_vars[i]: -1.1591, F_vars[i]: 0.2388, Q0_vars[i]: 682.0827\n",
      "f_train: -1.1591045792938541, F_train: 0.23883002583735483, Q0_train: 682.0826924735496\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 367.5039658128317, Left1: 4.0879653641239315\n",
      "f_vars[i]: -1.2583, F_vars[i]: 0.2213, Q0_vars[i]: 631.9182\n",
      "f_train: -1.258309600891215, F_train: 0.22126502225989914, Q0_train: 631.9182087935222\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 394.1296001664115, Left1: 7.94155497594852\n",
      "f_vars[i]: -1.2376, F_vars[i]: 0.2249, Q0_vars[i]: 642.1906\n",
      "f_train: -1.2375549644258312, F_train: 0.22486186629289992, Q0_train: 642.1905564760843\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 423.89824898925553, Left1: 1.5543438559822675\n",
      "f_vars[i]: -1.1329, F_vars[i]: 0.2436, Q0_vars[i]: 695.7884\n",
      "f_train: -1.1328851878571937, F_train: 0.2436290428105245, Q0_train: 695.7883662338288\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 413.3080407493401, Left1: 2.841387967412402\n",
      "f_vars[i]: -1.1722, F_vars[i]: 0.2365, Q0_vars[i]: 675.3128\n",
      "f_train: -1.1721888638409557, F_train: 0.2364595647597149, Q0_train: 675.3128130642434\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 373.72479010471994, Left1: 18.43607679093543\n",
      "f_vars[i]: -1.2915, F_vars[i]: 0.2156, Q0_vars[i]: 615.7265\n",
      "f_train: -1.2915207979963408, F_train: 0.21559551122012374, Q0_train: 615.726461790773\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=4 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0x81b54b71\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 7e+02]\n",
      "  GenCon const rng [3e+02, 4e+02]\n",
      "Presolve removed 34 rows and 67 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 259 rows, 197 columns, 721 nonzeros\n",
      "Presolved model has 43 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 154 continuous, 43 integer (43 binary)\n",
      "\n",
      "Root relaxation: objective 5.746592e+06, 74 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5746592.37    0   15          - 5746592.37      -     -    0s\n",
      "H    0     0                    1021915.4820 5746592.37   462%     -    0s\n",
      "     0     2 5746592.37    0   15 1021915.48 5746592.37   462%     -    0s\n",
      "H   31    40                    3736980.1477 5746592.37  53.8%   3.3    0s\n",
      "H   85    72                    5624645.3820 5746592.37  2.17%   3.4    0s\n",
      "H  468   187                    5722283.8737 5746592.37  0.42%   5.1    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 5\n",
      "\n",
      "Explored 564 nodes (2925 simplex iterations) in 0.06 seconds (0.06 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 4: 5.72228e+06 5.62465e+06 3.73698e+06 1.02192e+06 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 5.722283873658e+06, best bound 5.746592368591e+06, gap 0.4248%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 175.3871172511493, Left1: 0.8270889095026632\n",
      "f_vars[i]: -1.5014, F_vars[i]: 0.1822, Q0_vars[i]: 520.3827\n",
      "f_train: -1.5014385912439732, F_train: 0.1822110610427533, Q0_train: 520.3826892316346\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 310.05567246271664, Left1: 13.333740614413784\n",
      "f_vars[i]: -1.3028, F_vars[i]: 0.2137, Q0_vars[i]: 610.2929\n",
      "f_train: -1.3028070456031597, F_train: 0.21369297483287206, Q0_train: 610.2929442211301\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.6750456509438436, Left0: 249.2121265142606, Left1: 0.0\n",
      "f_vars[i]: -1.3824, F_vars[i]: 0.2006, Q0_vars[i]: 572.9587\n",
      "f_train: -1.3824210697374983, F_train: 0.20062044679687058, Q0_train: 572.9586723306095\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 206.33544858402468, Left1: 1.101066136935799\n",
      "f_vars[i]: -1.4739, F_vars[i]: 0.1864, Q0_vars[i]: 532.2112\n",
      "f_train: -1.4738852683608012, F_train: 0.18635279047106007, Q0_train: 532.2111934159462\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.8093016485170779, Left0: 276.2282027738046, Left1: 0.0\n",
      "f_vars[i]: -1.3370, F_vars[i]: 0.2080, Q0_vars[i]: 594.0637\n",
      "f_train: -1.3369605643879552, F_train: 0.20801033699864535, Q0_train: 594.0637079652122\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.9028323978905064, Left0: 234.77748085616258, Left1: 0.0\n",
      "f_vars[i]: -1.4250, F_vars[i]: 0.1939, Q0_vars[i]: 553.6938\n",
      "f_train: -1.4250260156298746, F_train: 0.19387487187617197, Q0_train: 553.693758348121\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 308.02732098778216, Left1: 9.121176675453114\n",
      "f_vars[i]: -1.3127, F_vars[i]: 0.2120, Q0_vars[i]: 605.5604\n",
      "f_train: -1.3126971227309712, F_train: 0.2120358678803695, Q0_train: 605.5603568175289\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.75771558510354, Left0: 278.5566880549253, Left1: 0.0\n",
      "f_vars[i]: -1.3463, F_vars[i]: 0.2065, Q0_vars[i]: 589.6720\n",
      "f_train: -1.3463204729231313, F_train: 0.20647258051300107, Q0_train: 589.671977568586\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 312.85978743211706, Left1: 11.85752604295817\n",
      "f_vars[i]: -1.3018, F_vars[i]: 0.2139, Q0_vars[i]: 610.7734\n",
      "f_train: -1.3018061350387806, F_train: 0.21386120431588088, Q0_train: 610.7733964520495\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 184.92464206632937, Left1: 6.160133894497903\n",
      "f_vars[i]: -1.4861, F_vars[i]: 0.1845, Q0_vars[i]: 526.9583\n",
      "f_train: -1.4860623418362164, F_train: 0.18451348409418009, Q0_train: 526.9582565566569\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 267.1006870174404, Left1: 0.8864589528488125\n",
      "f_vars[i]: -1.3528, F_vars[i]: 0.2054, Q0_vars[i]: 586.6451\n",
      "f_train: -1.3528016570678256, F_train: 0.20541271259114474, Q0_train: 586.6450651723263\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 259.60351130305446, Left1: 0.6228965557835835\n",
      "f_vars[i]: -1.3806, F_vars[i]: 0.2009, Q0_vars[i]: 573.8058\n",
      "f_train: -1.3805724265778065, F_train: 0.20091708126828664, Q0_train: 573.8058406807136\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.7743049324338358, Left0: 169.22108248071757, Left1: 0.0\n",
      "f_vars[i]: -1.5221, F_vars[i]: 0.1792, Q0_vars[i]: 511.6587\n",
      "f_train: -1.5220736528418337, F_train: 0.1791563664272286, Q0_train: 511.6586842798432\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.2682200193520146, Left0: 201.89060823068615, Left1: 0.0\n",
      "f_vars[i]: -1.4692, F_vars[i]: 0.1871, Q0_vars[i]: 534.2532\n",
      "f_train: -1.4691765504677985, F_train: 0.1870678065057764, Q0_train: 534.2532317250373\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 307.98397962001314, Left1: 10.392286691504808\n",
      "f_vars[i]: -1.3083, F_vars[i]: 0.2128, Q0_vars[i]: 607.6827\n",
      "f_train: -1.3082550021410513, F_train: 0.2127789919067188, Q0_train: 607.6826696839996\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=5 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xabbcfa6a\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 7e+02]\n",
      "  GenCon const rng [2e+02, 4e+02]\n",
      "Presolve removed 34 rows and 67 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 259 rows, 197 columns, 721 nonzeros\n",
      "Presolved model has 43 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 154 continuous, 43 integer (43 binary)\n",
      "\n",
      "Root relaxation: objective 5.746592e+06, 70 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5746592.37    0   15          - 5746592.37      -     -    0s\n",
      "H    0     0                    1021915.4820 5746592.37   462%     -    0s\n",
      "     0     2 5746592.37    0   15 1021915.48 5746592.37   462%     -    0s\n",
      "H   31    40                    3736980.1476 5746592.37  53.8%   3.3    0s\n",
      "H  109    76                    5624645.3835 5746592.37  2.17%   3.8    0s\n",
      "H  337   150                    5636810.0108 5746592.37  1.95%   5.9    0s\n",
      "H  469   198                    5696631.2218 5746592.37  0.88%   5.5    0s\n",
      "H  478   198                    5736372.5404 5746592.37  0.18%   5.4    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 6\n",
      "\n",
      "Explored 565 nodes (3038 simplex iterations) in 0.05 seconds (0.06 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 6: 5.73637e+06 5.69663e+06 5.63681e+06 ... 1.02192e+06\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 5.736372540413e+06, best bound 5.746592368612e+06, gap 0.1782%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 95.11836239607595, Left1: 0.8270888893081292\n",
      "f_vars[i]: -1.5292, F_vars[i]: 0.1781, Q0_vars[i]: 508.6720\n",
      "f_train: -1.5292013146935064, F_train: 0.1781105730328313, Q0_train: 508.6719677992808\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 67.25653873459471, Left1: 5.521790781527812\n",
      "f_vars[i]: -1.7367, F_vars[i]: 0.1497, Q0_vars[i]: 427.6110\n",
      "f_train: -1.7367422347758312, F_train: 0.1497272041689715, Q0_train: 427.61095133682153\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.6750456651792263, Left0: 143.46889717771472, Left1: 0.0\n",
      "f_vars[i]: -1.4771, F_vars[i]: 0.1859, Q0_vars[i]: 530.8152\n",
      "f_train: -1.4771122432757768, F_train: 0.18586399416896673, Q0_train: 530.8152236393906\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 43.20664509448948, Left1: 1.1010661339639611\n",
      "f_vars[i]: -1.7128, F_vars[i]: 0.1528, Q0_vars[i]: 436.3823\n",
      "f_train: -1.712818701555495, F_train: 0.15279847454189485, Q0_train: 436.38229555090464\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.809301606261613, Left0: 168.03331940241878, Left1: 0.0\n",
      "f_vars[i]: -1.4388, F_vars[i]: 0.1917, Q0_vars[i]: 547.5851\n",
      "f_train: -1.438769675634814, F_train: 0.1917359436433749, Q0_train: 547.5851213669926\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.9028323671144527, Left0: 25.39359108792684, Left1: 0.0\n",
      "f_vars[i]: -1.7874, F_vars[i]: 0.1434, Q0_vars[i]: 409.5202\n",
      "f_train: -1.787391978146398, F_train: 0.14339277231664443, Q0_train: 409.52023465253063\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 77.1918792465419, Left1: 2.0936989122375564\n",
      "f_vars[i]: -1.7158, F_vars[i]: 0.1524, Q0_vars[i]: 435.2683\n",
      "f_train: -1.7158350846243784, F_train: 0.1524084092417704, Q0_train: 435.26829495899176\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.7577156368536606, Left0: 94.20628993274208, Left1: 0.0\n",
      "f_vars[i]: -1.6315, F_vars[i]: 0.1636, Q0_vars[i]: 467.3215\n",
      "f_train: -1.6314501876964007, F_train: 0.16363179688530066, Q0_train: 467.3215446947967\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.3290464622571676, Left0: 145.45615939493496, Left1: 0.0\n",
      "f_vars[i]: -1.5415, F_vars[i]: 0.1763, Q0_vars[i]: 503.5550\n",
      "f_train: -1.5414893514461725, F_train: 0.17631887120116613, Q0_train: 503.5549863595844\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 116.22534564362991, Left1: 6.16013386022297\n",
      "f_vars[i]: -1.4878, F_vars[i]: 0.1842, Q0_vars[i]: 526.1959\n",
      "f_train: -1.4878372962666506, F_train: 0.18424655933355785, Q0_train: 526.1959371674816\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 63.548543384236815, Left1: 0.8864589577107509\n",
      "f_vars[i]: -1.6888, F_vars[i]: 0.1559, Q0_vars[i]: 445.3322\n",
      "f_train: -1.6888110972019934, F_train: 0.1559322564018348, Q0_train: 445.33216842035813\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 102.40837897103401, Left1: 0.6228965748201745\n",
      "f_vars[i]: -1.5992, F_vars[i]: 0.1681, Q0_vars[i]: 480.0642\n",
      "f_train: -1.599198799402303, F_train: 0.1680936234895037, Q0_train: 480.0642251549892\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.7743049102444388, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.7811, F_vars[i]: 0.1442, Q0_vars[i]: 411.7184\n",
      "f_train: -1.781139701313375, F_train: 0.1441624611115323, Q0_train: 411.71841473371256\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.268220015592476, Left0: 0.0, Left1: 0.0\n",
      "f_vars[i]: -1.8165, F_vars[i]: 0.1399, Q0_vars[i]: 399.4068\n",
      "f_train: -1.8165234044458702, F_train: 0.13985156001971594, Q0_train: 399.4067675135439\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 50.42796181645832, Left1: 0.8803053126440545\n",
      "f_vars[i]: -1.7848, F_vars[i]: 0.1437, Q0_vars[i]: 410.4450\n",
      "f_train: -1.784758159064575, F_train: 0.14371659165588638, Q0_train: 410.4450411797282\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=6 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xd7c9a588\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 7e+02]\n",
      "  GenCon const rng [2e+02, 5e+02]\n",
      "Presolve removed 30 rows and 60 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 263 rows, 204 columns, 739 nonzeros\n",
      "Presolved model has 45 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 159 continuous, 45 integer (45 binary)\n",
      "\n",
      "Root relaxation: objective 5.750950e+06, 72 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5750949.74    0   15          - 5750949.74      -     -    0s\n",
      "H    0     0                    1021915.4820 5750949.74   463%     -    0s\n",
      "H    0     0                    5127942.3311 5750949.74  12.1%     -    0s\n",
      "H    0     0                    5717793.3205 5750949.74  0.58%     -    0s\n",
      "\n",
      "Explored 1 nodes (72 simplex iterations) in 0.01 seconds (0.01 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 3: 5.71779e+06 5.12794e+06 1.02192e+06 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 5.717793320475e+06, best bound 5.750949741248e+06, gap 0.5799%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 212.51443379636513, Left1: 4.089947444818677\n",
      "f_vars[i]: -1.1408, F_vars[i]: 0.2422, Q0_vars[i]: 691.6275\n",
      "f_train: -1.1408075873911336, F_train: 0.24217211783652082, Q0_train: 691.6274852662191\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 189.11064999580705, Left1: 10.48541027668665\n",
      "f_vars[i]: -1.3088, F_vars[i]: 0.2127, Q0_vars[i]: 607.4446\n",
      "f_train: -1.3087527017804987, F_train: 0.2126956370975439, Q0_train: 607.444613884804\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 191.84517530462742, Left1: 0.8388051240776631\n",
      "f_vars[i]: -1.2351, F_vars[i]: 0.2253, Q0_vars[i]: 643.4074\n",
      "f_train: -1.2351120163237868, F_train: 0.22528795590561754, Q0_train: 643.4074401122958\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 212.91869215948458, Left1: 10.221318883818782\n",
      "f_vars[i]: -1.1697, F_vars[i]: 0.2369, Q0_vars[i]: 676.6200\n",
      "f_train: -1.169655351091579, F_train: 0.2369172868331992, Q0_train: 676.6200369076112\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 185.1511813847249, Left1: 1.0094061903403144\n",
      "f_vars[i]: -1.2705, F_vars[i]: 0.2192, Q0_vars[i]: 625.9536\n",
      "f_train: -1.270471622851064, F_train: 0.21917652872271748, Q0_train: 625.9536099535733\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 202.18205375039432, Left1: 6.339928254977451\n",
      "f_vars[i]: -1.2118, F_vars[i]: 0.2294, Q0_vars[i]: 655.0969\n",
      "f_train: -1.2118097402266883, F_train: 0.22938099492129554, Q0_train: 655.0968877117956\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 194.38327322113471, Left1: 15.196386823945488\n",
      "f_vars[i]: -1.3000, F_vars[i]: 0.2142, Q0_vars[i]: 611.6356\n",
      "f_train: -1.3000114391786672, F_train: 0.21416309176869855, Q0_train: 611.6355669681725\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 189.01058656891465, Left1: 1.7986611393716885\n",
      "f_vars[i]: -1.2698, F_vars[i]: 0.2193, Q0_vars[i]: 626.2738\n",
      "f_train: -1.2698166268855215, F_train: 0.219288644157152, Q0_train: 626.273804188443\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 190.0368740444437, Left1: 11.49515955387858\n",
      "f_vars[i]: -1.3026, F_vars[i]: 0.2137, Q0_vars[i]: 610.4110\n",
      "f_train: -1.3025609882382363, F_train: 0.21373432234312634, Q0_train: 610.4110299644216\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 211.32897499789513, Left1: 9.263064289278958\n",
      "f_vars[i]: -1.1517, F_vars[i]: 0.2402, Q0_vars[i]: 685.9087\n",
      "f_train: -1.1517493076228429, F_train: 0.24016970993490716, Q0_train: 685.9087412842832\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 188.15844466565912, Left1: 0.0\n",
      "f_vars[i]: -1.2666, F_vars[i]: 0.2198, Q0_vars[i]: 627.8303\n",
      "f_train: -1.266636100834443, F_train: 0.21983363994419128, Q0_train: 627.8302759616515\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 197.24519174030735, Left1: 6.23672250793075\n",
      "f_vars[i]: -1.2410, F_vars[i]: 0.2243, Q0_vars[i]: 640.4857\n",
      "f_train: -1.2409830406511446, F_train: 0.2242649196310045, Q0_train: 640.4857164544783\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 213.0796074783188, Left1: 1.4063765383754685\n",
      "f_vars[i]: -1.1332, F_vars[i]: 0.2436, Q0_vars[i]: 695.6404\n",
      "f_train: -1.133166315808632, F_train: 0.24357724199121455, Q0_train: 695.6404265341056\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 204.80123142532022, Left1: 0.27203481333237883\n",
      "f_vars[i]: -1.1772, F_vars[i]: 0.2356, Q0_vars[i]: 672.7434\n",
      "f_train: -1.177178402608316, F_train: 0.23555990617126096, Q0_train: 672.7434478842658\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 189.24301323664682, Left1: 11.437235766660308\n",
      "f_vars[i]: -1.3061, F_vars[i]: 0.2131, Q0_vars[i]: 608.7276\n",
      "f_train: -1.3060720240051074, F_train: 0.21314487894318973, Q0_train: 608.7276187606589\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=7 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 466 nonzeros\n",
      "Model fingerprint: 0xecbd7c24\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 7e+02]\n",
      "  GenCon const rng [1e+02, 6e+02]\n",
      "Presolve removed 30 rows and 60 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 263 rows, 204 columns, 721 nonzeros\n",
      "Presolved model has 45 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 159 continuous, 45 integer (45 binary)\n",
      "Found heuristic solution: objective 5720047.6616\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.01 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 5.72005e+06 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 5.720047661595e+06, best bound 5.753829746571e+06, gap 0.5906%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 139.77967325198435, Left1: 2.663607136256445\n",
      "f_vars[i]: -1.1435, F_vars[i]: 0.2417, Q0_vars[i]: 690.2013\n",
      "f_train: -1.1435305540405594, F_train: 0.2416727368749002, Q0_train: 690.2012864050081\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 131.14030600312995, Left1: 10.906021162224931\n",
      "f_vars[i]: -1.3079, F_vars[i]: 0.2128, Q0_vars[i]: 607.8653\n",
      "f_train: -1.307873362141563, F_train: 0.21284292517576947, Q0_train: 607.8652588544351\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 127.19957291693557, Left1: 1.1627043932094239e-05\n",
      "f_vars[i]: -1.2368, F_vars[i]: 0.2250, Q0_vars[i]: 642.5685\n",
      "f_train: -1.236795791587516, F_train: 0.22499421700376376, Q0_train: 642.5685413165594\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 144.18048642484086, Left1: 9.580672798588722\n",
      "f_vars[i]: -1.1709, F_vars[i]: 0.2367, Q0_vars[i]: 675.9794\n",
      "f_train: -1.1708964803631476, F_train: 0.23669297946191004, Q0_train: 675.9794299520403\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 123.75496825780125, Left1: 0.32238004050852\n",
      "f_vars[i]: -1.2719, F_vars[i]: 0.2189, Q0_vars[i]: 625.2677\n",
      "f_train: -1.2718754767385783, F_train: 0.21893637044452863, Q0_train: 625.2677338605964\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 136.65670148969326, Left1: 6.235968206699624\n",
      "f_vars[i]: -1.2120, F_vars[i]: 0.2293, Q0_vars[i]: 654.9930\n",
      "f_train: -1.2120155634551661, F_train: 0.22934461453193802, Q0_train: 654.992987735906\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 136.58738258409895, Left1: 15.50062104111558\n",
      "f_vars[i]: -1.2994, F_vars[i]: 0.2143, Q0_vars[i]: 611.9398\n",
      "f_train: -1.299378534192495, F_train: 0.21426962721442563, Q0_train: 611.9398251258754\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 125.65670183626864, Left1: 1.65677231195545\n",
      "f_vars[i]: -1.2701, F_vars[i]: 0.2192, Q0_vars[i]: 626.1324\n",
      "f_train: -1.27010593745824, F_train: 0.21923911788133277, Q0_train: 626.1323604338711\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 131.6986915744962, Left1: 11.328259725852945\n",
      "f_vars[i]: -1.3029, F_vars[i]: 0.2137, Q0_vars[i]: 610.2442\n",
      "f_train: -1.302908702148119, F_train: 0.2136758941548732, Q0_train: 610.2441629391373\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 143.67436802535698, Left1: 7.800412765471066\n",
      "f_vars[i]: -1.1546, F_vars[i]: 0.2397, Q0_vars[i]: 684.4461\n",
      "f_train: -1.1545577189410965, F_train: 0.2396575819930386, Q0_train: 684.446137894044\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 124.47878236057117, Left1: 0.0002929853125408499\n",
      "f_vars[i]: -1.2666, F_vars[i]: 0.2198, Q0_vars[i]: 627.8303\n",
      "f_train: -1.2666361302062379, F_train: 0.21983363490672841, Q0_train: 627.8302615749922\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 132.70257434822503, Left1: 5.7955383660111295\n",
      "f_vars[i]: -1.2419, F_vars[i]: 0.2241, Q0_vars[i]: 640.0446\n",
      "f_train: -1.2418710956286716, F_train: 0.22411046239140447, Q0_train: 640.0445968360842\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 139.250879439839, Left1: 0.6892529586134231\n",
      "f_vars[i]: -1.1345, F_vars[i]: 0.2433, Q0_vars[i]: 694.9238\n",
      "f_train: -1.1345285921044774, F_train: 0.24332633385330898, Q0_train: 694.9238495557038\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 134.0885944017601, Left1: 0.00030486991244060846\n",
      "f_vars[i]: -1.1777, F_vars[i]: 0.2355, Q0_vars[i]: 672.4714\n",
      "f_train: -1.1777075026730355, F_train: 0.23546464369330647, Q0_train: 672.4713845738547\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 132.6112059802555, Left1: 11.974425511438454\n",
      "f_vars[i]: -1.3050, F_vars[i]: 0.2133, Q0_vars[i]: 609.2648\n",
      "f_train: -1.30495079231979, F_train: 0.21333298583180874, Q0_train: 609.2648395418912\n",
      "f_train, F_train, Q0_train 都相等\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R(T)</th>\n",
       "      <th>R</th>\n",
       "      <th>average_profits</th>\n",
       "      <th>average_losses</th>\n",
       "      <th>average_lefts</th>\n",
       "      <th>average_operation_profits</th>\n",
       "      <th>alpha_values</th>\n",
       "      <th>F_vars</th>\n",
       "      <th>f_vars</th>\n",
       "      <th>Q0_vars</th>\n",
       "      <th>Q1_vars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]</td>\n",
       "      <td>382424.840720</td>\n",
       "      <td>0.567764</td>\n",
       "      <td>80.669023</td>\n",
       "      <td>383247.991105</td>\n",
       "      <td>[-0.08506229453659969, 0.0, -0.011624478377526...</td>\n",
       "      <td>[0.1781105730328313, 0.1497272041689715, 0.185...</td>\n",
       "      <td>[-1.5292013146935068, -1.7367422347758308, -1....</td>\n",
       "      <td>[508.6719677992808, 427.61095133682153, 530.81...</td>\n",
       "      <td>[179.69265890141008, 174.8700430514224, 111.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]</td>\n",
       "      <td>381485.592833</td>\n",
       "      <td>0.545828</td>\n",
       "      <td>253.097782</td>\n",
       "      <td>383261.152962</td>\n",
       "      <td>[-0.0011437656197090139, 0.1632658653254987, -...</td>\n",
       "      <td>[0.1822110610427533, 0.213692974832872, 0.2006...</td>\n",
       "      <td>[-1.5014385912439732, -1.30280704560316, -1.38...</td>\n",
       "      <td>[520.3826892316346, 610.2929442211299, 572.958...</td>\n",
       "      <td>[167.98193748925348, 0.0, 68.9349170127751, 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]</td>\n",
       "      <td>381336.528665</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>139.194362</td>\n",
       "      <td>383588.649771</td>\n",
       "      <td>[-0.0015991377508715243, -1.2032449666440252, ...</td>\n",
       "      <td>[0.24167268734385736, 0.21284291324079518, 0.2...</td>\n",
       "      <td>[-1.1435305709814743, -1.3078733659291804, -1....</td>\n",
       "      <td>[690.2011449476392, 607.8652247689411, 642.568...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]</td>\n",
       "      <td>381186.237569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>204.073323</td>\n",
       "      <td>383588.649771</td>\n",
       "      <td>[-0.002125561817740077, -1.2046857160931923, 0...</td>\n",
       "      <td>[0.24217211783301318, 0.2126956370970533, 0.22...</td>\n",
       "      <td>[-1.140807587393065, -1.3087527017792058, -1.2...</td>\n",
       "      <td>[691.6274852562015, 607.4446138834028, 643.407...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>380878.046401</td>\n",
       "      <td>0.518077</td>\n",
       "      <td>451.391513</td>\n",
       "      <td>383277.803513</td>\n",
       "      <td>[-0.0030949816573411226, -2.598102514864877, 0...</td>\n",
       "      <td>[0.24194479457186654, 0.2077669042950354, 0.22...</td>\n",
       "      <td>[-1.1420466348413532, -1.338438862398567, -1.2...</td>\n",
       "      <td>[690.9782651194907, 593.3684803306958, 635.483...</td>\n",
       "      <td>[0.0, 24.042957533156393, 13.327233357065273, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]</td>\n",
       "      <td>380366.251150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>400.468863</td>\n",
       "      <td>383588.649771</td>\n",
       "      <td>[0.0007044179842762471, -1.1895857102365583, 0...</td>\n",
       "      <td>[0.2408971141882399, 0.21492650257986898, 0.22...</td>\n",
       "      <td>[-1.1477672186181571, -1.2954812141974694, -1....</td>\n",
       "      <td>[687.9861595230092, 613.8158175447944, 642.976...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>378550.737367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>535.622744</td>\n",
       "      <td>383588.649771</td>\n",
       "      <td>[-0.0008425558155421423, -2.355718094714057, 0...</td>\n",
       "      <td>[0.24268303594897267, 0.21541143181171837, 0.2...</td>\n",
       "      <td>[-1.138025663482888, -1.2926096276357095, -1.2...</td>\n",
       "      <td>[693.0866334639921, 615.2007432255555, 647.406...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>376519.869499</td>\n",
       "      <td>0.779245</td>\n",
       "      <td>537.496790</td>\n",
       "      <td>383121.103039</td>\n",
       "      <td>[0.014318693191869875, -5.015606833388553, 0.0...</td>\n",
       "      <td>[0.24074003010421136, 0.1757345288203348, 0.19...</td>\n",
       "      <td>[-1.1486279599724263, -1.5455181409396475, -1....</td>\n",
       "      <td>[687.5375378113828, 501.8861433276146, 559.956...</td>\n",
       "      <td>[0.0, 117.83982955933664, 112.3021681092315, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R(T)                                              R  average_profits  \\\n",
       "5     7  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]    382424.840720   \n",
       "4     6  [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]    381485.592833   \n",
       "7     9  [7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]    381336.528665   \n",
       "6     8  [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]    381186.237569   \n",
       "2     4  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]    380878.046401   \n",
       "3     5  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]    380366.251150   \n",
       "1     3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]    378550.737367   \n",
       "0     2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]    376519.869499   \n",
       "\n",
       "   average_losses  average_lefts  average_operation_profits  \\\n",
       "5        0.567764      80.669023              383247.991105   \n",
       "4        0.545828     253.097782              383261.152962   \n",
       "7        0.000000     139.194362              383588.649771   \n",
       "6        0.000000     204.073323              383588.649771   \n",
       "2        0.518077     451.391513              383277.803513   \n",
       "3        0.000000     400.468863              383588.649771   \n",
       "1        0.000000     535.622744              383588.649771   \n",
       "0        0.779245     537.496790              383121.103039   \n",
       "\n",
       "                                        alpha_values  \\\n",
       "5  [-0.08506229453659969, 0.0, -0.011624478377526...   \n",
       "4  [-0.0011437656197090139, 0.1632658653254987, -...   \n",
       "7  [-0.0015991377508715243, -1.2032449666440252, ...   \n",
       "6  [-0.002125561817740077, -1.2046857160931923, 0...   \n",
       "2  [-0.0030949816573411226, -2.598102514864877, 0...   \n",
       "3  [0.0007044179842762471, -1.1895857102365583, 0...   \n",
       "1  [-0.0008425558155421423, -2.355718094714057, 0...   \n",
       "0  [0.014318693191869875, -5.015606833388553, 0.0...   \n",
       "\n",
       "                                              F_vars  \\\n",
       "5  [0.1781105730328313, 0.1497272041689715, 0.185...   \n",
       "4  [0.1822110610427533, 0.213692974832872, 0.2006...   \n",
       "7  [0.24167268734385736, 0.21284291324079518, 0.2...   \n",
       "6  [0.24217211783301318, 0.2126956370970533, 0.22...   \n",
       "2  [0.24194479457186654, 0.2077669042950354, 0.22...   \n",
       "3  [0.2408971141882399, 0.21492650257986898, 0.22...   \n",
       "1  [0.24268303594897267, 0.21541143181171837, 0.2...   \n",
       "0  [0.24074003010421136, 0.1757345288203348, 0.19...   \n",
       "\n",
       "                                              f_vars  \\\n",
       "5  [-1.5292013146935068, -1.7367422347758308, -1....   \n",
       "4  [-1.5014385912439732, -1.30280704560316, -1.38...   \n",
       "7  [-1.1435305709814743, -1.3078733659291804, -1....   \n",
       "6  [-1.140807587393065, -1.3087527017792058, -1.2...   \n",
       "2  [-1.1420466348413532, -1.338438862398567, -1.2...   \n",
       "3  [-1.1477672186181571, -1.2954812141974694, -1....   \n",
       "1  [-1.138025663482888, -1.2926096276357095, -1.2...   \n",
       "0  [-1.1486279599724263, -1.5455181409396475, -1....   \n",
       "\n",
       "                                             Q0_vars  \\\n",
       "5  [508.6719677992808, 427.61095133682153, 530.81...   \n",
       "4  [520.3826892316346, 610.2929442211299, 572.958...   \n",
       "7  [690.2011449476392, 607.8652247689411, 642.568...   \n",
       "6  [691.6274852562015, 607.4446138834028, 643.407...   \n",
       "2  [690.9782651194907, 593.3684803306958, 635.483...   \n",
       "3  [687.9861595230092, 613.8158175447944, 642.976...   \n",
       "1  [693.0866334639921, 615.2007432255555, 647.406...   \n",
       "0  [687.5375378113828, 501.8861433276146, 559.956...   \n",
       "\n",
       "                                             Q1_vars  \n",
       "5  [179.69265890141008, 174.8700430514224, 111.07...  \n",
       "4  [167.98193748925348, 0.0, 68.9349170127751, 13...  \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 24.042957533156393, 13.327233357065273, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "0  [0.0, 117.83982955933664, 112.3021681092315, 0...  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_2, stimulation_results_df_2 = None, None\n",
    "results_df_2, stimulation_results_df_2 = grid_flexible_F_fixed_R(\n",
    "    assigned_Ts=ASSIGNED_TS,\n",
    "    salvage_value=salvage_value,\n",
    "    cost=cost,\n",
    "    price=price,\n",
    "    Q_star=Q_star,\n",
    "    demand_df_train=demand_df_test,\n",
    "    Qk_hat_df_train=Qk_hat_df_test,\n",
    "    training_df=testing_df,\n",
    ")\n",
    "\n",
    "results_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_vars 中有 -1 的個數： 0\n"
     ]
    }
   ],
   "source": [
    "num_neg_ones = results_df_2.iloc[0][\"F_vars\"].count(-1)\n",
    "print(\"F_vars 中有 -1 的個數：\", num_neg_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2113.3908546916105)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_star * 0.74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "      <th>sum_first_8</th>\n",
       "      <th>sum</th>\n",
       "      <th>Lost_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.625929</td>\n",
       "      <td>67.884966</td>\n",
       "      <td>68.750730</td>\n",
       "      <td>68.558033</td>\n",
       "      <td>74.175914</td>\n",
       "      <td>68.558033</td>\n",
       "      <td>65.559446</td>\n",
       "      <td>71.308420</td>\n",
       "      <td>68.558033</td>\n",
       "      <td>68.558033</td>\n",
       "      <td>550.421472</td>\n",
       "      <td>687.537538</td>\n",
       "      <td>41.749504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60.770111</td>\n",
       "      <td>61.058111</td>\n",
       "      <td>59.574148</td>\n",
       "      <td>60.117141</td>\n",
       "      <td>58.717761</td>\n",
       "      <td>60.117141</td>\n",
       "      <td>57.979551</td>\n",
       "      <td>58.390955</td>\n",
       "      <td>60.117144</td>\n",
       "      <td>60.117141</td>\n",
       "      <td>476.724919</td>\n",
       "      <td>596.959204</td>\n",
       "      <td>49.113967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.073532</td>\n",
       "      <td>64.930685</td>\n",
       "      <td>65.683239</td>\n",
       "      <td>63.599781</td>\n",
       "      <td>63.459309</td>\n",
       "      <td>63.599781</td>\n",
       "      <td>64.215938</td>\n",
       "      <td>63.806809</td>\n",
       "      <td>63.599781</td>\n",
       "      <td>63.599781</td>\n",
       "      <td>515.369074</td>\n",
       "      <td>642.568635</td>\n",
       "      <td>-15.446150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63.121389</td>\n",
       "      <td>66.381203</td>\n",
       "      <td>61.668540</td>\n",
       "      <td>67.299906</td>\n",
       "      <td>67.404706</td>\n",
       "      <td>67.299906</td>\n",
       "      <td>70.525694</td>\n",
       "      <td>68.097560</td>\n",
       "      <td>67.299908</td>\n",
       "      <td>67.299906</td>\n",
       "      <td>531.798904</td>\n",
       "      <td>666.398718</td>\n",
       "      <td>95.416609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64.915095</td>\n",
       "      <td>62.604395</td>\n",
       "      <td>65.471782</td>\n",
       "      <td>61.716297</td>\n",
       "      <td>63.127936</td>\n",
       "      <td>61.716297</td>\n",
       "      <td>61.250627</td>\n",
       "      <td>60.709187</td>\n",
       "      <td>61.716291</td>\n",
       "      <td>61.716297</td>\n",
       "      <td>501.511615</td>\n",
       "      <td>624.944204</td>\n",
       "      <td>-46.073506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   demand_t1  demand_t2  demand_t3  demand_t4  demand_t5  demand_t6  \\\n",
       "0  65.625929  67.884966  68.750730  68.558033  74.175914  68.558033   \n",
       "1  60.770111  61.058111  59.574148  60.117141  58.717761  60.117141   \n",
       "2  66.073532  64.930685  65.683239  63.599781  63.459309  63.599781   \n",
       "3  63.121389  66.381203  61.668540  67.299906  67.404706  67.299906   \n",
       "4  64.915095  62.604395  65.471782  61.716297  63.127936  61.716297   \n",
       "\n",
       "   demand_t7  demand_t8  demand_t9  demand_t10  sum_first_8         sum  \\\n",
       "0  65.559446  71.308420  68.558033   68.558033   550.421472  687.537538   \n",
       "1  57.979551  58.390955  60.117144   60.117141   476.724919  596.959204   \n",
       "2  64.215938  63.806809  63.599781   63.599781   515.369074  642.568635   \n",
       "3  70.525694  68.097560  67.299908   67.299906   531.798904  666.398718   \n",
       "4  61.250627  60.709187  61.716291   61.716297   501.511615  624.944204   \n",
       "\n",
       "      Lost_0  \n",
       "0  41.749504  \n",
       "1  49.113967  \n",
       "2 -15.446150  \n",
       "3  95.416609  \n",
       "4 -46.073506  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df_test_analysis = demand_df_test.copy()\n",
    "demand_df_test_analysis[\"sum_first_8\"] = demand_df_test_analysis.iloc[:, :8].sum(axis=1)\n",
    "demand_df_test_analysis[\"sum\"] = demand_df_test_analysis.iloc[:, :10].sum(axis=1)\n",
    "\n",
    "demand_df_test_analysis[\"Lost_0\"] = (\n",
    "    demand_df_test_analysis[\"sum_first_8\"] - results_df_2.iloc[0][\"Q0_vars\"]\n",
    ")\n",
    "demand_df_test_analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_t1</th>\n",
       "      <th>demand_t2</th>\n",
       "      <th>demand_t3</th>\n",
       "      <th>demand_t4</th>\n",
       "      <th>demand_t5</th>\n",
       "      <th>demand_t6</th>\n",
       "      <th>demand_t7</th>\n",
       "      <th>demand_t8</th>\n",
       "      <th>demand_t9</th>\n",
       "      <th>demand_t10</th>\n",
       "      <th>sum_first_8</th>\n",
       "      <th>sum</th>\n",
       "      <th>Lost_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.625929</td>\n",
       "      <td>67.884966</td>\n",
       "      <td>68.750730</td>\n",
       "      <td>68.558033</td>\n",
       "      <td>74.175914</td>\n",
       "      <td>68.558033</td>\n",
       "      <td>65.559446</td>\n",
       "      <td>71.308420</td>\n",
       "      <td>68.558033</td>\n",
       "      <td>68.558033</td>\n",
       "      <td>550.421472</td>\n",
       "      <td>687.537538</td>\n",
       "      <td>41.749504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60.770111</td>\n",
       "      <td>61.058111</td>\n",
       "      <td>59.574148</td>\n",
       "      <td>60.117141</td>\n",
       "      <td>58.717761</td>\n",
       "      <td>60.117141</td>\n",
       "      <td>57.979551</td>\n",
       "      <td>58.390955</td>\n",
       "      <td>60.117144</td>\n",
       "      <td>60.117141</td>\n",
       "      <td>476.724919</td>\n",
       "      <td>596.959204</td>\n",
       "      <td>49.113967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63.121389</td>\n",
       "      <td>66.381203</td>\n",
       "      <td>61.668540</td>\n",
       "      <td>67.299906</td>\n",
       "      <td>67.404706</td>\n",
       "      <td>67.299906</td>\n",
       "      <td>70.525694</td>\n",
       "      <td>68.097560</td>\n",
       "      <td>67.299908</td>\n",
       "      <td>67.299906</td>\n",
       "      <td>531.798904</td>\n",
       "      <td>666.398718</td>\n",
       "      <td>95.416609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>63.427651</td>\n",
       "      <td>63.458016</td>\n",
       "      <td>59.857699</td>\n",
       "      <td>65.210366</td>\n",
       "      <td>66.962546</td>\n",
       "      <td>65.210366</td>\n",
       "      <td>68.788190</td>\n",
       "      <td>65.421392</td>\n",
       "      <td>65.210367</td>\n",
       "      <td>65.210366</td>\n",
       "      <td>518.336226</td>\n",
       "      <td>648.756959</td>\n",
       "      <td>108.815992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60.438469</td>\n",
       "      <td>59.245399</td>\n",
       "      <td>60.450320</td>\n",
       "      <td>60.543380</td>\n",
       "      <td>56.855468</td>\n",
       "      <td>60.543380</td>\n",
       "      <td>59.175878</td>\n",
       "      <td>58.100125</td>\n",
       "      <td>60.543382</td>\n",
       "      <td>60.543380</td>\n",
       "      <td>475.352419</td>\n",
       "      <td>596.439180</td>\n",
       "      <td>40.084124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>62.564427</td>\n",
       "      <td>62.207089</td>\n",
       "      <td>62.998637</td>\n",
       "      <td>61.999965</td>\n",
       "      <td>61.345170</td>\n",
       "      <td>61.999965</td>\n",
       "      <td>64.147963</td>\n",
       "      <td>63.211996</td>\n",
       "      <td>61.999964</td>\n",
       "      <td>61.999965</td>\n",
       "      <td>500.475214</td>\n",
       "      <td>624.475143</td>\n",
       "      <td>33.153669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>66.947411</td>\n",
       "      <td>67.567002</td>\n",
       "      <td>67.449213</td>\n",
       "      <td>67.936977</td>\n",
       "      <td>72.133012</td>\n",
       "      <td>67.936977</td>\n",
       "      <td>64.609175</td>\n",
       "      <td>66.191955</td>\n",
       "      <td>67.936978</td>\n",
       "      <td>67.936977</td>\n",
       "      <td>540.771722</td>\n",
       "      <td>676.645677</td>\n",
       "      <td>14.575785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>65.746933</td>\n",
       "      <td>65.853934</td>\n",
       "      <td>70.574162</td>\n",
       "      <td>62.239247</td>\n",
       "      <td>55.130102</td>\n",
       "      <td>62.239247</td>\n",
       "      <td>57.888206</td>\n",
       "      <td>63.679955</td>\n",
       "      <td>62.239243</td>\n",
       "      <td>62.239247</td>\n",
       "      <td>503.351787</td>\n",
       "      <td>627.830276</td>\n",
       "      <td>58.019618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>61.329502</td>\n",
       "      <td>63.260741</td>\n",
       "      <td>60.017189</td>\n",
       "      <td>63.453517</td>\n",
       "      <td>66.141381</td>\n",
       "      <td>63.453517</td>\n",
       "      <td>65.584679</td>\n",
       "      <td>64.101433</td>\n",
       "      <td>63.453519</td>\n",
       "      <td>63.453517</td>\n",
       "      <td>507.341958</td>\n",
       "      <td>634.248994</td>\n",
       "      <td>27.277733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>66.822772</td>\n",
       "      <td>69.549069</td>\n",
       "      <td>66.237491</td>\n",
       "      <td>69.280813</td>\n",
       "      <td>70.547457</td>\n",
       "      <td>69.280813</td>\n",
       "      <td>70.842404</td>\n",
       "      <td>73.111604</td>\n",
       "      <td>69.280814</td>\n",
       "      <td>69.280813</td>\n",
       "      <td>555.672423</td>\n",
       "      <td>694.234050</td>\n",
       "      <td>143.954009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>62.577572</td>\n",
       "      <td>67.210049</td>\n",
       "      <td>65.172995</td>\n",
       "      <td>67.044144</td>\n",
       "      <td>70.357863</td>\n",
       "      <td>67.044144</td>\n",
       "      <td>68.535449</td>\n",
       "      <td>70.440907</td>\n",
       "      <td>67.044145</td>\n",
       "      <td>67.044144</td>\n",
       "      <td>538.383124</td>\n",
       "      <td>672.471413</td>\n",
       "      <td>138.976356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>59.277409</td>\n",
       "      <td>59.472203</td>\n",
       "      <td>62.933669</td>\n",
       "      <td>60.318389</td>\n",
       "      <td>57.697020</td>\n",
       "      <td>60.318389</td>\n",
       "      <td>59.467526</td>\n",
       "      <td>57.168997</td>\n",
       "      <td>60.318390</td>\n",
       "      <td>60.318390</td>\n",
       "      <td>476.653603</td>\n",
       "      <td>597.290383</td>\n",
       "      <td>66.208561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    demand_t1  demand_t2  demand_t3  demand_t4  demand_t5  demand_t6  \\\n",
       "0   65.625929  67.884966  68.750730  68.558033  74.175914  68.558033   \n",
       "1   60.770111  61.058111  59.574148  60.117141  58.717761  60.117141   \n",
       "3   63.121389  66.381203  61.668540  67.299906  67.404706  67.299906   \n",
       "5   63.427651  63.458016  59.857699  65.210366  66.962546  65.210366   \n",
       "6   60.438469  59.245399  60.450320  60.543380  56.855468  60.543380   \n",
       "7   62.564427  62.207089  62.998637  61.999965  61.345170  61.999965   \n",
       "9   66.947411  67.567002  67.449213  67.936977  72.133012  67.936977   \n",
       "10  65.746933  65.853934  70.574162  62.239247  55.130102  62.239247   \n",
       "11  61.329502  63.260741  60.017189  63.453517  66.141381  63.453517   \n",
       "12  66.822772  69.549069  66.237491  69.280813  70.547457  69.280813   \n",
       "13  62.577572  67.210049  65.172995  67.044144  70.357863  67.044144   \n",
       "14  59.277409  59.472203  62.933669  60.318389  57.697020  60.318389   \n",
       "\n",
       "    demand_t7  demand_t8  demand_t9  demand_t10  sum_first_8         sum  \\\n",
       "0   65.559446  71.308420  68.558033   68.558033   550.421472  687.537538   \n",
       "1   57.979551  58.390955  60.117144   60.117141   476.724919  596.959204   \n",
       "3   70.525694  68.097560  67.299908   67.299906   531.798904  666.398718   \n",
       "5   68.788190  65.421392  65.210367   65.210366   518.336226  648.756959   \n",
       "6   59.175878  58.100125  60.543382   60.543380   475.352419  596.439180   \n",
       "7   64.147963  63.211996  61.999964   61.999965   500.475214  624.475143   \n",
       "9   64.609175  66.191955  67.936978   67.936977   540.771722  676.645677   \n",
       "10  57.888206  63.679955  62.239243   62.239247   503.351787  627.830276   \n",
       "11  65.584679  64.101433  63.453519   63.453517   507.341958  634.248994   \n",
       "12  70.842404  73.111604  69.280814   69.280813   555.672423  694.234050   \n",
       "13  68.535449  70.440907  67.044145   67.044144   538.383124  672.471413   \n",
       "14  59.467526  57.168997  60.318390   60.318390   476.653603  597.290383   \n",
       "\n",
       "        Lost_0  \n",
       "0    41.749504  \n",
       "1    49.113967  \n",
       "3    95.416609  \n",
       "5   108.815992  \n",
       "6    40.084124  \n",
       "7    33.153669  \n",
       "9    14.575785  \n",
       "10   58.019618  \n",
       "11   27.277733  \n",
       "12  143.954009  \n",
       "13  138.976356  \n",
       "14   66.208561  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_df_test_analysis[demand_df_test_analysis[\"Lost_0\"] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R(T)                                                                         7\n",
       "R                                [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
       "average_profits                                                   382424.84072\n",
       "average_losses                                                        0.567764\n",
       "average_lefts                                                        80.669023\n",
       "average_operation_profits                                        383247.991105\n",
       "alpha_values                 [-0.08506229453659969, 0.0, -0.011624478377526...\n",
       "F_vars                       [0.1781105730328313, 0.1497272041689715, 0.185...\n",
       "f_vars                       [-1.5292013146935068, -1.7367422347758308, -1....\n",
       "Q0_vars                      [508.6719677992808, 427.61095133682153, 530.81...\n",
       "Q1_vars                      [179.69265890141008, 174.8700430514224, 111.07...\n",
       "Name: 5, dtype: object"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demand_df_test_analysis.head()\n",
    "results_df_2.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08506229,  0.        , -0.01162448,  0.60724656])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_values = results_df_2.iloc[0][\"alpha_values\"]\n",
    "alpha_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++++++++++++++++++++++ THis is R=0 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0x7c7e00e0\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [3e+02, 3e+03]\n",
      "Presolve removed 62 rows and 97 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 231 rows, 167 columns, 612 nonzeros\n",
      "Presolved model has 41 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 126 continuous, 41 integer (41 binary)\n",
      "\n",
      "Root relaxation: objective 2.533262e+07, 85 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5333e+07    0   21          - 2.5333e+07      -     -    0s\n",
      "H    0     0                    2.524373e+07 2.5333e+07  0.35%     -    0s\n",
      "\n",
      "Explored 1 nodes (85 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.52437e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.524373243406e+07, best bound 2.533261583285e+07, gap 0.3521%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1144.0301924086202, Left1: 36.98013902744424\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1147.2146401786881, Left1: 17.658839232383343\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 23.95013703959512, Left0: 1147.1565240677305, Left1: 0.0\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1145.2760988103475, Left1: 1.1929361545380743\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 18.528398860166362, Left0: 1158.1720475343188, Left1: 0.0\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 27.037615877432472, Left0: 1135.8255066678205, Left1: 0.0\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 10.330585983076162, Left0: 1159.671523872997, Left1: 0.0\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1153.6823448104933, Left1: 5.711934684320568\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1132.405117791089, Left1: 18.63196479163662\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1136.3940269564055, Left1: 9.624653434906463\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1138.6077483185654, Left1: 35.72398762633202\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1168.8809024505395, Left1: 24.802197373810486\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 9.196225102519747, Left0: 1133.2631837868332, Left1: 0.0\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 1139.7578512715843, Left1: 24.290380924166584\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 6.286913241360708, Left0: 1129.9952670164112, Left1: 0.0\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=1 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0x3d42e3d0\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [5e+02, 2e+03]\n",
      "Presolve removed 55 rows and 83 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 238 rows, 181 columns, 635 nonzeros\n",
      "Presolved model has 47 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 134 continuous, 47 integer (47 binary)\n",
      "\n",
      "Root relaxation: objective 2.540762e+07, 89 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5408e+07    0   25          - 2.5408e+07      -     -    0s\n",
      "H    0     0                    2.538804e+07 2.5408e+07  0.08%     -    0s\n",
      "\n",
      "Explored 1 nodes (89 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.5388e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.538804436055e+07, best bound 2.540761695120e+07, gap 0.0771%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 864.4865541859278, Left1: 1.3320266561004246\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 868.4983776614915, Left1: 4.179683795642177\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.494361096698867, Left0: 864.4964830017955, Left1: 0.0\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 862.6709352896246, Left1: 3.807774725669333\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 886.6011257255556, Left1: 6.702636206273837\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.845951177695952, Left0: 840.99817687566, Left1: 0.0\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 891.2934302117237, Left1: 0.8369143515910764\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 8.565508626538758, Left0: 881.8890984342389, Left1: 0.0\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 837.8089499887839, Left1: 7.223925849980674\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 2.422123780279776, Left0: 846.0843275265487, Left1: 0.0\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.5955094169944459, Left0: 853.4133191802168, Left1: 0.0\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 913.8695579373602, Left1: 4.161348693608943\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.6376606011212971, Left0: 837.2890530897555, Left1: 0.0\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 854.0457861906891, Left1: 3.1138721000688747\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 830.0529166697116, Left1: 6.785318866206467\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=2 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0x9b436c22\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [8e+02, 2e+03]\n",
      "Presolve removed 55 rows and 83 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 238 rows, 181 columns, 635 nonzeros\n",
      "Presolved model has 47 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 134 continuous, 47 integer (47 binary)\n",
      "\n",
      "Root relaxation: objective 2.540750e+07, 88 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5407e+07    0   25          - 2.5407e+07      -     -    0s\n",
      "H    0     0                    2.538780e+07 2.5407e+07  0.08%     -    0s\n",
      "\n",
      "Explored 1 nodes (88 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.53878e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.538779517723e+07, best bound 2.540749947467e+07, gap 0.0776%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 579.4091854544656, Left1: 1.68947841768113\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 583.9436705857113, Left1: 4.8213623977098905\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.8577910975725445, Left0: 582.7030768508378, Left1: 0.0\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 578.1691287192477, Left1: 3.813188306363827\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 616.030079611496, Left1: 6.410200259288558\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.772083398577934, Left0: 544.6343068433034, Left1: 0.0\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 619.0042413332005, Left1: 1.3892546520169162\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 8.244358266108293, Left0: 605.9973084332223, Left1: 0.0\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 542.4627819542546, Left1: 6.809544179941099\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.163746740711872, Left0: 556.746526959222, Left1: 0.0\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.26522495544145386, Left0: 562.6602909033318, Left1: 0.0\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 658.8280233034043, Left1: 3.6910013991214328\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.43514190700898325, Left0: 538.4152603818297, Left1: 0.0\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 568.7419324855722, Left1: 2.413551467104867\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 526.2879501025548, Left1: 7.197183447751286\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=3 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0xc60b9deb\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 2e+03]\n",
      "Presolve removed 52 rows and 65 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 241 rows, 199 columns, 647 nonzeros\n",
      "Presolved model has 62 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 137 continuous, 62 integer (62 binary)\n",
      "\n",
      "Root relaxation: objective 2.540750e+07, 97 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5407e+07    0   27          - 2.5407e+07      -     -    0s\n",
      "H    0     0                    2.538780e+07 2.5407e+07  0.08%     -    0s\n",
      "\n",
      "Explored 1 nodes (97 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.53878e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.538779517814e+07, best bound 2.540749947535e+07, gap 0.0776%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 299.86554739244843, Left1: 1.6894780642987826\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 305.227408142747, Left1: 4.821362451086316\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.8577912144401125, Left0: 300.0430358585686, Left1: 0.0\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 295.5639652290297, Left1: 3.8131884187764626\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 344.45915784976887, Left1: 6.410200437845106\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 4.7720833550229145, Left0: 249.8069770529553, Left1: 0.0\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 350.6261478289755, Left1: 1.3892544946247654\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 8.24435831686128, Left0: 334.2040621734052, Left1: 0.0\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 247.86661418351878, Left1: 6.8095440614731615\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 3.1637465616656755, Left0: 266.4368275001914, Left1: 0.0\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.26522452100493865, Left0: 277.46586172172465, Left1: 0.0\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 403.81667892813675, Left1: 3.691001444572521\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.43514184545324497, Left0: 242.44112968216905, Left1: 0.0\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 283.02986749600404, Left1: 2.413551206114107\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 226.34559978329753, Left1: 7.197183336380476\n",
      "f_train: 0.0, F_train: 0.5, Q0_train: 1427.9667937105476\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=4 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0xa5ed6f9b\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 1e+03]\n",
      "Presolve removed 56 rows and 73 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 237 rows, 191 columns, 639 nonzeros\n",
      "Presolved model has 58 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 133 continuous, 58 integer (58 binary)\n",
      "\n",
      "Root relaxation: objective 2.541313e+07, 91 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5413e+07    0   25          - 2.5413e+07      -     -    0s\n",
      "H    0     0                    2.501788e+07 2.5413e+07  1.58%     -    0s\n",
      "     0     2 2.5413e+07    0   27 2.5018e+07 2.5413e+07  1.58%     -    0s\n",
      "H   36    22                    2.540086e+07 2.5409e+07  0.03%  10.6    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Cover: 1\n",
      "  Implied bound: 9\n",
      "\n",
      "Explored 47 nodes (519 simplex iterations) in 0.03 seconds (0.03 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 2.54009e+07 2.50179e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.540086165798e+07, best bound 2.540907229301e+07, gap 0.0323%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.0442706266182995, Left0: 0.0, Left1: 0.0\n",
      "f_train: -0.032123847918444026, F_train: 0.49196972857277776, Q0_train: 1405.0328718254357\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.081484115484246, Left1: 3.9735896354927718\n",
      "f_train: -0.026789362055680055, F_train: 0.49330305999732205, Q0_train: 1408.8407778239557\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 0.2542948950626851\n",
      "f_train: -0.02251727824615979, F_train: 0.4943709182782028, Q0_train: 1411.8905101549287\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.764879186039707, Left1: 1.4142064545967514\n",
      "f_train: -0.007753553922643652, F_train: 0.4980616212302191, Q0_train: 1422.4309126767862\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 25.73120573232177, Left1: 2.2199238035420876\n",
      "f_train: -0.07071726002291134, F_train: 0.48232804906424753, Q0_train: 1377.4968754778745\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 6.14495849748483, Left1: 1.208751934558677\n",
      "f_train: 0.07563218315967224, F_train: 0.5188990377496455, Q0_train: 1481.9411903896994\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 31.890054445462813, Left1: 1.0641162352530955\n",
      "f_train: -0.07240663864936203, F_train: 0.4819062446900743, Q0_train: 1376.292230198352\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 6.797781953293452, Left0: 18.0125701842548, Left1: 0.0\n",
      "f_train: -0.06330559620413179, F_train: 0.48417888431938677, Q0_train: 1382.7827380478097\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.980679405658884, Left1: 7.57986390964993\n",
      "f_train: 0.07148234237746265, F_train: 0.5178629799986897, Q0_train: 1478.9822782602366\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 5.026929325021456, Left0: 21.867347607356802, Left1: 0.0\n",
      "f_train: 0.0608189783600086, F_train: 0.5152000595261795, Q0_train: 1471.3771542421637\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 2.601641160733152\n",
      "f_train: 0.010784810222653318, F_train: 0.5026961764225452, Q0_train: 1435.6668945133072\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 21.85560591878084, Left1: 3.9287458972503373\n",
      "f_train: -0.18146370864474792, F_train: 0.4547581524499312, Q0_train: 1298.7590817353212\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.7437060145430223, Left0: 23.385195898975805, Left1: 0.0\n",
      "f_train: 0.10611484966197593, F_train: 0.5265038468407276, Q0_train: 1503.660020098846\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 21.09474529472054, Left1: 0.6543544472428948\n",
      "f_train: 0.02973949199711834, F_train: 0.5074343250744378, Q0_train: 1449.1987323904411\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 8.966909915220242, Left1: 2.0456162854748072\n",
      "f_train: 0.11153262776633999, F_train: 0.5278542884117062, Q0_train: 1507.5167915392535\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=5 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0x29cda3b0\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [1e+03, 2e+03]\n",
      "Presolve removed 56 rows and 73 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 237 rows, 191 columns, 639 nonzeros\n",
      "Presolved model has 58 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 133 continuous, 58 integer (58 binary)\n",
      "\n",
      "Root relaxation: objective 2.541313e+07, 91 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5413e+07    0   25          - 2.5413e+07      -     -    0s\n",
      "H    0     0                    1.898036e+07 2.5413e+07  33.9%     -    0s\n",
      "     0     2 2.5413e+07    0   23 1.8980e+07 2.5413e+07  33.9%     -    0s\n",
      "H   11     8                    2.540086e+07 2.5410e+07  0.04%   3.9    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 7\n",
      "\n",
      "Explored 15 nodes (154 simplex iterations) in 0.02 seconds (0.02 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 2.54009e+07 1.89804e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.540086165029e+07, best bound 2.540907229446e+07, gap 0.0323%\n",
      "Model status: 2\n",
      "Lost0: 0.0, Lost1: 0.04427070108886255, Left0: 0.0, Left1: 0.0\n",
      "f_train: 0.363351188895233, F_train: 0.5898514196403374, Q0_train: 1684.5764809388545\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.126535630824947, Left1: 3.973589645122729\n",
      "f_train: 0.3677319411655908, F_train: 0.5909108219858813, Q0_train: 1687.602063680086\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 0.25429486149232616\n",
      "f_train: 0.37780593320713596, F_train: 0.5933438118998666, Q0_train: 1694.5505212932935\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 9.81405485966502, Left1: 1.414206508322195\n",
      "f_train: 0.3931157152912994, F_train: 0.5970325187783241, Q0_train: 1705.0852231616313\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 25.437526863424935, Left1: 2.2199238678498006\n",
      "f_train: 0.311761959967491, F_train: 0.5773152772085405, Q0_train: 1648.774090711191\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 5.365821076855861, Left1: 1.2087519381427683\n",
      "f_train: 0.4974482463139913, F_train: 0.6218594724910351, Q0_train: 1775.9893541431118\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 31.593009645905795, Left1: 1.0641161758576345\n",
      "f_train: 0.30545024867741066, F_train: 0.5757743317472364, Q0_train: 1644.3732528118685\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 6.797781960631028, Left0: 17.811721518430204, Left1: 0.0\n",
      "f_train: 0.31980391286927423, F_train: 0.5792764634691976, Q0_train: 1654.3751084241903\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 4.263806064464848, Left1: 7.579863854253517\n",
      "f_train: 0.49279344455638396, F_train: 0.620764275352724, Q0_train: 1772.8615438509617\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 5.026929269582297, Left0: 21.437976405605806, Left1: 0.0\n",
      "f_train: 0.4755694670540622, F_train: 0.6167011245690621, Q0_train: 1761.2574550571453\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 2.6016412696092175\n",
      "f_train: 0.4161285758318165, F_train: 0.6025564819327652, Q0_train: 1720.8612950700765\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 19.072250252164167, Left1: 3.928745897847307\n",
      "f_train: 0.1727294527929859, F_train: 0.5430753187392917, Q0_train: 1550.98704328696\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 1.7437060246500096, Left0: 22.08212219576034, Left1: 0.0\n",
      "f_train: 0.5308544513260709, F_train: 0.6296823771154634, Q0_train: 1798.3310502112083\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 21.032144819721783, Left1: 0.654354382480733\n",
      "f_train: 0.4366225599781739, F_train: 0.607453960798842, Q0_train: 1734.84816945739\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 7.355003091592702, Left1: 2.045616279306614\n",
      "f_train: 0.5421574199379702, F_train: 0.6323141457254511, Q0_train: 1805.8472065787926\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=6 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0x61b0fa0c\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [8e+02, 2e+03]\n",
      "Presolve removed 53 rows and 91 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 240 rows, 173 columns, 650 nonzeros\n",
      "Presolved model has 37 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 136 continuous, 37 integer (37 binary)\n",
      "\n",
      "Root relaxation: objective 2.541692e+07, 87 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.5417e+07    0   21          - 2.5417e+07      -     -    0s\n",
      "H    0     0                    1.223711e+07 2.5416e+07   108%     -    0s\n",
      "     0     2 2.5416e+07    0   21 1.2237e+07 2.5416e+07   108%     -    0s\n",
      "H   63    74                    2.527288e+07 2.5414e+07  0.56%   4.3    0s\n",
      "\n",
      "Explored 87 nodes (445 simplex iterations) in 0.04 seconds (0.03 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 2.52729e+07 1.22371e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.527288392557e+07, best bound 2.541428588554e+07, gap 0.5595%\n",
      "Model status: 2\n",
      "Lost0: 8.78183542565577, Lost1: 0.0, Left0: 0.0, Left1: 11.536860989102479\n",
      "f_train: 0.7751852996363833, F_train: 0.6846415092758438, Q0_train: 1955.2906816835534\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.8845924019144604, Lost1: 0.0, Left0: 0.0, Left1: 4.644939883719871\n",
      "f_train: 0.7627590178826651, F_train: 0.6819524464822724, Q0_train: 1947.6108969327086\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 1.303397792219016\n",
      "f_train: 0.813296317509729, F_train: 0.6928114844147251, Q0_train: 1978.62358809108\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.6891160780118687, Lost1: 0.0, Left0: 0.0, Left1: 1.6097578430203612\n",
      "f_train: 0.8082538933002419, F_train: 0.6917372947875802, Q0_train: 1975.5557738556574\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.0, Lost1: 0.0, Left0: 0.0, Left1: 2.9510728650883493\n",
      "f_train: 0.6817887720292481, F_train: 0.6641378157830808, Q0_train: 1896.7334947713846\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 5.146342113285126, Lost1: 0.0, Left0: 0.0, Left1: 4.862354013043213\n",
      "f_train: 0.9443401292512692, F_train: 0.7199755090602376, Q0_train: 2056.202238445733\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 6.810647606232111, Lost1: 0.0, Left0: 0.0, Left1: 7.191006168422973\n",
      "f_train: 0.6403565655308845, F_train: 0.654834058283584, Q0_train: 1870.1625812393504\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 10.61396159246895, Lost1: 0.0, Left0: 0.0, Left1: 5.846958419859675\n",
      "f_train: 0.6825386110466161, F_train: 0.6643050533666385, Q0_train: 1897.211114203346\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 7.396487331963272, Lost1: 0.0, Left0: 0.0, Left1: 14.118112711865733\n",
      "f_train: 0.9425194032043285, F_train: 0.7196082840923861, Q0_train: 2055.153468325907\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 11.876938585234939, Lost1: 0.0, Left0: 0.0, Left1: 10.309527911012866\n",
      "f_train: 0.889352986021664, F_train: 0.7087566335501074, Q0_train: 2024.1618750632567\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 8.958240683067713, Lost1: 0.0, Left0: 0.0, Left1: 10.777832411609749\n",
      "f_train: 0.8368281769654811, F_train: 0.6977967731893838, Q0_train: 1992.861241745621\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 11.623493588401653, Lost1: 0.0, Left0: 0.0, Left1: 13.717002711491432\n",
      "f_train: 0.4967549911813749, F_train: 0.621696439593698, Q0_train: 1775.5237430157522\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 11.935993664469091, Lost1: 0.0, Left0: 0.0, Left1: 12.268455059634956\n",
      "f_train: 0.9504761680072242, F_train: 0.7212109291723702, Q0_train: 2059.7305162385487\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 3.651982704205693, Lost1: 0.0, Left0: 0.0, Left1: 0.0\n",
      "f_train: 0.8380769089811597, F_train: 0.6980600362880919, Q0_train: 1993.61310367155\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 3.9426418490852484, Lost1: 0.0, Left0: 0.0, Left1: 3.6532290150513202\n",
      "f_train: 1.0009990365699997, F_train: 0.7312549557941651, Q0_train: 2088.415589220684\n",
      "f_train, F_train, Q0_train 都相等\n",
      "+++++++++++++++++++++++++++++++++++++++ THis is R=7 +++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Set parameter Threads to value 12\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter TimeLimit to value 20000\n",
      "Set parameter NonConvex to value 2\n",
      "Set parameter IntFeasTol to value 1e-09\n",
      "Set parameter NumericFocus to value 3\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: to let Gurobi read it back, use rlp format\n",
      "Warning: variables 188 and 190 have the same name \"Left_0_aux_0\"\n",
      "Warning: default variable names used to write mps file\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Academic license 2563044 - for non-commercial use only - registered to 11___@g.nccu.edu.tw\n",
      "Optimize a model with 173 rows, 263 columns and 451 nonzeros\n",
      "Model fingerprint: 0x7dc4f434\n",
      "Model has 120 general constraints\n",
      "Variable types: 263 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e-01, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+03]\n",
      "  RHS range        [1e+00, 3e+03]\n",
      "  GenCon const rng [5e+02, 2e+03]\n",
      "Presolve removed 53 rows and 90 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 240 rows, 174 columns, 639 nonzeros\n",
      "Presolved model has 38 SOS constraint(s)\n",
      "Presolved model has 15 nonlinear constraint(s)\n",
      "Warning: Model contains variables with very large bounds participating\n",
      "         in nonlinear terms.\n",
      "         Presolve was not able to compute smaller bounds for these variables.\n",
      "         Consider bounding these variables or reformulating the model.\n",
      "\n",
      "\n",
      "Solving non-convex MINLP\n",
      "\n",
      "Variable types: 136 continuous, 38 integer (38 binary)\n",
      "Found heuristic solution: objective 2.524514e+07\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 2.52451e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.524514127959e+07, best bound 2.542797509868e+07, gap 0.7242%\n",
      "Model status: 2\n",
      "Lost0: 10.014793751860907, Lost1: 0.0, Left0: 0.0, Left1: 10.014794055471384\n",
      "f_train: 1.2735057752192374, F_train: 0.7813422881235575, Q0_train: 2231.4616839245186\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.19434734856668, Lost1: 0.0, Left0: 0.0, Left1: 2.194347591066048\n",
      "f_train: 1.2639080959099358, F_train: 0.7796981310568509, Q0_train: 2226.7660805347155\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 8.019705899363451, Lost1: 0.0, Left0: 0.0, Left1: 8.019706174674411\n",
      "f_train: 1.3229970866771303, F_train: 0.7896799114746096, Q0_train: 2255.2733824920547\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.2548893336885874e-06, Lost1: 0.0, Left0: 0.0, Left1: 1.4747593013453297e-06\n",
      "f_train: 1.3288332138194239, F_train: 0.7906475691772322, Q0_train: 2258.036948626101\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.8983678273798432e-06, Lost1: 0.0, Left0: 0.0, Left1: 2.1154513092369598e-06\n",
      "f_train: 1.1405956301493223, F_train: 0.7577889806308682, Q0_train: 2164.19500196129\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 8.02143225400214, Lost1: 0.0, Left0: 0.0, Left1: 8.021432500755328\n",
      "f_train: 1.5434645320255003, F_train: 0.8239678019434487, Q0_train: 2353.197320523828\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 7.374830386837213, Lost1: 0.0, Left0: 0.0, Left1: 7.374830675329463\n",
      "f_train: 1.0935527217199956, F_train: 0.7490501317430419, Q0_train: 2139.23742990715\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 19.10624018125054, Lost1: 0.0, Left0: 0.0, Left1: 19.10624044143026\n",
      "f_train: 1.1471477127000993, F_train: 0.7589895494625019, Q0_train: 2167.6237468115637\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 0.9516384752103686, Lost1: 0.0, Left0: 0.0, Left1: 0.951638760791705\n",
      "f_train: 1.5382495004756453, F_train: 0.8232101100001037, Q0_train: 2351.0334026539103\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 5.00089999272268, Lost1: 0.0, Left0: 0.0, Left1: 5.00090021878683\n",
      "f_train: 1.471321922405397, F_train: 0.81325822857909, Q0_train: 2322.6114902456056\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 9.03290474494483, Lost1: 0.0, Left0: 0.0, Left1: 9.032904927264866\n",
      "f_train: 1.374695036554698, F_train: 0.7981376483438661, Q0_train: 2279.428117290534\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 40.103057717502644, Lost1: 0.0, Left0: 0.0, Left1: 40.10305796655007\n",
      "f_train: 0.8507980533747093, F_train: 0.7007345255812077, Q0_train: 2001.2512674729578\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.40013623403623, Lost1: 0.0, Left0: 0.0, Left1: 2.400136497735579\n",
      "f_train: 1.573781215115587, F_train: 0.8283219824623304, Q0_train: 2365.6325709133966\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 1.0887470125453547e-06, Lost1: 0.0, Left0: 0.0, Left1: 1.3741884004048188e-06\n",
      "f_train: 1.3907129803011866, F_train: 0.8007060420010472, Q0_train: 2286.763279001797\n",
      "f_train, F_train, Q0_train 都相等\n",
      "Lost0: 2.0509214115930603, Lost1: 0.0, Left0: 0.0, Left1: 2.0509216658473064\n",
      "f_train: 1.6337391391027172, F_train: 0.8366812196993645, Q0_train: 2389.5059973038633\n",
      "f_train, F_train, Q0_train 都相等\n",
      "alphas: [-0.00969578  0.          0.00667337 -1.71702669]\n",
      "==================================================\n",
      "X_train: [18.626271399098204, 0.0, 279.54363806240866, 1]\n",
      "f_train: -0.032123847918444026, demand_trian: 2800.5637571324673, F_train: 0.49196972857277776, Q0_train: 1405.0328718254357\n",
      "X_test: [15.747241523289969, 1.0, 68.5580334239261, 1]\n",
      "f_test: -1.4121950968685657, demand_test: 687.5375378113828, F_test: 0.19588806281098134 ,Q0_test: 559.4432979567348\n",
      "==================================================\n",
      "X_train: [17.506621909633513, 0.0, 278.7162624424789, 1]\n",
      "f_train: -0.026789362055680055, demand_trian: 2786.392968239322, F_train: 0.49330305999732205, Q0_train: 1408.8407778239557\n",
      "X_test: [19.340630286841073, 1.0, 60.117140841850016, 1]\n",
      "f_test: -1.5033650206717974, demand_test: 596.9592036067162, F_test: 0.1819241791443945 ,Q0_test: 519.5633735824886\n",
      "==================================================\n",
      "X_train: [19.78041817361612, 0.0, 282.6600409928567, 1]\n",
      "f_train: -0.02251727824615979, demand_trian: 2828.613174489932, F_train: 0.4943709182782028, Q0_train: 1411.8905101549287\n",
      "X_test: [15.812464673381875, 1.0, 63.599780644783635, 1]\n",
      "f_test: -1.445915757272681, demand_test: 642.5686349943295, F_test: 0.19063093090613548 ,Q0_test: 544.4292783761824\n",
      "==================================================\n",
      "X_train: [18.21995099614819, 0.0, 282.6051635000845, 1]\n",
      "f_train: -0.007753553922643652, demand_trian: 2823.2472727362383, F_train: 0.4980616212302191, Q0_train: 1422.4309126767862\n",
      "X_test: [18.07779782141922, 1.0, 67.29990562424058, 1]\n",
      "f_test: -1.4431876081878832, demand_test: 666.3987180210572, F_test: 0.19105221445800322 ,Q0_test: 545.6324362217896\n",
      "==================================================\n",
      "X_train: [17.1192752427909, 0.0, 271.5709217716987, 1]\n",
      "f_train: -0.07071726002291134, demand_trian: 2707.336846903293, F_train: 0.48232804906424753, Q0_train: 1377.4968754778745\n",
      "X_test: [15.619099914247208, 1.0, 61.716296772614406, 1]\n",
      "f_test: -1.4566101264341809, demand_test: 624.9442037060373, F_test: 0.18898634515405724 ,Q0_test: 539.732450689428\n",
      "==================================================\n",
      "X_train: [18.031966070639623, 0.0, 294.82732979255314, 1]\n",
      "f_train: 0.07563218315967224, demand_trian: 2950.873416421069, F_train: 0.5188990377496455, Q0_train: 1481.9411903896994\n",
      "X_test: [19.240041146611173, 1.0, 65.21036606204129, 1]\n",
      "f_test: -1.4684007380294364, demand_test: 648.7569594501776, F_test: 0.1871858156177802 ,Q0_test: 534.5902579116306\n",
      "==================================================\n",
      "X_train: [15.095965991546668, 0.0, 268.37809350239485, 1]\n",
      "f_train: -0.07240663864936203, demand_trian: 2683.3684520769825, F_train: 0.4819062446900743, Q0_train: 1376.292230198352\n",
      "X_test: [19.036594793625053, 1.0, 60.54337988339254, 1]\n",
      "f_test: -1.4975727080225756, demand_test: 596.4391801420729, F_test: 0.1827878248933817 ,Q0_test: 522.0298884846545\n",
      "==================================================\n",
      "X_train: [16.507874083372748, 0.0, 271.79324626328133, 1]\n",
      "f_train: -0.06330559620413179, demand_trian: 2730.31648136185, F_train: 0.48417888431938677, Q0_train: 1382.7827380478097\n",
      "X_test: [17.845503693072967, 1.0, 61.999965248964, 1]\n",
      "f_test: -1.4763038161527953, demand_test: 624.4751430283195, F_test: 0.1859863552727172 ,Q0_test: 531.1646788253855\n",
      "==================================================\n",
      "X_train: [18.300867687463427, 0.0, 294.5961677507836, 1]\n",
      "f_train: 0.07148234237746265, demand_trian: 2941.1774097840153, F_train: 0.5178629799986897, Q0_train: 1478.9822782602366\n",
      "X_test: [17.03591648613, 1.0, 60.18521794460614, 1]\n",
      "f_test: -1.4805647248925629, demand_test: 598.9158704090889, F_test: 0.18534213608722544 ,Q0_test: 529.3248316158786\n",
      "==================================================\n",
      "X_train: [16.45038803605222, 0.0, 290.3096994523043, 1]\n",
      "f_train: 0.0608189783600086, demand_trian: 2908.2317958047756, F_train: 0.5152000595261795, Q0_train: 1471.3771542421637\n",
      "X_test: [15.34583497727569, 1.0, 67.93697703357421, 1]\n",
      "f_test: -1.4124476894488982, demand_test: 676.6456769913636, F_test: 0.19584827851216413 ,Q0_test: 559.3296766414907\n",
      "==================================================\n",
      "X_train: [18.090077144994208, 0.0, 285.1944291770183, 1]\n",
      "f_train: 0.010784810222653318, demand_trian: 2858.8498840533343, F_train: 0.5026961764225452, Q0_train: 1435.6668945133072\n",
      "X_test: [18.487143865722818, 1.0, 62.2392468806038, 1]\n",
      "f_test: -1.4809282007750266, demand_test: 627.8302761482197, F_test: 0.18528726098461773 ,Q0_test: 529.168111967228\n",
      "==================================================\n",
      "X_train: [17.14384350472883, 0.0, 255.01134436561506, 1]\n",
      "f_train: -0.18146370864474792, demand_trian: 2551.3770149272727, F_train: 0.4547581524499312, Q0_train: 1298.7590817353212\n",
      "X_test: [17.267713413390343, 1.0, 63.45351680696903, 1]\n",
      "f_test: -1.4610015982204345, demand_test: 634.2489939429554, F_test: 0.18831418117605536 ,Q0_test: 537.8127950083979\n",
      "==================================================\n",
      "X_train: [15.677370321112251, 0.0, 295.9741306872337, 1]\n",
      "f_train: 0.10611484966197593, demand_trian: 2959.9809823803407, F_train: 0.5265038468407276, Q0_train: 1503.660020098846\n",
      "X_test: [18.61027799735174, 1.0, 69.28081293465591, 1]\n",
      "f_test: -1.4351310836405848, demand_test: 694.2340499677117, F_test: 0.19230046071471907 ,Q0_test: 549.197344631717\n",
      "==================================================\n",
      "X_train: [16.491411629780153, 0.0, 285.71206497745555, 1]\n",
      "f_train: 0.02973949199711834, demand_trian: 2858.187406007267, F_train: 0.5074343250744378, Q0_train: 1449.1987323904411\n",
      "X_test: [19.331911629643145, 1.0, 67.04414401923533, 1]\n",
      "f_test: -1.4570540090859727, demand_test: 672.4714130735691, F_test: 0.1889183204273638 ,Q0_test: 539.5381765876891\n",
      "==================================================\n",
      "X_train: [17.849824553506323, 0.0, 299.94235032839333, 1]\n",
      "f_train: 0.11153262776633999, demand_trian: 2991.4416354874847, F_train: 0.5278542884117062, Q0_train: 1507.5167915392535\n",
      "X_test: [19.87760752501443, 1.0, 60.318389295313075, 1]\n",
      "f_test: -1.5072284263769433, demand_test: 597.2903829924923, F_test: 0.18134990349658292 ,Q0_test: 517.9232804714654\n"
     ]
    }
   ],
   "source": [
    "# 線性模型預測公式\n",
    "def compute_f_F_Q(X_data, alphas, Q_star):\n",
    "    f = sum(X_data[j] * alphas[j] for j in range(len(alphas)))\n",
    "    big_f = 1 / (1 + np.exp(-f))\n",
    "    q0 = big_f * Q_star\n",
    "    # print(f\"f_vars[i]: {f:.4f}, F_vars[i]: {big_f:.4f}, Q0_vars[i]: {q0:.4f}\")\n",
    "    return f, big_f, q0\n",
    "\n",
    "\n",
    "results_df_2, stimulation_results_df_2 = grid_flexible_F_fixed_R(\n",
    "    assigned_Ts=ASSIGNED_TS,\n",
    "    salvage_value=salvage_value,\n",
    "    cost=cost,\n",
    "    price=price,\n",
    "    Q_star=Q_star,\n",
    "    demand_df_train=demand_df_train,\n",
    "    Qk_hat_df_train=Qk_hat_df_train,\n",
    "    training_df=training_df,\n",
    ")\n",
    "\n",
    "alphas = np.array(results_df_2.iloc[0][\"alpha_values\"])\n",
    "print(f\"alphas: {alphas}\")\n",
    "\n",
    "train_result_list = []\n",
    "test_result_list = []\n",
    "\n",
    "for i in range(len(training_df)):\n",
    "    # 計算訓練與測試的 f_vars, F_vars, Q0_vars\n",
    "    X_train = training_df.iloc[i, :].values.flatten().tolist()\n",
    "    X_test = testing_df.iloc[i, :].values.flatten().tolist()\n",
    "\n",
    "    # 加入 bias 特徵\n",
    "    X_train.append(1)\n",
    "    X_test.append(1)\n",
    "    f_train, F_train, Q0_train = compute_f_F_Q(X_train, alphas, Q_star)\n",
    "    f_test, F_test, Q0_test = compute_f_F_Q(X_test, alphas, Q_star)\n",
    "\n",
    "    demand_train = sum(demand_df_train.iloc[i, :].values.flatten().tolist())\n",
    "    demand_test = sum(demand_df_test.iloc[i, :].values.flatten().tolist())\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"X_train: {X_train}\")\n",
    "    print(\n",
    "        f\"f_train: {f_train}, demand_trian: {demand_train}, F_train: {F_train}, Q0_train: {Q0_train}\"\n",
    "    )\n",
    "    print(f\"X_test: {X_test}\")\n",
    "    print(\n",
    "        f\"f_test: {f_test}, demand_test: {demand_test}, F_test: {F_test} ,Q0_test: {Q0_test}\"\n",
    "    )\n",
    "\n",
    "    # 計算結果\n",
    "    train_result_list.append((f_train, F_train, Q0_train))\n",
    "    test_result_list.append((f_test, F_test, Q0_test))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "BmCtfhVmxlqf",
    "HTASer1nQ6iQ",
    "aRmALsClGzQB",
    "zg9HWiZOypqj",
    "FTJPzWLlAz8L",
    "yXuk_hytiwhv",
    "lQUlr1TGYuqf",
    "uleVduhQ5KpR",
    "igerpH_M5KpT",
    "6EOHpsM05KpT"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
