{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demand_df.shape: (1, 6)\n",
      "    0   1   2   3   4  5\n",
      "0  20  13  13  12  18  8\n",
      "Qks.shape: (4, 1, 3)\n",
      "[[[28.72405882 16.1939655  21.59519548]]\n",
      "\n",
      " [[18.75314812 27.31053969  9.69929645]]\n",
      "\n",
      " [[18.38791398 18.07972823 25.66884721]]\n",
      "\n",
      " [[14.50054366 19.13785896 15.61070791]]]\n",
      "x_observed: [20], x_observed.sum: 20, Qk_percentile: 28.01117248700271\n",
      "x_observed: [20 13], x_observed.sum: 33, Qk_percentile: 26.454800528963677\n",
      "x_observed: [20 13 13], x_observed.sum: 46, Qk_percentile: 24.940753888502712\n",
      "x_observed: [20 13 13 12], x_observed.sum: 58, Qk_percentile: 18.785143857062355\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Qk_hat_2</th>\n",
       "      <th>Qk_hat_3</th>\n",
       "      <th>Qk_hat_4</th>\n",
       "      <th>Qk_hat_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.011172</td>\n",
       "      <td>59.454801</td>\n",
       "      <td>70.940754</td>\n",
       "      <td>76.785144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Qk_hat_2   Qk_hat_3   Qk_hat_4   Qk_hat_5\n",
       "0  48.011172  59.454801  70.940754  76.785144"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# å°æ¨£æœ¬åƒæ•¸\n",
    "T = 6  # t = 0 ~ 5ï¼ˆå…±6æœŸï¼‰ï¼Œæˆ‘å€‘æœƒå»ºç«‹ Qk_hat_2 ~ Qk_hat_5ï¼ˆå…±4æœŸï¼‰\n",
    "N = 1  #  item\n",
    "simulation_times = 3\n",
    "service_level = 0.95\n",
    "\n",
    "# ç”Ÿæˆ demand_df: æ¯ä¸€ row æ˜¯ä¸€å€‹ itemï¼Œæ¯ä¸€ column æ˜¯ä¸€å€‹æ™‚é–“é»\n",
    "np.random.seed(1)\n",
    "demand_data = np.random.normal(loc=15, scale=3, size=(N, T)).round().astype(int)\n",
    "demand_df = pd.DataFrame(demand_data)\n",
    "print(f\"demand_df.shape: {demand_df.shape}\")\n",
    "print(demand_df)\n",
    "\n",
    "Qks = np.random.normal(loc=20, scale=5, size=(T - 2, N, simulation_times))\n",
    "print(f\"Qks.shape: {Qks.shape}\")\n",
    "print(Qks[:, :, :])\n",
    "\n",
    "\n",
    "def make_Qk_hat_df_with_known_Qk(\n",
    "    demand_df: pd.DataFrame,\n",
    "    Qks: np.ndarray,\n",
    "    service_level: float,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    è¨ˆç®—æ¯æœŸçš„è£œè²¨é‡é ä¼° (Qk_hat)ã€‚\n",
    "\n",
    "    åƒæ•¸:\n",
    "    ----------\n",
    "    demand_df : pd.DataFrame\n",
    "        æ¯åˆ—ç‚ºæ™‚é–“é» (t=0..T-1)ï¼Œæ¯æ¬„ç‚ºæ¨£æœ¬ (N)ã€‚shape=(T, N)\n",
    "    Qks : np.ndarray\n",
    "        å·²çŸ¥çš„æ¨¡æ“¬è£œè²¨é‡åˆ†å¸ƒæ¨£æœ¬ï¼Œshape=(T-2, N, simulation_times)\n",
    "    service_level : float\n",
    "        æœå‹™æ°´æº– (ä¾‹å¦‚ 0.95 è¡¨ç¤º 95%)ã€‚\n",
    "\n",
    "    å›å‚³:\n",
    "    ----------\n",
    "    pd.DataFrame\n",
    "        æ¯åˆ—ç‚ºæ¨£æœ¬ (sample_0..sample_{N-1})ï¼Œæ¯æ¬„ç‚º Qk_hat_{2}..Qk_hat_{T-1}ã€‚\n",
    "\n",
    "    ç¯„ä¾‹ (Example):ï¼ˆåªå–ä¸€å€‹ item èˆ‰ä¾‹ï¼‰\n",
    "    ----------\n",
    "    å‡è¨­:\n",
    "        T = 6  # t = 0 ~ 5ï¼ˆå…±6æœŸï¼‰ï¼Œæˆ‘å€‘æœƒå»ºç«‹ Qk_hat_2 ~ Qk_hat_5ï¼ˆå…±4æœŸï¼‰\n",
    "        N = 1  #  item\n",
    "        simulation_times = 3\n",
    "\n",
    "        demand_df (shape 1Ã—6):\n",
    "            0   1   2   3   4   5\n",
    "        0  20  13  13  12  18   8\n",
    "\n",
    "        ä»£è¡¨ T=1 éœ€æ±‚æ˜¯ 20\n",
    "        T=2 éœ€æ±‚æ˜¯ 13\n",
    "        ...\n",
    "\n",
    "        Qks (shape 4Ã—1Ã—3): -> é€™æ˜¯å…¶ä¸­ä¸€ç­† item çš„è³‡æ–™ï¼ŒåŒ…å«\n",
    "        [[[28.724, 16.194, 21.595]],\n",
    "         [[18.753, 27.311,  9.699]],\n",
    "         [[18.388, 18.080, 25.669]],\n",
    "         [[14.501, 19.138, 15.611]]]\n",
    "\n",
    "    è¨ˆç®—éç¨‹:\n",
    "        - t=2 (è¨ˆç®— Qk_hat_2):\n",
    "          x_observed = [20]  â†’ sum=20 -> åªå– t=1\n",
    "          Qk_percentile = ç¬¬95ç™¾åˆ†ä½ â‰ˆ 28.0112\n",
    "          Qk_hat_2 = 20 + 28.0112 = 48.0112\n",
    "\n",
    "        - t=3 (è¨ˆç®— Qk_hat_3):\n",
    "          x_observed = [20,13] â†’ sum=33 -> åªå– t=1,2\n",
    "          Qk_percentile â‰ˆ 26.4548\n",
    "          Qk_hat_3 = 33 + 26.4548 = 59.4548\n",
    "\n",
    "        - t=4 (è¨ˆç®— Qk_hat_4):\n",
    "          x_observed = [20,13,13] â†’ sum=46 -> åªå– t=1,2,3\n",
    "          Qk_percentile â‰ˆ 24.9408\n",
    "          Qk_hat_4 = 46 + 24.9408 = 70.9408\n",
    "\n",
    "        - t=5 (è¨ˆç®— Qk_hat_5):\n",
    "          x_observed = [20,13,13,12] â†’ sum=58 -> åªå– t=1,2,3,4\n",
    "          Qk_percentile â‰ˆ 18.7851\n",
    "          Qk_hat_5 = 58 + 18.7851 = 76.7851\n",
    "\n",
    "    æœ€çµ‚è¼¸å‡º:\n",
    "        Qk_hat DataFrame (1Ã—4):\n",
    "               Qk_hat_2   Qk_hat_3   Qk_hat_4   Qk_hat_5\n",
    "              48.0112     59.4548     70.9408     76.7851\n",
    "    \"\"\"\n",
    "\n",
    "    N, T = demand_df.shape\n",
    "    Qk_hat_matrix = np.zeros((N, T - 2))\n",
    "\n",
    "    for t_index in range(T - 2):  # 0ï½3\n",
    "        Qks_t = Qks[t_index, :, :]  # shape: (3, simulation_times)\n",
    "\n",
    "        for item_idx in range(N):\n",
    "\n",
    "            # å–å‡ºå–®ä¸€ item çš„æ‰€æœ‰ Qkï¼Œä¸¦ä¸”è¨ˆç®— Qk çš„ service_level åˆ†ä½æ•¸\n",
    "            qk_dist = Qks_t[item_idx]  # shape: (simulation_times,)\n",
    "            Qk_percentile = np.percentile(qk_dist, service_level * 100)\n",
    "\n",
    "            # ç¾åœ¨æ˜¯è¨ˆç®— t=k çš„ Qk hat, å› æ­¤å–å‡ºå·²ç¶“è§€æ¸¬åˆ°çš„å€¼ï¼Œæ˜¯ 1 ~ k-1 çš„çœŸå¯¦å€¼\n",
    "            x_observed = demand_df.iloc[item_idx, : t_index + 1].values\n",
    "            print(\n",
    "                f\"x_observed: {x_observed}, x_observed.sum: {x_observed.sum()}, Qk_percentile: {Qk_percentile}\"\n",
    "            )\n",
    "            Qk_hat_matrix[item_idx, t_index] = x_observed.sum() + Qk_percentile\n",
    "\n",
    "    time_columns = [f\"Qk_hat_{t+2}\" for t in range(T - 2)]\n",
    "    return pd.DataFrame(Qk_hat_matrix, columns=time_columns)\n",
    "\n",
    "\n",
    "# åŸ·è¡Œ\n",
    "Qk_hat_df_example = make_Qk_hat_df_with_known_Qk(demand_df, Qks, service_level)\n",
    "Qk_hat_df_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary.csv\n",
      "test_chunk20_lasso1_fold5_lst0.8.csv\n",
      "test_chunk20_lasso1_fold5_lst0.9.csv\n",
      "test_chunk30_lasso1_fold5_lst0.9.csv\n",
      "test_chunk30_lasso1_fold5_lst0.8.csv\n",
      "train_chunk30_lasso1_fold5_lst0.9.csv\n",
      "train_chunk30_lasso1_fold5_lst0.8.csv\n",
      "train_chunk20_lasso1_fold5_lst0.8.csv\n",
      "train_chunk20_lasso1_fold5_lst0.9.csv\n"
     ]
    }
   ],
   "source": [
    "# åˆ—å‡ºæ‰€æœ‰ csv\n",
    "import os\n",
    "\n",
    "# ç›®éŒ„è·¯å¾‘\n",
    "directory = \"/Users/hanyuan/Github/Two-Phase-Newsvendor/results_0407\"\n",
    "\n",
    "# åˆ—å‡ºæ‰€æœ‰ .csv æª”æ¡ˆ\n",
    "csv_files = [f for f in os.listdir(directory) if f.endswith(\".csv\")]\n",
    "\n",
    "# é¡¯ç¤ºçµæœ\n",
    "for file in csv_files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Matched train-test pairs:\n",
      " - chunk20_lasso1_fold5_lst0.8.csv\n",
      " - chunk20_lasso1_fold5_lst0.9.csv\n",
      " - chunk30_lasso1_fold5_lst0.8.csv\n",
      " - chunk30_lasso1_fold5_lst0.9.csv\n",
      "\n",
      "âŒ Only in train:\n",
      "\n",
      "âŒ Only in test:\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# è³‡æ–™å¤¾è·¯å¾‘\n",
    "directory = \"/Users/hanyuan/Github/Two-Phase-Newsvendor/results_0407\"\n",
    "\n",
    "# å–å¾—æ‰€æœ‰ .csv æª”æ¡ˆåç¨±\n",
    "csv_files = [f for f in os.listdir(directory) if f.endswith(\".csv\")]\n",
    "\n",
    "# ç”¨ä¾†å­˜çµ„åˆéµ\n",
    "train_keys = set()\n",
    "test_keys = set()\n",
    "\n",
    "# åˆ†ææ¯å€‹æª”æ¡ˆ\n",
    "for filename in csv_files:\n",
    "    if filename.startswith(\"train_\"):\n",
    "        key = filename.replace(\"train_\", \"\")\n",
    "        train_keys.add(key)\n",
    "    elif filename.startswith(\"test_\"):\n",
    "        key = filename.replace(\"test_\", \"\")\n",
    "        test_keys.add(key)\n",
    "\n",
    "# æ‰¾å‡ºåªæœ‰åœ¨ train æœ‰çš„çµ„åˆ\n",
    "train_only = train_keys - test_keys\n",
    "\n",
    "# æ‰¾å‡ºåªæœ‰åœ¨ test æœ‰çš„çµ„åˆ\n",
    "test_only = test_keys - train_keys\n",
    "\n",
    "# æ‰¾å‡ºåŒæ™‚æœ‰ train å’Œ test çš„çµ„åˆ\n",
    "matched = train_keys & test_keys\n",
    "\n",
    "# é¡¯ç¤ºçµæœ\n",
    "print(\"âœ… Matched train-test pairs:\")\n",
    "for key in sorted(matched):\n",
    "    print(f\" - {key}\")\n",
    "\n",
    "print(\"\\nâŒ Only in train:\")\n",
    "for key in sorted(train_only):\n",
    "    print(f\" - {key}\")\n",
    "\n",
    "print(\"\\nâŒ Only in test:\")\n",
    "for key in sorted(test_only):\n",
    "    print(f\" - {key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 matched pairs.\n",
      "-----------------------------------\n",
      "key: chunk20_lasso1_fold5_lst0.8.csv\n",
      "train_files[key]: train_chunk20_lasso1_fold5_lst0.8.csv\n",
      "test_files[key]: test_chunk20_lasso1_fold5_lst0.8.csv\n",
      "âœ… Saved plot for: chunk20_lasso1_fold5_lst0.8.csv\n",
      "-----------------------------------\n",
      "key: chunk20_lasso1_fold5_lst0.9.csv\n",
      "train_files[key]: train_chunk20_lasso1_fold5_lst0.9.csv\n",
      "test_files[key]: test_chunk20_lasso1_fold5_lst0.9.csv\n",
      "âœ… Saved plot for: chunk20_lasso1_fold5_lst0.9.csv\n",
      "-----------------------------------\n",
      "key: chunk30_lasso1_fold5_lst0.8.csv\n",
      "train_files[key]: train_chunk30_lasso1_fold5_lst0.8.csv\n",
      "test_files[key]: test_chunk30_lasso1_fold5_lst0.8.csv\n",
      "âœ… Saved plot for: chunk30_lasso1_fold5_lst0.8.csv\n",
      "-----------------------------------\n",
      "key: chunk30_lasso1_fold5_lst0.9.csv\n",
      "train_files[key]: train_chunk30_lasso1_fold5_lst0.9.csv\n",
      "test_files[key]: test_chunk30_lasso1_fold5_lst0.9.csv\n",
      "âœ… Saved plot for: chunk30_lasso1_fold5_lst0.9.csv\n",
      "\n",
      "ğŸ‰ All plots saved in: /Users/hanyuan/Github/Two-Phase-Newsvendor/results_0407/plots\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# è¨­å®š seaborn æ¨£å¼\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# ğŸ”§ åƒæ•¸è¨­å®š\n",
    "input_dir = \"/Users/hanyuan/Github/Two-Phase-Newsvendor/results_0407\"\n",
    "output_dir = os.path.join(input_dir, \"plots\")\n",
    "os.makedirs(output_dir, exist_ok=True)  # å¦‚æœ plots è³‡æ–™å¤¾ä¸å­˜åœ¨å°±å»ºç«‹\n",
    "\n",
    "# ğŸ” å–å¾—æ‰€æœ‰ train/test æª”æ¡ˆ\n",
    "files = [f for f in os.listdir(input_dir) if f.endswith(\".csv\")]\n",
    "train_files = {f.replace(\"train_\", \"\"): f for f in files if f.startswith(\"train_\")}\n",
    "test_files = {f.replace(\"test_\", \"\"): f for f in files if f.startswith(\"test_\")}\n",
    "\n",
    "# ğŸ”— æ‰¾å‡ºäº¤é›†çµ„åˆéµ\n",
    "common_keys = sorted(set(train_files.keys()) & set(test_files.keys()))\n",
    "\n",
    "print(f\"Found {len(common_keys)} matched pairs.\")\n",
    "\n",
    "# ğŸ¯ å°æ¯çµ„é…å°åšåˆ†æå’Œç•«åœ–\n",
    "for key in common_keys:\n",
    "    print(f\"-----------------------------------\")\n",
    "    print(f\"key: {key}\")\n",
    "    print(f\"train_files[key]: {train_files[key]}\")\n",
    "    print(f\"test_files[key]: {test_files[key]}\")\n",
    "\n",
    "    train_path = os.path.join(input_dir, train_files[key])\n",
    "    test_path = os.path.join(input_dir, test_files[key])\n",
    "\n",
    "    # è®€å– CSV æª”æ¡ˆ\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    # train_df = train_df.drop(columns=[\"S12\", \"S15\"])\n",
    "\n",
    "    # è¨ˆç®—å¹³å‡\n",
    "    train_means = train_df.mean()\n",
    "    test_means = test_df.mean()\n",
    "\n",
    "    # baseline å’Œ theory æœ€ä½³\n",
    "    baseline_train = train_means[\"baseline\"]\n",
    "    baseline_test = test_means[\"baseline\"]\n",
    "    theory_best_train = train_means[\"S14\"]\n",
    "    theory_best_test = test_means[\"S14\"]\n",
    "\n",
    "    # ç™¾åˆ†æ¯”è®ŠåŒ–\n",
    "    train_pct_base = (train_means - baseline_train) / baseline_train * 100\n",
    "    test_pct_base = (test_means - baseline_test) / baseline_test * 100\n",
    "    train_pct_theory = (train_means - theory_best_train) / theory_best_train * 100\n",
    "    test_pct_theory = (test_means - theory_best_test) / theory_best_test * 100\n",
    "\n",
    "    # æ•´ç†æˆ DataFrame\n",
    "    avg_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Method\": train_means.index,\n",
    "            \"Train\": train_means.values,\n",
    "            \"Test\": test_means.values,\n",
    "            \"Train_%_Base\": train_pct_base.values,\n",
    "            \"Test_%_Base\": test_pct_base.values,\n",
    "            \"Train_%_Theory\": train_pct_theory.values,\n",
    "            \"Test_%_Theory\": test_pct_theory.values,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # é•·æ ¼å¼è½‰æ›\n",
    "    avg_df_melted = avg_df.melt(\n",
    "        id_vars=[\n",
    "            \"Method\",\n",
    "            \"Train_%_Base\",\n",
    "            \"Test_%_Base\",\n",
    "            \"Train_%_Theory\",\n",
    "            \"Test_%_Theory\",\n",
    "        ],\n",
    "        value_vars=[\"Train\", \"Test\"],\n",
    "        var_name=\"Dataset\",\n",
    "        value_name=\"Average Profit\",\n",
    "    )\n",
    "\n",
    "    # ç•«åœ–\n",
    "    plt.figure(figsize=(15, 9))\n",
    "    ax = sns.barplot(x=\"Method\", y=\"Average Profit\", hue=\"Dataset\", data=avg_df_melted)\n",
    "\n",
    "    # åŠ ä¸Šè¨»è§£\n",
    "    for patch, (method, ds) in zip(\n",
    "        ax.patches, zip(avg_df_melted[\"Method\"], avg_df_melted[\"Dataset\"])\n",
    "    ):\n",
    "        if ds == \"Train\":\n",
    "            pct_base = avg_df.loc[avg_df.Method == method, \"Train_%_Base\"].values[0]\n",
    "            pct_theory = avg_df.loc[avg_df.Method == method, \"Train_%_Theory\"].values[0]\n",
    "        else:\n",
    "            pct_base = avg_df.loc[avg_df.Method == method, \"Test_%_Base\"].values[0]\n",
    "            pct_theory = avg_df.loc[avg_df.Method == method, \"Test_%_Theory\"].values[0]\n",
    "\n",
    "        ax.annotate(\n",
    "            f\"{pct_base:.1f}%\\n({pct_theory:.1f}%)\",\n",
    "            (patch.get_x() + patch.get_width() / 2, patch.get_height()),\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=9,\n",
    "            xytext=(0, 5),\n",
    "            textcoords=\"offset points\",\n",
    "        )\n",
    "\n",
    "    plt.title(f\"Average Profit: {key}\\n% Change vs Baseline / Theory Best\")\n",
    "    plt.ylabel(\"Average Profit\")\n",
    "    plt.xlabel(\"Method\")\n",
    "    plt.xticks(rotation=30)\n",
    "    plt.legend(title=\"Dataset\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # å„²å­˜åœ–ç‰‡\n",
    "    plot_filename = os.path.join(output_dir, f\"avg_profit_{key.replace('.csv','')}.png\")\n",
    "    plt.savefig(plot_filename)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"âœ… Saved plot for: {key}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ All plots saved in: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 matched pairs.\n",
      "-----------------------------------\n",
      "key: chunk20_lasso1_fold5_lst0.8.csv\n",
      "train_files[key]: train_chunk20_lasso1_fold5_lst0.8.csv\n",
      "test_files[key]: test_chunk20_lasso1_fold5_lst0.8.csv\n",
      "âœ… Plots saved for: chunk20_lasso1_fold5_lst0.8.csv\n",
      "-----------------------------------\n",
      "key: chunk20_lasso1_fold5_lst0.9.csv\n",
      "train_files[key]: train_chunk20_lasso1_fold5_lst0.9.csv\n",
      "test_files[key]: test_chunk20_lasso1_fold5_lst0.9.csv\n",
      "âœ… Plots saved for: chunk20_lasso1_fold5_lst0.9.csv\n",
      "-----------------------------------\n",
      "key: chunk30_lasso1_fold5_lst0.8.csv\n",
      "train_files[key]: train_chunk30_lasso1_fold5_lst0.8.csv\n",
      "test_files[key]: test_chunk30_lasso1_fold5_lst0.8.csv\n",
      "âœ… Plots saved for: chunk30_lasso1_fold5_lst0.8.csv\n",
      "-----------------------------------\n",
      "key: chunk30_lasso1_fold5_lst0.9.csv\n",
      "train_files[key]: train_chunk30_lasso1_fold5_lst0.9.csv\n",
      "test_files[key]: test_chunk30_lasso1_fold5_lst0.9.csv\n",
      "âœ… Plots saved for: chunk30_lasso1_fold5_lst0.9.csv\n",
      "\n",
      "ğŸ‰ All plots saved to: /Users/hanyuan/Github/Two-Phase-Newsvendor/results_0407/plots\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# è¨­å®š seaborn æ¨£å¼\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# ğŸ”§ åƒæ•¸è¨­å®š\n",
    "input_dir = \"/Users/hanyuan/Github/Two-Phase-Newsvendor/results_0407\"\n",
    "output_dir = os.path.join(input_dir, \"plots\")\n",
    "os.makedirs(output_dir, exist_ok=True)  # å¦‚æœ plots è³‡æ–™å¤¾ä¸å­˜åœ¨å°±å»ºç«‹\n",
    "\n",
    "# ğŸ” å–å¾—æ‰€æœ‰ train/test æª”æ¡ˆ\n",
    "files = [f for f in os.listdir(input_dir) if f.endswith(\".csv\")]\n",
    "train_files = {f.replace(\"train_\", \"\"): f for f in files if f.startswith(\"train_\")}\n",
    "test_files = {f.replace(\"test_\", \"\"): f for f in files if f.startswith(\"test_\")}\n",
    "\n",
    "# ğŸ”— æ‰¾å‡ºäº¤é›†çµ„åˆéµ\n",
    "common_keys = sorted(set(train_files.keys()) & set(test_files.keys()))\n",
    "\n",
    "print(f\"Found {len(common_keys)} matched pairs.\")\n",
    "\n",
    "# ğŸ¯ å°æ¯çµ„é…å°åšåˆ†æå’Œç•«åœ–\n",
    "for key in common_keys:\n",
    "    print(f\"-----------------------------------\")\n",
    "    print(f\"key: {key}\")\n",
    "    print(f\"train_files[key]: {train_files[key]}\")\n",
    "    print(f\"test_files[key]: {test_files[key]}\")\n",
    "\n",
    "    train_path = os.path.join(input_dir, train_files[key])\n",
    "    test_path = os.path.join(input_dir, test_files[key])\n",
    "\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    # train_df = train_df.drop(columns=[\"S12\", \"S15\"])\n",
    "\n",
    "    # ========== 1ï¸âƒ£ è¨ˆç®— Relative (%) vs Baseline ==========\n",
    "    baseline_train = train_df[\"baseline\"].to_numpy().reshape(-1, 1)\n",
    "    baseline_test = test_df[\"baseline\"].to_numpy().reshape(-1, 1)\n",
    "\n",
    "    train_relative = (train_df.to_numpy() - baseline_train) / baseline_train * 100\n",
    "    test_relative = (test_df.to_numpy() - baseline_test) / baseline_test * 100\n",
    "\n",
    "    train_relative = pd.DataFrame(\n",
    "        train_relative, columns=train_df.columns, index=train_df.index\n",
    "    )\n",
    "    test_relative = pd.DataFrame(\n",
    "        test_relative, columns=test_df.columns, index=test_df.index\n",
    "    )\n",
    "\n",
    "    train_relative[\"Fold\"] = train_relative.index + 1\n",
    "    test_relative[\"Fold\"] = test_relative.index + 1\n",
    "\n",
    "    train_long = train_relative.melt(\n",
    "        id_vars=\"Fold\", var_name=\"Method\", value_name=\"Relative Profit (%)\"\n",
    "    )\n",
    "    test_long = test_relative.melt(\n",
    "        id_vars=\"Fold\", var_name=\"Method\", value_name=\"Relative Profit (%)\"\n",
    "    )\n",
    "    train_long[\"Dataset\"] = \"Train\"\n",
    "    test_long[\"Dataset\"] = \"Test\"\n",
    "\n",
    "    fold_long = pd.concat([train_long, test_long], axis=0)\n",
    "    fold_long = fold_long.reset_index(drop=True)\n",
    "\n",
    "    # ğŸ¨ 1. Line Plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.lineplot(\n",
    "        data=fold_long,\n",
    "        x=\"Fold\",\n",
    "        y=\"Relative Profit (%)\",\n",
    "        hue=\"Method\",\n",
    "        style=\"Dataset\",\n",
    "        markers=True,\n",
    "        dashes=False,\n",
    "    )\n",
    "    plt.axhline(0, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "    plt.title(f\"[{key}] Strategy Performance Across Folds (Relative to Baseline)\")\n",
    "    plt.legend(title=\"Method & Dataset\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f\"line_{key.replace('.csv','')}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # ğŸ¨ 2. Box Plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(data=fold_long, x=\"Method\", y=\"Relative Profit (%)\", hue=\"Dataset\")\n",
    "    plt.axhline(0, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "    plt.title(f\"[{key}] Strategy Performance Distribution Across Folds\")\n",
    "    plt.xticks(rotation=30)\n",
    "    plt.legend(title=\"Dataset\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f\"box_{key.replace('.csv','')}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # ========== 2ï¸âƒ£ Heatmap: Relative vs Theory ==========\n",
    "    theory_best_train = train_df[\"S14\"].to_numpy().reshape(-1, 1)\n",
    "    theory_best_test = test_df[\"S14\"].to_numpy().reshape(-1, 1)\n",
    "\n",
    "    train_theory_rel = (\n",
    "        (train_df.to_numpy() - theory_best_train) / theory_best_train * 100\n",
    "    )\n",
    "    test_theory_rel = (test_df.to_numpy() - theory_best_test) / theory_best_test * 100\n",
    "\n",
    "    train_theory_df = pd.DataFrame(\n",
    "        train_theory_rel, columns=train_df.columns, index=train_df.index\n",
    "    )\n",
    "    test_theory_df = pd.DataFrame(\n",
    "        test_theory_rel, columns=test_df.columns, index=test_df.index\n",
    "    )\n",
    "\n",
    "    train_theory_df[\"Fold\"] = train_theory_df.index + 1\n",
    "    test_theory_df[\"Fold\"] = test_theory_df.index + 1\n",
    "\n",
    "    train_theory_long = train_theory_df.melt(\n",
    "        id_vars=\"Fold\", var_name=\"Method\", value_name=\"Relative vs Theory (%)\"\n",
    "    )\n",
    "    train_theory_long[\"Dataset\"] = \"Train\"\n",
    "    test_theory_long = test_theory_df.melt(\n",
    "        id_vars=\"Fold\", var_name=\"Method\", value_name=\"Relative vs Theory (%)\"\n",
    "    )\n",
    "    test_theory_long[\"Dataset\"] = \"Test\"\n",
    "\n",
    "    merged = fold_long.merge(\n",
    "        pd.concat([train_theory_long, test_theory_long], axis=0),\n",
    "        on=[\"Fold\", \"Method\", \"Dataset\"],\n",
    "    )\n",
    "\n",
    "    heatmap_data = merged.pivot(\n",
    "        index=\"Fold\", columns=[\"Method\", \"Dataset\"], values=\"Relative Profit (%)\"\n",
    "    )\n",
    "    annot = merged.assign(\n",
    "        annot=merged[\"Relative Profit (%)\"].round(1).astype(str)\n",
    "        + \"\\n(\"\n",
    "        + merged[\"Relative vs Theory (%)\"].round(1).astype(str)\n",
    "        + \"%)\"\n",
    "    ).pivot(index=\"Fold\", columns=[\"Method\", \"Dataset\"], values=\"annot\")\n",
    "\n",
    "    # ğŸ¨ 3. Heatmap\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sns.heatmap(heatmap_data, annot=annot, fmt=\"\", cmap=\"coolwarm\", linewidths=0.5)\n",
    "    plt.title(\n",
    "        f\"[{key}] Relative Profit (%) Across Folds\\n(vs Baseline / (vs Theory Best))\"\n",
    "    )\n",
    "    plt.ylabel(\"Fold\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f\"heatmap_{key.replace('.csv','')}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"âœ… Plots saved for: {key}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ All plots saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1ï¸âƒ£ è¨ˆç®—å¹³å‡ profit\n",
    "# train_means = train_all_fold_profit_df.mean()\n",
    "# test_means = test_all_fold_profit_df.mean()\n",
    "\n",
    "# # 2ï¸âƒ£ å®šç¾© baseline & theory best\n",
    "# baseline_train = train_means[\"baseline\"]\n",
    "# baseline_test = test_means[\"baseline\"]\n",
    "# theory_best_train = train_means[\"S14\"]\n",
    "# theory_best_test = test_means[\"S14\"]\n",
    "\n",
    "# # 3ï¸âƒ£ è¨ˆç®—ç™¾åˆ†æ¯”è®ŠåŒ–ï¼šbaseline & theory\n",
    "# train_pct_base = (train_means - baseline_train) / baseline_train * 100\n",
    "# test_pct_base = (test_means - baseline_test) / baseline_test * 100\n",
    "# train_pct_theory = (train_means - theory_best_train) / theory_best_train * 100\n",
    "# test_pct_theory = (test_means - theory_best_test) / theory_best_test * 100\n",
    "\n",
    "# # 4ï¸âƒ£ å»º DataFrame\n",
    "# avg_df = pd.DataFrame(\n",
    "#     {\n",
    "#         \"Method\": train_means.index,\n",
    "#         \"Train\": train_means.values,\n",
    "#         \"Test\": test_means.values,\n",
    "#         \"Train_%_Base\": train_pct_base.values,\n",
    "#         \"Test_%_Base\": test_pct_base.values,\n",
    "#         \"Train_%_Theory\": train_pct_theory.values,\n",
    "#         \"Test_%_Theory\": test_pct_theory.values,\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# avg_df_melted = avg_df.melt(\n",
    "#     id_vars=[\n",
    "#         \"Method\",\n",
    "#         \"Train_%_Base\",\n",
    "#         \"Test_%_Base\",\n",
    "#         \"Train_%_Theory\",\n",
    "#         \"Test_%_Theory\",\n",
    "#     ],\n",
    "#     value_vars=[\"Train\", \"Test\"],\n",
    "#     var_name=\"Dataset\",\n",
    "#     value_name=\"Average Profit\",\n",
    "# )\n",
    "\n",
    "# # 5ï¸âƒ£ ç•«åœ–\n",
    "# plt.figure(figsize=(15, 9))\n",
    "# ax = sns.barplot(x=\"Method\", y=\"Average Profit\", hue=\"Dataset\", data=avg_df_melted)\n",
    "\n",
    "# # 6ï¸âƒ£ æ¨™è¨»ï¼šbaseline (%) åœ¨ç¬¬ä¸€è¡Œã€theory (%) æ‹¬è™Ÿå…§ç¬¬äºŒè¡Œ\n",
    "# for patch, (method, ds) in zip(\n",
    "#     ax.patches, zip(avg_df_melted[\"Method\"], avg_df_melted[\"Dataset\"])\n",
    "# ):\n",
    "#     if ds == \"Train\":\n",
    "#         pct_base = avg_df.loc[avg_df.Method == method, \"Train_%_Base\"].values[0]\n",
    "#         pct_theory = avg_df.loc[avg_df.Method == method, \"Train_%_Theory\"].values[0]\n",
    "#     else:\n",
    "#         pct_base = avg_df.loc[avg_df.Method == method, \"Test_%_Base\"].values[0]\n",
    "#         pct_theory = avg_df.loc[avg_df.Method == method, \"Test_%_Theory\"].values[0]\n",
    "\n",
    "#     ax.annotate(\n",
    "#         f\"{pct_base:.1f}%\\n({pct_theory:.1f}%)\",\n",
    "#         (patch.get_x() + patch.get_width() / 2, patch.get_height()),\n",
    "#         ha=\"center\",\n",
    "#         va=\"bottom\",\n",
    "#         fontsize=9,\n",
    "#         xytext=(0, 5),\n",
    "#         textcoords=\"offset points\",\n",
    "#     )\n",
    "\n",
    "# plt.title(\"Average Profit (Train vs Test) â€” % Change vs Baseline / Theory Best\")\n",
    "# plt.ylabel(\"Average Profit\")\n",
    "# plt.xlabel(\"Method\")\n",
    "# plt.xticks(rotation=30)\n",
    "# plt.legend(title=\"Dataset\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # è¨ˆç®— baselineï¼ˆè¨“ç·´èˆ‡æ¸¬è©¦ï¼‰\n",
    "# baseline_train = train_all_fold_profit_df[\"baseline\"].to_numpy().reshape(-1, 1)\n",
    "# baseline_test = test_all_fold_profit_df[\"baseline\"].to_numpy().reshape(-1, 1)\n",
    "\n",
    "# # è¨ˆç®—ç™¾åˆ†æ¯”è®ŠåŒ–\n",
    "# train_relative = (\n",
    "#     (train_all_fold_profit_df.to_numpy() - baseline_train) / baseline_train * 100\n",
    "# )\n",
    "# test_relative = (\n",
    "#     (test_all_fold_profit_df.to_numpy() - baseline_test) / baseline_test * 100\n",
    "# )\n",
    "\n",
    "# # è½‰å› DataFrameï¼Œä¸¦ä¿ç•™ column names\n",
    "# train_relative = pd.DataFrame(\n",
    "#     train_relative,\n",
    "#     columns=train_all_fold_profit_df.columns,\n",
    "#     index=train_all_fold_profit_df.index,\n",
    "# )\n",
    "# test_relative = pd.DataFrame(\n",
    "#     test_relative,\n",
    "#     columns=test_all_fold_profit_df.columns,\n",
    "#     index=test_all_fold_profit_df.index,\n",
    "# )\n",
    "\n",
    "# # åŠ å…¥ fold ç·¨è™Ÿ\n",
    "# train_relative[\"Fold\"] = train_relative.index + 1\n",
    "# test_relative[\"Fold\"] = test_relative.index + 1\n",
    "\n",
    "# # è½‰æ›æˆé•·æ ¼å¼\n",
    "# train_long = train_relative.melt(\n",
    "#     id_vars=\"Fold\", var_name=\"Method\", value_name=\"Relative Profit (%)\"\n",
    "# )\n",
    "# train_long[\"Dataset\"] = \"Train\"\n",
    "\n",
    "# test_long = test_relative.melt(\n",
    "#     id_vars=\"Fold\", var_name=\"Method\", value_name=\"Relative Profit (%)\"\n",
    "# )\n",
    "# test_long[\"Dataset\"] = \"Test\"\n",
    "\n",
    "# # åˆä½µæ•¸æ“š\n",
    "# fold_long = pd.concat([train_long, test_long], axis=0)\n",
    "\n",
    "# # === 1. ä½¿ç”¨ç·šåœ– (Line Plot) è§€å¯Ÿä¸åŒ Fold ä¸Šçš„è®ŠåŒ–è¶¨å‹¢ ===\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.lineplot(\n",
    "#     data=fold_long,\n",
    "#     x=\"Fold\",\n",
    "#     y=\"Relative Profit (%)\",\n",
    "#     hue=\"Method\",\n",
    "#     style=\"Dataset\",\n",
    "#     markers=True,\n",
    "#     dashes=False,\n",
    "# )\n",
    "# plt.axhline(0, color=\"gray\", linestyle=\"--\", linewidth=1)  # åŸºæº–ç·š\n",
    "# plt.title(\"Strategy Performance Across Folds (Relative to Baseline)\")\n",
    "# plt.legend(title=\"Method & Dataset\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "# plt.show()\n",
    "\n",
    "# # === 2. ä½¿ç”¨ç®±å‹åœ– (Box Plot) æŸ¥çœ‹ç­–ç•¥ç©©å®šæ€§ ===\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.boxplot(data=fold_long, x=\"Method\", y=\"Relative Profit (%)\", hue=\"Dataset\")\n",
    "# plt.axhline(0, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "# plt.title(\"Strategy Performance Distribution Across Folds\")\n",
    "# plt.xticks(rotation=30)\n",
    "# plt.legend(title=\"Dataset\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "# plt.show()\n",
    "\n",
    "# # 3ï¸âƒ£ Heatmapï¼šåŒæ™‚é¡¯ç¤º vs Baseline & vs Theory Bestï¼ˆæ¯ Fold çš„ S14ï¼‰\n",
    "# theory_best_train = train_all_fold_profit_df[\"S14\"].to_numpy().reshape(-1, 1)\n",
    "# theory_best_test = test_all_fold_profit_df[\"S14\"].to_numpy().reshape(-1, 1)\n",
    "\n",
    "# # vs Theory (%) è¨ˆç®—\n",
    "# train_theory_rel = (\n",
    "#     (train_all_fold_profit_df.to_numpy() - theory_best_train) / theory_best_train * 100\n",
    "# )\n",
    "# test_theory_rel = (\n",
    "#     (test_all_fold_profit_df.to_numpy() - theory_best_test) / theory_best_test * 100\n",
    "# )\n",
    "\n",
    "# # å› DataFrame ä¸¦ melt\n",
    "# train_theory_rel = pd.DataFrame(\n",
    "#     train_theory_rel,\n",
    "#     columns=train_all_fold_profit_df.columns,\n",
    "#     index=train_all_fold_profit_df.index,\n",
    "# )\n",
    "# train_theory_rel[\"Fold\"] = train_theory_rel.index + 1\n",
    "# train_theory_long = train_theory_rel.melt(\n",
    "#     id_vars=\"Fold\", var_name=\"Method\", value_name=\"Relative vs Theory (%)\"\n",
    "# )\n",
    "# train_theory_long[\"Dataset\"] = \"Train\"\n",
    "\n",
    "# test_theory_rel = pd.DataFrame(\n",
    "#     test_theory_rel,\n",
    "#     columns=test_all_fold_profit_df.columns,\n",
    "#     index=test_all_fold_profit_df.index,\n",
    "# )\n",
    "# test_theory_rel[\"Fold\"] = test_theory_rel.index + 1\n",
    "# test_theory_long = test_theory_rel.melt(\n",
    "#     id_vars=\"Fold\", var_name=\"Method\", value_name=\"Relative vs Theory (%)\"\n",
    "# )\n",
    "# test_theory_long[\"Dataset\"] = \"Test\"\n",
    "\n",
    "# # åˆä½µ baseline (%) èˆ‡ theory (%) è³‡æ–™\n",
    "# merged = fold_long.merge(\n",
    "#     pd.concat([train_theory_long, test_theory_long], axis=0),\n",
    "#     on=[\"Fold\", \"Method\", \"Dataset\"],\n",
    "# )\n",
    "\n",
    "# # Pivot heatmap values + annotations\n",
    "# heatmap_data = merged.pivot(\n",
    "#     index=\"Fold\", columns=[\"Method\", \"Dataset\"], values=\"Relative Profit (%)\"\n",
    "# )\n",
    "# annot = merged.assign(\n",
    "#     annot=merged[\"Relative Profit (%)\"].round(1).astype(str)\n",
    "#     + \"\\n(\"\n",
    "#     + merged[\"Relative vs Theory (%)\"].round(1).astype(str)\n",
    "#     + \"%)\"\n",
    "# ).pivot(index=\"Fold\", columns=[\"Method\", \"Dataset\"], values=\"annot\")\n",
    "\n",
    "# plt.figure(figsize=(14, 8))\n",
    "# sns.heatmap(heatmap_data, annot=annot, fmt=\"\", cmap=\"coolwarm\", linewidths=0.5)\n",
    "# plt.title(\"Relative Profit (%) Across Folds\\n(vs Baseline / (vs Theory Best))\")\n",
    "# plt.ylabel(\"Fold\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # è¨“ç·´éšæ®µåˆ†ä½ˆ\n",
    "\n",
    "# baseline_data = []\n",
    "# S1_data = []\n",
    "# S2_data = []\n",
    "# S12_data = []\n",
    "# S14_data = []\n",
    "# S15_data = []\n",
    "\n",
    "# for result in train_all_fold_stimulation_results:\n",
    "#     baseline_data.append(result[\"baseline\"])\n",
    "#     S1_data.append(result[\"S1\"])\n",
    "#     S2_data.append(result[\"S2\"])\n",
    "#     S12_data.append(result[\"S12\"])\n",
    "#     S14_data.append(result[\"S14\"])\n",
    "#     S15_data.append(result[\"S15\"])\n",
    "\n",
    "# # åˆä½µæ•¸æ“š\n",
    "# baseline_df = pd.concat(baseline_data, ignore_index=True)\n",
    "# S1_df = pd.concat(S1_data, ignore_index=True)\n",
    "# S2_df = pd.concat(S2_data, ignore_index=True)\n",
    "# S12_df = pd.concat(S12_data, ignore_index=True)\n",
    "# S14_df = pd.concat(S14_data, ignore_index=True)\n",
    "# S15_df = pd.concat(S15_data, ignore_index=True)\n",
    "\n",
    "\n",
    "# dfs = {\n",
    "#     \"baseline\": baseline_df,\n",
    "#     \"S1\": S1_df,\n",
    "#     \"S2\": S2_df,\n",
    "#     \"S12\": S12_df,\n",
    "#     \"S15\": S15_df,\n",
    "#     \"S14\": S14_df,\n",
    "# }\n",
    "\n",
    "# # èª¿ç”¨ç¹ªåœ–å‡½æ•¸\n",
    "# plot_strategies_profits_scatter(f\"{status}_{model_prefix}\", dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # æ¸¬è©¦çµæœåˆ†å¸ƒåœ–\n",
    "\n",
    "# baseline_data = []\n",
    "# S1_data = []\n",
    "# S2_data = []\n",
    "# S12_data = []\n",
    "# S14_data = []\n",
    "# S15_data = []\n",
    "\n",
    "# for result in test_all_fold_stimulation_results:\n",
    "#     baseline_data.append(result[\"baseline\"])\n",
    "#     S1_data.append(result[\"S1\"])\n",
    "#     S2_data.append(result[\"S2\"])\n",
    "#     S12_data.append(result[\"S12\"])\n",
    "#     S14_data.append(result[\"S14\"])\n",
    "#     S15_data.append(result[\"S15\"])\n",
    "# # åˆä½µæ•¸æ“š\n",
    "# baseline_df = pd.concat(baseline_data, ignore_index=True)\n",
    "# S1_df = pd.concat(S1_data, ignore_index=True)\n",
    "# S2_df = pd.concat(S2_data, ignore_index=True)\n",
    "# S12_df = pd.concat(S12_data, ignore_index=True)\n",
    "# S14_df = pd.concat(S14_data, ignore_index=True)\n",
    "# S15_df = pd.concat(S15_data, ignore_index=True)\n",
    "\n",
    "# dfs = {\n",
    "#     \"baseline\": baseline_df,\n",
    "#     \"S1\": S1_df,\n",
    "#     \"S2\": S2_df,\n",
    "#     \"S12\": S12_df,\n",
    "#     \"S15\": S15_df,\n",
    "#     \"S14\": S14_df,\n",
    "# }\n",
    "\n",
    "# # èª¿ç”¨ç¹ªåœ–å‡½æ•¸\n",
    "# plot_strategies_profits_scatter(f\"{status}_{model_prefix}\", dfs)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "BmCtfhVmxlqf",
    "HTASer1nQ6iQ",
    "aRmALsClGzQB",
    "zg9HWiZOypqj",
    "FTJPzWLlAz8L",
    "yXuk_hytiwhv",
    "lQUlr1TGYuqf",
    "uleVduhQ5KpR",
    "igerpH_M5KpT",
    "6EOHpsM05KpT"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
